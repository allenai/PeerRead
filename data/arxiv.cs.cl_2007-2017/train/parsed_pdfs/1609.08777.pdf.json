{
  "name" : "1609.08777.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Character Sequence Models for Colorful Words",
    "authors" : [ "Kazuya Kawakami", "Chris Dyer", "Bryan R. Routledge", "Noah A. Smith" ],
    "emails" : [ "kkawakam@cs.cmu.edu,", "cdyer@cs.cmu.edu,", "routledge@cmu.edu,", "nasmith@cs.washington.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 9.\n08 77\n7v 1\n[ cs\n.C L\n] 2\n8 Se\nWe present a neural network architecture to predict a point in color space from the sequence of characters in the color’s name. Using large scale color–name pairs obtained from an online color design forum, we evaluate our model on a “color Turing test” and find that, given a name, the colors predicted by our model are preferred by annotators to color names created by humans. Our datasets and demo system are available online at http://colorlab.us."
    }, {
      "heading" : "1 Introduction",
      "text" : "Color is a valuable vehicle for studying the association between words and their nonlinguistic referents. Perception of color has long been studied in psychology, and quantitative models linking physical stimuli and psychological perception have been in place since the 1920s (Broadbent, 2004). Although perceptually faithful color representations require only a few dimensions (§2), linguistic expressions of color often rely on association and figurative language. There are, for example, 34,000 examples of “blue” in our data. The varieties of blue range can be emotional, descriptive, metaphoric, literal, and whimsical. Consider these examples (best viewed in color): murkey blue, blueberry muffin, greeny blue, and jazzy blue.\nThis rich variety of descriptive names of colors provides an ideal way to study linguistic creativity, its variation, and an important aspect of visual understanding. This paper uses predictive modeling to explore the relationship between colors (represented\nin three dimensions) and casual, voluntary linguistic descriptions of them by users of a crafting and design website (§3).1\nIn this dataset’s creative vocabulary, word-level representations are so sparse as to be useless, so we turn to models that build name representations out of characters (§4). We evaluate our model on a “color Turing test” and find that, given a name, it tends to generate a color that humans find matches the name better than the color that actually inspired the name. We also investigate the reverse mapping, from colors to names (§5). We compare a conditional LSTM language model used in caption generation (Karpathy and Fei-Fei, 2014) to a new latentvariable model, achieving a 10% perplexity reduction.\nWe expect such modeling to find purchase in computational creativity applications (Veale and Al-Najjar, 2015), design and marketing aids (Deng et al., 2010), and new methods for studying the interface between the human visual and linguistic systems (Marcus, 1991)."
    }, {
      "heading" : "2 Color Spaces",
      "text" : "In electronic displays and other products, colors are commonly represented in RGB space where each color is embedded in {0, . . . , 255}3, with coordinates corresponding to red, green, and blue levels. While convenient for digital processing, distances in this space are perceptually non-uniform. We instead use a different three-dimensional representation, Lab , which was originally designed so that Euclidean distances correlate with human-perceived\n1http://www.colourlovers.com\ndifferences (Hunter, 1958). Lab is also continuous, making it more suitable for the gradient-based learning used in this paper. The transformation from RGB to Lab is nonlinear."
    }, {
      "heading" : "3 Task and Dataset",
      "text" : "We consider the task of predicting a color in Lab space given its name. Our dataset is a collection of user-named colors downloaded from COLOURlovers,1 a creative community where people create and share colors, palettes, and patterns. Our dataset contains 776,364 pairs with 581,483 unique names. Examples of the color/name pairs from COLOURlovers are the following: Sugar Hearts You, Vitamin C, Haunted milk.\nWe considered two held-out datasets from other sources; these do not overlap with the training data. ggplot2: the 141 officially-named colors used in ggplot2, a common plotting package for the R programming language (e.g., MidnightBlue. MediumSeaGreen),2 Paint: The paint manufacturer Sherwin Williams has 7,750 named colors (e.g., Pompeii Red, Butter Up).3"
    }, {
      "heading" : "4 Names to Colors",
      "text" : "Our word-to-color model is used to predict a color in Lab space given the sequence of characters in a color’s name, c = 〈c1, c2, . . . , c|c|〉, where each ci is a character in a finite alphabet. Each character ci is represented by learned vector embedding in R 300. To build a color out of the sequence, we use an LSTM (Hochreiter and Schmidhuber, 1997) with 300 hidden units. The final hidden state is used as a\n2http://sape.inf.usi.ch/quick-_reference/ggplot2/colour 3http://bit.ly/PaintColorNames\nvector representation h ∈ R300 of the sequence. The associated color value in Lab space is then defined to be ŷ = σ(Wh + b), where W ∈ R3×300 and b ∈ R3 transform h.\nThis model instantiates the one proposed by Ling et al. (2015) for learning word embeddings built from representations of characters.\nTo learn the parameters of the model (i.e., the parameters of the LSTMs, the character embeddings, and W and b), we use reference color labels y from our training set and minimize squared error, ||y − ŷ||2, averaged across the training set. Learning is accomplished using backpropagation and the Adam update rule (Kingma and Ba, 2014)."
    }, {
      "heading" : "4.1 Evaluation",
      "text" : "We evaluated our model in two ways. First, we computed mean-squared error on held-out data using several variants of our model. The baseline models are linear regression models, which predict a color from a bag of character unigrams and bigrams. We compare an RNN and LSTMs with one and two layers. Table 2 shows that the two-layer LSTM achieves lower error than the unigram and bigram baselines and an RNN. We see the same pattern of results on the out-of-domain test sets.\nThe Color Turing Test. Our second evaluation attempts to assess whether our model’s associations are human-like. For this evaluation, we asked human judges to choose the color better described by a name from one of our test sets: our model’s predicted color or the color in the data. For each dataset, we randomly selected 20 examples. 111 judges considered each instance.4 Judges were presented instances in random order and forced to make a choice between the two and explicitly directed to\n4We excluded results from an additional 19 annotators wh made more than one mistake in a color blindness test (Oliver, 1888).\nmake an arbitrary choice if neither was better.5 The test is shown at http://colorlab.us/turk.\nResults are shown in Table 3; on the ggplot2 and Paint datasets, our prediction is preferred to the actual names in a majority of cases. The Test dataset from COLOURlovers is a little bit challenging, with more noisy and creative names; still, in the majority of cases, our prediction is preferred."
    }, {
      "heading" : "4.2 Visualization and Exploration",
      "text" : "To better understand our model, we provide illustrations of its predictions on several kinds of inputs.\nCharacter by character prediction. We consider how our model reads color names character by character. Fig. 1 shows some examples, such as blue, variously modified. The word deep starts dark brown, but eventually modifies blue to a dark blue. Our model also performs sensibly on colors named after things (mint, cream, sand).\nGenre and color. We can use our model to investigate how colors are evoked in text by predicting the colors of each word in a text. Fig. 3 shows a colored recipe. Noting that many words are rendered in neutral grays and tans, we investigated how our model colors words in three corpora: 3,300 English poems (1800–present), 256 recipes from the CURD dataset\n5A preliminary study that allowed a judge to say that there was no difference led to a similar result.\n(Tasse and Smith, 2008),6 and 6,000 beer reviews.7 For each corpus, we examine the distribution of Euclidean distances of ŷ from the Lab representation of the “middle” color RGB (128, 128, 128). The Euclidean distances from the mean are measuring the variance of the color of words in a document. Fig. 2 shows these distributions; recipes and beer reviews are more “colorful” than poems, under our model’s learned definition of color."
    }, {
      "heading" : "5 Generating Names from Colors",
      "text" : "The first of our two color naming models generates character sequences conditioned on Lab color representations, following other sequenceto-sequence approaches (Sutskever et al., 2014; Karpathy and Fei-Fei, 2014). The transformation is as follows: First, a linear transformation maps the color vector into 300 dimensions, together\n6http://www.cs.cmu.edu/˜ark/CURD/ 7http://beeradvocate.com\ncomprising the initial hidden and memory vectors. Next a character LSTM is iteratively applied to the hidden, memory, and next-character vectors, and the next character produced by applying affine and then softmax functions to the hidden vector. The model is trained to maximize conditional likelihood of each character given its history. We used 300 dimensions for character embeddings and recurrence weights. The output vocabulary size was 98 without lowercasing.\nWe also propose a model to capture variations in color description with latent variables by extending the variational autoencoder (Kingma and Welling, 2013) to a conditional model. We want to model the conditional probability of word y and latent variables z given color x. The latent variable gives the model capacity to account for the complexity of the color–word mapping. Since p(y, z | x) = p(z)p(y | x, z), the variational objective is:\nEqφ(z|x)[− log qφ(z | x) + log pθ(y, z | x)]\n= Eqφ(z|x)[− log qφ(z | x) + log pθ(y | x, z)p(z)]\n≃ −DKL(qφ(z | x) || p(z)) + 1\nL\nL∑\nl=1\nlog pθ(y | x, z l)\nThe first term regularizes the shape of posterior, q(z | x), to be close to prior p(z) where it is a Gaussian distribution, p(z) = N (0, I). The second term is the log likelihood of the character sequence conditioned on color values. To optimize θ and φ, we reparameterize the model, we write z in terms of a mean and variance and samples from a standard normal distribution, i.e., z = µ + σǫ with ǫ ∼ N (0, I). We predict mean and log variance of the model with a multi-layer perceptron and initialize the decoder-LSTM with h0 = tanh(Wz + b). We trained the model with mini-batch size 128 and Adam optimizer. The sample size L was set to 1.\nEvaluation. We evaluated our models by estimating perplexity on the Test set (Table 1). Our baseline is a character-level unconditional LSTM language model. Conditioning on color improved percharacter perplexity by 7% and the latent variable gave a further 3%; see Table 4.\nA second dataset we evaluate on is the Munroe Color Corpus8 which contains 2,176,417 color description for 829 words (i.e., single words have mul-\n8https://blog.xkcd.com/2010/05/03/color-_survey-_results/\ntiple color descriptions). Monroe et al. (2016) have developed word-based (rather character-based) recurrent neural network model.\nOur character-based model with 1024 hidden units achieved 12.48 per-description perplexity, marginally better than 12.58 obtained with a wordbased neural network model reported in that work. Thus, we see that modeling color names as sequences of characters is wholly feasible. However, since the corpus only contains color description for 829 words, the model trained on the Munroe Color Corpus does not provide suitable supervision for evaluation on our more lexically diverse dataset."
    }, {
      "heading" : "6 Related Work and Discussion",
      "text" : "Color is one of the lowest-level visual signals playing an important role in cognition (Wurm et al., 1993) and behavior (Maier et al., 2008; Lichtenfeld et al., 2009). It plays a role in human object recognition: to name an object, we first need to encode visual information such as shape and surface information including color and texture. Given a visual encoding, we search our memory for a structural, semantic and phonological description (Humphreys et al., 1999). Adding color information to shape significantly improves naming accuracy and speeds correct response times (Rossion et al., 2004).\nColors and their names have some association in our cognition. The Stroop (1935) effect is a wellknown example showing interference of colors and color terms: when we see a color term printed in a different color—blue—it takes us longer to name the word, and we are more prone to naming errors than when the ink matches—blue (De Houwer, 2003).\nRecent evidence suggests that colors and words are associated in the brain. The brain uses different regions to perceive various modalities, but processing a color word activates the same brain region as the color it denotes (del Prado Martı́n et al., 2006;\nSimmons et al., 2007). Closer to NLP, the relationship between visual stimuli and their linguistic descriptions by humans has been explored extensively through automatic text generation from images (Kiros et al., 2014; Karpathy and Fei-Fei, 2014; Xu et al., 2015). Color association with word semantics has also been investigated in several previous papers (Mohammad, 2011; Heer and Stone, 2012; Andreas and Klein, 2014; McMahan and Stone, 2015)."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we introduced a computational model to predict a point in color space from the sequence of characters in the color’s name. Using a large set of color–name pairs obtained from a color design forum, we evaluate our model on a “color Turing test” and find that, given a name, the colors predicted by our model are preferred by annotators to color names created by humans. We also investigate the reverse mapping, from colors to names. We compare a conditional LSTM language model to a new latent-variable model, achieving a 10% perplexity reduction."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Lucas Beyer for very helpful comments and discussions, and we also appreciate all the participants of our color Turing test."
    } ],
    "references" : [ {
      "title" : "Grounding language with points and paths in continuous spaces",
      "author" : [ "Andreas", "Klein2014] Jacob Andreas", "Dan Klein" ],
      "venue" : "In CoNLL,",
      "citeRegEx" : "Andreas et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Andreas et al\\.",
      "year" : 2014
    }, {
      "title" : "A critical review of the development of the CIE1931 RGB colormatching functions",
      "author" : [ "Arthur D. Broadbent" ],
      "venue" : "Color Research & Application,",
      "citeRegEx" : "Broadbent.,? \\Q2004\\E",
      "shortCiteRegEx" : "Broadbent.",
      "year" : 2004
    }, {
      "title" : "Category specificity in the processing of color-related and form-related words: An erp study",
      "author" : [ "Olaf Hauk", "Friedemann Pulvermüller" ],
      "venue" : null,
      "citeRegEx" : "Martı́n et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Martı́n et al\\.",
      "year" : 2006
    }, {
      "title" : "Consumer preferences for color combinations: An empirical analysis of similarity-based color relationships",
      "author" : [ "Deng et al.2010] Xiaoyan Deng", "Sam K. Hui", "J. Wesley Hutchinson" ],
      "venue" : "Journal of Consumer Psychology,",
      "citeRegEx" : "Deng et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2010
    }, {
      "title" : "Color naming models for color selection, image editing and palette design",
      "author" : [ "Heer", "Stone2012] Jeffrey Heer", "Maureen Stone" ],
      "venue" : "In Proc. CHI",
      "citeRegEx" : "Heer et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Heer et al\\.",
      "year" : 2012
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "Jürgen Schmidhuber" ],
      "venue" : "Neural computation,",
      "citeRegEx" : "Hochreiter et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Hochreiter et al\\.",
      "year" : 1997
    }, {
      "title" : "From objects to names: A cognitive neuroscience approach",
      "author" : [ "Cathy J. Price", "M. Jane Riddoch" ],
      "venue" : null,
      "citeRegEx" : "Humphreys et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Humphreys et al\\.",
      "year" : 1999
    }, {
      "title" : "Photoelectric color difference meter. Josa, 48(12):985–993",
      "author" : [ "Richard S. Hunter" ],
      "venue" : null,
      "citeRegEx" : "Hunter.,? \\Q1958\\E",
      "shortCiteRegEx" : "Hunter.",
      "year" : 1958
    }, {
      "title" : "Deep visual-semantic alignments for generating image descriptions",
      "author" : [ "Karpathy", "Fei-Fei2014] Andrej Karpathy", "Li FeiFei" ],
      "venue" : "arXiv preprint arXiv:1412.2306",
      "citeRegEx" : "Karpathy et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Karpathy et al\\.",
      "year" : 2014
    }, {
      "title" : "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980",
      "author" : [ "Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba" ],
      "venue" : null,
      "citeRegEx" : "Kingma et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kingma et al\\.",
      "year" : 2014
    }, {
      "title" : "Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114",
      "author" : [ "Kingma", "Welling2013] Diederik P. Kingma", "Max Welling" ],
      "venue" : null,
      "citeRegEx" : "Kingma et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Kingma et al\\.",
      "year" : 2013
    }, {
      "title" : "Multimodal neural language models",
      "author" : [ "Kiros et al.2014] Ryan Kiros", "Ruslan Salakhutdinov", "Rich Zemel" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning",
      "citeRegEx" : "Kiros et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kiros et al\\.",
      "year" : 2014
    }, {
      "title" : "The semantic red effect: Processing the word red undermines intellectual performance",
      "author" : [ "Lichtenfeld", "Markus A. Maier", "Andrew J. Elliot", "Reinhard Pekrun." ],
      "venue" : "Journal of Experimental Social",
      "citeRegEx" : "Lichtenfeld et al\\.,? 2009",
      "shortCiteRegEx" : "Lichtenfeld et al\\.",
      "year" : 2009
    }, {
      "title" : "Character-based neural machine translation. CoRR, abs/1511.04586",
      "author" : [ "Ling et al.2015] Wang Ling", "Isabel Trancoso", "Chris Dyer", "Alan W Black" ],
      "venue" : null,
      "citeRegEx" : "Ling et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ling et al\\.",
      "year" : 2015
    }, {
      "title" : "Mediation of the negative effect of red on intellectual performance",
      "author" : [ "Andrew J. Elliot", "Stephanie Lichtenfeld" ],
      "venue" : "Personality and Social Psychology Bulletin",
      "citeRegEx" : "Maier et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Maier et al\\.",
      "year" : 2008
    }, {
      "title" : "Graphic design for electronic documents and user",
      "author" : [ "Aaron Marcus" ],
      "venue" : null,
      "citeRegEx" : "Marcus.,? \\Q1991\\E",
      "shortCiteRegEx" : "Marcus.",
      "year" : 1991
    }, {
      "title" : "A Bayesian model of grounded color semantics. Transactions of the Association for Computational Linguistics, 3:103–115",
      "author" : [ "McMahan", "Stone2015] Brian McMahan", "Matthew Stone" ],
      "venue" : null,
      "citeRegEx" : "McMahan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "McMahan et al\\.",
      "year" : 2015
    }, {
      "title" : "Colourful language: Measuring word-colour associations",
      "author" : [ "Saif Mohammad" ],
      "venue" : null,
      "citeRegEx" : "Mohammad.,? \\Q2011\\E",
      "shortCiteRegEx" : "Mohammad.",
      "year" : 2011
    }, {
      "title" : "Learning to generate compositional color descriptions",
      "author" : [ "Monroe et al.2016] Will Monroe", "Noah D. Goodman", "Christopher Potts" ],
      "venue" : "In Proc. EMNLP",
      "citeRegEx" : "Monroe et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Monroe et al\\.",
      "year" : 2016
    }, {
      "title" : "Tests for colorblindness",
      "author" : [ "Charles A Oliver" ],
      "venue" : "Transactions of the American Ophthalmological Society,",
      "citeRegEx" : "Oliver.,? \\Q1888\\E",
      "shortCiteRegEx" : "Oliver.",
      "year" : 1888
    }, {
      "title" : "Revisiting snodgrass and vanderwart’s object pictorial set: The role of surface detail in basiclevel object recognition",
      "author" : [ "Gilles Pourtois" ],
      "venue" : null,
      "citeRegEx" : "Rossion and Pourtois,? \\Q2004\\E",
      "shortCiteRegEx" : "Rossion and Pourtois",
      "year" : 2004
    }, {
      "title" : "A common neural substrate for perceiving and knowing about color",
      "author" : [ "W. Kyle Simmons", "Vimal Ramjee", "Michael S. Beauchamp", "Ken McRae", "Alex Martin", "Lawrence W. Barsalou" ],
      "venue" : null,
      "citeRegEx" : "Simmons et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Simmons et al\\.",
      "year" : 2007
    }, {
      "title" : "Studies of interference in serial verbal reactions",
      "author" : [ "J. Ridley Stroop" ],
      "venue" : "Journal of experimental psychology,",
      "citeRegEx" : "Stroop.,? \\Q1935\\E",
      "shortCiteRegEx" : "Stroop.",
      "year" : 1935
    }, {
      "title" : "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104–3112",
      "author" : [ "Oriol Vinyals", "Quoc VV Le" ],
      "venue" : null,
      "citeRegEx" : "Sutskever et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Sour cream: Toward semantic processing of recipes",
      "author" : [ "Tasse", "Smith2008] Dan Tasse", "Noah A Smith" ],
      "venue" : "Technical report,",
      "citeRegEx" : "Tasse et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Tasse et al\\.",
      "year" : 2008
    }, {
      "title" : "Unweaving the lexical rainbow: Grounding linguistic creativity in perceptual semantics",
      "author" : [ "Veale", "Al-Najjar2015] Tony Veale", "Khalid AlNajjar" ],
      "venue" : null,
      "citeRegEx" : "Veale et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Veale et al\\.",
      "year" : 2015
    }, {
      "title" : "Color improves object recognition in normal and low vision",
      "author" : [ "Wurm et al.1993] Lee H. Wurm", "Gordon E. Legge", "Lisa M. Isenberg", "Andrew Luebker" ],
      "venue" : "Journal of Experimental Psychology: Human perception and performance,",
      "citeRegEx" : "Wurm et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Wurm et al\\.",
      "year" : 1993
    }, {
      "title" : "Show, attend and tell: Neural image caption generation",
      "author" : [ "Xu et al.2015] Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Aaron Courville", "Ruslan Salakhutdinov", "Richard Zemel", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Xu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Perception of color has long been studied in psychology, and quantitative models linking physical stimuli and psychological perception have been in place since the 1920s (Broadbent, 2004).",
      "startOffset" : 170,
      "endOffset" : 187
    }, {
      "referenceID" : 3,
      "context" : "We expect such modeling to find purchase in computational creativity applications (Veale and Al-Najjar, 2015), design and marketing aids (Deng et al., 2010), and new methods for studying the interface between the human visual and linguistic systems (Marcus, 1991).",
      "startOffset" : 137,
      "endOffset" : 156
    }, {
      "referenceID" : 15,
      "context" : ", 2010), and new methods for studying the interface between the human visual and linguistic systems (Marcus, 1991).",
      "startOffset" : 100,
      "endOffset" : 114
    }, {
      "referenceID" : 7,
      "context" : "differences (Hunter, 1958).",
      "startOffset" : 12,
      "endOffset" : 26
    }, {
      "referenceID" : 13,
      "context" : "This model instantiates the one proposed by Ling et al. (2015) for learning word embeddings built from representations of characters.",
      "startOffset" : 44,
      "endOffset" : 63
    }, {
      "referenceID" : 19,
      "context" : "We excluded results from an additional 19 annotators wh made more than one mistake in a color blindness test (Oliver, 1888).",
      "startOffset" : 109,
      "endOffset" : 123
    }, {
      "referenceID" : 23,
      "context" : "The first of our two color naming models generates character sequences conditioned on Lab color representations, following other sequenceto-sequence approaches (Sutskever et al., 2014; Karpathy and Fei-Fei, 2014).",
      "startOffset" : 160,
      "endOffset" : 212
    }, {
      "referenceID" : 18,
      "context" : "Monroe et al. (2016) have developed word-based (rather character-based) recurrent neural network model.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 26,
      "context" : "Color is one of the lowest-level visual signals playing an important role in cognition (Wurm et al., 1993) and behavior (Maier et al.",
      "startOffset" : 87,
      "endOffset" : 106
    }, {
      "referenceID" : 14,
      "context" : ", 1993) and behavior (Maier et al., 2008; Lichtenfeld et al., 2009).",
      "startOffset" : 21,
      "endOffset" : 67
    }, {
      "referenceID" : 12,
      "context" : ", 1993) and behavior (Maier et al., 2008; Lichtenfeld et al., 2009).",
      "startOffset" : 21,
      "endOffset" : 67
    }, {
      "referenceID" : 6,
      "context" : "Given a visual encoding, we search our memory for a structural, semantic and phonological description (Humphreys et al., 1999).",
      "startOffset" : 102,
      "endOffset" : 126
    }, {
      "referenceID" : 22,
      "context" : "The Stroop (1935) effect is a wellknown example showing interference of colors and color terms: when we see a color term printed in a different color—blue—it takes us longer to name the word, and we are more prone to naming errors than when the ink matches—blue (De Houwer, 2003).",
      "startOffset" : 4,
      "endOffset" : 18
    }, {
      "referenceID" : 11,
      "context" : "Closer to NLP, the relationship between visual stimuli and their linguistic descriptions by humans has been explored extensively through automatic text generation from images (Kiros et al., 2014; Karpathy and Fei-Fei, 2014; Xu et al., 2015).",
      "startOffset" : 175,
      "endOffset" : 240
    }, {
      "referenceID" : 27,
      "context" : "Closer to NLP, the relationship between visual stimuli and their linguistic descriptions by humans has been explored extensively through automatic text generation from images (Kiros et al., 2014; Karpathy and Fei-Fei, 2014; Xu et al., 2015).",
      "startOffset" : 175,
      "endOffset" : 240
    }, {
      "referenceID" : 17,
      "context" : "Color association with word semantics has also been investigated in several previous papers (Mohammad, 2011; Heer and Stone, 2012; Andreas and Klein, 2014; McMahan and Stone, 2015).",
      "startOffset" : 92,
      "endOffset" : 180
    } ],
    "year" : 2016,
    "abstractText" : "We present a neural network architecture to predict a point in color space from the sequence of characters in the color’s name. Using large scale color–name pairs obtained from an online color design forum, we evaluate our model on a “color Turing test” and find that, given a name, the colors predicted by our model are preferred by annotators to color names created by humans. Our datasets and demo system are available online at http://colorlab.us.",
    "creator" : "LaTeX with hyperref package"
  }
}