{
  "name" : "1703.06959.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "CSI: A Hybrid Deep Model for Fake News Detection",
    "authors" : [ "Natali Ruchansky", "Sungyong Seo", "Yan Liu" ],
    "emails" : [ "natalir@bu.edu", "sungyons@usc.edu", "yanliu.cs@usc.edu", "permissions@acm.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this work, we propose a model that combines all three characteristics for a more accurate and automated prediction. Speci cally, we incorporate the behavior of both parties, users and articles, and the group behavior of users who propagate fake news. Motivated by the three characteristics, we propose a model called CSI which is composed of three modules: Capture, Score, and Integrate. e rst module is based on the response and text; it uses a Recurrent Neural Network to capture the temporal pa ern of user activity on a given article. e second module learns the source characteristic based on the behavior of users, and the two are integrated with the third module to classify an article as fake or not. Experimental analysis on real-world data demonstrates that CSI achieves higher accuracy than existing models, and extracts meaningful latent representations of both users and articles.\nKEYWORDS Fake news detection, Neural networks, Deep learning, Social networks, Group anomaly detection, Temporal analysis."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Fake news on social media has experienced a resurgence of interest due to the recent political climate and the growing concern around its negative e ect. For example, in January 2017, a spokesman for the German government stated that they “are dealing with a phenomenon of a dimension that [they] have not seen before”, referring to the proliferation of fake news [3]. Not only does it provide a\n∗ ese authors contributed equally to this work.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. CIKM’17 , Singapore, Singapore © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. 978-1-4503-4918-5/17/11. . .$15.00 DOI: 10.1145/3132847.3132877\nsource of spam in our lives, but fake news also has the potential to manipulate public perception and awareness in a major way.\nDetecting misinformation on social media is an extremely important but also a technically challenging problem. e di culty comes in part from the fact that even the human eye cannot accurately distinguish true from false news; for example, one study found that when shown a fake news article, respondents found it “‘somewhat’ or ‘very’ accurate 75% of the time”, and another found that 80% of high school students had a hard time determining whether an article was fake [2, 9]. In an a empt to combat the growing misinformation and confusion, several fact-checking websites have been deployed to expose or con rm stories (e.g. snopes.com). ese websites play a crucial role in combating fake news, but they require expert analysis which inhibits a timely response. As a response, numerous articles and blogs have been wri en to raise public awareness and provide tips on di erentiating truth from falsehood [29]. While each author provides a di erent set of signals to look out for, there are several characteristics that are generally agreed upon, relating to the text of an article, the response it receives, and its source.\ne most natural characteristic is the text of an article. Advice in the media varies from evaluating whether the headline matches the body of the article, to judging the consistency and quality of the language. A empts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-cra ed and data-speci c textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34]. ese approaches are limited by the fact that the linguistic characteristics of fake news are still not yet fully understood. Further, the characteristics vary across di erent types of fake news, topics, and media platforms.\nA second characteristic is the response that a news article is meant to illicit. Advice columns encourage readers to consider how a story makes them feel – does it provoke either anger or an emotional response? e advice stems from the observation that fake news o en contains opinionated and in ammatory language, cra ed as click bait or to incite confusion [8, 33]. For example, the New York Times cited examples of people pro ting from publishing fake stories online; the more provoking, the greater the response, and the larger the pro t [26]. E orts to automate response detection typically model the spread of fake news as an epidemic on a social graph [12, 16, 17, 35], or use hand-cra ed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classi er [6, 18, 25, 27, 41, 45]. Unfortunately, access to a social graph is not always feasible in practice, and manual selection of features is labor intensive.\nA nal characteristic is the source of the article. Advice here ranges from checking the structure of the url, to the credibility of the media source, to the pro le of the journalist who authored it; in fact, Google has recently banned nearly 200 publishers to aid this\nar X\niv :1\n70 3.\n06 95\n9v 4\n[ cs\n.L G\n] 3\nS ep\n2 01\n7\ntask [37]. In the interest of exposure to a large audience, a set of loyal promoters may be deployed to publicize and disseminate the content. In fact, several small-scale analyses have observed that there are o en groups of users that heavily publicize fake news, particularly just a er its publication [1, 22]. For example, Figure 1 shows an example of three Twi er users who consistently promote the same fake news stories. Approaches here typically focus on data-dependent user behaviors, or identifying the source of an epidemic, and disregard the fake news articles themselves [31, 40].\nEach of the three characteristics mentioned above has ambiguities that make it challenging to successfully automate fake news detection based on just one of them. Linguistic characteristics are not fully understood, hand-cra ed features are data-speci c and arduous, and source identi cation does not trivially lead to fake news detection. In this work, we build a more accurate automated fake news detection by utilizing all three characteristics at once: text, response, and source. Instead of relying on manual feature selection, the CSI model that we propose is built upon deep neural networks, which can automatically select important features. Neural networks also enable CSI to exploit information from di erent domains and capture temporal dependencies in users engagement with articles. A key property of CSI is that it explicitly outputs information both on articles and users, and does not require the existence of a social graph, domain knowledge, nor assumptions on the types and distribution of behaviors that occur in the data.\nSpeci cally, CSI is composed of one module for each side of the activity, user and article – Figure 3b illustrates the intuition. e rst module, called Capture, exploits the temporal pa ern of user activity, including text, to capture the response a given article received. Capture is constructed as a Recurrent Neural Network (more precisely an LSTM) which receives article-speci c information such as the temporal spacing of user activity on the article and a doc2vec [19] representation of the text generated in this activity (such as a tweet). e second module, which we call Score, uses a neural network and an implicit user graph to extract a representation and assign a score to each user that is indicative of their propensity to participate in a source promotion group. Finally, the third module, Integrate, combines the response, text, and source information from the rst two modules to classify each article as fake or not. e three module composition of CSI allows it to independently learn characteristics from both sides\nof the activity, combine them for a more accurate prediction and output feedback both on the articles (as a falsehood classi cation) and on the users (as a suspiciousness score).\nExperiments on two real-world datasets demonstrate that by incorporating text, response, and source, the CSI model achieves signi cantly higher classi cation accuracy than existing models. In addition, we demonstrate that both the Capture and Score modules provide meaningful information on each side of the activity. Capture generates low-dimensional representations of news articles and users that can be used for tasks other than classi cation, and Score rates users by their participation in group behavior. e main contributions can be summarized as:\n(1) To the best of our knowledge, we propose the rst model that explicitly captures the three common characteristics of fake news, text, response, and source, and identi es misinformation both on the article and on the user side. (2) e proposed model, which we call CSI, evades the cost of manual feature selection by incorporating neural networks. e features we use capture the temporal behavior and textual content in a general way that does not depend on the data context nor require distributional assumptions. (3) Experiments on real world datasets demonstrate that CSI is more accurate in fake news classi cation than previous work, while requiring fewer parameters and training."
    }, {
      "heading" : "2 RELATEDWORK",
      "text" : "e task of detecting fake news has undergone a variety of labels, from misinformation, to rumor, to spam. Just as each individual may have their own intuitive de nition of such related concepts, each paper adopts its own de nition of these words which con icts or overlaps both with other terms and other papers. For this reason, we specify that the target of our study is detecting news content that is fabricated, that is fake. Given the disparity in terminology, we overview existing work grouped loosely according to which of the three characteristics (text, response, and source) it considers.\nere has been a large body of work surrounding text analysis of fake news and similar topics such as rumors or spam. is work has focused on mining particular linguistic cues, for example, by nding anomalous pa erns of pronouns, conjunctions, and words associated with negative emotional word usage [10, 28]. For example, Gupta et al. [13] found that fake news o en contain an\nin ated number of swear words and personal pronouns. Branching o of the core linguistic analysis, many have combined the approach with traditional classi ers to label an article as true or false [6, 11, 18, 25, 27, 41, 45]. Unfortunately, the linguistic indicators of fake news across topic and media platform are not yet well understood; Rubin et al. [34] explained that there are many types of fake news, each with di erent potential textual indicators. us existing works design hand-cra ed features which is not only laborious but highly dependent on the speci c dataset and the availability of domain knowledge to design appropriate features. To expand beyond the speci city of hand-cra ed features, Ma et al. [24] proposed a model based on recurrent neural networks that uses mainly linguistic features. In contrast to [24], the CSI model we propose captures all three characteristics, is able to isolate suspicious users, and requires fewer parameters for a more accurate classi cation.\ne response characteristic has also received a ention in existing work. Outside of the fake news domain, Castillo et al. [5] showed that the temporal pa ern of user response to news articles plays an important role in understanding the properties of the content itself. From a slightly di erent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35]. e epidemic approach requires access to a graph which is infeasible in many scenarios. Another approach has been to utilize hand-cra ed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classi er [6, 18, 25, 27, 41, 45]. As with the linguistic features, these works require feature-engineering which is laborious and lacks generality.\ne nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38]. Another approach identi es group anomalies. Early work in group anomaly detection assumed that the groups were known a priori, and the goal was to detect which of them were anomalous [31]. Such information is not feasible in practice, hence later works propose variants of mixtures models for the data, where the learned parameters are used to identify the anomalous groups [42, 43]. Muandet et al. [30] took a similar approach by combining kernel embedding with an SVM classi er. Most recently, Yu et al. [44] proposed a uni ed hierarchical Bayes model to infer the groups and detect group anomalies simultaneously. ere has also been a strong line of work surrounding detecting suspicious user behavior of various types; a nice overview is given in [15]. Of this line, the most related is the CopyCatch model proposed in [4], which identi es temporal bipartite cores of user activity on pages. In contrast to existing works, the CSI model we propose can identify group anomalies as well as the core behaviors they are responsible for (fake news). e model does not require group information as input, does not make assumptions about a particular distribution, and learns a representation and score for each user.\nIn contrast to the vast array of work highlighted here, the CSI model we propose does not rely on hand-cra ed features, domain knowledge, or distributional assumptions, o ering a more general modeling of the data. Further, CSI captures all three characteristics and outputs both a classi cation of articles, a scoring of users, and representations of both users and articles that can be used for in separate analysis."
    }, {
      "heading" : "3 PROBLEM",
      "text" : "In this section we rst lay out preliminaries, and then discuss the context of fake news which we address. Preliminaries: We consider a series of temporal engagements that occurred between n users with m news-articles over time [1,T ]. Each engagement between a user ui and an article aj at time t is represented as ei jt = (ui ,aj , t). In particular, in our se ing, an engagement is composed of textual information relayed by the user ui about article aj , at time t ; for example, a tweet or a Facebook post. Figure 2 illustrates the se ing. In addition, we assume that each news article is associated with a label L(aj ) = 0 if the news is true, and L(aj ) = 1 if it is false. roughout we will use italic characters x for scalars, bold characters h for vectors, and capital bold characters W for matrices.\nstory published\nGoal: While the overarching theme of this work is fake news detection, the goal is two fold (1) accurately classify fake news, and (2) identify groups of suspicious users. In particular, given a temporal sequence of engagements E = {ei jt = (ui ,aj , t)}, our goal is to produce a label L̂(aj ) ∈ [0, 1] for each article, and a suspiciousness score si for each user. To do this we encapsulate the text, response, and source characteristics in a model and capture the temporal behavior of both parties, users and articles, as well as textual information exchanged in the activity. We make no assumptions on the distribution of user behavior, nor on the context of the engagement activity."
    }, {
      "heading" : "4 MODEL",
      "text" : "In this section, we give the details of the proposed model, which we call CSI. e model consists of two main parts, a module for extracting temporal representation of news articles, and a module for representing and scoring the behavior of users. e former captures the response characteristic described in Section 1 while incorporating text, and the la er captures the source characteristic. Speci cally, CSI is composed of the following three parts, the speci cation and intuition of which is shown in Figure 3:\n(1) Capture: To extract temporal representations of articles we use a Recurrent Neural Network (RNN). Temporal engagements are stored as vectors and are fed into the RNN which produces an output a representation vector vj . (2) Score: To compute a score si and representation ỹi , userfeatures are fed into a fully connected layer and a weight is applied to produce the scores vectors s. (3) Integrate: e outputs of the two modules are concatenated and the resultant vector is used for classi cation.\nWith the rst two modules, Capture and Score, the CSI model extracts representations of both users and articles as low-dimensional vectors; these representations are important for the fake news task, but can also be used for independent analysis of users and articles.\nwc\nL̂j\n⊙\nCapture\nScore\ns\nvj\nmj\n. . .\nh1 hT\nx1 xTxt\nx̃tx̃1 x̃T\n...\nws\nIntegrate\npj ... ... yi si ...\n...\nWu\nWa Wa Wa\n...\n...\nỹi\n...\nWr ...\n...\nỹi\n(a) e CSI model speci cation. e Capture module depicts the LSTM for a single article aj , while the Scoremodule operates over all users. e output of Score is then ltered to be relevant to aj .\nCapture\nScore\nIntegrate\narticle published\n.\n. .\nuser vector and score\nper-article score\narticle vector\nFAKE!\n.\n. . . . .\n(b) Intuition behind CSI. Here, Capture receives the temporal series of engagements, and Score is fed an implicit user graph constructed from the engagements over all articles in the data.\nFigure 3: An illustration of the proposed CSI model.\nIn addition, Score produces a score for each user as a compact version of the vector. e Integrate module then combines the article representations with the user scores for an ultimate prediction of the veracity of an article. In the sections that follow, we discuss the details of each module.\n4.1 Capture news article representation In the rst module, we seek to capture the pa ern of temporal engagement of users with an article aj both in terms of the frequency and distribution. In other words, we wish to capture not only the number of users that engaged with aj in Figure 3b, but also how the engagements were spaced over time. Further, we incorporate textual information naturally available with the engagement, such as the text of a tweet, in a general and automated way.\nAs the core of the rst module, we use a Recurrent Neural Network (RNN), since RNNs have been shown to be e ective at capturing temporal pa erns in data and for integrating di erent sources of information. A key component of Capture is the choice of features used as input to the cells for each article. Our feature vector xt has the following form:\nxt = (η,∆t ,xu ,xτ ) e rst two variables, η and ∆t , capture the temporal pa ern of engagement an article receives with two simple, yet powerful quantities: the number of engagements η, and the time between engagements ∆t . Together, η and ∆t provide a general of measure the frequency and distribution of the response an article received. Next, we incorporate source by adding a user feature vector xu that is global and not speci c to a given article. In line with existing literature on information retrieval and recommender systems [21], we construct the binary incidence matrix of which articles a user engaged with, and apply the Singular Value Decomposition (SVD) to extract a lower-dimensional representation for each ui . Finally, a vector xτ is included which carries the text characteristic of an engagement with a given article aj . To avoid hand-cra ed textual feature selection for xτ , we use doc2vec [19] on the text of each engagement. Further technical details will be explained in Section 5.\nSince the temporal and textual features come from di erent domains, it is not desirable to incorporate them into the RNN as raw input. To standardize the input features, we insert an embedding layer between the raw features xt and the inputs x̃t of the RNN. is embedding layer is a fully connected layer as following:\nx̃t = tanh(Waxt + ba )\nwhere Wa is a weight matrix applied to the raw features xt at time t and ba is a bias vector. Both Wa and ba are the xed for all xt . To capture the temporal response of users to an article, we construct the Capture module using a Long Short-Term Memory (LSTM) model because of its propensity for capturing long-term dependencies and its exibility in processing inputs of variable lengths. For the sake of brevity we do not discuss the well-established LSTM model here, but refer the interested reader to [14] for more detail.\nWhat is important for our discussion is that in the nal step of the LSTM, x̃T is fed as input and the last hidden state hT is passed to the fully connected layer. e result is a vector:\nvj = tanh(WrhT + br )\nis vector serves as a low dimension representation of the temporal pa ern of engagements a given article aj received– capturing both the response and textual characteristics. e vectors vj will be fed to the Integrate module for article classi cation, but can also be used for stand-alone analysis of articles. Partitioning: In principle, the feature vector xt associated with each engagement can be considered as an input into a cell; however, this would be highly ine cient for large data. A more e cient approach is to partition a given sequence by changing the granularity, and using an aggregate of each partition (such as an average) as input to a cell. Speci cally, the feature vector for article aj at partition t has the following form: η is the number of engagements that occurred in partition t , ∆t holds the time between the current and previous non-empty partitions, xu is the average of user-features over users ui that engaged with aj during t , and τ is the textual content exchanged during t .\n4.2 Score users In the second module, we wish to capture the source characteristic present in the behavior of users. To do this, we seek a compact representation that will have the same (small) dimension for every article (since it will ultimately be used in the Integrate module). Given a set of user features, we rst apply a fully connected layer to extract vector representations of each user as follows:\nỹi = tanh(Wuyi + bu ) where Wu is the weight matrix and bu is the bias; L2-regularization is used on Wu with parameter λ. is results in a vector representation ỹi for each user ui that is learned jointly with the Capture module. To aggregate this information, we apply a weight vector ws to produce a scalar score si for each user as: si = σ (w>s · ỹi + bs ) with bs as the bias of a fully connected layer, and σ as the sigmoid function. e set of si forms the vector s of user scores.\nIn principle, user features can be constructed using information from the users social network pro le. Since we wish to capture the source characteristic, we construct a weighted user graph where an edge denotes the number of articles with which two users have both engaged. Users who engage in group behavior will correspond to dense blocks in the adjacency matrix. Following the literature, we apply the SVD to the adjacency matrix and extract a lowerdimensional feature yi for each user, ultimately obtaining (si , ỹi ) for each user ui .\nBy constructing the Score module in this way, CSI is able to jointly learn from the two sides of the engagements while extracting information that is meaningful to the source characteristic. As with the Capture module, the vector ỹi can be used for stand-alone analysis of the users.\n4.3 Integrate to classify\nEach of the Capture and Score modules outputs information on articles and users with respect to the three characteristics of interest. In order to incorporate the two sources of information, we propose a third module as the nal step of CSI in which article representations vj are combined with the user scores si to produce a label prediction L̂j for each article.\nTo integrate the two modules, we apply a maskmj to the vector s that selects only the entries si whose corresponding userui engaged with a given articleaj . ese values are average to producepj which captures the suspiciousness score of the users that engage with the speci c article aj . e overall score pj is concatenated with vj from Capture, and the resultant vector cj is fed into the last fully connected layer to predict the label L̂j of article aj .\nL̂j = σ (w>c cj + bc ) is integration step enables the modules to work together to form a more accurate prediction. By jointly training the CSI with the Capture and Score modules, the model learns both user and article information simultaneously. At the same time, the CSI model generates information on articles and users that captures di erent important characteristics of the fake news problem, and combines the information for an ultimate prediction.\nTraining: e loss function for training CSI is speci ed as:\nLoss = − 1 N N∑ j=1 [ Lj log L̂ J + (1 − Lj ) log(1 − L̂j ) ] + λ 2 | |Wu | |22\nwhere Lj is a the ground-truth label. To reduce over ing in CSI, random units in Wa and Wr are dropped out for training. Under these constraints, the parameters in Capture, Score, and Integrate are jointly trained by back-propagation."
    }, {
      "heading" : "4.4 Generality",
      "text" : "We have presented the CSI model in the context of fake news; however, our model can be easily generalized to any dataset. Consider a set of engagements between an actor qi and a target r j over time t ∈ [0,T ], in other words, the article in Figure 3b is a target and each user is an actor. e Capture module can be used to capture the temporal pa erns of engagements exhibited on targets by actors, and Score can be used to extract a score and representation of each actor qi that captures the participation in group behavior. Finally, Integrate combines the rst two modules to enhance the prediction quality on targets. For example, consider users accessing a set of databases. e Capture module can identify databases which received an unusual pa ern of access, and Score can highlight users that were likely responsible. In addition, the exibility of CSI allows for integration of additional domain knowledge."
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : "In this section, we demonstrate the quality of CSI on two real world datasets. In the main set of experiments, we evaluate the accuracy of the classi cation produced by CSI. In addition, we investigate the quality of the scores and representations produced by the Score module and show that they are highly related to the score characteristic. Finally, we show the robustness of our model when labeled data is limited and investigate temporal behaviors of suspicious users. Datasets In order to have a fair comparison, we use two realworld social media datasets that have been used in previous work, Twitter and Weibo [24]. To date, these are the only publicly available datasets that include all three characteristics: response, text, and user information. Each dataset has a number of articles with labels L(aj ); in Twitter the articles are news stories, and in Weibo they are discussion topics. Each article also has a set of engagements (tweets) made by a user ui at time t . A summary of the statistics is listed in Table 1."
    }, {
      "heading" : "5.1 Model setup",
      "text" : "We rst describe the details of two important components in CSI: 1) how to obtain the temporal partitions discussed in Section 4 and 2) the speci c features for each dataset. Partitioning: As mentioned in Section 4, treating each time-stamp as its own input to a cell can be extremely ine cient and can reduce utility. Hence, we propose to partition the data into segments, each of which will be an input to a cell. We apply a natural partitioning by changing the temporal granularity from seconds to hours. Hyperparameters: We use cross-validation to set the regularization parameter for the loss function in Section 4.3 to λ = 0.01, the dropout probability as 0.2, the learning rate to 0.001, and use the Adam optimizer. Features: Recall from Section 4 that Capture operates on xt = (η,∆t ,xu ,xτ ) – temporal, user, and textual features. To apply doc2vec[19] to the Weibo data, we rst apply Chinese text segmentation.1 To extract xu , we apply the SVD with rank 20 for Twitter and 10 for Weibo, resulting in 122 dimensional xt for Twitter and 112 for Weibo. (SVD dimension chosen using the Scree plot.) We then set the embedding dimension so that each x̃t has dimension 100. e SVD rank for xi for Score is 50 for both datasets, and the dimension of Wu is 100."
    }, {
      "heading" : "5.2 Fake news classi cation accuracy",
      "text" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classi cation tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24]. Further, to evaluate the utility of di erent features included in the model, we consider CI as the CSI model using only textual features xt = (xτ ), CI-t as using textual and temporal features xt = (η,∆t ,xτ ), and nally CSI using textual, temporal, and user features. Since the rst two do not incorporate user information, we omit the S from the name. All RNN-based models including LSTM-1 and GRU-2 were implemented with eano2 and tested with Nvidia Tesla K40c GPU. e AdaGrad algorithm is used as an optimizer for LSTM-1 and GRU-2 as per [24]. For CSI, we used the Adam algorithm.\n1h ps://github.com/fxsjy/jieba 2h p://deeplearning.net/so ware/theano\nTable 2 shows the classi cation results using 80% of entire data as training samples, 5% to tune parameters, and the remaining 15% for testing; we use 5-fold cross validation. is division is chosen following previous work for fair comparison, and will be studied in later sections. We see that CSI outperforms other models in both accuracy and F-score. Speci cally, CI shows similar performance with GRU-2 which is a more complex 2-layer stacked network. is performance validates our choice of capturing fundamental temporal behavior, and demonstrates how a simpler structure can bene t from be er features and partitioning. Further, it shows the bene t of utilizing doc2vec over simple tf-idf.\nNext, we see that CI-t exhibits an improvement of more than 1% in both accuracy and F-score over CI. is demonstrated that while linguistic features may carry some temporal properties, the frequency and distribution of engagements caries useful information in capturing the di erence between true and fake news.\nFinally, CSI gives the best performance over all comparison models and versions. We see that integrating user features boosts the overall numbers up to 4.3% from GRU-2. Put together, these results demonstrate that CSI successfully captures and leverages all three characteristics of text, response, and source, for accurately classifying fake news."
    }, {
      "heading" : "5.3 Model complexity",
      "text" : "In practice, the availability of labeled examples of true and fake news may be limited, hence, in this section, we study the usability of CSI in terms of the number of parameters and amount of labeled training samples it requires.\nAlthough CSI is based on deep neural networks, the compact set of features that Capture utilizes results in fewer required parameters than other models. Furthermore, the user relations in Score can deliver condensed representations which cannot be captured by an RNN, allowing CSI to have less parameters than other RNNbased models. In particular, the model has on the order of 52K parameters, whereas GRU-2 has 621K parameter.\nTo study the number of labeled samples CSI relies on, we study the accuracy as a function of the training set size. Figure 4 shows that even if only 10% training samples are available, CSI can show comparable performance with GRU-2; thus, the CSI model is lighter and can be trained more easily with fewer training samples."
    }, {
      "heading" : "5.4 Interpreting user representations",
      "text" : "In this section, we analyze the output of Score which is a score si and a representation ỹi for every user. Since the available data does not have ground-truth labels on users, we perform a qualitative evaluation of the information contained in (si , ỹi ) with respect to the source characteristic of fake news.\nAlthough we lack user-labels, the dataset still contains information that can be used as a proxy. In particular, we want to evaluate whether (si , ỹi ) captures the suspicious behavior of users in terms promotion of fake news and group behavior. For the former, a reasonable proxy is the fraction of fake news a user engages with, denoted `i ∈ [0, 1] with 0.0 meaning the user has never reacted to fake news, and 1.0 meaning the engagements are exclusively with fake news. In addition, we consider the corresponding scores for articles as the average over users, namely pj is the average of si and λj is the average of `i over ui that engaged with aj .\nTo test the extent to which (si , ỹi ) capture `i , we compute the correlation between the two measures across users; Table 3 shows the Pearson correlation coe cient and signi cance. For both datasets and on both sides of the user-article engagement, we nd a statistically signi cant positive relationship between the two scores. Results are consistent for the Spearman coe cient and for ordinary least squares regression(OLS). In addition, Figures 5a and 5b show the distribution of `i among a subset of users with highest and lowest si . Most of the users who were assigned a high si by CSI (marked as most suspicious) have `i close to 1, while those with low si have low `i . Altogether, the results demonstrate that si and pj hold meaningful information with respect to user levels of engagement with fake news.\nTo investigate the relation of ỹi to `i , we regress the cosine distance between ỹi and ỹi′ against the di erence between `i and `i′ for each pair of users (i, i ′). Consistent with results for si , we nd a positive correlation of 0.631 for Twitter and 0.867 for Weibo, both of which are statistically signi cant at the 1% level. Further, we visualize the space of user representations by projecting a sample of the vectors ỹi onto the rst and second singular vectors µ1 and µ2 of the matrix of ỹi ’s. Figure 6 shows the projection for both datasets, where each point corresponds to a user ui and is colored according to `i . We see that the space exhibits a strong separation between users with extreme `i , suggesting that the vectors ỹi o er a good latent representation of user behavior with respect to fake news and can be used for deeper user analysis.\nNext, we analyze the propensity of (si , ỹi ) to capture group behavior. We construct an implicit user graph by adding an edge between users who have engaged with the same article, and by analyze the clustering of users in the graph. We apply the BiMax algorithm proposed by Prelić et al. [32] to search for biclusters in the adjacency matrix.3 We nd that for both datasets, users with large `i participate in more and larger biclusters than those with low `i . Further, biclusters for users with large `i are formed largely with fake news articles, while those for low `i are largely with true news.\nis suggests that suspicious users exhibit the source characteristic with respect to fake news. In addition, for each pair of users (ui ,ui′)we compute the Jaccard distance between the set of articles they interacted with. We compute the correlation between this quantity and |si − si′ | as well as the cosine distance between ỹi and ỹi′ . For the former we nd a correlation of 0.36 for Twitter and 0.21 for Weibo, and for the la er we nd 0.30 for Twitter and 0.16 for Weibo. All results are signi cant at the 1% level, with Spearman correlation and OLS giving consistent results.\nOverall, despite lack of ground-truth labels on users, our analysis demonstrates that the Score module captures meaningful information with respect to the the source characteristic. e user score si provides the model with an indication of the suspiciousness of user ui with respect to group behavior and fake news engagement. Further, the ỹi vector provides a representation of each user that can be used for deeper analysis of user behavior in the data.\n3BiMax available here h p://www.kemaleren.com/the-bimax-algorithm.html"
    }, {
      "heading" : "5.5 Characterizing user behavior",
      "text" : "In this section, we ask whether the users marked as suspicious by CSI have any characteristic behavior. Using the si scores of each user we select approximately 25 users from the most suspicious groups, and the same amount from the least suspicious group.\nWe consider two properties of user behavior: (1) the lag and (2) the activity. To measure lag for each user, we compute the lag in time between time between an article’s publication, and when the user rst engaged with it. We then plot the distribution of user lags separated by most and least suspicious, and true and fake news. Figure 7 shows the CDF of the results. Immediately we see that the most suspicious users in each dataset are some of the rst to promote the fake content – supporting the source characteristic. In contrast, both types of users act similarly on real news.\nNext, we measure the user activity as the time between engagements user ui had with a particular article aj . Figure 8 shows the CDF of user activity. We see that on both datasets, suspicious users o en have bursts of quick engagements with a given article; this behavior di ers more signi cantly from the least suspicious users on fake news than it does on true news. Interestingly, the behavior of suspicious users on Twitter is similar on fake and true news, which may demonstrate a sophistication in fake content promotion techniques. Overall, these distributions show that the combination of temporal, textual, and user features in xt provides meaningful information to capture the three key characteristics, and for CSI to distinguishing suspicious users."
    }, {
      "heading" : "5.6 Utilizing temporal article representations",
      "text" : "In this section, we investigate the vector vj that is the output of Capture for each article aj . Intuitively, these vectors are a lowdimensional representation of the temporal and textual response an article has received, as well as the types of users the response has come from. In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classi cation [20]. Hence, in the context of this work it is natural to wondering whether these vectors can be used for deeper insight into the space of articles.\nAs an example, we consider applying Spectral Clustering for a more ne-grained partition than two classes. We consider the set of vj associated with the test set of Twitter and Weibo articles, and set k = 5 clusters according to the elbow curve. Figure 9 shows\nthe results in the space of the rst two singular vectors (µ1 and µ2) of the matrix formed by the vectors vj for each respective dataset, with one color for each cluster.\nTable 4 shows the breakdown of true and false articles in each cluster. We can see that the results gives a natural division both among true and fake articles. For example, on the Twitter datasets, while both C2 and C4 are composed of mostly fake news, we can see that the projections of their temporal representation are quite separated. is separation suggests that there may be di erent types of fake news which exhibit slightly di erent signals in the text, response, and source characteristics, for example, satire and spam. e Weibo data shows two poles: C1 in the top le corresponds largely to true news, while C2 and C4 captures di erent types of fake news. Meanwhile, C3 and C5 which are spread across the middle, have more mixed membership.\nIn the context of the general framework described in Section 4, the results show that the vj vectors produced by the Capture module o er insight into the population of users with respect to their behavior towards fake news. Aside from the classi cation output of the model, the representations can be used stand-alone for gaining insight about targets (articles) in the data."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "In this work, we study the timely problem of fake news detection. While existing work has typically addressed the problem by focusing on either the text, the response an article receives, or the users who source it, we argue that it is important to incorporate all three. We propose the CSI model which is composed of three modules. e rst module, Capture, captures the abstract temporal behavior of user encounters with articles, as well as temporal textual and user features, to measure response as well as the text. e second component, Score, estimates a source suspiciousness score for every user, which is then combined with the rst module by Integrate to produce a predicted label for each article.\ne separation into modules allows CSI to output a prediction separately on users and articles, incorporating each of the three characteristics, meanwhile combining the information for classi - cation. Experiments on two real-world datasets demonstrate the accuracy of CSI in classifying fake news articles. Aside from accurate prediction, the CSI model also produces latent representations of both users and articles that can be used for separate analysis; we demonstrate the utility of both the extracted representations and the computed user scores.\ne CSI model is general in that it does not make assumptions on the distribution of user behavior, on the particular textual context of the data, nor on the underlying structure of the data. Further, by utilizing the power of neural networks, we incorporate di erent sources of information, and capture the temporal evolution of engagements from both parties, users and articles. At the same time, the model allows for easy incorporation of richer data, such as user pro le information, or advanced text libraries. Overall our\nwork demonstrates the value in modeling the three intuitive and powerful characteristics of fake news.\nDespite encouraging results, fake news detection remains a challenging problem with many open questions. One particularly interesting direction would be to build models that incorporate concepts from reinforcement learning and crowd sourcing. Including humans in the learning process could lead to more accurate and, in particular, more timely predictions."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "is work is supported in part by NSF Research Grant IIS-1619458 and IIS-1254206. e views and conclusions are those of the authors and should not be interpreted as representing the o cial policies of the funding agency, or the U.S. Government."
    } ],
    "references" : [ {
      "title" : "Copycatch: stopping group aacks by spoing lockstep behavior in social networks",
      "author" : [ "Alex Beutel", "Wanhong Xu", "Venkatesan Guruswami", "Christopher Palow", "Christos Faloutsos" ],
      "venue" : "In Proceedings of the 22nd international conference on World Wide Web",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Characterizing the life cycle of online news stories using social media reactions",
      "author" : [ "Carlos Castillo", "Mohammed El-Haddad", "Jürgen Pfeer", "Ma Stempeck" ],
      "venue" : "In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Information credibility on twier",
      "author" : [ "Carlos Castillo", "Marcelo Mendoza", "Barbara Poblete" ],
      "venue" : "In Proceedings of the 20th international conference on World wide web",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "DeBot: Twier Bot Detection via Warped Correlation",
      "author" : [ "Nikan Chavoshi", "Hossein Hamooni", "Abdullah Mueen" ],
      "venue" : "IEEE 16th International Conference on Data Mining (ICDM)",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "Misleading online content: Recognizing clickbait as false news",
      "author" : [ "Yimin Chen", "Niall J Conroy", "Victoria L Rubin" ],
      "venue" : "In Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Americans Believe ey Can Detect Fake News",
      "author" : [ "Bre Edkins" ],
      "venue" : "Studies Show ey Can’t. (December",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2016
    }, {
      "title" : "Detecting Deceptive Opinions with Prole Compatibility",
      "author" : [ "Vanessa Wei Feng", "Graeme Hirst" ],
      "venue" : "In IJCNLP",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Emergent: a novel data-set for stance classication",
      "author" : [ "William Ferreira", "Andreas Vlachos" ],
      "venue" : "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language  Technologies. ACL",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Rumor Cascades",
      "author" : [ "Adrien Friggeri", "Lada A Adamic", "Dean Eckles", "Justin Cheng" ],
      "venue" : "In ICWSM",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Tweetcred: Real-time credibility assessment of content on twier",
      "author" : [ "Aditi Gupta", "Ponnurangam Kumaraguru", "Carlos Castillo", "Patrick Meier" ],
      "venue" : "In International Conference on Social Informatics",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Recurrent neural networks for time series classication",
      "author" : [ "Michael Hüsken", "Peter Stagge" ],
      "venue" : "Neurocomputing",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Suspicious behavior detection: Current trends and future directions",
      "author" : [ "Meng Jiang", "Peng Cui", "Christos Faloutsos" ],
      "venue" : "IEEE Intelligent Systems 31,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "Epidemiological modeling of news and rumors on twier",
      "author" : [ "Fang Jin", "Edward Dougherty", "Parang Saraf", "Yang Cao", "Naren Ramakrishnan" ],
      "venue" : "In Proceedings of the 7th Workshop on Social Network Mining and Analysis. ACM,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes",
      "author" : [ "Srijan Kumar", "Robert West", "Jure Leskovec" ],
      "venue" : "In Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Commiee,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "Rumor Detection over Varying Time Windows",
      "author" : [ "Sejeong Kwon", "Meeyoung Cha", "Kyomin Jung" ],
      "venue" : "PLOS ONE 12,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2017
    }, {
      "title" : "Distributed Representations of Sentences and Documents",
      "author" : [ "oc V Le", "Tomas Mikolov" ],
      "venue" : "In ICML,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Sequential short-text classi- cation with recurrent and convolutional neural networks",
      "author" : [ "Ji Young Lee", "Franck Dernoncourt" ],
      "venue" : "arXiv preprint arXiv:1603.03827",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2016
    }, {
      "title" : "Mining of massive datasets",
      "author" : [ "Jure Leskovec", "Anand Rajaraman", "Jerey David Ullman" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2014
    }, {
      "title" : "Fake News Is Not the Only Problem. (November 2016)",
      "author" : [ "Gilad Lotan" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2016
    }, {
      "title" : "Identifying infection sources and regions in large networks",
      "author" : [ "Wuqiong Luo", "Wee Peng Tay", "Mei Leng" ],
      "venue" : "IEEE Transactions on Signal Processing 61,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "Detecting rumors from microblogs with recurrent neural networks",
      "author" : [ "Jing Ma", "Wei Gao", "Prasenjit Mitra", "Sejeong Kwon", "Bernard J Jansen", "Kam-Fai Wong", "Meeyoung Cha" ],
      "venue" : "Proceedings of IJCAI",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2016
    }, {
      "title" : "Detect rumors using time series of social context information on microblogging websites",
      "author" : [ "Jing Ma", "Wei Gao", "Zhongyu Wei", "Yueming Lu", "Kam-Fai Wong" ],
      "venue" : "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2015
    }, {
      "title" : "How Fake News Goes Viral: A Case Study",
      "author" : [ "Sapa Maheshwari" ],
      "venue" : null,
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2016
    }, {
      "title" : "Social spam detection",
      "author" : [ "Benjamin Markines", "Ciro Cauto", "Filippo Menczer" ],
      "venue" : "In Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2009
    }, {
      "title" : "Linguistic traces of a scientic fraud: e case of Diederik Stapel",
      "author" : [ "David M Markowitz", "Jerey T Hancock" ],
      "venue" : "PloS one 9,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2014
    }, {
      "title" : "How to tell fake news from real news. (January 2017)",
      "author" : [ "Laura McClure" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2017
    }, {
      "title" : "One-class support measure machines for group anomaly detection",
      "author" : [ "Krikamol Muandet", "Bernhard Schölkopf" ],
      "venue" : "arXiv preprint arXiv:1303.0309",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2013
    }, {
      "title" : "Spoing fake reviewer groups in consumer reviews",
      "author" : [ "Arjun Mukherjee", "Bing Liu", "Natalie Glance" ],
      "venue" : "In Proceedings of the 21st international conference on World Wide Web",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2012
    }, {
      "title" : "A systematic comparison and evaluation of biclustering methods for gene expression data",
      "author" : [ "Amela Prelić", "Stefan Bleuler", "Philip Zimmermann", "Anja Wille", "Peter Bühlmann", "Wilhelm Gruissem", "Lars Hennig", "Lothar iele", "Eckart Zitzler" ],
      "venue" : "Bioinformatics 22,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2006
    }, {
      "title" : "Deception Detection and Rumor Debunking for Social Media",
      "author" : [ "Victoria L Rubin" ],
      "venue" : null,
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2017
    }, {
      "title" : "Deception detection for news: three types of fakes",
      "author" : [ "Victoria L Rubin", "Yimin Chen", "Niall J Conroy" ],
      "venue" : "Proceedings of the Association for Information Science and Technology",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2015
    }, {
      "title" : "Rumors, false ags, and digital vigilantes: Misinformation on twier aer the 2013 boston marathon bombing",
      "author" : [ "Kate Starbird", "Jim Maddock", "Mania Orand", "Peg Achterman", "Robert M Mason" ],
      "venue" : "iConference 2014 Proceedings",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2014
    }, {
      "title" : "Sequence to sequence learning with neural networks. In Advances in neural information processing",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "oc V Le" ],
      "venue" : null,
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2014
    }, {
      "title" : "Google has banned 200 publishers since it passed a new policy against fake news. (January 2017)",
      "author" : [ "Tess Townsend" ],
      "venue" : "google-adsense-advertisers-publishers-fake-news",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2017
    }, {
      "title" : "Online human-bot interactions: Detection, estimation, and characterization",
      "author" : [ "Onur Varol", "Emilio Ferrara", "Clayton A Davis", "Filippo Menczer", "Alessandro Flammini" ],
      "venue" : null,
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2017
    }, {
      "title" : "A Long Short-Term Memory Model for Answer Sentence Selection in estion Answering",
      "author" : [ "Di Wang", "Eric Nyberg" ],
      "venue" : "In ACL",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2015
    }, {
      "title" : "Rumor source detection with multiple observations: Fundamental limits and algorithms",
      "author" : [ "Zhaoxu Wang", "Wenxiang Dong", "Wenyi Zhang", "Chee Wei Tan" ],
      "venue" : "In ACM SIGMETRICS Performance Evaluation Review,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2014
    }, {
      "title" : "False rumors detection on sina weibo by propagation structures",
      "author" : [ "Ke Wu", "Song Yang", "Kenny Q Zhu" ],
      "venue" : "In Data Engineering (ICDE),",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2015
    }, {
      "title" : "Group anomaly detection using exible genre models",
      "author" : [ "Liang Xiong", "Barnabás Póczos", "Je G Schneider" ],
      "venue" : "In Advances in neural information processing systems",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2011
    }, {
      "title" : "Hierarchical Probabilistic Models for Group Anomaly Detection",
      "author" : [ "Liang Xiong", "Barnabás Póczos", "Je G Schneider", "Andrew J Connolly", "Jake VanderPlas" ],
      "venue" : "AISTATS",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2011
    }, {
      "title" : "Glad: group anomaly detection in social media analysis",
      "author" : [ "Rose Yu", "Xinran He", "Yan Liu" ],
      "venue" : "ACM Transactions on Knowledge Discovery from Data (TKDD) 10,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2015
    }, {
      "title" : "Enquiring minds: Early detection of rumors in social media from enquiry posts",
      "author" : [ "Zhe Zhao", "Paul Resnick", "Qiaozhu Mei" ],
      "venue" : "In Proceedings of the 24th International Conference on World Wide Web",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2015
    }, {
      "title" : "Information source detection in the SIR model: A sample-path-based approach",
      "author" : [ "Kai Zhu", "Lei Ying" ],
      "venue" : "IEEE/ACM Transactions on Networking (TON) 24,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "e diculty comes in part from the fact that even the human eye cannot accurately distinguish true from false news; for example, one study found that when shown a fake news article, respondents found it “‘somewhat’ or ‘very’ accurate 75% of the time”, and another found that 80% of high school students had a hard time determining whether an article was fake [2, 9].",
      "startOffset" : 359,
      "endOffset" : 365
    }, {
      "referenceID" : 25,
      "context" : "As a response, numerous articles and blogs have been wrien to raise public awareness and provide tips on dierentiating truth from falsehood [29].",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 7,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 9,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 20,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 23,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 24,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 30,
      "context" : "Aempts to automate the evaluation of text have manifested in sophisticated natural language processing and machine learning techniques that rely on hand-craed and data-specic textual features to classify a piece of text as true or false [11, 13, 24, 27, 28, 34].",
      "startOffset" : 240,
      "endOffset" : 264
    }, {
      "referenceID" : 4,
      "context" : "Advice columns encourage readers to consider how a story makes them feel – does it provoke either anger or an emotional response? e advice stems from the observation that fake news oen contains opinionated and inammatory language, craed as click bait or to incite confusion [8, 33].",
      "startOffset" : 278,
      "endOffset" : 285
    }, {
      "referenceID" : 29,
      "context" : "Advice columns encourage readers to consider how a story makes them feel – does it provoke either anger or an emotional response? e advice stems from the observation that fake news oen contains opinionated and inammatory language, craed as click bait or to incite confusion [8, 33].",
      "startOffset" : 278,
      "endOffset" : 285
    }, {
      "referenceID" : 22,
      "context" : "New York Times cited examples of people proting from publishing fake stories online; the more provoking, the greater the response, and the larger the prot [26].",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 8,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 13,
      "endOffset" : 29
    }, {
      "referenceID" : 12,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 13,
      "endOffset" : 29
    }, {
      "referenceID" : 13,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 13,
      "endOffset" : 29
    }, {
      "referenceID" : 31,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 13,
      "endOffset" : 29
    }, {
      "referenceID" : 2,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 14,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 21,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 23,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 37,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 41,
      "context" : "social graph [12, 16, 17, 35], or use hand-craed features that are social-network dependent, such as the number of Facebook likes, combined with a traditional classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 33,
      "context" : "task [37].",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 18,
      "context" : "In fact, several small-scale analyses have observed that there are oen groups of users that heavily publicize fake news, particularly just aer its publication [1, 22].",
      "startOffset" : 161,
      "endOffset" : 168
    }, {
      "referenceID" : 27,
      "context" : "Approaches here typically focus on data-dependent user behaviors, or identifying the source of an epidemic, and disregard the fake news articles themselves [31, 40].",
      "startOffset" : 156,
      "endOffset" : 164
    }, {
      "referenceID" : 36,
      "context" : "Approaches here typically focus on data-dependent user behaviors, or identifying the source of an epidemic, and disregard the fake news articles themselves [31, 40].",
      "startOffset" : 156,
      "endOffset" : 164
    }, {
      "referenceID" : 15,
      "context" : "information such as the temporal spacing of user activity on the article and a doc2vec [19] representation of the text generated in this activity (such as a tweet).",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 6,
      "context" : "by nding anomalous paerns of pronouns, conjunctions, and words associated with negative emotional word usage [10, 28].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 24,
      "context" : "by nding anomalous paerns of pronouns, conjunctions, and words associated with negative emotional word usage [10, 28].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "[13] found that fake news oen contain an",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 7,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 14,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 21,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 23,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 37,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 41,
      "context" : "Branching o of the core linguistic analysis, many have combined the approach with traditional classiers to label an article as true or false [6, 11, 18, 25, 27, 41, 45].",
      "startOffset" : 143,
      "endOffset" : 170
    }, {
      "referenceID" : 30,
      "context" : "[34] explained that there are many types of fake news, each with dierent potential textual indicators.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[24] proposed a model based on recurrent neural networks that uses mainly linguistic features.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "In contrast to [24], the CSI model we propose captures all three characteristics, is able to isolate suspicious users, and requires fewer parameters for a more accurate classication.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "[5] showed that the temporal paern of user response to news articles plays an important role in understanding the properties of the content itself.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "From a slightly dierent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].",
      "startOffset" : 160,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : "From a slightly dierent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].",
      "startOffset" : 160,
      "endOffset" : 176
    }, {
      "referenceID" : 13,
      "context" : "From a slightly dierent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].",
      "startOffset" : 160,
      "endOffset" : 176
    }, {
      "referenceID" : 31,
      "context" : "From a slightly dierent point of view, one popular approach has been to measure the response an article received by studying its propagation on a social graph [12, 16, 17, 35].",
      "startOffset" : 160,
      "endOffset" : 176
    }, {
      "referenceID" : 2,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 14,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 21,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 23,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 37,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 41,
      "context" : "Another approach has been to utilize hand-craed socialnetwork dependent behaviors, such as the number of Facebook likes, as features in a classier [6, 18, 25, 27, 41, 45].",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 19,
      "context" : "e nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].",
      "startOffset" : 113,
      "endOffset" : 125
    }, {
      "referenceID" : 36,
      "context" : "e nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].",
      "startOffset" : 113,
      "endOffset" : 125
    }, {
      "referenceID" : 42,
      "context" : "e nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].",
      "startOffset" : 113,
      "endOffset" : 125
    }, {
      "referenceID" : 3,
      "context" : "e nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 34,
      "context" : "e nal characteristic, source, has been studied as the task of identifying the source of an epidemic on a graph [23, 40, 46], or isolating bots based on certain documented behaviors [7, 38].",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 27,
      "context" : "Early work in group anomaly detection assumed that the groups were known a priori, and the goal was to detect which of them were anomalous [31].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 38,
      "context" : "Such information is not feasible in practice, hence later works propose variants of mixtures models for the data, where the learned parameters are used to identify the anomalous groups [42, 43].",
      "startOffset" : 185,
      "endOffset" : 193
    }, {
      "referenceID" : 39,
      "context" : "Such information is not feasible in practice, hence later works propose variants of mixtures models for the data, where the learned parameters are used to identify the anomalous groups [42, 43].",
      "startOffset" : 185,
      "endOffset" : 193
    }, {
      "referenceID" : 26,
      "context" : "[30] took a similar approach by combining kernel embedding with an SVM classier.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 40,
      "context" : "[44] proposed a unied hierarchical Bayes model to infer the groups",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "ere has also been a strong line of work surrounding detecting suspicious user behavior of various types; a nice overview is given in [15].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 0,
      "context" : "Of this line, the most related is the CopyCatch model proposed in [4], which identies temporal bipartite cores of user activity on pages.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 17,
      "context" : "In line with existing literature on information retrieval and recommender systems [21], we construct the binary incidence matrix of which articles a user",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 15,
      "context" : "To avoid hand-craed textual feature selection for xτ , we use doc2vec [19] on the text of each engagement.",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 10,
      "context" : "For the sake of brevity we do not discuss the well-established LSTM model here, but refer the interested reader to [14] for more detail.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 20,
      "context" : "Datasets In order to have a fair comparison, we use two realworld social media datasets that have been used in previous work, Twitter and Weibo [24].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 15,
      "context" : "To apply doc2vec[19] to the Weibo data, we rst apply Chinese text segmentation.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 21,
      "context" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classication tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].",
      "startOffset" : 242,
      "endOffset" : 246
    }, {
      "referenceID" : 41,
      "context" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classication tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].",
      "startOffset" : 257,
      "endOffset" : 261
    }, {
      "referenceID" : 2,
      "context" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classication tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].",
      "startOffset" : 267,
      "endOffset" : 270
    }, {
      "referenceID" : 20,
      "context" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classication tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].",
      "startOffset" : 280,
      "endOffset" : 284
    }, {
      "referenceID" : 20,
      "context" : "In the main set of experiments, we use two real-world datasets, Twitter and Weibo, to compare the proposed CSI model with ve state-of-the-art models that have been used for similar classication tasks and were discussed in Section 2: SVM-TS [25] , DT-Rank [45], DTC [6] , LSTM-1 [24], and GRU-2 [24].",
      "startOffset" : 296,
      "endOffset" : 300
    }, {
      "referenceID" : 20,
      "context" : "e AdaGrad algorithm is used as an optimizer for LSTM-1 and GRU-2 as per [24].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 28,
      "context" : "[32] to search for biclusters in the adjacency matrix.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 32,
      "context" : "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classication [20].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 35,
      "context" : "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classication [20].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 16,
      "context" : "In a general sense, the output of an LSTM has been used for a variety of tasks such as machine translation [36], question answering [39], and text classication [20].",
      "startOffset" : 161,
      "endOffset" : 165
    } ],
    "year" : 2017,
    "abstractText" : "e topic of fake news has drawn aention both from the public and the academic communities. Such misinformation has the potential of aecting public opinion, providing an opportunity for malicious parties to manipulate the outcomes of public events such as elections. Because such high stakes are at play, automatically detecting fake news is an important, yet challenging problem that is not yet well understood. Nevertheless, there are three generally agreed upon characteristics of fake news: the text of an article, the user response it receives, and the source users promoting it. Existing work has largely focused on tailoring solutions to one particular characteristic which has limited their success and generality. In this work, we propose a model that combines all three characteristics for a more accurate and automated prediction. Specically, we incorporate the behavior of both parties, users and articles, and the group behavior of users who propagate fake news. Motivated by the three characteristics, we propose a model called CSI which is composed of three modules: Capture, Score, and Integrate. e rst module is based on the response and text; it uses a Recurrent Neural Network to capture the temporal paern of user activity on a given article. e second module learns the source characteristic based on the behavior of users, and the two are integrated with the third module to classify an article as fake or not. Experimental analysis on real-world data demonstrates that CSI achieves higher accuracy than existing models, and extracts meaningful latent representations of both users and articles.",
    "creator" : "LaTeX with hyperref package"
  }
}