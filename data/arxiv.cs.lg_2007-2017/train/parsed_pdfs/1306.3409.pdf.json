{
  "name" : "1306.3409.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Constrained fractional set programs and their  application in local clustering and community detection",
    "authors" : [ "Thomas Bühler", "Syama Sundar Rangapuram" ],
    "emails" : [ "tb@cs.uni-saarland.de", "srangapu@mpi-inf.mpg.de", "setzer@mia.uni-saarland.de", "hein@cs.uni-saarland.de" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Graph-based data appear in manifold ways in learning problems - either the data have already graph structure as in the case of social networks and biological networks or a similarity graph is constructed using a similarity measure based on features of the data. Several graph-based problems in clustering and community detection can be modelled as the optimization of\nProceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&CP volume 28. Copyright 2013 by the author(s).\na ratio of set functions (referred to here as fractional set program). Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al., 2010).\nIt turns out that in practice often additional background or domain knowledge about the learning problem is available. Such prior knowledge can then be incorporated as constraints into the optimization problem. In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm. Recently, Rangapuram & Hein (2012) proposed a generalization of the normalized cut problem that can handle must-link and cannot-link constraints. In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al. (2010) considered size and distance constraints for the maximum density subgraph problem.\nSince the above-mentioned combinatorial problems are NP-hard, the standard approach is to consider convex or spectral relaxations which can be solved globally optimally in polynomial time. Due to its practical efficiency the spectral relaxation is very popular in machine learning, e.g. spectral clustering (Hagen & Kahng, 1991; Shi & Malik, 2000). However, it is often quite loose and thus leads to a solution far away from the optimal one of the original problem. Moreover, spectral-type relaxations (Mahoney et al., 2012)\nar X\niv :1\n30 6.\n34 09\nv1 [\nst at\n.M L\n] 1\n4 Ju\nfail to guarantee that the constraints which encode the prior knowledge are satisfied.\nIn another line of work (Hein & Bühler, 2010; Szlam & Bresson, 2010; Hein & Setzer, 2011; Bresson et al., 2012), it has been shown that tight continuous relaxations exist for all balanced graph cut problems and the normalized cut subject to must-link and cannotlink constraints (Rangapuram & Hein, 2012). A tight relaxation means that the continuous and the combinatorial optimization problem are equivalent in the sense that the optimal values agree and the optimal solution of the combinatorial problem can be obtained from the continuous solution. While the resulting algorithms provide no guarantee to yield the globally optimal solution, the standard loose relaxations are outperformed by a large margin in practice.\nIn this paper we show that any constrained minimization problem of a ratio of non-negative set functions allows a tight relaxation into a continuous optimization problem. This result together with our efficient minimization techniques enables the easy integration of prior information in form of constraints into many problems in graph-based clustering and community detection. While the general framework introduced in this paper is applicable to all problems discussed so far, we will focus on two particular applications: local clustering by constrained balanced graph cuts, and community detection via constrained densest subgraph problems. Compared to previous work, the algorithms developed in this paper are the first to guarantee that all given constraints are fulfilled by the obtained solution. Note that in principle our method could also be applied to a setting with soft or noisy constraints, however we will focus here on the case of hard constraints. In the experimental section we will show the superior performance compared to state of the art methods (Andersen & Lang, 2006; Mahoney et al., 2012)."
    }, {
      "heading" : "2. Fractional set programs in clustering and community detection",
      "text" : "In the following, G = (V,W ) denotes an undirected, weighted graph with a non-negative, symmetric weight matrix W ∈ Rn×n, where n = |V |. Moreover, by assigning a non-negative weight gi to each vertex i, we can define the general volume of a subset A ⊂ V as volg(A) = ∑ i∈A gi. As special cases, we obtain for gi = 1 the cardinality |A| and for gi equal to the degree di = ∑ j∈V wij the classical volume vol(A) = vold(A). Furthermore, A = V \\A denotes the complement of A.\nThe balanced graph cut problem is a well-known problem in computer science with applications rang-\ning from parallel computing to image segmentation (Pothen et al., 1990; Shi & Malik, 2000). A very popular balanced graph cut criterion is the normalized cut1,\nNCut(C,C) = cut(C,C)\nvold(C) vold(C) , for C ⊂ V,\nwhere cut(C,C) := ∑ i∈C,j∈C wij . The spectral relaxation of the normalized cut leads to the popular spectral clustering method (von Luxburg, 2007). A related criterion is the normalized Cheeger cut,\nNCC(C,C) = cut(C,C)\nmin{vold(C), vold(C)} , for C ⊂ V.\nMore general balanced graph cuts were studied by Hein & Setzer (2011). In practice, often additional information about the desired solution is available which can be incorporated into the problem via constraints. This motivates us to consider a more general class of problems where one optimizes a ratio of set functions2 subject to constraints. In the following, we discuss two examples of constrained problems in network analysis.\nConstrained balanced graph cuts for local clustering. Recently, there has been a strong interest in balanced graph cut methods for local clustering. Starting with the work of Spielman & Teng (2004), initially, the goal was to develop an algorithm that finds a subset near a given seed vertex with small normalized cut or normalized Cheeger cut value with running time linear in the size of the obtained cluster. The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph. Algorithms of this type have been applied for community detection in networks (Andersen & Lang, 2006).\nIn contrast, Mahoney et al. (2012) give up the runtime requirement and formulate the task as an explicit optimization problem, where one aims at finding the optimal normalized cut subject to a seed constraint and an upper bound on the volume of the set containing the seed set. Again, the idea is to find a local cluster around a given seed set. Motivated by the standard spectral relaxation of the normalized cut problem, they derive a spectral-type relaxation which is biased towards solutions fulfilling the seed constraint. Their method has been successfully applied in semisupervised image segmentation (Maji et al., 2011) and for community detection around a given query set (Mahoney et al., 2012). However, while they provide an ap-\n1This is up to a constant factor the same as the usual definition, NCut(C,C) = cut(C,C)\n( 1\nvold(C) + 1 vold(C)\n) .\n2A set function Ŝ on a set V is a function Ŝ : 2V → R.\nproximation guarantee for their relaxation, they cannot guarantee that the returned solution satisfies seed and volume constraints.\nIn this paper we consider an extended version of the problem of Mahoney et al. (2012). Let J denote the\nset of seed vertices, Ŝ a symmetric balancing function (e.g. Ŝ(C) = vold(C) vold(C) for the normalized cut) and let volg(C) be the general volume of set C, where g ∈ Rn+ are vertex weights. The general local clustering problem can then be formulated as\nmin C⊂V\ncut(C,C)\nŜ(C) (1)\nsubject to : volg(C) ≤ k, and J ⊂ C.\nThe choice of the balancing function Ŝ allows the user to influence the trade-off between getting a partition with small cut and a balanced partition. One could also combine this with must- and cannot-link constraints (see Rangapuram & Hein, 2012) or add even more complex constraints such as an upper bound on the diameter of C. However, in order to compare to the method of Mahoney et al. (2012), we restrict ourselves in this paper to the normalized cut with volume constraints, that is Ŝ(C) = vold(C) vold(C) and g = d.\nConstrained local community detection. A second related problem is constrained local community detection. In community detection it makes more sense to find a highly connected set instead of emphasizing the separation to the remaining part of the graph by minimizing the cut. Thus, we are searching for a set C which has high association, defined as assoc(C) = ∑ i,j∈C wij . Dividing the association of C by its size yields the density of C. The subgraph of maximum density can be computed in polynomial time (Goldberg, 1984). However, the obtained communities in the unconstrained problem are typically either too large or too small, which calls for size constraints. Note that the introduction of such constraints makes the problem NP-hard (Khuller & Saha, 2009).\nA general class of (local) community detection problems can thus be formulated as\nmax C⊂V\nassoc(C)\nvolg(C) (2)\nsubject to : k1 ≤ volh(C) ≤ k2, and J ⊂ C,\nwhere g, h ∈ Rn+ are vertex weights. This formulation generalizes the above-mentioned density-based approaches by replacing the denominator by a general volume function volg. One can use the vertex weights g to bias the obtained community towards one with\ndesired properties by assigning small weights to vertices which one would prefer to occur in the solution and larger weights to ones which are less preferred.\nThe problem (2) with only lower bound constraints has been considered in team selection (Gajewar & Das Sarma, 2012) and bioinformatics (Saha et al., 2010) where constant factor approximation algorithms were developed. However, in the case of equality and upper bound constraints the problem is very hard even when using only cardinality constraints (i.e., hi = 1), and it has been shown that there is no polynomial time approximation scheme in these cases (Khot, 2006; Khuller & Saha, 2009). Our method can handle such hard upper bound and equality constraints. In the experiments we show results for a community detection problem with a specified query set J and an upper bound on the size for a co-author network.\nNote that if volg(C) = vold(C), one can decompose the objective of (2) analogously to the argument for the normalized cut (Shi & Malik, 2000) as\nassoc(C) vold(C) = 1− cut(C,C) vold(C) .\nThis implies that for volg(C) = vold(C) in (2) and Ŝ(C) = vold(C) in (1), the problem (2) is equivalent to (1) if we choose the same constraints. If one has only the constraint vold(C) ≤ 12 vold(V ) both problems are equivalent to the normalized Cheeger cut.\nContributions of this paper. We show that all constrained non-negative fractional set programs have an equivalent tight continuous relaxation. This general result enables the integration of prior information in form of constraints into clustering and community detection problems. In particular, it allows us to derive efficient algorithms for problems (1) and (2). Our algorithms consistently outperform competing methods (Andersen & Lang, 2006; Mahoney et al., 2012). Moreover, we are not aware of any other methods for the above problems which can guarantee that the solution always satisfies volume and seed constraints.\nAlthough the tight relaxation results in Hein & Setzer (2011) and Rangapuram & Hein (2012) encompass a large class of problems, they are not applicable to the problems considered in this paper because of the following limitations: First, tight relaxations were shown by Hein & Setzer (2011) only for a ratio of symmetric non-negative set functions, where the numerator is restricted to be submodular. We extend the results to arbitrary ratios of non-negative set functions without any restrictions concerning symmetry or submodularity. Second, only equality constraints for non-negative\nset functions restricted to be either submodular or supermodular could be handled by Rangapuram & Hein (2012). We generalize this to inequality constraints3 without any restrictions on the constraint set functions in order to handle the constraints in (1) and (2)."
    }, {
      "heading" : "3. Tight relaxations of fractional set programs with constraints",
      "text" : "The problems discussed in the last section can be written in the following general form:\nmin C⊂V\nR̂(C) Ŝ(C) =: Q̂(C) (3)\nsubject to : M̂i(C) ≤ ki, i = 1, . . . ,K\nwhere R̂, Ŝ, M̂i : 2 V → R are set functions on a set V = {1, . . . , n}. We assume here that R̂, Ŝ are nonnegative and that R̂(∅) = Ŝ(∅) = 0. No assumptions are made on the set functions M̂i, in particular they are not required to be non-negative. Thus also lower bound constraints can be written in the above form. Moreover, the formulation in (3) also encompasses the subset constraint J ⊂ C in (1) and (2) as it can be written as equality constraint |J | − |J ∩ C| = 0. Alternatively, we will discuss a direct integration of the subset constraint into the objective in Section 5.\nThe connection between the set-valued and the continuous space is achieved via thresholding. Let f ∈ Rn, and we assume wlog that f is ordered in ascending order f1 ≤ f2 ≤ · · · ≤ fn. One defines the sets\nCi := {j ∈ V |fj ≥ fi} , i = 1, . . . , n. (4)\nWe frequently make use of this notation in the following. Furthermore, we use 1C ∈ Rn to denote the indicator vector of the set C, i.e. the vector which is 1 at entry j if j ∈ C and 0 otherwise. A key tool for the derivation of the results of this paper is the Lovasz extension as a way to extend a set function (seen as function on the hypercube) to a function on Rn.\nDefinition 1 Let R̂ : 2V → R be a set function with R̂(∅) = 0, and f ∈ Rn in ascending order f1 ≤ f2 ≤ · · · ≤ fn. The Lovasz extension R : Rn → R of R̂ is defined as R(f) = ∑n−1 i=1 R̂(Ci+1) (fi+1 − fi)+R̂(V )f1.\nNote thatR(1C) = R̂(C) for all C ⊂ V , i.e. R is indeed an extension of R̂ from 2V to Rn. In the following, we always use the hat-symbol (̂) to denote set functions and omit it for the corresponding Lovasz extension.\n3Note that M̂(C) = k is equivalent to k ≤ M̂(C) ≤ k.\nA particular important class of set functions are submodular set functions since their Lovasz extension is convex (Bach, 2011).\nDefinition 2 A set function R̂ : 2V → R is submodular if for all A,B ⊂ V , R̂(A ∪ B) + R̂(A ∩ B) ≤ R̂(A) + R̂(B). It is supermodular, if the converse inequality holds true, and modular if we have equality.\nThe connection between submodular set functions and convex functions is as follows (see Bach, 2011).\nProposition 1 Let R : RV → R be the Lovasz extension of R̂ : 2V → R. Then, R̂ is submodular if and only if R is convex. Furthermore, if R̂ is submodular, then minA⊂V R̂(A) = minf∈[0,1]n R(f).\nThus submodular minimization problems reduce to convex minimization problems. A similar equivalence of continuous and combinatorial optimization problems is the main topic of this paper. In the following we list some useful properties of the Lovasz extension (see Fujishige, 2005; Bach, 2011; Hein & Setzer, 2011).\nProposition 2 Let R : RV → R be the Lovasz extension of R̂ : 2V → R. Then,\n• R is positively one-homogeneous4,\n• R(f) ≥ 0, ∀ f ∈ RV and R(1) = 0 if and only if R̂(A) ≥ 0, ∀A ⊂ V and R̂(V ) = 0,\n• Let S : RV → R be the Lovasz extension of Ŝ : 2V → R. Then, λ1R + λ2 S is the Lovasz extension of λ1 R̂+ λ2 Ŝ, for all λ1, λ2 ∈ R.\nUnconstrained fractional set programs. Using the property of the Lovasz extension that R(1C) = R̂(C) for all C ⊂ V , one can directly observe that the following continuous fractional program is a relaxation of the unconstrained version of problem (3)\ninf f∈Rn+\nR(f) S(f) .\nThe following theorem shows that the relaxation is in fact tight, in the sense that the optimal values agree and the solution of the set-valued problem can be computed from the solution of the continuous problem.\nNote that given a vector f ∈ Rn for the continuous problem, one can construct a set C ′ by computing\nC ′ = arg min Ci,i=1,...,n\nR̂(Ci) Ŝ(Ci) ,\n4R : RV → R is positively one-homogeneous if R(αf) = αR(f), ∀α ∈ R with α ≥ 0.\nwhere the sets Ci are defined in (4). We refer to this process as optimal thresholding.\nTheorem 1 Let R̂, Ŝ : 2V → R be non-negative set functions and R,S : Rn → R their Lovasz extensions, respectively. Then, it holds that\ninf C⊂V\nR̂(C) Ŝ(C) = inf f∈Rn+ R(f) S(f) .\nMoreover, it holds for all f ∈ Rn+, R(f) S(f) ≥ mini=1,...,n R̂(Ci)\nŜ(Ci) . Thus a minimizer of the set ratio\ncan be found by optimal thresholding. Let furthermore R̂(V ) = Ŝ(V ) = 0, then all the above statements hold if one replaces Rn+ with Rn.\nIn practice it may sometimes by difficult to derive and/or work with explicit forms of the Lovasz exten-\nsions of R̂ and Ŝ. However, the following more general version of Theorem 1 shows that, given a decomposition of R̂ and Ŝ into a difference of submodular set functions, one needs the Lovasz extension only for the first term of R̂ and the second term of Ŝ. The remaining terms can be replaced by any convex one-homogeneous functions that also extend the corresponding set functions. Note that by Proposition 3 such a decomposition always exists.\nTheorem 1 (b) Let R̂, Ŝ : 2V → R be non-negative set functions and R̂ := R̂1 − R̂2 and Ŝ := Ŝ1 − Ŝ2 be decompositions into differences of submodular set functions. Let the Lovasz extensions of R̂1, Ŝ2 be given by R1, S2 and let R ′ 2, S ′ 1 be positively one-homogeneous convex functions with S′1(1A) = Ŝ1(A) and R ′ 2(1A) = R̂2(A) such that S ′ 1−S2 is non-negative. Define R := R1 −R′2 and S := S′1 − S2. Then,\ninf C⊂V\nR̂(C) Ŝ(C) = inf f∈RV+ R(f) S(f) .\nMoreover, it holds for all f ∈ Rn+, R(f) S(f) ≥ mini=1,...,n R̂(Ci)\nŜ(Ci) . Thus a minimizer of the set ratio\ncan be found by optimal thresholding. Let furthermore R̂(V ) = Ŝ(V ) = 0, then all the above statements hold if one replaces Rn+ with Rn.\nBefore we prove the above Theorem, we collect some useful results. Lemma 1 shows that the Lovasz extension of a submodular set function R̂ is an upper bound on any one-homogeneous convex function R′ which extends the set function R̂ to the continuous space.\nLemma 1 Let R̂ : 2V → R be a submodular set function with R̂(∅) = 0. Let R′ be a positively onehomogeneous convex function with R′(1A) = R̂(A) for all A ⊂ V . Then, it holds ∀f ∈ RV+ that\nR′(f) ≤ n−1∑ i=1 R̂(Ci+1) (fi+1 − fi) + f1R̂(V ).\nLet furthermore R̂(V ) = 0, then the above inequality holds for all f ∈ RV .\nProof: Let f be ordered in increasing order f1 ≤ f2 ≤ · · · ≤ fn. Note that every convex, positively onehomogeneous function R′ : RV → R can be written as R(f) = supu∈U 〈u, f〉, where U is a convex set (see Hiriart-Urruty & Lemaréchal, 2001). Then, since for any u ∈ U , 〈u, f〉 ≤ R′(f), it holds that\nR̂(Ci) = R ′(1Ci) ≥ 〈u,1Ci〉 , i = 1, . . . , n,\nfor any u ∈ U and hence for all f ∈ RV+,\nn−1∑ i=1 R̂(Ci+1) (fi+1 − fi) + f1R̂(V )\n≥ n−1∑ i=1 〈 u,1Ci+1 〉 (fi+1 − fi) + f1 〈u,1〉\n= n∑ i=1 fiui. (5)\nAs this holds for all u ∈ U we obtain for all f ∈ RV+, n−1∑ i=1 R̂(Ci+1) (fi+1 − fi) + R̂(V )f1 ≥ sup u∈U 〈f, u〉 = R′(f) .\nFor the second statement we use the fact that with the condition R̂(V ) = 0 the lower bound in (5) holds for all f ∈ RV .\nThe main part of the proof of Theorem 1 (b) is the following Lemma which implies that optimal thresholding of a vector f always leads to non-increasing values of R(f)/S(f).\nLemma 2 Let R̂, Ŝ : 2V → R and R,S : Rn → R satisfy the assumptions of Theorem 1 (b). Then for all f ∈ RV+,\nR(f) S(f) ≥ min i=1,...,n R̂(Ci)\nŜ(Ci) .\nLet furthermore R̂(V ) = Ŝ(V ) = 0, then the result holds for all f ∈ RV .\nProof: Let R1, S2 and R ′ 2, S ′ 1 satisfy the conditions from Theorem 1 (b). Let furthermore R2 and S1 be the Lovasz extensions of R̂2 and Ŝ1. With Lemma 1 and Def. 1, we get ∀f ∈ Rn+,\nR(f) = R1(f)−R′2(f) ≥ R1(f)−R2(f)\n= n−1∑ i=1 R̂(Ci+1) (fi+1 − fi) + f1R̂(V )\n= n−1∑ i=1 R̂(Ci+1) Ŝ(Ci+1) Ŝ(Ci+1) (fi+1− fi) + R̂(V ) Ŝ(V ) Ŝ(V )f1\n≥ min j=1,...,n\nR̂(Cj)\nŜ(Cj) ( n−1∑ i=1 Ŝ(Ci+1) (fi+1−fi)+f1Ŝ(V ) )\nwhere we used the non-negativity of R̂ and Ŝ as well as the fact that f ∈ Rn+. Again using Def. 1, the above is equal to\nmin j=1,...,n\nR̂(Cj) Ŝ(Ci) (S1(f)− S2(f))\n≥ min j=1,...,n\nR̂(Cj) Ŝ(Ci) (S′1(f)− S2(f)) .\nBy assumption, S′1−S2 is non-negative and thus division gives the result. The second statement is shown analogously.\nNow we are ready to prove Theorem 1 (b).\nProof of Theorem 1 (b): Lemma 2 implies that\ninf f∈RV+\nR(f) S(f) ≥ inf f∈RV+\nmin Ci def. by f i=1,...,n\nR̂(Ci) Ŝ(Ci) ≥ inf A⊂V R̂(A) Ŝ(A) .\nOn the other hand we have\ninf A⊂V\nR̂(A) Ŝ(A) = inf A⊂V R(1A) S(1A) ≥ inf f∈RV+ R(f) S(f) ,\nwhich implies equality. The statement regarding optimal thresholding has been shown in Lemma 2. The proof for the case where R̂(V ) = Ŝ(V ) = 0 works analogously.\nNote that no assumptions except non-negativity are made on R̂ and Ŝ - every non-negative fractional set program has a tight relaxation into a continuous fractional program. The efficient minimization of the continuous objective will be the topic of Section 4.\nConstrained fractional set programs. To solve the constrained fractional set program (3) we make use of the concept of exact penalization (Di Pillo, 1994), where the main idea is to transform a given\nconstrained optimization problem into an equivalent unconstrained one by adding a penalty term. We use the same idea for our constrained fractional set programs and define the penalty set function for a constraint M̂i(C) ≤ ki as\nT̂i(C) =\n{ max { 0, M̂i(C)− ki } , C 6= ∅,\n0, C = ∅. (6)\nThe function T̂i(C) is zero if C is feasible for the ith constraint and otherwise increasing with increasing infeasibility. The special treatment of the empty set in the definition of T̂i is a technicality required for the Lovasz extension. Defining T̂ (C) := ∑K i=1 T̂i(C), we can now formulate a modified problem\nmin C⊂V\nR̂(C) + γ ∑K i T̂i(C)\nŜ(C) =: Q̂γ(C). (7)\nWe will show that using a feasible set of (3) one can compute a γ such that (7) is equivalent to the original constrained problem. Once we have established the equivalence, we can then apply Theorem 1, noting that T̂ is a non-negative set function. This leads to the main result of this paper showing a tight relaxation of all problems of form (3) where R̂, Ŝ are non-negative set functions. In the following, the constant θ quantifies a “minimum value” of T̂i on the infeasible sets:\nθ = min i=1,...,K\n[ min\nM̂i(C)>ki\nM̂i(C)− ki ] .\nFor example, if M̂(C) = |C|, then θ is equal to 1. If M̂(C) = volg(C) and all vertex weights gi are rational numbers which are multiples of a fraction 1ρ , ρ ∈ N, then θ ≥ 1ρ . Note that in practice, the constant θ and the parameter γ introduced in the following are never explicitly computed (see experimental section).\nTheorem 2 Let R̂, Ŝ : 2V → R be non-negative set functions and R, S their Lovasz extensions. Let C0 ⊂ V be feasible and Ŝ(C0) > 0. Denote by T the Lovasz extension of T̂ . Then, for γ > R̂(C0) θŜ(C0) maxC⊂V Ŝ(C),\nmin M̂i(C)≤ki, i=1,...,K\nR̂(C) Ŝ(C) = min f∈Rn+ R(f) + γ T (f) S(f) := Qγ(f)\nMoreover, for any f ∈ Rn+ with Qγ(f) < Q̂γ(C0) for the given γ, we have Qγ(f) ≥ mini=1,...,n Q̂γ(Ci), and the minimizing set on the right hand side is feasible.\nProof: We will first show the equivalence between the constrained fractional set program (3) and the unconstrained problem (7) for the given choice of γ. Then\nthe equivalence to the continuous problem will follow by Theorem 1.\nDefine T̂ (C) := ∑K i=1 T̂i(C). Note that for any feasible subset C, that is M̂i(C) ≤ ki, i = 1, . . . ,K, the objective Qγ of problem (7) is equal to the objective Q of problem (3). Thus, if we show that all minimizers of the second problem satisfy the constraints then the equivalence follows. Suppose that C∗ 6= ∅ is a minimizer of the second problem and that C∗ is infeasible. Then by definition we have T̂ (C∗) ≥ θ. This yields\nQ̂γ(C ∗) =\nR̂(C∗) + γT̂ (C∗)\nŜ(C∗) (8)\n≥ γT̂ (C ∗)\nŜ(C∗) ≥ γT̂ (C\n∗)\nmaxC⊂V Ŝ(C) ≥ γθ maxC⊂V Ŝ(C) ,\nwhere we used the non-negativity of R̂ and Ŝ. Hence\nQ̂γ(C ∗) ≥ γθ maxC⊂V Ŝ(C) > R̂(C0) Ŝ(C0) = Q̂γ(C0),\nwhich contradicts the fact that C∗ is optimal.\nNoting that T̂ is a non-negative function with T̂ (∅) = 0 and γ > 0, we have a ratio of non-negative set functions which attain the value zero on the empty set. Thus application of Theorem 1 yields the equivalence to the continuous problem.\nThe second statement can be seen as follows. Suppose Qγ(f) < Q̂γ(C0). By Lemma 2 we obtain\nQγ(f) ≥ min i=1,...,n Q̂γ(Ci).\nNow suppose that the minimizer C∗ of the right hand side is not feasible, then again by the derivation in (8) and the choice of γ,\nQ̂γ(C ∗) ≥ γθ\nmaxC⊂V Ŝ(C) > Q̂γ(C0),\nwhich leads to a contradiction. Thus C∗ is feasible.\nNote that Theorem 2 implies that the set found by optimal thresholding of the solution of the continuous program is guaranteed to satisfy all constraints. We are not aware of any other method which can give the same guarantee for the problems (1) and (2)."
    }, {
      "heading" : "4. Minimization of the tight continuous relaxation",
      "text" : "The continuous optimization problems in Theorems 1 and 2 have the form\nmin f∈Rn+\nR(f) S(f) := Q(f), (9)\nwhere R and S are non-negative. The fact that they are the Lovasz extensions of set functions R̂, Ŝ also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).\nProposition 3 Every set function Ŝ with Ŝ(∅) = 0 can be written as Ŝ = Ŝ1 − Ŝ2, where S1 and S2 are submodular and Ŝ1(∅) = Ŝ2(∅) = 0. The Lovasz extension S can be written as difference of convex functions.\nThe above result implies that (9) can be written as ratio of differences of convex functions (d.c.), i.e. R = R1 − R2 with R1, R2 convex, and similarly for S. As the proof of Proposition 3 is constructive, the explicit form of this decomposition can be calculated. We can now use a modification of the RatioDCA which has recently been proposed as an algorithm for minimizing a non-negative ratio of one-homogeneous d.c. functions (Hein & Setzer, 2011). This modification is necessary as the problems in Theorem 1 and 2 require optimization over the positive orthant. We report the modified version in order to make the paper self-contained.\nRatioDCA Minimization of a non-negative ratio of one-homogeneous d.c functions over Rn+ 1: Initialization: f0 ∈ Rn+, λ0 = Q(f0) 2: repeat 3: f l+1 = arg min\nu∈Rn+, ‖u‖2≤1\n{ R1(u)− 〈 u, r2(f l) 〉\n+λl ( S2(u)− 〈 u, s1(f l) 〉 )}\nwhere r2(f l) ∈ ∂R2(f l), s1(f l) ∈ ∂S1(f l)\n4: λl+1 = Q(f l+1) 5: until |λl+1−λl|\nλl <\nWe will refer to the convex optimization problem solved at each step (line 3) as the inner problem.\nProposition 4 The sequence f l produced by RatioDCA satisfies Q(f l+1) < Q(f l) for all l ≥ 0 or the sequence terminates.\nProof: Let Φf l(u) := R1(u)− 〈 u, r2(f l) 〉 +λl ( S2(u)−〈\nu, s1(f l) 〉 )\ndenote the objective of the inner problem. The optimal value of the inner problem is non-positive since\nΦf l(f l) = R1(f l)− 〈 f l, r2(f l) 〉\n+ λl ( S2(f l)− 〈 f l, s1(f l) 〉 )\n= R1(f l)−R2(f l) + λl ( S2(f l)− S1(f l) ) = 0,\nwhere we used the fact that 〈 f l, r2(f l) 〉 = R2(f l) and〈\nf l, s1(f l) 〉 = S1(f l). Since Φf l is one-homogeneous,\nthe minimum of Φf l is always attained at the boundary of the constraint set. If the optimal value is zero, then f l is a possible minimizer and the sequence terminates. Otherwise the optimal value is negative and at the optimal point we get\n0 > Φf l(f l+1)\n= R1(f l+1)− 〈 f l+1, r2(f l) 〉\n+ λl ( S2(f l+1)− 〈 f l+1, s1(f l) 〉 )\n≥ R1(f l+1)−R2(f l+1) + λl ( S2(f l+1)− S1(f l+1) ) ,\nwhere we used that for a positively one-homogeneous convex function one has for all f, g ∈ Rn+,\nS(f) ≥ S(g) + 〈f − g, s(g)〉 = 〈f, s(g)〉 .\nThus we obtain\nQ(f l+1) = R1(f l+1)−R2(f l+1) S1(f l+1)− S2(f l+1) < λl = Q(f l).\nThe norm constraint of the inner problem is necessary as otherwise the problem would be unbounded from below. However, the choice of the norm plays no role in the proof and any norm can be chosen. Moreover, in the special case where the one-homogeneous function R is convex and S is concave, the RatioDCA reduces to Dinkelbach’s method from fractional programming (Dinkelbach, 1967) and therefore computes the global optimum. In the general case, convergence to the global optimum cannot be guaranteed. However, we can provide a quality guarantee: RatioDCA either improves a given feasible set or stops after one iteration.\nTheorem 3 Let A be a feasible set and γ > R̂(A) maxC⊂V Ŝ(C)/(θ Ŝ(A)). Let f\n∗ denote the result of RatioDCA after initializing with the vector 1A, and let Cf∗ denote the set found by optimal thresholding of f∗. Either RatioDCA terminates after one iteration, or Cf∗ is feasible and R̂(Cf∗ )\nŜ(Cf∗ ) < R̂(A) Ŝ(A) .\nProof: Proposition 4 implies that the RatioDCA either directly terminates or produces a strictly monotonically decreasing sequence. In the latter case, using the strict monotonicity and the fact that thresholding does not increase the objective (Lemma 2), we obtain\nQ̂γ(A) = Qγ(1A) Prop. 4 > Qγ(f ∗)\nLemma 2 ≥ Qγ(1Cf∗ ) = Q̂γ(Cf∗) .\nAssume now that Cf∗ is infeasible. Then, one can derive analogously to the proof of Theorem 2 that\nQ̂γ(Cf∗) ≥ γθmaxC⊂V Ŝ(C) > Q̂(A) = Q̂γ(A), which is a contradiction to Q̂γ(A) > Q̂γ(Cf∗). Hence, Cf∗ has to be feasible and it holds that Q̂(A) = Q̂γ(A) > Q̂γ(Cf∗) = Q̂(Cf∗).\nThe above theorem implies that all constraints of the original constrained fractional set program are fulfilled by the set Cf∗ returned by RatioDCA."
    }, {
      "heading" : "5. Tight relaxations of constrained maximum density and constrained balanced graph cut problems",
      "text" : "The framework introduced in this paper allows us to derive tight relaxations of all problems discussed in Section 2. In the following, we will derive a tight relaxation of the local community detection problem\nmax C⊂V\nassoc(C)\nvolg(C) (10)\nsubject to : volh(C) ≤ k, and J ⊂ C.\nFor the constrained balanced graph cut problem, the tight relaxation can be found in a very similar way and is thus omitted here.\nFirst, we integrate the volume constraint via a penalty term, see (7), which yields the equivalent problem\nmin C⊂V\ns.t.J⊂C\nvolg(C) + γT̂k(C)\nassoc(C) , (11)\nwhere T̂k is given as T̂k(C) = max {0, volh(C)− k} and γ >\nvolg(C0) vol(V ) θ assoc(C0) for a feasible set C0 ⊂ V . Note that the penalty term is equal to T̂k(C) = volh(C) − min {k, volh(C)} , which is a difference of submodular functions.\nWe could reformulate the seed constraint J ⊂ C as inequality constraint |J∩C|−|J | ≥ 0 and add a similar penalty function to the numerator of (11). However, using the structure of the problem, a more direct way to incorporate the seed constraint is possible. It holds that (11) has the equivalent form\nmin A⊂V \\J\nvolg(A) + volg(J) + γT̂k′(A)\nassoc(A) + assoc(J) + 2cut(J,A) , (12)\nwhere k′ = k − volh(J). Solutions C∗ of (11) and A∗ of (12) are related via C∗ = A∗∪J . In order to derive the tight relaxation via Theorem 1, we need the Lovasz extension of the set functions in (12). For technical reasons, we replace the constant set functions volg(J) and assoc(J) by volg(J)P̂ (A) and assoc(J)P̂ (A), respectively, where P̂ is defined as P̂ (A) = 1 for A 6= ∅\nand P̂ (∅) = 0. This leads to the problem\nmin A⊂V \\J\nvolg(A) + volg(J)P̂ (A) + γT̂k′(A)\nassoc(A) + assoc(J)P̂ (A) + 2cut(J,A) . (13)\nThe only difference to (12) lies in the treatment of the empty set. Note that with 00 := ∞ the empty set can never be optimal for problem (13). Given an optimal solution A∗ of (13), one then either considers either A∗ ∪ J or J , depending on whichever has lower objective, which then implies equivalence to (12).\nThe resulting tight relaxation will be a minimization problem over Rm with m = |V \\J | and we assume wlog that the first m vertices of V are the ones in V \\J . Moreover, we use the notation fmax = maxi=1,...,m fi\nfor f ∈ Rm, and d(A)i = ∑ j∈A wij . The following Lovasz extensions are useful:\nSet function Lovasz extension\ncut(A,A) 1 2 ∑m i,j wij |fi − fj |\nvolg(A) 〈f, (gi)mi=1〉 assoc(A) 〈 f, (d\n(V \\J) i ) m i=1\n〉 − 1\n2 ∑m i,j wij |fi − fj |\nP̂ (A) fmax\nT̂k′(A) 〈f, (hi)mi=1〉 − T (2) k′ (f)\nFor the sake of brevity, we do not specify the convex function T (2) k′ . Recall from Section 4 that we need only an element of the subdifferential for T (2) k′ which by Prop. 2.2 in Bach (2011) is given by\n( t (2) k′ (f) ) ji =  0 volh(Ai+1) > k ′ k′ − volh(Ai+1) volh(Ai) ≥ k′, volh(Ai+1) ≤ k′\nhji volh(Ai) < k ′\n,\nwhere ji denotes the index of the i-th smallest component of the vector f . The above Lovasz extensions lead to the following tight relaxation of (13):\nmin f∈Rm+ R1(f)−R2(f) S1(f)− S2(f) , (14)\nwhere R1(f) = 〈(gi)mi=1 + γ(hi)mi=1, f〉 + volg(J)fmax, S1(f) = 〈(di)mi=1 + (d (J) i ) m i=1, f〉 + assoc(J) fmax, R2(f) = γT (2) k′ (f) and S2(f) = 1 2 ∑m i,j wij |fi − fj |.\nLower bound constraints. Constraints of the form volh(C) ≥ k are rewritten as − volh(C) ≤ −k, which leads to the penalty term, see (6),\nT̂k(C) =\n{ max {0, k − volh(C)} , C 6= ∅,\n0, C = ∅.\nThe decomposition T̂k(C) = k P̂ (C)−min {k, volh(C)} then again yields a difference of submodular functions (noting k ≥ 0). The derivation then proceeds analogously to the case of upper bound constraints.\nSolution via RatioDCA. Observe that both numerator and denominator of the tight relaxation (14) are one-homogeneous d.c. functions and thus we can apply the RatioDCA of Section 4. The crucial step in the algorithm is solving the inner problem (line 3). For both (14) and the tight relaxation of the constrained balanced graph cut problem, it has the form\nmin f∈Rm+ ‖f‖2≤1\n{c1fmax + 〈f, c2〉+ λl 1\n2 m∑ i,j wij |fi − fj |}, (15)\nfor c1 ∈ R and c2 ∈ Rm. We solve this problem via the following equivalent dual problem.\nLemma 3 The inner problem (15) is equivalent to\n− min ‖α‖∞≤1 αij=−αji min v∈Sm\n1\n2 ∥∥∥∥PRm+ (−c1v − c2 − λl2 Aα )∥∥∥∥2\n2\nwhere (Aα)i := ∑ j wij(αij − αji), PRm+ denotes the projection on the positive orthant and Sm is the simplex Sm = {v ∈ Rm | vi ≥ 0, ∑m i=1 vi = 1}.\nProof: First we replace the inner problem (15) by the modified problem\nmin f∈Rm+\nλl\n2 m∑ i,j=1 wij |fi − fj |+ c1 max i fi + 〈f, c2〉+ 1 2 ‖f‖22 .\n(16)\nGiven a solution f∗ of (16), a solution of (15) can be obtained via f∗/ ‖f∗‖2, which can be shown using the 1-homogeneity of the objective (15). We then derive the dual problem as follows:\nmin f∈Rm+\nλl\n2 m∑ i,j=1 wij |fi − fj |+ c1 max fi + 〈f, c2〉+ 1 2 ‖f‖22\n= min f∈Rm+ { max ‖α‖∞≤1 αij=−αji λl 2 m∑ i,j=1 wij (fi − fj)αij\n+ max v∈Sm\nc1 〈f, v〉+ 〈f, c2〉+ 1\n2 ‖f‖22 } = max ‖α‖∞≤1 αij=−αji v∈Sm min f∈Rm+ 1 2 ‖f‖22 + 〈 f, c1v + c2 + λl 2 Aα 〉 ,\nwhere (Aα)i := ∑ j wij(αij − αji). The optimization over f has the solution\nf = PRm+\n( −c1v − c2 − λl\n2 Aα\n) .\nPlugging f into the objective and using that〈 PRm+ (x), x 〉 = ∥∥∥PRm+ (x)∥∥∥22, we obtain the result.\nThis dual problem can be solved efficiently using FISTA (Beck & Teboulle, 2009), a proximal gradient method with guaranteed convergence rate O( 1k2 ) where k is the number of steps. The resulting explicit steps in FISTA with B∞(1) = {x ∈ R | |x| ≤ 1} to solve the inner problem are given below.\nFISTA for the inner problem\nInput: Lipschitz constant L of ∇Ψ, Initialization: t1 = 1, α\n1 ∈ R|E|, repeat\nv = arg min u∈Sm ∥∥∥PRm+ (−c1u− c2 − λl2 Aα)∥∥∥22 z = PRm+ ( −c1v − c2 − λ l 2 Aα )\nβk+1rs = PB∞(1) ( αkrs + 1 Lλ lwrs ( zr − zs )) tk+1 = 1+ √ 1+4t2k 2 , αk+1rs = β k+1 rs + tk−1 tk+1 ( βk+1rs − βkrs ) .\nuntil duality gap <\nThe most expensive part of each iteration of the algorithm is a sparse matrix multiplication, which scales linearly in the number of edges. To solve the first subproblem in FISTA, we make use of the following fact:\nLemma 4 Let x ∈ Rn and y := PRn+(x), then\narg min v∈Sn ‖y − v‖22 ∈ arg min v∈Sn ∥∥∥PRn+ (x− v)∥∥∥22. Proof: The proof is a straightforward but technical transformation of the KKT optimality conditions of the left problem into the ones of the right problem.\nLemma 4 implies that the minimization problem can be solved via a standard projection onto the simplex, which can be computed in linear time (Kiwiel, 2007).\nUnconstrained version. In the unconstrained case of the maximum density problem, the tight relaxation (14) reduces to a convex-concave ratio. As remarked in Section 4 it can then be solved globally optimally with our method, which in this case is equivalent to Dinkelbach’s method (Dinkelbach, 1967). In every iteration, we have to solve\nmin f∈Rn+ ‖f‖∞≤1\n{〈g, f〉 − λ 〈d, f〉+ λ 2 n∑ i,j=1 wij |fi − fj |}. (17)\nNote that here we used the fact that one can replace the L2 norm constraint in the inner problem by a L∞ norm constraint, see the remark after Prop. 4. The following lemma shows that (17) can be rewritten as a\ns-t-min-cut-problem, which shows that the procedure is similar to the method of Goldberg (1984).\nLemma 5 Problem (17) is equivalent to the problem\nmin fV ∈H, fs=1, ft=0\n1\n2 ∑ i,j∈V ′ w′ij |fi − fj |,\nwith V ′ = V ∪ {s, t}, H := { u ∈ Rn+, ‖u‖∞ ≤ 1 } and some non-negative weights w′ij, i, j ∈ V ′.\nProof: Note that adding constant terms to the objective does not change the minimizer. We rewrite\nn∑ i=1 gi(fi−0)+λ n∑ i=1 di−λ n∑ i=1 difi+ λ 2 n∑ i,j=1 wij |fi − fj |\n= n∑ i=1 gi|fi − 0|+ λ n∑ i=1 di|1− fi|+ λ 2 n∑ i,j=1 wij |fi − fj |, where we have used that f ∈ H, where H :={ u ∈ Rn+, ‖u‖∞ ≤ 1 } . We define the graph as V ′ = V ∪ {s, t} and the weight matrix W ′ with\nw′ij =  λwij if i, j ∈ V ,2λdj if i = s and j ∈ V , 2gi if i ∈ V and j = t,\nand can rewrite the problem as\nmin fV ∈H, fs=1, ft=0\n1\n2 ∑ i,j∈V ′ w′ij |fi − fj |,\nwhich is a s-t-mincut.\nThe above problem can be efficiently solved, e.g., using the pseudo-flow algorithm of Hochbaum (1998)."
    }, {
      "heading" : "6. Experiments",
      "text" : "We empirically evaluate the performance of our approach on local clustering and community detection problems. Our goal is to address the following questions: (i) In terms of the original objective of the fractional set program, how does the locally optimal solution of our tight relaxation compare to the globally optimal solution of a loose relaxation? (ii) How good is our quality guarantee (Theorem 3), i.e. how often does our method improve a given sub-optimal solution obtained by another method?\nIn all experiments we start the RatioDCA with 10 different random initializations and report the result with smallest objective value. Regarding the parameter γ from Theorem 2, it turns out that best results are obtained by first solving the unconstrained case (γ = 0)\nand then increasing γ sequentially, until all constraints are fulfilled. In principle, this strategy could also be used to deal with soft or noisy constraints, however we focus here on the case of hard constraints.\nLocal clustering. We first consider the local normalized cut problem,\nmin C⊂V\ns∈C, vold(C)≤k\ncut(C,C) vol (V )\nvold(C) vold(C) , (18)\nwhere s ∈ V is a given seed vertex. We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).\nIn Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally.\nThe resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments. The local clustering technique of Andersen & Lang (2006) explores the graph locally by performing a lazy random walk with the transition matrix M = 12 ( I +WD−1 ) , where D is the degree matrix of the graph and the initial distribution is concentrated on the seed set. Under\nsome conditions on the seed set, it is shown that after a specified number of steps optimal thresholding of the random walk vector yields a set with “good” normalized Cheeger cut. However, they cannot guarantee that the resulting set contains the seed. For a fair comparison, we compute the full sequence of random walk vectors until the stationary distribution is reached, and in each step perform constrained optimal thresholding according to the normalized cut objective.\nFor each dataset we generate 10 random seeds. In order to ensure that meaningful intervals for the volume constraint are explored, we first solve the local clustering problem only with the seed constraint. Treating this as the “unconstrained” solution C0, we then repeat the experiment with upper bounds of the form vol(C) ≤ α vol(C0), where α ∈ {0.2, 0.4, 0.6, 0.8}.\nTable 1 shows mean and standard deviation of the normalized cut values averaged over the 10 different random trials (seeds) and average runtime over the different runs and volume constraints. To demonstrate the quality guarantee (Theorem 3) we also initialize CFSP with the solution of LS and LRW. Our method CFSP consistently outperforms the competing methods by large margins and always finds solutions that satisfy all constraints. In some cases CFSP initialized with LS or LRW outperforms CFSP with 10 random initializations. While LRW is very fast, the obtained normalized cuts are far from being competitive. Note that CFSP still performs better if one uses for the optimal thresholding the normalized Cheeger cut for which LRW has been designed. This is shown in Table 2 where we compare the normalized Cheeger cut of our solutions (note that we optimized the normalized cut) to the solution obtained by the Lazy Random Walk method where we threshold in each step according to the normalized Cheeger cut objective.\nCommunity detection. We evaluate our approach for local community detection according to (10). The task is to extract communities around given seed sets in a co-author network constructed from the DBLP\npublication database. Each node in the network represents a researcher and an edge between two nodes indicates a common publication. The weights of the graph are defined as wij = ∑ l∈Pi∩Pj 1 |Al| , where Pi, Pj denotes the set of publications of authors i and j and Al denote the sets of authors for publication l, i.e. the weights represent the total contribution to shared papers. This normalization avoids the problem of giving high weight to a researcher who has publications that have a large number of authors, which usually does not reflect close collaboration with all co-authors.\nTo avoid finding a trivial densely connected group of researchers with few connections to the rest of the authors, we further restrict the graph by considering only authors with at least two publications and maximum distance two from the seed set. As volume function in (10), we use the volume of the original graph in order to further enforce densely connected components.\nWe perform local community detection with the size constraint |C| ≤ 20 and three different seed sets J1 = {P. Bartlett , P. Long, G. Lugosi}, J2 = {E. Candes , J. Tropp} and J3 = {O. Bousquet}. J1 consists of well-known researchers in learning theory, and all members of the detected community work in this area. To validate this, we counted the number of publications in the two main theory conferences COLT and ALT. On average each author has 18.2 publications in these two conferences (see Table 3 for more details). The seeds J2 yield a community of key scientists in the field of sparsity such as T. Tao, R. Baraniuk, J. Romberg, M. Wakin, R. Vershynin etc. The third community contains researchers who either are/were members of the group of B. Schölkopf or have closely collaborated with his group."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work has been supported by DFG Excellence Cluster MMCI and ERC Starting Grant NOLEPRO."
    } ],
    "references" : [ {
      "title" : "Communities from seed sets",
      "author" : [ "R. Andersen", "K. Lang" ],
      "venue" : "In WWW, pp",
      "citeRegEx" : "Andersen and Lang,? \\Q2006\\E",
      "shortCiteRegEx" : "Andersen and Lang",
      "year" : 2006
    }, {
      "title" : "Local graph partitioning using pagerank vectors",
      "author" : [ "R. Andersen", "F. Chung", "K. Lang" ],
      "venue" : "In FOCS, pp",
      "citeRegEx" : "Andersen et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Andersen et al\\.",
      "year" : 2006
    }, {
      "title" : "Learning with submodular functions: A convex optimization perspective",
      "author" : [ "F. Bach" ],
      "venue" : "CoRR, abs/1111.6453,",
      "citeRegEx" : "Bach,? \\Q2011\\E",
      "shortCiteRegEx" : "Bach",
      "year" : 2011
    }, {
      "title" : "Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "IEEE Trans. Image Processing,",
      "citeRegEx" : "Beck and Teboulle,? \\Q2009\\E",
      "shortCiteRegEx" : "Beck and Teboulle",
      "year" : 2009
    }, {
      "title" : "Convergence and energy landscape for Cheeger cut clustering",
      "author" : [ "X. Bresson", "T. Laurent", "D. Uminsky", "J.H. von Brecht" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Bresson et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bresson et al\\.",
      "year" : 2012
    }, {
      "title" : "A local graph partitioning algorithm using heat kernel pagerank",
      "author" : [ "F. Chung" ],
      "venue" : "In WAW, pp",
      "citeRegEx" : "Chung,? \\Q2009\\E",
      "shortCiteRegEx" : "Chung",
      "year" : 2009
    }, {
      "title" : "Exact penalty methods",
      "author" : [ "G. Di Pillo" ],
      "venue" : "Algorithms for Continuous Optimization,",
      "citeRegEx" : "Pillo,? \\Q1994\\E",
      "shortCiteRegEx" : "Pillo",
      "year" : 1994
    }, {
      "title" : "On nonlinear fractional programming",
      "author" : [ "W. Dinkelbach" ],
      "venue" : "Management Science,",
      "citeRegEx" : "Dinkelbach,? \\Q1967\\E",
      "shortCiteRegEx" : "Dinkelbach",
      "year" : 1967
    }, {
      "title" : "Community detection in graphs",
      "author" : [ "S. Fortunato" ],
      "venue" : "Physics Reports,",
      "citeRegEx" : "Fortunato,? \\Q2010\\E",
      "shortCiteRegEx" : "Fortunato",
      "year" : 2010
    }, {
      "title" : "Multi-skill collaborative teams based on densest subgraphs",
      "author" : [ "A. Gajewar", "A. Das Sarma" ],
      "venue" : "In SDM, pp",
      "citeRegEx" : "Gajewar and Sarma,? \\Q2012\\E",
      "shortCiteRegEx" : "Gajewar and Sarma",
      "year" : 2012
    }, {
      "title" : "Finding a maximum density subgraph",
      "author" : [ "A.V. Goldberg" ],
      "venue" : "Technical Report UCB/CSD-84-171,",
      "citeRegEx" : "Goldberg,? \\Q1984\\E",
      "shortCiteRegEx" : "Goldberg",
      "year" : 1984
    }, {
      "title" : "Fast spectral methods for ratio cut partitioning and clustering",
      "author" : [ "L. Hagen", "A.B. Kahng" ],
      "venue" : "In ICCAD, pp",
      "citeRegEx" : "Hagen and Kahng,? \\Q1991\\E",
      "shortCiteRegEx" : "Hagen and Kahng",
      "year" : 1991
    }, {
      "title" : "Semi-supervised eigenvectors for locally-biased learning",
      "author" : [ "T. Hansen", "M. Mahoney" ],
      "venue" : "In NIPS, pp. 2537–2545,",
      "citeRegEx" : "Hansen and Mahoney,? \\Q2012\\E",
      "shortCiteRegEx" : "Hansen and Mahoney",
      "year" : 2012
    }, {
      "title" : "An inverse power method for nonlinear eigenproblems with applications in 1spectral clustering and sparse PCA",
      "author" : [ "M. Hein", "T. Bühler" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Hein and Bühler,? \\Q2010\\E",
      "shortCiteRegEx" : "Hein and Bühler",
      "year" : 2010
    }, {
      "title" : "Beyond spectral clustering tight relaxations of balanced graph cuts",
      "author" : [ "M. Hein", "S. Setzer" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Hein and Setzer,? \\Q2011\\E",
      "shortCiteRegEx" : "Hein and Setzer",
      "year" : 2011
    }, {
      "title" : "The pseudoflow algorithm and the pseudoflow-based simplex for the maximum flow problem",
      "author" : [ "D.S. Hochbaum" ],
      "venue" : "In IPCO, pp",
      "citeRegEx" : "Hochbaum,? \\Q1998\\E",
      "shortCiteRegEx" : "Hochbaum",
      "year" : 1998
    }, {
      "title" : "Ruling out PTAS for graph min-bisection, dense k-subgraph, and bipartite clique",
      "author" : [ "S. Khot" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "Khot,? \\Q2006\\E",
      "shortCiteRegEx" : "Khot",
      "year" : 2006
    }, {
      "title" : "On finding dense subgraphs",
      "author" : [ "S. Khuller", "B. Saha" ],
      "venue" : "In ICALP, pp",
      "citeRegEx" : "Khuller and Saha,? \\Q2009\\E",
      "shortCiteRegEx" : "Khuller and Saha",
      "year" : 2009
    }, {
      "title" : "On Linear-Time algorithms for the continuous quadratic knapsack problem",
      "author" : [ "K. Kiwiel" ],
      "venue" : "J. Opt. Theory Appl.,",
      "citeRegEx" : "Kiwiel,? \\Q2007\\E",
      "shortCiteRegEx" : "Kiwiel",
      "year" : 2007
    }, {
      "title" : "A local spectral method for graphs: With applications to improving graph partitions and exploring data graphs locally",
      "author" : [ "M.W. Mahoney", "L. Orecchia", "N.K. Vishnoi" ],
      "venue" : null,
      "citeRegEx" : "Mahoney et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Mahoney et al\\.",
      "year" : 2012
    }, {
      "title" : "Biased normalized cuts",
      "author" : [ "S. Maji", "N.K. Vishnoi", "J. Malik" ],
      "venue" : "In CVPR, pp. 2057–2064,",
      "citeRegEx" : "Maji et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Maji et al\\.",
      "year" : 2011
    }, {
      "title" : "Partitioning sparse matrices with eigenvectors of graphs",
      "author" : [ "A. Pothen", "H.D. Simon", "Liou", "K.-P" ],
      "venue" : "SIAM J. Matrix Anal. Appl.,",
      "citeRegEx" : "Pothen et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Pothen et al\\.",
      "year" : 1990
    }, {
      "title" : "Constrained 1spectral clustering",
      "author" : [ "S.S. Rangapuram", "M. Hein" ],
      "venue" : "In AISTATS, pp. 1143–1151,",
      "citeRegEx" : "Rangapuram and Hein,? \\Q2012\\E",
      "shortCiteRegEx" : "Rangapuram and Hein",
      "year" : 2012
    }, {
      "title" : "Dense subgraphs with restrictions and applications to gene annotation graphs",
      "author" : [ "B. Saha", "A. Hoch", "S. Khuller", "L. Raschid", "Zhang", "X.-N" ],
      "venue" : "In RECOMB,",
      "citeRegEx" : "Saha et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Saha et al\\.",
      "year" : 2010
    }, {
      "title" : "Normalized cuts and image segmentation",
      "author" : [ "J. Shi", "J. Malik" ],
      "venue" : "IEEE Trans. Patt. Anal. Mach. Intell.,",
      "citeRegEx" : "Shi and Malik,? \\Q2000\\E",
      "shortCiteRegEx" : "Shi and Malik",
      "year" : 2000
    }, {
      "title" : "Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems",
      "author" : [ "D.A. Spielman", "Teng", "S.-H" ],
      "venue" : "In STOC,",
      "citeRegEx" : "Spielman et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Spielman et al\\.",
      "year" : 2004
    }, {
      "title" : "Total variation and Cheeger cuts",
      "author" : [ "A. Szlam", "X. Bresson" ],
      "venue" : "In ICML, pp. 1039–1046,",
      "citeRegEx" : "Szlam and Bresson,? \\Q2010\\E",
      "shortCiteRegEx" : "Szlam and Bresson",
      "year" : 2010
    }, {
      "title" : "A tutorial on spectral clustering",
      "author" : [ "U. von Luxburg" ],
      "venue" : "Statistics and Computing,",
      "citeRegEx" : "Luxburg,? \\Q2007\\E",
      "shortCiteRegEx" : "Luxburg",
      "year" : 2007
    }, {
      "title" : "Constrained K-means clustering with background knowledge",
      "author" : [ "K. Wagstaff", "C. Cardie", "S. Rogers", "S. Schroedl" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Wagstaff et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Wagstaff et al\\.",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al.",
      "startOffset" : 221,
      "endOffset" : 238
    }, {
      "referenceID" : 23,
      "context" : "Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al., 2010).",
      "startOffset" : 258,
      "endOffset" : 277
    }, {
      "referenceID" : 26,
      "context" : "In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 26,
      "context" : "In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm. Recently, Rangapuram & Hein (2012) proposed a generalization of the normalized cut problem that can handle must-link and cannot-link constraints.",
      "startOffset" : 27,
      "endOffset" : 251
    }, {
      "referenceID" : 19,
      "context" : "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation.",
      "startOffset" : 22,
      "endOffset" : 44
    }, {
      "referenceID" : 19,
      "context" : "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al.",
      "startOffset" : 22,
      "endOffset" : 207
    }, {
      "referenceID" : 19,
      "context" : "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al. (2010) considered size and distance constraints for the maximum density subgraph problem.",
      "startOffset" : 22,
      "endOffset" : 230
    }, {
      "referenceID" : 19,
      "context" : "Moreover, spectral-type relaxations (Mahoney et al., 2012) ar X iv :1 30 6.",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 4,
      "context" : "In another line of work (Hein & Bühler, 2010; Szlam & Bresson, 2010; Hein & Setzer, 2011; Bresson et al., 2012), it has been shown that tight continuous relaxations exist for all balanced graph cut problems and the normalized cut subject to must-link and cannotlink constraints (Rangapuram & Hein, 2012).",
      "startOffset" : 24,
      "endOffset" : 111
    }, {
      "referenceID" : 19,
      "context" : "In the experimental section we will show the superior performance compared to state of the art methods (Andersen & Lang, 2006; Mahoney et al., 2012).",
      "startOffset" : 103,
      "endOffset" : 148
    }, {
      "referenceID" : 21,
      "context" : "The balanced graph cut problem is a well-known problem in computer science with applications ranging from parallel computing to image segmentation (Pothen et al., 1990; Shi & Malik, 2000).",
      "startOffset" : 147,
      "endOffset" : 187
    }, {
      "referenceID" : 1,
      "context" : "The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph.",
      "startOffset" : 43,
      "endOffset" : 79
    }, {
      "referenceID" : 5,
      "context" : "The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph.",
      "startOffset" : 43,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "Their method has been successfully applied in semisupervised image segmentation (Maji et al., 2011) and for community detection around a given query set (Mahoney et al.",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 19,
      "context" : ", 2011) and for community detection around a given query set (Mahoney et al., 2012).",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 19,
      "context" : "In contrast, Mahoney et al. (2012) give up the runtime requirement and formulate the task as an explicit optimization problem, where one aims at finding the optimal normalized cut subject to a seed constraint and an upper bound on the volume of the set containing the seed set.",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 19,
      "context" : "In this paper we consider an extended version of the problem of Mahoney et al. (2012). Let J denote the set of seed vertices, Ŝ a symmetric balancing function (e.",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 19,
      "context" : "However, in order to compare to the method of Mahoney et al. (2012), we restrict ourselves in this paper to the normalized cut with volume constraints, that is Ŝ(C) = vold(C) vold(C) and g = d.",
      "startOffset" : 46,
      "endOffset" : 68
    }, {
      "referenceID" : 10,
      "context" : "The subgraph of maximum density can be computed in polynomial time (Goldberg, 1984).",
      "startOffset" : 67,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "The problem (2) with only lower bound constraints has been considered in team selection (Gajewar & Das Sarma, 2012) and bioinformatics (Saha et al., 2010) where constant factor approximation algorithms were developed.",
      "startOffset" : 135,
      "endOffset" : 154
    }, {
      "referenceID" : 16,
      "context" : ", hi = 1), and it has been shown that there is no polynomial time approximation scheme in these cases (Khot, 2006; Khuller & Saha, 2009).",
      "startOffset" : 102,
      "endOffset" : 136
    }, {
      "referenceID" : 19,
      "context" : "Our algorithms consistently outperform competing methods (Andersen & Lang, 2006; Mahoney et al., 2012).",
      "startOffset" : 57,
      "endOffset" : 102
    }, {
      "referenceID" : 2,
      "context" : "A particular important class of set functions are submodular set functions since their Lovasz extension is convex (Bach, 2011).",
      "startOffset" : 114,
      "endOffset" : 126
    }, {
      "referenceID" : 2,
      "context" : "In the following we list some useful properties of the Lovasz extension (see Fujishige, 2005; Bach, 2011; Hein & Setzer, 2011).",
      "startOffset" : 72,
      "endOffset" : 126
    }, {
      "referenceID" : 2,
      "context" : "The fact that they are the Lovasz extensions of set functions R̂, Ŝ also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).",
      "startOffset" : 116,
      "endOffset" : 128
    }, {
      "referenceID" : 2,
      "context" : "The fact that they are the Lovasz extensions of set functions R̂, Ŝ also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).",
      "startOffset" : 116,
      "endOffset" : 208
    }, {
      "referenceID" : 7,
      "context" : "Moreover, in the special case where the one-homogeneous function R is convex and S is concave, the RatioDCA reduces to Dinkelbach’s method from fractional programming (Dinkelbach, 1967) and therefore computes the global optimum.",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 2,
      "context" : "2 in Bach (2011) is given by ( t (2) k′ (f) ) ji =  0 volh(Ai+1) > k ′ k′ − volh(Ai+1) volh(Ai) ≥ k′, volh(Ai+1) ≤ k′ hji volh(Ai) < k ′ ,",
      "startOffset" : 5,
      "endOffset" : 17
    }, {
      "referenceID" : 18,
      "context" : "Lemma 4 implies that the minimization problem can be solved via a standard projection onto the simplex, which can be computed in linear time (Kiwiel, 2007).",
      "startOffset" : 141,
      "endOffset" : 155
    }, {
      "referenceID" : 7,
      "context" : "As remarked in Section 4 it can then be solved globally optimally with our method, which in this case is equivalent to Dinkelbach’s method (Dinkelbach, 1967).",
      "startOffset" : 139,
      "endOffset" : 157
    }, {
      "referenceID" : 10,
      "context" : "The following lemma shows that (17) can be rewritten as a s-t-min-cut-problem, which shows that the procedure is similar to the method of Goldberg (1984).",
      "startOffset" : 138,
      "endOffset" : 154
    }, {
      "referenceID" : 15,
      "context" : ", using the pseudo-flow algorithm of Hochbaum (1998).",
      "startOffset" : 37,
      "endOffset" : 53
    }, {
      "referenceID" : 19,
      "context" : "We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).",
      "startOffset" : 85,
      "endOffset" : 107
    }, {
      "referenceID" : 19,
      "context" : "We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).",
      "startOffset" : 85,
      "endOffset" : 164
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally.",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets.",
      "startOffset" : 3,
      "endOffset" : 354
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al.",
      "startOffset" : 3,
      "endOffset" : 585
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments.",
      "startOffset" : 3,
      "endOffset" : 740
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments.",
      "startOffset" : 3,
      "endOffset" : 784
    }, {
      "referenceID" : 19,
      "context" : "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments. The local clustering technique of Andersen & Lang (2006) explores the graph locally by performing a lazy random walk with the transition matrix M = 12 ( I +WD−1 ) , where D is the degree matrix of the graph and the initial distribution is concentrated on the seed set.",
      "startOffset" : 3,
      "endOffset" : 891
    } ],
    "year" : 2013,
    "abstractText" : "The (constrained) minimization of a ratio of set functions is a problem frequently occurring in clustering and community detection. As these optimization problems are typically NP-hard, one uses convex or spectral relaxations in practice. While these relaxations can be solved globally optimally, they are often too loose and thus lead to results far away from the optimum. In this paper we show that every constrained minimization problem of a ratio of non-negative set functions allows a tight relaxation into an unconstrained continuous optimization problem. This result leads to a flexible framework for solving constrained problems in network analysis. While a globally optimal solution for the resulting non-convex problem cannot be guaranteed, we outperform the loose convex or spectral relaxations by a large margin on constrained local clustering problems.",
    "creator" : "LaTeX with hyperref package"
  }
}