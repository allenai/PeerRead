{
  "name" : "1601.03785.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Method for Image Reduction Based on a Generalization of Ordered Weighted Averaging Functions∗",
    "authors" : [ "A. Diego S. Farias", "Valdigleis S. Costa", "Luiz Ranyer A. Lopes", "Benjamı́n Bedregal", "Regivan H. N. Santiago" ],
    "emails" : [ "nio.diego@ufersa.edu.br", "valdigleis@ppgsc.ufrn.br", "ranyer.lopes@gmail.com", "bedregal@dimap.ufrn.br", "regivan@dimap.ufrn.br" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function - OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions — DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the\n∗Preprint submitted to IEEE Transactions on Fuzzy Systems. †Federal University of Semi-Arid - UFERSA, Pau dos Ferros, RN, Brazil, 59.900-000, antonio.diego@ufersa.edu.br ‡DIMAp, valdigleis@ppgsc.ufrn.br §DIMAp, ranyer.lopes@gmail.com ¶DIMAp, bedregal@dimap.ufrn.br ‖Dimap, regivan@dimap.ufrn.br ∗∗DIMAP: Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte — UFRN, Natal, RN, Brazil, 59.072-970\nar X\niv :1\n60 1.\n03 78\n5v 1\nconstruction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided in [1]. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality.\nKeywords: Aggregation functions, OWA functions, Image reduction, Noise reduction."
    }, {
      "heading" : "1 Introduction",
      "text" : "Image processing has great applicability in several areas. In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc. Such images are not always obtained with a suitable quality, and to detect the desired information, various methods have been developed in order to eliminate most of the noise contained in these images.\nAnother problem addressed in image processing is the decrease of resolution, usu-\nally aiming the reduction of memory consumption required for its storage [4].\nThere are several techniques for image reduction in the literature, more recently Paternain et. al. [1] constructed reduction operators using weighted averaging aggregation functions. The proposed method consists of: (1) To reduce a given image by using a reduction operator; (2) To build a new image from the reduced one, and (3) To analyze the quality of the last image by using the measures PSNR and MSIM [4].\nIn this work we introduce a class of aggregation functions called: Dynamic Ordered Weighted Averaging Function - (DYOWA). They generalize the OWA function introduced by Yager [5] and in particular the operators: Arithmetic Mean, Median, Maximum, Minimum and cOWA. We provide a range of their properties such as: idempotence, symmetry and homogeneity as well two methods 1: (1) for image reduction 1These methods were implemented by using Java 1.8.0 31 software in a 64 bits MS Windows machine.\nand (2) for noise treatment.\nThis paper is structured in the following way: SECTION 2 provides some basics of Aggregation Functions Theory. SECTION 3 introduces Dynamic Ordered Weighted Averaging functions, shows some examples and properties, and introduces a particular DY OWA function, called H, which will be fundamental for this work. In SECTION 4 we provide an application of DY OWA’s to image reduction and in SECTION 5, we show that DY OWA functions are able to treat images with noise, aiming to improve the reduction method used in SECTION 4. Finally, section SECTION 6 gives the final remarks of this work."
    }, {
      "heading" : "2 Aggregation Functions",
      "text" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13]. In this section we introduce them together with examples and properties. We also present a special family of aggregation functions called Ordered Weighted Averaging - OWA and show some of its features."
    }, {
      "heading" : "2.1 Definition and Examples",
      "text" : "Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have:\nDefinition 1. An n-ary aggregation function is a mapping f : [0, 1]n → [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that:\n1. f(0, ..., 0) = 0 and f(1, ..., 1) = 1;\n2. If x ≤ y, i.e., xi ≤ yi, for all i = 1, 2, ..., n, then f(x) ≤ f(y).\nExample 1.\n(a) Arithmetic Mean: Arith(x) = 1\nn (x1 + x2...+ xn)\n(b) Minimum: Min(x) = min{x1, x2, ..., xn};\n(c) Maximum: Max(x) = max{x1, x2, ..., xn};\n(d) Harmonic mean: fn(x) = n\n1 x1 + 1x2 + · · ·+ 1 xn\n;\nFrom now on we will use the short term “aggregation” instead of “n-ary aggrega-\ntion function”.\nAggregations can be divided into four distinct classes: Averaging, Conjunctive, Disjunctive and Mixed. Since this paper focus on averaging aggregations, we will define only this class. A wider approach in aggregation can be found in [15, 14, 16, 17].\nDefinition 2. An aggregation is called Averaging, if for all x ∈ [0, 1]n we have:\nMin(x) ≤ f(x) ≤Max(x)\nExample 2. The Arithmetic Mean, the Maximum and the Minimum are averaging aggregation functions."
    }, {
      "heading" : "2.2 Special Types Aggregation Functions",
      "text" : "An aggregation function f :\n(1) is Idempotent if, and only if, f(x, ..., x) = x for all x ∈ [0, 1].\n(2) is Homogeneous of order k if, and only if, for all λ ∈ [0, 1] and x ∈ [0, 1]n,\nf(λx1, λx2, ..., λxn) = λ kf(x1, x2, ..., xn). When f is homogeneous of order 1 we simply say that f is homogeneous.\n(3) is Shift-invariant if, and only if, f(x1+r, x2+r, .., xn+r) = f(x1, x2, .., xn)+\nr, for all r ∈ [−1, 1], x ∈ [0, 1]n such that (x1 + r, x2 + r, ..., xn + r) ∈ [0, 1]n and f(x1, x2, ..., xn) + r ∈ [0, 1].\n(4) is Monotonic if, and only if, x ≤ y implies f(x) ≤ f(y).\n(5) is Strictly Monotone if, and only if, f(x) < f(y) whenever x < y, i.e. x ≤ y\nand x 6= y.\n(6) has a Neutral Element e ∈ [0, 1], if for all t ∈ [0, 1] at any coordinate input\nvector x, it has to be:\nf(e, ..., e, t, e, ..., e) = t, and\n(7) f is Symmetric if, and only if, its value is not changed under the permutations\nof the coordinates of x, i.e, we have:\nf(x1, x2, ..., xn) = f(xp(1) , xp(2) , · · · , xp(n))\nFor all x and any permutation P : {1, 2, ..., n} → {1, 2, ..., n}.\n(8) An Absorbing Element (Annihilator) of an aggregation function f , is an ele-\nment a ∈ [0, 1] such that:\nf(x1, x2, ..., xi−1, a, xi+1, ..., xn) = a\n(9) A Zero Divisor of an aggregation function is an element a ∈ ]0, 1[, such that,\nthere is some vector x with xj > 0, for all 1 ≤ j ≤ n, and f(x1, ..., xj−1, a, xj+1, .., xn) = 0.\n(10) A One Divisor of an aggregation function f is an element a ∈ ]0, 1[ such that,\nthere is some vector x with xj < 1, for all 1 ≤ j ≤ n, and f(x1, ..., xj−1, a, xj+1, .., xn) = 1.\n(11) If N : [0, 1]→ [0, 1] is a strong negation2 and f : [0, 1]n → [0, 1] is an aggrega-\ntion function, then the dual aggregation function of f is:\nfd(x1, x2, ..., xn) = N(f(N(x1), N(x2), ..., N(xn)))\nwhich is also an aggregation function.\nExample 3.\n(i) The functions: Arith,Min andMax are examples of idempotent, homogeneous,\nshift-invariant, monotonic and symmetric functions.\n(ii) Min and Max have 0 and 1 elements as annihilator, respectively, but Arith\ndoes not have annihiladors.\n(iii) Min, Max and Arith do not have zero divisors and one divisors.\n(iv) The dual of Max with respect to negation N(x) = 1− x is the Min function."
    }, {
      "heading" : "2.3 Ordered Weighted Averaging Function - OWA",
      "text" : "In the field of aggregation functions there is a very important subclass in which the elements are parametric; they are called: Ordered Weighted Averaging or simply OWA [5].\nAn OWA is an aggregation function which associates weights to all components xi of an input vector x. To achieve that observe the following definition. 2A strong negation is an antitonic function N : [0, 1] → [0, 1] such that N(N(α)) = α for all α ∈ [0, 1].\nDefinition 3. Let be an input vector x = (x1, x2, . . . , xn) ∈ [0, 1]n and a vector of weights w = (w1, . . . , wn), such that n∑ i=1 wi = 1. Assuming the permutation:\nSort(x) = (xp(1), xp(2), . . . , xp(n))\nsuch that xp(i) ≥ xp(i+1), i.e., xp(1) ≥ xp(2) ≥ . . . ≥ xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1]n → [0, 1] such that:\nOWAw(x) = n∑ i=1 wi · xp(i)\nIn what follows we remove w from OWAw(x). The main properties of such func-\ntions are:\n(a) For any vector of weights w, the function OWA(x) is idempotent and mono-\ntonic. Moreover, OWA(x) is strictly increasing if all weights w are positive;\n(b) The dual of a OWAw is denoted by (OWA)d, with the vector of weights dually\nordered, i.e. (OWAw)d = OWAwd , where wd = (wp(n), wp(n−1), ..., wp(1)).\n(c) OWA are continuous, symmetric and shift-invariant functions;\n(d) They do not have neutral or absorption elements, except in the special case of\nfunctions OWA of Max and Min.\n2.3.1 Examples of special functions OWA\n1. If all weight vector components are equal to 1n , then OWA(x) = Arith((x).\n2. If w = (1, 0, 0, ..., 0), then OWA(x) = Max(x).\n3. If w = (0, 0, 0, ..., 1), then OWA(x) = Min(x).\n4. if wi = 0, for all i, with the exception of a k-th member, i.e, wk = 1, then this\nOWA is called static and OWAw(x) = xk\n5. Given a vector x and its ordered permutation Sort(x) = (x(1), . . . , x(n)), the\nMedian function\nMed(x) =  1 2 (x(k) + x(k+1)), if n = 2k\nx(k+1), if n = 2k + 1\nis an OWA function in which the vector of weights is defined by:\n• If n is odd, then wi = 0 for all i 6= dn2 e and wdn/2e = 1. • If n is even, then wi = 0 for all i 6= dn+12 e and i 6= b n+1 2 c, and wdn/2e =\nwbn/2c = 1 2 .\nExample 4. The n-dimensional cOWA function [18] is the OWA operator, with weighted vector defined by:\n• If n is even, then wj = 2(2j−1)n2 , for 1 ≤ j ≤ n 2 , and wn/2+i = wn/2−i+1, for\n1 ≤ i ≤ n2 .\n• If n is odd, then wj = 2(2j−1)n2 , for 1 ≤ j ≤ n−1 2 , wn/2+i = wn/2−i+1, for\n1 ≤ i ≤ n2 , and w(n+1)/2 = 1− 2 (n−1)/2∑ j=1 wi.\nThe OWA functions are defined in terms of a predetermined vector of weights. In the next section we propose the generalization of the concept of OWA in order to relax the vector of weights. To achieve that we replace the vector of weights by a family of functions. The resulting functions are called Dynamic Ordered Weighted Avegaring Functions or in short: DYOWAs."
    }, {
      "heading" : "3 Dynamic Ordered Weighted Avegaring Functions -",
      "text" : "DY OWA\nBefore defining the notion of DY OWA functions, we need to establish the notion of weight-function.\nDefinition 4. A finite family of functions Γ = {fi : [0, 1]n → [0, 1] | 1 ≤ i ≤ n} such that: n∑ i=1 fi(x) = 1. is called family of weight-function (FWF).\nA Dynamic Ordered Weighted Averaging Function or simply DYOWA associ-\nated to a FWF Γ is a function of the form:\nDY OWAΓ(x) = n∑ i=1 fi(x) · xi\nBelow we show some examples ofDY OWA operators with their respective weight-\nfunctions.\nExample 5. Let be Γ = {fi(x) = 1n | 1 ≤ i ≤ n}. TheDY OWA operator associated to Γ, DY OWAΓ(x), is Arith(x).\nExample 6. The function Minimum can be obtained from Γ = {fi | 1 ≤ i ≤ n}, where f1(x) = f2(x) = · · · = fn−1(x) = 0 and fn(x) = 1, for all x ∈ [0, 1]n.\nExample 7. Similarly, the function Maximum is also of type DY OWA with Γ dually defined.\nExample 8. For any vector of weights w = (w1, w2, ..., wn), A function OWAw(x) is a DY OWA in which the weight-functions are given by: fi(x) = wp(i), where p : {1, 2, · · · , n} −→ {1, 2, · · · , n} is the permutation, such that p(i) = j with xi = x(j). For example: If w = (0.3, 0.4, 0.3), then for x = (0.1, 1.0, 0.9) we have x1 = x(3), x2 = x(1) and x3 = x(2). Thus, f1(x) = 0.3, f2(x) = 0.3, f3(x) = 0.4, and DY OWA(x) = 0.3 · 0.1 + 0.3 · 1.0 + 0.4 · 0.9 = 0.69\nRemark 1. Example 8 shows that the functionsOWA, introduced by Yager, are special cases of DY OWA functions. There are, however, some DY OWA functions which are not OWA.\nExample 9. Let Γ = {sin(x) · y, 1− sin(x) · y}. The respective DY OWA function is DY OWA(x, y) = (sin(x) · y) ·x+ (1− sin(x) · y) · y, which is not an OWA function.\n3.1 Properties of DY OWA Functions\nThe next theorem characterizes the DY OWA functions which are also aggregations.\nTheorem 1. Let Γ = {f1, · · · , fn} be a FWF. ADY OWAΓ is an aggregation function if, and only if, it is monotonic.\nProof. Obviously, ifDY OWAΓ is an aggregation, then it is monotonic function. Conversely, if DY OWAΓ is monotonic, then for it to become an aggregation, enough to show that\nDY OWAΓ(0, ..., 0) = 0 e DY OWAΓ(1, ..., 1) = 1,\nthis follows from the definition of DY OWA.\nCorollary 1. A DY OWA is an aggregation function if, and only if, it is an a aggregation of type averaging.\nProof. For all x = (x1, ..., xn) have to\nMin(x) ≤ xi ≤Max(x), ∀i = 1, 2, ..., n.\nSo, n∑ i=1 fi(x) ·Min(x) ≤ n∑ i=1 fi(x) · xi ≤ n∑ i=1 fi(x) ·Max(x), but as n∑ i=1 fi(x) = 1, it follows that\nMin(x) ≤ n∑ i=1 fi(x) · xi ≤Max(x)\nCorollary 2. All functions of the type DY OWA presented in examples 4, 5, 6, 7 and 8 are averaging aggregation functions.\nProof. Just see that those functions are monotonic.\nProposition 1. For every Γ, DY OWAΓ is idempotent.\nProof. If x = (x, ..., x) with t ∈ [0, 1], then:\nDY OWAΓ(x) = n∑ i=1 fi(x) · x = x · n∑ i=1 fi(x) = x\nThis property is important because it tells us that every DY OWA is idempotent,\nregardless it is an aggregation or not.\nProposition 2. If Γ is invariant under translations, i.e, fi(x1 +λ, x2 +λ, ..., xn+λ) = fi(x1, x2, ..., xn) for any x ∈ [0, 1]n, for i ∈ {1, 2, · · · , n} and λ ∈ [−1, 1], then DY OWAΓ is shift-invariant.\nProof. Let x = (x1, ..., xn) ∈ [0, 1]n and λ ∈ [−1, 1] such that (x1+λ, x2+λ, ..., xn+ λ) ∈ [0, 1]n. then,\nDY OWAΓ (x1 + λ, ..., xn + λ) =\n=\nn∑ i=1 fi(x1 + λ, ..., xn + λ) · (xi + λ)\n=\nn∑ i=1 fi(x1 + λ, ..., xn + λ) · xi\n+ n∑ i=1 fi(x1 + λ, ..., xn + λ) · λ\n=\nn∑ i=1 fi(x1, ..., xn) · xi + λ\n= DY OWAΓ(x1, ..., xn) + λ\nProposition 3. If Γ is homogeneous of order k (i.e., if fi is homogeneus of order k, for each fi ∈ Γ), then DY OWAΓ(x) is homogeneous of order k + 1.\nProof. Of course that, if λ = 0, then DY OWAΓ(λx1, ..., λxn) = λf(x1, ..., xn). Now, to λ 6= 0 we have:\nDY OWAΓ(λx1, ..., λxn) = n∑ i=1 fi(λx1, ..., λxn) · λxi\n= λ · n∑ i=1 λkfi(x1, ..., xn)xi = λk+1 ·DY OWAΓ(x1, ..., xn)\nExample 10. Let Γ be defined by\nfi(x1, ..., xn) =  1 n , if x1 = ... = xn = 0 xi n∑\nj=1 xj\n, otherwise\nThen,\nDY OWAΓ(x) =  0, if x1, ..., xn = 0 n∑ i=1 x2i\nn∑ i=1 xi , otherwise\nThisDY OWAΓ is idempotent, homogeneous and shift-invariant. However,DY OWAΓ is not monotonic, sinceDY OWAΓ(0.5, 0.2, 0.1) = 0.375 andDY OWAΓ(0.5, 0.22, 0.2) = 0.368.\nThe next definition provides a special FWF, which will be used to build aDY OWA\nwhose properties are very important for this paper.\nDefinition 5. Consider the family Γ of functions\nfi(x) =  1 n , if x = (x, ..., x) 1 n−1 1− |xi−Med(x)|n∑ j=1 |xj−Med(x)|  , otherwise\nThen, Γ is a FWF, i.e. n∑ i=1 fi(x) = 1, for all x ∈ [0, 1]n. Let H be the associated DY OWA. The computation of H can be performed using the following expressions:\nH(x) =  x, if x = (x, ..., x) 1 n−1 n∑ i=1 xi − xi|xi−Med(x)|n∑ j=1 |xj−Med(x)|\n , otherwise Example 11. Let be n = 3. So, for x = (0.1, 0.3, 0) we have\nf1(x) = 0.5, f2(x) = 0.167, f3(x) = 0.333 and H(x) = 0.08.\nProposition 4. The weight-functions defined in Definition 5 are such that: fi(x1 + λ, ..., xn + λ) = fi(x1, x2, ..., xn) and fi(λx1, ..., λxn) = fi(x1, ..., xn), for any 1 ≤ i ≤ n.\nProof. Writing x′ = (x1+λ, ..., xn+λ), then f(x1+λ, ..., xn+λ) = (f1(x′), ..., fn(x′)). Clearly, Med(x′) = Med(x) + λ. Thus, for x 6= (x, ..., x) we have:\nfi(x ′) = 1n−1 1− |xi+λ−Med(x′)|n∑ j=1 |xj+λ−Med(x′)|  = 1n−1\n1− |xi+λ−(Med(x)+λ)|n∑ j=1 |xj+λ−(Med(x)+λ)|  = 1n−1\n1− |xi−Med(x)|n∑ j=1 |xj−Med(x)|  = fi(x).\nTherefore, f(x′) = (f1(x′), ..., fn(x′)) = (f1(x), ..., fn(x)). The case in which x = (x, ..., x) is immediate.\nTo check the second property, make x′′ = (λx1, ..., λxn), note that Med(x′′) =\nλmed(x) and for x 6= (x, ..., x)\nfi(x ′′) = 1n−1 1− |λxi−Med(λx)|n∑ j=1 |λxj−Med(λx)|  = 1n−1\n1− |λxi−λMed(x)|n∑ j=1 |λxj−λMed(x)|  = 1n−1 1− |λ|·|xi−Med(x)| |λ|·\nn∑ j=1 |xj−Med(x)|  = 1n−1\n1− |xi−Med(x)|n∑ j=1 |xj−Med(x)|  = fi(x)\nTherefore, f(x′′) = (f1(x′′), ..., fn(x′′)) = (f1(x), ..., fn(x)) = f(x). The case in which x = (x, ..., x) is also immediately\nCorollary 3. H is shift-invariant and homogeneous.\nProof. Straightforward for propositions 2 and 3.\nThe function H is of great importance to this work, since this function, as well as some DY OWA’s already mentioned will provide us tools able: (1) To reduce the size of images and (2) To deal with noise reduction.\nNow, we present some other properties of function H."
    }, {
      "heading" : "3.2 Properties of H",
      "text" : "In addition to idempotency, homogeneity and shift-invariance H has the following proprerties.\nProposition 5. H has no neutral element.\nProof. Suppose H has a neutral element e, find the vector of weight for x = (e, ..., e, x, e, ..., e). Note that if n ≥ 3, then Med(x) = e and therefore,\nfi(x) = 1\nn−1 1− |xi−Med(x)|n∑ j=1 |xj−Med(x)|  = 1n−1\n1− |xi−e|n∑ j=1 |xj−e|  = 1n−1 ( 1− |xi−e||x−e| )\ntherefore,\nfi(x) =  1 n−1 , if xi = e 0, if xi = x , to n ≥ 3\ni.e.,\nf(x) = (\n1 n−1 , ..., 1 n−1 , 0, 1 n−1 , ..., 1 n−1 ) and\nH(x) = (n− 1) · e n− 1 = e\nBut since e is a neutral element of H, H(x) = x. Absurd, since we can always take x 6= e.\nFor n = 2, we have Med(x) = x+ e\n2 , where x = (x, e) or x = (e, x). In both\ncases it is not difficult to show that f(x) = (0.5, 0.5) and H(x) = x+ e\n2 . Thus, taking\nx 6= e, again we have H(x, e) 6= x.\nProposition 6. H has no absorbing elements.\nProof. To n = 2, we have H(x) = x1 + x2\n2 , which has no absorbing elements. Now\nfor n ≥ 3 we have to x = (a, 0, ..., 0) with Med(x) = 0 therefore,\nf1(x) = 1\nn− 1\n( 1− a\na\n) = 0 and fi = 1\nn− 1 ,∀i = 2, ..., n.\ntherefore,\nH(a, 0, ..., 0) = 0 · a+ 1 n− 1 · 0 + ...+ 1 n− 1 · 0 = a⇒ a = 0,\nbut to x = (a, 1, ..., 1) we have to Med(x) = 1. Furthermore,\nf1(x) = 1\nn− 1\n( 1− 1− a 1 − a ) = 0\nand\nfi = 1\nn− 1 para i = 2, 3, ..., n.\ntherefore,\nH(a, 1, ..., 1) = 0 · a+ 1 n− 1 · 1 + ...+ 1 n− 1 · 1 = a⇒ a = 1.\nWith this we prove that H does note have annihiladors.\nProposition 7. H has no zero divisors.\nProof. Let a ∈ ]0, 1[ and consider x = (a, x2, ..., xn) ∈ ]0, 1]n. In order to have H(x) = n∑ i=1 fi(x) · xi = 0 we have fi(x) · xi = 0 for all i = 1, 2, ..., n. But as a 6= 0 and we can always take x2, x3, ..., xn also different from zero, then for each i = 1, 2, ..., n there remains only the possibility of terms:\nfi(x) = 0 para i = 1, 2, ..., n.\nThis is absurd, for fi(x) ∈ [0, 1] e n∑ i=1 fi(x) = 1. like this, H has no zero divisors.\nProposition 8. H does not have one divisors\nProof. Just to see that a ∈ ]0, 1[, we have to H(a, 0, ..., 0) = f1(x).a ≤ a < 1.\nProposition 9. H is symmetric.\nProof. Let P : {1, 2, ..., n} → {1, 2, ..., n} be a permutation. So we can easily see that Med(xP (1), xP (2), ..., xP (n)) = Med(x1, x2, ..., xn) for all x = (x1, x2, ..., xn) ∈\n[0, 1]n. We also have to n∑ i=1 |xP (i)−Med(xP (1), xP (2), ..., xP (n))| = n∑ i=1 |xi−Med(x)|. Thus, it suffices to consider the case where (xP (1), xP (2), ..., xP (n)) 6= (x, x, ..., x). But (xP (1), xP (2), ..., xP (n)) 6= (x, x, ..., x) we have to:\nH (xP (1), xP (2), ..., xP (n)) =\n= 1n−1 n∑ i=1 xP (i) − xP (i)|xP (i)−Med(xP (1),...,xP (n))|n∑ j=1 |xP (i)−Med(xP (1),...,xP (n))|  = n∑ i=1 xP (i)\nn−1 − 1 n−1 · n∑ i=1 xP (i)|xP (i)−Med(x1,...,xn)| n∑\nj=1 |xP (i)−Med(x1,...,xn)|\n=\nn∑ i=1 xi\nn−1 − 1 n−1 · n∑ i=1 xP (i)|xP (i)−Med(x1,...,xn)| n∑\nj=1 |xi−Med(x1,...,xn)|\n=\nn∑ i=1 xi\nn−1 − 1 n−1 · n∑ i=1 xi|xi−Med(x1,...,xn)| n∑\nj=1 |xi−Med(x1,...,xn)|\n= H(x1, ..., xn).\nTherefore, H satisfies the following properties:\n• Idempotence\n• Homogeneity\n• Shift-invariance\n• Symmetry.\n• H has no neutral element\n• H has no absorbing elements\n• H has no zero divisors\n• H does not have one divisors\nRemark 2. Unfortunately we do not prove here the monotonicity of H, due to its complexity, but we suspect that it is true. This demonstration will be relegated to a future work.\nThe next two sections show the suitability of DY OWA. They will provide appli-\ncations for image and noise reduction."
    }, {
      "heading" : "4 DY OWA’s as images reduction tools",
      "text" : "In this part of our work we use the functions DY OWA studied in Examples 4, 5, 6, 7 and 8, and definition 5 to build image reduction operators, the resulting images will be compared with the reduced image obtained from the operator function H.\nAn image is a matrix m × n, M = A(i, j), where each A(i, j) represents a pixel. In essence, a reduction operator reduces a given image m×n to another m′×n′, such that m′ < m and n′ < n. For example,\n 0.1 0.2 0 0.5 0.3 0.3 0.2 0.8 1 0.5 0.6 0.4\n0 0.3 0.5 0.7\n 7−→  0.1 0 1 0.6 \nIn Grayscale images the value of pixels belong to the set [0, 255], which can be\nnormalized by dividing them by 255, so that we can think of pixels as values in the range [0, 1].\nThere are several possible ways to reduce a given image, as shown in the following\nexample:\nExample 12. The image\nM =  0.8 0.7 0.2 1 0.5 0.5 0.6 0.2 0.3 0.1 1 0 0 0 0.6 0.4 0.9 1\n0.1 0.2 0.3 0.4 0.5 0.6\n ,\ncan be reduced to another 2× 3 by partitioning M in blocks 2× 2:\nM =   0.8 0.7 0.6 0.2   0.2 1 0.3 0.1   0.5 0.5 1 0   0 0\n0.1 0.2\n  0.6 0.4\n0.3 0.4\n  0.9 1\n0.5 0.6\n  ,\nand applying to each block, for example, the function f(x, y, z, w) = Max(x, y, z, w): We obtain, the image:\nM∗ =  0.8 1 1 0.2 0.6 1  Applying g(x, y, z, w) = Min(x, y, z, w) we would obtain:\nM∗∗ =  0.2 0.1 0 0 0.2 0.5  In fact, if we apply any other function, we get a new image (usually different from\nthe previous one), but what is the best?\nOne possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one. The magnified image is then compared with the original input image.\nExample 13. From M∗ and M∗∗, we get images 4 × 6, M ′ and M ′′, simply cloning each pixel , [ x ] 7−→  x x x x \nWe obtain, new images\nM1 =  0.8 0.8 1 1 1 1 0.8 0.8 1 1 1 1 0.2 0.2 0.6 0.6 1 1\n0.2 0.2 0.6 0.6 1 1  and\nM2 =  0.2 0.2 0.1 0.1 0 0 0.2 0.2 0.1 0.1 0 0 0 0 0.2 0.2 0.5 0.5\n0 0 0.2 0.2 0.5 0.5  Since M1 e M2 have the same size as the original image M , we can now measure what is the best reduction. This can be done by comparing the initial image M with each of the resulting images, M1 and M2. But, how do we compare?\nOne of the possibilities to compare the images M1 and M2 with the original image\nM is to use the mensure PSNR [4], calculated as follows:\nPSNR(I,K) = 10 · log10 (\nMAX2I MSE(I,K)\n) ,\nwhere I = I(i, j) andK = K(i, j) are two images,MSE(I,K) = 1nm m∑ i=1 n∑ j=1 [I(i, j)− K(i, j)]n and MAXI is the maximum possible pixel value of pixel. Observe that the closer the image the smaller the value of MSE and the larger the value of PSNR 3.\nIn what follows, we use DY OWA operators: H, cOWA,Median and Arith to\nreduce size of images in grayscale. We apply the following method:\nMethod 1\n1. Reduce the input images using the H, cOWA, Arithmetic Mean and Median; 3In particular, if the input image are equal, then the MSE value is zero and the PSNR will be infinity.\n2. Magnify the reduced image to the size of the original image using the method\ndescribed in example 13;\n3. Compare the last image with the original one using the measure PSNR.\nRemark 3. This general method can be applied to any kind of image. In this work we applied it to the 10 images in grayscale of size 512× 512 (Figure 2) 4.\nIn the tables I and II we present the PSNR values between the input images and the output provided by Method 1. Table 1 provides results for operators using blocks 2×2 and Table II for blocks 4× 4.\nAccording to PSNR, Arith provided the higher quality image. However, the reduction operators generated by H and cOWA provide us quite similar images to those given by Arith.\nObserve that although the Method 1 is very simple, it introduces noise in the resulting image. In what follows we show that the operator H is suitable to filter images with noise. This is done by using H to define the weights which are used in the process of convolution. This new process will, then, be used to provide a better comparison in the Method 1. 4In this paper we made two reductions: using 2× 2 blocks and 4× 4 blocks."
    }, {
      "heading" : "5 DY OWA’s as Tools of Noise Reduction",
      "text" : "In this section we show that the DY OWA operators studied in section III can be used to deal with images containing noise.\nThe methodology employed here consists to analyze the previous images with Gaussian noise σ = 10% and 15%; apply a filter built upon the operators H, cOWA and Arith based on convolution method (See [4]), and compare the resulting images with the original one using PSNR.\nTables III and IV demonstrate the power of H on images with noise. All listed operators improved significantly the quality of the image with noise. However, H exceeded all other analyzed.\nFigure 4 shows an example of a image with Gaussian noise σ = 15% and the\nFigure 5 the output image after applying the filter of convolution using H.\nThe reader can see in tables III and IV that H proved to be an excellent operator\nfor noise reduction.\nIn what follows, we modify the Method 1 in order to provide a better magnified\nimage to be compare with the original one.\nMethod 1’\n1. Reduce the input images using the H, cOWA, Arithmetic Mean and Median;\nSince the output of convolution using H is closer to the original input image, the\ntables V and VI show that the process of reduction using H is more efficient."
    }, {
      "heading" : "6 Final Remarks",
      "text" : "In this paper we propose a generalized form of Ordered Weighted Averaging function, called Dynamic Ordered Weighted Averaging function or simply DYOWA. This functions are defined by weights, which are obtained dynamically from of each input vector x ∈ [0, 1]n. We demonstrate, among other results, that OWA functions are instances of DY OWAs, and, hence, functions like: Arithmetic Mean, Median, Maximum, Minimum and cOWA are also examples of DY OWA.\nIn the second part of this work we present a particular DY OWA, called of H, and show that it is idempotent, symmetric, homogeneous, shift-invariant, and moreover, it has no zero divisors and one divisors, and also does not have neutral elements. Since aggregation functions which satisfy these properties are extensively used in image processing, we tested its usefulness to: (1) reduce the size of images and (2) deal with noise in images.\nIn terms of image reduction, Method 1 showed a weakness, since it adds noise during the process of magnification. However, the treatment of noise with function H improved the magnification step providing an evidence that the function H is more efficient to perform the image reduction process."
    } ],
    "references" : [ {
      "title" : "R",
      "author" : [ "D. Paternain", "J. Fernandeza", "H. Bustince" ],
      "venue" : "Mesiar ,G. Beliakov, Construction of image reduction operators using averaging aggregation functions, Fuzzy Sets and Systems 261 ",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Brain Tumor MRI Image Segmentation and Detection in Image Processing",
      "author" : [ "R.P. Joseph", "C.S. Singh", "M. Manikandan" ],
      "venue" : "International Journal of Research and Tecnology, vol 3 ",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "ISEF Based Identification of RCT/Filling in 30  Dental Caries of Decayed Tooth",
      "author" : [ "A.J. Solanki", "K.R. Jain", "N.P. Desai" ],
      "venue" : "International Journal of Image Processing (IJIP), vol 7 ",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Digital Image Processing",
      "author" : [ "R.C. Gonzales", "R.E. Woods" ],
      "venue" : "third edition, Pearson",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Ordered weighted averaging aggregation operators in multicriteria decision making",
      "author" : [ "R.R. Yager" ],
      "venue" : "IEEE Trans. Syst. ManCybern. 18 ",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "On the use of aggregation operations in information fusion processes",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "Fuzzy Sets Syst. 142 ",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Fuzzy Multiple Attribute Decision Making: Methods and Applications",
      "author" : [ "S.-J. Chen", "C.-L. Hwang" ],
      "venue" : "Springer, Berlin, Heidelberg",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Type - 1 OWA operators for aggregating uncertain information with uncertain weight sinduced by type -2 linguistic quantifiers",
      "author" : [ "S. -M. Zhou", "F. Chiclana", "R.I. John", "J.M. Garibaldi" ],
      "venue" : "Fuzzy Sets Syst",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Using a web personal evaluation tool — PET for lexicographic multi-criteria service selection",
      "author" : [ "R.R. Yager", "G. Gumrah", "M. Reformat" ],
      "venue" : "Knowl. - Based Syst. 24 ",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "E",
      "author" : [ "D. Paternain", "A. Jurio", "E. Barrenechea", "H. Bustince", "B.C. Bedregal" ],
      "venue" : "Szmidt: An alternative to fuzzy methods in decision-making problems. Expert Syst. Appl. 39(9): 7729-7735 ",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "R",
      "author" : [ "H. Bustince", "M. Galar", "B.C. Bedregal", "A. Kolesárová" ],
      "venue" : "Mesiar: A New Approach to Interval-Valued Choquet Integrals and the Problem of Ordering in Interval-Valued Fuzzy Set Applications. IEEE T. Fuzzy Systems 21(6): 1150-1162 ",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Image reduction using means on discrete product lattices",
      "author" : [ "G. Beliakov", "H. Bustince", "D. Paternain" ],
      "venue" : "IEEETrans. ImageProcess. 21 ",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Aggregation method for motor drive systems",
      "author" : [ "X. Liang", "W. Xu" ],
      "venue" : "Eletric Power System Research 117 ",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "H",
      "author" : [ "D. Dubois" ],
      "venue" : "Prade (Eds.), Fundamental sof Fuzzy Sets, Kluwer Academic Publishers, Dordrecht",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Aggregation functions: a guide for practitioners",
      "author" : [ "G. Beliakov", "A. Pradera", "T. Calvo" ],
      "venue" : "Stud. Fuzziness Soft Comput. 221",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Aggregation Functions",
      "author" : [ "M. Grabisch", "E. Pap", "J.L. Marichal", "R. Mesiar" ],
      "venue" : "University Press Cambridge",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Fuzzy Implications",
      "author" : [ "M. Baczyńnski", "B. Jayaram" ],
      "venue" : "Springer, Berlin",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Centered OWA operators",
      "author" : [ "R.R. Yager" ],
      "venue" : "Soft Comput. 11 ",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Image magnification using interval information",
      "author" : [ "A. Jurio", "M. Pagola", "R. Mesiar", "G. Beliakov", "H. Bustince" ],
      "venue" : "IEEE Trans. Image Process. 20 ",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Image Super-Revolution Via Sparse Representation",
      "author" : [ "J. Yang", "J. Wright", "T.S. Huang", "Y. Ma" ],
      "venue" : "IEEE Trans on Image Processing, v. 19, n. 11 ",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Image Super-Revolution as Sparse Representation of Raw Image Patches",
      "author" : [ "J. Yang", "J. Wright", "T.S. Huang", "Y. Ma" ],
      "venue" : "Computer Vision and Pattern Recoginition, 2008. CVPR 2008. IEEE Conference, IEEE",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In terms of image reduction we apply the methodology provided in [1].",
      "startOffset" : 65,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : "In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 2,
      "context" : "In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc.",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : "Another problem addressed in image processing is the decrease of resolution, usually aiming the reduction of memory consumption required for its storage [4].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "[1] constructed reduction operators using weighted averaging aggregation functions.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "The proposed method consists of: (1) To reduce a given image by using a reduction operator; (2) To build a new image from the reduced one, and (3) To analyze the quality of the last image by using the measures PSNR and MSIM [4].",
      "startOffset" : 224,
      "endOffset" : 227
    }, {
      "referenceID" : 4,
      "context" : "They generalize the OWA function introduced by Yager [5] and in particular the operators: Arithmetic Mean, Median, Maximum, Minimum and cOWA.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 5,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 8,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 7,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 6,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 10,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 9,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 166,
      "endOffset" : 176
    }, {
      "referenceID" : 1,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 166,
      "endOffset" : 176
    }, {
      "referenceID" : 11,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 166,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 0,
      "context" : "1 Definition and Examples Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have: Definition 1.",
      "startOffset" : 111,
      "endOffset" : 117
    }, {
      "referenceID" : 0,
      "context" : "1 Definition and Examples Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have: Definition 1.",
      "startOffset" : 155,
      "endOffset" : 161
    }, {
      "referenceID" : 0,
      "context" : "An n-ary aggregation function is a mapping f : [0, 1] → [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.",
      "startOffset" : 47,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "An n-ary aggregation function is a mapping f : [0, 1] → [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.",
      "startOffset" : 56,
      "endOffset" : 62
    }, {
      "referenceID" : 0,
      "context" : "An n-ary aggregation function is a mapping f : [0, 1] → [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.",
      "startOffset" : 148,
      "endOffset" : 154
    }, {
      "referenceID" : 14,
      "context" : "A wider approach in aggregation can be found in [15, 14, 16, 17].",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "A wider approach in aggregation can be found in [15, 14, 16, 17].",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 15,
      "context" : "A wider approach in aggregation can be found in [15, 14, 16, 17].",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 16,
      "context" : "A wider approach in aggregation can be found in [15, 14, 16, 17].",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "An aggregation is called Averaging, if for all x ∈ [0, 1] we have:",
      "startOffset" : 51,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : ", x) = x for all x ∈ [0, 1].",
      "startOffset" : 21,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "(2) is Homogeneous of order k if, and only if, for all λ ∈ [0, 1] and x ∈ [0, 1], f(λx1, λx2, .",
      "startOffset" : 59,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "(2) is Homogeneous of order k if, and only if, for all λ ∈ [0, 1] and x ∈ [0, 1], f(λx1, λx2, .",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 0,
      "context" : ", xn)+ r, for all r ∈ [−1, 1], x ∈ [0, 1] such that (x1 + r, x2 + r, .",
      "startOffset" : 35,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : ", xn + r) ∈ [0, 1] and f(x1, x2, .",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : ", xn) + r ∈ [0, 1].",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "(6) has a Neutral Element e ∈ [0, 1], if for all t ∈ [0, 1] at any coordinate input vector x, it has to be:",
      "startOffset" : 30,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "(6) has a Neutral Element e ∈ [0, 1], if for all t ∈ [0, 1] at any coordinate input vector x, it has to be:",
      "startOffset" : 53,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "(8) An Absorbing Element (Annihilator) of an aggregation function f , is an element a ∈ [0, 1] such that:",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "(11) If N : [0, 1]→ [0, 1] is a strong negation2 and f : [0, 1] → [0, 1] is an aggregation function, then the dual aggregation function of f is:",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "(11) If N : [0, 1]→ [0, 1] is a strong negation2 and f : [0, 1] → [0, 1] is an aggregation function, then the dual aggregation function of f is:",
      "startOffset" : 20,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "(11) If N : [0, 1]→ [0, 1] is a strong negation2 and f : [0, 1] → [0, 1] is an aggregation function, then the dual aggregation function of f is:",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "(11) If N : [0, 1]→ [0, 1] is a strong negation2 and f : [0, 1] → [0, 1] is an aggregation function, then the dual aggregation function of f is:",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 4,
      "context" : "3 Ordered Weighted Averaging Function - OWA In the field of aggregation functions there is a very important subclass in which the elements are parametric; they are called: Ordered Weighted Averaging or simply OWA [5].",
      "startOffset" : 213,
      "endOffset" : 216
    }, {
      "referenceID" : 0,
      "context" : "2A strong negation is an antitonic function N : [0, 1] → [0, 1] such that N(N(α)) = α for all α ∈ [0, 1].",
      "startOffset" : 48,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "2A strong negation is an antitonic function N : [0, 1] → [0, 1] such that N(N(α)) = α for all α ∈ [0, 1].",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 0,
      "context" : "2A strong negation is an antitonic function N : [0, 1] → [0, 1] such that N(N(α)) = α for all α ∈ [0, 1].",
      "startOffset" : 98,
      "endOffset" : 104
    }, {
      "referenceID" : 0,
      "context" : ", xn) ∈ [0, 1] and a vector of weights w = (w1, .",
      "startOffset" : 8,
      "endOffset" : 14
    }, {
      "referenceID" : 0,
      "context" : "≥ xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1] → [0, 1] such that: OWAw(x) = n ∑",
      "startOffset" : 96,
      "endOffset" : 102
    }, {
      "referenceID" : 0,
      "context" : "≥ xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1] → [0, 1] such that: OWAw(x) = n ∑",
      "startOffset" : 105,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "The n-dimensional cOWA function [18] is the OWA operator, with weighted vector defined by: • If n is even, then wj = 2(2j−1) n2 , for 1 ≤ j ≤ n 2 , and wn/2+i = wn/2−i+1, for 1 ≤ i ≤ n2 .",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "A finite family of functions Γ = {fi : [0, 1] → [0, 1] | 1 ≤ i ≤ n} such that: n ∑",
      "startOffset" : 39,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "A finite family of functions Γ = {fi : [0, 1] → [0, 1] | 1 ≤ i ≤ n} such that: n ∑",
      "startOffset" : 48,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "The function Minimum can be obtained from Γ = {fi | 1 ≤ i ≤ n}, where f1(x) = f2(x) = · · · = fn−1(x) = 0 and fn(x) = 1, for all x ∈ [0, 1].",
      "startOffset" : 133,
      "endOffset" : 139
    }, {
      "referenceID" : 0,
      "context" : ", x) with t ∈ [0, 1], then:",
      "startOffset" : 14,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : ", xn) for any x ∈ [0, 1], for i ∈ {1, 2, · · · , n} and λ ∈ [−1, 1], then DY OWAΓ is shift-invariant.",
      "startOffset" : 18,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : ", xn) ∈ [0, 1] and λ ∈ [−1, 1] such that (x1+λ, x2+λ, .",
      "startOffset" : 8,
      "endOffset" : 14
    }, {
      "referenceID" : 0,
      "context" : ", xn+ λ) ∈ [0, 1].",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "n ∑ i=1 fi(x) = 1, for all x ∈ [0, 1].",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : "This is absurd, for fi(x) ∈ [0, 1] e n ∑ i=1 fi(x) = 1.",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 0,
      "context" : ", xn) ∈ [0, 1].",
      "startOffset" : 8,
      "endOffset" : 14
    }, {
      "referenceID" : 0,
      "context" : "normalized by dividing them by 255, so that we can think of pixels as values in the range [0, 1].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.",
      "startOffset" : 219,
      "endOffset" : 231
    }, {
      "referenceID" : 19,
      "context" : "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.",
      "startOffset" : 219,
      "endOffset" : 231
    }, {
      "referenceID" : 20,
      "context" : "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.",
      "startOffset" : 219,
      "endOffset" : 231
    }, {
      "referenceID" : 3,
      "context" : "But, how do we compare? One of the possibilities to compare the images M1 and M2 with the original image M is to use the mensure PSNR [4], calculated as follows:",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 3,
      "context" : "The methodology employed here consists to analyze the previous images with Gaussian noise σ = 10% and 15%; apply a filter built upon the operators H, cOWA and Arith based on convolution method (See [4]), and compare the resulting images with the original one using PSNR.",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 0,
      "context" : "This functions are defined by weights, which are obtained dynamically from of each input vector x ∈ [0, 1].",
      "startOffset" : 100,
      "endOffset" : 106
    } ],
    "year" : 2016,
    "abstractText" : "In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions — DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the ∗Preprint submitted to IEEE Transactions on Fuzzy Systems. †Federal University of Semi-Arid UFERSA, Pau dos Ferros, RN, Brazil, 59.900-000, antonio.diego@ufersa.edu.br ‡DIMAp, valdigleis@ppgsc.ufrn.br §DIMAp, ranyer.lopes@gmail.com ¶DIMAp, bedregal@dimap.ufrn.br ‖Dimap, regivan@dimap.ufrn.br ∗∗DIMAP: Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte — UFRN, Natal, RN, Brazil, 59.072-970 1 ar X iv :1 60 1. 03 78 5v 1 [ cs .A I] 1 5 Ja n 20 16 construction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided in [1]. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality.",
    "creator" : "LaTeX with hyperref package"
  }
}