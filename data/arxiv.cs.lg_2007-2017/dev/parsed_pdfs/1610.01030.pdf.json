{
  "name" : "1610.01030.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Applications of Online Deep Learning for Crisis Response Using Social Media Information",
    "authors" : [ "Dat Tien Nguyen", "Shafiq Joty", "Muhammad Imran", "Hassan Sajjad", "Prasenjit Mitra" ],
    "emails" : [ "pmitra}@qf.org.qa" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords deep learning, supervised classification, twitter, text classification, crisis response"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Emergency events such as natural or man-made disasters bring unique challenges for humanitarian response organizations. Particularly, sudden-onset crisis situations demand officials to make fast decisions based on minimum information available to deploy rapid crisis response. However, information scarcity during time-critical situations hinders decision-making processes and delays response efforts [4, 7].\nDuring crises, people post updates regarding their statuses, ask for help and other useful information, report infrastructure damages, injured people, etc., on social media platforms like Twitter [26]. Humanitarian organizations can use this citizen-generated information to provide relief if critical information is easily available in a timely fashion.1 In this paper, we consider the classifica-\n1http://www.napsgfoundation.org/wp-content/uploads/2013/02/ NAPSG-Remote-Sensing-Webcast-022213.pdf\nThis article has been peer reviewed and accepted at the 4th international workshop on Social Web for Disaster Management (SWDM), co-located with the 25th Conference of Information and Knowledge Management (CIKM), October 24–28, 2016, Indianapolis, USA.\nCopyright is held by the authors.\ntion of the social media posts into different humanitarian categories to fulfill different information needs of humanitarian organizations. Specifically, we address two types of information needs described as follows:\nInformativeness of social media posts: Information posted on social networks during crises vary greatly in value. Most messages contain irrelevant information not useful for disaster response and management. Humanitarian organizations do not want a deluge of noisy messages that are of a personal nature or those that do not contain any useful information. They want clean data that consists of messages containing potentially useful information. They can then use this information for various purposes such as situational awareness. In order to assist humanitarian organizations, we perform binary classification. That is, we aim to classify each message into one of the two classes i.e. “informative\" vs. “not informative\".\nInformation types of social media posts Furthermore, humanitarian organizations are interested in sorting social media posts into different categories. Identifying social media posts by category assists humanitarian organizations in coordinating their response. Categories such as infrastructure damage, reports of deceased or injured, urgent need for shelter, food and water, or donations of goods or services could therefore be directed to different relief functions. In this work, we show how we can classify tweets into multiple classes.\nAutomatic classification of short crisis-related messages such as tweets is a challenging task due to a number of reasons. Tweets are short (only 140 characters), informal, often contain abbreviations, spelling variations and mistakes, and, therefore, they are hard to understand without enough context. Despite advances in natural language processing (NLP), interpreting the semantics of short informal texts automatically remains a hard problem. Traditional classification approaches rely on manually engineered features like cue words and TF-IDF vectors for learning [7]. Due to the high variability of the data during a crisis, adapting the model to changes in features and their importance manually is undesirable (and often infeasible).\nTo overcome these issues, we use Deep Neural Networks (DNNs) to classify the tweets. DNNs are usually trained using online learning and have the flexibility to adaptively learn the model parameters as new batches of labeled data arrive, without requiring to retrain the model from scratch. DNNs use distributed condensed representation of words and learn the representation as well as higher level abstract features automatically for the classification task. Distributed representation (as opposed to sparse discrete representation) generalizes well. This can be a crucial advantage at the beginning of a new disaster, when there is not enough event-specific labeled data. We can train a reasonably good DNN model using previously labeled data from other events, and then the model is\nar X\niv :1\n61 0.\n01 03\n0v 2\n[ cs\n.C L\n] 5\nO ct\n2 01\n6\n!!\n!! !! !!\nfine-tuned adaptively as newly labeled data arrives in small batches. In this paper, we use Deep Neural Network (DNN) to address two types of information needs of response organizations: (i) identifying informative tweets and (ii) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. Moreover, we make our source code publicly available for crisis computing community for further research at: https://github.com/CrisisNLP/deep-learning-for-big-crisis-data\nIn the next section, we provide details regarding DNNs we use and the online learning algorithm. Section 3 describes datasets and online learning settings. In Section 4, we describe results of our models. Section 5 presents related-work and we conclude our paper in Section 6."
    }, {
      "heading" : "2. DEEP NEURAL NETWORK",
      "text" : "As argued before, deep neural networks (DNNs) can be quite effective in classifying tweets during a disaster situation because of their distributed representation of words and automatic feature learning capabilities. Furthermore, DNNs are usually trained using online algorithms, which nicely suits the needs of a crisis response situation.\nOur main hypothesis is that in order to effectively classify tweets, which are short and informal, a classification model should learn the key features at different levels of abstraction. To this end, we use a Convolutional Neural Network (CNN), which has been shown to be effective for sentence-level classification tasks [13]."
    }, {
      "heading" : "2.1 Convolutional Neural Network",
      "text" : "Figure 1 demonstrates how a CNN works with an example tweet.2 Each word in the vocabulary V is represented by a D dimensional vector in a shared look-up table L ∈ R|V |×D . L is considered a model parameter to be learned. We can initialize L randomly or using pretrained word embedding vectors like word2vec [16].\nGiven an input tweet s = (w1, · · · , wT ), we first transform it into a feature sequence by mapping each word token wt ∈ s to an 2The HTTP tag in the example represents URLs.\nindex inL. The look-up layer then creates an input vector xt ∈ RD for each token wt, which are passed through a sequence of convolution and pooling operations to learn high-level abstract features.\nA convolution operation involves applying a filter u ∈ RL.D to a window of L words to produce a new feature\nht = f(u.xt:t+L−1 + bt) (1)\nwhere xt:t+L−1 denotes the concatenation of L input vectors, bt is a bias term, and f is a nonlinear activation function (e.g., sig, tanh). A filter is also known as a kernel or a feature detector. We apply this filter to each possibleL-word window in the tweet to generate a feature map hi = [h1, · · · , hT+L−1]. We repeat this processN times with N different filters to get N different feature maps. We use a wide convolution [12] (as opposed to narrow), which ensures that the filters reach the entire sentence, including the boundary words. This is done by performing zero-padding, where out-of-range (i.e., t<1 or t>T ) vectors are assumed to be zero.\nAfter the convolution, we apply a max-pooling operation to each feature map.\nm = [µp(h1), · · · , µp(hN )] (2) where µp(hi) refers to the max operation applied to each window of p features in the feature map hi. For instance, with p = 2, this pooling gives the same number of features as in the feature map (because of the zero-padding). Intuitively, the filters compose local n-grams into higher-level representations in the feature maps, and max-pooling reduces the output dimensionality while keeping the most important aspects from each feature map.\nSince each convolution-pooling operation is performed independently, the features extracted become invariant in locations (i.e., where they occur in the tweet), thus acting like bag-of-n-grams. However, keeping the order information could be important for modeling sentences. In order to model interactions between the features picked up by the filters and the pooling, we include a dense layer of hidden nodes on top of the pooling layer\nz = f(Vm+ bh) (3)\nwhere V is the weight matrix, bh is a bias vector, and f is a nonlinear activation. The dense layer naturally deals with variable sentence lengths by producing fixed size output vectors z, which are fed to the output layer for classification.\nDepending on the classification tasks, the output layer defines a probability distribution. For binary classification tasks, it defines a Bernoulli distribution:\np(y|s, θ) = Ber(y| sig(wTz+ b)) (4) where sig refers to the sigmoid function, and w are the weights from the dense layer to the output layer and b is a bias term. For multi-class classification the output layer uses a softmax function. Formally, the probability of k-th label in the output for classification into K classes:\nP (y = k|s, θ) = exp (w T k z+ bk)∑K\nj=1 exp (w T j z+ bj)\n(5)\nwhere, wk are the weights associated with class k in the output layer. We fit the models by minimizing the cross-entropy between the predicted distributions ŷnθ = p(yn|sn, θ) and the target distributions yn (i.e., the gold labels).3 The objective function f(θ) can 3Other loss functions (e.g., hinge) yielded similar results.\nAlgorithm 1: Online learning of CNN 1. Initialize the model parameters θ0; 2. for a minibatch Bt = {s1 . . . sn} at time t do\na. Compute the loss f(θt) in Equation 6; b. Compute gradients of the loss f ′(θt) using backpropagation; c. Update: θt+1 = θt − ηt 1nf\n′(θt); end\nbe written as:\nf(θ) = N∑ n=1 K∑ k=1 ynk log P (yn = k|sn, θ) (6)\nwhere,N is the number of training examples and ynk = I(yn = k) is an indicator variable to encode the gold labels, i.e., ytk = 1 if the gold label yt = k, otherwise 0."
    }, {
      "heading" : "2.2 Online Learning",
      "text" : "DNNs are usually trained with first-order online methods like stochastic gradient descent (SGD). This method yields a crucial advantage in crisis situations, where retraining the whole model each time a small batch of labeled data arrives is impractical. Algorithm 1 demonstrates how our CNN model can be trained in a purely online setting. We first initialize the model parameters θ0 (line 1), which can be a trained model from other disaster events or it can be initialized randomly to start from scratch.\nAs a new batch of labeled tweets Bt = {s1 . . . sn} arrives, we first compute the log-loss (cross entropy) in Equation 6 forBt with respect to the current parameters θt (line 2a). Then, we use backpropagation to compute the gradients f ′(θt) of the loss with respect to the current parameters (line 2b). Finally, we update the parameters with the learning rate ηt and the mean of the gradients (line 2c). We take the mean of the gradients to deal with minibatches of different sizes. Notice that we take only the current minibatch into account to get an updated model. Choosing a proper learning rate ηt can be difficult in practice. Several adaptive methods such as ADADELTA [27], ADAM [14], etc., have been proposed to overcome this issue. In our model, we use ADADELTA."
    }, {
      "heading" : "2.3 Word Embedding and Fine-tuning",
      "text" : "As mentioned before, we can initialize the word embeddings L randomly, and learn them as part of model parameters by backpropagating the errors to the look-up layer. Random initialization may lead the training algorithm to get stuck in a local minima. One can plug the readily available embeddings from external sources (e.g., Google embeddings [16]) in the neural network model and use them as features without further task-specific tuning. However, the latter approach does not exploit the automatic feature learning capability of DNN models, which is one of the main motivations of using them. In our work, we use pre-trained word embeddings (see below) to better initialize our models, and we fine-tune them for our task, which turns out to be beneficial.\nMikolov et al. [16] propose two log-linear models for computing word embeddings from large (unlabeled) corpuses efficiently: (i) a bag-of-words model CBOW that predicts the current word based on the context words, and (ii) a skip-gram model that predicts surrounding words given the current word.4 They released their pre-trained 300-dimensional word embeddings trained by the skip-gram model on a Google news dataset. 4https://code.google.com/p/word2vec/\nSince we work on disaster related tweets, which are quite different from news, we have trained domain-specific embeddings of 300-dimensions (vocabulary size 20 million) using the Skip-gram model of word2vec tool [17] from a large corpus of disaster related tweets. The corpus contains 57, 908 tweets and 9.4 million tokens."
    }, {
      "heading" : "3. DATASET AND EXPERIMENTAL SETTINGS",
      "text" : "In this section, we describe the datasets used for the classification tasks and the settings for CNN and online learning."
    }, {
      "heading" : "3.1 Dataset and Preprocessing",
      "text" : "We use CrisisNLP [9] labeled datasets. The CNN models were trained online using a labeled dataset related to the 2015 Nepal Earthquake5 and the rest of the datasets are used to train an initial model (θ0 in Algorithm 1) upon which the online learning is performed. The Nepal earthquake dataset consists of approximately 12k labeled tweets collected from Twitter during the event using different keywords like NepalEarthquake. Of all the labeled tweets, 9k are labeled by trained volunteers6 during the actual event using the AIDR platform [8] and the remaining 3k tweets are labeled using the Crowdflower7 crowdsourcing platform.\nThe dataset is labeled into different informative classes (e.g., affected individuals, infrastructure damage, donations etc.) and one “not-related” or “irrelevant” class. Table 1 provides a one line description of each class and also the total number of labels in each class. Other useful information and Not related or irrelevant are the most frequent classes in the dataset.\nData Preprocessing: We normalize all characters to their lowercased forms, truncate elongations to two characters, spell out every digit to D, all twitter usernames to userID, and all URLs to HTTP. We remove all punctuation marks except periods, semicolons, question and exclamation marks. We further tokenize the tweets using the CMU TweetNLP tool [6]."
    }, {
      "heading" : "3.2 Online Training Settings",
      "text" : "Before performing the online learning, we assume that an initial model θ0 exists. In our case, we train the initial model using all the datasets from CrisisNLP except the Nepal earthquake. For online training, we sort the Nepal labeled data based on the time stamp of the tweets. This brings the tweets in their posting order. Next, the dataset D is divided at each time interval dt in which case D is defined as: D = ∑T t=1 dt where dt = 200. For each time interval t, we divide the available labeled dataset into a train set (70%), dev set (10%), and a test set (20%) using ski-learn toolkit’s module [19], which ensured that the class distribution remains reasonably balanced in each subset.\nBased on the data splitting strategy mentioned above, we start online learning to train a binary and a multi-class classifier. For the binary classifier training, we merge all the informative classes to create one general Informative class. We train CNN models by optimizing the cross entropy in Equation 4 using the gradient-based online learning algorithm ADADELTA [27].8 The learning rate and the parameters were set to the values as suggested by the authors. The maximum number of epochs was set to 25. To avoid overfitting, we use dropout [23] of hidden units and early stop-\n5https://en.wikipedia.org/wiki/April_2015_Nepal_earthquake 6These are trained volunteers from the Stand-By-Task-Force organization (http://blog.standbytaskforce.com/). 7crowdflower.com 8Other algorithms (SGD, Adagrad) gave similar results.\nping based on the accuracy on the validation set.9 We experimented with {0.0, 0.2, 0.4, 0.5} dropout rates and {32, 64, 128} minibatch sizes. We limit the vocabulary (V ) to the most frequent P% (P ∈ {80, 85, 90}) words in the training corpus. The word vectors in L were initialized with the pre-trained embeddings. We use rectified linear units (ReLU) for the activation functions (f ), {100, 150, 200} filters each having window size (L) of {2, 3, 4}, pooling length (p) of {2, 3, 4}, and {100, 150, 200} dense layer units. All the hyperparameters are tuned on the development set."
    }, {
      "heading" : "4. RESULTS",
      "text" : "In this section, we present our results for binary and multi-class classification tasks."
    }, {
      "heading" : "4.1 Binary Classification",
      "text" : "Figure 2 shows the results for the “informative\" vs. “not informative\" binary classification task using online learning. The performance of the model is quite inconsistent as the size of the in-event training data varies. We observe an improvement in performance initially. However, the results dropped when the training size is between 2200 to 3900 tweets. We investigated this strange result and found that this could be due to the inconsistencies in the annotation procedure and the data sources. In our in-event (Nepal Earthquake) training data, first 3000 tweets are from CrowdFlower and the rest are from AIDR. Tweets in CrowdFlower were annotated by paid workers, where AIDR tweets are annotated by volunteers. We speculate these inconsistencies can affect the performance at the beginning, but as the model sees more AIDR data (4000+), the performance stabilizes."
    }, {
      "heading" : "4.2 Multi-Class Classification",
      "text" : "Figure 3 summarizes the results of online training for the multiclass classification task. Since multi-class classification is a harder task than binary classification, the first training run provides very low accuracy and the results continue to drop until a good number of training examples are available, which in this case is approximately 2200 labeled tweets. As in the binary classification case, after the initial dip in performance, once over 3000 tweets are available, the performance of the classifier improves and remains stable after that.\nThe benefit of using online learning methods like CNN compared to offline learning methods used in classifiers like SVM, Naive Bayes, and Logistic Regression is online training. The labeled data comes in batches and retraining a model on the complete data every time with the addition of newly labeled data is an expensive task. Online training methods learn in small batches, which suits the situation in hand perfectly.\nAnother advantage of neural network methods is automatic feature extraction that does not require any manual feature engineering. The models take labeled tweets as input and automatically\n9l1 and l2 regularization on weights did not work well.\nlearn features based on distributed representation of words."
    }, {
      "heading" : "4.3 Discussion",
      "text" : "Rapid analysis of social media posts during time-critical situations is important for humanitarian response organization to take timely decisions and to launch relief efforts. This work proposes solutions to two main challenges that humanitarian organizations face while incorporating social media data into crisis response. First, how to filter-out noisy and irrelevant messages from big crisis data and second, categorization of the informative messages into different classes of interest. By utilizing labeled data from past crises, we show the performance of DNNs trained using the proposed online learning algorithm for binary and multi-class classification tasks.\nWe observe that past labeled data helps when no event-specific data is available in the early hours of a crisis. However, labeled data from event always help improve the classification accuracy."
    }, {
      "heading" : "5. RELATED WORK",
      "text" : "Recent studies have shown the usefulness of crisis-related data on social media for disaster response and management [1, 22, 24]. A number of systems have been developed to classify, extract, and summarize [21] crisis-relevant information from social media; for a detailed survey see [7]. Cameron, et al., describe a platform for emergency situation awareness [2]. They classify interesting tweets using an SVM classifier. Verma, et al., use Naive Bayes and MaxEnt classifiers to find situational awareness tweets from several crises [25]. Imran, et al., implemented AIDR to classify a Twitter data stream during crises [8]. They use a random forest classifier in\nan offline setting. After receiving every mini-batch of 50 training examples, they replace the older model with a new one. In [10], the authors show the performance of a number of non-neural network classifiers trained on labeled data from past crisis events. However, they do not use DNNs in their comparison.\nDNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11]. The emergence of tools such as word2vec [17] and GloVe [20] have enabled NLP researchers to learn word embeddings efficiently and use them to train better models.\nCollobert, et al. [5] presented a unified DNN architecture for solving various NLP tasks including part-of-speech tagging, chunking, named entity recognition and semantic role labeling. They showed that DNNs outperform traditional models in most of these tasks. They also proposed a multi-task learning framework for solving the tasks jointly.\nKim [13] and Kalchbrenner et al. [12] used convolutional neural networks (CNN) for sentence-level classification tasks (e.g., sentiment/polarity classification, question classification) and showed that CNNs outperform traditional methods (e.g., SVMs, MaxEnts). Caragea, Silvescu, and Tapia used CNNs to identify informative messages during disasters [3]. However, to the best of our knowledge, no previous research has shown the efficacy of CNNs to both the binary classification and the multi-class classification problems using online learning."
    }, {
      "heading" : "6. CONCLUSIONS",
      "text" : "We presented an online learning model namely Convolutional Neural Network for the purpose of classifying tweets in a disaster response scenario. We proposed a new online learning algorithm for training CNNs in online fashion. We showed that online training of the model perfectly suits the disaster response situation. We assume that a base model trained on past crisis labeled data exists and the event-specific labeled data arrive in small batches which are used to perform online learning. The neural network models bring an additive advantage of automatic feature extraction which eases the training process when compared with offline learning methods like SVM, logistic regression. The model uses only labeled tweets for training and automatically learns features from them. We re-\nported the results of two classification tasks (i.e. binary and multiclass). Moreover, we also provide source code for the online learning of CNN models to research community for further extensions."
    }, {
      "heading" : "7. REFERENCES",
      "text" : "[1] A. Acar and Y. Muraki. Twitter for crisis communication:\nlessons learned from japan’s tsunami disaster. International Journal of Web Based Communities, 7(3):392–402, 2011.\n[2] M. A. Cameron, R. Power, B. Robinson, and J. Yin. Emergency situation awareness from twitter for crisis management. In Proceedings of the 21st international conference companion on World Wide Web, pages 695–698. ACM, 2012.\n[3] C. Caragea, A. Silvescu, and A. H. Tapia. Identifying informative messages in disaster events using convolutional neural networks. International Conference on Information Systems for Crisis Response and Management, 2016.\n[4] C. Castillo. Big Crisis Data. Cambridge University Press, 2016.\n[5] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493–2537, 2011.\n[6] K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan, and N. A. Smith. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 42–47. Association for Computational Linguistics, 2011.\n[7] M. Imran, C. Castillo, F. Diaz, and S. Vieweg. Processing social media messages in mass emergency: a survey. ACM Computing Surveys (CSUR), 47(4):67, 2015.\n[8] M. Imran, C. Castillo, J. Lucas, P. Meier, and S. Vieweg. AIDR: Artificial intelligence for disaster response. In Proceedings of the companion publication of the 23rd international conference on World wide web companion, pages 159–162. International World Wide Web Conferences Steering Committee, 2014.\n[9] M. Imran, P. Mitra, and C. Castillo. Twitter as a lifeline: Human-annotated twitter corpora for NLP of crisis-related messages. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC), 2016.\n[10] M. Imran, P. Mitra, and J. Srivastava. Cross-language domain adaptation for classifying crisis-related short messages. International Conference on Information Systems for Crisis Response and Management, 2016.\n[11] S. R. Joty and E. Hoque. Speech act modeling of written asynchronous conversations with task-specific embeddings and conditional structured models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, 2016.\n[12] N. Kalchbrenner, E. Grefenstette, and P. Blunsom. A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 655–665, Baltimore, Maryland, June 2014. Association for Computational Linguistics.\n[13] Y. Kim. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar, October 2014. Association for Computational Linguistics.\n[14] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.\n[15] P. Liu, S. Joty, and H. Meng. Fine-grained opinion mining with recurrent neural networks and word embeddings. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1433–1443, Lisbon, Portugal, September 2015. Association for Computational Linguistics.\n[16] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.\n[17] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111–3119, 2013.\n[18] D. T. Nguyen, K. A. A. Mannai, S. Joty, H. Sajjad, M. Imran, and P. Mitra. Rapid classification of crisis-related data on social networks using convolutional neural networks. arXiv preprint arXiv:1608.03902, 2016.\n[19] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.\n[20] J. Pennington, R. Socher, and C. Manning. Glove: Global\nvectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha, Qatar, October 2014. Association for Computational Linguistics.\n[21] K. Rudra, S. Banerjee, N. Ganguly, P. Goyal, M. Imran, and P. Mitra. Summarizing situational tweets in crisis scenario. In Proceedings of the 27th ACM Conference on Hypertext and Social Media, pages 137–147. ACM, 2016.\n[22] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes twitter users: real-time event detection by social sensors. In Proceedings of the 19th international conference on World wide web, pages 851–860. ACM, 2010.\n[23] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15:1929–1958, 2014.\n[24] I. Varga, M. Sano, K. Torisawa, C. Hashimoto, K. Ohtake, T. Kawai, J.-H. Oh, and S. De Saeger. Aid is out there: Looking for help from tweets during a large scale disaster. In ACL (1), pages 1619–1629, 2013.\n[25] S. Verma, S. Vieweg, W. J. Corvey, L. Palen, J. H. Martin, M. Palmer, A. Schram, and K. M. Anderson. Natural language processing to the rescue? extracting\" situational awareness\" tweets during mass emergency. In ICWSM. Citeseer, 2011.\n[26] S. Vieweg, C. Castillo, and M. Imran. Integrating social media communications into the rapid assessment of sudden onset disasters. In Social Informatics, pages 444–461. Springer, 2014.\n[27] M. D. Zeiler. ADADELTA: an adaptive learning rate method. CoRR, abs/1212.5701, 2012."
    } ],
    "references" : [ {
      "title" : "Twitter for crisis communication: lessons learned from japan’s tsunami disaster",
      "author" : [ "A. Acar", "Y. Muraki" ],
      "venue" : "International Journal of Web Based Communities, 7(3):392–402",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Emergency situation awareness from twitter for crisis management",
      "author" : [ "M.A. Cameron", "R. Power", "B. Robinson", "J. Yin" ],
      "venue" : "Proceedings of the 21st international conference companion on World Wide Web, pages 695–698. ACM",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Identifying informative messages in disaster events using convolutional neural networks",
      "author" : [ "C. Caragea", "A. Silvescu", "A.H. Tapia" ],
      "venue" : "International Conference on Information Systems for Crisis Response and Management",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Big Crisis Data",
      "author" : [ "C. Castillo" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa" ],
      "venue" : "The Journal of Machine Learning Research, 12:2493–2537",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "B",
      "author" : [ "K. Gimpel", "N. Schneider" ],
      "venue" : "O’Connor, D. Das, D. Mills, J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan, and N. A. Smith. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 42–47. Association for Computational Linguistics",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Processing social media messages in mass emergency: a survey",
      "author" : [ "M. Imran", "C. Castillo", "F. Diaz", "S. Vieweg" ],
      "venue" : "ACM Computing Surveys (CSUR), 47(4):67",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "AIDR: Artificial intelligence for disaster response",
      "author" : [ "M. Imran", "C. Castillo", "J. Lucas", "P. Meier", "S. Vieweg" ],
      "venue" : "Proceedings of the companion publication of the 23rd international conference on World wide web companion, pages 159–162. International World Wide Web Conferences Steering Committee",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Twitter as a lifeline: Human-annotated twitter corpora for NLP of crisis-related messages",
      "author" : [ "M. Imran", "P. Mitra", "C. Castillo" ],
      "venue" : "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Cross-language domain adaptation for classifying crisis-related short messages",
      "author" : [ "M. Imran", "P. Mitra", "J. Srivastava" ],
      "venue" : "International Conference on Information Systems for Crisis Response and Management",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Speech act modeling of written asynchronous conversations with task-specific embeddings and conditional structured models",
      "author" : [ "S.R. Joty", "E. Hoque" ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "author" : [ "N. Kalchbrenner", "E. Grefenstette", "P. Blunsom" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Y. Kim" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D.P. Kingma", "J. Ba" ],
      "venue" : "CoRR, abs/1412.6980",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Fine-grained opinion mining with recurrent neural networks and word embeddings",
      "author" : [ "P. Liu", "S. Joty", "H. Meng" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2015
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "T. Mikolov", "K. Chen", "G. Corrado", "J. Dean" ],
      "venue" : "arXiv preprint arXiv:1301.3781",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 3111–3119",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Rapid classification of crisis-related data on social networks using convolutional neural networks",
      "author" : [ "D.T. Nguyen", "K.A.A. Mannai", "S. Joty", "H. Sajjad", "M. Imran", "P. Mitra" ],
      "venue" : "arXiv preprint arXiv:1608.03902",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Scikit-learn: Machine learning in Python",
      "author" : [ "F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay" ],
      "venue" : "Journal of Machine Learning Research, 12:2825–2830",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Glove: Global  vectors for word representation",
      "author" : [ "J. Pennington", "R. Socher", "C. Manning" ],
      "venue" : "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2014
    }, {
      "title" : "Summarizing situational tweets in crisis scenario",
      "author" : [ "K. Rudra", "S. Banerjee", "N. Ganguly", "P. Goyal", "M. Imran", "P. Mitra" ],
      "venue" : "Proceedings of the 27th ACM Conference on Hypertext and Social Media, pages 137–147. ACM",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Earthquake shakes twitter users: real-time event detection by social sensors",
      "author" : [ "T. Sakaki", "M. Okazaki", "Y. Matsuo" ],
      "venue" : "Proceedings of the 19th international conference on World wide web, pages 851–860. ACM",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov" ],
      "venue" : "Journal of Machine Learning Research, 15:1929–1958",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Aid is out there: Looking for help from tweets during a large scale disaster",
      "author" : [ "I. Varga", "M. Sano", "K. Torisawa", "C. Hashimoto", "K. Ohtake", "T. Kawai", "J.-H. Oh", "S. De Saeger" ],
      "venue" : "ACL (1), pages 1619–1629",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Natural language processing to the rescue? extracting\" situational awareness\" tweets during mass emergency",
      "author" : [ "S. Verma", "S. Vieweg", "W.J. Corvey", "L. Palen", "J.H. Martin", "M. Palmer", "A. Schram", "K.M. Anderson" ],
      "venue" : "ICWSM. Citeseer",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Integrating social media communications into the rapid assessment of sudden onset disasters",
      "author" : [ "S. Vieweg", "C. Castillo", "M. Imran" ],
      "venue" : "Social Informatics, pages 444–461. Springer",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "ADADELTA: an adaptive learning rate method",
      "author" : [ "M.D. Zeiler" ],
      "venue" : "CoRR, abs/1212.5701",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "However, information scarcity during time-critical situations hinders decision-making processes and delays response efforts [4, 7].",
      "startOffset" : 124,
      "endOffset" : 130
    }, {
      "referenceID" : 6,
      "context" : "However, information scarcity during time-critical situations hinders decision-making processes and delays response efforts [4, 7].",
      "startOffset" : 124,
      "endOffset" : 130
    }, {
      "referenceID" : 25,
      "context" : ", on social media platforms like Twitter [26].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 6,
      "context" : "Traditional classification approaches rely on manually engineered features like cue words and TF-IDF vectors for learning [7].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 12,
      "context" : "To this end, we use a Convolutional Neural Network (CNN), which has been shown to be effective for sentence-level classification tasks [13].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 15,
      "context" : "We can initialize L randomly or using pretrained word embedding vectors like word2vec [16].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 11,
      "context" : "We use a wide convolution [12] (as opposed to narrow), which ensures that the filters reach the entire sentence, including the boundary words.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 26,
      "context" : "Several adaptive methods such as ADADELTA [27], ADAM [14], etc.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 13,
      "context" : "Several adaptive methods such as ADADELTA [27], ADAM [14], etc.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 15,
      "context" : ", Google embeddings [16]) in the neural network model and use them as features without further task-specific tuning.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 15,
      "context" : "[16] propose two log-linear models for computing word embeddings from large (unlabeled) corpuses efficiently: (i) a bag-of-words model CBOW that predicts the current word based on the context words, and (ii) a skip-gram model that predicts surrounding words given the current word.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "com/p/word2vec/ Since we work on disaster related tweets, which are quite different from news, we have trained domain-specific embeddings of 300-dimensions (vocabulary size 20 million) using the Skip-gram model of word2vec tool [17] from a large corpus of disaster related tweets.",
      "startOffset" : 228,
      "endOffset" : 232
    }, {
      "referenceID" : 8,
      "context" : "We use CrisisNLP [9] labeled datasets.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "Of all the labeled tweets, 9k are labeled by trained volunteers during the actual event using the AIDR platform [8] and the remaining 3k tweets are labeled using the Crowdflower crowdsourcing platform.",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 5,
      "context" : "We further tokenize the tweets using the CMU TweetNLP tool [6].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 18,
      "context" : "For each time interval t, we divide the available labeled dataset into a train set (70%), dev set (10%), and a test set (20%) using ski-learn toolkit’s module [19], which ensured that the class distribution remains reasonably balanced in each subset.",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 26,
      "context" : "We train CNN models by optimizing the cross entropy in Equation 4 using the gradient-based online learning algorithm ADADELTA [27].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 22,
      "context" : "To avoid overfitting, we use dropout [23] of hidden units and early stop-",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "Recent studies have shown the usefulness of crisis-related data on social media for disaster response and management [1, 22, 24].",
      "startOffset" : 117,
      "endOffset" : 128
    }, {
      "referenceID" : 21,
      "context" : "Recent studies have shown the usefulness of crisis-related data on social media for disaster response and management [1, 22, 24].",
      "startOffset" : 117,
      "endOffset" : 128
    }, {
      "referenceID" : 23,
      "context" : "Recent studies have shown the usefulness of crisis-related data on social media for disaster response and management [1, 22, 24].",
      "startOffset" : 117,
      "endOffset" : 128
    }, {
      "referenceID" : 20,
      "context" : "A number of systems have been developed to classify, extract, and summarize [21] crisis-relevant information from social media; for a detailed survey see [7].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "A number of systems have been developed to classify, extract, and summarize [21] crisis-relevant information from social media; for a detailed survey see [7].",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 1,
      "context" : ", describe a platform for emergency situation awareness [2].",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 24,
      "context" : ", use Naive Bayes and MaxEnt classifiers to find situational awareness tweets from several crises [25].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 7,
      "context" : ", implemented AIDR to classify a Twitter data stream during crises [8].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 9,
      "context" : "In [10], the authors show the performance of a number of non-neural network classifiers trained on labeled data from past crisis events.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "DNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11].",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "DNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11].",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 17,
      "context" : "DNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11].",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 14,
      "context" : "DNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11].",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 10,
      "context" : "DNNs and word embeddings have been applied successfully to address NLP problems [5, 3, 18, 15, 11].",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 16,
      "context" : "The emergence of tools such as word2vec [17] and GloVe [20] have enabled NLP researchers to learn word embeddings efficiently and use them to train better models.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 19,
      "context" : "The emergence of tools such as word2vec [17] and GloVe [20] have enabled NLP researchers to learn word embeddings efficiently and use them to train better models.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 4,
      "context" : "[5] presented a unified DNN architecture for solving various NLP tasks including part-of-speech tagging, chunking, named entity recognition and semantic role labeling.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 12,
      "context" : "Kim [13] and Kalchbrenner et al.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "[12] used convolutional neural networks (CNN) for sentence-level classification tasks (e.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "Caragea, Silvescu, and Tapia used CNNs to identify informative messages during disasters [3].",
      "startOffset" : 89,
      "endOffset" : 92
    } ],
    "year" : 2016,
    "abstractText" : "During natural or man-made disasters, humanitarian response organizations look for useful information to support their decisionmaking processes. Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management. Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task. In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: (i) identifying informative tweets and (ii) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. We test our models using a crisis-related real-world Twitter dataset.",
    "creator" : "LaTeX with hyperref package"
  }
}