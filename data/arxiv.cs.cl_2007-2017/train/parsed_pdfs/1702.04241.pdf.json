{
  "name" : "1702.04241.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Detection of Slang Words in e-Data using semi- Supervised Learning",
    "authors" : [ "Alok Ranjan Pal", "Diganta Saha" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "DOI : 10.5121/ijaia.2013.4504 49\nin different communication mediums like internet, mobile services etc. people use few words, which are slang in nature. This approach detects those abusive words using supervised learning procedure. But in the real life scenario, the slang words are not used in complete word forms always. Most of the times, those words are used in different abbreviated forms like sounds alike forms, taboo morphemes etc. This proposed approach can detect those abbreviated forms also using semi supervised learning procedure. Using the synset and concept analysis of the text, the probability of a suspicious word to be a slang word is also evaluated.\nKeywords\nNatural Language Processing (NLP), Slang word, Suspicious word, Synset, Concept."
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "The Internet technology and the Telecommunication system have become indispensable in everyone’s life today. The obvious reason is people can share information with other around the world via e-mail, chatting, community forums, SMS etc. Through these electronic mediums people share different types of information related to study, research, business, sports, entertainment, national and international affairs etc.\nBut this technological revolution has some dark side also. While sharing the information, sometimes people use jargon words, which appear openly in different public community forums. This type of malfunctioning on web has some instant as well as long time effect on society. Few anti social communities use this medium with bad intension to spread rumor and violence. Recently, Governments of different countries are taking different steps to protect the malfunctioning over Internet and Telecommunication system, as the use of few particular words are restricted in SMS service, few selected sites are blocked and discussions on community forums are strictly monitored etc.\nThis algorithmic approach can detect the jargon words in different e-texts, if it is used as a script in a data handling procedure and the e-texts are passed through this script before submission on the web or any network.\nOrganization of rest of the paper is as follows: Section 2 is about motivation of our paper; Section 3 describes the background; Section 4 depicts the proposed approach in detail; Section 5 depicts experimental results; Section 6 represents conclusion of the paper."
    }, {
      "heading" : "2. MOTIVATION",
      "text" : "Recently, to stop this malfunctioning Governments of different countries are taking different effective steps. In Pakistan, use of around 1700 specific words on any kind of communication medium is strictly prohibited. In USA, CHINA and few countries access of few web sites are restricted. Most recently, Government of India has warned few community sites to monitor the data shared through their systems.\nThis proposed algorithm can filter the abusive words as well as suspicious word forms in an e-text when those are shared on a medium"
    }, {
      "heading" : "3. BACKGROUND",
      "text" : "Natural Language Processing (NLP) [1] is one of the challenging tasks in recent day’s research field. Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc. These research works greatly depend on some knowledge driven methods [8]. WordNet [2, 18, 20] is a knowledge source, which is used greatly in different knowledge based research works. The key features of this knowledge base are, it is machine readable and in this knowledge base the words are arranged semantically instead of alphabetically. The words of symmetric sense create a group, called synset and each synset represents a particular sense, called concept [19].This semantic architecture of words play a vital role in different knowledge based research works of NLP like Automatic Summarisation, ELearning [3], Automatic Medical Diagnosis etc.\nOur approach adopts the idea of resolution of sense of a word from a given text."
    }, {
      "heading" : "4. PROPOSED APPROACH",
      "text" : "This algorithmic approach handles the slang words in four ways. First, using supervised learning methodology the jargon words of complete word form are detected by the help of an initially populated jargon word Database (Figure 10).\nAn additional job is performed in this stage. Using the synset analysis, the context of the discussion (concept) [19] is evaluated.\nSecondly, the jargon words, which are used in some abbreviated forms but sound like a jargon word, are detected by the help of a sounds-alike jargon word Database (Figure 11).\nThirdly, the algorithm deals with those words, which are suspicious in nature to be a jargon word (Figure 5). Using a sliding window mechanism the partially matched jargon words are detected and stored in a temporary Database with a counter value (Figure 13) for further verification.\nFinally, the suspicious words are verified by the help of synset and concept analysis as they can be used for further decision making.\nThe proposed approach is described below using modular representation:\nAlgorithm 1: The over all procedure is described in Figure 1, where each module performs a particular task. In module 1, the barely appeared words are detected using supervised learning. In module 2, the sounds-alike abbreviated forms of slang words are detected. The suspicious words are detected in Module 4 and the probability analysis for a suspicious word to be a jargon word is handled in Module 3.\nInput: Input text. Output: Text to be submitted.\n1. Stop words are eliminated from the input text. 2. Text, with only meaningful words, is created. 3. This text is passed to\na. Module 1 for detecting the slang words. b. Module 3 for deriving the concept from the text.\n4. Text, without completely matched slang words, is obtained from Module 1. 5. The text from Module 1 is passed to Module 2, where the sounds-alike slang words\nare checked.\n6. The text from Module 2 is passed to Module 4, where the occurrence of any suspicious word is checked.\nIf any suspicious word is found in the text, it is passed to Module 3, where the learning set is enriched.\n7. Text, without any slang or suspicious word is derived for further use. 8. Stop.\nModule 1: Algorithm 2: This algorithm detects the barely appeared jargon words using supervised learning. A hand tagged Database of slang words is considered (Figure 2) as a learning set. The Time Complexity of the algorithm is O(n 2 ). Complexity of picking up the n number of words from the text is of O(n) and checking the each word with the entries of the Database is O(n).\nInput: Text, containing only meaningful words. Output: Text, without slang words.\n1. Repeat steps 2, 3 and 4 for each word of the text. 2. A word from the text is taken. 3. The word is matched with each entry of the slang word Database. 4. If the word is matched with any entry, the algorithm stops proceeding and Exit.\nElse: Goto step1 loop.\n5. Stop.\nModule 2: Algorithm 3: This algorithm detects the sounds-alike abbreviated forms of slang words using a Database (Figure 3) of related entries. The Time Complexity of the algorithm is O(n 2 ), derived in the same way as in Module 1: Algorithm 2.\nInput: Text, free from completely matched slang words. Output: Text, without slang words.\n1. Repeat steps 2, 3 and 4 for each word of the text. 2. A word is taken from the text. 3. The word is matched with each entry of the sounds-alike slang word Database.\n4. If the word is matched with any entry,\nA message displays the actual slang word, which must be changed to proceed and Exit.\nModule 4: Algorithm 5: This algorithm finds the words, which are suspicious in nature to be a jargon word (Figure 4) using sliding window mechanism. If any word partially matches with a jargon word, that word is treated as a suspicious word. The Time Complexity of the algorithm is O(n 2 ) due to the nesting of operations at Step 1 and Step 4.\nInput: Text, without slang word. Output: a) Text, which can be used for proceeding and\nb) List of Suspicious words.\n1. Repeat step 2, 3 and 4 for each word of the input text. 2. A word is taken. 3. A character window (Figure 5) of some fixed length is taken and set at the\nbeginning of the word.\n4. Repeat step 5 till the window lies within the word length. 5. If the window is matched with any part of the slang words,\nA message, mentioning the suspicious word is displayed and waits for confirmation to proceed.\nIf the user confirms the suspicious word as a slang word,\nthe word is stored in slang word Database directly and exit.\nElse,\nThe suspicious word is passed to module 3 for enriching the learning set.\nElse,\nThe window is shifted right by one character.\n6. The text is displayed. 7. Stop.\nModule 3: Algorithm 4: This algorithm evaluates the probability of a suspicious word to be a jargon word by the help of a learning set (Figure 6), which increases the efficiency of the jargon word detection procedure. The maximum Time Complexity of the algorithm is O(n 2 ), which is evaluated at step 1.\nInput: a) Text, containing the only meaningful words from the input text and\nb) Suspicious words from module 4.\nOutput: Slang words would be stored in slang word Database (Module 1).\n1. Intersection (Figure 6) is performed between the words of the input text and the different synsets. 2. The concept is derived from the highest value of intersection. 3. Some predefined weight is assigned to the derived concept. 4. Suspicious words from Module 4 are stored in a Database with some counter. 5. Repeat steps 6, 7 and 8 for each suspicious word. 6. The counter value of a suspicious word is taken. 7. The counter value is updated by the weight, assigned for the concept. 8. If the counter value of a suspicious word crosses some thresh hold value,\nthe suspicious word is treated as a slang word and is stored in slang word Database (Module 1) for further decision making.\n9. Stop."
    }, {
      "heading" : "5. OUTPUT AND DISCUSSION",
      "text" : "The experiment was started with a data set of commonly used slang words (Figure 7) and a table, consists of different synsets and the related concepts (Figure 8). A weight is assigned to each concept from real life experience (\"assgval\" in Figure 8), which is used further for learning mechanism. For experiment few Greek words are considered as slang words\nIn Figure 9, the input text proceeds further as there is no jargon word in the input text.\nFigure 10 depicts the existence of few slang words in an input text.\nFigure 11 depicts the detection of sounds-alike abbreviated forms of different slang words in a text.\nFigure 12 depicts the detection suspicious words in an input text.\nIf the user accepts a suspicious words as a jargon word, the suspicious words are stored in the jargon word Database for further decision making. Otherwise, the suspicious words are stored in a temporary Database with some counter (\"JCount\" in Figure 13) for further verification. Counter denotes the frequency of occurrence of that suspicious word in different contexts.\nNow, the learning ability of the algorithm is discussed with example. Figure 8 depicts concept analysis of a discussion. The different synsets and associated concepts are formulated for experiment. From our real life observation, it is obvious that the probability of a suspicious word, to be a slang word, is changed according to different contexts. In the “assgval” column, these different values are stored from real life experience.\nIn figure 12, the context of the discussion is derived as “Movie”. So, the suspicious words were stored in to the temporary Database (Figure 13), with the pre-assigned weight 10 (column \"JValue\" in Figure 13).\nThen another text is considered, which is related to “Sports” and the suspicious words are stored into the temporary Database with pre-assigned weight 7 (Figure 14).\nIf any suspicious word is used repeatedly in different contexts, the associated \"JValue\" would be increased (Figure 14). If the \"JValue\" of any particular suspicious word crosses some threshold value, that suspicious word would be treated as a slang word and that would be stored in the jargon word Database (Figure 15) as those words can participate in decision making from the next time. Experimentally, threshold value is taken 50 in this case.\nIn this way, as much as the algorithm is trained by different input texts of different contexts, the jargon word Database becomes stronger. The \"assgval\" and all other user assigned values are considered from the real life observation and those values may vary situation wise"
    }, {
      "heading" : "6. CONCLUSION AND FUTURE WORK",
      "text" : "This algorithm detects the barely appeared jargon words, different abbreviated forms of jargon words and suspicious words from an e-text, which is used in any open medium. If the learning mechanism is handled with proper synset and probability analysis, the algorithm can solve a big problem of recent day.\nBut, in some cases like medical field, judicial system etc. few words are used, which are considered as jargon words in our normal life. These situations should be considered as exceptional cases"
    } ],
    "references" : [ {
      "title" : "Computational Processing of Natural Language: Tasks, Problems and Solutions",
      "author" : [ "A. Gelbukh" ],
      "venue" : "Congreso Internacional de Computacion en Mexico D.F",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "WordNet: A Lexical Database",
      "author" : [ "Miller", "A. George" ],
      "venue" : "Comm. ACM, Vol.38,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1993
    }, {
      "title" : "Dataintensive Question Answering",
      "author" : [ "E. Brill", "J. Lin", "M. Banko", "S. Dumais", "A. Ng" ],
      "venue" : "Proc. of the Tenth Text Retrieval Conference",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2001
    }, {
      "title" : "Internet, a true friend of translator",
      "author" : [ "A. Gelbukh", "I.A" ],
      "venue" : "Bolshakov,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "Internet, a true friend of translator\", the Google wildcard operator",
      "author" : [ "A. Gelbukh", "I.A. Bolshakov" ],
      "venue" : "International Journal of Translation,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2006
    }, {
      "title" : "A Portrait of the Semantic Web in Action",
      "author" : [ "J. Heflin", "J. Hendler" ],
      "venue" : "IEEE Intelligent Systems,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2001
    }, {
      "title" : "Providing Muchine Tractablle Dictionan Tools",
      "author" : [ "Y. Wilks", "D. Fass", "C. Guo", "J. McDonal", "T. Plate", "B. Slator" ],
      "venue" : "In Semantics and the lexicon (Pustejowsky J. Ed.)",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1993
    }, {
      "title" : "An adapted Lesk algorithm for word sense disambiguation using WordNet",
      "author" : [ "S. Banerjee", "T. Pedersen" ],
      "venue" : "In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics, Mexico City",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine conefrom an ice cream cone\", Roc",
      "author" : [ "M. Lesk" ],
      "venue" : "SIGDOC Conference,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1986
    }, {
      "title" : "Associative Anaphora Resolution: A Web-Based Approach",
      "author" : [ "R. Bunescu" ],
      "venue" : "Proc. of the EACL-2003 Workshop on the Computational Treatment of Anaphora,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2003
    }, {
      "title" : "Synonymous Paraphrasing Using WordNet and Internet",
      "author" : [ "I.A. Bolshakov", "A. Gelbukh" ],
      "venue" : "Lecture Notes in Computer Science N 3136,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2004
    }, {
      "title" : "Detection and Correction of Malapropisms in Spanish by means of Internet Search",
      "author" : [ "I.A. Bolshakov", "S.N. Galicia-Haro", "A. Gelbukh" ],
      "venue" : "Lecture Notes in Artificial Intelligence N 3658,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "Various Criteria of Collocation Cohesion in Internet: Comparison of Resolving Power",
      "author" : [ "I.A. Bolshakov", "E.I. Bolshakova", "Kotlyarov A.P", "Gelbukh A" ],
      "venue" : "CICLing",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Natural Language modeling for phoneme-to-text transposition",
      "author" : [ "A.M. Deroualt", "B. Merialdo" ],
      "venue" : "IEEE transactions on Pattern Analysis and Machine Intelligence",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1986
    }, {
      "title" : "A maximum entropy Part-of-speech tagger",
      "author" : [ "A. Ratnaparkhi" ],
      "venue" : "Proceedings of the Empirical Methods in NLP conference,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1996
    }, {
      "title" : "A New Approach to Word Sense Disambiguation Based on Context Similarity",
      "author" : [ "M. Nameh", "S.M. Fakhrahmad", "M. Zolghadri Jahromi" ],
      "venue" : "Proceedings of the World Congress on Engineering",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "A Keyword Selection Method Based on Lexical Chains",
      "author" : [ "SUO Hong-Guang", "LIU Yu-Shu", "CAO Shu", "CAO Shu-Ying" ],
      "venue" : "Journal of Chinese Information Processing\",",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    }, {
      "title" : "Applying Word Sense Disambiguation to Question Answering System for E-Learning",
      "author" : [ "Jason C. Hung", "Ching-Sheng Wang", "Che-Yu Yang", "Mao-Shuen Chiu", "George YEE" ],
      "venue" : "Proceedings of the 19th Inter. Conf.on Advance Information Networking and Applications",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2005
    }, {
      "title" : "WordNet An on-line lexical database\", International Journal of Lexicography, 3(4):235-244",
      "author" : [ "G.A. Miller", "R. Beckwith", "C. Fellbaum", "D. Gross", "Miller K. J" ],
      "venue" : "International Journal of Artificial Intelligence & Applications (IJAIA),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1990
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Natural Language Processing (NLP) [1] is one of the challenging tasks in recent day’s research field.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 3,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 162,
      "endOffset" : 171
    }, {
      "referenceID" : 4,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 162,
      "endOffset" : 171
    }, {
      "referenceID" : 7,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 199,
      "endOffset" : 210
    }, {
      "referenceID" : 8,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 199,
      "endOffset" : 210
    }, {
      "referenceID" : 15,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 199,
      "endOffset" : 210
    }, {
      "referenceID" : 13,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 235,
      "endOffset" : 243
    }, {
      "referenceID" : 14,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 235,
      "endOffset" : 243
    }, {
      "referenceID" : 9,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 265,
      "endOffset" : 269
    }, {
      "referenceID" : 10,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 284,
      "endOffset" : 288
    }, {
      "referenceID" : 11,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 302,
      "endOffset" : 306
    }, {
      "referenceID" : 12,
      "context" : "Many research works are carried out in different sub-domains of NLP, as Information Retrieval (IR), Automated Classification [7], Language Translation by Machine [4, 5, 6], Word Sense Disambiguation [9, 10, 17], Part of speech Tagging [15, 16], Anaphora Resolution [11], Paraphrasing [12], Malapropism [13], Collocation Testing [14] etc.",
      "startOffset" : 328,
      "endOffset" : 332
    }, {
      "referenceID" : 6,
      "context" : "These research works greatly depend on some knowledge driven methods [8].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 1,
      "context" : "WordNet [2, 18, 20] is a knowledge source, which is used greatly in different knowledge based research works.",
      "startOffset" : 8,
      "endOffset" : 19
    }, {
      "referenceID" : 16,
      "context" : "WordNet [2, 18, 20] is a knowledge source, which is used greatly in different knowledge based research works.",
      "startOffset" : 8,
      "endOffset" : 19
    }, {
      "referenceID" : 18,
      "context" : "WordNet [2, 18, 20] is a knowledge source, which is used greatly in different knowledge based research works.",
      "startOffset" : 8,
      "endOffset" : 19
    }, {
      "referenceID" : 17,
      "context" : "The words of symmetric sense create a group, called synset and each synset represents a particular sense, called concept [19].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "This semantic architecture of words play a vital role in different knowledge based research works of NLP like Automatic Summarisation, ELearning [3], Automatic Medical Diagnosis etc.",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 17,
      "context" : "Using the synset analysis, the context of the discussion (concept) [19] is evaluated.",
      "startOffset" : 67,
      "endOffset" : 71
    } ],
    "year" : 2013,
    "abstractText" : "The proposed algorithmic approach deals with finding the sense of a word in an electronic data. Now a day, in different communication mediums like internet, mobile services etc. people use few words, which are slang in nature. This approach detects those abusive words using supervised learning procedure. But in the real life scenario, the slang words are not used in complete word forms always. Most of the times, those words are used in different abbreviated forms like sounds alike forms, taboo morphemes etc. This proposed approach can detect those abbreviated forms also using semi supervised learning procedure. Using the synset and concept analysis of the text, the probability of a suspicious word to be a slang word is also evaluated.",
    "creator" : "PScript5.dll Version 5.2.2"
  }
}