{
  "name" : "1301.3871.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Combinatorial Optimization by Learning and Simulation of Bayesian Networks",
    "authors" : [ "Pedro Larraiiaga", "Ramon Etxeberria", "Jose A. Lozano", "Jose M. Peiia" ],
    "emails" : [ "ccplamup@si.ehu.es,", "ramon@edunet.com,", "lozano@si.ehu.es,", "ccbpepaj@si.ehu.es" ],
    "sections" : [ {
      "heading" : null,
      "text" : "This paper shows how the Bayesian network paradigm can be used in order to solve com binatorial optimization problems. To do it some methods of structure learning from data and simulation of Bayesian networks are in serted inside Estimation of Distribution Al gorithms (EDA). EDA are a new tool for evo lutionary computation in which populations of individuals are created by estimation and simulation of the joint probability distribu tion of the selected individuals. We propose new approaches to EDA for combinatorial op timization based on the theory of probabilis tic graphical models. Experimental results are also presented.\n1 Introduction\nRoughly speaking, search strategies can be classified as complete or heuristic strategies. The underlying idea in the complete search is the systematic examination of all the possible points of the search space. On the other hand, heuristic algorithms can be classified as deter ministic or non-deterministic. In deterministic heuris tic strategies the same solution is always achieved un der the same conditions. Non-deterministic search is motivated by trying to avoid getting stuck in local maximum. Randomness is used to escape from local maximum and, due to its stochasticity, different runs might lead us to achieve different solutions under the same conditions. While some of the stochastic heuris tic strategies (e.g., simulated annealing) store only one solution in each iteration of the algorithm, in other approaches -evolutionary computation- the search is based on a population of individuals (each of which represent a point of the search space). This population evolves as the algorithm proceeds toward more promis ing zones of the space of solutions. Examples of evolu-\ntionary computation are genetic algorithms, evolution ary strategies, evolutionary programming and genetic programming.\nThe behavior of the addressed evolutionary computa tion algorithms depends on several parameters associ ated with them (operators of crossing and mutation, probabilities of crossing and mutation, size of the pop ulation, rate of generational reproduction, number of generations, ... ). If the researcher does not have ex perience in the resolution of a concrete optimization problem by means of this type of approach, the choice of the suitable values for all the parameters is itself converted into an optimization problem. This reason, together with the fact that the prediction of the move ments of the populations in the search space is ex tremely difficult, has motivated the birth of a type of algorithms denominated Estimation of Distribution Algorithms (EDA) (Miihlenbein and PaaB 1996).\nIn EDA there are neither crossover nor mutation oper ators and, instead, the new population of individuals is sampled from the probability distribution, which is estimated from the database containing only selected individuals from the previous generation. Whereas in the heuristics coming from evolutionary computation, the interrelations between the different variables rep resenting the individuals are kept in mind implicitly building block hypothesis-, in EDA, the interrelations are expressed in an explicit way through the joint prob ability distribution associated with the individuals se lected in each iteration. In fact, the estimation of the joint probability distribution associated with the data base containing the selected individuals constitutes the bottleneck of this new heuristic.\nThe fundamental objective of this work is to propose new EDA for combinatorial optimization problems. These new algorithms are based on three different ap proaches to the structure learning of Bayesian net works: (i) detecting conditional independencies, (ii) penalized maximum likelihood, and (iii) Bayesian ap proach.\n344 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nThe outline of this work is as follows. Section 2 in troduces the EDA approach, classifying the different methods found in the literature according to the com plexity of the probabilistic model used. In Section 3 a brief presentation of the different approaches to struc ture learning and simulation of Bayesian networks is done. In Section 4 we present new approaches to com binatorial optimization based on induction and simu lation of Bayesian networks, while in Section 5 we show some experimental results. Section 6 picks up the con clusions of our work and some notes about possible future lines of research.\n2 Estimation of Distribution Algorithms\n2.1 Introduction\nThe poor behavior of genetic algorithms in some prob lems -deceptive problems- in which the designed op erators of crossing and mutation do not guarantee the preservation of the building block hypothesis have led to the development of other type of algorithms.\nThese referred algorithms are known as Estimation of Distribution Algorithms (EDA). EDA are population based search algorithms that use probabilistic mod eling of promissing solutions in combination with the simulation of the induced models to guide their search.\nThe underlying idea of EDA is introduced starting from a problem that arises in the supervised clasifi cation and that it is known as feature subset selec tion (FSS) -see Inza et al. (1999)-. Given a file of cases with information on n predictive variables, X1, X2, . .. , Xn and the class variable C to which the case belongs, the problem consists of selecting a subset of variables that will induce a classifier with the high est predictive capacity in a test set. The cardinality of the search space is 2n.\nFigure 1 shows an schematic of the EDA approach. In the first step N individuals are generated at random, for example, based on an uniform distribution on each variable. These N individuals constitute the initial population, D0, and each of them is evaluated. In a second step, a number Se (Se < N) of individuals are selected (usually those with the higher objective func tion value). Next, the induction of the n-dimensional probabilistic model that best reflects the interdepen dences between the n variables is carried out. In a fourth step, N new individuals (the new population) are obtained by means of the simulation of the prob ability distribution learnt in the previous step. Steps 2, 3 and 4 are repeated until a stopping condition is verified.\nLet us introduce a general notation that will be used to express a pseudocode of EDA in combinatorial op timization problems.\nWe use X;, i = 1, ... , n, to represent a random vari able. A possible instantiation of X; is denoted x;. p(X; = x;) (or simply p(x;)) represents the mass prob ability for the variable X; over the point x;. Simi larly, we use X = (X1, ... , Xn) to represent an n dimensional random variable and x = (x1, ... , xn) to represent one of its possible instantiations. The joint probability mass of X is denoted p(X = x) (or simply p(x)). The conditional mass probability of the variable X; given the value Xj of the variable Xj is represented as p(X; = x;!Xj = Xj) (or simply by p(x;ixj)). We will use D to represent a data set, i.e., a set of N instantiations of the variables (X1 , ... , Xn)·\nConnecting this notation with the one we need to ex press the pseudocode of EDA -see Figure 2-, x = (x1, ... , Xn) will denote individuals of n genes, and D1 will denote the population of N individuals in gen eration l. Similarly, Dfe will represent the popula tion of the selected Se individuals from D1• In EDA our interest will be to estimate p(x 1 nse), that is, the joint mass probability over one individual x being among the selected individuals. This joint probability mass must be estimated in each generation. We de note the joint probability mass of the l-th generation as Pt(x) = Pt(x I Df_:l).\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 345\nr--i\"E\"\"D\"A---------------------, 2.2.2 Pairwise dependencies Do f-- Generate N individuals (the initial population) randomly Repeat for l = 1, 2, . . . until a stopping criterion is met The estimation of the joint probability distribution can\nDf_:1 f-- Select Se � N individuals from D1-1 according to a selection method also be done quickly only taking dependencies between PI(\"')= p(..,IDf_:1) f-- Estimate the probability distribution pairs of variables into account -see Figure 3. On the of an individual being among the selected individuals other hand, where in the algorithms of the previous D1 f-- Sample N individuals (the new population) from PI(\"')\nL_ _____________________ _J subsection only a learning of the parameters was car-\nFigure 2: Pseudocode for EDA approach\nThe aim of this new paradigm is to try to detect the interdependences between the variables that represent one point in the search space. The basic idea consists of inducing probabilistic models from the best individ uals found. Afterwards the models are sampled gen erating new solutions, which are used to update the model. This cycle is repeated until a stopping crite rion is verified. The main problem of EDA lies on how the probability distribution p1 (x) is estimated. Obvi ously, the computation of all the parameters needed to specify the probability model is impractical. This has led to several approximations where the probabil ity distribution is assumed to factorize according to a probability model.\n2.2 Proposed EDA in combinatorial optimization\nIn this subsection a revision of the EDA approaches found in the literature for combinatorial optimization problems will be carried out. See Larraiiaga et a!. (1999a, 1999b) for a more detailed revision.\n2.2.1 Without interdependencies\nIn all the works belonging to this category it is as sumed that the n-dimensional joint probability dis tribution factorizes as a product of n univariate and independent probability distributions. That is PL(x) = IT�=1 PL(xi)· Obviously this assumption is very far from what happens in a difficult optimization problem where the interdependencies between the variables will exist in some degree.\nApproaches in this category include the following ones: Bit-Based Simulated Crossover (BSC) (Syswerda 1993), Population-Based Incremental Learning (PBIL) (Baluja 1994), the compact Genetic Algorithm (eGA) (Harik et a!. 1998), and the Univariate Marginal Dis tribution Algorithm (UMDA) (Miihlenbein 1998).\nIn the Univariate Marginal Distribution Algorithm (UMDA) (Miihlenbein 1998) PL(xi) is estimated from the relative marginal frequencies of the i-th variable of the selected individuals Df_!\\.\nried out -the structure of the model remained fixed in this subsection, the parametric learning is extended to structural.\nIn De Bonet et a!. (1997) a greedy algorithm called MIMIC (Mutual Information Maximization for Input Clustering) is developed. MIMIC searches for the best permutation between the variables in order to find the probability distribution belonging to the class P tr ( x), where:\nP1r(x) = {Ptr(x) I Ptr(x) =\nP(Xi1 I Xi2) · p(Xi2 I Xi3) .. · p(xin-1 I XiJ · p(xin)}, (1) that is closest with respect to the Kullback-Leibler dis tance to the set of selected points. It is easy to prove that the agreement between two probability distribu tions, p(x) and Ptr(x), being Ptr(x) E P1r(x), mea sured by its Kullback-Leibler divergence is a function of Htr(x) = h(Xd + 2:.7::1\n1 h(Xij I xii+1), where h(Xii I Xii+1) denotes the mutual information be tween the variables Xij and Xii+1, and h(Xin) is the entropy of the variable Xin. Applying this result, the problem of searching for the best Ptr(x) E P1r(x) is equivalent to searching for the permutation, 1r*, of the n variables minimizing H1r(x). To find 7r* the authors propose a straightforward greedy algorithm avoiding searching through all n! permutations. The idea is to select Xin as the variable with the smallest estimated entropy and, afterwards, at every step, to pick up the variable -from the set of variables not chosen so far whose average conditional entropy with respect to the previous is the smallest.\nAnother approaches in this group are the proposed by Baluja and Davies (1997) and the BMDA (Bivari ate Marginal Distribution Algorithm) of Pelikan and Miihlenbein (1999).\n2.2.3 Multiply interdependencies\nSeveral approaches to EDA have been proposed in the literature in which the factorization of the joint proba bility distribution requires of statistics of order greater than two -see Figure 4.\nIn the work of Miihlenbein et a!. (1999) the FDA (Fac torized Distribution Algorithm) is introduced. This algorithm applies to additively decomposed functions for which, using the running intersection property, a factorization of the mass-probability based on residu als and separators is obtained.\n346 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nThe work of Etxeberria and Larraiiaga (1999) is the first published paper in which a factorization of the joint probability distribution encoded by a Bayesian network is learnt from the database containing the se lected individuals in each generation. The algorithm developed is called EBNA (Estimation of Bayesian Networks Algorithm) and makes use of the BIC ap proach applied to the Bayesian quality together with greedy algorithms to perform the search in the space of models.\nIn BOA (Bayesian Optimization Algorithm), proposed by Pelikan et al. (1999), a Bayesian metric, BDe, to measure the goodness of every structure found and a greedy search procedure are used. The search begins at each generation from scratch.\nMiihlenbein and Mahnig (1999) introduce the LFDA (Learning Factorized Distribution Algorithm) which essentially follows the same approach as in EBNA.\nHarik (1999) presents an algorithm -Extend compact Genetic Algorithm (EcGA)- whose basic idea consists of factorizing the joint probability distribution in a product of marginal distributions of variable size.\n3 Structure learning and simulation in Bayesian networks\n3.1 Introduction\nBayesian networks have been surrounded by a growing interest in the recent years, shown by the large num ber of dedicated books and a wide range of theoretical and practical publications in this field. Textbooks in clude the following ones: Pearl (1988), Jensen (1996)\nFDA EBNA.BOA\n,.··o· ··-.... ·· -. /00\\:Q·· .. . ·· o ·\n'···--;.::6:6 :,-) coo/ .... - �'\nEcGA\nFigure 4: Graphical representation of proposed EDA in combinatorial optimization with multiply depen dencies (FDA, EBNA, BOA and EcGA)\nand Castillo et al. (1997). More recently Cowell et al. (1999) provides an excellent compilation material covering recent advances in the field.\nLet X = (X1, ... , Xn) be a set of random variables. We will use Xi to denote a value of Xi, the i-th compo nent of X, andy = (xi)x,EY to denote a value ofY � X. A probabilistic graphical model for X is a graph ical factorization of the joint generalized probability density function, p(X = x) (or simply p(x)). The representation consists of two components: a structure and a set of local generalized probability densities. The structure S for X is a directed acyclic graph (DAG) that represents a set of conditional independences1 as sertions on the variables on X. The structure S for X represents the assertions that xi and its non descendents are independent given Paf 2, i = 2, ... , n. Thus, the factorization is as follows:\nn p(x) =p(xl, . . . , xn) = IJp(xi lpaf). (2)\ni=l\nThe local generalized probability densities associated with the probabilistic graphical model are precisely those in the previous equation.\nIn this paper, we assume that the local generalized probability densities depend on a finite set of parame ters Bs E EJs. Thus, we rewrite the previous equation as follows:\nn p(x I Os) = IT p(xi I paf, Oi) (3)\ni=l\n1 Given Y, Z, W three disjoints sets of variables, we said that Y is conditionally independent of Z given W if for any y, z, w we have p(y I z, w) = p(y I w).\n2 Paf represents the set of parents -variables from which an arrow is coming out- of the variable X; in the probabilistic graphical model with structure given by S.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 347\nwhere Os = (01, ... , On). Taking both components of the probabilistic graphical model into account, this will be represented by M = (S, Os).\nIn the particular case of every variable X; E X be ing discrete, the probabilistic graphical model will be called Bayesian network. If the variable X; has r; possible values, x�, . . . , x�', the local distribution, p(x; I pa{'8, 0;) is an unrestricted discrete distribution:\n( k I j,S (} ) - () - () p X; pai ' i - x71Pa{ = ijk (4)\nwhere pai'8, . .. , pa{' ,s denotes the values of Paf, the set of parents of the variable X; in the structure S. The number q; denotes the number of possible differ ent instantiations of the parent variables of X;. Thus, q; = I1xuEPa, r9. The local parameters are given by 0; = ((Bijk)��1)j�1). In others words, the parameter ()ijk represent the conditional probability of variable X; being in its k-th value, given that the set of its parent variables is in its j-th value. We assume that each parameter ()ijk is greater than zero.\n3.2 Structure learning\nOnce the Bayesian network is built, it constitutes an efficient device to perform probabilistic inference. Nevertheless, the problem of building such a network remains. The structure and conditional probabili ties necessary for characterizing the Bayesian network can be provided either externally by experts -time consuming and subject to mistakes- or by automatic learning from a database of cases. On the other hand, the learning task can be separated into two subtasks: structure learning, that is, to identify the topology of the Bayesian network, and parametric learning, the numerical parameters (conditional probabilities) for a given network topology.\nThe different approaches to Bayesian network model induction can be classified from a double perspec tive. Firstly, we take the complexity of the learnt model into account (tree, polytree or multiply con nected). Secondly, we can consider the nature of the modeling (detecting conditional independencies versus score+search).\nThe reader can consult some good reviews about model induction in Bayesian networks in Heckerman (1995) and Buntine (1996).\n3.3 Simulation\nA good number of methods for the simulation of Bayesian networks have been developed during the last years. In this paper, we will use the method Probabilis tic Logic Sampling (PLS) proposed by Henrion (1988).\nIn this method the instantiations are generated one variable at a time in a forward way, that is, a variable is sampled after all its parents have already been sam pled. Thus, variables must be ordered in such a way that the values for Pa; must be assigned before X; is sampled. An ordering of the variables satisfying such property is called an ancestral ordering. Once the val ues of Pa; have been assigned, we simulate a value for X; using the distribution p(xrr(i)IPa;). Figure 5 shows a pseudocode of the method.\n4 New approaches to combinatorial optimization based on learning and\nsimulation of Bayesian networks\nIn this section three different apl?roaches to combina torial optimi�ation based on the learning and simula tion of Bayesian networks will be introduced.\n4.1 Detecting conditional independencies EBNApc\nAmong the many methods for recovering Bayesian networks by means of detecting conditional indepen dencies, we will use the PC algorithm (Spirtes et al. 1991) in order to obtain the structure which best fits p(x1Df,:1). The PC algorithm starts by forming the complete undirected graph and then it tries to \"thin\" it. First, edges with zero order conditional indepen dence relations are removed, then edges with first order conditional independence relations, and so on. In or der to check the conditional independencies Chi square tests (a = 0.01) will be performed.\n4.2 Penalized maximum likelihood EBN ABle This approach corresponds to that developed by Etxe berria and Larraiiaga (1999). In their paper, the score used to evaluate the goodness of each structure found during the search is the penalized maximum likelihood. In particular, they propose the use of the Bayesian In formation Criterion (BIC) (Schwarz 1978).\nThis means that to evaluate a Bayesian network struc ture S, from a database D containing N cases, its cor-\n348 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nresponding BIC score, denoted BIC(S, D), is as fol lows:\nBIC(S, D) =\nn � � N··k logN � L L...- L...- Nijk log ;/. - -2- L...- (ri- 1)qi i=l j=l k=l t) i=l where Nijk and Nii and qi are defined as above. (5)\nThe quantitative part of the Bayesian network, that is, the parameters of the local probability distributions, are calculated every generation using their expected values as obtained by Cooper and Herskovits (1992):"
    }, {
      "heading" : "Niik + 1 E[Bijk I S, D] = N . ij + Ti",
      "text" : "(6)\nUnfortunately, finding the best model requires search ing through all possible structures, which has been proved to be NP-hard (Chickering et a!. 1994). Al though promising results have been obtained using global search techniques (Larrafiaga et al. 1996a, 1996b and Etxeberria et al. 1997a, 1997b, Myers et al. 1999), their computation cost makes them unfea sible for our problem. We need to find a model good enough as quickly as possible, so a simple algorithm which returns a good structure, even if it is not opti mal, is preferred. An interesting algorithm with these characteristics is the Algorithm B (Buntine 1991). The Algorithm B is a greedy search heuristic which starts with an arc-less structure and, at each step it adds the arc with the maximum improvement in the BIC approximation (or whatever measure is used). The al gorithm stops when adding an arc would not increase the scoring measure used.\nAnother possibility to find good models in a fast way consists in the use of local search strategies. Start ing with a given structure, at every step the addition or deletion of an arc with the maximum increase in the scoring measure is performed. Local search strate gies stop when no modification of the structure im proves the scoring measure. The main drawback of\nlocal search strategies is that they heavily depend on the initial structure. Hovewer, Chickering et a!. (1995) reported that local search strategies perform quite well when the initial structure is reasonably good. More over, if we base our search on the assumption that p(xiDfe) will not differ very much from p(x1Df�1), the model found in the previous generation could be used as the initial one for the current generation.\nIn the initial model -see Figure 6-, M0, the struc ture So is the DAG without arcs at all and the local probability distributions are those given by the n uni dimensional marginal probabilities p(X i = Xi) = -!:;, i = 1, . . . , n. This means that M0 assigns the same probability to all individuals. The learning of M1 is done by using the Algorithm B, while the rest of the models are learnt by means of local search. This local search start with the model obtained in the previous generation.\n4.3 Penalized marginal likelihood\nEBNAK2+pen\nIn this approach we propose to combine the Bayesian approach to calculate the marginal likelihood intro duced by Cooper and Herskovits (1992) in addition with a penalizing term introduced to avoid a more complex Bayesian network. Thus, we propose to search for the Bayesian network structure S that max imizes the expression:\nlogp(D I S)- f(N) dim(S). (7)\nUsing the K2 metric for calculate logp(D I S), the expression we want to maximize is:\nAlthough we are aware of the implicit penalization of complex structures that the Bayesian approach in volves, we understand that the addition of a explicit penalization term to the metric derived by Cooper and Herskovits (1992) might be of interest in this new framework.\nTo carry out such a purpose, we use a theorem proved by Etxeberria et al. (1997a) which bounds the number of parent nodes in the Bayesian network with the best score for each variable. The application of the theorem allows us to reduce the search space and, above all, to determine the maximum number of parents in the op timal learnt Bayesian network for each variable. The\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 349\nimprovement of the approach we propose here is con cerned with the fact that the bound for the cardinality of the parent set is obtained in an automatic way and can be different for each variable of the domain. Our approach is based on the following theorem:\nTheorem 1 (Etxeberria et al., 1997a) Let X = (X1, . . . , Xn) an n-dimensional variable. Let ri be the number of values that an unidimensional variable Xi can have, with i = 1, . . . , n. Let D be a database with N cases over X. Consider the variable Xi. Let m, l E N where l < ri and N =rim+ l. Let pa E N where\npa+l n-l II r'--J II I rj j=l j=n-pa\n1 I [N!h + l- 1)! ( (2ri -1)!) m] > (ri- 1) f(N) og (N + ri- 1)! (ri-1)!\n(9) r�, . .. r�_1 being r1, ... , ri-1, ri+l, . . . , rn sort in as cending order. Then, the variable Xi will not have more than pa parent nodes in the network structure which maximizes:\nmore than 5 parent nodes in the structure which . . I [Tin Tiq' (r,-1)! Tin N '] maximizes og i=l j=l (N•;+r•-1)! k=l ijk· - f(N) 2::7=1 (ri- 1)qi. The experimental results presented by Etxeberria et al. (1997a) show that the application of this score to the structure learning of Bayesian networks reduces the complexity without affecting the quality of the learnt models.\n5 Experimental results\n5.1 Introduction\nIn order to measure the performance of the new proposed algorithms, EBN Ape, EBN Anic and EGN AK2+pen, we have carried out some experiments. We check empirically in four problems the validity of our approaches against two simple type of EDAs, the U M DA and MIMIC algorithms and against the Ge netic Algorithm (GA).\n5.2 The problems\n[ n Qi (ri _ 1)! r, l n OneMax problem log !l }1 (Nij + ri- 1)! g Nijk! -f(N) t;(ri-l)qi. This �s an easy linear problem. It can be written math-\n(10) ematically as:\nAs an illustrative example of application of the pre vious theorem, let us consider a domain with n = 20 variables, where the set containing the number of dif ferent values for each variables is given by\n7 5 5 ....---..... ....---..... ....---.....\n{r1 , ... , r i, .. . , r20} = {3, .. . , 3, 4, 3, ... , 3, 4, 3, . .. , 3, 4} (11) Suppose that the database D contains N = 422 cases and that we use the penalizing function known as the Akaike information criterion, that is f(N) = 1, (Akaike, 1974). Using theorem 1, we obtain the upper bound for the parent nodes of variable X8 in the Bayesian network with the best score. Dividing N(422) by rs(4) we obtain m 105 and l 2. On the other 17 ....---..... hand, the set {r� , ... ,r�, ... , r19 } = {3, ... , 3, 4, 4}. Calculating the right side of equation (9) we\n. 1 (N!(rs+l-1)! ((2rs-1 !)m) obtam: (rs-1)/(N) log (N+rs 1)! (rs-1 ! 231.0034. The first natural number, pa, for which n;:i1 rj - n;==-�-pa rj is bigger than 231.0034 is f n5+1 1 nn-l I _ 36 pa = 5, in act j=l rj - j=n-5 rj - - 3342 = 297. This means that X8 will not have\nn F1 = FoneMax (x) = L Xi· (12)\ni=l\nThe objective is to maximize the function F1 with Xi E {0, 1}.\nCheckerboard problem\nIn this problem, a s x s grid is given. Each point of the grid can take two values 0 or 1. The aim of the problem is to create a checkerboard pattern of O's and 1's on the grid. Each location with a value of 1 should be surrounded in all four directions by a value of 0, and vice-versa. Only the four primary directions are considered in the evaluation. The evaluation is mea sured by counting the number of correct surrounding bits for the present value of each bit position for a (s- 2) x (s- 2) grid. In this manner, the corners are not included in the evaluation. The maximum value is 4(s - 2)2. The individuals of this problem have di mension n = s2. If we consider the grid as a matrix C = [cij]i,j=l, ... ,s and interpret J(a, b) as the Kronecker's delta function, the checkerboard function can be written as follows:\nF2 = Fcheckerboard(C) = 4(s- 2)2-\n350 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nn-1 n-1 Three stopping conditions were taken into account. L L 6(cii' Ci-1j )+6(cii' Ci+lj )+o(cij' cii-d+o(cij' CiHd:<'irstly, the algorithm is stopped when a fixed num-i=2 i=2 ber of function evaluations is reached. Secondly, the (13) algorithm is stopped when the average value of the in dividuals in the population improves less than a fixed SixPeaks problem\nThis maximization problem can be defined mathemat ically as:\nvalue. Thirdly the algorithm is stopped when it finds the optimum in case it is known. It does not mat ter what condition is first met, whenever one of them occurs the algorithm is stopped.\nWe use truncation selection as the selection method\nmax{tail(O, x), head(1, x), tail(1, x), head(O, x)}+R(x, t) of choice, i.e. the best individuals are selected. The (14) number of selected individuals was set up to half of\nF3 = FsixPeaks(x,t) =\nwhere\ntail (b, x) =number of trailing b's in x\nhead(b, x) =number of leading b's in x\n{ n if R(x, t) =\n0\ntail(O,x) > t and head(1,x) >tor tail(1, x) > t and head(O, x) > t otherwise.\nIn our experiments, the value of t was set to 30% of n.\nEqualProducts problem\nGiven a set n real numbers { b1, b2, ... , bn}, a subset of them is chosen. The objective is to minimize the difference between the products of the selected and unselected numbers. Mathematically:\nF4 = FEqua!Products(x) = lg Xibi-g (1- Xi)bi l · (15)\nIn our experiments the set of the n real numbers was built sampling a uniform distribution in the interval [0, 4]. Thus, we do not know the optimum of this prob lem.\n5.3 General considerations\nIn this section we will set up some of the parame ters and decisions that are common to all EDA ap plications and those that are necessary in the G A ap proach. In particular the characteristics to define in EDA approaches are: size of the population, stopping condition, selection method and number of selected in dividuals.\nThe size of the population is the same in all the ap proaches. It was set up depending on the complexity of the problem. These values -chosen after carrying out some experiments- were assigned to 512, 1000, 1600 and 1600 respectively.\nthe population.\nSome of this information is summarized in Table 1.\nDimension Max. Evaluat. Type Optimum 128 100,000 Max. 128 100 100,000 Max. 256 50 300,000 Max. 84 50 300,000 Min.\nA GA was implemented using the GENITOR software (Whitley and Kauth 1988). The classical mutation and one-point crossover operators together with rank based selection were used.\nWe carried out 100 experiments for each function and algorithm.\n5.4 Results\nTable 2 summarizes the mean value of the results ob tained for each algorithm in each problem before the algorithm stopped. For a more detailled analysis the reader can consult Larranaga et al. (1999b).\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 351\nA deeper analysis of the results has been carried out by means of statistical tests. We have performed a Kruskal-Wallis test (o: = 0.05) related to the objec tive value reached for the algorithms. In all the prob lems, the results showed that significative differences between the algorithms exist.\nMoreover, five more Kruskal-Wallis test were made for each problem. For this task, the algorithms were ranked with respect to the mean function value. Each algorithm was tested with its next algorithm in the rank order. For instance, in the case of the Checker board problem, the algorithms are ranked as follows: EBNAK2+pen, EBNABie, GA, MIMIC, EBNApe and UMDA. For this case, we tested, EBNAK2+pen against EBN ABJe, later EBN ABle against GA, and so on.\nTable 3 summarizes the tests results. The entries of the table show the existence or absence of significative differences. The same number for two consecutive al gorithms (in the rank order) means that there is no sig nificative difference. For example, in the Checkerboard problem, because EBN AK2+pen and EBN As1e have different numbers, this means that a significative dif ference between both algorithms exists. However, EBNA8w, GA, MIMIC and EBNApe were as signed the same number, which means that there is no significative difference between EBN ABle and GA, between GA and MIMIC, and between MIMIC and EBN Ape. The particular numbers in each entry rep resent the number of algorithms that obtained better results (for the test carried out), where 1 means the best algorithm.\nAs a result of the experiments, we conclude that EBN AK2+pen is the algorithm that returned the best results. EBN Asw obtains results that are near those obtained by EBN AK2+pen· On the contrary, the worst results were obtained with EBN Ape and GA.\n6 Conclusions and futher work\nIn this paper, we have introduced new approaches for combinatorial optimization based on the structure learning of Bayesian networks from different perspec tives �detecting independencies and by penalized max imum likelihood and marginal likelihood. Also empiri cal evidence of the behavior of the proposed algorithms has been shown.\nThere remain some open questions in this new frame work for optimization. Among them, the determina tion of an appropiate sample size, the development of techniques able to deal with optimization under con straints, the parallelization of the diferents tasks, and the study of the behavoir of EDA from a mathematical point of view.\nAcknowledgement\nThis work was partially supported by the Spanish Comisi6n Interministerial de Ciencia y Tecnologia (CICYT) under project TIC97-1135-C04-03, by the University of the Basque Country under project UPV 140.226-EB131/99, and by the Departamento de Edu caci6n, Universidades e Investigaci6n under grant PI98/74. We thank E. Bengoetxea and the anonymous reviewers for useful suggestions.\nReferences\n[1] H. Akaike (1978). New Look at the Statistical Model Identification. IEEE Transactions on Automatic Con trol19, 6, 716�723.\n[2] S. Baluja (1994). Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learn ing. Carnegie Mellon Report. CMU-CS-94-163.\n[3] S. Baluja and S. Davies (1997). Using Optimal Dependency-Trees for Combinatorial Optimization: Learning the Structure of the Search Space. Carnegie Mellon Report. CMU-CS-97-107.\n[4] W. Buntine (1991). Theory refinement in Bayesian networks. Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, 52�60.\n[5] W. Buntine (1996). A Guide to the Literature on Learning Probabilistic Networks from Data. IEEE Transactions on Knowledge and Data Engineering 8: 2, 195�210.\n[6] E. Castillo, J. M. Gutierrez, and A. S. Hadi (1997). Expert Systems and Probabilistic Network Models. Springer-Verlag.\n[7] D. M. Chickering, D. Geiger, and D. Heckerman (1994). Learning Bayesian networks is NP�hard. Tech nical Report MSR-TR-94-17. Microsoft Research.\n352 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\n[8] D. M. Chickering, D. Geiger, and D. Heckerman (1995). Learning Bayesian Networks: Search Meth ods and Experimental Results. Preliminary Papers of the Fifth International Workshop on Artificial Intelli gence and Statistics, 112-128.\n[9] G. F. Cooper and E. A. Herskovits (1992). A Bayesian method for the induction of probabilistic networks from data. Machine Learning 9, 309-347.\n[10] R. G. Cowell, A. P. Dawid, S. L. Lauritzen and D. J. Spiegelhalter (1999). Probabilistic Networks and Ex pert Systems. Springer-Verlag.\n[11] J. S. De Bonet, C. L. Isbell, and P. Viola (1997). MIMIC: Finding Optima by Estimating Probability Densities, Advances in Neural Information Processing Systems, Vol. 9 .\n[12] R. Etxeberria, P. Larraiiaga, and J. M. Picaza (1997a). Reducing Bayesian networks complexity while learning from data. Proceedings of Causal Mod els and Statistical Learning, 151-168.\n[13] R. Etxeberria, P. Larraiiaga, and J. M. Picaza (1997b). Analysis of the behaviour of the genetic algo rithms when searching Bayesian networks from data. Pattern Recognition Letters 18: 11-13, 1269-1273.\n[14] R. Etxeberria and P. Larraiiaga (1999). Global opti mization with Bayesian networks, II Symposium on Artificial Intelligence. CIMAF99. Special Session on Distributions and Evolutionary Optimization, 332- 339.\n[15] G. Harik (1999). Linkage learning in via Probabilis tic Modeling in the ECGA. IlliGAL Technical Report, No. 99010.\n[16] G. Harik, F. G. Lobo, and D. E. Goldberg (1998). The Compact Genetic Algorithm. Proceedings of the IEEE Conference on Evolutionary Computation, 523-528.\n[17] D. Heckerman (1995). A Tutorial on Learning with Bayesian Networks. Technical Report MSR-TR-95-06. Microsoft Research.\n[18] M. Henrion (1988). Propagating uncertainty m Bayesian networks by probabilistic logic sampling. Uncertainty in Artificial Intelligence 2, 149-163.\n[19] I. Inza, P. Larraiiaga, R. Etxeberria and B. Sierra (1999). Feature Subset Selection by estimation and simulation of Bayesian networks. Technical Report, University of the Basque Country, KZAA-IK-99-02.\n[20] F. V. Jensen (1996). An introduction to Bayesian net works . University College of London.\n[21] P. Larraiiaga, M. Poza, Y. Yurramendi, R. H. Murga, and C. M. H. Kuijpers (1996a). Structure learning of Bayesian networks by genetic algorithms: A perfor mance analysis of control parameters. IEEE Transac tions on Pattern Analysis and Machine Intelligence 18 (9), 912-926.\n[22] P. Larraiiaga, C. M. H. Kuijpers, R. H. Murga, andY. Yurramendi (1996b). Searching for the best ordering in the structure learning of Bayesian networks, IEEE Transactions on Systems, Man and Cybernetics 26 (4), 487-493.\n[23] P. Larraiiaga, R. Etxeberria, J. A. Lozano, B. Sierra, I. Inza, and J. M. Peiia (1999a). A review of the coop eration between evolutionary computation and proba bilistic graphical models. Second Symposium on Arti ficial Intelligence. Adaptive Systems. CIMAF gg, 314- 324.\n[24] P. Larraiiaga, R. Etxeberria, J. A. Lozano, and J. M. Peiia (1999b). Optimization by learning and sim ulation of Bayesian and Gaussian networks. Technical Report, University of the Basque Country, KZAA-IK99-04.\n[25] H. Miihlenbein (1998). The Equation for Response to Selection and its Use for Prediction, Evolutionary Computation 5, 303-346.\n[26] H. Miihlenbein and G. Paaf3(1996). From Recombina tion of Genes to the Estimation of Distributions I. Bi nary Parameters. Lecture Notes in Computer Science 1411: Parallel Problem Solving from Nature-PPSN IV , 178-187.\n[27] H. Miihlenbein, T. Mahnig, and A. Ochoa (1999). Schemata, Distributions and Graphical Models in Evolutionary Computation. Journal of Heuristics 5, 215-247.\n[28] H. Miihlenbein and T. Mahnig (1999). FDA - A scal able evolutionary algorithm for the optimization of additively decomposed functions. Evolutionary Com putation 7(4), 353-376.\n[29] J. W. Myers, K. B. Laskey and T. Levitt (1999). Learning Bayesian Networks from Incomplete data with Stochastic Search Algorithms. Proceedings of the Fifteenth Conference on Uncertainty in Artificial In telligence, 476-485.\n[30] J. Pearl (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann.\n[31] M. Pelikan and H. Miihlenbein (1999). The Bivariate Marginal Distribution Algorithm, Advances in Soft Computing-Engineering Design and Manufacturing. Springer-Verlag, 521-535.\n[32] M. Pelikan, D. E. Goldberg and E. Cantu-Paz (1999). BOA: The Bayesian optimization algorithm. Proceed ings of the Genetic and Evolutionary Computation Conference GECC0-99, Vol. 1, Morgan Kaufmann Publishers, 525-532.\n[33] G. Schwarz (1978). Estimating the dimension of a model. Annals of Statistics 7(2), 461-464.\n[34] P. Spirtes, C. Glymour, and R. Scheines (1991). An algorithm for fast recovery of sparse causal graphs. Social Science Computing Reviews 9, 62-72.\n[35] G. Syswerda (1993). Simulated crossover in genetic al gorithms. Foundations of Genetic Algorithms 2, 239- 255, Morgan Kaufmann.\n[36] D. Whitley and J. Kauth (1988). GENITOR: A differ ent genetic algorithm, Proceedings of the Rocky Moun tain Conference on Artificial Intelligence, Vol. 2, 118- 130."
    } ],
    "references" : [ {
      "title" : "New Look at the Statistical Model Identification",
      "author" : [ "H. Akaike" ],
      "venue" : "IEEE Transactions on Automatic Con­ trol19,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1978
    }, {
      "title" : "Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learn­ ing",
      "author" : [ "S. Baluja" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1994
    }, {
      "title" : "Using Optimal Dependency-Trees for Combinatorial Optimization: Learning the Structure of the Search Space",
      "author" : [ "S. Baluja", "S. Davies" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1997
    }, {
      "title" : "Theory refinement in Bayesian networks",
      "author" : [ "W. Buntine" ],
      "venue" : "Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1991
    }, {
      "title" : "A Guide to the Literature on Learning Probabilistic Networks from Data",
      "author" : [ "W. Buntine" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1996
    }, {
      "title" : "and A",
      "author" : [ "E. Castillo", "J.M. Gutierrez" ],
      "venue" : "S. Hadi ",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "and D",
      "author" : [ "D.M. Chickering", "D. Geiger" ],
      "venue" : "Heckerman ",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "and D",
      "author" : [ "D.M. Chickering", "D. Geiger" ],
      "venue" : "Heckerman ",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A Bayesian method for the induction of probabilistic networks from data",
      "author" : [ "G.F. Cooper", "E.A. Herskovits" ],
      "venue" : "Machine Learning",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1992
    }, {
      "title" : "S",
      "author" : [ "R.G. Cowell", "A.P. Dawid" ],
      "venue" : "L. Lauritzen and D. J. Spiegelhalter ",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "and P",
      "author" : [ "J.S. De Bonet", "C.L. Isbell" ],
      "venue" : "Viola ",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "and J",
      "author" : [ "R. Etxeberria", "P. Larraiiaga" ],
      "venue" : "M. Picaza ",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "and J",
      "author" : [ "R. Etxeberria", "P. Larraiiaga" ],
      "venue" : "M. Picaza ",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Global opti­ mization with Bayesian networks, II Symposium on Artificial Intelligence. CIMAF99",
      "author" : [ "P.R. Etxeberria" ],
      "venue" : "Larraiiaga",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1999
    }, {
      "title" : "Linkage learning in via Probabilis­ tic Modeling in the ECGA",
      "author" : [ "G. Harik" ],
      "venue" : "IlliGAL Technical Report,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1999
    }, {
      "title" : "and D",
      "author" : [ "G. Harik", "F.G. Lobo" ],
      "venue" : "E. Goldberg ",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "A Tutorial on Learning with Bayesian Networks",
      "author" : [ "D. Heckerman" ],
      "venue" : "Technical Report MSR-TR-95-06. Microsoft Research",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1995
    }, {
      "title" : "Propagating uncertainty m Bayesian networks by probabilistic logic sampling",
      "author" : [ "M. Henrion" ],
      "venue" : "Uncertainty in Artificial Intelligence",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1988
    }, {
      "title" : "R",
      "author" : [ "I. Inza", "P. Larraiiaga" ],
      "venue" : "Etxeberria and B. Sierra ",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "An introduction to Bayesian net­",
      "author" : [ "F.V. Jensen" ],
      "venue" : "College of London",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1996
    }, {
      "title" : "and C",
      "author" : [ "P. Larraiiaga", "M. Poza", "Y. Yurramendi", "R.H. Murga" ],
      "venue" : "M. H. Kuijpers ",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "andY",
      "author" : [ "P. Larraiiaga", "C.M.H. Kuijpers", "R.H. Murga" ],
      "venue" : "Yurramendi ",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "and J",
      "author" : [ "P. Larraiiaga", "R. Etxeberria", "J.A. Lozano", "B. Sierra", "I. Inza" ],
      "venue" : "M. Peiia ",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "and J",
      "author" : [ "P. Larraiiaga", "R. Etxeberria", "J.A. Lozano" ],
      "venue" : "M. Peiia ",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "The Equation for Response to Selection and its Use for Prediction",
      "author" : [ "H. Miihlenbein" ],
      "venue" : "Evolutionary Computation",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1998
    }, {
      "title" : "From Recombina­ tion of Genes to the Estimation of Distributions I. Bi­ nary Parameters",
      "author" : [ "G.H. Miihlenbein" ],
      "venue" : "Lecture Notes in Computer Science 1411: Parallel Problem Solving from Nature-PPSN",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1996
    }, {
      "title" : "and A",
      "author" : [ "H. Miihlenbein", "T. Mahnig" ],
      "venue" : "Ochoa ",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "FDA - A scal­ able evolutionary algorithm for the optimization of additively decomposed functions",
      "author" : [ "T.H. Miihlenbein" ],
      "venue" : "Mahnig",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1999
    }, {
      "title" : "K",
      "author" : [ "J.W. Myers" ],
      "venue" : "B. Laskey and T. Levitt ",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "The Bivariate Marginal Distribution Algorithm, Advances in Soft Computing-Engineering Design and Manufacturing",
      "author" : [ "H.M. Pelikan" ],
      "venue" : "Miihlenbein",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1999
    }, {
      "title" : "D",
      "author" : [ "M. Pelikan" ],
      "venue" : "E. Goldberg and E. Cantu-Paz ",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Estimating the dimension of a model",
      "author" : [ "G. Schwarz" ],
      "venue" : "Annals of Statistics",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 1978
    }, {
      "title" : "and R",
      "author" : [ "P. Spirtes", "C. Glymour" ],
      "venue" : "Scheines ",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Simulated crossover in genetic al­ gorithms",
      "author" : [ "G. Syswerda" ],
      "venue" : "Foundations of Genetic Algorithms",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 1993
    }, {
      "title" : "GENITOR: A differ­ ent genetic algorithm",
      "author" : [ "D. Whitley", "J. Kauth" ],
      "venue" : "Proceedings of the Rocky Moun­ tain Conference on Artificial Intelligence,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "In our experiments the set of the n real numbers was built sampling a uniform distribution in the interval [0, 4].",
      "startOffset" : 107,
      "endOffset" : 113
    } ],
    "year" : 2011,
    "abstractText" : "This paper shows how the Bayesian network paradigm can be used in order to solve com­ binatorial optimization problems. To do it some methods of structure learning from data and simulation of Bayesian networks are in­ serted inside Estimation of Distribution Al­ gorithms (EDA). EDA are a new tool for evo­ lutionary computation in which populations of individuals are created by estimation and simulation of the joint probability distribu­ tion of the selected individuals. We propose new approaches to EDA for combinatorial op­ timization based on the theory of probabilis­ tic graphical models. Experimental results are also presented.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}