{
  "name" : "1401.3438.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Ultrametric Constraint and its Application to Phylogenetics",
    "authors" : [ "Neil C.A. Moore", "Patrick Prosser" ],
    "emails" : [ "ncam@cs.st-andrews.ac.uk", "pat@dcs.gla.ac.uk" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "One of the grand challenges of phylogenetics is to build the Tree of Life (ToL), a representation of the evolutionary history of every living thing. To date, biologists have catalogued about 1.7 million species, yet estimates of the total number of species range from 4 to 100 million. Of the 1.7 million species identified only about 80,000 have been placed in the ToL so far (Pennisi, 2003). There are applications for the ToL: to help understand how pathogens become more virulent over time, how new diseases emerge, and to recognise species at risk of extinction (Pennisi, 2003; Mace, Gittleman, & Purvis, 2003). One approach to building the ToL is divide and conquer: combining smaller trees such as those available from TreeBase (TreeBASE, 2003) into so-called “supertrees” (Bininda-Emonds, 2004) to approach a more complete ToL.\nTo date, supertree construction has been dominated by imperative techniques (Semple & Steel, 2000; Semple, Daniel, Hordijk, Page, & Steel, 2004; Daniel, 2003; Bordewich, Evans, & Semple, 2006; Ng & Wormald, 1996; Bryant & Steel, 1995; Page, 2002) but recently new declarative approaches have emerged using constraint programming (Gent, Prosser, Smith, & Wei, 2003; Prosser, 2006; Beldiceanu, Flener, & Lorca, 2008) and answer set programming (Wu, You, & Lin, 2007). One of the properties of rooted trees that suits these approaches is that trees are by their nature ultrametric: in rooted trees the root node has depth 0, and the depth of other nodes is 1 plus the depth of their parent. Taking any\nc©2008 AI Access Foundation. All rights reserved.\nthree leaves a, b and c in pairs it must be that one pair has a deeper most recent common ancestor (mrca) than the other pairs, or that all three pairs have the same mrca. And this is what we mean by ultrametric, that for any three there is a tie for the minimum. In fact, if we know the depth of the mrca of all pairs of leaves the structure of the tree is uniquely determined. This inspires a constraint programming encoding for rooted trees, using the ultrametric constraint that we will define later. We explore solutions to the phylogenetic supertree problem and its variants. In so doing, we show the practicality of an ultrametric encoding for rooted tree problems, as well as arguing that this is a valuable addition to the set of techniques for supertree problems.\nThe paper is organised as follows. First, we introduce constraint programming and the supertree construction problem. We then propose a specialised ultrametric constraint, in terms of its propagation procedures, that maintains bounds(Z)-consistency (Bessière, 2006) on three variables. We show that this specialised constraint is required because models that use toolkit primitives cannot guarantee the ultrametric property on the supertree problem via propagation alone. Furthermore, the space complexity of such models becomes prohibitive. The ultrametric constraint is then extended to maintain the property over a symmetric matrix of variables. We then go on to show that this constraint can be efficiently applied to the problem of supertree construction, in particular that applying propagation to this model gives a polynomial time procedure for supertree construction. We then demonstrate this on real data and give justification that there has been an improvement in time and space over previous constraint encodings. One of the benefits of the constraint programming approach is that variants of the supertree problem can be addressed within this one model. We justify this assertion by proposing a constraint solution finding essential relations in the supertree (Daniel, 2003), addressing ancestral divergence dates (Semple et al., 2004; Bryant, Semple, & Steel, 2004), modelling nested taxa (Page, 2004; Daniel & Semple, 2004) and coping with conflicting data."
    }, {
      "heading" : "2. Background",
      "text" : "In this section we give necessary definitions and descriptions of the Constraint Satisfaction Problem (Tsang, 1993), Constraint Programming, and the Supertree problem."
    }, {
      "heading" : "2.1 Constraint Programming and the CSP",
      "text" : "Constraint Programming (CP) (Rossi, van Beek, & Walsh, 2007) is a declarative style of programming where problems are modelled as a CSP, i.e., as a set of variables that have to be assigned values from those variables’ domains to satisfy a set of constraints. Values might typically be integers drawn from finite domains, real numbers from ranges, or more complex entities like sets or graphs. We will only be considering integers.\nDefinition 1. A constraint satisfaction problem (CSP) is a triple (V,D,C) where V is a set of n variables {v1, . . . , vn}; D = {dom(v1), . . . , dom(vn)} is a collection of domains, each a totally ordered set of integer values; and C = {c1, . . . , ce} is a set of e constraints, each with a scope of variables scope(c) = (vc1 , . . . , vck) and a relation rel(c) ⊆ dom(vc1)×. . .×dom(vck). An assignment of value x ∈ dom(v) to variable vi ∈ V is denoted by (vi, x). A constraint c ∈ C is satisfied by an assignment {(vc1 , xc1), . . . , (vck , xck)} when scope(c) = (vc1 , . . . , vck)\nand (xc1, . . . , xck) ∈ rel(c). A set of assignments {(v1, x1), . . . , (vn, xn)} involving every variable in the problem is a solution when it satisfies all the constraints in C.\nA constraint solver finds a solution to a CSP via a process of constraint propagation and search. Constraint propagation is an inferencing process that takes place when a variable is initialised or loses values. Propagation maintains a level of consistency, such as arcconsistency (Mackworth, 1977), across the variables, removing values from domains that cannot occur in any solution (i.e., removing unsupported values). We use the definitions of (generalized) arc-consistency ((G)AC) due to Bessière (2006):\nDefinition 2. Given a CSP (V,D,C), a constraint c ∈ C with scope(c) = (vc1 , . . . , vck), and a variable v ∈ scope(c), a value x ∈ dom(v) is consistent with respect to c (alternatively, supported by c) iff there exists a satisfying assignment α = {(vc1 , a1), . . . , (vck , ak)} for c such that (v, x) ∈ α and ∀i, ai ∈ dom(vci). The domain dom(v) is (generalized) arcconsistent on c iff all values in dom(v) are consistent with respect to c, and the CSP is (generalized) arc-consistent when all variable domains are (generalized) arc-consistent on all constraints in C.\nArc-consistency can be established on a CSP using an algorithm such as AC3 (Mackworth, 1977). For sake of exposition we assume all constraints in C are binary and that for each constraint c we have a counterpart c′ such that scope(c) = (va, vb) and scope(c′) = (vb, va) with rel(c\n′) = rel−1(c). For example, if we have the constraint cxy = x < y then we also have the constraint cyx = y > x. At the heart of AC3 is the revise function, which takes a binary constraint c as its argument and delivers a Boolean result. The function removes from dom(va) all values that have no support in dom(vb) w.r.t. the constraint c, and returns true if any removals take place. Initially all constraints are added to a set S. Constraints are iteratively removed from S and revised. If revise(ckm) returns true then S becomes S ∪ {cik|cik ∈ C ∧ i 6= k ∧ i 6= m}. This step can be considered as the propagation of a domain reduction on variable vk to variables constrained by vk. The iteration terminates when S is empty or a variable’s domain becomes empty. When S is empty the arc-consistency algorithm has reached a fixed point (i.e., a further application of the arc-consistency process will have no effect on the domains of the variables) and the problem has been made arc-consistent. When a domain empties, we have shown the there are no solutions globally and hence we can stop. The AC3 algorithm has O(e · d3) time complexity, where e is the number of constraints and d the size of the largest domain, however other algorithms can achieve a time bound of O(e · d2) (Yuanlin & Yap, 2001; Bessière & Régin, 2001).\nWe demonstrate arc-consistency with the example of Figure 1 by Smith (1995). We have three constrained integer variables x, y and z, each with an integer domain {1..5}, and binary constraints cxy : x < y − 2, cyz : y + z is even, and czx : z < 2x+ 1. Since the constraints are binary we can represent the problem as a constraint graph, where nodes are vertices and edges are constraints. Initially the constraint cxy is revised with respect to x and the values {3..5} are removed from dom(x). Then cxy is revised w.r.t. y and dom(y) becomes {4, 5}. cyz is then revised w.r.t. y with no effect and then revised w.r.t. z, again with no effect. Revising czx w.r.t. z reduces dom(z) such that it becomes {1..4}, consequently the constraint cyz is added into the set of constraints pending revision. Constraint czx is\nrevised w.r.t. x and then cyz w.r.t. to y, both with no effect. The revision set at that point is empty and arc-consistency has been established with variable domains dom(x) = {1, 2}, dom(y) = {4, 5}, and dom(z) = {1..4}.\nSolving a CSP may involve search, i.e., we might need to try different values for variables in order to determine if a solution exists. Typically a constraint solver will begin by establishing arc-consistency, and then repeatedly select a variable and assign it a value from its domain (instantiate it). This effectively reduces that variable’s domain to a singleton, and arc-consistency is then re-established. If this succeeds another instantiation is made, but if it fails we backtrack by undoing the most recent instantiation. This is called MAC, for maintaining arc-consistency (Sabin & Freuder, 1994).\nFigure 2 shows a constraint program for the problem in Figure 1 using the choco constraint programming toolkit for the Java language (Choco, 2008), and it finds solution x = 1, y = 4, and z = 2 first.\nConstraint toolkits tend to be based around the AC5 algorithm (van Hentenryck, Deville, & Teng, 1992), allowing propagators to be specialised for specific constraints resulting in improved efficiency and adaptability. AC5 amends set S from AC3 to contain triples of the form (v, c, δ) where v ∈ scope(c) and δ is the set of values lost by v, consequently\nrevision is more efficient because propagation can focus of values that may have lost support, rather than having to check every value for support. In an object-oriented toolkit language a constraint has associated propagation methods that should be implemented, and these methods are activated when a domain event occurs on a variable involved in that constraint. Domain events can be the initialisation of a variable, an increase in the lower bound, a decrease in the upper bound, the removal of a value between the bounds, or the instantiation of that variable. This is an exhaustive list, however some toolkits allow only one event: that one or more values have been lost and the propagator writer must then determine what action to take. To give examples of using a toolkit with specialised constraints, when modelling a routing problem we might have a constrained integer variable for each location to be visited, with a domain of values corresponding to the index of the next destination (the so-called “single-successor” model). A subtour elimination constraint (Caseau & Laburthe, 1997) might then be used to ensure that only legal tours are produced, and Régin’s alldifferent constraint (Régin, 1994) could be added to increase domain filtering. In a pick up and delivery variant, side constraints could be added to ensure that some locations are visited before others. For a job shop scheduling problem we might have a model that uses 0/1 variables to decide the relative order of pairs of activities that share a resource, and we might increase propagation by adding Carlier and Pinson’s edge finding constraint (1994).\nThe constraint programming approach is general and practical for modelling and solving problems, and provides a framework for the combination of problem specific algorithms in one solver. This allows us to solve many classes of problems efficiently and to model even more problems via the addition of side constraints."
    }, {
      "heading" : "2.2 The Supertree Problem",
      "text" : "Supertree construction is a problem in phylogenetics where we are to combine leaf-labelled species trees, where the sets of leaf labels intersect, into a single tree that respects all arboreal relationships in each input tree (Bininda-Emonds, 2004). Species trees describe part of the evolutionary history of a set of species. Labels on leaves correspond to existing species and internal nodes represent divergence events in evolutionary history where one species split into at least two other species. Species trees may also be annotated with dates on internal nodes, representing the time at which the divergence event happened.\nWe now define the term displays, which makes precise what we mean by “respects arboreal relationships”: supertree T1 displays a tree T2 if and only if T2 is equivalent to T4 (i.e. they induce the same hierarchy on the leaf labels) where T4 is obtained by the following steps (Semple & Steel, 2000):\n1. Let L be the set of leaves of T1 that are in T2. 2. Let T3 be the unique subtree of T1 that connects all leaves in L. 3. To obtain T4: wherever there is a subpath (p1, . . . , pk) of a path from the root to a leaf in T3 where p2, . . . , pk−1 are all interior nodes of degree 2, contract this into a single edge.\nThe problem is then to produce a rooted species tree T from a forest of input trees F, so that T contains all the species in F and displays every tree in F . Figures 3 and 4 illustrate the displays property.\nWe say that two trees T1 and T2 are compatible (incompatible) if there exists (doesn’t exist) a third tree T3 that displays T1 and T2. Variants on the supertree problem that have previously been published and solved in the specialist bioinformatics literature include finding all solutions1, counting solutions, finding conserved relationships in all supertrees (Daniel, 2003), incorporating nested taxa (Semple et al., 2004), incorporating ancestral divergence dates (Semple et al., 2004) and the possibility of contradictory input data (Semple & Steel, 2000)."
    }, {
      "heading" : "3. The Ultrametric Constraint",
      "text" : "The ultrametric constraint was first proposed by Gent et al. (2003) within the context of supertree construction (Bininda-Emonds, 2004), and was implemented using toolkit primitives. We review this encoding and show that in most constraint toolkits this is inefficient in terms of both space and time. This motivates the creation of a specialised ultrametric propagator over three variables, that maintains the ultrametric property over the bounds of those variables. It is presented by describing the necessary propagation methods. We then extend it to a specialised propagator that maintains the ultrametric property on a symmetric matrix of variables."
    }, {
      "heading" : "3.1 Previous Work on the Ultrametric Constraint",
      "text" : "First, we give a definition of the ultrametric constraint.\nDefinition 3. An ultrametric constraint on three variables (henceforth, Um-3) x, y and z constrains them such that:\n(x > y = z) ∨ (y > x = z) ∨ (z > x = y) ∨ (x = y = z) (1)\nThis constraint ensures that there is a tie for the least element of the three, i.e., either all three are the same, or two are the same and the other is greater. The constraint was proposed by Gent et al. (2003), used again by Prosser (2006) and both times implemented as a literal translation of Equation 1 using toolkit primitives. Evidence obtained from the JChoco, ECLiPSe and ILog constraint programming toolkits shows that no propagation is done to lower bounds by this combination of primitive constraints. This is due to the disjunctive constraints since in many constraint programming toolkits propagation is delayed until only one of the disjuncts can be true, this is known as delayed-disjunction consistency (van Hentenryck, Saraswat, & Deville, 1998). Consequently, in the above encoding values that cannot occur in any satisfying assignment might not be pruned from the domain of a variable. Consider the case for three variables: x ∈ {1, 2, 3}, y ∈ {2, 3} and z ∈ {3}. The domains of the variables are already at a fixed point with respect to delayed-disjunction consistency but there is no ultrametric assignment where x takes the value 1, i.e., delayeddisjunction propagation does not achieve arc-consistency. As we shall see later, finding a solution to the supertree problem using toolkit constraints can result in a backtracking search, and we prefer to avoid this. Of course, higher levels of consistency would overcome this, such as constructive-disjunction consistency (van Hentenryck et al., 1998), singleton\n1. There may be multiple supertrees for the same set of input trees.\narc-consistency (Debruyne & Bessière, 1997) or the filtering algorithm of Lhomme (2003). However, the cost of these is greater in the average case than delayed-disjunction, preventing their use in toolkits. In fact for the Um-3 constraint it is especially unfortunate that the lower bounds may not be trimmed properly:\nLemma 1. In the Um-3 constraint, when lower bounds are supported (i.e., form an ultrametric instantiation with values in the other constrained variables), they support each other.\nProof. Consider three supported lower bounds. Suppose for a contradiction that the two least of these are distinct. One of these is distinct lowest and it cannot be supported on account of the fact that it is not equal to anything or larger than anything. Therefore by contradiction the two least must be equal. However the other lower bound is at least as large as these, so the lower bounds are mutually supportive.\nThis Lemma will have important implications for the species tree model to be presented in detail in Section 4: in particular, the lower bounds of a bounds(Z)-consistency model form a solution, where bounds(Z)-consistency (Bessière, 2006) is defined as follows\nDefinition 4. Given (V,D,C) and constraint c ∈ C with scope(c) = (vc1, . . . , vck), a tuple τ = (xc1 , . . . , xck) is a bound support when τ ∈ rel(c) and for all xci ∈ τ , min(dom(vci)) ≤ xci ≤ max(dom(vci)). A constraint c is bounds(Z)-consistent if for all vci ∈ scope(c) there exist bound supports involving both min(dom(vci)) and max(dom(vci)). A CSP is bounds(Z)consistent when every constraint c ∈ C is bounds(Z)-consistent.\nWe will henceforth abbreviate “bound support” to “support” and bounds(Z)-consistency to BC(Z). BC(Z) differs from AC because it puts weaker conditions on the values that comprise the support: rather than them having to be in the domain, they need to only be between the lower and upper bounds of the domain. This means that BC(Z) prunes a subset of the values that AC can, in general. Weaker levels of consistency such as BC(Z) are useful because in certain problems they can prune the same number of values as AC more easily, or fewer values much more quickly. In our case, BC(Z) is interesting because this level of consistency is “just enough” to ensure that the problem can be solved by propagation with no search, as we shall see."
    }, {
      "heading" : "3.2 Design of a BC(Z) UM-3 Propagator",
      "text" : "In this Section we describe a Um-3 propagator that enforces BC(Z), namely UM-3-BCZ."
    }, {
      "heading" : "3.2.1 Analysis of Lower and Upper Bounds",
      "text" : "In this section we don’t take account of domains becoming empty. Since we analyse lower and upper bounds in isolation a lower bound may pass an upper bound or vice-versa, thereby emptying a domain. If this happens then the propagator described in Section 3.2.2 will not enforce BC(Z), rather it will terminate. This is not a problem, because a domain becoming empty means that there is no solution and to continue would be a waste of time. Concordantly, in this section, when we analyse lower bounds we will assume the upper bound is ∞ so that the domain cannot become null for this reason, and vice-versa.\nThe procedure LBFix in Figure 5 takes as input three variables and removes any unsupported values at the lower bounds of the domain. The intuition for the algorithm achieving this is that each one needs to be involved in a tie for least element, hence if the smallest lower bound is strictly less than the others then it must be unsupported.\nThe possible states of lower bounds when LBFix is invoked are summarised in Figure 6. Either all three are different (case 1), all three are the same (case 2) or two are the same and one different (cases 3 and 4). These give relationships between bounds at a point in time when some lower bound may be unsupported. The boxes in Figure 6 are shaded as follows: regions shaded black are removed by propagation whereas gray regions are supported. What the diagrams are not supposed to suggest is that, for example in case 1, the bounds differ by 1. Rather when two bounds are lined up they are the same bound and when one is different from another they are different by some non-zero but unspecified amount. Hence they describe relationships and not actual values.\nThe following shows that LBFix removes all unsupported values and does not remove any supported values.\nLemma 2. After LBFix is invoked all lower bounds of the argument variables are supported w.r.t. the Um-3 constraint and no supported values are removed.\nProof. For cases 1 and 4 (Figure 6) the condition on line A2 is satisfied, so line A2.1 is executed, this results in the removal of the unsupported range and by inspection the remaining bounds are mutually supportive. In cases 2 and 3, the condition on line A2 is failed and so no changes are made to the domains; the bounds are mutually supportive.\nThe procedure UBFix in Figure 5 does the same job to upper bounds that LBFix does to lower bounds. The following Lemma justifies this assertion and the cases used in the proof are shown in Figure 7:\nLemma 3. After UBFix is invoked either\n• all upper bounds of the argument variables are supported w.r.t. the UM-3-BCZ constraint and no supported values are removed, or\n• a domain is null as a result of removing unsupported values.\nProof. Let S, M and L be the domains with smallest, middle and largest upper bounds, breaking ties arbitrarily. Let s, m and l be these upper bounds.\nFirst we will prove that in case 1 (Figure 7) the shaded region in M is supported if and only if L ∩b S 6= ∅: Potentially, the bound can be supported by\n• equal values in S and L at least as small as it (i.e., S ∩b L 6= ∅), or\n• an equal value in either S or L, and a value at least as large in the remaining domain.\nHowever, notice that the latter is impossible due to the fact that only L contains an equal value, and S has no value as large as this.\nSimilar arguments can establish that the shaded regions in L in case 1, M in case 3 and L in case 3 are supported if and only if M ∩bS 6= ∅, L∩bS 6= ∅ and M ∩bS 6= ∅, respectively.\nNow we will establish the Lemma for each of the cases 1, 2, 3 and 4:\nCases 2 and 4 The condition on line A4 is false, and so no domains are changed. The upper bounds are mutually supportive in each case.\nCase 1 and shaded region of M is unsupported From above L ∩b S = ∅. Hence UBFix line A4.2 will be executed and the unsupported region removed. Now the upper bounds l ∈ L, s ∈ M and s ∈ S are mutually supportive.\nCase 1 and shaded region of M is supported From above L∩bS 6= ∅. If the shaded region of L is also supported then M ∩b S 6= ∅ and so neither line A4.2 nor A4.4 is executed and no changes are made to the domains. The upper bound of S is also supported, by m ∈ L, m ∈ M and s ∈ S. If the shaded region of L is not supported then M ∩b S = ∅ and so line A4.4 is executed resulting in the removal of the region. The new bounds s ∈ S, m ∈ M and s ∈ L are mutually supportive.\nCase 3 and shaded regions of M and L supported From above, L ∩b S 6= ∅ and M ∩b S 6= ∅. Hence no domain changes result from executing UBFix. l ∈ L and s ∈ S are supported by l ∈ L, s ∈ M and s ∈ S. m ∈ M is supported by s ∈ L, m ∈ M and s ∈ S.\nCase 3 and shaded regions of M and L are unsupported From above, L∩bS = ∅ and M ∩b S = ∅ and so line A4.2 of UBFix is executed and this results in M becoming null.\nCase 3, shaded region of M supported but shaded region of L not supported From above L∩bS 6= ∅ and M ∩bS = ∅, so that A4.4 is executed to remove the unsupported region. The new bounds of s ∈ S, m ∈ M and s ∈ L are mutually supportive.\nCase 3, shaded region of L supported but shaded region of M not supported Symmetric with previous case.\nNote that there is no analog of Lemma 1 for upper bounds since, for example, the bounds of x = {1, 2, 3}, y = {1, 2} and z = {1} are all supported, but not mutually supportive."
    }, {
      "heading" : "3.2.2 The Propagation Algorithm",
      "text" : "Having presented LBFix and UBFix we are now in a position to present the complete propagation algorithm. The propagator works with arbitrary domains and it enforces BC(Z), except when a domain becomes empty, in which case it does no further work. The algorithm is described by the action taken when any of three domain events occur:\nmin The domain has lost its lower bound since propagator was last invoked.\nmax The domain has lost its upper bound since propagator was last invoked.\nfix The domain is a singleton, i.e., the variable is instantiated and upper and lower bounds are equal.\ni.e. we only consider events on the bounds of the variables. The algorithm is listed in lines A5-A9 of Figure 5. Intuitively these procedures work because, as we will show, a change to an upper bound can affect the support for other upper bounds, but a change in a lower bound can affect support for both lower and other upper bounds. Hence we need only run LBFix when a lower bound may have changed, but UBFix must be run for a change of either lower or upper bounds. Whilst it would be correct to cycle between trimming upper and lower bounds until a fixed point is reached (i.e. no more changes occur), we can guarantee a fixed point more easily.\nLemma 4. It is possible for a change in a lower bound to result in the loss of support for another lower bound.\nProof. All the bounds in the diagram have support, but when the black shaded lower bound is lost the dark gray shaded lower bound loses support.\nLemma 5. It is possible for a change in a lower bound to result in the loss of support for an upper bound.\nProof. All the bounds in the diagram have support, but when the black shaded lower bound is lost the dark gray shaded upper bound loses support.\nLemma 6. It is possible for the loss of an upper bound to cause the loss of support for another upper bound.\nProof. All the bounds in the diagram have support, but when the black shaded upper bound is lost the dark gray shaded upper bound loses support.\nCorollary 1. It is impossible for a change in an upper bound to result in the loss of support for a lower bound.\nProof. By Lemma 1 a lower bound retains support as long as the other lower bounds are intact, hence losing an upper bound has no effect.\nWhy the asymmetry between upper and lower bounds? It is due to the asymmetry in the definition of UM-3-BCZ and has the practical repercussion that BC(Z) lower bounds must be mutually supportive whereas BC(Z) upper bounds may not be and may require support from other values including lower bounds.\nCorollary 1 suggests that a further improvement on the algorithm in Figure 5 is to execute Line A6 and A9 if and only if any lower bound lost is the only remaining support for an upper bound. However, the conditionals intrinsic in UBFix amount to much the same thing and there is little point in repeating them.\nThe point of these theorems has been to build up a complete proof of correctness and BC(Z) status:\nTheorem 1. The code for min, max and fix events listed in Figure 5 does not remove any values involved in bound supports for the UM-3-BCZ constraint, and, if all the domains are non-null after propagation, the resultant domains will be BC(Z).\nProof. First we must establish that no values are removed during propagation that could be involved in a support, and that the result domains are subsets of the input domains. The former is immediate from Lemmas 2 and 3, because values are only removed as a result of executing LBFix and UBFix. The latter is immediate from inspection of LBFix and UBFix, because they only ever make lower bounds larger and upper bounds smaller.\nThe final thing to establish is that BC(Z) is enforced, unless a domain becomes null. If any domain becomes empty as a result of running the algorithm then the Theorem is trivially true. If no domain becomes empty then we must show that all the bounds are supported. For lower bounds, by Lemma 4 and Corollary 1 we know that only the loss of a lower bound can result in the need to change a lower bound during propagation. Lower bounds can change as a result of either fix or min events, hence the propagator in Figure 5 runs LBFix in either event. When LBFix runs it leaves all lower bounds supported, as was shown in Lemma 2. For upper bounds, by Lemmas 5 and 6 we know that the loss of either a lower or upper bound can result in the loss of an upper bound. Hence upper or lower bounds can change as a result of any event, and lower bounds can also change as a result of LBFix, hence the propagator runs UBFix in all events, and it runs after LBFix has finished, if necessary. When UBFix runs it leaves all upper bounds supported provided no domain becomes empty, as was shown in Lemma 3.\nThe propagation algorithm runs in Θ(1) time. This is because all of the operations in LBFix, UBFix, min, max and fix events are Θ(1), provided that our domain representation allows access to the upper and lower bounds in Θ(1). This can be guaranteed if domain reductions only occur at the bounds, as is the case here, or if domains are represented using one of the structures proposed by van Hentenryck et al. (1992)."
    }, {
      "heading" : "3.3 Entailment",
      "text" : "Schulte and Carlsson (2006) define entailment as when all possible constractions of the domains in a constraint’s scope are consistent. If we can detect that this has happened we can stop running the propagator henceforth, since it cannot prune any more values.\nDefinition 5. A propagator is entailed by domains D = {d1, . . . , dn} when any set of domains that are subsets of these, i.e., any E = {e1, . . . , en} s.t. ∀i.ei ⊆ di, are at a fixed point.\nWe now describe a sufficient condition for the UM-3-BCZ constraint to be entailed, i.e., the UM-3-BCZ constraint becomes entailed as soon as two variables have singleton domains:\nTheorem 2. UM-3-BCZ becomes entailed as soon as two variables have singleton domains.\nProof. Consider the possible scenarios: either the two singletons are the same (case (a) in Figure 8) or they are distinct (case (b) in Figure 8). The domains before propagation are shown in Figure 8 as boxes; the domains after propagation are shaded gray. Clearly all remaining choices for the third variable are valid instantiations and since the propagation algorithm is safe they cannot be removed by further propagation and by definition the propagation will be at a fixed point."
    }, {
      "heading" : "3.4 Ultrametric Matrix Constraint",
      "text" : "The supertree model presented in Section 4 makes use of the ultrametric constraint, however in this context the desired end product is to constrain a whole matrix to be an ultrametric matrix, and not merely to constrain three variables.\nDefinition 6. A symmetric matrix M is an ultrametric matrix if and only if for every set of three distinct indices i, j and k, there is a tie for the minimum of Mij , Mik and Mjk; and Mii = 0 for all i.\nThe ultrametric matrix constraint can be achieved for matrix M by posting the constraint UM-3-BCZ(Mij ,Mik,Mjk) over all choices of distinct i, j and k, but at a cost of introducing\n( n 3 ) constraints. In practical constraint solvers any model containing this con-\nstraint will have Ω(n3) space complexity, since the solver must have a list of all Θ(n3) constraints stored somewhere. However, when a domain event occurs for any matrix variable Mij it is straightforward to iterate over all k indices doing the same propagation as UM-Matrix-BCZ from Figure 5. This replaces a Θ(n3) space list representation of the set of UM-3-BCZ constraints by a Θ(1) code representation. Hence we propose the ultrametric matrix constraint propagator UM-Matrix-BCZ in Figure 9.\nThis propagator mimics part of the AC3 algorithm (Mackworth, 1977) since it (a) receives a propagation event on a variable, (b) identifies which constraints are over that variable, and (c) arranges for the propagation to be carried out. Any events caused as a result are queued and dispatched by the underlying propagator as normal and this may cause UM-Matrix-BCZ to be run again. Each variable can be involved in up to n − 2 constraints, since each variable has two indices in the matrix and we have a constraint involving each choice of three different indices.\nThe algorithm propagates in Θ(n) time, which is more expensive per event than using ( n 3 ) Um-3 constraints, but a factor of n fewer propagators wake up as a result of each event."
    }, {
      "heading" : "4. Supertree Construction",
      "text" : "We now review imperative solutions to the supertree construction problem, review the first constraint programing solution (Gent et al., 2003), and present a new encoding that exploits the specialised UM-Matrix-BCZ constraint."
    }, {
      "heading" : "4.1 Imperative Solutions to the Supertree Problem",
      "text" : "The earliest imperative techniques are due to Bryant and Steel (1995) and Ng and Wormald (1996). Both present a OneTree algorithm which is based on the Build algorithm of Aho, Sagiv, Szymanski, and Ullman (1981). OneTree is based on the observation that in a tree any three leaf nodes define a unique relation with respect to their most recent common ancestor (mrca), such that mrca(a, b) is the interior node furthest from the root that has both leaf nodes a and b as descendants. We abuse notation by writing mrca(a, b) > mrca(c, d) when the former has a greater depth than the latter, and similarly mrca(a, b) = mrca(c, d) if they have the same depth. Given three different leaf nodes/species (labelled a, b, and c) one of the following four relations must hold:\n(1) mrca(a, b) > mrca(a, c) = mrca(b, c)\n(2) mrca(a, c) > mrca(a, b) = mrca(c, b)\n(3) mrca(b, c) > mrca(b, a) = mrca(c, a)\n(4) mrca(a, b) = mrca(a, c) = mrca(b, c)\nWe now say that in (1), (2) and (3) we have the triples (ab)c, (ac)b, and (bc)a (where (xy)z can be read as “x is closer to y than z”) and in (4) we have the fan (abc), i.e., in a fan the relationship between species is unresolved as we dont specify which pair is most closely related. This is shown in Figure 10. Prior to applying the OneTree algorithm two (or more) species trees are broken up into triples and fans using the BreakUp algorithm (Ng & Wormald, 1996), resulting in a linear sized encoding of those trees. The supertree is then constructed (if possible) using this encoding as input.\nFigure 11 shows an example of the BreakUp algorithm process. Two variants of the process are shown; at the top we have a hard breakup, where fans are considered as hard evidence that must be respected (hard polytomies as described by Ng and Wormald, 1996) and below a soft breakup where fans are taken as a lack of evidence (soft polytomies as described by Bryant and Steel, 1995). For hard breakup the algorithm is modified such\nthat when encountering a k−fan this is broken up into ( n 3 ) 3-fans, and in a soft breakup a fan is broken into a linear number of rooted triples. Algorithms for hard and soft breakups are given in Figures 12 and 13, and are used by the imperative OneTree algorithm here and the constraint programming models.\nA toy set of input triples and single solution are shown in Figure 14. The triples have been drawn to reflect how the solution is compatible with them.\nNg and Wormald (1996) give the complexity of OneTree as O(h(n)) where h(n) = n(n+ t+ bn)α(n+ t+ f), n is the number of labels, t the number of triples, f the number of fans, b is the sum of the squares of the number of leaves in the fans, and α is the inverse Ackermann function (and is less than 4 for all conceivable inputs and so behaves like a constant). Therefore if the input trees are fully resolved (i.e., have no fans) then running\ntime complexity is O(n2) but in the worst case complexity grows to O(n4). This should be contrasted with the O(t · n) complexity of Bryant and Steel’s OneTree (1995)."
    }, {
      "heading" : "4.2 A Constraint Encoding using Toolkit Constraints",
      "text" : "This second stage, i.e., OneTree equivalent, was first solved as a constraint program by Gent et al. (2003). The encoding takes advantage of an equivalence between ultrametric trees and ultrametric matrices:\nDefinition 7. Let M be a real symmetric n × n matrix. An ultrametric tree for M is a rooted tree T such that:\n1. T has n leaves, each corresponding to a unique row of M;\n2. each internal node of T has at least 2 children;\n3. for any two leaves i and j, Mij is the label of the most recent common ancestor of i and j; and\n4. along any path from the root to a leaf, the labels strictly increase.\nTheorem 3. A symmetric matrix M has an ultrametric tree T if and only if it is an ultrametric matrix. Furthermore, the tree T uniquely determines the matrix M and the matrix M uniquely determines the tree T .\nProof. A proof is given by Gusfield (1997).\nThere is a clear correspondence between Definition 7 and the description of a species tree given in Section 4: a species tree T is an ultrametric tree for matrix M , where Mij is the depth of the mrca of species i and j or Mij is the divergence date of those two species. For this reason we can use an ultrametric matrix model to solve the supertree problem."
    }, {
      "heading" : "4.2.1 The Model of Gent et al.",
      "text" : "Given as input a forest F with n distinct leaf labels, a symmetric n × n matrix M of constrained integer variables is created with domains {1, . . . , n − 1} or {0} on the main diagonal. Variable Mij is the depth of the mrca of species i and j. Initially, constraints are posted to make the whole matrix ultrametric thus ensuring that any resulting tree is ultrametric:\nMij > Mik = Mjk ∨ Mik > Mij = Mjk ∨ Mjk > Mij = Mik ∨ Mij = Mik = Mjk\n(2)\nfor each i < j < k. The input trees are then broken up into triples and fans using either of the breakup algorithms of Figures 12 and 13. For each triple (ij)k produced the constraint\nMij > Mik = Mjk (3)\nis posted and for each 3-fan (ijk)\nMij = Mik = Mjk (4)\nis posted. These constraints break the disjunctions of Equation 2. The model has (n2−n)/2 variables and\nt+ f +\n( n\n3\n)\n= O(n3) +O(n3) + Θ(n3) = Θ(n3) (5)\nconstraints, where t is the number of triples and f the number of fans. There are O(n3) of each because each one breaks the disjunction in at most one constraint from Equation 2, and there are Θ(n3) of those."
    }, {
      "heading" : "4.2.2 Converting Back to Tree Representation",
      "text" : "The final step is to use an algorithm based on the constructive proof by Gusfield (1997) of the ⇐ direction of Theorem 3 to build a tree from the matrix M produced by a constraint solver. We will not describe this algorithm in detail, but for the sake of intuition it works as follows\n• Pick an arbitrary leaf s. Let the number of distinct entries in row s be d.\n• Partition the other leaves into sets p1, . . . , pd based on their entry in row s.\n• Solve the problem recursively on each pi by ignoring all the rows and columns in the matrix D not in pi.\n• Combine into overall solution by attaching subproblem solutions at the correct depth on the path to s.\nFigure 15 shows one recursion of the algorithm with a choice of leaf a and shows that row a fully describes the path to a in the corresponding tree."
    }, {
      "heading" : "4.2.3 Time Complexity of the Model of Gent et al.",
      "text" : "BreakUp, and the procedures to build a constraint model and to convert an ultrametric matrix to a tree are all polynomial time. However the complexity of backtracking search over O(n2) variables with O(n)-size domains is worst case O(nn 2\n). This is an upper bound on the time taken to solve the supertree problem. We have not attempted to derive a lesser upper bound on the time complexity, since, as we will show in the following section, our new model has provably achieved a polynomial time bound."
    }, {
      "heading" : "4.3 A Constraint Encoding Using the New Propagator Design",
      "text" : "This issue of potentially exponential solution time model of Section 4.2 is worrying, but in our experiments the time taken to solve instances has not been a major issue. Conversely the memory requirements are a problem in practice, but not in theory! The model requires Θ(n3) space for n species, but the constant factor is inhibiting. Posting the constraint of Equation 1 literally (using toolkit propagators) as described in Section 3 uses 23 propagators in the JChoco toolkit. This requires roughly 23 times the runtime memory of a single propagator, since each corresponds to a single Java object, and each of these have comparable footprints. As we will show in the empirical study of Section 5, this prevents modest instances from being loaded on typical current workstations.\nUsing the new propagator of Section 3 we replace these ( n 3 ) propagators with a single compact propagator and as a result memory usage is reduced asymptotically from Θ(n3) to Θ(n2) since now the model memory is dominated by the Θ(n2) space needed for the matrix M . Also reducing the amount of space to be initialised delivers a proportional saving in build time. But most importantly, using the new constraint provides a solution to exponential time complexity, because enforcing BC(Z) on the model allows a solution to be read out of the lower bound of each domain. Theorem 4 is a proof of correctness for this algorithm.\nFigure 16 gives a schema for the constraint programming algorithm for supertree construction, CPBuild. The algorithm takes as input a forest F of trees. In line 1 a constraint model is produced, i.e., an n × n symmetric array of constrained integers variables is created, where there are n unique species in the forest, and the UM-Matrix-BCZ constraint is then posted over those variables. Lines 2 and 3 breaks these input trees into their triples and fans using either of the breakup algorithms given in Figures 12 and 13, and posts them into the model as constraints. Propagators for the constraints are executed to a fixed point in line 4; if this succeeds a tree is created from the lower bounds of the ultrametric matrix otherwise we fail.\nLemma 7. If the propagator for every constraint in a model enforces BC(Z) and furthermore the lower bounds are mutually supportive, then after executing all propagators to a fixed point, either the lower bounds are a solution, or we have an empty domain and fail.\nProof. If we reduce each domain to just the lower bound after a fixed point is obtained then each bound is supported because they are mutually supportive by supposition. Hence every constraint is simultaneously satisfied by these singleton domains and, by definition, we have a solution.\nTheorem 4. CPBuild is a polynomial time solution to the supertree problem.\nProof. The only constraints involved in the model are those for triples and fans and ultrametric constraints. By Theorem 1 we know that all lower bounds are supported after the propagators run, and by Lemma 1 we know that the lower bounds are mutually supportive. The same is true of the disjunction-breaking propagators. Hence by Lemma 7, and as shown in Figure 16, we can either read out a solution or fail. We can enforce BC(Z) on the problem in polynomial time as shown below.\nImmediate from this is that we can preserve the polynomial time solution with the addition of a polynomial number of side-constraints, so long as these additional constraints preserve the property that lower bounds are mutually supportive. In fact, CSPs such as these with ordered domains where all constraints have the property that lower bounds are mutually supportive belong to a known tractable class called min-closed (Jeavons & Cooper, 1995)."
    }, {
      "heading" : "4.3.1 Time Complexity of CPBuild",
      "text" : "The algorithm can be implemented to run in O(n4) time using a variation on the AC3 algorithm. AC3 (Mackworth, 1977) begins with a queue containing all constraints. It repeatedly removes a constraint until none remain and runs the associated propagator. Any constraints over affected variables are re-queued, if necessary. Once the queue empties, all propagators are at a fixed point. We need O(n3) constraints so the worst case complexity is\nO(n3) ︸ ︷︷ ︸\nbuild initial Q\n+ O(n)O(n3) ︸ ︷︷ ︸\nworst case re-queues with 1 value removed at a time\n. O(1) ︸ ︷︷ ︸\npropagation time\nor O(n4) overall. This matches the worst case complexity of OneTree (Ng & Wormald, 1996). Our constraint solution has its worst case when the problem is unsolvable, since when it is unsolvable domains are emptied by propagation, whereas for solvable instances propagation reaches a fixed point sooner."
    }, {
      "heading" : "5. Empirical Study",
      "text" : "We present an empirical study to determine if any practical improvements have been achieved in constraint solutions to the supertree problem and, if so, what size of improvement. Experiments were run using a 1.7GHz Pentium 4 processor with 768MB of memory, using Sun Java build 1.5.0 06-b05. The constraint toolkit used was JChoco version 1.1.04.\nInput trees were broken up using a hard breakup, consequently in all cases fans were treated as hard polytomies2.\nOur benchmark is real-life seabird data previously used by Kennedy and Page (2002) and Beldiceanu et al. (2008) and we present statistics on various techniques for producing supertrees, namely OneTree, and the CP solutions of Section 4 (entries Toolkit and CPBuild). For completeness we reproduce the results of Beldiceanu et al. (2008) over the same data set, and tabulate this as TreeCon. TreeCon uses a single-successor model, where constrained integer variables represent nodes within a tree, and domains correspond to possible successors3. A unique variable represents the root and loops on itself (i.e., vroot = root), and leaf nodes have an indegree of zero. Precedence and incomparability constraints are then generated from the input trees.\nThe TreeCon results were encoded in the same constraint programming toolkit as ours but on a processor that was approximately twice as fast (3GHz). We do not correct the times to compensate for this factor. We mark in bold results that differ very significantly between the CPBuild and TreeCon results, specifically those whose runtimes would undoubtedly be a factor of 10 different on the same processor. Results are reported for combinations of seabird trees (input trees named A to G) and the following data is tabulated below:\nData The combination attempted.\nn Total distinct species in input trees\nSol T iff supertree is possible\nTechnique Type of algorithm used to solve\nBuild Time in milliseconds to initialise CP model\nSolve Time in milliseconds to first solution, if any\nTotal = Build + Solve\nNodes Number of nodes in search tree\nMem Model memory in MB\nIn the table, DNL means that the model could not be loaded (as it was too large) and DNF means that it could not be solved within 30 mins, but succeeded in loading. We have not provided the memory usage of OneTree; however it is smaller than that of any of the constraint encodings.\nThe most obvious thing to note is how much faster the imperative approach is compared to the constraint techniques. Why is this? Primarily it is due to the lower complexity of OneTree in the absence of fans (we have not investigated if we can benefit from this), and partly due to the generality of the constraint programming approach. The imperative approach is highly specialised to only one class of problem whereas the constraint approach sits within a toolkit, and runs on top of a general purpose constraint maintenance system. We should not expect that the constraint approach will compete in raw speed but what we later demonstrate (in Section 6) is that the approach benefits from its versatility, i.e., the\n2. In a later section we use soft breakup. 3. An alternative constraint model of a tree might use 0/1 variables corresponding to potential edges\nwithin an adjacency matrix (Prosser & Unsworth, 2006), or indeed the CP(Graph) computation domain (Dooms, 2006).\ncosts of space and time is repaid by the ease of accommodating variants of the problem into the same model.\nData n Sol Technique Build Solve Total Nodes Mem AB 23 T Toolkit 2056 374 2430 23 26.92\nCPBuild 183 131 314 23 0.24 TreeCon 302 OneTree 13\nAC 32 F Toolkit 2670 327 2997 0 36.34 CPBuild 189 153 342 0 0.34 TreeCon 406 OneTree 12 AD 47 T Toolkit 8235 946 9181 38 118.51 CPBuild 220 248 468 38 0.70 TreeCon 398 OneTree 22 AE 95 F Toolkit DNL DNL DNL DNL > 629 CPBuild 340 1477 1817 0 2.79 TreeCon 10393 OneTree 37 AF 31 T Toolkit 2497 379 2876 19 32.99 CPBuild 188 137 325 18 0.32 TreeCon 127 OneTree 20 AG 46 T Toolkit 7671 871 8542 31 111.07 CPBuild 222 252 474 31 0.68 TreeCon 409 OneTree 21 BC 29 F Toolkit 2056 21931 23987 171 26.90 CPBuild 171 107 278 0 0.27 TreeCon 32 OneTree 8 BD 42 T Toolkit 5833 930 6763 33 84.26 CPBuild 201 251 452 33 0.55 TreeCon 301 OneTree 17 BE 94 F Toolkit DNL DNL DNL DNL > 629 CPBuild 335 16340 16675 0 2.71 TreeCon 892 OneTree 11 BF 30 T Toolkit 2405 343 2748 29 29.83 CPBuild 174 99 273 29 0.28 TreeCon 144 OneTree 8 BG 40 T Toolkit 5098 651 5749 30 72.71 CPBuild 203 353 556 30 0.51 TreeCon 1440 OneTree 13 CD 45 T Toolkit 10056 1134 11190 45 143.91 CPBuild 224 276 500 45 0.77 TreeCon 630 OneTree 14 CE 68 T Toolkit DNL DNL DNL DNL > 629 CPBuild 516 1451 1967 68 2.72 TreeCon 27180 OneTree 36 CF 34 T Toolkit 3101 563 3662 30 43.72 CPBuild 180 133 313 30 0.36 TreeCon 393 OneTree 11 CG 44 F Toolkit 6683 587 7270 0 97.10 CPBuild 210 215 425 0 0.61 TreeCon 1530\nOneTree 14 DE 104 F Toolkit DNL DNL DNL DNL > 629\nCPBuild 360 2021 2381 0 3.31 TreeCon 1126 OneTree 34\nDF 44 T Toolkit 6613 987 7600 37 97.10 CPBuild 203 250 453 37 0.60 TreeCon 630 OneTree 17 DG 56 F Toolkit 14090 2280 16370 1 201.42 CPBuild 252 640 892 0 0.99 TreeCon 910 OneTree 19 EF 94 F Toolkit DNL DNL DNL DNL > 629 CPBuild 331 9546 9877 0 2.71 TreeCon 1035 OneTree 12 EG 97 F Toolkit DNL DNL DNL DNL > 629 CPBuild 344 8900 9244 0 2.89 TreeCon 1211 OneTree 15 FG 38 F Toolkit 4299 DNL DNL DNL 61.41 CPBuild 195 212 407 0 0.46 TreeCon 62 OneTree 10 ABDF 72 T Toolkit 27032 5291 32323 63 382.52 CPBuild 277 722 999 59 1.48 TreeCon 8139 OneTree 34 ABDG 78 F Toolkit 60847 DNF DNF DNF 553.49 CPBuild 301 3633 3934 0 1.91 TreeCon 347 OneTree 29 ACDF 72 F Toolkit 31067 1931 32998 0 434.84 CPBuild 286 649 935 0 1.61 TreeCon 8690 OneTree 28 ACDG 81 F Toolkit DNL DNL DNL DNL > 629 CPBuild 307 1711 2018 0 2.06 TreeCon 12650 OneTree 35 ACE 97 F Toolkit DNL DNL DNL DNL > 629 CPBuild 737 1632 2369 0 2.91 OneTree 38\nThe most impressive aspect of the matrix model of Section 4.3 over that of Section 4.2 is the improvement in memory requirements, so that all instances can now be loaded comfortably. This also has a dramatic impact on the build time. These improvements dominate the reduction in solve time in practice. The toolkit model is outperformed by CPBuild by an order of magnitude on each instance; moreover, there are two cases of search occurring in the toolkit model (on data sets BC and ABDG) whereas CPBuild never has to search. The polynomial time complexity is due to the provable absence of search.\nOur results also compare well against those of Beldiceanu et al. (2008). There is one case, BE, where CPBuild is an order of magnitude slower than TreeCon; so far we do not have an explanation for this. There are four cases when TreeCon is significantly worse than CPBuild. No results are available for TreeCon over the data set ACE. It should be noted that Beldiceanu et al. do not yet have a complete filtering algorithm for this problem based on their constraint model and, from personal communication, although the TreeCon\nmodel never backtracked over the birds data set there is as yet no proof that the complexity of their model is polynomial. It should also be noted that we see CPBuild taking more time on unsolvable instances than solvable instances, as predicted.\nFigure 17 shows the supertree, displayed with treeView (Page, 1996), produced from the largest compatible forest {A,B,D,F}. This supertree has 72 leaves and takes about 1 second to produce. Although the result is not printed in the table, finding the forest {A,B,C,D,E, F,G} incompatible takes about 12 seconds in total (1.5 seconds to build the model and 10 seconds to determine incompatibility)."
    }, {
      "heading" : "6. Versatility of the Constraint Model",
      "text" : "One of the strengths of constraint programming is its versatility: given a constraint model of a core problem this model can then be enhanced to address variants of the original pure problem. We demonstrate this versatility with respect to the ultrametric model, presenting four variants of the supertree problem (a) incorporating ancestral divergence dates into the model, (b) nested taxa, (c) determining if an induced triple or fan is common to all supertrees, and (d) coping with incompatibilities."
    }, {
      "heading" : "6.1 Ancestral Divergence Dates",
      "text" : "Semple et al. (2004) and Bryant et al. (2004) add temporal information to the input trees. Interior nodes may be labelled with integer ranks such that if interior node v2 is a proper descendant of v1 then rank(v1) < rank(v2), resulting in a ranked phylogenetic tree. Additionally relative divergence dates may be expressed in the form “div(c,d) predates div(a,b)” and this is interpreted as “the divergence of species c and d predates that of species a and b”. The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations. The algorithm outputs a ranked tree that respects those relations or returns “not compatible”.\nThis is trivial to incorporate into the constraint model. If trees have been ranked then for each pair of species (i, j) in the leaf set we instantiate the constrained integer variable Mij to the value of mrca(i, j). For a predates relation “div(c,d) predates div(a,b)” we post the constraint Mcd < Mab. This is done before step 4 of CPBuild (Figure 16), i.e., ranks and predates relations become side constraints. Similarly time bounds on speciation events are posted as unary constraints, i.e. in a dated phylogenetic tree upper and lower divergence bounds are given on interior nodes, such that l(a, b) and u(a, b) give respectively the lower and upper bounds on the divergence dates of species a and b. In the constraint program the following two side constraints are then posted (again, before step 4): l(a, b) ≤ Mab and Mab ≤ u(a, b).\nA demonstration of ranked trees is given in Figure 18. On the left we have two ranked species trees of cats used recently by Semple et al. (2004) and originally by Janczewski, Modi, Stephens, and O’Brien (1995). The branch lengths of the source trees have been translated into rankings and added to the interior vertices of those trees. On the right we have one of the 17 possible resultant supertrees. In total, 7 of the 17 solutions contain interior nodes with ranges. If interior nodes are labelled with specific values rather than ranges then 30 solutions are produced, some of which are structurally identical. This goes some way to addressing the issue of enumerating all supertrees compactly, raised as a challenge by Semple et al. (2004). In Figure 19 we show the effect of adding a predates constraint to a supertree construction. The data has previously been used by Bryant et al. (2004) in their Figures 5 and 6."
    }, {
      "heading" : "6.2 Nested Taxa",
      "text" : "A taxon (plural, taxa) is a group of organisms comprising a single common ancestor and its descendents (Dawkins & Wong, 2004). For example the species “lion” and the class “birds” are taxa. So far, all our species trees have been leaf-labelled, however this is restrictive\nbecause trees may be annotated with taxa names on both leaves and internal nodes, giving nested taxa. For example, Figure 20 shows tree T1 with an internal node labelled P which has descendents a and b, i.e., the a and b taxa are nested within the P taxon. Problems related to creating compatible supertrees for this type of data were raised by Page (2004) and defined and solved by Daniel and Semple (2004). A set of input trees and possible solution to the problem are shown in Figure 20: notice that all labels are conserved in the solution, all ancestral relationships are conserved and, for any labels li and lj from the same input tree, li is ancestor of lj in the input tree if and only if li is ancestor of lj in the solution tree. This is an instance of the problem Higher Taxa Compatibility defined by Daniel and Semple (2004) and Semple et al. (2004), where the result tree must perfectly display all of the input trees. We now define the problem more formally.\nDefinition 8. A rooted X-tree (Daniel & Semple, 2004) is a species tree where internal nodes as well as leaves may be labelled from the set X.\nIn the following we will be slightly loose and may use a label l to identify the labelled node, as well as the label itself, e.g., “descendants of l” means the same as “descendants of the node labelled l”.\nDefinition 9. A rooted X-tree T perfectly displays a rooted X ′-tree T ′ when\n1. X ′ ⊆ X;\n2. T ′ displays T , neglecting internal labels;\n3. if a is a descendant of b in T ′ then a is a descendant of b in T ; and\n4. if a is not a descendant of b in T ′ then a is not a descendant of b in T .\nA rooted X-tree T perfectly displays a forest of phylogenetic trees F = {T1, . . . , Tn} when it perfectly displays every Ti."
    }, {
      "heading" : "6.2.1 Constraint Encoding",
      "text" : "Our constraint encoding is implemented by the addition of variables and side constraints to the standard model of Section 4. We describe how to transform the input to make the constraint solution simpler, and then describe the variables and constraints needed.\nSubstitution Taxon P in Figure 21 appears on an internal node of T1, we will call such a label an enclosing taxon. Note also that it appears on a leaf in T2. The input trees are preprocessed to replace any tree with an enclosing taxon P on a leaf by the same tree with any single subtree rooted at P substituted in its place. There must be such a subtree elsewhere in the input forest, or we have a contradiction that M is an enclosing taxon. This process does not add or remove any information, since the relationships between M and everything in the tree still holds, and the new relationships between the taxa in the subtree at M and the rest of the tree were always implicit in the input.\nThe aim of this process was just to obtain a set of inputs where enclosing taxa appear on internal nodes only, because without loss of generality our constraint encoding assumes that this is the case. Figure 21 shows an example of the substitution process applied to trees T1 and T2, and T2 would be replaced with T ′ 2.\nVariables and constraints The variables added are one integer variable vl per enclosing taxa/label l, each with a domain of {1, . . . , n− 1}. The value of this variable in a solution is the tree depth of the internal node which it labels, and the label’s position in the final tree is determined because it must be at the unique node of that depth on a path from one of its nested taxa to the root. See Figure 15 and suppose for the sake of argument that we have an enclosing taxa M which labels b, and the variable lM = 1 in a solution. The unique location where the label M can go is at the root node.\nProperties (1) and (2) from Definition 9 above are immediate from the properties of the earlier model which is the foundation for this one. Before explaining how to enforce property (3) we introduce some notations for convenience. Function desc(l, F ) returns the set of all descendants of label l in any tree T in the forest F , and notDesc(l, T ) returns the set of labels that are not descendants of l in tree T .\nWe first need a constraint that l must label every single species that it labels in an input. For every enclosing label l, post the following set of constraints:\n{vl ≤ Mij | i ∈ desc(l, F ) ∧ j ∈ desc(l, F ) ∧ i 6= j} (6)\nso that the label must settle at least as shallow as any mrca of its descendants in input, and hence they must remain descendants. Notice that it is necessary to consider pairs of species from distinct input trees. An alternative of taking pairs from the same tree does not work, because it is necessary for all pairs to be under the same internal node l, rather than two\ndistinct nodes that happen to be at the correct depth. Next, the label must be constrained so that no label that was not already a descendant becomes one. For each X-tree T and enclosing label l ∈ X, post the following set of constraints:\n{vl > Mij | i ∈ desc(l, {T}) ∧ j ∈ notDesc(l, T )} (7)\nso that the label l must be placed strictly deeper than any mrca of a descendant and something that’s not a descendant, i.e., no non-descendents of l can be a descendent in the result. As an illustration we list the generated constraints for the example of Figure 20.\n1. Equation 6 and l = P : {vP ≤ Mab, vP ≤ Mag, vP ≤ Mbg}\n2. Equation 6 and l = Q: {vQ ≤ Mde, vQ ≤ Mdf , vQ ≤ Mef}\n3. Equation 7, l = P and T ∈ {T1, T2}: {vP > Mac, vP > Mad, vP > Mae, vP > Mbc, vP > Mbd, vP > Mbe, vP > Mgf , vP > Mgd, vP > Mge, vP > Mbf}\n4. Equation 7, l = Q and T ∈ {T1, T2}: {vQ > Mad, vQ > Mae, vQ > Mbd, vQ > Mbe, vP > Mcd, vQ > Mce, vQ > Mgf , vP > Mbf , vP > Mgd, vP > Mge}\nThe number of new constraints created by both Equations 6 and 7 is bounded by the number of distinct pairs of species, i.e. Θ(n2) new constraints."
    }, {
      "heading" : "6.3 Necessity",
      "text" : "There may be many possible supertrees for a given input forest. One question is then, what relationships are common to all supertrees? The problem of determining if a derived induced triple (or fan) in a supertree is necessary (i.e., common to all possible supertrees) is introduced by (Daniel, 2003) along with the polynomial time decision procedureNecessity.\nThe algorithm Necessity in Figure 22 takes as arguments a forest F of trees, assumed to be compatible, and a rooted triple or fan τ and determines if τ occurs in every supertree that displays the trees in F . The algorithm is a simple modification of CPBuild, where lines 1 to 3 are essentially the same. In line 4 the negation of the triple τ is posted to the problem, where ¬τ is posted as\nMik 6= Mjk ∨Mij ≤ Mik ∨Mij ≤ Mik (8)\nwhen τ = (ij)k and posted as\nMij 6= Mik ∨Mij 6= Mjk ∨Mik 6= Mjk (9)\nwhen τ = (ijk). A call is then made to propagate to make the problem arc-consistent (line 5), and if this fails then τ is necessary, otherwise it is not necessary. The algorithm has the same complexity as CPBuild."
    }, {
      "heading" : "6.4 Coping with Conflict",
      "text" : "When a supertree cannot be produced from a pair of trees some of the input triples and fans must be in conflict with one another, either directly or indirectly. Junker’s quickXPlain method (Junker, 2004) discovers a minimal subset of constraints that when posted and propagated result in a failure. This set is not necessarily the smallest possible set but is\nminimal in the sense that the removal of any element from this set will not constitute a sound explanation, and the addition of any constraint would be redundant. When the set of constraints are input triples and fans, this minimal set is semantically a collection of input data that is incompatible. Junker (2004) state that this method can be achieved by a worst case of 2k · log2(n/k) + 2k propagations\n4, where k is the size of the minimal explanation found and n is the number of constraints.\nAn alternative approach is to satisfy as many of the input triples and fans as is possible within a reasonable amount of time, i.e., polynomial time. Semple and Steel propose such an algorithm, MinCutSupertree (2000), and this has been refined by Page (2002). We now propose a similar scheme within the constraint programming framework. We call this algorithm GreedyBuild and it works as follows. We associate a constrained integer variable x, with a domain of {0, 1}, to each triple and fan. If the variable is assigned the value 0 then the triple (or fan) is respected, otherwise it is ignored. Therefore for a triple (ij)k we post the constraint of equation 10 and for a 3-fan (ijk) the constraint of equation 11.\n(x = 0 ∧Mij > Mik = Mjk) ∨ (x = 1 ∧ (Mik 6= Mjk ∨Mij ≤ Mik ∨Mij ≤ Mik)) (10)\n(x = 0 ∧Mij = Mik = Mjk) ∨ (x = 1 ∧ (Mij 6= Mik ∨Mij 6= Mjk ∨Mik 6= Mjk)) (11)\nGreedyBuild then instantiates in turn each of the x variables, i.e. the decision variables, preferring the value 0 to the value 1, and after each instantiation the problem is made arcconsistent. The algorithm is shown in Figure 23. In line 1 a constraint model is produced, i.e., an n×n symmetric array of constrained integers variables is created, where there are n unique species in the forest, and the UM-Matrix-BCZ constraint is then posted over those variables. The variable X of line 2 is then the set of decision variables. The input trees are broken up as before, and a new variable x is created for each triple or fan. In line 6 the constraints of equations 10 and 11 are posted into the model. The loop of lines 10 to 12 in turn select a decision variable, set it to its lowest possible value, and then make the problem arc-consistent. This might in turn cause uninstantiated variables to have the value 0 removed from their domain if their associated triple or fan conflicts with the triple\n4. Our BC(Z) propagator is O(1), however, so the time complexity is the same as the number of propagations.\nor fan that has just been enforced. This process terminates without failure, because any conflicting triples or fans are essentially ignored. In line 13 the ultrametric matrix is then converted to a tree. The complexity of GreedyBuild is then O((t+ f) · n4) where there are t triples and f fans.\nGreedyBuild was applied to the forest of bird data {A,B,C,D,E, F,G} from section 5, using a soft breakup. This data is incompatible when we use CPBuild, however GreedyBuild produces the supertree in Figure 24. This supertree contains 121 species. SoftBreakup produced 201 triples, and of those 17 were rejected. It took less than 2 seconds to build the model and about 100 seconds to solve that model. This should be compared to CPBuild over the same data set, taking 1.5 seconds to build the model and 10 seconds to determine incompatibility. GreedyBuild was also applied to the data set ABDF, producing the identical supertree to CPBuild, in comparable time (890ms to build the model and 578ms to solve).\nHaving executed GreedyBuild the decision variables in the set X (lines 2, 7, 10 and 11) can be analysed to identify the set of triples and fans that have been excluded from the supertree, i.e., if an x variable has been instantiated with the value 1 then its corresponding triple or fan has been ignored.\nNote that we do not claim any biological significance in the arbitrary order we use to suppress triples. GreedyBuild could be amended to follow the order of MinCutSupertree but we have not investigated this. GreedyBuild can also be enhanced as follows. Currently if a triple or fan exists in multiple input trees then it occurs only once as a constraint. This information could be exploited by weighting the decision variables to take into consideration the relative weight of evidence for a triple or fan, e.g., the number of times that a triple or fan occurs as input. The decision variables can then be instantiated in non-increasing order of weight, i.e., a variable ordering heuristic can be used. In the extreme GreedyBuild can be modified to become OptBuild where a full backtracking search is performed with the objective of minimising the sum of the decision variables, but\nat a potentially exponential cost in time. This would return the tree with the fewest possible input triples suppressed."
    }, {
      "heading" : "6.5 Summary",
      "text" : "With little effort, the constraint model has been adapted to deal with ancestral divergence dates and nested taxa. Both have been achieved by adding side constraints. This has an added advantage with respect to ancestral divergence as it can result in a more compact enumeration of output trees when interior nodes are labelled with ranges rather than specific values.\nWhen input trees conflict we propose two options: use quickXPlain to determine the cause of that conflict or greedily build a supertree using GreedyBuild. Bryant et al. (2004) state that they have essentially an “all-or-nothing” approach to supertree construction when using RankedTree and what is needed is something akin to MinCutSupertree, i.e. when trees are incompatible build a supertree that violates the minimum number of triples or fans, and do this in polynomial time (Page, 2002; Semple & Steel, 2000). This has since been done by Bordewich et al. (2006) and can also be done in our constraint model by incorporating the constraints identified in section 6.1 into GreedyBuild.\nAlthough not shown, it is obvious that ancestral divergence data and nested taxa can be combined in the one model, simply by adding all the necessary constraint and auxiliary variables for both variants into the one model. This, again, could be done in GreedyBuild, but would require some heuristic or rule to be used when deciding what constraints to ignore when the input trees and side constraints are incompatible.\nIn our opinion, deriving, combining and analysing the results of imperative algorithms for supertree problems is much more difficult than the above. Most algorithms for variants required far more complex data structures and tailored algorithms for processing them. Moreover, to combine the algorithms once produced seems practically impossible on account of their intricacy. Finally constraint programming provides various generic methods like quickXPlain “out of the box” that turn out to be of interest in supertree problems."
    }, {
      "heading" : "7. Conclusion",
      "text" : "We have presented a new constraint propagator for the ultrametric constraint over three integer variables, and shown how this can be extended to a symmetric matrix of constrained integer variables. When bounds(Z)-consistency is established on the symmetric array the lower bounds of variables give mutual support. This is sufficient for modelling and solving the supertree construction problem in O(n4) time and O(n2) space, comparable to the complexity of OneTree (Ng & Wormald, 1996) but inferior to that of the algorithm of Bryant and Steel (1995). So, why bother with the CPBuild approach when efficient imperative approaches already exist? The answer lies in the versatility of constraint programming. Rather than develop a new algorithm for a new variant of the supertree problem we add side constraints to a base model, and we have shown that a polynomial time bound can often be achieved. We have done this for ancestral divergence dates and nested taxa, we have shown how our model can be used to deliver necessary triples and fans, and we have proposed GreedyBuild as a way of dealing with incompatible trees."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank Pierre Flener and Xavier Lorca; Barbara Smith, Ian Gent and Christine Wei Wu; Charles Semple, Mike Steel and Rod Page; Muffy Calder and Joe Sventek; Stanislav Zivny; Chris Unsworth; and our three anonymous reviewers/co-authors."
    } ],
    "references" : [ {
      "title" : "Inferring a tree from lowest common ancestors with an application to the optimization of relational expressions",
      "author" : [ "A. Aho", "Y. Sagiv", "T. Szymanski", "J. Ullman" ],
      "venue" : "SIAM J. Comput,",
      "citeRegEx" : "Aho et al\\.,? \\Q1981\\E",
      "shortCiteRegEx" : "Aho et al\\.",
      "year" : 1981
    }, {
      "title" : "Combining tree partitioning, precedence, and incompatibility",
      "author" : [ "N. Beldiceanu", "P. Flener", "X. Lorca" ],
      "venue" : "constraints. Constraints,",
      "citeRegEx" : "Beldiceanu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Beldiceanu et al\\.",
      "year" : 2008
    }, {
      "title" : "Refining the basic constraint propagation algorithm",
      "author" : [ "C. Bessière", "Régin", "J.-C" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Bessière et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Bessière et al\\.",
      "year" : 2001
    }, {
      "title" : "Constraint propagation",
      "author" : [ "C. Bessière" ],
      "venue" : "Handbook of constraint programming. Elsevier. Chapter 3.",
      "citeRegEx" : "Bessière,? 2006",
      "shortCiteRegEx" : "Bessière",
      "year" : 2006
    }, {
      "title" : "Phylogenetic Supertrees: Combining information to reveal the tree of life",
      "author" : [ "O. Bininda-Emonds" ],
      "venue" : "Springer.",
      "citeRegEx" : "Bininda.Emonds,? 2004",
      "shortCiteRegEx" : "Bininda.Emonds",
      "year" : 2004
    }, {
      "title" : "Extending the limits of supertree methods",
      "author" : [ "M. Bordewich", "G. Evans", "C. Semple" ],
      "venue" : "Annals of combinatorics,",
      "citeRegEx" : "Bordewich et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bordewich et al\\.",
      "year" : 2006
    }, {
      "title" : "Extension Operations on Sets of Leaf-labeled Trees",
      "author" : [ "D. Bryant", "M. Steel" ],
      "venue" : "Advances in Applied Mathematics,",
      "citeRegEx" : "Bryant and Steel,? \\Q1995\\E",
      "shortCiteRegEx" : "Bryant and Steel",
      "year" : 1995
    }, {
      "title" : "Supertree methods for ancestral divergence dates and other applications",
      "author" : [ "D. Bryant", "C. Semple", "M. Steel" ],
      "venue" : "Computational Biology Series Kluwer",
      "citeRegEx" : "Bryant et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Bryant et al\\.",
      "year" : 2004
    }, {
      "title" : "Adjustment of heads and tails for the jobshop scheduling problem",
      "author" : [ "J. Carlier", "E. Pinson" ],
      "venue" : "European Journal of Operational Research,",
      "citeRegEx" : "Carlier and Pinson,? \\Q1994\\E",
      "shortCiteRegEx" : "Carlier and Pinson",
      "year" : 1994
    }, {
      "title" : "Solving small TSPs with constraints",
      "author" : [ "Y. Caseau", "F. Laburthe" ],
      "venue" : "In Proceedings International Conference on Logic Programming,",
      "citeRegEx" : "Caseau and Laburthe,? \\Q1997\\E",
      "shortCiteRegEx" : "Caseau and Laburthe",
      "year" : 1997
    }, {
      "title" : "Supertree methods: Some new approaches",
      "author" : [ "P. Daniel" ],
      "venue" : "Master’s thesis, Department of Mathematics and Statistics, University of Canterbury.",
      "citeRegEx" : "Daniel,? 2003",
      "shortCiteRegEx" : "Daniel",
      "year" : 2003
    }, {
      "title" : "Supertree algorithms for nested taxa",
      "author" : [ "P. Daniel", "C. Semple" ],
      "venue" : "Computational Biology Series Kluwer",
      "citeRegEx" : "Daniel and Semple,? \\Q2004\\E",
      "shortCiteRegEx" : "Daniel and Semple",
      "year" : 2004
    }, {
      "title" : "The Ancestor’s Tale",
      "author" : [ "R. Dawkins", "Y. Wong" ],
      "venue" : null,
      "citeRegEx" : "Dawkins and Wong,? \\Q2004\\E",
      "shortCiteRegEx" : "Dawkins and Wong",
      "year" : 2004
    }, {
      "title" : "Some practicable filtering techniques for the constraint satisfaction problem",
      "author" : [ "R. Debruyne", "C. Bessière" ],
      "venue" : "In Proceedings of IJCAI’97,",
      "citeRegEx" : "Debruyne and Bessière,? \\Q1997\\E",
      "shortCiteRegEx" : "Debruyne and Bessière",
      "year" : 1997
    }, {
      "title" : "The CP(Graph) Computation Domain in Constraint Programming",
      "author" : [ "G. Dooms" ],
      "venue" : "Ph.D. thesis, Université catholique de Louvain, Faculté des sciences appliquées.",
      "citeRegEx" : "Dooms,? 2006",
      "shortCiteRegEx" : "Dooms",
      "year" : 2006
    }, {
      "title" : "Supertree construction with constraint programming",
      "author" : [ "I. Gent", "P. Prosser", "B. Smith", "W. Wei" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "Gent et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Gent et al\\.",
      "year" : 2003
    }, {
      "title" : "Algorithms on strings, trees, and sequences: computer science and computational biology",
      "author" : [ "D. Gusfield" ],
      "venue" : "Cambridge University Press, New York, NY, USA.",
      "citeRegEx" : "Gusfield,? 1997",
      "shortCiteRegEx" : "Gusfield",
      "year" : 1997
    }, {
      "title" : "Molecular evolution of mitochondrial 12S RNA and Cytochrome b sequences in the pantherine lineage of Felidae",
      "author" : [ "D. Janczewski", "W. Modi", "J. Stephens", "S. O’Brien" ],
      "venue" : "Mol. Biol. Evol.,",
      "citeRegEx" : "Janczewski et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Janczewski et al\\.",
      "year" : 1995
    }, {
      "title" : "Tractable constraints on ordered domains",
      "author" : [ "P.G. Jeavons", "M.C. Cooper" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Jeavons and Cooper,? \\Q1995\\E",
      "shortCiteRegEx" : "Jeavons and Cooper",
      "year" : 1995
    }, {
      "title" : "QUICKXPLAIN: Preferred Explanations and Relaxations for OverConstrained Problems",
      "author" : [ "U. Junker" ],
      "venue" : "Proceedings AAAI2004, pp. 167–172.",
      "citeRegEx" : "Junker,? 2004",
      "shortCiteRegEx" : "Junker",
      "year" : 2004
    }, {
      "title" : "Seabird supertrees: Combining partial estimates of procellariiform phylogeny",
      "author" : [ "M. Kennedy", "R. Page" ],
      "venue" : "The Auk,",
      "citeRegEx" : "Kennedy and Page,? \\Q2002\\E",
      "shortCiteRegEx" : "Kennedy and Page",
      "year" : 2002
    }, {
      "title" : "An efficient filtering algorithm for disjunction of constraints",
      "author" : [ "O. Lhomme" ],
      "venue" : "Principles and Practice of Constraint Programming, pp. 904–908. Springer.",
      "citeRegEx" : "Lhomme,? 2003",
      "shortCiteRegEx" : "Lhomme",
      "year" : 2003
    }, {
      "title" : "Consistency in networks of relations",
      "author" : [ "A. Mackworth" ],
      "venue" : "Artificial Intelligence, 8, 99–118.",
      "citeRegEx" : "Mackworth,? 1977",
      "shortCiteRegEx" : "Mackworth",
      "year" : 1977
    }, {
      "title" : "Reconstruction of rooted trees from subtrees",
      "author" : [ "M.P. Ng", "N.C. Wormald" ],
      "venue" : "Discrete Appl. Math.,",
      "citeRegEx" : "Ng and Wormald,? \\Q1996\\E",
      "shortCiteRegEx" : "Ng and Wormald",
      "year" : 1996
    }, {
      "title" : "TREEVIEW: An application to display phylogenetic trees on personal computers",
      "author" : [ "R. Page" ],
      "venue" : "Computer Applications in the Biosciences, 12, 357–358.",
      "citeRegEx" : "Page,? 1996",
      "shortCiteRegEx" : "Page",
      "year" : 1996
    }, {
      "title" : "Taxonomy, supertrees, and the tree of life",
      "author" : [ "R. Page" ],
      "venue" : "Bininda-Emonds, O. (Ed.), Phylogenetic Supertrees: Combining information to reveal the tree of life, pp. 247–265. Computational Biology Series Kluwer.",
      "citeRegEx" : "Page,? 2004",
      "shortCiteRegEx" : "Page",
      "year" : 2004
    }, {
      "title" : "Modified mincut supertrees",
      "author" : [ "R.D.M. Page" ],
      "venue" : "InWABI ’02: Proceedings of the Second International Workshop on Algorithms in Bioinformatics, pp. 537–552 London, UK. Springer-Verlag. 937",
      "citeRegEx" : "Page,? 2002",
      "shortCiteRegEx" : "Page",
      "year" : 2002
    }, {
      "title" : "Modernizing the Tree of Life",
      "author" : [ "E. Pennisi" ],
      "venue" : "Science, 300, 1692–1697.",
      "citeRegEx" : "Pennisi,? 2003",
      "shortCiteRegEx" : "Pennisi",
      "year" : 2003
    }, {
      "title" : "Supertree construction with constraint programming: recent progress and new challenges",
      "author" : [ "P. Prosser" ],
      "venue" : "WCB06 - Workshop on Constraint Based Methods for Bioinformatics, pp. 75–82.",
      "citeRegEx" : "Prosser,? 2006",
      "shortCiteRegEx" : "Prosser",
      "year" : 2006
    }, {
      "title" : "Rooted Tree and Spanning Tree Constraints",
      "author" : [ "P. Prosser", "C. Unsworth" ],
      "venue" : "In 17th ECAI Workshop on Modelling and Solving Problems with Constraints",
      "citeRegEx" : "Prosser and Unsworth,? \\Q2006\\E",
      "shortCiteRegEx" : "Prosser and Unsworth",
      "year" : 2006
    }, {
      "title" : "A filtering algorithm for constraints of difference in CSP’s",
      "author" : [ "Régin", "J.-C." ],
      "venue" : "Proceedings AAAI’94, pp. 362–367.",
      "citeRegEx" : "Régin and J..C.,? 1994",
      "shortCiteRegEx" : "Régin and J..C.",
      "year" : 1994
    }, {
      "title" : "Contradicting conventional wisdom in constraint satisfaction",
      "author" : [ "D. Sabin", "E. Freuder" ],
      "venue" : "In Proceedings of ECAI-94,",
      "citeRegEx" : "Sabin and Freuder,? \\Q1994\\E",
      "shortCiteRegEx" : "Sabin and Freuder",
      "year" : 1994
    }, {
      "title" : "Finite domain constraint programming systems",
      "author" : [ "C. Schulte", "M. Carlsson" ],
      "venue" : "In Handbook of constraint programming. Elsevier. Chapter",
      "citeRegEx" : "Schulte and Carlsson,? \\Q2006\\E",
      "shortCiteRegEx" : "Schulte and Carlsson",
      "year" : 2006
    }, {
      "title" : "Supertree algorithms for ancestral divergence dates and nested",
      "author" : [ "C. Semple", "P. Daniel", "W. Hordijk", "R. Page", "M. Steel" ],
      "venue" : "taxa. Bioinformatics,",
      "citeRegEx" : "Semple et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Semple et al\\.",
      "year" : 2004
    }, {
      "title" : "A supertree method for rooted trees",
      "author" : [ "C. Semple", "M. Steel" ],
      "venue" : "Discrete Appl. Math.,",
      "citeRegEx" : "Semple and Steel,? \\Q2000\\E",
      "shortCiteRegEx" : "Semple and Steel",
      "year" : 2000
    }, {
      "title" : "A Tutorial on Constraint Programming",
      "author" : [ "B.M. Smith" ],
      "venue" : "Technical Report 95.14, University of Leeds.",
      "citeRegEx" : "Smith,? 1995",
      "shortCiteRegEx" : "Smith",
      "year" : 1995
    }, {
      "title" : "Foundations of Constraint Satisfaction",
      "author" : [ "E. Tsang" ],
      "venue" : "Academic Press.",
      "citeRegEx" : "Tsang,? 1993",
      "shortCiteRegEx" : "Tsang",
      "year" : 1993
    }, {
      "title" : "A generic arc-consistency algorithm and its specializations",
      "author" : [ "P. van Hentenryck", "Y. Deville", "Teng", "C.-M" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Hentenryck et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Hentenryck et al\\.",
      "year" : 1992
    }, {
      "title" : "Design, implementation, and evaluation of the constraint language cc(fd)",
      "author" : [ "P. van Hentenryck", "V. Saraswat", "Y. Deville" ],
      "venue" : "Journal of Logic Programming,",
      "citeRegEx" : "Hentenryck et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Hentenryck et al\\.",
      "year" : 1998
    }, {
      "title" : "Quartet-based phylogeny reconstruction with answer set programming",
      "author" : [ "G. Wu", "You", "J.-H", "G. Lin" ],
      "venue" : "IEEE/ACM Transactions on Computational Biology and Bioinformatics,",
      "citeRegEx" : "Wu et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2007
    }, {
      "title" : "Making AC-3 an optimal algorithm",
      "author" : [ "Z. Yuanlin", "R.H.C. Yap" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Yuanlin and Yap,? \\Q2001\\E",
      "shortCiteRegEx" : "Yuanlin and Yap",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 27,
      "context" : "7 million species identified only about 80,000 have been placed in the ToL so far (Pennisi, 2003).",
      "startOffset" : 82,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "There are applications for the ToL: to help understand how pathogens become more virulent over time, how new diseases emerge, and to recognise species at risk of extinction (Pennisi, 2003; Mace, Gittleman, & Purvis, 2003).",
      "startOffset" : 173,
      "endOffset" : 221
    }, {
      "referenceID" : 4,
      "context" : "One approach to building the ToL is divide and conquer: combining smaller trees such as those available from TreeBase (TreeBASE, 2003) into so-called “supertrees” (Bininda-Emonds, 2004) to approach a more complete ToL.",
      "startOffset" : 163,
      "endOffset" : 185
    }, {
      "referenceID" : 10,
      "context" : "To date, supertree construction has been dominated by imperative techniques (Semple & Steel, 2000; Semple, Daniel, Hordijk, Page, & Steel, 2004; Daniel, 2003; Bordewich, Evans, & Semple, 2006; Ng & Wormald, 1996; Bryant & Steel, 1995; Page, 2002) but recently new declarative approaches have emerged using constraint programming (Gent, Prosser, Smith, & Wei, 2003; Prosser, 2006; Beldiceanu, Flener, & Lorca, 2008) and answer set programming (Wu, You, & Lin, 2007).",
      "startOffset" : 76,
      "endOffset" : 246
    }, {
      "referenceID" : 26,
      "context" : "To date, supertree construction has been dominated by imperative techniques (Semple & Steel, 2000; Semple, Daniel, Hordijk, Page, & Steel, 2004; Daniel, 2003; Bordewich, Evans, & Semple, 2006; Ng & Wormald, 1996; Bryant & Steel, 1995; Page, 2002) but recently new declarative approaches have emerged using constraint programming (Gent, Prosser, Smith, & Wei, 2003; Prosser, 2006; Beldiceanu, Flener, & Lorca, 2008) and answer set programming (Wu, You, & Lin, 2007).",
      "startOffset" : 76,
      "endOffset" : 246
    }, {
      "referenceID" : 28,
      "context" : "To date, supertree construction has been dominated by imperative techniques (Semple & Steel, 2000; Semple, Daniel, Hordijk, Page, & Steel, 2004; Daniel, 2003; Bordewich, Evans, & Semple, 2006; Ng & Wormald, 1996; Bryant & Steel, 1995; Page, 2002) but recently new declarative approaches have emerged using constraint programming (Gent, Prosser, Smith, & Wei, 2003; Prosser, 2006; Beldiceanu, Flener, & Lorca, 2008) and answer set programming (Wu, You, & Lin, 2007).",
      "startOffset" : 329,
      "endOffset" : 414
    }, {
      "referenceID" : 3,
      "context" : "We then propose a specialised ultrametric constraint, in terms of its propagation procedures, that maintains bounds(Z)-consistency (Bessière, 2006) on three variables.",
      "startOffset" : 131,
      "endOffset" : 147
    }, {
      "referenceID" : 10,
      "context" : "We justify this assertion by proposing a constraint solution finding essential relations in the supertree (Daniel, 2003), addressing ancestral divergence dates (Semple et al.",
      "startOffset" : 106,
      "endOffset" : 120
    }, {
      "referenceID" : 33,
      "context" : "We justify this assertion by proposing a constraint solution finding essential relations in the supertree (Daniel, 2003), addressing ancestral divergence dates (Semple et al., 2004; Bryant, Semple, & Steel, 2004), modelling nested taxa (Page, 2004; Daniel & Semple, 2004) and coping with conflicting data.",
      "startOffset" : 160,
      "endOffset" : 212
    }, {
      "referenceID" : 25,
      "context" : ", 2004; Bryant, Semple, & Steel, 2004), modelling nested taxa (Page, 2004; Daniel & Semple, 2004) and coping with conflicting data.",
      "startOffset" : 62,
      "endOffset" : 97
    }, {
      "referenceID" : 36,
      "context" : "Background In this section we give necessary definitions and descriptions of the Constraint Satisfaction Problem (Tsang, 1993), Constraint Programming, and the Supertree problem.",
      "startOffset" : 113,
      "endOffset" : 126
    }, {
      "referenceID" : 22,
      "context" : "Propagation maintains a level of consistency, such as arcconsistency (Mackworth, 1977), across the variables, removing values from domains that cannot occur in any solution (i.",
      "startOffset" : 69,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "We use the definitions of (generalized) arc-consistency ((G)AC) due to Bessière (2006):",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "Arc-consistency can be established on a CSP using an algorithm such as AC3 (Mackworth, 1977).",
      "startOffset" : 75,
      "endOffset" : 92
    }, {
      "referenceID" : 3,
      "context" : "The AC3 algorithm has O(e · d3) time complexity, where e is the number of constraints and d the size of the largest domain, however other algorithms can achieve a time bound of O(e · d2) (Yuanlin & Yap, 2001; Bessière & Régin, 2001). We demonstrate arc-consistency with the example of Figure 1 by Smith (1995). We have three constrained integer variables x, y and z, each with an integer domain {1.",
      "startOffset" : 209,
      "endOffset" : 310
    }, {
      "referenceID" : 8,
      "context" : "For a job shop scheduling problem we might have a model that uses 0/1 variables to decide the relative order of pairs of activities that share a resource, and we might increase propagation by adding Carlier and Pinson’s edge finding constraint (1994). The constraint programming approach is general and practical for modelling and solving problems, and provides a framework for the combination of problem specific algorithms in one solver.",
      "startOffset" : 199,
      "endOffset" : 251
    }, {
      "referenceID" : 4,
      "context" : "2 The Supertree Problem Supertree construction is a problem in phylogenetics where we are to combine leaf-labelled species trees, where the sets of leaf labels intersect, into a single tree that respects all arboreal relationships in each input tree (Bininda-Emonds, 2004).",
      "startOffset" : 250,
      "endOffset" : 272
    }, {
      "referenceID" : 10,
      "context" : "Variants on the supertree problem that have previously been published and solved in the specialist bioinformatics literature include finding all solutions1, counting solutions, finding conserved relationships in all supertrees (Daniel, 2003), incorporating nested taxa (Semple et al.",
      "startOffset" : 227,
      "endOffset" : 241
    }, {
      "referenceID" : 33,
      "context" : "Variants on the supertree problem that have previously been published and solved in the specialist bioinformatics literature include finding all solutions1, counting solutions, finding conserved relationships in all supertrees (Daniel, 2003), incorporating nested taxa (Semple et al., 2004), incorporating ancestral divergence dates (Semple et al.",
      "startOffset" : 269,
      "endOffset" : 290
    }, {
      "referenceID" : 33,
      "context" : ", 2004), incorporating ancestral divergence dates (Semple et al., 2004) and the possibility of contradictory input data (Semple & Steel, 2000).",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 4,
      "context" : "(2003) within the context of supertree construction (Bininda-Emonds, 2004), and was implemented using toolkit primitives.",
      "startOffset" : 52,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "The Ultrametric Constraint The ultrametric constraint was first proposed by Gent et al. (2003) within the context of supertree construction (Bininda-Emonds, 2004), and was implemented using toolkit primitives.",
      "startOffset" : 76,
      "endOffset" : 95
    }, {
      "referenceID" : 15,
      "context" : "The constraint was proposed by Gent et al. (2003), used again by Prosser (2006) and both times implemented as a literal translation of Equation 1 using toolkit primitives.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "The constraint was proposed by Gent et al. (2003), used again by Prosser (2006) and both times implemented as a literal translation of Equation 1 using toolkit primitives.",
      "startOffset" : 31,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "arc-consistency (Debruyne & Bessière, 1997) or the filtering algorithm of Lhomme (2003). However, the cost of these is greater in the average case than delayed-disjunction, preventing their use in toolkits.",
      "startOffset" : 28,
      "endOffset" : 88
    }, {
      "referenceID" : 3,
      "context" : "This Lemma will have important implications for the species tree model to be presented in detail in Section 4: in particular, the lower bounds of a bounds(Z)-consistency model form a solution, where bounds(Z)-consistency (Bessière, 2006) is defined as follows",
      "startOffset" : 221,
      "endOffset" : 237
    }, {
      "referenceID" : 37,
      "context" : "This can be guaranteed if domain reductions only occur at the bounds, as is the case here, or if domains are represented using one of the structures proposed by van Hentenryck et al. (1992).",
      "startOffset" : 165,
      "endOffset" : 190
    }, {
      "referenceID" : 32,
      "context" : "3 Entailment Schulte and Carlsson (2006) define entailment as when all possible constractions of the domains in a constraint’s scope are consistent.",
      "startOffset" : 13,
      "endOffset" : 41
    }, {
      "referenceID" : 22,
      "context" : "This propagator mimics part of the AC3 algorithm (Mackworth, 1977) since it (a) receives a propagation event on a variable, (b) identifies which constraints are over that variable, and (c) arranges for the propagation to be carried out.",
      "startOffset" : 49,
      "endOffset" : 66
    }, {
      "referenceID" : 15,
      "context" : "Supertree Construction We now review imperative solutions to the supertree construction problem, review the first constraint programing solution (Gent et al., 2003), and present a new encoding that exploits the specialised UM-Matrix-BCZ constraint.",
      "startOffset" : 145,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "1 Imperative Solutions to the Supertree Problem The earliest imperative techniques are due to Bryant and Steel (1995) and Ng and Wormald (1996).",
      "startOffset" : 94,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "1 Imperative Solutions to the Supertree Problem The earliest imperative techniques are due to Bryant and Steel (1995) and Ng and Wormald (1996). Both present a OneTree algorithm which is based on the Build algorithm of Aho, Sagiv, Szymanski, and Ullman (1981).",
      "startOffset" : 94,
      "endOffset" : 144
    }, {
      "referenceID" : 6,
      "context" : "1 Imperative Solutions to the Supertree Problem The earliest imperative techniques are due to Bryant and Steel (1995) and Ng and Wormald (1996). Both present a OneTree algorithm which is based on the Build algorithm of Aho, Sagiv, Szymanski, and Ullman (1981). OneTree is based on the observation that in a tree any three leaf nodes define a unique relation with respect to their most recent common ancestor (mrca), such that mrca(a, b) is the interior node furthest from the root that has both leaf nodes a and b as descendants.",
      "startOffset" : 94,
      "endOffset" : 260
    }, {
      "referenceID" : 23,
      "context" : "Ng and Wormald (1996) give the complexity of OneTree as O(h(n)) where h(n) = n(n+ t+ bn)α(n+ t+ f), n is the number of labels, t the number of triples, f the number of fans, b is the sum of the squares of the number of leaves in the fans, and α is the inverse Ackermann function (and is less than 4 for all conceivable inputs and so behaves like a constant).",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 6,
      "context" : "This should be contrasted with the O(t · n) complexity of Bryant and Steel’s OneTree (1995).",
      "startOffset" : 58,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : ", OneTree equivalent, was first solved as a constraint program by Gent et al. (2003). The encoding takes advantage of an equivalence between ultrametric trees and ultrametric matrices:",
      "startOffset" : 66,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "A proof is given by Gusfield (1997).",
      "startOffset" : 20,
      "endOffset" : 36
    }, {
      "referenceID" : 16,
      "context" : "The final step is to use an algorithm based on the constructive proof by Gusfield (1997) of the ⇐ direction of Theorem 3 to build a tree from the matrix M produced by a constraint solver.",
      "startOffset" : 73,
      "endOffset" : 89
    }, {
      "referenceID" : 22,
      "context" : "AC3 (Mackworth, 1977) begins with a queue containing all constraints.",
      "startOffset" : 4,
      "endOffset" : 21
    }, {
      "referenceID" : 19,
      "context" : "Our benchmark is real-life seabird data previously used by Kennedy and Page (2002) and Beldiceanu et al.",
      "startOffset" : 59,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "Our benchmark is real-life seabird data previously used by Kennedy and Page (2002) and Beldiceanu et al. (2008) and we present statistics on various techniques for producing supertrees, namely OneTree, and the CP solutions of Section 4 (entries Toolkit and CPBuild).",
      "startOffset" : 87,
      "endOffset" : 112
    }, {
      "referenceID" : 1,
      "context" : "Our benchmark is real-life seabird data previously used by Kennedy and Page (2002) and Beldiceanu et al. (2008) and we present statistics on various techniques for producing supertrees, namely OneTree, and the CP solutions of Section 4 (entries Toolkit and CPBuild). For completeness we reproduce the results of Beldiceanu et al. (2008) over the same data set, and tabulate this as TreeCon.",
      "startOffset" : 87,
      "endOffset" : 337
    }, {
      "referenceID" : 14,
      "context" : "An alternative constraint model of a tree might use 0/1 variables corresponding to potential edges within an adjacency matrix (Prosser & Unsworth, 2006), or indeed the CP(Graph) computation domain (Dooms, 2006).",
      "startOffset" : 197,
      "endOffset" : 210
    }, {
      "referenceID" : 1,
      "context" : "Our results also compare well against those of Beldiceanu et al. (2008). There is one case, BE, where CPBuild is an order of magnitude slower than TreeCon; so far we do not have an explanation for this.",
      "startOffset" : 47,
      "endOffset" : 72
    }, {
      "referenceID" : 24,
      "context" : "Figure 17 shows the supertree, displayed with treeView (Page, 1996), produced from the largest compatible forest {A,B,D,F}.",
      "startOffset" : 55,
      "endOffset" : 67
    }, {
      "referenceID" : 7,
      "context" : "The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 32,
      "context" : "1 Ancestral Divergence Dates Semple et al. (2004) and Bryant et al.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 7,
      "context" : "(2004) and Bryant et al. (2004) add temporal information to the input trees.",
      "startOffset" : 11,
      "endOffset" : 32
    }, {
      "referenceID" : 7,
      "context" : "(2004) and Bryant et al. (2004) add temporal information to the input trees. Interior nodes may be labelled with integer ranks such that if interior node v2 is a proper descendant of v1 then rank(v1) < rank(v2), resulting in a ranked phylogenetic tree. Additionally relative divergence dates may be expressed in the form “div(c,d) predates div(a,b)” and this is interpreted as “the divergence of species c and d predates that of species a and b”. The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations. The algorithm outputs a ranked tree that respects those relations or returns “not compatible”. This is trivial to incorporate into the constraint model. If trees have been ranked then for each pair of species (i, j) in the leaf set we instantiate the constrained integer variable Mij to the value of mrca(i, j). For a predates relation “div(c,d) predates div(a,b)” we post the constraint Mcd < Mab. This is done before step 4 of CPBuild (Figure 16), i.e., ranks and predates relations become side constraints. Similarly time bounds on speciation events are posted as unary constraints, i.e. in a dated phylogenetic tree upper and lower divergence bounds are given on interior nodes, such that l(a, b) and u(a, b) give respectively the lower and upper bounds on the divergence dates of species a and b. In the constraint program the following two side constraints are then posted (again, before step 4): l(a, b) ≤ Mab and Mab ≤ u(a, b). A demonstration of ranked trees is given in Figure 18. On the left we have two ranked species trees of cats used recently by Semple et al. (2004) and originally by Janczewski, Modi, Stephens, and O’Brien (1995).",
      "startOffset" : 11,
      "endOffset" : 1694
    }, {
      "referenceID" : 7,
      "context" : "(2004) and Bryant et al. (2004) add temporal information to the input trees. Interior nodes may be labelled with integer ranks such that if interior node v2 is a proper descendant of v1 then rank(v1) < rank(v2), resulting in a ranked phylogenetic tree. Additionally relative divergence dates may be expressed in the form “div(c,d) predates div(a,b)” and this is interpreted as “the divergence of species c and d predates that of species a and b”. The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations. The algorithm outputs a ranked tree that respects those relations or returns “not compatible”. This is trivial to incorporate into the constraint model. If trees have been ranked then for each pair of species (i, j) in the leaf set we instantiate the constrained integer variable Mij to the value of mrca(i, j). For a predates relation “div(c,d) predates div(a,b)” we post the constraint Mcd < Mab. This is done before step 4 of CPBuild (Figure 16), i.e., ranks and predates relations become side constraints. Similarly time bounds on speciation events are posted as unary constraints, i.e. in a dated phylogenetic tree upper and lower divergence bounds are given on interior nodes, such that l(a, b) and u(a, b) give respectively the lower and upper bounds on the divergence dates of species a and b. In the constraint program the following two side constraints are then posted (again, before step 4): l(a, b) ≤ Mab and Mab ≤ u(a, b). A demonstration of ranked trees is given in Figure 18. On the left we have two ranked species trees of cats used recently by Semple et al. (2004) and originally by Janczewski, Modi, Stephens, and O’Brien (1995). The branch lengths of the source trees have been translated into rankings and added to the interior vertices of those trees.",
      "startOffset" : 11,
      "endOffset" : 1759
    }, {
      "referenceID" : 7,
      "context" : "(2004) and Bryant et al. (2004) add temporal information to the input trees. Interior nodes may be labelled with integer ranks such that if interior node v2 is a proper descendant of v1 then rank(v1) < rank(v2), resulting in a ranked phylogenetic tree. Additionally relative divergence dates may be expressed in the form “div(c,d) predates div(a,b)” and this is interpreted as “the divergence of species c and d predates that of species a and b”. The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations. The algorithm outputs a ranked tree that respects those relations or returns “not compatible”. This is trivial to incorporate into the constraint model. If trees have been ranked then for each pair of species (i, j) in the leaf set we instantiate the constrained integer variable Mij to the value of mrca(i, j). For a predates relation “div(c,d) predates div(a,b)” we post the constraint Mcd < Mab. This is done before step 4 of CPBuild (Figure 16), i.e., ranks and predates relations become side constraints. Similarly time bounds on speciation events are posted as unary constraints, i.e. in a dated phylogenetic tree upper and lower divergence bounds are given on interior nodes, such that l(a, b) and u(a, b) give respectively the lower and upper bounds on the divergence dates of species a and b. In the constraint program the following two side constraints are then posted (again, before step 4): l(a, b) ≤ Mab and Mab ≤ u(a, b). A demonstration of ranked trees is given in Figure 18. On the left we have two ranked species trees of cats used recently by Semple et al. (2004) and originally by Janczewski, Modi, Stephens, and O’Brien (1995). The branch lengths of the source trees have been translated into rankings and added to the interior vertices of those trees. On the right we have one of the 17 possible resultant supertrees. In total, 7 of the 17 solutions contain interior nodes with ranges. If interior nodes are labelled with specific values rather than ranges then 30 solutions are produced, some of which are structurally identical. This goes some way to addressing the issue of enumerating all supertrees compactly, raised as a challenge by Semple et al. (2004). In Figure 19 we show the effect of adding a predates constraint to a supertree construction.",
      "startOffset" : 11,
      "endOffset" : 2294
    }, {
      "referenceID" : 7,
      "context" : "(2004) and Bryant et al. (2004) add temporal information to the input trees. Interior nodes may be labelled with integer ranks such that if interior node v2 is a proper descendant of v1 then rank(v1) < rank(v2), resulting in a ranked phylogenetic tree. Additionally relative divergence dates may be expressed in the form “div(c,d) predates div(a,b)” and this is interpreted as “the divergence of species c and d predates that of species a and b”. The RankedTree algorithm (Bryant et al., 2004) takes as input a collection of precedence constraints derived from input ranked species trees and predates relations. The algorithm outputs a ranked tree that respects those relations or returns “not compatible”. This is trivial to incorporate into the constraint model. If trees have been ranked then for each pair of species (i, j) in the leaf set we instantiate the constrained integer variable Mij to the value of mrca(i, j). For a predates relation “div(c,d) predates div(a,b)” we post the constraint Mcd < Mab. This is done before step 4 of CPBuild (Figure 16), i.e., ranks and predates relations become side constraints. Similarly time bounds on speciation events are posted as unary constraints, i.e. in a dated phylogenetic tree upper and lower divergence bounds are given on interior nodes, such that l(a, b) and u(a, b) give respectively the lower and upper bounds on the divergence dates of species a and b. In the constraint program the following two side constraints are then posted (again, before step 4): l(a, b) ≤ Mab and Mab ≤ u(a, b). A demonstration of ranked trees is given in Figure 18. On the left we have two ranked species trees of cats used recently by Semple et al. (2004) and originally by Janczewski, Modi, Stephens, and O’Brien (1995). The branch lengths of the source trees have been translated into rankings and added to the interior vertices of those trees. On the right we have one of the 17 possible resultant supertrees. In total, 7 of the 17 solutions contain interior nodes with ranges. If interior nodes are labelled with specific values rather than ranges then 30 solutions are produced, some of which are structurally identical. This goes some way to addressing the issue of enumerating all supertrees compactly, raised as a challenge by Semple et al. (2004). In Figure 19 we show the effect of adding a predates constraint to a supertree construction. The data has previously been used by Bryant et al. (2004) in their Figures 5 and 6.",
      "startOffset" : 11,
      "endOffset" : 2446
    }, {
      "referenceID" : 22,
      "context" : "Problems related to creating compatible supertrees for this type of data were raised by Page (2004) and defined and solved by Daniel and Semple (2004).",
      "startOffset" : 88,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : "Problems related to creating compatible supertrees for this type of data were raised by Page (2004) and defined and solved by Daniel and Semple (2004). A set of input trees and possible solution to the problem are shown in Figure 20: notice that all labels are conserved in the solution, all ancestral relationships are conserved and, for any labels li and lj from the same input tree, li is ancestor of lj in the input tree if and only if li is ancestor of lj in the solution tree.",
      "startOffset" : 126,
      "endOffset" : 151
    }, {
      "referenceID" : 10,
      "context" : "Problems related to creating compatible supertrees for this type of data were raised by Page (2004) and defined and solved by Daniel and Semple (2004). A set of input trees and possible solution to the problem are shown in Figure 20: notice that all labels are conserved in the solution, all ancestral relationships are conserved and, for any labels li and lj from the same input tree, li is ancestor of lj in the input tree if and only if li is ancestor of lj in the solution tree. This is an instance of the problem Higher Taxa Compatibility defined by Daniel and Semple (2004) and Semple et al.",
      "startOffset" : 126,
      "endOffset" : 580
    }, {
      "referenceID" : 10,
      "context" : "Problems related to creating compatible supertrees for this type of data were raised by Page (2004) and defined and solved by Daniel and Semple (2004). A set of input trees and possible solution to the problem are shown in Figure 20: notice that all labels are conserved in the solution, all ancestral relationships are conserved and, for any labels li and lj from the same input tree, li is ancestor of lj in the input tree if and only if li is ancestor of lj in the solution tree. This is an instance of the problem Higher Taxa Compatibility defined by Daniel and Semple (2004) and Semple et al. (2004), where the result tree must perfectly display all of the input trees.",
      "startOffset" : 126,
      "endOffset" : 605
    }, {
      "referenceID" : 10,
      "context" : ", common to all possible supertrees) is introduced by (Daniel, 2003) along with the polynomial time decision procedureNecessity.",
      "startOffset" : 54,
      "endOffset" : 68
    }, {
      "referenceID" : 19,
      "context" : "Junker’s quickXPlain method (Junker, 2004) discovers a minimal subset of constraints that when posted and propagated result in a failure.",
      "startOffset" : 28,
      "endOffset" : 42
    }, {
      "referenceID" : 19,
      "context" : "Junker (2004) state that this method can be achieved by a worst case of 2k · log2(n/k) + 2k propagations 4, where k is the size of the minimal explanation found and n is the number of constraints.",
      "startOffset" : 0,
      "endOffset" : 14
    }, {
      "referenceID" : 19,
      "context" : "Junker (2004) state that this method can be achieved by a worst case of 2k · log2(n/k) + 2k propagations 4, where k is the size of the minimal explanation found and n is the number of constraints. An alternative approach is to satisfy as many of the input triples and fans as is possible within a reasonable amount of time, i.e., polynomial time. Semple and Steel propose such an algorithm, MinCutSupertree (2000), and this has been refined by Page (2002).",
      "startOffset" : 0,
      "endOffset" : 414
    }, {
      "referenceID" : 19,
      "context" : "Junker (2004) state that this method can be achieved by a worst case of 2k · log2(n/k) + 2k propagations 4, where k is the size of the minimal explanation found and n is the number of constraints. An alternative approach is to satisfy as many of the input triples and fans as is possible within a reasonable amount of time, i.e., polynomial time. Semple and Steel propose such an algorithm, MinCutSupertree (2000), and this has been refined by Page (2002). We now propose a similar scheme within the constraint programming framework.",
      "startOffset" : 0,
      "endOffset" : 456
    }, {
      "referenceID" : 26,
      "context" : "when trees are incompatible build a supertree that violates the minimum number of triples or fans, and do this in polynomial time (Page, 2002; Semple & Steel, 2000).",
      "startOffset" : 130,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "Bryant et al. (2004) state that they have essentially an “all-or-nothing” approach to supertree construction when using RankedTree and what is needed is something akin to MinCutSupertree, i.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 5,
      "context" : "This has since been done by Bordewich et al. (2006) and can also be done in our constraint model by incorporating the constraints identified in section 6.",
      "startOffset" : 28,
      "endOffset" : 52
    }, {
      "referenceID" : 6,
      "context" : "This is sufficient for modelling and solving the supertree construction problem in O(n4) time and O(n2) space, comparable to the complexity of OneTree (Ng & Wormald, 1996) but inferior to that of the algorithm of Bryant and Steel (1995). So, why bother with the CPBuild approach when efficient imperative approaches already exist? The answer lies in the versatility of constraint programming.",
      "startOffset" : 213,
      "endOffset" : 237
    } ],
    "year" : 2008,
    "abstractText" : "A phylogenetic tree shows the evolutionary relationships among species. Internal nodes of the tree represent speciation events and leaf nodes correspond to species. A goal of phylogenetics is to combine such trees into larger trees, called supertrees, whilst respecting the relationships in the original trees. A rooted tree exhibits an ultrametric property; that is, for any three leaves of the tree it must be that one pair has a deeper most recent common ancestor than the other pairs, or that all three have the same most recent common ancestor. This inspires a constraint programming encoding for rooted trees. We present an efficient constraint that enforces the ultrametric property over a symmetric array of constrained integer variables, with the inevitable property that the lower bounds of any three variables are mutually supportive. We show that this allows an efficient constraint-based solution to the supertree construction problem. We demonstrate that the versatility of constraint programming can be exploited to allow solutions to variants of the supertree construction problem.",
    "creator" : null
  }
}