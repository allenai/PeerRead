{
  "name" : "1705.10030.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Supervised Complementary Entity Recognition with Augmented Key-value Pairs of Knowledge",
    "authors" : [ "Hu Xu", "Lei Shu", "Philip S. Yu" ],
    "emails" : [ "psyu}@uic.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 5.\n10 03\n0v 1\n[ cs\n.C L\n] 2\n9 M\nay 2\n01 7\ntask in sentiment analysis on product reviews and complementary entities (products) are one important type of opinion targets that may work together with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as a supervised sequence labeling with the capability of expanding domain knowledge as key-value pairs from unlabeled reviews, by automatically learning and enhancing knowledgebased features. We use Conditional Random Field (CRF) as the base learner and augment CRF with knowledge-based features (called the Knowledge-based CRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of supervised CER task."
    }, {
      "heading" : "1 Introduction",
      "text" : "Aspect extraction (or opinion target extraction) is an important task in sentiment analysis (Pang et al., 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015). Besides opinion targets about the reviewed product itself (e.g., the “screen” in “iPhone’s screen is great.”), products that are compatible or incompatible with the reviewed product are also important opinion targets. Extracting those kinds of opinion targets are studied as Complementary Entity Recognition (CER) in (Xu et al., 2016b,a). For example, if the sold product is a tablet stand, then the “iPhone” in “This tablet stand works with my iPhone” is a complementary entity. Note that CER highly relies on entity’s contextual information (e.g., the word “works” in the previous example) and\nsuch information can be domain dependent. For example, “holds” in “This tablet stand holds my iPhone well” is a context verb particular for tablet stand. A traditional supervised method like Conditional Random Field (CRF) (Lafferty et al., 2001) may have good precision on such extraction yet suffer from low recall due to unseen context words appear in the test data but not in the training data. To solve this problem, instead of using supervised method, (Xu et al., 2016b) uses an unsupervised method by leveraging manually-crafted high precision dependency rules (Bach and Badaskar, 2007; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Joshi and Penstein-Rosé, 2009) to expand (bootstrap) context words as knowledge on a large amount of unlabeled data and combine those context words with another set of manually-crafted high recall dependency rules for CER. However, crafting dependency rules for both context words and CER can be time-consuming and such rules may be domain dependent and subject to change for new domains.\nTo benefit from both the supervised and unsupervised methods, we consider to automatically learn patterns for both CER and knowledge expansion (of context words) from training data and expand context word knowledge on unlabeled data. So when making predictions on the test data, the model can leverage more contextual knowledge from unlabeled data to make better predictions. Or put it another way, we wish the prediction behavior of a supervised model can change after training when it sees more unlabeled data. This framework is inspired by the lifelong sequence labeling method proposed in (Shu et al., 2017, 2016). However, we do not expand knowledge for lifelong learning here and we make one step further: we automatically learn knowledge-based features and knowledge (or context words) as key-value\npairs rather than manually crafting them. We use CRF as the base learner and augment CRF with knowledge-based features (a modified dependency relation) that are automatically learned from the training data. The augmented CRF is called Knowledge-based CRF (KCRF).\nThe proposed method has the following steps:\nPre-training We first train a CRF as a traditional sequence labeling training process using handcrafted features, including primitive features (defined later) such as dependency relation based features. Then we automatically select from those primitive features as knowledge-based features to build a group of key-value pairs as initial knowledge, where keys are selected feature types and values are feature values (e.g., context words) appear in the training data. Knowledge-based Training Then we train a Knowledge-based CRF (KCRF) based on the initial knowledge. So KCRF knows which features (as keys) can be used to expand knowledge (get more values for the same key). Knowledge Expansion We expand the values in initial knowledge by iteratively collecting reliable knowledge from reliable predictions on plenty of unlabeled reviews. Experiments demonstrate that the expanded knowledge is effective in predicting test data."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We briefly review the terms used throughout this paper. We use dependency relations as the major type of knowledge-based features since a dependency relation associates one word (current word) with another word (context word), which can be viewed as a piece of context knowledge.\nDefinition 1 (Dependency Relation) A dependency relation is a typed relation between two words in a sentence with the following format:\n(type, gov, govpos, dep, deppos),\nwhere type is the type of a dependency relation, gov is the governor word, govpos is the POS (PartOf-Speech) tag of the governor word, dep is the dependent word and deppos is the POS tag of the dependent word.\nDefinition 2 (Dependency Feature) A dependency feature for the n-th word is a simplified dependency relation with the following attributes:\n(role, type, gov/dep, govpos/deppos),\nwhere role can be either “GOV” or “DEP” indicating whether the n-th word is a governor word or a dependent word; type is the type of the original dependency relation; gov/dep is the other word associated with the n-th word via the original dependency relation and govpos/deppos is the POS tag of the other word.\nNote here we omit the n-th word, its POS-tag in a dependency relation and define them as separate features since they are the same for all dependency features of the n-th word.\nDefinition 3 (Primitive Feature) A primitive feature can be either a dependency feature or a current word feature (taking current word as a feature). Primitive features are used to generate knowledge base.\nDefinition 4 (Knowledge Base) A knowledge base is a set of key-value pairs (k, v) ∈ KB, where k is the knowledge type and v is the knowledge value belonging to that type. The same k may have multiple knowledge values. We further define separate knowledge bases KBto for each tag to ∈ T , where T is the set of output labels for sequence labeing and KB = {KBto |to ∈ T}.\nDefinition 5 (Knowledge-based Feature) A knowledge-based feature is defined based on a knowledge type k in a knowledge base. We use d ∈ D to denote an index about a knowledgebased feature in a feature vector xn. So xn,d = 1 indicates that the d-th feature of the n-th word is a knowledge-based feature of type kd with some (kd, v) found in KB. We use K = ∪to∈TK to to denote all knowledge types in KB.\nA primitive feature can generate a knowledgebased feature in the form of (k, v). Current word feature has a corresponding knowledge type k = [WORD] and takes the current word as the knowledge value v (e.g., we use ([WORD], “phone”) to indicate “phone” is in the knowledge base as type [WORD] ). Dependency features have a corresponding knowledge type k = [role, type, govpos/deppos], which is similar to a dependency feature. The gov/dep part (the other word related to the current word in a dependency relation) is considered as the knowledge value v = gov/dep. For example, if K={[WORD], [DEP, nmod:with, VBZ], [GOV, nmod:poss, PRP$]} and we have knowledge value “phone” and “works” for the first two types, we may have KB={([WORD], “phone”),\n([DEP, nmod:with, VBZ], “works”) }. We describe how to automatically obtain all knowledge types K and how to get initial knowledge values in the next section."
    }, {
      "heading" : "3 Pre-training",
      "text" : "The role of pre-training is to identify knowledge types K and initial knowledge values. It is important to obtain useful knowledge types and reliable knowledge values because some knowledge types may not help the prediction task and wrong knowledge values may be harmful to the performance of predictions. Fortunately, a trained CRF model can tell us which features are more useful for prediction and need to be enhanced with knowledge. The basic idea is to perform a traditional CRF training using primitive features and select knowledgebased features K and initial knowledge values based on the weights λ of primitive features in the trained CRF model.\nLet x′n denote a feature vector of the n-th word in an input sequence for pre-training. We use r ∈ R to denote an index about a primitive feature so x′n,r = 1 means the n-th word has a primitive feature (e.g., WORD=“phone” or (DEP, nmod:with, works, VBZ)) indexed by r. We distinguish different feature functions according to the value of yn and the primitive features indexed by r in x′n. We care about the following type of feature function, which is a multiplication of 2 indicator functions:\nf tor (yn, x ′ n) = I(yn = to)I(x ′ n,r), (1)\nIt turns all combinations of primitive features r ∈ R and tag set T into {0, 1}. Further we use a similar notation λtor for the corresponding weight. A positive weight λtor > 0 indicates a primitive feature indexed by r has positive impact on predicting tag to; while a negative weight λ to r < 0 indicates a primitive feature indexed by r has negative impact on predicting tag to.\nAfter training CRF using primitive features, we obtain the weights λtor for r ∈ R and to ∈ T , which are very important to know which primitive features are more useful for prediction and need to be expanded. We use entropy to measure the usefulness of a primitive feature. We compute the probability of each tag to for r:\npr(to) = exp(λtor )\n∑|T | l=1 exp(λtlr ) . (2)\nBased on Equation 2, we compute the entropy for a primitive feature indexed by r:\nH(r) = −\n|T | ∑\no=1\npr(to)logp r(to). (3)\nThe intuition of using entropy is that a salient primitive feature should favor some tags over the others so it has low entropy. We select primitive features that attain the maximum probability for tag to and have entropies below δ (We set δ = 0.3 for |T | = 2):\nRto = {r|H(r) < δ ∧ to = argmax tl pr(tl)}.\n(4)\nWe obtain a set of primitive features indexed by Rto and use it to generate (k, v) for tag to since each primitive feature can be interpreted as a (k, v). We group the same k under Rto to form the set Kto and use the associated v as initial knowledge value."
    }, {
      "heading" : "4 Knowledge-based Training",
      "text" : "We train KCRF using knowledge-based features in this section. A knowledge-based feature simply tells whether a feature found in an example with a specified knowledge type has some values found in the current knowledge base (or KB). We use xn to denote the feature vectors with knowledgebased features for the n-th word and use d ∈ D to denote a knowledge-based feature indexed by d in xn. So xn,d = 1 indicates that the d-th feature is a knowledge-based feature and the n-th word has a knowledge with type kd and initial knowledge value v found in KB:\nxn,d = I ( (kd, v) ∈ KB ) . (5)\nFor example, if ([DEP, nmod:with, VBZ], “works”) ∈ KB, the word “phone” has a dependency relation knowledge-based feature with type k = [DEP, nmod:with, VBZ] and v = “works” and current word knowledge-based feature k = [WORD] and v = “phone”. We denote the trained KCRF as c and its parameters λc. It predicts on x and generates probabilities p(y|x;λc) for y ∈ Y ."
    }, {
      "heading" : "5 Knowledge Expansion",
      "text" : "We perform sequence labeling on a large amount of unlabeled reviews under the same category as\nthe target entity to expand the KB using c. We assume that target entities under the same category share similar knowledge. Here the key point is to ensure the quality of the expanded knowledge since it is very easy to have harmful knowledge from unlabeled reviews without human supervision. We aggregate knowledge from reliable predictions on those reviews. To obtain a reliable prediction for the n-th word, we marginalize over y1:N of other positions except n as:\np(yn|x;λ c) =\n∑\ny1\n· · · ∑\nyn−1\n∑\nyn+1\n· · · ∑\nyN\np(y1:N |x;λ c).\n(6)\nThen if a tag to attains the maximum probability that is larger than a threshold: maxto (\np(yn = to|x;λ c) ) > δ′, we consider it as a reliable prediction for tag to at position n. The knowledgebased features kd and potential knowledge values associated with such a reliable prediction are considered as candidate knowledge. We use cKBto as the set of candidate knowledge for tag to. We further prune the knowledge since similar knowledge may appear in the knowledge base of another tag so this can make candidate knowledge from reliable predictions not reliable.\nAlgorithm 1 is to maintain high-quality knowledge during expansion. We use U to denote a set of unlabeled sequences and we transform u ∈ U to knowledge-based feature vectors x ∈ X based on current knowledge base KB (line 2). We apply KCRF c and current KB on x and get reliable prediction in line 8. We add associated knowledge in line 9) and prune it to get reliable knowledge and update KB in line 14-17. The whole process will stop once no reliable knowledge is available. Note that during knowledge expansion, KCRF c itself is never re-trained."
    }, {
      "heading" : "6 Experimental Results",
      "text" : ""
    }, {
      "heading" : "6.1 Dataset",
      "text" : "We use the dataset1 from (Xu et al., 2016b), which includes 7 products. We take 50% reviews of the first 4 products as the training data for all methods that require supervised training. The remaining reviews of the first 4 products (for in-domain test) and all reviews of the last 3 products (for outof-domain test) are test data. Similar to (Xu et al., 2016b), we also randomly select 6000 unlabeled\n1 https://www.cs.uic.edu/˜hxu/\nAlgorithm 1: Knowledge Expansion\nInput : (c,KB), with KB = {KBto |to ∈ T}, U = {u1, ..., u|U |} Output: (c,KB), with updated KB\n1 do 2 transform each u ∈ U into a sequence of knowledge-based feature vectors x ∈ X using KB 3 for x ∈ X do 4 use (c,KB) to predict 5 use Equation 6 to compute\np(yn|x;λ c) for n = 1 : N\n6 for n = 1, ..., N do 7 for to ∈ T do 8 if maxto(p(yn = to|x)) > δ ′\nthen\n9 add associated (k, v) to cKBto for k ∈ Kto\n10 end\n11 end\n12 end\n13 end 14 for to ∈ T do 15 cKBto ← cKBto − ∪tl 6=tocKB tl 16 KB.KBto ← KBto ∪cKBto\n17 end 18 cKB ← ∪tocKB to 19 while cKB 6= ∅ 20 return (c,KB)\nreviews for each category from (McAuley et al., 2015) and use them as unlabeled reviews to expand knowledge."
    }, {
      "heading" : "6.2 Compared Methods",
      "text" : "Since this paper proposes a supervised method on CER, we focus on the improvements of KCRF over CRF. We use CRFSuite2 as the base implementation of CRF. CRF(-)DR: This is a very basic CRF without dependency relations as features to show that dependency relations are useful features. We use the following features: current word, POS-tags, 4 nearby words and POS-tags on the left and right, number of digits and whether current word has slash/dash. CRF: This is the baseline with dependency relations as features. It is also the same learner as in the pre-training step of KCRF.\n2http://www.chokkan.org/software/crfsuite/\nCRF-Init: This baseline uses the trained KCRF and initial KB directly on test data without knowledge expansion on unlabeled data. KCRF: This is the proposed method that uses trained KCRF and initial KB to expand knowledge on unlabeled reviews under the same category as the target entity. We empirically set δ′ = 0.8 as the precisions of most predictions are around 0.8."
    }, {
      "heading" : "6.3 Evaluation Methods",
      "text" : "We perform evaluation on each mention of complementary entities. We count true positive tp, false positive fp and false negative fn. For each sentence, one recognized complementary entity that is contained in the annotated complementary entities for that sentence is considered as one count for the tp; one recognized complementary entity that are not found contributes one count to the fp; any annotated complementary entity that can not be recognized contributes one count to the fn. Then we compute precision P, recall R and F1-score F1 based on tp, fp and fn."
    }, {
      "heading" : "6.4 Result Analysis",
      "text" : "From Table 1, we can see that KCRF performs well on F1-score. It significantly outperforms other methods on recall, which indicates that the expanded knowledge is helpful. CRF-Init performs better than CRF on most products, which indicates that knowledge-based features are better than primitive features in general. However, we notice that in order to get a higher recall, KCRF sacrifices its precision a lot. So how to further ensure that the expanded knowledge is of high quality to keep high precision is still an open problem.\nThe performance of KCRF does not drop much for the last 3 products even though we do not have any training data for those products. This is because KCRF can utilize unlabeled data to expand knowledge about the last 3 products separately from the knowledge of the first 4 products. One\nintuitive example is that “work” can be a frequent general verb knowledge that exists in the training data for some verb related knowledge type. Then later KCRF expands such a verb to other domainspecific verbs like “insert” for Compact Flash that does not have training data."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we propose a supervised method for Complementary Entity Recognition (CER), called KCRF. KCRF can automatically identify knowledge-based features and expand knowledge as key-value pairs from plenty of unlabeled reviews. Experiments show that the expanded knowledge is useful in improving the performance of predictions, especially for products without training data."
    } ],
    "references" : [ {
      "title" : "A review",
      "author" : [ "Nguyen Bach", "Sameer Badaskar" ],
      "venue" : null,
      "citeRegEx" : "Bach and Badaskar.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bach and Badaskar.",
      "year" : 2007
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John Lafferty", "Andrew McCallum", "Fernando CN Pereira." ],
      "venue" : "Proceedings of the Eighteenth International Conference on Machine Learning (ICML",
      "citeRegEx" : "Lafferty et al\\.,? 2001",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Sentiment Analysis: Mining Opinions, Sentiments, and Emotions",
      "author" : [ "Bing Liu." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Liu.,? 2015",
      "shortCiteRegEx" : "Liu.",
      "year" : 2015
    }, {
      "title" : "Inferring networks of substitutable and complementary products",
      "author" : [ "J.J. McAuley", "R. Pandey", "J. Leskovec." ],
      "venue" : "KDD.",
      "citeRegEx" : "McAuley et al\\.,? 2015",
      "shortCiteRegEx" : "McAuley et al\\.",
      "year" : 2015
    }, {
      "title" : "Thumbs up?: sentiment classification using machine learning techniques",
      "author" : [ "Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan." ],
      "venue" : "Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for",
      "citeRegEx" : "Pang et al\\.,? 2002",
      "shortCiteRegEx" : "Pang et al\\.",
      "year" : 2002
    }, {
      "title" : "Extracting product features and opinions from reviews",
      "author" : [ "Ana-Maria Popescu", "Orena Etzioni." ],
      "venue" : "Natural language processing and text mining, Springer, pages 9–28.",
      "citeRegEx" : "Popescu and Etzioni.,? 2007",
      "shortCiteRegEx" : "Popescu and Etzioni.",
      "year" : 2007
    }, {
      "title" : "Supervised opinion aspect extraction by exploiting past extraction results",
      "author" : [ "Lei Shu", "Bing Liu", "Hu Xu", "Annice Kim." ],
      "venue" : "arXiv preprint arXiv:1612.07940 .",
      "citeRegEx" : "Shu et al\\.,? 2016",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2016
    }, {
      "title" : "Lifelong learning crf for supervised aspect extraction",
      "author" : [ "Lei Shu", "Hu Xu", "Bing Liu." ],
      "venue" : "arXiv preprint arXiv:1705.00251 .",
      "citeRegEx" : "Shu et al\\.,? 2017",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2017
    }, {
      "title" : "Mining compatible/incompatible entities from question and answering via yes/no answer classification using distant label expansion",
      "author" : [ "Hu Xu", "Lei Shu", "Jingyuan Zhang", "Philip S Yu." ],
      "venue" : "arXiv preprint arXiv:1612.04499 .",
      "citeRegEx" : "Xu et al\\.,? 2016a",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2016
    }, {
      "title" : "Cer: Complementary entity recognition via knowledge expansion on large unlabeled product reviews",
      "author" : [ "Hu Xu", "Sihong Xie", "Lei Shu", "Philip S. Yu." ],
      "venue" : "Proceedings of IEEE International Conference on Big Data.",
      "citeRegEx" : "Xu et al\\.,? 2016b",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Aspect extraction (or opinion target extraction) is an important task in sentiment analysis (Pang et al., 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).",
      "startOffset" : 92,
      "endOffset" : 111
    }, {
      "referenceID" : 5,
      "context" : ", 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).",
      "startOffset" : 27,
      "endOffset" : 83
    }, {
      "referenceID" : 2,
      "context" : ", 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).",
      "startOffset" : 27,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "A traditional supervised method like Conditional Random Field (CRF) (Lafferty et al., 2001) may have good precision on such extraction yet suffer from low recall due to unseen context words appear in the test data but not in the training data.",
      "startOffset" : 68,
      "endOffset" : 91
    }, {
      "referenceID" : 9,
      "context" : "To solve this problem, instead of using supervised method, (Xu et al., 2016b) uses an unsupervised method by leveraging manually-crafted high precision dependency rules (Bach and Badaskar, 2007; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Joshi and Penstein-Rosé, 2009) to expand (bootstrap) context words as knowledge on a large amount of unlabeled data and combine those context words with another set of manually-crafted high recall dependency rules for CER.",
      "startOffset" : 59,
      "endOffset" : 77
    }, {
      "referenceID" : 0,
      "context" : ", 2016b) uses an unsupervised method by leveraging manually-crafted high precision dependency rules (Bach and Badaskar, 2007; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Joshi and Penstein-Rosé, 2009) to expand (bootstrap) context words as knowledge on a large amount of unlabeled data and combine those context words with another set of manually-crafted high recall dependency rules for CER.",
      "startOffset" : 100,
      "endOffset" : 210
    }, {
      "referenceID" : 9,
      "context" : "We use the dataset from (Xu et al., 2016b), which includes 7 products.",
      "startOffset" : 24,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "Similar to (Xu et al., 2016b), we also randomly select 6000 unlabeled",
      "startOffset" : 11,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "reviews for each category from (McAuley et al., 2015) and use them as unlabeled reviews to expand knowledge.",
      "startOffset" : 31,
      "endOffset" : 53
    } ],
    "year" : 2017,
    "abstractText" : "Extracting opinion targets is an important task in sentiment analysis on product reviews and complementary entities (products) are one important type of opinion targets that may work together with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as a supervised sequence labeling with the capability of expanding domain knowledge as key-value pairs from unlabeled reviews, by automatically learning and enhancing knowledgebased features. We use Conditional Random Field (CRF) as the base learner and augment CRF with knowledge-based features (called the Knowledge-based CRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of supervised CER task.",
    "creator" : "LaTeX with hyperref package"
  }
}