{
  "name" : "1401.4598.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SAS+ Planning as Satisfiability",
    "authors" : [ "Ruoyun Huang", "Yixin Chen", "Weixiong Zhang" ],
    "emails" : [ "RUOYUN.HUANG@WUSTL.EDU", "CHEN@CSE.WUSTL.EDU", "WEIXIONG.ZHANG@WUSTL.EDU" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Planning as satisfiability is a principal approach to planning with many eminent advantages. The existing planning as satisfiability techniques usually use encodings compiled from STRIPS. We introduce a novel SAT encoding scheme (SASE) based on the SAS+ formalism. The new scheme exploits the structural information in SAS+, resulting in an encoding that is both more compact and efficient for planning. We prove the correctness of the new encoding by establishing an isomorphism between the solution plans of SASE and that of STRIPS based encodings. We further analyze the transition variables newly introduced in SASE to explain why it accommodates modern SAT solving algorithms and improves performance. We give empirical statistical results to support our analysis. We also develop a number of techniques to further reduce the encoding size of SASE, and conduct experimental studies to show the strength of each individual technique. Finally, we report extensive experimental results to demonstrate significant improvements of SASE over the state-of-the-art STRIPS based encoding schemes in terms of both time and memory efficiency."
    }, {
      "heading" : "1. Introduction",
      "text" : "Planning as satisfiability (SAT) is one of the main paradigms for planning. Methods using this technique usually compile a planning problem into a sequence of SAT instances, with increasing time horizons (Kautz & Selman, 1999). Planning as satisfiability has a number of distinct characteristics that make it efficient and widely applicable. It makes use of the extensive advancement in fast SAT solvers. The SAT formulae can be extended to accommodate a variety of complex problems, such as planning with uncertainty (Castellini, Giunchiglia, & Tacchella, 2003), numerical planning (Hoffmann, Kautz, Gomes, & Selman, 2007) and temporally expressive planning (Huang, Chen, & Zhang, 2009).\nA key factor for the performance of the planning as satisfiability approaches is the SAT encoding scheme, which is the way a planning problem is compiled into SAT formulae with boolean variables and clauses. As the encoding scheme has a great impact on the efficiency of SAT-based planning, developing novel and superior SAT encodings has been an active research topic. Extensive research has been done to make the SAT encoding more compact. One example of compact encoding is the lifted action representation (Kautz & Selman, 1996; Ernst, Millstein, & Weld, 1997). In this compact encoding scheme, an action is represented by a conjunction of parameters. As a result, this method mitigates the issue of blowing up encoding size. The original scheme does not guarantee the optimality on makespans. However, an improved lifted action representation that preserves optimality was proposed (Robinson, Gretton, Pham, & Sattar, 2009). A new encoding is proposed\nc©2012 AI Access Foundation. All rights reserved.\nbased on a relaxed parallelism semantic (Rintanen, Heljanko, & Niemelä, 2006), which also does not guarantee optimality.\nAll these previous enhancements are based on the conventional STRIPS formalism for planning. Recently, the SAS+ formalism (Bäckström & Nebel, 1996) attracted a lot of attention because of its rich structural information. The SAS+ formalism represents a planning problem using multi-valued state variables instead of the propositional facts in STRIPS (Bäckström & Nebel, 1996). The SAS+ formalism has been used to derive heuristics (Helmert, 2006; Helmert, Haslum, & Hoffmann, 2008), landmarks (Richter, Helmert, & Westphal, 2008), new search models (Chen, Huang, & Zhang, 2008), and strong mutual exclusion constraints (Chen, Huang, Xing, & Zhang, 2009).\nIn this paper, we proposed the first SAS+ based SAT encoding scheme (SASE) for classical planning. Unlike previous STRIPS based SAT encoding schemes that model only actions and facts, SASE directly models transitions in the SAS+ formalism. Transitions can be viewed as a highlevel abstraction of actions, and there are typically significantly fewer transitions than actions in a planning task. The proposed SASE scheme describes two major classes of constraints: first the constraints between transitions and second the constraints that match actions with transitions. We theoretically and empirically studied the new SAS+ based SAT encoding and compared it against the traditional STRIPS based SAT encoding. To further improve the performance of SASE, we proposed a number of techniques to reduce encoding size by recognizing certain structures of actions and transitions.\nWe studied the relationship between the solution space of SASE and that of STRIPS based encoding. The results showed that the solution plans found by SATPlan06, a representative STRIPS based encoding, and by SASE are isomorphic, meaning that there is a bijective mapping between the two. Hence, we showed the equivalence between solving the STRIPS based encoding and SASE.\nAs an attempt to understand the performance gain of SASE, we studied how the new encoding scheme makes a SAT solving algorithm behave in a more favorable way. The study was quantified by the widely used VSIDS heuristic (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). The transition variables that we introduced have higher frequencies in clauses, and consequently have higher VSIDS scores. The higher VSIDS scores lead to more branching on transition variables than action variables. Since the transition variables have high scores and hence stronger constraint propagation, branching more on the transition variables leads to faster SAT solving. We provided empirical evidence to support our explanation. Moreover, we introduced an indicator called the transition index, and empirically showed that there is a strong correlation between the transition index and SAT solving speedup.\nFinally, we evaluated SASE on the standard benchmarks from the recent International Planning Competitions. Our results show that the new SASE encoding scheme is more efficient in both terms of time and memory usage compared to STRIPS-based encodings, and solves some large instances that the state-of-the-art STRIPS-based SAT planners fail to solve.\nThe paper is organized as follows. After giving some basic definitions in Section 2, we present our SAS+ based SASE encoding in Section 3 and prove its equivalence to the STRIPS based encoding in Section 4. We study why SASE works better for modern SAT solvers in Section 5. The techniques to further reduce the encoding size are presented in Section 6. We present our experimental results in Section 7. Finally, we review related works and conclude in Section 8."
    }, {
      "heading" : "2. Background",
      "text" : "In this section, we first briefly introduce the STRIPS formalism and review a representative STRIPS based SAT encoding. Then, we define the SAS+ formalism, from which we develop the new SAT encoding scheme."
    }, {
      "heading" : "2.1 The STRIPS Formalism",
      "text" : "The traditional STRIPS planning representation is defined over binary-valued propositional facts. A STRIPS planning problem is a tuple Ψ = (F ,A, ϕI , ϕG), where:\n• F is a set of propositional facts;\n• A is a set of actions. Each action a ∈ A is a triple a = (pre(a), add(a), del(a)), where pre(a) ⊆ F is the set of preconditions, and add(a) ⊆ F and del(a) ⊆ F are the sets of add facts and delete facts, respectively;\n• A state ϕ ⊆ F is a subset of facts that are assumed true. Any fact not in ϕ is assumed false in this state. ϕI ⊆ F is the initial state, and ϕG ⊆ F is the specification of a goal state or goal states.\nWe define three sets of actions. We use ADD(f) to denote the set of actions that have f as one of their add effects, meaning ADD(f) = {a | f ∈ add(a)}. Similarly, two other action sets are DEL(f) = {a | f ∈ del(a)} and PRE(f) = {a | f ∈ pre(a)}.\nAn action a is applicable to a state ϕ if pre(a) ⊆ ϕ. We use apply(ϕ, a) to denote the state after applying an applicable action a to ϕ, in which variable assignments are changed into (ϕ \\ del(a)) ∪ add(a). We also write apply(s, P ) to denote the state after applying a set of actions P in parallel, P ⊆ A, to s. A set of actions P is applicable to ϕ, when 1) each a ∈ P is applicable to ϕ, and 2) there does not exist two actions a1, a2 ∈ P such that a1 and a2 are mutually exclusive (mutex) (Blum & Furst, 1997). Two actions a and b are mutex at time step t when one of the following three conditions holds:\n• Inconsistent effects: del(a) ∩ add(b) 6= ∅ or del(b) ∩ add(a) 6= ∅.\n• Interference: del(a) ∩ pre(b) 6= ∅ or del(b) ∩ pre(a) 6= ∅.\n• Competing needs: There exist f1 ∈ pre(a) and f2 ∈ pre(b), such that f1 and f2 are mutex at time step t− 1.\nTwo facts f1 and f2 are mutex at a time step if, for all actions a and b such that f1 ∈ add(a), f2 ∈ add(b), a and b are mutex at the previous time step. We call this mutex defined on planning graphs as P-mutex, in order to distinguish this mutex from another notion of mutex in the next section.\nDefinition 1 (Parallel solution plan). For a STRIPS planning problem Ψ = (F ,A, ϕI , ϕG), a parallel solution plan is a sequence P = {P1, P2, . . . , PN}, where each Pt ⊆ A, t = 1, 2, . . . , N , is a set of actions executed at time step t, such that\nϕG ⊆ apply(. . . apply(apply(ϕI , P1), P2) . . . PN ).\n2.2 STRIPS Based SAT Encoding (PE)\nA SAT instance is a tuple (V,C), where V is a set of variables and C is a set of clauses. Given a SAT instance (V,C), an assignment Γ sets every variable v ∈ V true or false, denoted as Γ(v) = ⊥ or Γ(v) =⊥. If an assignment Γ makes every clause in C to be true, then Γ is a solution to (V,C). The encoding scheme by SatPlan06 (Kautz, Selman, & Hoffmann, 2006) (denoted as PE in the following), which is compiled from planning graphs, is a well known and extensively tested STRIPS based encoding. To facilitate the encoding, SatPlan06 introduces a dummy action dumf which has f as both its precondition and add-effect. We use A+ to denote the set of actions when dummy actions are added, which is A ∪ {dumf | ∀f ∈ F}. Unless otherwise indicated, action set ADD(f), DEL(f), and PRE(f) all include the corresponding dummy actions.\nWe denote a SatPlan06 encoding up to time step N as PE(Ψ, N), for a given STRIPS task Ψ = (F ,A, ϕI , ϕG). As a SAT instance, PE(Ψ, N) is defined by (V,C), where V = {Wf,t|f ∈ F , t ∈ [1, N + 1]} ∪ {Wa,t|a ∈ A +, t ∈ [1, N ]}. Wf,t = ⊥\nindicates that f is true at t, otherwise Wf,t =⊥. The clause set C includes the following types of clauses:\nI. Initial state: (∀f, f ∈ ϕI): Wf,1;\nII. Goal state: (∀f, f ∈ ϕG): Wf,N+1;\nIII. Add effect: (∀f ∈ F , t ∈ [1, N ]): Wf,t+1 → ∨ ∀a,f∈add(a)Wa,t;\nIV. Precondition: (∀a ∈ A+, f ∈ pre(a), t ∈ [1, N ])): Wa,t → Wf,t;\nV. Mutex of actions: (∀a, b ∈ A+, t ∈ [1, N ], a and b are mutex): W a,t ∨W b,t;\nVI. Mutex of facts: (∀f, g ∈ F , t ∈ [1, N + 1], f and g are mutex) : W f,t ∨W g,t;\nClauses in class I and II enforce that the initial state is true at the first time step, and that the goal facts need to be true at the last time step, respectively. Clauses in class III specify that if a fact f is true at time step t, then there is at least one action a ∈ A+ at time step t − 1 that has f as an add effect. Clauses of class IV specify that if an action a is true at time t, then all its preconditions are true at time t. Classes V and VI specify mutex between actions and facts, respectively.\nPE is one of the most typical SAT encoding schemes for STRIPS planning. It has both action variables and fact variables, and enforces the same semantics as the one defined by a planning graph. Later we will show the equivalence between our new SASE encoding and PE."
    }, {
      "heading" : "2.3 The SAS+ Formalism",
      "text" : "The SAS+ formalism (Bäckström & Nebel, 1996) represents a classical planning problem by a set of multi-valued state variables. A planning task Π in the SAS+ formalism is defined as a tuple Π = {X ,O, sI , sG}, where\n• X = {x1, · · · , xN} is a set of state variables, each with an associated finite domainDom(xi);\n• O is a set of actions and each action a ∈ O is a tuple (pre(a), eff(a)), where pre(a) and eff(a) are sets of partial state variable assignments in the form of xi = v, v ∈ Dom(xi);\n• A state s is a full assignment (a set of assignments that assigns a value to every state variable). If an assignment (x = f) is in s, we can write s(x) = f . We denote S as the set of all states.\n• sI ∈ S is the initial state, and sG is a partial assignment of some state variables that define the goal. A state s ∈ S is a goal state if sG ⊆ s.\nWe first define what transition is. In this paper, we build constraints by recognizing that transitions are atomic elements of state transitions. Actions, cast as constraints as well in our case, act as another layer of logic flow over transitions.\nDefinition 2 (Transition). For a SAS+ planning task Π = {X ,O, sI , sG}, given a state variable x ∈ X , a transition is a re-assignment of x from value f to g, f, g ∈ Dom(x), written as δxf→g, or from an unknown value to g, written as δx∗→g. We may also simplify the notation of δ x f→g as δf→g or δ, when there is no confusion.\nTransitions in a SAS+ planning task can be classified into three categories.\n• Transitions of the form δxf→g are called regular. A regular transition δ x f→g is applicable to a\nstate s, iff s(x) = f . Let s′ = apply(s, δxf→g) be the state after applying transition δ to state s, we have s′(x) = g.\n• Transitions of the form δxf→f are called prevailing. A prevailing transition δ x f→f is applicable\nto a state s iff s(x) = f , and apply(s, δxf→f ) = s.\n• Transitions of the form δx∗→g are called mechanical. A mechanical transition δ x ∗→g can be\napplied to an arbitrary state s, and the result of apply(s, δx∗→g) is a state s ′ with s′(x) = g.\nA transition is applicable at a state s only in the above three cases. For each action a, we denote its transition set as Trans(a), which includes: all regular transitions δxf→g such that (x = f) ∈ pre(a) and (x = g) ∈ eff(a), all prevailing transitions δxf→f such that (x = f) ∈ pre(a), and all mechanical transitions δx∗→g such that (x = g) ∈ eff(a). Given a transition δ, we useA(δ) to denote the set of actions a such that δ ∈ Trans(a). We call A(δ) the supporting action set of δ.\nFor a state variable x, we introduce T (x) = {δxf→g}∪{δ x f→f}∪{δ x ∗→g}, for all f, g ∈ Dom(x), which is the set of all transitions that affect x. We also define T as the union of T (x), ∀x ∈ X . T is the set of all transitions. We also use R(x) = {δxf→f | ∀f, f ∈ Dom(x)} to denote the set of all prevailing transitions related to x, and R the union of R(x) for all x ∈ X .\nDefinition 3 (Transition Mutex). For a SAS+ planning task, two different transitions δ1 and δ2 are mutually exclusive iff there exists a state variable x ∈ X such that δ1, δ2 ∈ T (x), and one of the following holds:\n1. Neither δ1 nor δ2 is a mechanical transition.\n2. At least one of δ1 and δ2 is a mechanical transition, with δ1 and δ2 transit to different values.\nA set of transitions T is applicable to a state s when 1) every transition δ ∈ T is applicable to s, and 2) there do not exist two transitions δ1, δ2 ∈ T such that δ1 and δ2 are mutually exclusive. When T is applicable to s, we write apply(s, T ) to denote the state after applying all transitions in T to s in an arbitrary order.\nDefinition 4 (Transition Plan). A transition plan is a sequence of {T1, T2, . . . , TN}, where each Tt, t ∈ [1, N ], is a set of transitions executed at time step t, such that\nsG ⊆ apply(. . . apply(apply(sI , T1), T2) . . . TN ).\nIn a SAS+ planning task, for a given state s and an action a, when all variable assignments in pre(a) match the assignments in s, a is applicable in state s. We use apply(s, a) to denote the state after applying a to s, in which variable assignments are changed according to eff(a).\nDefinition 5 (S-Mutex). For a SAS+ planning task Π = {X ,O, sI , sG}, two actions a1, a2 ∈ O are S-mutex iff either of the following holds:\n1. There exists a transition δ, such that δ is not prevailing (δ 6∈ R), and δ ∈ Trans(a1) and δ ∈ Trans(a2). Actions a1 and a2 in this case deletes each other’s precondition.\n2. There exist two transitions δ and δ′ such that they are mutually exclusive to each other and δ ∈ Trans(a1) and δ ′ ∈ Trans(a2).\nWe named this mutex in SAS+ planning S-mutex to distinguish it from the P-mutex defined in STRIPS planning. We will show in Section 4 that these two types of mutual exclusions are equivalent. Therefore, in this paper we in general use the single term mutual exclusion (mutex) for both, unless otherwise indicated.\nFor a SAS+ planning task, we write apply(s, P ) to denote the state after applying a set of actions P , P ⊆ O, to s. A set of actions P is applicable to s when 1) each a ∈ P is applicable to s, and 2) there are no two actions a1, a2 ∈ P such that a1 and a2 are S-mutex.\nDefinition 6 (Action Plan). For a SAS+ task, an action plan is a sequence P = {P1, . . . , PN}, where each Pt, t ∈ [1, N ], is a set of actions executed at time step t such that\nsG ⊆ apply(. . . apply(apply(sI , P1), P2) . . . PN ).\nThe definition of an action plan for SAS+ planning is essentially the same as that for STRIPS planning (Definition 1). The relation between transition plan and action plan is the key to the new encoding scheme introduced in this paper. There always exists a unique transition plan for a valid action plan. In contrast, given a transition plan, there may not be a corresponding action plan; or there could be multiple corresponding action plans.\nDefinition 7 (Step Optimal Plan). For a SAS+ planning task, a step optimal plan is an action plan P = {P1, . . . , PN} with the minimum N .\nIt is worth noting that there are a few different optimization metrics in classical planning research, including step optimality (Definition 7), the number of actions and the total action cost. The criteria used in recent IPC competitions (The 6th Int’l Planning Competition, 2008; The 7th Int’l Planning Competition, 2011) is the total action cost. While step optimality is a widely used criterion, action cost is a more realistic criterion in many domains such as those involving numerical resources. Nevertheless, action cost assumes plans to be sequential. In other words, it does not consider concurrency between actions, which is a limitation in many cases.\nThe step optimality was introduced in GraphPlan (Blum & Furst, 1997), and became more popular when planning graph analysis was used in several planning systems (Kautz & Selman, 1999; Hoffmann & Nebel, 2001; Do & Kambhampati, 2000). Step optimality takes the concurrency between actions into consideration, although it assumes a same unit duration for all actions. The planning methods for step optimality, in particular SAT-based planners, can potentially be made useful for other optimization metrics, which is a topic of our future work.\n3. SAS+ Based SAT Encoding (SASE)\nWe now introduce our new encoding for SAS+ planning tasks, denoted as SASE. We use the same search framework as SatPlan: start with a small number of time steps N and increase N by one after each step until a satisfiable solution is found. For a given N , we encode a planning task as a SAT instance which can be solved by a SAT solver. A SASE instance includes two types of binary variables:\n1. Transition variables: Uδ,t, ∀δ ∈ T and t ∈ [1, N ], which may also be written as Ux,f,g,t when δ is explicitly δxf→g;\n2. Action variables: Ua,t, ∀a ∈ O and t ∈ [1, N ].\nAs to constraints, SASE has eight classes of clauses for a SAS+ planning task. In the following,\nwe define each class for every time step t ∈ [1, N ] unless otherwise indicated.\nA. Initial state: ∀x, sI(x) = f , ∨\n∀δf→g∈T (x) Ux,f,g,1;\nB. Goal: ∀x, sG(x) = g, ∨\n∀δf→g∈T (x) Ux,f,g,N ;\nC. Progression: ∀δxh→f ∈ T and t ∈ [1, N − 1], Ux,h,f,t → ∨\n∀δx f→g\n∈T (x) Ux,f,g,t+1;\nD. Regression: ∀δxf→g ∈ T and t ∈ [2, N ], Ux,f,g,t → ∨\n∀δx f ′→f\n∈T (x) Ux,f ′,f,t−1;\nE. Transition mutex: ∀δ1∀δ2 such that δ1 and δ2 are transition mutex, U δ1,t ∨ U δ2,t;\nF. Composition of actions: ∀a ∈ O, Ua,t → ∧ ∀δ∈Trans(a) Uδ,t;\nG. Action existence: ∀δ ∈ T \\R, Uδ,t → ∨ ∀a,δ∈Trans(a) Ua,t;\nH. Action mutex: ∀a1∀a2 such that ∃δ, δ ∈ T (a1) ∩ T (a2) and δ 6∈ R, Ua1,t ∨ Ua2,t;\nClauses in classes C and D specify and restrict how transitions change over time steps. Clauses in class E enforce that at most one related transition can be true for each state variable at each time step. Clauses in classes F and G together encode how actions are composed to match the transitions. Clauses in class H enforce the mutual exclusions between actions.\nNote that there are essential differences between transition variables in SASE and fact variables in PE. In terms of semantics, a transition variable at time step n in SASE is equivalent to the conjunction of two fact variables in PE, at time step n and n + 1, respectively. Nevertheless, fact variables are not able to enforce a transition plan as transition variables do. This is because\ntransition variables not only imply the values of multi-valued variables, but also enforce how these values propagate over time steps.\nIn addition, transition variables are different from action variables regarding their roles in SAT solving. This is because in SASE, action variables only exist in the constraints for transition-action matching, but not in the constraints between time steps. Transition variables exist in both. Thus transition variables appear more frequently in a SAT instance. The inclusion of those high-frequency variables can help the SAT solvers through the VSIDS rule for variable branching. We shall discuss this issue further and provide an empirical study, in Section 5.\nWe now show how SASE works using an example. Consider a planning task with two multivalued variables x and y, where Dom(x) = {f, g, h} and Dom(y) = {d, e}. There are three actions a1 = {δxf→g, δ y d→e}, a2 = {δ x f→g, δ y e→d} and a3 = {δ x g→h, δ y e→d}. The initial state is {x = f, y = d} and the goal state is {x = h, y = d}. One solution to this instance is a plan of two actions: a1 at time step 1 and then a3 at time step 2.\nIn the following we list the constraints between transitions and actions, namely those specified in classes F and G. The clauses in other classes are self-explanatory. In particular, here we only list the variables and clauses for time step 1, because these constraints all repeat for time step 2. The transition variables at time step 1 are { Ux,f,g,1, Ux,f,f,1, Ux,g,h,1, Ux,g,g,1, Ux,h,h,1, Uy,d,d,1, Uy,e,e,1, Uy,e,d,1, Uy,d,e,1 }, and they repeat for time step 2. The action variables at time step 1 are { Ua1,1, Ua2,1, Ua3,1}, and they repeat for time step 2.\nThe clauses in class F are: Ua1,1 ∨ Ux,f,g,1, Ua1,1 ∨ Ux,d,e,1, Ua2,1 ∨ Ux,f,g,1, Ua2,1 ∨ Uy,e,d,1, Ua3,1 ∨Ux,g,h,1 and Ua3,1 ∨Ux,e,d,1. The clauses in class G are Ux,f,g,1 ∨Ua1,1 ∨Ua2,1, Ux,g,h,1 ∨ Ua3,1, Uy,d,e,1 ∨ Ua1,1, and Uy,e,d,1 ∨ Ua2,1 ∨ Ua3,1.\nThe solution, in terms of actions, has action variables Ua1,1 and Ua3,2 to be\n⊥ , and all other ac-\ntion variables⊥. In addition, the corresponding transition plan has the following transition variables\n⊥ : {Ux,f,g,1, Ux,g,h,2, Uy,d,e,1, Uy,e,d,2}, while all other transition variables are false.\nAs mentioned above, although there are often multiple transition plans, a transition plan may not correspond to a valid action plan. In this particular example, there are several different transition plans that satisfy the initial and the goal states, but some of them do not have a corresponding action plan. For example, suppose transition variables {Ux,f,g,1, Ux,g,h,2, Uy,d,d,1, Uy,d,d,2} to be true. This qualifies as a transition plan, because the goals are achieved. This transition plan however does not lead to a valid action plan."
    }, {
      "heading" : "4. Correctness of SAS+ Based Encoding",
      "text" : "It is important to prove the correctness of the proposed encoding. We achieve this by proving that SASE for SAS+ planning has the same solution space as that of PE used in STRIPS planning. More specifically, we show that, for a given planning task and a given time stepN , the SAT instance from SASE is satisfiable if and only if the SAT instance from PE is satisfiable. Here, we assume the correctness of the PE encoding, in SatPlan06 (Kautz et al., 2006) for STRIPS planning.\nPE(Ψ, N) denotes the PE formula that corresponds to the N-step planning problem. SASE(Π, N) gives the formula in the case of SASE encoding of the equivalent SAS+ problem."
    }, {
      "heading" : "4.1 Solution Structure of STRIPS Based Encoding",
      "text" : "In this section, we study a few properties of the solutions in a STRIPS based encoding. These properties provide some key insights for establishing the relationship between PE and SASE encodings.\nLemma 1 Given a STRIPS task Ψ = (F ,A, ϕI , ϕG), a time step N , and its PE SAT instance PE(Ψ, N) = (V,C), suppose there is a satisfiable solution denoted as Γ, a fact f ∈ F , and t ∈ [1, N ] such that: 1) Γ(Wdumf ,t) =⊥, 2) Γ(Wf,t) = ⊥\n, and 3) ∀a ∈ DEL(f), Γ(Wa,t) =⊥, then we can construct an alternative solution Γ′ to PE(Ψ, N) as follows:\nΓ′(v) =\n{ ⊥\n, v = Wdumf ,t, v ∈ V\nΓ(v), v 6= Wdumf ,t, v ∈ V (1)\nProof This can be proved by showing that Γ′ satisfies every individual clause in C. See Appendix A for more details.\nLemma 2 Given a STRIPS task Ψ = (F ,A, ϕI , ϕG), a time step N , and its PE SAT instance PE(Ψ, N) = (V,C), suppose there is a satisfiable solution denoted as Γ, a fact f ∈ F , and t ∈ [1, N ] such that: 1) Γ(Wf,t) =⊥, 2) there exists an action a ∈ ADD(f) such that Γ(Wa,t−1) = ⊥ , then we can construct an alternative solution Γ′ to PE(Ψ, N) as follows:\nΓ′(v) =\n{ ⊥ , v = Wf,t, v ∈ V\nΓ(v), v 6= Wf,t, v ∈ V (2)\nProof We can prove this by showing that Γ′ makes every individual clause (three types) in C to be true. See Appendix A for more details.\nLemmas 1 and 2 show that under certain conditions, some dummy action variables and fact variables in PE are free variables. They can be set to be either true or false while the SAT instance remains satisfied. Although we can manipulate these free variables to construct an alternative solution Γ′ from a given solution Γ, both Γ and Γ′ refer to the same STRIPS plan, because there is no change to any action variable. This leads to an important insight concerning the solutions of PE: a solution plan to a STRIPS planning problem Ψ may correspond to multiple solutions to PE(Ψ, N).\nProposition 1 Given a STRIPS task Ψ = (F ,A, ϕI , ϕG), a time step N , and its PE SAT instance PE(Ψ, N) = (V,C), those clauses that define competing needs mutex and fact mutex can be inferred from other clauses in PE(Ψ, N).\nThese mutexes are implied by the PE formula, thus by the completeness of resolution, Proposition 1 is true. Proposition 1 implies that when encoding a STRIPS task, it is not necessary to encode fact mutex and competing needs action mutex, as they are implied by other clauses. Therefore, while considering the completeness and correctness of PE, we can ignore these redundant clauses. Analysis with a similar conclusion can be found in the literature (Sideris & Dimopoulos, 2010), although different approaches are used."
    }, {
      "heading" : "4.2 Equivalence of STRIPS and SAS+ Based Encodings",
      "text" : "A classical planning problem can be represented by both STRIPS and SAS+ formalisms that give rise to the same set of solutions. Given a STRIPS taskΨ = (F ,A, ϕI , ϕG) and its equivalent SAS+ planning task Π = (X ,O, sI , sG), the following isomorphisms (bijective mappings) exist:\n• φf : F → ∏\nX Dom(X) (a binary STRIPS fact corresponds to an variable assignment in SAS+);\n• φa : A → O (a STRIPS action corresponds to a SAS+ action);\n• φi : ϕI → sI (can be derived from φf );\n• φg : ϕG → sG (can be derived from φf ).\nFurthermore, since both formalisms represent the same planning task, these mappings preserve the relations between actions and facts. For example, if f ∈ pre(a) where f ∈ F and a ∈ A in a STRIPS formalism, we have φf (f) ∈ pre(φa(a)) in the SAS+ formalism.\nFirst, we show that the parallelism semantics enforced by S-mutex in SAS+ is equivalent to that\nof P-mutex in STRIPS.\nLemma 3 Given a SAS+ planning task Π = (X ,O, sI , sG) and its equivalent STRIPS task Ψ = (F ,A, ϕI , ϕG), suppose we have actions a, b ∈ O, and their equivalent actions a\n′, b′ ∈ A (i.e. a = φa(a ′) and b = φa(b ′)), a and b are S-mutex iff a′ and b′ are P-mutex.\nProof We can prove this by showing in both directions that given two actions with one type of mutex, there is also mutux of the other type. Details are in Appendix A.\nLemma 3 connects P-mutex and S-mutex. Based on that we can construct the relations between\nthe encodings, which are used in the proofs of both Theorems 1 and 2, respectively.\nTheorem 1 Given a STRIPS task Ψ and a SAS+ task Π that are equivalent, for a time step bound N , if PE(Ψ, N) is satisfiable, SASE(Π, N) is also satisfiable.\nProof We prove this theorem by construction. Suppose we know the solution to PE, we prove that we can construct a solution to SASE accordingly. Details are in Appendix A.\nTheorem 2 Given a STRIPS task Ψ and a SAS+ task Π that are equivalent, for a time step bound N , if SASE(Π, N) is satisfiable, PE(Ψ, N) is also satisfiable.\nProof This can be proved by using the same technique used for Theorem 1. See Appendix A for more details.\nFrom Theorems 1 and 2, we reach the following conclusion.\nTheorem 3 A classical planning problem is solvable by the PE encoding if and only if it is solvable by the SASE encoding. Further, for solvable problems, the solution plans found by the two encodings have the same, optimal makespan.\nTheorem 3 reveals that a planning solution can be found by SASE if and only if it can be found by PE. In terms of SAT solutions, the proofs show that there is an epimorphism (a surjective mapping) between the solutions to PE and the solutions to SASE. That is, multiple SAT solutions in\nPE map to one SAT solution in SASE and every SAT solution in SASE is mapped from at least one SAT solution in PE. This is due to the existence of free variables in the PE encoding. One solution in SASE corresponds to a group of solutions in PE with the same assignments to real action variables but different assignments to the free variables."
    }, {
      "heading" : "5. SAT Solving Efficiency on Different Encodings",
      "text" : "In Section 4, we showed that PE and SASE are semantically equivalent in that they have the same solution space. In this section, we study what makes them different regarding SAT solving efficiency. In particular, we want to understand how PE and SASE make a SAT solver behave differently on the same planning task. Modern SAT solvers, which nowadays all employ many sophisticated techniques, are too complicated to be characterized by simple models. In general, it is difficult to accurately estimate the time that a SAT solver needs to solve a SAT instance. In this section, we provide an explanation of why the SAT encodings from SASE are more efficient for SAT solvers to solve than the SAT encodings from PE, and provide empirical evidence to support this explanation.\nIn this section, we first discuss SASE’s problem structure in Section 5.1 and the reason that the widely used SAT solving heuristic VSIDS (Moskewicz et al., 2001) works better on SASE encodings. The idea of VSIDS is to select those variables that appear frequently in the original and learnt clauses, since they lead to stronger constraint propagation and space pruning. If we order all the variables by their VSIDS scores, a large population of the top-ranked transition variables introduced in SASE have higher VSIDS scores than the top-ranked action variables. As a result, those top-ranked transition variables are selected more often and provide stronger constraint propagation, speeding up SAT solving.\nWe study the significance of transition variables, and explain why they make search more efficient. In Section 5.2, we present a comparison on transition variables versus action variables. In Section 5.3, we show how often transition variables are chosen as decision variables, which is a direct evidence of transition variables’ significance.\nFinally, in Section 5.4 we empirically define a significance index of transition variables. This index measures the significance of transition variables within the context of the VSDIS heuristic, and correlates with the speedup in SAT solving. All analysis in this section uses SatPlan06 as the baseline."
    }, {
      "heading" : "5.1 VSIDS Heuristic in SAT Solving",
      "text" : "The SAT solvers we use are based on the Conflict Driven Clause Learning framework. A decision variable refers to the one selected as the next variable for branching. Once a decision variable is chosen, more variables could be fixed by unit propagation. The ordering of decision variables significantly affects the problem solving efficiency. Most existing complete SAT algorithms use variants of the VSIDS heuristic (Moskewicz et al., 2001) as their variable ordering strategy.\nThe VSIDS heuristic essentially evaluates a variable by using the Exponential Moving Average (EMA) of the number of times (frequency) it appears in all the clauses. This frequency value keeps changing because of the learnt clauses. Therefore, VSIDS uses a smoothing scheme which periodically scales down the scores of all variables by a constant in order to reflect the importance of recent changes in frequencies. The variable that occurs most frequently usually has a higher value, thus also a higher chance of being chosen as a decision variable. A random decision is made if there is a tie. Thus, variables associated with more recent conflict clauses have higher priorities. We\nfirst consider the frequency in the original clauses only. Then we investigate further by taking the periodic update into consideration.\nGiven the fact that the frequency is used as the main measurement, VSIDS will be most effective when the difference between variables’ frequencies are large and there are some variables with high frequencies. If all variables have the same frequency, then picking decision variables will be purely random. Further, variables with high frequencies are desirable since they lead to stronger constraint propagation.\nThe major difference between the SAT instances in PE and SASE is that in the latter encoding, actions are not responsible for the constraint propagation across time steps. Figure 1 illustrates their difference. In SASE, the SAT instance can be conceptually reduced to the following search problem of two hierarchies.\n• At the top level, we search for a transition plan as defined in Definition 4. This amounts to finding a set of transitions for each time step t (corresponding to all δ such that Uδ,t is set to⊥\n), so that they satisfy the clauses in classes A-E of the SASE encoding.\n• At the lower level, we try to find an action plan that satisfies the transition plan. In other words, for a given transition plan that satisfies clauses in classes A-E, we try to find an action\nplan satisfying clauses in classes F-H."
    }, {
      "heading" : "5.2 Transition Variables versus Action Variables",
      "text" : "Let us first formulate how the frequency of a variable is measured. Given a SAT instance (V,C), for each variable v ∈ V , we define a function h(v) to indicate the frequency of v. That is, h(v) is the number of clauses that v appears in. We sort all variables in V by their h values in a descending order, and study the variables above a certain h value.\nDefinition 8 (High h Value Variable Set). Given a SAT instance (V,C), for a h′ ∈ {h(v) | v ∈ V }, we denote V (h′) as the set of all variables v ∈ V such that h(v) ≥ h′.\nWe further define percentile and top variable set to quantify our analysis. Instead of a specific\nh() value, we use a percentage of all h values to make the analysis comparable across instances.\nDefinition 9 (Percentile). Given a SAT instance (V,C), the percentile hp (0 ≤ p ≤ 100), is the h value of a variable v ∈ V , such that at least p% of the variables v′ ∈ V have h(v′) larger than or equal to hp.\nDefinition 10 (Top p Variable Set). Given a SAT instance (V,C) and a percentile hp, we call V (hp) the top p variable set, denoted as V p.\nWe use Vo and Vδ to denote the action variables and transition variables in V , respectively. We also define V po = Vo∩V p, and similarly V pδ = Vδ ∩V p. Table 1 compares the h values of transition variables and action variables in SAT instances. This table has two parts. For the first part, we list the average and standard deviation of h values for both transition variables and action variables. The data are collected from the first satisfiable SAT instance of the largest solvable planning task in every domain that we consider. From the average h value, it is evident that in most domains transition variables occur more frequently than action variables. Furthermore, the standard deviation of transition variables are in general not only larger than action variables’ standard deviation, but also even larger than the expected value of transition variables. The high frequencies of transition variables, along with large standard deviations, are preferred by the VSIDS heuristic and can aid SAT solving, as we discussed earlier.\nThe second part lists the average h values for transition variables and action variables, in the top p variable set with different values of p: 1%, 2%, 5% and 10%. The difference between V po and V pδ is very large. In most domains, transition variables dominate the top variable sets, while action variables exist in the top 10% variable set in only a few domains. One exception is the Airport domain. However, even in this domain, although the average h value of all transition variables is smaller than the average h value of action variables, among the top 1% variables, the average h value of transition variables is larger than the average h value of action variables. Since VSIDS picks the variable with the highest heuristic value, transition variables have higher chances be picked as the decision variables."
    }, {
      "heading" : "5.3 Branching Frequency of Transition Variables",
      "text" : "In Section 5.2, we considered the difference between transition variables and action variables, in terms of the h values. As mentioned earlier, however, the VSIDS heuristic periodically updates heuristic values of all variables. The dynamic updating of heuristic values is not captured by the above analysis. In the following, we present more direct empirical evidence to show that transition variables are indeed chosen more frequently than action variables for branching, especially at early stages of SAT solving. That is, a SAT solver spends most of its time deciding an appropriate transition plan. This analysis takes into consideration VSIDS’s dynamic updating strategy.\nWe empirically test the probabilities that transition variables and action variables are chosen as branching variables. We measure for every k consecutive decision variables, the number of transition variables (Mδ) and action variables (Mo) selected as the decision variables. If all variables are selected equally likely, we should have\nE(Mδ) = k |Vδ|\n|Vδ|+ |Vo| and E(Mo) = k\n|Vo|\n|Vδ|+ |Vo| , (3)\nwhich implies: E(Mδ)\nk|Vδ| =\nE(Mo)\nk|Vo| (4)\nWe empirically study where we divide the SAT solving process into epoches of length k = 1000 each, for all domains from IPC-3 to IPC-6. We present the results of three representative domains in Figure 2, and the results on all domains in Figures 9 and 10 in Appendix B. In each domain, we choose an instance with at least 100,000 decisions. In some domains (e.g. Woodworking), even the biggest instance has only thousands of decisions. In such a case, we choose the instance with the largest number of decisions. For every epoch, we plot the branching frequency, which is Mδ k|Vδ| for transition variables and Mo k|Vo| for action variables, respectively. According to (4), these two branching frequencies should be about the same if the two classes of variables are chosen equally likely.\nThe results from Openstacks and Zenotravel show clear distinctions between transition variables and action variables. While they are evidently different, the branching frequencies in Openstack has a higher variance. The results of Storage domain show a completely different pattern, where variables do not distinguish by their branching frequencies.\nFrom Figures 9 and 10, it is evident that, for all these instances except Storage-12 andWoodworking-\n20, the branching frequencies of transition variables are higher than that of action variables. In fact, in many cases, the branching frequencies of transition variables can be up to 10 times higher than those of action variables. In Transport-26 and Zenotravel-15, the difference is orders of magnitude larger. Hence, this empirical study shows that the SAT solvers branch much more frequently on the newly introduced transition variables than the action variables."
    }, {
      "heading" : "5.4 Transition Index and SAT Solving Speedup",
      "text" : "The behavior of transition variables, as presented above, suggests that there is a correlation between the significance of transition variables and the speedup that SASE achieves. Nevertheless, the study on branching frequency only profiles the connection by showing what happens during SAT solving. Another interesting study should reveal what leads to the speedup in a more direct way. To quantify the analysis, we introduce transition index.\nAs mentioned earlier, the h value does not exactly reflect how VSIDS works, as it updates dynamically throughout SAT solving. Nevertheless, by putting together all variables and studying their h values, the statistics on the population leads to the following definition of the transition index.\nDefinition 11 (Transition Index). Given a planning problem’s SAT instance (V,C), we measure the top p(0 ≤ p ≤ 100) variable set, and calculate the transition index of p as follows:\n|V pδ |/|V p|\n|Vδ|/|V |\nEssentially, the transition index measures the relative density of transition variables in the top variable set. If the distribution of the transition variables is homogeneous under the total ordering based on h, |V pδ |/|V p| should equal to |Vδ|/|V | for any given p. A transition index larger than 1 indicates that the transition variables have a higher-than-normal density in the top p% variable set. The larger the transition index is, the more often the transition variables occurring in the top p% variable set.\nGiven a planning problem’s SAT instance, there is correlation between its transition index and the speedup SASE provides. In Figures 3 and 4 we measure such correlation for all the domains from IPC-3 to IPC-6. Each dot in one of the figures refers to an individual planning instance. The y-axis is the speedup of SASE over SatPlan06. The x-axis is the transition index under a given p. Bootstrap aggregating (Breiman, 1996) is used for the regression lines. For each measurement, we calculate Spearman’s rank correlation coefficient (Myers & Well, 2003), which assesses how well the relationship between two variables can be described using a monotonic function. If there are no repeated data values, a perfect Spearman’s correlation coefficient of 1 occurs when each of the variables is a perfect monotone function of the other.\nThe instances included in Figure 3 are those solved by both SatPlan06 and SASE, with Precosat as the SAT solver. To reduce noise, we do not consider those small instances that both SASE and SatPlan06 spend less than 1 second to solve. In total we have 186 instances. The speedup of each instance is SASE’s SAT solving time divided by SatPlan06’s SAT solving time, which is greater than 1 in most cases. It can be observed there is a trend that a larger transition index leads to higher speedup. Such a result links the significance of top ranked (high frequency) transition variables to the speedup in SAT solving.\nIn Figure 3 there is a cluster of instances of small transition indices (to the bottom-left of each plot in Figure 3). These instances distinguish themselves by having much smaller transition indexes. In fact, it turns out that these instances are all from either the Airport or the Rovers domain and have the same property: there are a very high number of action mutual exclusions, contributing to the majority of clauses. On the other hand, mutual exclusions are binary constraints, which do not contribute significantly to a SAT problem’s hardness, because they are trivial for unit propagation. As mentioned earlier, transition index is merely a heuristic to indicate the significance of transition variables. In these instances, the enormous number of action mutual exclusion constraints makes the transition index small. However, they do not make the problems harder, because two-literal clauses are trivial for SAT solving. As a result, we can ignore these outlier instances in our correlation analysis. In Figure 4 we removed those instances from the Airport and Rovers domains, resulting in a total of 159 instances. In this analysis, the correlation becomes even more explicit.\nThere is, however, one caveat for this study by including all instances from all domains. Some domains have more than thirty instances solved, while in some other domains, we can only solve\nfive. As a result, this study is biased toward those domains with more instances solved. It will be an interesting future study to see how transition index works in a more sophisticated experimental setting, such as by eliminating certain domain specific factors (Hoffmann, Gomes, & Selman, 2006)."
    }, {
      "heading" : "6. Reducing the Encoding Size of SASE",
      "text" : "We now propose several techniques to further reduce the size of SAT instances in SASE. We first represent all mutual exclusions in SASE using a more compact clique representation. We then develop a few new techniques to recognize the special structures of SASE and further reduce the encoding size."
    }, {
      "heading" : "6.1 Mutual Exclusion Cliques",
      "text" : "Mutual exclusions in SASE naturally define cliques of transitions or actions in which at most one of them can be true at any time step. There are two types of cliques: 1) for each x ∈ X , T (x) is a clique of transitions enforced by the class E clauses, and 2) for each transition δ that is not prevailing, A(δ) is a clique of actions enforced by the class H clauses.\nIt requires O(n2) clauses to encode all mutexes within a clique of size n in a pair-wise manner. To reduce the number of clauses used, we in SASE use a compact representation (Rintanen, 2006), which uses Θ(n log n) auxiliary variables and Θ(n logn) clauses. For cliques with large n, the reduction in number of clauses will be significant. To show how it works, consider a simple example. Suppose that we have a clique {x, y, z} where at most one variable can be true. We introduce auxiliary variables b0 and b1 and clauses x ⇔ b0 ∧ b1, y ⇔ b0 ∧ b1 and z ⇔ b0 ∧ b1."
    }, {
      "heading" : "6.2 Reduction Techniques",
      "text" : "Action variables form the majority of all variables, and also lead to many clauses to represent action mutual exclusions even if the clique technique is used. Thus, it is important to reduce the number of action variables. We propose three methods when certain structure of a SAS+ planning task is observed."
    }, {
      "heading" : "6.2.1 REDUCING SUBSUMED ACTION CLIQUES",
      "text" : "We observe that many action cliques share common elements, while transition cliques do not. In the following, we discuss the case where one action clique is a subset of another. Given two transitions δ1 and δ2, if A(δ1) ⊆ A(δ2), we say clique A(δ1) is subsumed by clique A(δ2).\nIn preprocessing, for each transition δ1 ∈ T , we check if A(δ1) is subsumed by another transition δ2’s action clique. If so, we do not encode action clique A(δ1). In the special case when A(δ1) = A(δ2) for two transitions δ1 and δ2, we only need to encode one of them.\nTable 2 presents the number of cliques and their average sizes, before and after reducing action cliques, on some representative problems. The reduction is substantial on most problem domains, except for Driverlog in which no reduction occurred. Note that the average sizes of cliques are increased since smaller ones are subsumed and not encoded."
    }, {
      "heading" : "6.2.2 UNARY TRANSITION REDUCTION",
      "text" : "Given a transition δ such that |T (δ)| = 1, we say that the only action a in T (δ) is reducible. Since a is the only action supporting δ, they are logically equivalent. For any such action a, we remove Va,t and replace it by Uδ,t, for t = 1, · · · , N . An effect of this reduction on a few representative domains can be seen in Table 3."
    }, {
      "heading" : "6.2.3 UNARY DIFFERENCE SET REDUCTION",
      "text" : "Besides unary transition variables, an action variable may also be eliminated by two or more transition variables. A frequent pattern is the following: given a transition δ, for all actions in A(δ), their transition sets differ by only one transition.\nDefinition 12 Given a transition δ ∈ T , let I = ⋂\na∈A(δ) Trans(a). If for every a ∈ A(δ), |Trans(a) \\ I| = 1, we call the action set A(δ) a unary difference set.\nConsider a transition δ1 with A(δ1) = {a1, a2, . . . , an}. If A(δ1) is a unary difference set, the transition sets must have the following form:\nTrans(a1) = {δ1, δ2, . . . , δk, θ1}\nTrans(a2) = {δ1, δ2, . . . , δk, θ2}\n...\nTrans(an) = {δ1, δ2, . . . , δk, θn}\nIn this case, we eliminate the action variables for a1, · · · , an by introducing the following clauses. For each i, i = 1, · · · , n, we replace Vai,t by Uδ1,t ∧ Uθi,t, for t = 1, · · · , N . In such a case, the action variables can be eliminated and represented by only two transition variables. The reason that this reduction can be done is that the n actions are in at least one action clique. The mutual exclusions between these actions maintain the correctness when all but one of the shared transitions are reduced.\nTable 3 shows the number of reducible actions in several representative problems. In Zenotravel, all action variables can be eliminated when the two reduction methods are used. In Openstack and Storage, there is only one type of reduction that can be applied."
    }, {
      "heading" : "7. Experimental Analysis and Results",
      "text" : "We experimentally analyzed the performance of planning using SASE in comparison against many state-of-the-art planners. We tested all problem instances of STRIPS domains in IPC-3 to IPC-6. PSR and Philosophers were not included because they have derived facts, which cannot be handled correctly by any of the planners tested. We used the parser by Fast-Downward (Helmert, 2006, 2008) to generate the SAS+ formalism from STRIPS inputs. The preprocessing and encoding parts of SASE were implemented in Python2.6. All the instances were based on grounded STRIPS. In nearly all cases, the problem solving took much longer time than the pre-processing, thus we only reported the overall running time.\nWe ran all experiments on a PC workstation with a 2.3 GHz AMD Quad-Core Opteron processor. The running time for each instance was set to 1800 seconds, and the memory was limited to 4GB. For all planners, the running time included parsing, preprocessing and problem solving. The memory consumption was the peak memory usage reported by the SAT solvers."
    }, {
      "heading" : "7.1 Comparison Results",
      "text" : "Precosat (build236) (Biere, 2009), the winner of the application track in the SAT’09 competition, was used as the SAT solver for most planners that we tested and compared. Besides Precosat, we also used CryptoMinisat (Soos, Nohl, & Castelluccia, 2009), the winner of SAT Race 2010, as the underlying solver of SatPlan06 and SASE. The nine planners considered are listed as follows.\n1. SP06 and SP06-Crypto. They are the original SatPlan06 planner (Kautz et al., 2006), only\nwith the underlying SAT solver changed to Precosat and CryptoMinisat, respectively.\n2. SASE and SASE-Crypto. They are SASE encoding introduced in this paper, with all the\noptimization methods turned on. The underlying SAT solvers are Precosat and CryptoMinisat, respectively.\n3. SP06L. It is SatPlan06 (Kautz et al., 2006) with long-distance mutual exclusion (londex) (Chen\net al., 2009). We compared against londex since it also derives transition information from the SAS+ formalism. We used domain transition graphs from Fast-Downward’s parser to derive londex information.\n4. SP06C. It is SatPlan06 with the clique technique (Rintanen, 2006) to represent the mutual\nexclusions. The clique information was obtained via Fast-Downward. Note that due to the\ndifferent grounding strategies by SatPlan06 and Fast-Downward, not all of the mutual exclusions defined in SatPlan06 could be covered by cliques.\n5. nplan. The nplan solver (Rintanen et al., 2006) is set to use ∀-step to generate plans with the same optimality metric as other planners. The executable is the most recent release from\nnplan’s homepage. The build-in SAT solver is changed to Precosat.\n6. SplitE. It is the split encoding (Robinson et al., 2009) using Precosat. We have obtained\nsource code from the authors and recompiled it on our 64bit Linux workstation.\n7. LM-cut. This is a sequential optimal planner, using LM-Cut heuristic (Helmert & Domshlak,\n2009) and A* search. We used the implementation in Fast-Downward.\nWe present the results as two sets of planners, as in Figures 5 and 6, respectively. For both sets of data, we show the number of instances that are solvable in the testing domains, with respect to the given time limit and memory limit.\nFigure 5 compares the results of several different solvers using their original version. Our data suggests that SASE has clear advantages. LM-cut is the least efficient, although the comparison is\nnot very meaningful as it uses an optimization metric different from other planners. For running time and memory consumption, SASE is clearly superior to all the other planners. Among all planners, nplan is slightly better than the others on smaller instances, but on larger instances, SatPlan06 becomes more competitive.\nIn Figure 6, we compare the results of different variants of both SatPlan06 and SASE. Both SP06L and SP06C extend SatPlan06 with additional techniques. They in general make little improvements over the original SatPlan06.\nFor SAT based planners, we present in Figure 7 the number of instances that are solvable with increasing limits on the number of variables and number of clauses. Note that the curves are slightly affected by the given time and memory limit, thus efficient planners like SASE stops at a smaller number of clauses. The results show SASE has an advantage in terms of the number of variables and number of clauses over the other planners.\nTable 4 presents the number of instances solved in each planning domain, within the given time and memory limit. In general, SASE solved more instances than the other planners. Due to some programming bugs, nplan could not find the correct solutions with the optimal makespan in domains Openstacks, Rovers and Storage. The SplitE parser could not handle problems in Airport and Pathways. Therefore, we did not evaluate the corresponding encoding on those benchmarks. Although LM-Cut overall solved fewer instances, in a few domains it performed better than all the SAT based planners. These domains seemed to allow less concurrencies between action. In particular, domains Openstacks and Sokoban only have plans that are strictly sequential, meaning that there are no actions that can be executed at the same time step. The plans for such instances often require more time steps, making them more challenging for SAT-based planners.\nBoth SP06L and SP06C used Fast-Downward’s parser to obtain domain transition graph information. Therefore, for SP06C and SP06L, it took too much time to pre-process grounded STRIPS instances twice (one by Fast-Downward and one by original SP06). In consequence, the efficiency of londex or clique representation may not compensate for pre-processing time, leading to slightly worse performance than the original SP06 in a few instances. For example, londex was helpful in TPP, but not in Trucks and Scanalyzer. The clique representation was very helpful in Airport domain, with 10 more instances solved, but did not help much in Pegsol and Satellite.\nComparing with nplan, in general SASE was better, but nplan performed better than SASE on those domains with few concurrencies. For example, both Sokoban and Trucks have only one action at nearly every time step. We believe the reason should be the way nplan encodes all mutual exclusions as linear encoding (Rintanen et al., 2006), which could be further used to improve SASE.\nSplitE in general was slightly worse than SP06. It won over SP06 on 5 domains and SP06 was superior to SplitE on 6 domains. Overall, SplitE was competitive not to nplan or SASE. Rovers however was the only domain where SplitE performed better than all others. Although CryptoMinisat performed better than Precosat in SAT Race 2010, it was not as good for planning problems. For both SASE and SP06, CryptoMinisat solved fewer instances."
    }, {
      "heading" : "7.2 Ablation Study",
      "text" : "Figure 8 shows the number of solvable problems from all the problems in IPC-3 to IPC-6, with increasing limits on running time, memory consumption, number of variables and number of clauses. Precosat was used for all planners. Running time was the total time including preprocessing and problem solving. Memory usage was based on the status report by Precosat. Under the maximum CPU time (1800s) and memory limit (4Gb), when both clique representation and reduction techniques were not used, SASE solved 398 instances. By turning on either the clique representation or the action reduction technique, SASE solved 416 and 405 instances, respectively. When both clique and action reduction techniques were turned on, SASE solves 426 instances.\nThe reduction method improved upon problem solving time, as well as the clique representation. The clique representation provided a substantial improvement to memory consumption, followed by action reduction. For numbers of clauses, the clique technique gave a significant reduction. Finally, both techniques helped reduce the number of variables."
    }, {
      "heading" : "8. Conclusions and Future Research",
      "text" : "In this paper, we developed a novel SAS+ based SAT encoding scheme SASE, and showed that it improves the efficiency of STRIPS based SAT encodings in terms of both time and memory. When compared with the state-of-the-art SAT based planners, SASE has clear advantages as shown by our experimental analysis. We proved the correctness of the SASE encoding by showing that there is an isomorphism between the solution plans of SASE and the solution plans of SatPlan06. We further analyzed the search space structure of SASE, and explained why it is more efficient. Below, we briefly discuss some related work and highlight several directions for future research."
    }, {
      "heading" : "8.1 Other Semantics and Encodings",
      "text" : "Many enhancements have been developed for SAT based planning since it was introduced (Kautz & Selman, 1992). The split action representation (Kautz & Selman, 1992; Ernst et al., 1997) uses a conjunction of multiple variables to represent an action. The optimality is, however, lost. Robinson et al. (2009) propose a new way of doing splitting without sacrificing the optimality. The results\nshow that this method has advantages over SatPlan06 (Kautz et al., 2006). There are many published works with thorough analysis, or improvements along this line of research on SatPlan family encodings. In particular, the power of mutual exclusion, in the context of planning as SAT, has attracted interests (Chen et al., 2009; Sideris & Dimopoulos, 2010). A new encoding scheme called SMP is proposed, which preserves the merits of londex and shows certain advantages over the existing encoding schemes (Sideris & Dimopoulos, 2010).\nThe planner family of SatPlan and its variants are step-optimal. The step-optimality semantics, along with a relaxed parallel semantics, are formalized as ∀-step and ∃-step, respectively (Dimopoulos, Nebel, & Koehler, 1997; Rintanen et al., 2006). ∃-step enforces weaker mutual exclusions than ∀-step, thus may lead to reduced running time due to fewer calls to the SAT solver. As a trade-off, it loses the optimality of time steps. The semantics in both SatPlan06 and SASE are ∀-step. The research on various kinds of semantics are orthogonal to our contribution in SASE, and the idea of SASE can be migrated to new semantics.\nSince SAT based planning has also been applied to sequential planning, the idea of SASE can also be extended to this field. The first planner of this kind is MEDIC (Ernst et al., 1997), which extends the idea of splitted action representation. This study shows that for sequential planning, splitting yields very competitive planners. It has also been proposed to utilize the advantages of sequential and parallel planning (Büttner & Rintanen, 2005)."
    }, {
      "heading" : "8.2 Additional Techniques for Planning as SAT",
      "text" : "The tremendous amount of two-literal clauses (such as the mutual exclusion clauses in the case of planning) is a key challenge to approaches based on satisfiability tests. It has been proposed to mitigate the burden of encoding them by recognizing certain structures (Brafman, 2001). In traditional SAT planning systems like SatPlan06, the mutual exclusions are encoded in a quadratic manner. Rintanen proposes a log size technique (Rintanen, 2006), called clique representation, for the mutual exclusion constraints, and later a linear size one (Rintanen et al., 2006). The mutual exclusions in SASE are represented by the clique representation. The log size of the clique representation is supposed to be less compact than the linear encoding. Our results, however, have shown that SASE is in general more compact. This is mainly due to the compactness of SAS+ formalism. It is certainly an open question whether the linear size encoding technique can be adopted to further improve SASE.\nThere are also techniques beyond encoding to boost SAT-based planning. Rintanen introduces how to incorporate symmetry information into SAT instances (Rintanen, 2003). MaxPlan (Xing, Chen, & Zhang, 2006) does a planning graph analysis to find an upper bound on the optimal make span and then does SAT queries using decreasing time steps, until it meets an unsatisfiable SAT instance. A lemma reusing method is proposed (Nabeshima, Soh, Inoue, & Iwanuma, 2006) to reuse the learnt clauses across multiple SAT solvings. A multiple-step query strategy is introduced (Ray & Ginsberg, 2008), which however asks for modified SAT procedures. All these boosting methods are proposed in the context of STRIPS based planning. It is interesting to incorporate these techniques into SASE and study if they can further improve the performance."
    }, {
      "heading" : "8.3 More Understanding of Structure in General SAT Instances",
      "text" : "SAT is intrinsically hard. The performance of modern SAT solvers improves constantly. It is therefore interesting and important to understand why SAT solvers work well on certain instances, and\nfurthermore, what makes a SAT instance easy or hard. There is much prior research that tries to obtain such an understanding, including backdoor set (Williams, Gomes, & Selman, 2003) and backbone (Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999; Zhang, Rangan, & Looks, 2003; Zhang, 2004). Backdoor set variables are a set of variables, such that when these variables are assigned, other variables’ assignments can be derived in polynomial time. Backbone variables are those variables that have the same assignment in all valid solutions, which can be further exploited to improve SAT solving efficiency. A recent study in the context of planning reveals that there is clear correlations between the SAT solving efficiency and goal asymmetry (Hoffmann et al., 2006).\nIt will be interesting to see if there are connections between SASE’s problem structure and those theories above. For example, is the improvement of SASE because it can lead to a smaller backdoor set? Second, we have shown that the efficiency of SASE is a result of transition variables’ significance, and there is strong correlation between the speedup from SASE and the transition index. It is interesting to investigate if similar variable set and predictive index can be automatically found for general SAT solving.\nFinally, given the efficiency of SASE, it is promising to apply it to other SAT-based planning approaches, such as those for complex planning with preferences (Giunchiglia & Maratea, 2007) and temporal features (Huang et al., 2009)."
    }, {
      "heading" : "9. Acknowledgments",
      "text" : "This research was supported by National Science Foundation of the United States under grants NeTS-1017701, DBI-0743797, IIS-0713109, and a Microsoft Research New Faculty Fellowship. We thank Joerg Hoffmann, Jussi Rintanen and several anonymous reviewers for the helpful comments. We particularly thank Malte Helmert for making the SAS+ parser available. We also thank the computing resource and supports from engineering IT group of Washington University in St. Louis."
    }, {
      "heading" : "Appendix A. Proofs",
      "text" : "Lemma 1 Given a STRIPS task Ψ = (F ,A, ϕI , ϕG), a time step N , and its PE SAT instance PE(Ψ, N) = (V,C), suppose there is a satisfiable solution denoted as Γ, a fact f ∈ F , and t ∈ [1, N ] such that: 1) Γ(Wdumf ,t) =⊥, 2) Γ(Wf,t) = ⊥\n, and 3) ∀a ∈ DEL(f), Γ(Wa,t) =⊥, then we can construct an alternative solution Γ′ to PE(Ψ, N) as follows:\nΓ′(v) =\n{ ⊥\n, v = Wdumf ,t, v ∈ V\nΓ(v), v 6= Wdumf ,t, v ∈ V (5)\nProof We show that Γ′ satisfies every clause in C just as Γ does. Since all variables butWdumf ,t keep the same value, we only need to examine those clauses that haveWdumf ,t in them. According to the definition of PE, Wdumf ,t may exist in three types of clauses:\n1. Clauses for add effects. In this case, the clauses are of the form Wf,t+1 → (Wdumf ,t ∨\nWa1,t ∨ · · · ∨Wam,t), which is equivalent toW f,t+1 ∨Wdumf ,t ∨Wa1,t ∨ · · · ∨Wam,t. Since Γ′(Wdumf ,t) = ⊥ , such clauses are still true.\n2. Clauses for preconditions. In this case, the clauses are of the form Wdumf ,t → Wf,t, which\nis equivalent to Wdumf ,t ∨Wf,t. Since Γ ′(Wf,t) =\n⊥ , these clauses remain true for Γ′.\n3. Clauses of mutual exclusion between actions. Without loss of generality, let us denote such a\nclause Wdumf ,t ∨Wa,t. For a given f , the actions in all such clauses are mutex with dumf , because f is their delete effect. According to the construction, since Γ′(Wa,t) = Γ(Wa,t) =⊥, all such clauses are true.\nThe three cases above conclude that all clauses that include Wdumf ,t are satisfied by Γ ′. There-\nfore, Γ′ is also a solution to PE.\nLemma 2 Given a STRIPS task Ψ = (F ,A, ϕI , ϕG), a time step N , and its PE SAT instance PE(Ψ, N) = (V,C), suppose there is a satisfiable solution denoted as Γ, a fact f ∈ F , and t ∈ [1, N ] such that: 1) Γ(Wf,t) =⊥, 2) there exists an action a ∈ ADD(f) such that Γ(Wa,t−1) = ⊥ , then we can construct an alternative solution Γ′ to PE(Ψ, N) as follows:\nΓ′(v) =\n{ ⊥\n, v = Wf,t, v ∈ V\nΓ(v), v 6= Wf,t, v ∈ V (6)\nProof We show that Γ′ makes each clause in C to be true. Since all variables but Wf,t keep the same value, we only need to look at those clauses that have Wf,t in them. According to the definition of PE, Wf,t may exist in three types of clauses.\n1. Clauses for add effects. In this case, f is an add effect of multiple actions. Let us write this clauses asWf,t → (Wa1,t−1∨Wa2,t−1∨· · ·∨Wam,t−1), which isWf,t∨Wa1,t−1∨Wa2,t−1∨ · · ·∨Wam,t−1. Since there exists an action a ∈ ADD(f) such that Γ(Wa,t−1) = ⊥ , the clause\nis still true in Γ′.\n2. Clauses for preconditions. In this case, f is a precondition of an action b. This clause is written asWb,t → Wf,t, which is equivalent toWb,t ∨Wf,t. Since Γ ′(Wf,t) = ⊥ , this clause\nis still true.\n3. Clauses of fact mutex. Without loss of generality, consider a fact g that is mutex with f . The corresponding clause will be Wf,t ∨ Wg,t. Since Γ ′(Wf,t) = ⊥ , this clause is true if\nΓ′(Wg,t) =⊥.\nWe now suppose Γ′(Wg,t) =\n⊥\nand show that it leads to a contradiction. According to clauses\nof class III, there must be a variable Wb,t−1, such that g ∈ add(b) and Γ ′(Wb,t−1) =\n⊥ .\nAccording to the definition of mutex, two facts are mutex only when every pair of the actions that add them are mutex. Thus, Wa,t−1 and Wb,t−1 are mutex. Therefore, Γ ′(Wa,t−1) = ⊥ and Γ′(Wb,t−1) = ⊥\n, leading to a contradiction. As a result, Γ′(Wg,t) =⊥, and consequently this clause is satisfied.\nThe three cases above conclude that all clauses that include Wf,t are satisfied by Γ ′. Therefore,\nΓ′ is also a solution to PE.\nLemma 3 Given a SAS+ planning task Π = (X ,O, sI , sG) and its equivalent STRIPS task Ψ = (F ,A, ϕI , ϕG), suppose we have actions a, b ∈ O, and their equivalent actions a\n′, b′ ∈ A (i.e. a = φa(a ′) and b = φa(b ′)), a and b are S-mutex iff a′ and b′ are P-mutex.\nProof We construct the proof by studying it on both directions. Based on Proposition 1, we only consider inconsistent effects and interference mutex in P-mutex.\n⇒: if a′ and b′ are P-mutex in Ψ, a and b are S-mutex in Π. Since a′ and b′ are P-mutex, one either deletes precondition or add-effect of the other. Without loss of generality, suppose a′ deletes f (i.e. f ∈ del(a′) ∩ pre(b′)). Consequently, there must be a transition δ1 = δ x f→h ∈ T (a) such that f 6= h and δ2 = δ x f→g ∈ T (b). There are two cases to be considered.\n1) δ1 6= δ2. δ1 and δ2 are mutex transitions by Definition 3, since they both change their value from f . Therefore, a and b are S-mutex, according to the second condition in Definition 5.\n2) δ1 = δ2. In this case, a and b are S-mutex by the first condition of Definition 5.\nBased on the two cases, we conclude that a and b are S-mutex. A similar argument applies to the case when one action deletes the other’s add-effect.\n⇐: if a and b are S-mutex in Π, a′ and b′ are P-mutex in Ψ. If two actions a and b are S-mutex in Π, there are two cases.\n1) There exists a transition δ, which is in both T (a) and T (b). Consequently, a′ and b′ deletes each other’s precondition and thus they are P-mutex.\n2) There exist two distinct transitions δ1 ∈ T (a), δ2 ∈ T (b) and a multi-valued variable x ∈ X , such that {δ1, δ2} ⊆ T (x). Let us denote these two transitions as δ x v1→v2 and δ x v3→v4 . In such a case, suppose δxv1→v2 and δ x v3→v4 are allowed to be executed in parallel in a STRIPS plan. It obviously leads to a contradiction, since v1, v2, v3, v4 ∈ Dom(x) are values of the same multi-valued variable, and by the definition of SAS+ formalism, only one of them can be true at the same time. Therefore, the preconditions of a′ and b′ must be mutex, and hence a′ and b′ are P-mutex.\nTheorem 1 Given a STRIPS task Ψ and a SAS+ task Π that are equivalent, for a time step bound N , if PE(Ψ, N) is satisfiable, SASE(Π, N) is also satisfiable.\nProof Since PE(Ψ, N) is satisfiable, we denote one of its solutions as ΓΨ. We first present how to construct an assignment to SASE(Π, N) from ΓΨ. Next, we prove that this constructed assignment satisfies every clause in SASE(Π, N). Construction. There are two steps for the construction. According to Lemmas 1 and 2, there are in general some free variables in ΓΨ. In the first step, we construct an alternative solution to PE(Ψ, N) by changing all free variables in ΓΨ to be true according to Lemmas 1 and 2. Let us denote the resulting solution as Γ′Ψ. Then, we construct an assignment for SASE(Π, N) from Γ ′ Ψ. The value of each variable in ΓΠ is defined as follows.\n1. For every a ∈ O (which is also in A)1, we let Ua,t = Wa,t.\n2. For every transition δf→g ∈ T , if Wf,t =\n⊥\nand Wg,t+1 =\n⊥\nin Γ′Ψ, we set Ux,f,g,t =\n⊥\nin\nΓΠ.\n1. For simplicity, we use a to denote the same action in A instead of using φa(a).\nSatisfiability. We prove that every individual clause in SASE is satisfied by ΓΠ. There are eight types of clauses.\n1. (Forward progression). According to our construction, we need to show that, for any t ∈ [1, N − 2],\n∀δxh→f ∈ T , (Wh,t ∧Wf,t+1) → ∨\n∀g,δx f→g ∈T\n(Wf,t+1 ∧Wg,t+2) (7)\nIf Γ′Ψ(Wf,t+1) =⊥, then (7) is satisfied by Γ ′ Ψ. If Γ ′ Ψ(Wf,t+1) =\n⊥ , we consider an action\nset Y = {dumf} ∪ DEL(f), which is a subset of Trans(δ x f→g). There are two possibilities.\n• For every action a ∈ Y , Γ′Ψ(Wa,t+1) =⊥. In such a case, Wdumf ,t+1 and Wf,t+2 are free variables according to Lemmas 1 and 2, respectively. Therefore, according to the\nconstruction in Γ′Ψ, which assigns all free variables to true, variables Wf,t+1, Wf,t+2 andWdumf ,t+1 are all ⊥\n. In addition, δf→f is always in T , meaningWf,t+2 is included in the right hand side of (7). Therefore, (7) is satisfied by Γ′Ψ.\n• There exists an action a ∈ Y , such that Γ′Ψ(Wa,t+1) =\n⊥ . In such a case, let us\nconsider an arbitrary fact g ∈ add(a). If Γ′Ψ(Wg,t+2) =\n⊥\n, then (7) is satisfied by Γ′Ψ. Otherwise, according to Lemma 2,Wg,t+2 is a free variable andWg,t+2 is already set to true in our construction of Γ′Ψ. Therefore, Γ ′ Ψ satisfies (7).\n2. (Regression). According to our construction, we need to show that, for any t ∈ [2, N − 1],\n∀δxf→g ∈ T , (Wf,t ∧Wg,t+1) → ∨\n∀h,δx h→f ∈T (x)\n(Wh,t−1 ∧Wf,t) (8)\nConsider clauses of class III (add effect) in PE. These clauses indicate that for each fact f ∈ F ,Wf,t implies a disjunction ofWa,t−1 for all actions a such that f ∈ add(a). Thus, for a given f , the following clauses are included in PE, which are satisfied by Γ′Ψ:\nWf,t → ∨\n∀a∈ADD(f)\nWa,t−1. (9)\nFor a given f , we consider the action set ⋃\n∀hA(δh→f ), denoted as Z. Since ADD(f) ⊆ Z,\nWf,t → ∨\n∀a∈Z\nWa,t−1 (10)\nFor any transition δxh→f , for each action a ∈ A(δ x h→f ), since h ∈ pre(a), Γ ′ Ψ satisfies Wa,t−1 → Wh,t−1. Therefore, for each h ∈ pre(a), we have\n∨\n∀a∈A(δx h→f )\nWa,t−1 → Wh,t−1. (11)\nBy expanding set Z, we can convert (10) to:\nWf,t → ∨\n∀h,δx h→f ∈T\n( ∨\n∀a∈A(δx h→f )\nWa,t−1). (12)\nBy combining (11) and (12), we have:\nWf,t → ∨\n∀h,δx h→f ∈T\nWh,t−1, (13)\nwhich implies\nWf,t → ∨\n∀h,δx h→f ∈T\n(Wh,t−1 ∧Wf,t). (14)\nFrom (14), we can see that the clauses of regression in (8) are true.\n3. (Initial state). We need to show that for each variable x in X such that sI(x) = f : ∨\n∀g,δf→g∈T\nUf,g,1 (15)\nAccording to our construction, (15) becomes:\n∨\n∀g,δf→g∈T\n(Wf,1 ∧Wg,2),\nwhich is equivalent to:\nWf,1 ∧ ( ∨\n∀g,δf→g∈T (x)\nWg,2) (16)\nSince f is in the initial state, ΓΨ(Wf,1) = Γ ′ Ψ(Wf,1) =\n⊥ . Therefore the first part of the\nconjunction in (16) is true. The rest part of (16) can be seen to be true following a similar argument as that for the progression case.\n4. (Goal). The goal clauses can be shown in a similar way as that for the initial state clauses.\n5. (Composition of actions). The clauses we want to prove are, for any action a, Ua,t → ∧\n∀δ∈Trans(a) Uδ,t, or equivalently, Ua,t ∨ ∧ ∀δ∈Trans(a) Uδ,t.\nSuppose Trans(a) = {δf1→g1 , δf2→g2 , . . . , δfm→gm}. The clause we need to show becomes:\n(Wa,t ∨Wf1,t) ∧ (Wa,t ∨Wg1,t) ∧ (Wa,t ∨Wf2,t) ∧ (Wa,t ∨Wg2,t) ∧ . . .\n∧(Wa,t ∨Wfm,t) ∧ (Wa,t ∨Wgm,t) (17)\nLet us call these two-literal disjunctions in (17) as sub-clauses. All those Wa,t ∨ Wfi,t subclauses in (17) are exactly the same as the precondition clause (class IV) in PE. So all Wa,t ∨Wfi,t in (17) are satisfied. Next, let us consider those Wa,t ∨ Wgi,t sub-clauses. For any g = gi, i = 1, · · · ,m. There are four cases whereWa,t andWg,t are assigned different values:\n• (Wa,t =⊥,Wg,t =⊥): Wa,t ∨Wg,t is satisfied.\n• (Wa,t =⊥,Wg,t =\n⊥ ): Wa,t ∨Wg,t is satisfied.\n• (Wa,t =\n⊥ ,Wg,t = ⊥ ): Wa,t ∨Wg,t is satisfied.\n• (Wa,t =\n⊥\n,Wg,t =⊥): According to Lemma 2,Wg,t is a free variable. Therefore, since Γ′Ψ(Wg,t) = ⊥ ,Wa,t ∨Wg,t is satisfied by Γ ′ Ψ, and hence satisfied by ΓΠ.\n6. (Transition mutex). Consider any mutex clause between two regular transitions δ1 = δf→g and δ2 = δf ′→g′ . Let δf→g ∈ Trans(a) and δf ′→g′ ∈ Trans(b), we see that a and b are S-mutex. According to Lemma 3, a and b are also P-mutex in PE. Therefore, we have Wa,t∨Wb,t. From our construction, we knowUa,t∨Ub,t. Then, since we have the composition of actions, Ua,t → ∧ ∀δ∈Trans(a) Uδ,t and Ub,t → ∧ ∀δ∈Trans(b) Uδ,t. A simple resolution of\nthese clauses yields Uδ1,t ∨ Uδ2,t, which equals to the transition mutex clause Uδ1,t → Uδ2,t. Therefore, the transition mutex clause is true in ΓΠ. A similar argument applies when the transitions are prevailing and mechanical.\n7. (Action existence). The clauses that we want to prove are Uδ,t → ∨\nδ∈Trans(a) Ua,t, for any transitions δ. By our construction, the clauses become\nWf,t ∨Wg,t+1 ∨ ∨\n∀a∈A(δf→g)\nWa,t. (18)\nLet δ = δf→g. First, we know by definition that ⋃\n∀hA(δh→g) = ADD(g). Let us denote ADD(g) as Z. According to clauses of class III in PE, there are clauses:\nWg,t → ∨\n∀a∈Z\nWa,t. (19)\nWe divide Z into multiple action sets according to different fact from {f, h1, . . . , hm}, denoted as Zf , Zh1 , · · · , Zhm . In fact, for each h ∈ {f, h1, . . . , hm}, Zh is equivalent to A(δh→g). Consider any hi, i = 1, · · · ,m. According to the clauses of class IV, for every action a ∈ PRE(h), there is a clauseWa,t → Whi,t, which is\nWa,t ∨Whi,t. (20)\nNext, we perform resolutions by using (19) and all the clauses in (20), for all such hi and corresponding actions. We consequently have:\nWg,t ∨ (Wh1,t ∨Wh2,t ∨ · · · ∨Whm,t) ∨ ∨\n∀a∈Zf\nWa,t. (21)\nFurther, note that all h1, h2, . . . , fm are mutex to f , a resolution using all the mutex clauses in PEresults in:\n(21), Wh1,t ∨Wf,t, Wh2,t ∨Wf,t, . . . ,Whm,t ∨Wf,t\nWg,t ∨ (Wf,t ∨Wf,t ∨ · · · ∨Wf,t) ∨ ∨\n∀a∈Zf Wa,t\n(22)\nSince Zf = A(δf→g), the outcome of (22) leads to (18).\n8. (Action mutex). Action mutex clauses are satisfied by ΓΠ according to Lemma 3.\nCombining all the cases concludes that the constructed solution ΓΠ satisfies all the clauses in SASE which means SASE is satisfiable. Since for all action a, ΓΨ(Wa,t) = Γ ′ Ψ(Wa,t) = ΓΠ(Ua,t), ΓΨ and ΓΠ represent the same solution plan.\nTheorem 2 Given a STRIPS task Ψ and a SAS+ task Π that are equivalent, for a time step bound N , if SASE(Π, N) is satisfiable, PE(Ψ, N) is also satisfiable.\nProof Assuming ΓΠ is a satisfiable solution to SASE(Π, N), we first construct an assignment ΓΨ from ΓΠ, and show that ΓΨ satisfies every clause in PE(Ψ, N). Construction. We construct a solution ΓΨ as follows:\n1. For every a ∈ A (which is also in O), we let Wa,t = Ua,t;\n2. For every dummy action variable dumf , we let Wdumf ,t = Uδf→f ,t;\n3. For every transition δf→g ∈ T , if Ux,f,g,t =\n⊥\nin ΓΠ, we setWf,t = Wg,t+1 =\n⊥\nin ΓΠ;\n4. For each fact f , if Uh,f,t =⊥ for every transition δh→f ∈ T (which implies that case 3 will not assign a value to f ), we setWf,t to be ⊥.\nSatisfiability. Next, we prove that every clause in PE is satisfied by ΓΨ. The clauses for the initial and goal states are obviously satisfied. Now we consider the add-effect clauses. The clauses that we want to prove are, for every fact f :\nWf,t → ∨\n∀a∈ADD(f)\nWa,t−1 (23)\nFor a given fact f , we consider all the facts h 6= f , such that δh→f ∈ T . For all such h, there are two further cases:\n• There exists a fact h such that δxh→f ∈ T and Ux,h,f,t−1 =\n⊥\nin ΓΠ. In the satisfiable SASE instance, the action existence clauses in class F specify that the truth of a non-prevailing transition δ indicates a disjunction of all actions in A(δ). Since Ux,h,f,t−1 = ⊥ , it follows that in the SASE instance there is an action a ∈ A(δxh→f ) such that Ua,t−1 = ⊥ . Then, by our construction of ΓΨ, we see that both Wh,t−1 and Wf,t are true. Since Wf,t and Wa,t−1, a ∈ ADD(f), are all true, (23) is satisfied by ΓΨ.\n• If for every fact h that δxh→f ∈ T , Ux,h,f,t−1 =⊥ in ΓΠ, then, according to our construction, Wf,t =⊥ in ΓΨ. Thus, ΓΨ satisfies (23).\nThe two cases above conclude that ΓΨ satisfies the add effect clauses. Next, we show that ΓΨ satisfies the precondition clauses, Wa,t → Wf,t (i.e. Wa,t ∨Wf,t), for all actions a ∈ A and facts f ∈ pre(a). In SASE, we have clauses of class F, which are Ua,t → Uδ,t, for all actions a ∈ O and δ ∈ Trans(a). Let the transition be δxf,g, we have Ua,t ∨ (Uf,t−1 ∧ Ug,t−1), which implies Ua,t ∨ Uf,t−1. By our construction, we knowWa,t ∨Wf,t−1 is true. Finally, the mutex clauses are satisfied by ΓΨ according to Lemma 3. Combining all the cases concludes that the constructed solution ΓΨ satisfies all the clauses in PE which means PE is satisfiable.\nAppendix B. Branching Frequency in All Domains"
    } ],
    "references" : [ {
      "title" : "Complexity results for SAS+ planning",
      "author" : [ "C. Bäckström", "B. Nebel" ],
      "venue" : null,
      "citeRegEx" : "Bäckström and Nebel,? \\Q1996\\E",
      "shortCiteRegEx" : "Bäckström and Nebel",
      "year" : 1996
    }, {
      "title" : "Satisfiability Planning with Constraints on the Number of Actions",
      "author" : [ "M. Büttner", "J. Rintanen" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Büttner and Rintanen,? \\Q2005\\E",
      "shortCiteRegEx" : "Büttner and Rintanen",
      "year" : 2005
    }, {
      "title" : "SAT-based planning in complex domains:Concurrency, constraints and nondeterminism",
      "author" : [ "C. Castellini", "E. Giunchiglia", "A. Tacchella" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Castellini et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Castellini et al\\.",
      "year" : 2003
    }, {
      "title" : "Long-distance mutual exclusion for planning",
      "author" : [ "Y. Chen", "R. Huang", "Z. Xing", "W. Zhang" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Chen et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2009
    }, {
      "title" : "Fast Planning by Search in Domain Transition Graphs",
      "author" : [ "Y. Chen", "R. Huang", "W. Zhang" ],
      "venue" : "In Proceedings of AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Chen et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2008
    }, {
      "title" : "Encoding planning problems in nonmonotonic logic programs",
      "author" : [ "Y. Dimopoulos", "B. Nebel", "J. Koehler" ],
      "venue" : "Proceeding of the Fourth European Conference on Planning,",
      "citeRegEx" : "Dimopoulos et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Dimopoulos et al\\.",
      "year" : 1997
    }, {
      "title" : "Solving Planning Graph by Compiling it into a CSP",
      "author" : [ "B. Do", "S. Kambhampati" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Do and Kambhampati,? \\Q2000\\E",
      "shortCiteRegEx" : "Do and Kambhampati",
      "year" : 2000
    }, {
      "title" : "Automatic SAT-compilation of planning problems",
      "author" : [ "M. Ernst", "T. Millstein", "D. Weld" ],
      "venue" : "In Proceedings of International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Ernst et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Ernst et al\\.",
      "year" : 1997
    }, {
      "title" : "Planning as satisfiability with preferences",
      "author" : [ "E. Giunchiglia", "M. Maratea" ],
      "venue" : "In Proceedings of AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Giunchiglia and Maratea,? \\Q2007\\E",
      "shortCiteRegEx" : "Giunchiglia and Maratea",
      "year" : 2007
    }, {
      "title" : "The Fast Downward planning system",
      "author" : [ "M. Helmert" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Helmert,? \\Q2006\\E",
      "shortCiteRegEx" : "Helmert",
      "year" : 2006
    }, {
      "title" : "Concise finite-domain representations for PDDL planning tasks",
      "author" : [ "M. Helmert" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Helmert,? \\Q2008\\E",
      "shortCiteRegEx" : "Helmert",
      "year" : 2008
    }, {
      "title" : "Landmarks, Critical paths and Abstractions: What’s the difference anyway",
      "author" : [ "M. Helmert", "C. Domshlak" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Helmert and Domshlak,? \\Q2009\\E",
      "shortCiteRegEx" : "Helmert and Domshlak",
      "year" : 2009
    }, {
      "title" : "Explicit-State Abstraction: A New Method for Generating Heuristic Functions",
      "author" : [ "M. Helmert", "P. Haslum", "J. Hoffmann" ],
      "venue" : "In Proceedings of AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Helmert et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Helmert et al\\.",
      "year" : 2008
    }, {
      "title" : "Structure and Problem Hardness : Goal Asymmetry and DPLL Proofs in SAT-based Planning",
      "author" : [ "J. Hoffmann", "C. Gomes", "B. Selman" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Hoffmann et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoffmann et al\\.",
      "year" : 2006
    }, {
      "title" : "SAT encodings of state-space reachability problems in numeric domains",
      "author" : [ "J. Hoffmann", "H. Kautz", "C. Gomes", "B. Selman" ],
      "venue" : "In Proceedings of International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Hoffmann et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Hoffmann et al\\.",
      "year" : 2007
    }, {
      "title" : "The FF planning system: Fast plan generation through heuristic search",
      "author" : [ "J. Hoffmann", "B. Nebel" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Hoffmann and Nebel,? \\Q2001\\E",
      "shortCiteRegEx" : "Hoffmann and Nebel",
      "year" : 2001
    }, {
      "title" : "An Optimal Temporally Expressive Planner: Initial Results and Application to P2P Network Optimization",
      "author" : [ "R. Huang", "Y. Chen", "W. Zhang" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Huang et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2009
    }, {
      "title" : "Planning as satisfiability",
      "author" : [ "H. Kautz", "B. Selman" ],
      "venue" : "In Proceedings of European Conference on Artificial Intelligence",
      "citeRegEx" : "Kautz and Selman,? \\Q1992\\E",
      "shortCiteRegEx" : "Kautz and Selman",
      "year" : 1992
    }, {
      "title" : "Pushing the envelope: Planning, propositional logic, and stochastic search",
      "author" : [ "H. Kautz", "B. Selman" ],
      "venue" : "In Proceedings of AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Kautz and Selman,? \\Q1996\\E",
      "shortCiteRegEx" : "Kautz and Selman",
      "year" : 1996
    }, {
      "title" : "Unifying sat-based and graph-based planning",
      "author" : [ "H. Kautz", "B. Selman" ],
      "venue" : "In Proceedings of International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Kautz and Selman,? \\Q1999\\E",
      "shortCiteRegEx" : "Kautz and Selman",
      "year" : 1999
    }, {
      "title" : "SatPlan: Planning as Satisfiability",
      "author" : [ "H. Kautz", "B. Selman", "J. Hoffmann" ],
      "venue" : "In 5th International Planning Competition, International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Kautz et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Kautz et al\\.",
      "year" : 2006
    }, {
      "title" : "Determining computational complexity from characteristic ‘phase transitions",
      "author" : [ "R. Monasson", "R. Zecchina", "S. Kirkpatrick", "B. Selman", "L. Troyansky" ],
      "venue" : null,
      "citeRegEx" : "Monasson et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Monasson et al\\.",
      "year" : 1999
    }, {
      "title" : "Chaff: Engineering an Efficient SAT Solver",
      "author" : [ "M. Moskewicz", "C. Madigan", "Y. Zhao", "L. Zhang", "S. Malik" ],
      "venue" : "In 39th Design Automation Conference",
      "citeRegEx" : "Moskewicz et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Moskewicz et al\\.",
      "year" : 2001
    }, {
      "title" : "Research Design and Statistical Analysis (2nd edition)",
      "author" : [ "J.L. Myers", "A.D. Well" ],
      "venue" : null,
      "citeRegEx" : "Myers and Well,? \\Q2003\\E",
      "shortCiteRegEx" : "Myers and Well",
      "year" : 2003
    }, {
      "title" : "Lemma reusing for SAT based planning and scheduling",
      "author" : [ "H. Nabeshima", "T. Soh", "K. Inoue", "K. Iwanuma" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Nabeshima et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Nabeshima et al\\.",
      "year" : 2006
    }, {
      "title" : "The complexity of optimal planning and a more efficient method for finding solutions",
      "author" : [ "K. Ray", "M.L. Ginsberg" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Ray and Ginsberg,? \\Q2008\\E",
      "shortCiteRegEx" : "Ray and Ginsberg",
      "year" : 2008
    }, {
      "title" : "Landmarks Revisited",
      "author" : [ "S. Richter", "M. Helmert", "M. Westphal" ],
      "venue" : "In Proceedings of AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Richter et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Richter et al\\.",
      "year" : 2008
    }, {
      "title" : "Symmetry Reduction for SAT Representations of Transition System",
      "author" : [ "J. Rintanen" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Rintanen,? \\Q2003\\E",
      "shortCiteRegEx" : "Rintanen",
      "year" : 2003
    }, {
      "title" : "Biclique-based representations of binary constraints for making SAT planning applicable to larger problems",
      "author" : [ "J. Rintanen" ],
      "venue" : "In Proceedings of European Conference on Artificial Intelligence",
      "citeRegEx" : "Rintanen,? \\Q2006\\E",
      "shortCiteRegEx" : "Rintanen",
      "year" : 2006
    }, {
      "title" : "Planning as Satisfiability: parallel plans and algorithms for plan search",
      "author" : [ "J. Rintanen", "K. Heljanko", "I. Niemelä" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Rintanen et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Rintanen et al\\.",
      "year" : 2006
    }, {
      "title" : "SAT-Based Parallel Planning Using a Split Representation of Actions",
      "author" : [ "N. Robinson", "C. Gretton", "D. Pham", "A. Sattar" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Robinson et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Robinson et al\\.",
      "year" : 2009
    }, {
      "title" : "Constraint propagation in propositional planning",
      "author" : [ "A. Sideris", "Y. Dimopoulos" ],
      "venue" : "In Proceedings of International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Sideris and Dimopoulos,? \\Q2010\\E",
      "shortCiteRegEx" : "Sideris and Dimopoulos",
      "year" : 2010
    }, {
      "title" : "Extending sat solvers to cryptographic problems",
      "author" : [ "M. Soos", "K. Nohl", "C. Castelluccia" ],
      "venue" : "In International Conference on Theory and Applications of Satisfiability Testing",
      "citeRegEx" : "Soos et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Soos et al\\.",
      "year" : 2009
    }, {
      "title" : "Backdoors to typical case complexity",
      "author" : [ "R. Williams", "C. Gomes", "B. Selman" ],
      "venue" : "In Proceedings of International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Williams et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2003
    }, {
      "title" : "MaxPlan: Optimal Planning by Decomposed Satisfiability and Backward Reduction",
      "author" : [ "Z. Xing", "Y. Chen", "W. Zhang" ],
      "venue" : "In 5th International Planning Competition, International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Xing et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2006
    }, {
      "title" : "Configuration landscape analysis and backbone guided local search: Part I: Satisfiability and maximum satisfiability",
      "author" : [ "W. Zhang" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Zhang,? \\Q2004\\E",
      "shortCiteRegEx" : "Zhang",
      "year" : 2004
    }, {
      "title" : "Backbone Guided Local Search for Maximum Satisfiability",
      "author" : [ "W. Zhang", "A. Rangan", "M. Looks" ],
      "venue" : "In Proceedings of International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Zhang et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "The SAS+ formalism has been used to derive heuristics (Helmert, 2006; Helmert, Haslum, & Hoffmann, 2008), landmarks (Richter, Helmert, & Westphal, 2008), new search models (Chen, Huang, & Zhang, 2008), and strong mutual exclusion constraints (Chen, Huang, Xing, & Zhang, 2009).",
      "startOffset" : 54,
      "endOffset" : 104
    }, {
      "referenceID" : 20,
      "context" : "Here, we assume the correctness of the PE encoding, in SatPlan06 (Kautz et al., 2006) for STRIPS planning.",
      "startOffset" : 65,
      "endOffset" : 85
    }, {
      "referenceID" : 22,
      "context" : "1 and the reason that the widely used SAT solving heuristic VSIDS (Moskewicz et al., 2001) works better on SASE encodings.",
      "startOffset" : 66,
      "endOffset" : 90
    }, {
      "referenceID" : 22,
      "context" : "Most existing complete SAT algorithms use variants of the VSIDS heuristic (Moskewicz et al., 2001) as their variable ordering strategy.",
      "startOffset" : 74,
      "endOffset" : 98
    }, {
      "referenceID" : 28,
      "context" : "To reduce the number of clauses used, we in SASE use a compact representation (Rintanen, 2006), which uses Θ(n log n) auxiliary variables and Θ(n logn) clauses.",
      "startOffset" : 78,
      "endOffset" : 94
    }, {
      "referenceID" : 20,
      "context" : "They are the original SatPlan06 planner (Kautz et al., 2006), only with the underlying SAT solver changed to Precosat and CryptoMinisat, respectively.",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 20,
      "context" : "It is SatPlan06 (Kautz et al., 2006) with long-distance mutual exclusion (londex) (Chen et al.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 3,
      "context" : ", 2006) with long-distance mutual exclusion (londex) (Chen et al., 2009).",
      "startOffset" : 53,
      "endOffset" : 72
    }, {
      "referenceID" : 28,
      "context" : "It is SatPlan06 with the clique technique (Rintanen, 2006) to represent the mutual exclusions.",
      "startOffset" : 42,
      "endOffset" : 58
    }, {
      "referenceID" : 29,
      "context" : "The nplan solver (Rintanen et al., 2006) is set to use ∀-step to generate plans with the same optimality metric as other planners.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 30,
      "context" : "It is the split encoding (Robinson et al., 2009) using Precosat.",
      "startOffset" : 25,
      "endOffset" : 48
    }, {
      "referenceID" : 29,
      "context" : "We believe the reason should be the way nplan encodes all mutual exclusions as linear encoding (Rintanen et al., 2006), which could be further used to improve SASE.",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "The split action representation (Kautz & Selman, 1992; Ernst et al., 1997) uses a conjunction of multiple variables to represent an action.",
      "startOffset" : 32,
      "endOffset" : 74
    }, {
      "referenceID" : 7,
      "context" : "The split action representation (Kautz & Selman, 1992; Ernst et al., 1997) uses a conjunction of multiple variables to represent an action. The optimality is, however, lost. Robinson et al. (2009) propose a new way of doing splitting without sacrificing the optimality.",
      "startOffset" : 55,
      "endOffset" : 197
    }, {
      "referenceID" : 20,
      "context" : "show that this method has advantages over SatPlan06 (Kautz et al., 2006).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 3,
      "context" : "In particular, the power of mutual exclusion, in the context of planning as SAT, has attracted interests (Chen et al., 2009; Sideris & Dimopoulos, 2010).",
      "startOffset" : 105,
      "endOffset" : 152
    }, {
      "referenceID" : 29,
      "context" : "The step-optimality semantics, along with a relaxed parallel semantics, are formalized as ∀-step and ∃-step, respectively (Dimopoulos, Nebel, & Koehler, 1997; Rintanen et al., 2006).",
      "startOffset" : 122,
      "endOffset" : 181
    }, {
      "referenceID" : 7,
      "context" : "The first planner of this kind is MEDIC (Ernst et al., 1997), which extends the idea of splitted action representation.",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 28,
      "context" : "Rintanen proposes a log size technique (Rintanen, 2006), called clique representation, for the mutual exclusion constraints, and later a linear size one (Rintanen et al.",
      "startOffset" : 39,
      "endOffset" : 55
    }, {
      "referenceID" : 29,
      "context" : "Rintanen proposes a log size technique (Rintanen, 2006), called clique representation, for the mutual exclusion constraints, and later a linear size one (Rintanen et al., 2006).",
      "startOffset" : 153,
      "endOffset" : 176
    }, {
      "referenceID" : 27,
      "context" : "Rintanen introduces how to incorporate symmetry information into SAT instances (Rintanen, 2003).",
      "startOffset" : 79,
      "endOffset" : 95
    }, {
      "referenceID" : 35,
      "context" : "There is much prior research that tries to obtain such an understanding, including backdoor set (Williams, Gomes, & Selman, 2003) and backbone (Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999; Zhang, Rangan, & Looks, 2003; Zhang, 2004).",
      "startOffset" : 143,
      "endOffset" : 246
    }, {
      "referenceID" : 13,
      "context" : "A recent study in the context of planning reveals that there is clear correlations between the SAT solving efficiency and goal asymmetry (Hoffmann et al., 2006).",
      "startOffset" : 137,
      "endOffset" : 160
    }, {
      "referenceID" : 16,
      "context" : "Finally, given the efficiency of SASE, it is promising to apply it to other SAT-based planning approaches, such as those for complex planning with preferences (Giunchiglia & Maratea, 2007) and temporal features (Huang et al., 2009).",
      "startOffset" : 211,
      "endOffset" : 231
    } ],
    "year" : 2011,
    "abstractText" : "Planning as satisfiability is a principal approach to planning with many eminent advantages. The existing planning as satisfiability techniques usually use encodings compiled from STRIPS. We introduce a novel SAT encoding scheme (SASE) based on the SAS+ formalism. The new scheme exploits the structural information in SAS+, resulting in an encoding that is both more compact and efficient for planning. We prove the correctness of the new encoding by establishing an isomorphism between the solution plans of SASE and that of STRIPS based encodings. We further analyze the transition variables newly introduced in SASE to explain why it accommodates modern SAT solving algorithms and improves performance. We give empirical statistical results to support our analysis. We also develop a number of techniques to further reduce the encoding size of SASE, and conduct experimental studies to show the strength of each individual technique. Finally, we report extensive experimental results to demonstrate significant improvements of SASE over the state-of-the-art STRIPS based encoding schemes in terms of both time and memory efficiency.",
    "creator" : "gnuplot 4.4 patchlevel 0-rc1"
  }
}