{
  "name" : "1703.06925.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Black-Box Optimization in Machine Learning with Trust Region Based Derivative Free Algorithm",
    "authors" : [ "Hiva Ghanbari", "Katya Scheinberg" ],
    "emails" : [ "<hiva.ghanbari@gmail.com>,", "<katyascheinberg@gmail.com>." ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 3.\n06 92\n5v 1\n[ cs\n.L G\n] 2\n0 M\nar 2\n01 7\nDerivative Free Optimization (DFO-TR) method to directly maximize the Area Under Receiver Operating Characteristic Curve (AUC), which is a nonsmooth, noisy function. We show that AUC is a smooth function, in expectation, if the distributions of the positive and negative data points obey a jointly normal distribution. The practical performance of this algorithm is compared to three prominent Bayesian optimization methods and random search. The presented numerical results show that DFO-TR surpasses Bayesian optimization and random search on various blackbox optimization problem, such as maximizing AUC and hyperparameter tuning."
    }, {
      "heading" : "1. Introduction",
      "text" : "Most machine learning (ML) models rely on optimization tools to perform training. Typically these models are formed so that at least stochastic estimates of the gradient can be computed; for example, when optimizing least squares or logistic loss of a neural network on a given data set. Lately, however, with the increasing need to tune hyperparameters of ML models, black-box optimization methods have been given significant consideration. These methods do not rely on any explicit gradient computation, but assume that only function values can be computed, usually with noise.\nThere are two relatively independent directions of research for black-box optimization–Bayesian Optimization (BO) (Mockus, 1994; Brochu et al., 2010), predominantly popular in the ML community, and derivative free optimization (DFO) (Conn et al., 2009)–popular in the optimization community. There are other classes of methods for blackbox optimization developed in the fields of simulation op-\n1Lehigh University, Bethlehem, PA, USA. Correspondence to: Hiva Ghanbari <hiva.ghanbari@gmail.com>, Katya Scheinberg <katyascheinberg@gmail.com>.\ntimization and engineering, but they are more specialized and we will not focus on them here.\nBoth BO and DFO methods are usually applied to functions that are not known to be convex. The key difference between the BO and DFO methods, is that BO methods always contain a component that aims at the exploration of the space, hence seeking a global solution, while DFO methods are content with a local optimum. However, it has been shown in DFO literature (More & Wild, 2009) that DFO methods tend to escape shallow local minima and are quite well suited for problems with a few well defined local basins (and possiblymany small local basins that appear due to noise).\nBO until recently have been established as the method of choice for hyperparameter optimization (HPO). While BO methods have been shown to be effective at finding good solutions (not always globally optimal, as that can only be achieved in the limit), their efficiency slows down significantly as the number of iterations grows. Overall, the methods are quite computationally costly and scale poorly with the number of hyperparameters. Recently, the BO efficiency has been called into question in comparison with a simple random search (Li et al., 2016), whose iterations require nothing, but function evaluations. Moreover, some improvements on random search have been proposed to incorporate cheeper function evaluations and further increase its efficiency for HPO.\nIn this paper, we will explore properties of an efficient class of DFO methods–model-based trust region methods–in application to problems in ML.We will show that these methods can bemore efficient than BO and random search, especially for problems of dimensions higher than 2 or 3. In the specific case of HPO, hyperparameters can be continuous, discrete or categorical. While some DFO methods have been developed for the case of optimization over categorical or binary variables, these methods essentially rely on local search heuristics and we do not consider them here. Our goal is to examine, in detail, the behavior of various black-box methods in a purely continuous setting. We also aim to explore practical scalability of the methods with respect to the dimension of the search space and nonlinearity of the function. While we will list some experiments on\nHPO problems, these problems are limited to three continuous hyperparameters. Hence, to perform our comparison on problems of larger dimension, we mainly focus on a different problem–optimizing Area Under Receiver Operating Characteristic (ROC) Curve (AUC) (Hanley & McNeil, 1982), over a set of linear classifiers.\nAUC is a widely used measure for learning with imbalanced data sets, which are dominant in ML applications. Various results has been reported in terms of comparing the AUC value as a performance measure of a classifier versus the usual prediction accuracy, that is the total percentage of misclassified examples (Bradley, 1997; Ferri et al., 2002; Brefeld & Scheffer, 2005; Lu et al., 2010). In particular, in (Bradley, 1997), AUC is used to evaluate the performance of some ML algorithms such as decision trees, neural networks, and some statistical methods, where, experimentally, it is shown that AUC has advantages over the accuracy. In (Cortes & Mohri, 2004), a statistical analysis of the relationship between AUC and the error rate, including the expected value and the variance of AUC for a fixed error rate, has been presented. Their results show that the average AUC value monotonically increases with the classification accuracy, but in the case of uneven class distributions, the variance of AUC can be large. This observation implies that the classifiers with the same fixed low accuracy may have noticeably different AUC values. Therefore, optimizing AUC value directly may be desirable, however doing so using gradient-based optimization techniques is not feasible, because this function is a discontinuous step function, hence its gradients are either zero or undefined.\nThis difficulty motivates various state-of-the-art techniques optimizing an approximation of this discontinuous loss function. In (Yan et al., 2003; Herschtal & Raskutti, 2004; Calders & Jaroszewicz, 2007), various smooth nonconvex approximation of AUC has been optimized by the gradient descent method. Alternatively, a ranking loss, which is defined as 1−AUC value, is minimized approximately, by replacing it with the pairwise margin loss, such as exponential loss, logistic loss, and hinge loss (Joachims, 2006; Steck, 2007; Rudin & Schapire, 2009; Zhao et al., 2011), which results in a convex problem. In terms of computational effort, each iteration of the gradient descent algorithm applied to the pairwise exponential or logistic loss has quadratic computational complexity with the number of training samples N . However, computing the gradient of the pairwise hinge loss can be done by a method with the reduced complexity of O(N logN). The same method can be applied to compute the AUC value itself, which we utilize in our approach.\nIn this work, we apply a variant of a model-based trust region derivative free method, called DFO-TR, (Conn et al., 2009) to directly maximize the AUC function over a set of\nlinear classifiers, without using any hyperparameters. We note that in HPO the black-box function is often the validation error or accuracy achieved by the classifier trained using some given set of hyperparameters. Hence, like AUC this function is often piecewise constant and discontinuous. Thus, we believe that optimizing AUC directly and HPO in continuous domains have many common properties as black-box optimization problems. The main goal of this work is to demonstrate the advantages of the DFO-TR framework over other black-box optimization algorithms, such as Bayesian optimization and random search for various ML applications.\nBayesian optimization is known in the ML community as a powerful tool for optimizing nonconvex objective functions, which are expensive to evaluate, and whose derivatives are not accessible. In terms of required number of objective function evaluations, Bayesian optimization methods are considered to be some of the most efficient techniques (Mockus, 1994; Jones et al., 1998; Brochu et al., 2010) for black-box problems of low effective dimensionality. In theory, Bayesian optimizationmethods seek global optimal solution, due to their sampling schemes, which trade-off between exploitation and exploration (Brochu et al., 2010; Eggensperger et al., 2013). Specifically, Bayesian optimization methods construct a probabilistic model by using point evaluations of the true function. Then, by using this model, the subsequent configurations of the parameters will be selected (Brochu et al., 2010) by optimizing an acquisition function derived from the model. The model is built based on all past evaluation points in an attempt to approximate the true function globally. As a result, the acquisition function is often not trivial to maintain and optimize and per iteration complexity of BO methods increases. On the other hand, DFO-TR and other model-based DFO methods content themselves with building a local model of the true function, hence maintenance of such models remains moderate and optimization step on each iteration is cheap.\nWe compare DFO-TR with SMAC (Hutter et al., 2011), SPEARMINT (Snoek et al., 2012), and TPE (Bergstra et al., 2011), which are popular Bayesian optimization algorithms based on different types of model. We show that DFO-TR is capable of obtaining better or comparable objective function values using fewer function evaluations and a much better computational effort overall. We also show that DFO-TR is more efficient than random search, finding better objective function values faster. We also discuss the convergence properties of DFO-TR and its stochastic variant (Chen et al., 2015), and argue that these results apply to optimizing expected AUC value, when it is a smooth function. We suggest further improvements to the algorithm by applying stochastic function evaluations and thus reducing function evaluation complexity and\ndemonstrate computational advantage of this approach.\nIn summary our contributions are as follows\n• We provide a computational comparison that shows that model-based trust-region DFO methods can be\nsuperior to BO methods and random search on a variety of black-box problems over continuous variables arising in ML.\n• We utilize recently developed theory of stochastic model-based trust region methods to provide theoret-\nical foundations for applying the method to optimize AUC function over a set of linear classifiers. We show that this function is continuous in expectations under certain assumptions on the data set.\n• We provide a simple direct way to optimize AUC function, which is often more desirable than optimiz-\ning accuracy or classical loss functions.\nThis paper is organized in six sections. In the next section, we describe the practical framework of a DFO-TR algorithm. In §3, we describe how AUC function can be interpreted as a smooth function in expectation. In §4, we state the main similarities and differences between Bayesian optimization and DFO-TR. We present computational results in §5. Finally, we state our conclusions in §6."
    }, {
      "heading" : "2. Algorithmic Framework of DFO-TR",
      "text" : "Model-based trust region DFO methods (Conn et al., 1997; Powell, 2004) have been proposed for a class of optimization problems of the formminw∈Rd f(w), when computing the gradient and the Hessian of f(w) is not possible, either because it is unknown or because the computable gradient is too noisy to be of use. It is, however, assumed that some local first-order or even second-order information of the objective function is possible to construct to an accuracy sufficient for optimization. If the function is smooth, then such information is usually constructed by building an interpolation or regression model of f(w) using a set of points for which function value is (approximately known) (Conn et al., 2009). By using quadratic models, these methods are capable of approximating the secondorder information efficiently to speed up convergence and to guarantee convergence to local minima, rather than simply local stationary points. They have been shown to be themost practical black-box optimizationmethods in deterministic settings (More & Wild, 2009). Extensive convergence analysis of these methods over smooth deterministic functions have been summarized in (Conn et al., 2009).\nRecently, several variants of trust region methods have been proposed to solve stochastic optimization problem minw Eξ[f(w, ξ)], where f(w, ξ) is a stochastic function\nof a deterministic vector w ∈ Rd and a random variable ξ (Shashaani et al., 2015; Billups & Larson, 2016; Chen et al., 2015). In particular, in (Chen et al., 2015), a trust region based stochastic method, referred to STORM (STochastic Optimization with Random Models), is introduced and shown to converge, almost surely, to a stationary point ofEξ[f(w, ξ)], under the assumption thatEξ[f(w, ξ)] is smooth. Moreover, in recent work (Blanchet et al., 2016) a convergence rate of this method has been analyzed. This class of stochastic methods utilizes samples of f(w, ξ) to construct models that approximate Eξ[f(w, ξ)] sufficiently accurately, with high enough probability. In the next section, we will show that the AUC function can be a smooth function in expectation, under some conditions, hence STORM method and tis convergence properties are applicable. For general convergent framework of STORM, we refer the reader to (Chen et al., 2015).\nHere in Algorithm 1, we present the specific practical implementation of a deterministic algorithm, which can work with finite training sets rather than infinite distributions, but shares many properties with STORM and produces very good results in practice. The key difference between STORM and DFO-TR is that the former requires resampling f(w, ξ) for various w’s, at each iteration, since f(w, ξ) is a random value for any fixed w, while DFO-TR computes only one value of deterministic f(w) per iteration. When applied to deterministic smooth functions, this algorithm converges to a local solution (Conn et al., 2009), but here we apply it to a nonsooth function which can be viewed as a noisy version of a smooth function (as argued in the next section). While there are no convergence results for DFO-TR or STORM for deterministic nonsooth, noisy functions, the existing results indicate that the DFOTR method will converge to a neighborhood of the solution before the noise in the function estimates prevents further progress. Our computational results conform this.\nWe note a few key properties on the algorithm. At each iteration, a quadratic model, not necessarily convex, is constructed using previously evaluated points that are sufficiently close to the current iterate. Then, this model is optimized inside the trust region B(wk,∆k) := {w : ‖w − wk‖ ≤ ∆k}. The global solution for the trust region subproblem is well known and can be obtained efficiently in O(d3) operations (Conn et al., 2000), which is not expensive, since in our setting d is small. The number of points that are used to construct the model is at most (d+1)(d+2)\n2 ,\nbut good models that exploit some second-order information can be constructed with O(d) points. Each iteration requires only one new evaluation of the function and the new function value either provides an improvement over the best observed value or can be used to improve the local model (Scheinberg & Toint, 2010). Thus the method utilizes function evaluations very efficiently.\nAlgorithm 1 Trust Region based Derivative Free Optimization (DFO-TR)\n1: Initializations: 2: Initialize w0,∆0 > 0, and choose 0 < η0 < η1 < 1, θ > 1, and 0 < γ1 < 1 < γ2. 3: Define an interpolation set W ∈ B(w0,∆0). 4: Compute f(w) for all w ∈ W , let m = |W|. 5: Let w0 := w̄0 = argminw∈W f(w). 6: for k = 1, 2, · · · do 7: Build the model: 8: Discard all w ∈ W such that ‖w − wk‖ ≥ θ∆k . 9: UsingW construct an interpolation model:\nQk(w) = fk + g T k (w − wk)\n+ 12 (w − wk) THk(w − wk).\n10: Minimize the model within the trust region: 11: ŵk = argminw∈B(wk,∆k) Qk(w). 12: Compute f(ŵk) and ρk := f(wk)−f(ŵk)\nQk(wk)−Qk(ŵk) .\n13: Update the interpolation set: 14: if m < 12 (d+ 1)(d+ 2) then 15: add new point ŵk to the interpolation set W , andm := m+ 1. 16: else 17: if ρk ≥ η0 then replace argmaxw∈W ‖w − wk‖ with ŵk, 18: otherwise do the same if ‖w − wk‖ < maxw∈W ‖w − wk‖. 19: end if 20: Update the trust region radius: 21: if ρk ≥ η1 then wk+1 ← ŵk and∆k+1 ← γ2∆k. 22: if ρk < η0 then wk+1 ← wk, and ifm > d+ 1 update∆k+1 ← γ1∆k, otherwise∆k+1 ← ∆k. 23: end for."
    }, {
      "heading" : "3. AUC function and its expectation",
      "text" : "In this section, we define the AUC function of a linear classifier wTx and demonstrate that under certain assumptions on the data set distribution, its expected value is smooth with respect to w. First, suppose that we have two given sets S+ := {x + i : i = 1, . . . , N+} and S− := {x −\nj : j = 1, . . . , N−}, sampled from distributions D1 and D2, respectively. For a given linear classifier wTx, the corresponding AUC value, a (noisy) nonsmooth deterministic function, is obtained as (Mann & Whitney, 1947)\nFAUC(w) =\n∑N+ i=1 ∑N − j=1 Iw(x + i , x − j )\nN+N− , (1)\nwhere Iw is an indicator function defined as\nIw(x + i , x − j ) =\n{\n+1 if wTx+i > w Tx−j , 0 otherwise.\nClearly, FAUC(w) is piece-wise constant function of w, hence it is not continuous. However, we show that the ex-\npected value of AUC, denoted byE[FAUC(w)], is a smooth function of the vector w, where the expectation is taken over S+ and S−, in some cases.\nTo this end, first we need to interpret the expected value of AUC in terms of a probability value. For two given finite sets S+ and S−, the AUC value of the classifier wTx can be interpreted as\nFAUC(w) = P ( wTX+ > w TX− ) ,\nwhere X+ and X− are randomly sampled from S+ and S−, respectively. Now, if two sets S+ and S− are randomly drawn from distributions D1 and D2, then the expected value of AUC is defined as\nE [FAUC(w)] = P ( wT X̂+ > w T X̂− ) , (2)\nwhere X̂+ and X̂− are randomly chosen from distributions D1 and D2, respectively. In what follows, we show that if two distributions D1 and D2 are jointly normal, then E[FAUC(w)] is a smooth function of w. We use the following results from statistic.\nTheorem 1 If two d−dimensional random vectors X̂1 and X̂2 have a joint multivariate normal distribution, such that\n(\nX̂1 X̂2\n)\n∼ N (µ,Σ) , (3)\nwhere µ =\n(\nµ1 µ2\n)\nand Σ =\n(\nΣ11 Σ12 Σ21 Σ22\n)\n.\nThen, the marginal distributions of X̂1 and X̂2 are normal distributions with the following properties\nX̂1 ∼ N (µ1,Σ11) , X̂2 ∼ N (µ2,Σ22) .\nProof 1 The proof can be found in (Tong, 1990).\nTheorem 2 Consider two random vectors X̂1 and X̂2, as defined in (3), then for any vector w ∈ Rd, we have\nZ = wT ( X̂1 − X̂2 ) ∼ N ( µZ , σ 2 Z ) , (4)\nwhere µZ = w T (µ1 − µ2)\nand σ2Z = w T (Σ11 +Σ22 − Σ12 − Σ21)w.\n(5)\nProof 2 The proof can be found in (Tong, 1990).\nNow, in what follows, we have the formula for the expected value of the AUC.\nTheorem 3 If two random vectors X̂1 and X̂2, respectively drawn from distributions D1 and D2, have a joint\nnormal distribution as defined in Theorem 1, then the expected value of AUC function can be defined as\nE [FAUC(w)] = φ\n(\nµZ σZ\n)\n,\nwhere φ is the cumulative function of the standard normal distribution, so that φ(x) = e− 1 2 x2/2π, for ∀x ∈ R.\nProof 3 From Theorem 2 we have\nE [FAUC(w)]\n= P ( wT X̂+ > w T X̂− ) = P ( wT (X̂+ − X̂−) > 0 )\n= P (Z > 0) = 1− P (Z ≤ 0)\n= 1− P\n(\nZ − µZ σZ ≤ −µZ σZ\n)\n= 1− φ\n(\n−µZ σZ\n)\n= φ\n(\nµZ σZ\n)\n,\nwhere random variable Z has been defined in (4), with the stated mean and variance in (5).\nIn Theorem 3, since the cumulative function of the standard normal distribution, i.e., φ, is a smooth function, we can conclude that for a given linear classifier wTx, the corresponding expected value of AUC, is a smooth function of w. Moreover, it is possible to compute derivatives of this function, if the first and second moments of the normal distribution are known. We believe that the assumption of the positive and negative data classes obeying jointly normal distribution is too strong to be satisfied for most of the practical problems, hence we do not think that the gradient estimates of φ (µZ/σZ) will provide good estimates of the true expected AUC. However, we believe that smoothness of the expected AUC remains true in cases of many practical distributions. The extension of this observation can be considered as a subject of a future study."
    }, {
      "heading" : "4. Bayesian Optimization versus DFO-TR",
      "text" : "Bayesian optimization framework, as outlined in Algorithm 2, like DFO-TR framework operates by constructing a (probabilistic) modelM(w) of the true function f by using function values computed thus far by the algorithm. The next iterate wk is computed by optimizing an acquisition function, aM , which presents a trade-off between minimizing the model and improving the model, by exploring areas where f(w) has not been sampled. Different Bayesian optimization algorithms use different models and different acquisition functions, for instance, expected improvement (M. Schonlau & Jones, 1998) over the best observed function value is a popular acquisition function in the literature.\nThe key advantage and difficulty of BO methods is that the acquisition function may have a complex structure, and needs to be optimized globally on each iteration. For example, the algorithm in (Brochu et al., 2010) uses deterministic derivative free optimizer DIRECT (Jones et al., 1993) to maximize the acquisition function. When evaluation of f(w) is very expensive, then the expense of optimizing the acquisition function may be small in comparison. However, in many case, as we will see in our computational experiments, this expense can be dominant. In contrast, the DFO-TR method, as described in Algorithm 1, maintains a quadratic model by using only the points in the neighborhood of the current iterate and global optimization of this model subject to the trust region constraint can be done efficiently, as was explained in the previous section. While Q(w) is a local model, it can capture nonconvexity of the true function f(w) and hence allows the algorithm to follow negative curvature directions. As we will see in §5.2, for the same amount of number of function evaluations, DFO-TR achieved better or comparable function values, while requiring significantly less computational time than Bayesian optimization algorithms (TPE, SMAC, and SPEARMINT).\nAlgorithm 2 Bayesian Optimization\n1: for t = 1, 2, · · · do 2: Findwk by optimizing the acquisition function over\nmodelM : wk ← argminw aM (w|D1:k−1). 3: Sample the objective function: vk := f(wk). 4: Augment the data D1:k = {D1:k−1, (wk, vk)}\nand update the modelM . 5: end for"
    }, {
      "heading" : "5. Numerical Experiments",
      "text" : ""
    }, {
      "heading" : "5.1. Optimizing Smooth, NonConvex Benchmark Functions",
      "text" : "In this section, we compare the performance of DFO-TR and Bayesian optimization algorithms on optimizing three nonconvex smooth benchmark functions. We compare the precision ∆fopt with the global optimal value, which is known, and is computed after a given number of function evaluations.\nAlgorithm 1 is implemented in Python 2.7.11 1 . We start from the zero vector as the initial point. In addition, the trust region radius is initialized as ∆0 = 1 and the initial interpolation set has d + 1 random members. The parameters are chosen as η0 = 0.001, η1 = 0.75, θ = 10, γ1 = 0.98, and γ2 = 1.5. We have used the hyperparameter optimization library, HPOlib 2, to perform the experi-\n1 https://github.com/TheClimateCorporation/dfo-algorithm 2 www.automl.org/hpolib\nments on TPE, SMAC, and SPEARMINT algorithms, implemented in Python, Java3, and MATLAB, respectively. Each benchmark function is evaluated on its known search space, as is defined in the default setting of the HPOlib (note that DFO-TR does not require nor utilizes a restricted search space).\nWe can see that on all three problems DFO-TR reaches the global value accurately and quickly, outperforming BO methods. This is because DFO-TR utilizes second-order information effectively, which helps following negative curvature and significantly improving convergence in the absence of noise. Among the three Bayesian optimization algorithms SPEARMINT performs better while the performance of TPE and SMAC is comparable to each other, but inferior to those of SPEARMINT and DFO-TR."
    }, {
      "heading" : "5.2. Optimizing AUC Function",
      "text" : "In this section, we compare the performance of DFOTR and the three Bayesian optimization algorithms, TPE, SMAC, and SPEARMINT, on the task of optimizing AUC of a linear classifier, defined byw. While in §3, we have argued that E[FAUC(w)] is a smooth function, in practice we have a finite data set, hence we compute the noisy nonsmooth estimate of E[FAUC(w)]. This, essentially means, that we can only expect to optimize the objective up to some accuracy, after which the noise will prevent further progress.\nIn our experiments, we used 12 binary class data sets, as shown in Table 4, where some of the data sets are normalized so that each dimension has mean 0 and variance 1. These data sets can be downloaded from LIBSVM website 3 and UCI machine learning repository.\nThe average value of AUC and its standard deviation, using five-fold cross-validation, is reported as the performance measure. Table 5 summarizes the results.\nThe initial vector w0 for DFO-TR is set to zero and the search space of Bayesian optimization algorithms is set to interval [−1, 1]. For each data set, a fixed total budget of number of function evaluations is given to each algorithm and the final AUC computed on the test set is compared.\nFor each data set, the bold number indicates the best average AUC value found by a Bayesian optimization algorithms. We can see that DFO-TR attains comparable or better AUC value to the best one, in almost all cases. Since for each data set, all algorithms are performed for the same budget of number of function evaluations, we do not include the time spent on function evaluations in the reported time. Thus, the time reported in Table 5 is only the optimizer time. As we can see, DFO-TR is significantly faster than Bayesian optimization algorithms, while it performs competitively in terms of the average value of AUC. Note that the problems are listed in the order of increasing dimension d. Even thought the MATLAB implantation of SPEARMINT probably puts it at a certain disadvantage in terms of computational time comparisons, we observe that it is clearly a slow method, whose complexity grows significantly as d increases.\nNext, we compare the performance of DFO-TR versus the random search algorithm (implemented in Python 2.7.11) on maximizing AUC. Table 6 summarizes the results, in a similar manner to Table 5. Moreover, in Table 6, we also allow random search to use twice the budget of the\n3 https://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/binary.htm\nfunction evaluations, as is done in (Jamieson & Talwalkar, 2015) when comparing random search to BO. The random search algorithm is competitive with DFO-TR on a few problems, when using twice the budget, however, it can be seen that as the problem dimension grows, the efficiency of random search goes down substantially. Overall, DFO-TR consistently surpasses random search when function evaluation budgets are equal, while not requiring very significant overhead, as the BO methods.\nWe finally note that while we exclude comparisons with other methods, that optimize AUC surrogates, from this paper, due to lack of space, we have performed such experiments and observed that the final AUC values obtained by DFO-TR and BO are competitive with other existing methods."
    }, {
      "heading" : "5.2.1. STOCHASTIC VERSUS DETERMINISTIC DFO-TR",
      "text" : "In order to further improve efficiency of DFO-TR, we observe that STORM framework and theory (Chen et al., 2015) suggests that noisy function evaluations do not need to be accurate far away from the optimal solution. In our context, this means that AUC can be evaluated on small subsets of the training set, which gradually increase as the algorithm progresses. In particular, at each iteration, we compute AUC on a subset of data, which is sampled from positive and negative sets uniformly at random, at the rate\nmin{N,max{k × ⌊50× (N/(N+ +N−))⌋+\n⌊1000× (N/(N+ +N−))⌋, ⌊0.1×N⌋}},\nwhere N+ = S+ and N− = S−, and N = N+, when we sample from the positive class and N = N−, when we sample from the negative one. For each class, at least 10 percent of the whole training data is used.\nWe include an additional modification–after each unsuccessful step with ρk < η0, we compute fnew(wk) by resampling over data points. Then, we update f(wk) such that f(wk) := (f(wk) + fnew(wk)) /2. This is done, so that accidental incorrectly high AUC values are not pre-\nventing the algorithm from making progress. This results in a less expensive (in terms of function evaluation cost) algorithm, while, as we see in Figure 1, the convergence to the optimal solution is comparable.\nWe chose two data sets shuttle and letter to compare the performance of the stochastic variant of the DFO-TR with the deterministic one. These sets were chosen because they contain a relatively large number of data points and hence the effect of subsampling can be observed. We repeated each experiment four times using five-fold crossvalidation (due to the random nature of the stochastic sampling). Hence, for each problem, the algorithms have been applied 20 times in total, and the average AUC values are reported in Figure 1. At each round, all parameters of DFOTR and S-DFO-TR are set as described in §5.1, except w0, which is a random vector evenly distributed over [−1, 1].\nAs we see in Figure 1, the growth rate of AUC over iterations in S-DFO-TR is as competitive as that of DFO-TR. However, by reducing the size of the data sets, the iteration of S-DFO-TR are significantly cheaper than that of DFO-TR, especially at the beginning. This indicates that the methods can handle large data sets.\nWe finally note that we chose to optimize AUC over linear classifiers for simplicity only. Any other classifier parametrized by w can be trained using a black-box optimizer in a similar way. However, the current DFO-TR method have some difficulties in convergence with problems when dimension of w is very large."
    }, {
      "heading" : "5.3. Hyperparameter Tuning of Cost-Sensitive RBF-Kernel SVM",
      "text" : "Finally, we turn to hyperparamater tuning to show that DFO-TR can also outperform state-of-the-art methods on this problem. We consider tuning parameters of an RBFkernel, cost-sensitive, SVM, with ℓ2 regularization parameter λ, kernel width γ, and positive class cost cp. Thus, in this setting, we compare the performance of DFO-TR,\nTable 6. Comparing DFO-TR vs. random search algorithm.\nData DFO-TR Random Search Random Search\nAUC num. fevals AUC num. fevals AUC num. fevals\nfourclass 0.835±0.019 100 0.836±0.017 100 0.839±0.021 200 svmguide1 0.988±0.004 100 0.965±0.024 100 0.977±0.009 200 diabetes 0.829±0.041 100 0.783±0.038 100 0.801±0.045 200 shuttle 0.990±0.001 100 0.982±0.006 100 0.988±0.001 200 vowel 0.975±0.027 100 0.944±0.040 100 0.961±0.031 200\nmagic04 0.842±0.006 100 0.815±0.009 100 0.817±0.011 200 letter 0.987±0.003 200 0.920±0.026 200 0.925±0.018 400 segment 0.992±0.007 300 0.903±0.041 300 0.908±0.036 600 ijcnn1 0.913±0.005 300 0.618±0.010 300 0.629±0.013 600 svmguide3 0.776±0.046 300 0.690±0.038 300 0.693±0.039 600 german 0.795±0.024 300 0.726±0.028 300 0.739±0.021 600 satimage 0.757±0.013 300 0.743±0.029 300 0.750±0.020 600\n10 20 30 40 50 60 70 80 90 100 110\nNumber of accessed data points (scale 1e+4)\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\nA U\nC v\nal ue\nDFO-TR, letter (d=16, N=20000)\n0 50 100 150 200 250\nNumber of accessed data points (scale 1e+4)\n0.9\n0.91\n0.92\n0.93\n0.94\n0.95\n0.96\n0.97\n0.98\n0.99\nA U\nC v\nal ue\nDFO-TR, shuttle (d=9, N=43500)\n0 5 10 15 20 25\nNumber of accessed data points (scale 1e+4)\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\nA U\nC v\nal ue\nS-DFO-TR, letter (d=16, N=20000)\n0 5 10 15 20 25 30 35 40\nNumber of accessed data points (scale 1e+4)\n0.9\n0.91\n0.92\n0.93\n0.94\n0.95\n0.96\n0.97\n0.98\n0.99\nA U\nC v\nal ue\nS-DFO-TR, shuttle (d=9, N=43500)\nFigure 1. Comparison of stochastic DFO-TR and deterministic one in optimizing AUC function.\nrandom search, and Bayesian optimization algorithms, in tuning a three-dimensional hyperparameterw = (λ, γ, cp), in order to achieve a high test accuracy.\nFor the random search algorithm, as well as the Bayesian optimization algorithms, the search space is chosen as λ ∈ [10−6, 100], γ ∈ [100, 103], as is done in (Jamieson & Talwalkar, 2015), and cp ∈ [10−2, 102]. The setting of Algorithm 1 is as described in §5.1, while w0 = (λ0, γ0, cp0) is a three-dimensional vector randomly drawn from the search space defined above.\nWe have used the five-fold cross-validation with the trainvalidate-test framework as follows: we used two folds as the training set for the SVM model, other two folds as the validation set to compute and maximize the validation accuracy, and the remaining one as the test set to report the test accuracy.\nFigure 2 illustrates the performance of DFO-TR versus random search and Bayesian optimization algorithms, in terms of the average test accuracy over the number of function\nevaluations. As we can see, DFO-TR constantly surpasses random search and Bayesian optimization algorithms. It is worth mentioning that random search is competitive with the BO methods and in contrast to §5.1 and §5.2, SMAC performs the best among the Bayesian optimization algorithms."
    }, {
      "heading" : "6. Conclusion",
      "text" : "In this work, we demonstrate that model-based derivative free optimization is a better alternative to Bayesian optimization for some black-box optimization tasks arising in machine learning. We rely on an existing convergent stochastic trust region framework to provide theoretical foundation for the chosen algorithm, and we demonstrate the efficiency of a practical implementation of DFO-TR for optimizing AUC function over the set of linear classifiers, hyperparameter tuning, and on other benchmark problems."
    } ],
    "references" : [ {
      "title" : "Algorithms for hyper-parameter optimization",
      "author" : [ "J. Bergstra", "R. Bardenet", "Y. Bengio", "B. Kegl" ],
      "venue" : "In Proc. of NIPS-11,",
      "citeRegEx" : "Bergstra et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bergstra et al\\.",
      "year" : 2011
    }, {
      "title" : "Stochastic derivative-free optimization using a trust region framework",
      "author" : [ "S.C. Billups", "J. Larson" ],
      "venue" : "J. Computational Optimization and Apps,",
      "citeRegEx" : "Billups and Larson,? \\Q2016\\E",
      "shortCiteRegEx" : "Billups and Larson",
      "year" : 2016
    }, {
      "title" : "Convergence rate analysis of a stochastic trust region method for nonconvex optimization",
      "author" : [ "J. Blanchet", "C. Cartis", "M. Menickelly", "K. Scheinberg" ],
      "venue" : null,
      "citeRegEx" : "Blanchet et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Blanchet et al\\.",
      "year" : 2016
    }, {
      "title" : "The use of the area under the ROC curve in the evaluation of machine learning algorithms",
      "author" : [ "A.P. Bradley" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "Bradley,? \\Q1997\\E",
      "shortCiteRegEx" : "Bradley",
      "year" : 1997
    }, {
      "title" : "AUC maximizing support vector learning",
      "author" : [ "U. Brefeld", "T. Scheffer" ],
      "venue" : null,
      "citeRegEx" : "Brefeld and Scheffer,? \\Q2005\\E",
      "shortCiteRegEx" : "Brefeld and Scheffer",
      "year" : 2005
    }, {
      "title" : "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning",
      "author" : [ "E. Brochu", "V.M. Cora", "N. de Freitas" ],
      "venue" : null,
      "citeRegEx" : "Brochu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Brochu et al\\.",
      "year" : 2010
    }, {
      "title" : "Efficient AUC optimization for classification",
      "author" : [ "T. Calders", "S. Jaroszewicz" ],
      "venue" : "Discovery in Databases, Warsaw,",
      "citeRegEx" : "Calders and Jaroszewicz,? \\Q2007\\E",
      "shortCiteRegEx" : "Calders and Jaroszewicz",
      "year" : 2007
    }, {
      "title" : "Stochastic optimization using a trust-region method and random models",
      "author" : [ "R. Chen", "M. Menickelly", "K. Scheinberg" ],
      "venue" : null,
      "citeRegEx" : "Chen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Recent progress in unconstrained nonlinear optimization without derivatives",
      "author" : [ "A.R. Conn", "K. Scheinberg", "Ph. L. Toint" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Conn et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Conn et al\\.",
      "year" : 1997
    }, {
      "title" : "Introduction To Derivative-Free Optimization",
      "author" : [ "A.R. Conn", "K. Scheinberg", "L.N. Vicente" ],
      "venue" : "Society for Industrial and Applied Mathematics. Philadelphia,",
      "citeRegEx" : "Conn et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Conn et al\\.",
      "year" : 2009
    }, {
      "title" : "AUC optimization vs. error rate minimization",
      "author" : [ "C. Cortes", "M. Mohri" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Cortes and Mohri,? \\Q2004\\E",
      "shortCiteRegEx" : "Cortes and Mohri",
      "year" : 2004
    }, {
      "title" : "Towards an empirical foundation for assessing bayesian optimization of hyperparameters",
      "author" : [ "K. Eggensperger", "M. Feurer", "F. Hutter", "J. Bergstra", "J. Snoek", "H.H. Hoos", "K.L. Brown" ],
      "venue" : "In NIPS Workshop on Bayesian Optimization in Theory and Practice,",
      "citeRegEx" : "Eggensperger et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Eggensperger et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning decision trees using the area under the ROC curve",
      "author" : [ "C. Ferri", "P. Flach", "J. Hernandez-Orallo" ],
      "venue" : null,
      "citeRegEx" : "Ferri et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Ferri et al\\.",
      "year" : 2002
    }, {
      "title" : "The meaning and use of the area under a receiver operating characteristic (ROC) curve",
      "author" : [ "J.A. Hanley", "B.J. McNeil" ],
      "venue" : null,
      "citeRegEx" : "Hanley and McNeil,? \\Q1982\\E",
      "shortCiteRegEx" : "Hanley and McNeil",
      "year" : 1982
    }, {
      "title" : "Optimizing area under the ROC curve using gradient descent",
      "author" : [ "A. Herschtal", "B. Raskutti" ],
      "venue" : null,
      "citeRegEx" : "Herschtal and Raskutti,? \\Q2004\\E",
      "shortCiteRegEx" : "Herschtal and Raskutti",
      "year" : 2004
    }, {
      "title" : "Sequential model-based optimization for general algorithm configuration",
      "author" : [ "F. Hutter", "H.H. Hoos", "K. Leyton-Brown" ],
      "venue" : "In Proc. of LION-5,",
      "citeRegEx" : "Hutter et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Hutter et al\\.",
      "year" : 2011
    }, {
      "title" : "Non-stochastic best arm identification and hyperparameter optimization",
      "author" : [ "Jamieson", "Kevin", "Talwalkar", "Ameet" ],
      "venue" : null,
      "citeRegEx" : "Jamieson et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jamieson et al\\.",
      "year" : 2015
    }, {
      "title" : "Training linear SVMs in linear time",
      "author" : [ "T. Joachims" ],
      "venue" : "In ACM SIGKDD, pp",
      "citeRegEx" : "Joachims,? \\Q2006\\E",
      "shortCiteRegEx" : "Joachims",
      "year" : 2006
    }, {
      "title" : "Lipschitzian optimization without the lipschitz constant",
      "author" : [ "D.R. Jones", "C.D. Perttunen", "B.E. Stuckman" ],
      "venue" : "J. Optimization Theory and Apps,",
      "citeRegEx" : "Jones et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Jones et al\\.",
      "year" : 1993
    }, {
      "title" : "Efficient global optimization of expensive black-box functions",
      "author" : [ "D.R. Jones", "M. Schonlau", "W.J. Welch" ],
      "venue" : "J. Global Optimization,",
      "citeRegEx" : "Jones et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Jones et al\\.",
      "year" : 1998
    }, {
      "title" : "Hyperband: A novel bandit-based approach to hyperparameter optimization",
      "author" : [ "L. Li", "K. Jamieson", "G. DeSalvo", "A. Rostamizadeh", "A. Talwalkar" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Evolving neural networks with maximum AUC for imbalanced data classification",
      "author" : [ "X. Lu", "K. Tang", "X. Yao" ],
      "venue" : null,
      "citeRegEx" : "Lu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2010
    }, {
      "title" : "Global versus local search in constrained optimization of computer models",
      "author" : [ "M. Schonlau", "W.J. Welch", "D.R. Jones" ],
      "venue" : "In New Developments and Applications in Experimental Design,",
      "citeRegEx" : "Schonlau et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Schonlau et al\\.",
      "year" : 1998
    }, {
      "title" : "On a test whether one of two random variables is stochastically larger than the other",
      "author" : [ "H.B. Mann", "D.R. Whitney" ],
      "venue" : "Ann. Math. Statist,",
      "citeRegEx" : "Mann and Whitney,? \\Q1947\\E",
      "shortCiteRegEx" : "Mann and Whitney",
      "year" : 1947
    }, {
      "title" : "Application of bayesian approach to numerical methods of global and stochastic optimization",
      "author" : [ "J. Mockus" ],
      "venue" : "J. Global Optimization,",
      "citeRegEx" : "Mockus,? \\Q1994\\E",
      "shortCiteRegEx" : "Mockus",
      "year" : 1994
    }, {
      "title" : "Benchmarking derivative-free optimization algorithms",
      "author" : [ "J.J. More", "S.M. Wild" ],
      "venue" : "SIAM J. Optim,",
      "citeRegEx" : "More and Wild,? \\Q2009\\E",
      "shortCiteRegEx" : "More and Wild",
      "year" : 2009
    }, {
      "title" : "Least Frobenius norm updating of quadratic models that satisfy interpolation conditions",
      "author" : [ "M.J.D. Powell" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Powell,? \\Q2004\\E",
      "shortCiteRegEx" : "Powell",
      "year" : 2004
    }, {
      "title" : "Margin-based ranking and an equivalence between adaboost and rankboost",
      "author" : [ "C. Rudin", "R.E. Schapire" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Rudin and Schapire,? \\Q2009\\E",
      "shortCiteRegEx" : "Rudin and Schapire",
      "year" : 2009
    }, {
      "title" : "Self-correcting geometry in model-based algorithms for derivative-free unconstrained optimization",
      "author" : [ "K. Scheinberg", "Toint", "Ph. L" ],
      "venue" : "SIAM J. Optim,",
      "citeRegEx" : "Scheinberg et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Scheinberg et al\\.",
      "year" : 2010
    }, {
      "title" : "ASTRODF: A class of adaptive sampling trust-region algorithms for derivative-free simulation optimization",
      "author" : [ "S. Shashaani", "F.S. Hashemi", "R. Pasupathy" ],
      "venue" : null,
      "citeRegEx" : "Shashaani et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Shashaani et al\\.",
      "year" : 2015
    }, {
      "title" : "Practical bayesian optimization of machine learning algorithms",
      "author" : [ "J. Snoek", "H. Larochelle", "R.P. Adams" ],
      "venue" : "In Proc. of NIPS-12,",
      "citeRegEx" : "Snoek et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Snoek et al\\.",
      "year" : 2012
    }, {
      "title" : "Hinge rank loss and the area under the ROC curve",
      "author" : [ "H. Steck" ],
      "venue" : "In ECML, Lecture Notes in Computer Science,",
      "citeRegEx" : "Steck,? \\Q2007\\E",
      "shortCiteRegEx" : "Steck",
      "year" : 2007
    }, {
      "title" : "The multivariate normal distribution",
      "author" : [ "Y.L. Tong" ],
      "venue" : "Springer Series in Statistics,",
      "citeRegEx" : "Tong,? \\Q1990\\E",
      "shortCiteRegEx" : "Tong",
      "year" : 1990
    }, {
      "title" : "Optimizing classifier performance via approximation to the wilcoxon-mann-witney statistic",
      "author" : [ "L. Yan", "R. Dodier", "M.C. Mozer", "R. Wolniewicz" ],
      "venue" : "Proceedings of the Twentieth Intl. Conf. on Machine Learning,",
      "citeRegEx" : "Yan et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2003
    }, {
      "title" : "Online AUC maximization",
      "author" : [ "P. Zhao", "S.C.H. Hoi", "R. Jin", "T. Yang" ],
      "venue" : "In Proceedings of the 28th ICML,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "There are two relatively independent directions of research for black-box optimization–Bayesian Optimization (BO) (Mockus, 1994; Brochu et al., 2010), predominantly popular in the ML community, and derivative free optimization (DFO) (Conn et al.",
      "startOffset" : 114,
      "endOffset" : 149
    }, {
      "referenceID" : 5,
      "context" : "There are two relatively independent directions of research for black-box optimization–Bayesian Optimization (BO) (Mockus, 1994; Brochu et al., 2010), predominantly popular in the ML community, and derivative free optimization (DFO) (Conn et al.",
      "startOffset" : 114,
      "endOffset" : 149
    }, {
      "referenceID" : 9,
      "context" : ", 2010), predominantly popular in the ML community, and derivative free optimization (DFO) (Conn et al., 2009)–popular in the optimization community.",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 20,
      "context" : "Recently, the BO efficiency has been called into question in comparison with a simple random search (Li et al., 2016), whose iterations require nothing, but function evaluations.",
      "startOffset" : 100,
      "endOffset" : 117
    }, {
      "referenceID" : 3,
      "context" : "Various results has been reported in terms of comparing the AUC value as a performance measure of a classifier versus the usual prediction accuracy, that is the total percentage of misclassified examples (Bradley, 1997; Ferri et al., 2002; Brefeld & Scheffer, 2005; Lu et al., 2010).",
      "startOffset" : 204,
      "endOffset" : 282
    }, {
      "referenceID" : 12,
      "context" : "Various results has been reported in terms of comparing the AUC value as a performance measure of a classifier versus the usual prediction accuracy, that is the total percentage of misclassified examples (Bradley, 1997; Ferri et al., 2002; Brefeld & Scheffer, 2005; Lu et al., 2010).",
      "startOffset" : 204,
      "endOffset" : 282
    }, {
      "referenceID" : 21,
      "context" : "Various results has been reported in terms of comparing the AUC value as a performance measure of a classifier versus the usual prediction accuracy, that is the total percentage of misclassified examples (Bradley, 1997; Ferri et al., 2002; Brefeld & Scheffer, 2005; Lu et al., 2010).",
      "startOffset" : 204,
      "endOffset" : 282
    }, {
      "referenceID" : 3,
      "context" : "In particular, in (Bradley, 1997), AUC is used to evaluate the performance of some ML algorithms such as decision trees, neural networks, and some statistical methods, where, experimentally, it is shown that AUC has advantages over the accuracy.",
      "startOffset" : 18,
      "endOffset" : 33
    }, {
      "referenceID" : 33,
      "context" : "In (Yan et al., 2003; Herschtal & Raskutti, 2004; Calders & Jaroszewicz, 2007), various smooth nonconvex approximation of AUC has been optimized by the gradient descent method.",
      "startOffset" : 3,
      "endOffset" : 78
    }, {
      "referenceID" : 17,
      "context" : "Alternatively, a ranking loss, which is defined as 1−AUC value, is minimized approximately, by replacing it with the pairwise margin loss, such as exponential loss, logistic loss, and hinge loss (Joachims, 2006; Steck, 2007; Rudin & Schapire, 2009; Zhao et al., 2011), which results in a convex problem.",
      "startOffset" : 195,
      "endOffset" : 267
    }, {
      "referenceID" : 31,
      "context" : "Alternatively, a ranking loss, which is defined as 1−AUC value, is minimized approximately, by replacing it with the pairwise margin loss, such as exponential loss, logistic loss, and hinge loss (Joachims, 2006; Steck, 2007; Rudin & Schapire, 2009; Zhao et al., 2011), which results in a convex problem.",
      "startOffset" : 195,
      "endOffset" : 267
    }, {
      "referenceID" : 34,
      "context" : "Alternatively, a ranking loss, which is defined as 1−AUC value, is minimized approximately, by replacing it with the pairwise margin loss, such as exponential loss, logistic loss, and hinge loss (Joachims, 2006; Steck, 2007; Rudin & Schapire, 2009; Zhao et al., 2011), which results in a convex problem.",
      "startOffset" : 195,
      "endOffset" : 267
    }, {
      "referenceID" : 9,
      "context" : "In this work, we apply a variant of a model-based trust region derivative free method, called DFO-TR, (Conn et al., 2009) to directly maximize the AUC function over a set of linear classifiers, without using any hyperparameters.",
      "startOffset" : 102,
      "endOffset" : 121
    }, {
      "referenceID" : 24,
      "context" : "In terms of required number of objective function evaluations, Bayesian optimization methods are considered to be some of the most efficient techniques (Mockus, 1994; Jones et al., 1998; Brochu et al., 2010) for black-box problems of low effective dimensionality.",
      "startOffset" : 152,
      "endOffset" : 207
    }, {
      "referenceID" : 19,
      "context" : "In terms of required number of objective function evaluations, Bayesian optimization methods are considered to be some of the most efficient techniques (Mockus, 1994; Jones et al., 1998; Brochu et al., 2010) for black-box problems of low effective dimensionality.",
      "startOffset" : 152,
      "endOffset" : 207
    }, {
      "referenceID" : 5,
      "context" : "In terms of required number of objective function evaluations, Bayesian optimization methods are considered to be some of the most efficient techniques (Mockus, 1994; Jones et al., 1998; Brochu et al., 2010) for black-box problems of low effective dimensionality.",
      "startOffset" : 152,
      "endOffset" : 207
    }, {
      "referenceID" : 5,
      "context" : "In theory, Bayesian optimizationmethods seek global optimal solution, due to their sampling schemes, which trade-off between exploitation and exploration (Brochu et al., 2010; Eggensperger et al., 2013).",
      "startOffset" : 154,
      "endOffset" : 202
    }, {
      "referenceID" : 11,
      "context" : "In theory, Bayesian optimizationmethods seek global optimal solution, due to their sampling schemes, which trade-off between exploitation and exploration (Brochu et al., 2010; Eggensperger et al., 2013).",
      "startOffset" : 154,
      "endOffset" : 202
    }, {
      "referenceID" : 5,
      "context" : "Then, by using this model, the subsequent configurations of the parameters will be selected (Brochu et al., 2010) by optimizing an acquisition function derived from the model.",
      "startOffset" : 92,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : "We compare DFO-TR with SMAC (Hutter et al., 2011), SPEARMINT (Snoek et al.",
      "startOffset" : 28,
      "endOffset" : 49
    }, {
      "referenceID" : 30,
      "context" : ", 2011), SPEARMINT (Snoek et al., 2012), and TPE (Bergstra et al.",
      "startOffset" : 19,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : ", 2012), and TPE (Bergstra et al., 2011), which are popular Bayesian optimization algorithms based on different types of model.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 7,
      "context" : "We also discuss the convergence properties of DFO-TR and its stochastic variant (Chen et al., 2015), and argue that these results apply to optimizing expected AUC value, when it is a smooth function.",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 8,
      "context" : "Model-based trust region DFO methods (Conn et al., 1997; Powell, 2004) have been proposed for a class of optimization problems of the formminw∈Rd f(w), when computing the gradient and the Hessian of f(w) is not possible, either because it is unknown or because the computable gradient is too noisy to be of use.",
      "startOffset" : 37,
      "endOffset" : 70
    }, {
      "referenceID" : 26,
      "context" : "Model-based trust region DFO methods (Conn et al., 1997; Powell, 2004) have been proposed for a class of optimization problems of the formminw∈Rd f(w), when computing the gradient and the Hessian of f(w) is not possible, either because it is unknown or because the computable gradient is too noisy to be of use.",
      "startOffset" : 37,
      "endOffset" : 70
    }, {
      "referenceID" : 9,
      "context" : "If the function is smooth, then such information is usually constructed by building an interpolation or regression model of f(w) using a set of points for which function value is (approximately known) (Conn et al., 2009).",
      "startOffset" : 201,
      "endOffset" : 220
    }, {
      "referenceID" : 9,
      "context" : "Extensive convergence analysis of these methods over smooth deterministic functions have been summarized in (Conn et al., 2009).",
      "startOffset" : 108,
      "endOffset" : 127
    }, {
      "referenceID" : 29,
      "context" : "Recently, several variants of trust region methods have been proposed to solve stochastic optimization problem minw Eξ[f(w, ξ)], where f(w, ξ) is a stochastic function of a deterministic vector w ∈ R and a random variable ξ (Shashaani et al., 2015; Billups & Larson, 2016; Chen et al., 2015).",
      "startOffset" : 224,
      "endOffset" : 291
    }, {
      "referenceID" : 7,
      "context" : "Recently, several variants of trust region methods have been proposed to solve stochastic optimization problem minw Eξ[f(w, ξ)], where f(w, ξ) is a stochastic function of a deterministic vector w ∈ R and a random variable ξ (Shashaani et al., 2015; Billups & Larson, 2016; Chen et al., 2015).",
      "startOffset" : 224,
      "endOffset" : 291
    }, {
      "referenceID" : 7,
      "context" : "In particular, in (Chen et al., 2015), a trust region based stochastic method, referred to STORM (STochastic Optimization with Random Models), is introduced and shown to converge, almost surely, to a stationary point ofEξ[f(w, ξ)], under the assumption thatEξ[f(w, ξ)] is smooth.",
      "startOffset" : 18,
      "endOffset" : 37
    }, {
      "referenceID" : 2,
      "context" : "Moreover, in recent work (Blanchet et al., 2016) a convergence rate of this method has been analyzed.",
      "startOffset" : 25,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "For general convergent framework of STORM, we refer the reader to (Chen et al., 2015).",
      "startOffset" : 66,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "When applied to deterministic smooth functions, this algorithm converges to a local solution (Conn et al., 2009), but here we apply it to a nonsooth function which can be viewed as a noisy version of a smooth function (as argued in the next section).",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 32,
      "context" : "Proof 1 The proof can be found in (Tong, 1990).",
      "startOffset" : 34,
      "endOffset" : 46
    }, {
      "referenceID" : 32,
      "context" : "Proof 2 The proof can be found in (Tong, 1990).",
      "startOffset" : 34,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "For example, the algorithm in (Brochu et al., 2010) uses deterministic derivative free optimizer DIRECT (Jones et al.",
      "startOffset" : 30,
      "endOffset" : 51
    }, {
      "referenceID" : 18,
      "context" : ", 2010) uses deterministic derivative free optimizer DIRECT (Jones et al., 1993) to maximize the acquisition function.",
      "startOffset" : 60,
      "endOffset" : 80
    }, {
      "referenceID" : 7,
      "context" : "In order to further improve efficiency of DFO-TR, we observe that STORM framework and theory (Chen et al., 2015) suggests that noisy function evaluations do not need to be accurate far away from the optimal solution.",
      "startOffset" : 93,
      "endOffset" : 112
    } ],
    "year" : 2017,
    "abstractText" : "In this work, we utilize a Trust Region based Derivative Free Optimization (DFO-TR) method to directly maximize the Area Under Receiver Operating Characteristic Curve (AUC), which is a nonsmooth, noisy function. We show that AUC is a smooth function, in expectation, if the distributions of the positive and negative data points obey a jointly normal distribution. The practical performance of this algorithm is compared to three prominent Bayesian optimization methods and random search. The presented numerical results show that DFO-TR surpasses Bayesian optimization and random search on various blackbox optimization problem, such as maximizing AUC and hyperparameter tuning.",
    "creator" : "LaTeX with hyperref package"
  }
}