{
  "name" : "1703.07438.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The NLTK FrameNet API: Designing for Discoverability with a Rich Linguistic Resource",
    "authors" : [ "Nathan Schneider", "Chuck Wooters" ],
    "emails" : [ "nathan.schneider@georgetown.edu", "wooters@semanticmachines.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "For over a decade, the Berkeley FrameNet (henceforth, simply “FrameNet”) project (Baker et al., 1998) has been documenting the vocabulary of contemporary English with respect to the theory of frame semantics (Fillmore, 1982). A freely available, linguistically-rich resource, FrameNet now covers over 1,000 semantic frames, 10,000 lexical senses, and 100,000 lexical annotations in sentences drawn from corpora. The resource has formed a basis for much research in natural language processing—most notably, a tradition of semantic role labeling that continues to this day (Gildea and Jurafsky, 2002; Baker et al., 2007; Das et al., 2014; FitzGerald et al., 2015; Roth and Lapata, 2015, inter alia).\nDespite the importance of FrameNet, computational users are often frustrated by the complexity of its custom XML format. Whereas much of the resource is browsable on the web (http://framenet. icsi.berkeley.edu/), certain details of the linguistic descriptions and annotations languish in obscurity as they are not exposed by the HTML views of the data.1 The few open source APIs for\n1For example, one of the authors was recently asked by a FrameNet user whether frame-to-frame relations include mappings between individual frame elements. They do, but the user’s confusion is understandable because these mappings are not exposed in the HTML frame definitions on the website. (They can be explored visually via the FrameGrapher tool on the website, https://framenet.icsi.\nreading FrameNet data are now antiquated, and none has been widely adopted.2\nWe describe a new, user-friendly Python API for accessing FrameNet data. The API is included within recent releases of the popular NLTK suite (Bird et al., 2009), and provides access to nearly all the information in the FrameNet release."
    }, {
      "heading" : "2 Installation",
      "text" : "Instructions for installing NLTK are found at nltk.org. NLTK is cross-platform and supports Python 2.7 as well as Python 3.x environments. It is bundled in the Anaconda and Enthought Canopy Python distributions for data scientists.3\nIn a working NLTK installation (version 3.2.2 or later), one merely has to invoke a method to download the FrameNet data:4,5\n>>> import nltk >>> nltk.download('framenet_v17')\nberkeley.edu/fndrupal/FrameGrapher, if the user knows to look there.) In the interest of space, our API does not show them in the frame display, but they can be accessed via an individual frame relation object or with the fe_relations() method, §4.4.\n2We are aware of: • github.com/dasmith/FrameNet-python (Python) • nlp.stanford.edu/software/framenet.shtml (Java) • github.com/FabianFriedrich/Text2Process/tree/ master/src/de/saar/coli/salsa/reiter/framenet (Java) • github.com/GrammaticalFramework/gf-contrib/tree/ master/framenet (Grammatical Framework) None of these has been updated in the past few years, so they are likely not fully compatible with the latest data release.\n3https://www.continuum.io/downloads, https://store.enthought.com/downloads\n4>>> is the standard Python interactive prompt, generally invoked by typing python on the command line. Python code can then be entered at the prompt, where it is evaluated/executed. Henceforth, examples will assume familiarity with the basics of Python.\n5By default, the 855MB data release is installed under the user’s home directory, but an alternate location can be specified: see http://www.nltk.org/data.html.\nar X\niv :1\n70 3.\n07 43\n8v 2\n[ cs\n.C L\n] 2\n2 Ju\nl 2 01\n7\nSubsequently, the framenet module is loaded as follows (with alias fn for convenience): >>> from nltk.corpus import framenet as fn"
    }, {
      "heading" : "3 Overview of FrameNet",
      "text" : "FrameNet is organized around conceptual structures known as frames. A semantic frame represents a scene—a kind of event, state, or other scenario which may be universal or culturally-specific, and domain-general or domain-specific. The frame defines participant roles or frame elements (FEs), whose relationships forms the conceptual background required to understand (certain senses of) vocabulary items. Oft-cited examples by Fillmore include: • Verbs such as buy, sell, and pay, and nouns such\nas buyer, seller, price, and purchase, are all defined with respect to a commercial transaction scene (frame). FEs that are central to this frame— they may or may not be mentioned explicitly in a text with one of the aforementioned lexical items—are the Buyer, the Seller, the Goods being sold by the Seller, and the Money given as payment in exchange by the Buyer. • The concept of REVENGE—lexicalized in vocabulary items such as revenge, avenge, avenger, retaliate, payback, and get even—fundamentally presupposes an Injury that an Offender has inflicted upon an Injured_party, for which an Avenger (who may or may not be the same as the Injured_party) seeks to exact some Punishment on the Offender. • A hypotenuse presupposes a geometrical notion of right triangle, while a pedestrian presupposes a street with both vehicular and nonvehicular traffic. (Neither frame is currently present in FrameNet.)\nThe FEs in a frame are formally listed alongside an English description of their function within the frame. Frames are organized in a network, including an inheritance hierarchy (e.g., REVENGE is a special case of an EVENT) and other kinds of frameto-frame relations.\nVocabulary items listed within a frame are called lexical units (LUs). FrameNet’s inventory of LUs includes both content and function words. Formally, an LU links a lemma with a frame.6\n6The lemma name incorporates a part-of-speech tag. The lemma may consist of a single word, such as surrender.v, or multiple words, such as give up.v.\nIn a text, a token of an LU is said to evoke the frame. Sentences are annotated with respect to frame-evoking tokens and their FE spans. Thus:\n[Snape]Injured_party ’s revenge [on Harry]Offender labels overt mentions of participants in the REVENGE frame.\nThe reader is referred to (Fillmore and Baker, 2009) for a contemporary introduction to the resource and the theory of frame semantics upon which it is based. Extensive linguistic details are provided in (Ruppenhofer et al., 2016)."
    }, {
      "heading" : "4 API Overview",
      "text" : ""
    }, {
      "heading" : "4.1 Design Principles",
      "text" : "The API is designed with the following goals in mind: Simplicity. It should be easy to access important objects in the database (primarily frames, lexical units, and annotations), whether by iterating over all entries or searching for particular ones. To avoid cluttering the API with too many methods, other information in the database should be reachable via object attributes. Calling the API’s help() method prints a summary of the main methods for accessing information in the database. Discoverability. Many of the details of the database are complex. The API makes it easy to browse what is in database objects via the Python interactive prompt. The main way it achieves this is with pretty-printed displays of the objects, such as the frame display in figure 1 (see §4.3). The display makes it clear how to access attributes of the object that a novice user of FrameNet might not have known about.\nIn our view, this approach sets this API apart from others. Some of the other NLTK APIs for complex structured data make it difficult to browse the structure without consulting documentation. On-demand loading. The database is stored in thousands of XML files, including files indexing the lists of frames, frame relations, LUs, and full-text documents, plus individual files for all frames, LUs, and full-text documents. Unzipped, the FrameNet 1.7 release is 855 MB. Loading all of these files—particularly the corpus annotations—is slow and memory-intensive, costs which are unnecessary for many purposes. Therefore, the API is carefully designed with lazy data structures to load XML files only as needed. Once loaded, all data is cached in memory for fast subsequent access."
    }, {
      "heading" : "4.2 Lexicon Access Methods",
      "text" : "The main methods for looking up information in the lexicon are:\nframes(name) frame(nameOrId)\nlus(name, frame) lu(id)\nfes(name, frame)\nThe methods with plural names (left) are for searching the lexicon by regular expression pattern to be matched against the entry name. In addition (or instead), lus() and fes() allow for the results to be restricted to a particular frame. The result is a list with 0 or more elements. If no arguments are provided, all entries in the lexicon are returned.\nAn example of a search by frame name pattern:7\n>>> fn.frames('(?i)creat')\n7(?i) makes the pattern case-insensitive.\n[<frame ID=268 name=Cooking_creation>, <frame ID=1658 name=Create_physical_artwork>, ...]\nSimilarly, a search by LU name pattern—note that the .v suffix is used for all verbal LUs:\n>>> fn.lus(r'.+en\\.v') [<lu ID=5331 name=awaken.v>, <lu ID=7544 name=betoken.v>, ...]\nThe frame() and lu() methods are for retrieving a single known entry by its name or ID. Attempting to retrieve a nonexistent entry triggers an exception of type FramenetError.\nTwo additional methods are available for frame lookup: frame_ids_and_names(name) to get a mapping from frame IDs to names, and frames_by_lemma(name) to get all frames with some LU matching the given name pattern."
    }, {
      "heading" : "4.3 Database Objects",
      "text" : "All structured objects in the database—frames, LUs, FEs, etc.—are loaded as AttrDict data structures. Each AttrDict instance is a mapping from string keys to values, which can be strings, numbers, or structured objects. AttrDict is so called because it allows keys to be accessed as attributes: >>> f = fn.frame('Revenge') >>> f.keys() dict_keys(['cBy', 'cDate', 'name', 'ID', '_type', 'definition', 'definitionMarkup', 'frameRelations', 'FE', 'FEcoreSets', 'lexUnit', 'semTypes', 'URL']) >>> f.name 'Revenge' >>> f.ID 347\nFor the most important kinds of structured objects, the API specifies textual displays that organize the object’s contents in a human-readable fashion. Figure 1 shows the display for the REVENGE frame, which would be printed by entering fn.frame('Revenge') at the interactive prompt. The display gives attribute names in square brackets; e.g., lexUnit, which is a mapping from LU names to objects. Thus, after the code listing in the previous paragraph, f.lexUnit['revenge.n'] would access to one of the LU objects in the frame, which in turn\nhas its own attributes and textual display."
    }, {
      "heading" : "4.4 Advanced Lexicon Access",
      "text" : "Frame relations. The inventory of frames is organized in a semantic network via several kinds of frame-to-frame relations. For instance, the REVENGE frame is involved in one frame-toframe relation: it is related to the more general REWARDS_AND_PUNISHMENTS frame by Inheritance, as shown in the middle of figure 1. REWARDS_AND_PUNISHMENTS, in turn, is involved in Inheritance relations with other frames. Each frame-to-frame relation bundles mappings between corresponding FEs in the two frames.\nApart from the frameRelations attribute of frame objects, frame-to-frame relations can be browsed by the main method frame_relations(frame, frame2, type), where the optional arguments allow for filtering by one or both frames and the kind of relation. Within a frame relation object, pairwise FE relations are stored in the feRelations attribute. Main method fe_relations() provides direct access to links between FEs. The inventory of relation types, including Inheritance, Causative, Inchoative, Subframe, Perspective_on, and others, is available\nvia main method frame_relation_types().\nSemantic types. These provide additional semantic categorizations of FEs, frames, and LUs. For FEs, they mark selectional restrictions (e.g., f.FE['Avenger'].semType gives the Sentient type). Main method propagate_semtypes() propogates the FE semantic type labels marked explicitly to other FEs according to inference rules that follow the FE relations. This should be called prior to inspecting FE semtypes (it is not called by default because it takes several seconds to run).\nThe semantic types are database objects in their own right, and they are organized in their own inheritance hierarchy. Main method semtypes() returns all semantic types as a list; main method semtype() looks up a particular one by name, ID, or abbreviation; and main method semtype_inherits() checks whether two semantic types have a subtype– supertype relationship."
    }, {
      "heading" : "4.5 Corpus Access",
      "text" : "Frame-semantic annotations of sentences can be accessed via the exemplars and subCorpus attributes of an LU object, or via the following main methods:\nannotations(luname, exemplars, full_text) sents() exemplars(luname) ft_sents(docname)\ndoc(id) docs(name)\nannotations() returns a list of frame annotation sets. Each annotation set consists of a frameevoking target (token) within a sentence, the LU\nin the frame it evokes, its overt FE spans in the sentence, and the status of null-instatiated FEs.8 Optionally, the user may filter by LU name, or limit by the type of annotation (see next paragraph): exemplars and full_text both default to True. In the XML, the components of an annotation set are stored in several annotation layers: one (and sometimes more than one) layer of FEs, as well as additional layers for other syntactic information (including grammatical function and phrase type labels for each FE, and copular or support words relative to the frame-evoking target).\nAnnotation sets are organized by sentence. Corpus sentences appear in two kinds of annotation: exemplars() retrieves sentences with lexicographic annotation (where a single target has been selected for annotation to serve as an example of an LU); the optional argument allows for filtering the set of LUs. ft_sents() retrieves sentences from documents selected for full-text annotation (as many targets in the document as possible have been annotated); the optional argument allows for filtering by document name. sents() can be used to iterate over all sentences. Technically, each sentence object contains multiple annotation sets: the first is for sentence-level annotations, including the part-of-speech tagging and in some cases named entity labels; subsequent annotation sets are for\n8In frame semantics, core FEs that are not overt but are conceptually required by a frame are said to be implicit via null instantiation (Fillmore and Baker, 2009).\nframe annotations. As lexicographic annotations have only one frame annotation set, it is visualized in the sentence display: figure 2 shows the display for f.lexUnit['revenge.n'].exemplars[20]. Full-text annotations display target information only, allowing the user to drill down to see each annotation set, as in figure 3.\nSentences of full-text annotation can also be browsed by document using the doc() and docs() methods. The document display lists the sentences with numeric offsets."
    }, {
      "heading" : "5 Limitations and future work",
      "text" : "The main part of the Berkeley FrameNet data that the API currently does not support are valence patterns. For a given LU, the valence patterns summarize the FEs’ syntactic realizations across annotated tokens. They are displayed in each LU’s “Lexical Entry” report on the FrameNet website.\nWe intend to add support for valence patterns in future releases, along with more sophisticated querying/browsing capabilities for annotations, and better displays for syntactic information associated with FE annotations. Some of this functionality can be modeled after tools like FrameSQL (Sato, 2003) and Valencer (Kabbach and Ribeyre, 2016). In addition, it is worth investigating whether the API can be adapted for FrameNets in other languages, and to support cross-lingual mappings being added to 14 of these other FrameNets in the ongoing Multilingual FrameNet project.9"
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Collin Baker, Michael Ellsworth, and Miriam R. L. Petruck for helping us to understand the FrameNet annotation process and the technical aspects of the data, and for co-organizing the FrameNet tutorial in which an early version of the API was introduced (Baker et al., 2015). We also thank NLTK project leader Steven Bird, Mikhail Korborov, Pierpaolo Pantone, Rob Malouf, and anyone else who may have contributed to the release of the API by reviewing the code and reporting bugs; and anonymous reviewers for their suggestions."
    } ],
    "references" : [ {
      "title" : "Getting the roles right: using FrameNet in NLP",
      "author" : [ "Collin Baker", "Nathan Schneider", "Miriam R.L. Petruck", "Michael Ellsworth." ],
      "venue" : "Proc. of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorial Ab-",
      "citeRegEx" : "Baker et al\\.,? 2015",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 2015
    }, {
      "title" : "The Berkeley FrameNet project",
      "author" : [ "Collin F. Baker", "Charles J. Fillmore", "John B. Lowe." ],
      "venue" : "Proc. of COLING-ACL, pages 86–90, Montreal, Quebec, Canada.",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit",
      "author" : [ "Steven Bird", "Ewan Klein", "Edward Loper." ],
      "venue" : "O’Reilly Media, Inc., Sebastopol, CA.",
      "citeRegEx" : "Bird et al\\.,? 2009",
      "shortCiteRegEx" : "Bird et al\\.",
      "year" : 2009
    }, {
      "title" : "Frame-semantic parsing",
      "author" : [ "Dipanjan Das", "Desai Chen", "André F.T. Martins", "Nathan Schneider", "Noah A. Smith." ],
      "venue" : "Computational Linguistics, 40(1):9–56.",
      "citeRegEx" : "Das et al\\.,? 2014",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2014
    }, {
      "title" : "Frame Semantics",
      "author" : [ "Charles J. Fillmore." ],
      "venue" : "Linguistics in the Morning Calm, pages 111–137. Hanshin Publishing Co., Seoul, South Korea.",
      "citeRegEx" : "Fillmore.,? 1982",
      "shortCiteRegEx" : "Fillmore.",
      "year" : 1982
    }, {
      "title" : "A frames approach to semantic analysis",
      "author" : [ "Charles J. Fillmore", "Collin Baker." ],
      "venue" : "Bernd Heine and Heiko Narrog, editors, The Oxford Handbook of Linguistic Analysis, pages 791–816. Oxford University Press, Oxford, UK.",
      "citeRegEx" : "Fillmore and Baker.,? 2009",
      "shortCiteRegEx" : "Fillmore and Baker.",
      "year" : 2009
    }, {
      "title" : "Semantic role labeling with neural network factors",
      "author" : [ "Nicholas FitzGerald", "Oscar Täckström", "Kuzman Ganchev", "Dipanjan Das." ],
      "venue" : "Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 960–970, Lisbon, Por-",
      "citeRegEx" : "FitzGerald et al\\.,? 2015",
      "shortCiteRegEx" : "FitzGerald et al\\.",
      "year" : 2015
    }, {
      "title" : "Automatic labeling of semantic roles",
      "author" : [ "Daniel Gildea", "Daniel Jurafsky." ],
      "venue" : "Computational Linguistics, 28(3):245–288.",
      "citeRegEx" : "Gildea and Jurafsky.,? 2002",
      "shortCiteRegEx" : "Gildea and Jurafsky.",
      "year" : 2002
    }, {
      "title" : "Valencer: an API to query valence patterns in FrameNet",
      "author" : [ "Alexandre Kabbach", "Corentin Ribeyre." ],
      "venue" : "Proc. of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pages 156–160, Os-",
      "citeRegEx" : "Kabbach and Ribeyre.,? 2016",
      "shortCiteRegEx" : "Kabbach and Ribeyre.",
      "year" : 2016
    }, {
      "title" : "Contextaware frame-semantic role labeling",
      "author" : [ "Michael Roth", "Mirella Lapata." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 3:449–460.",
      "citeRegEx" : "Roth and Lapata.,? 2015",
      "shortCiteRegEx" : "Roth and Lapata.",
      "year" : 2015
    }, {
      "title" : "FrameNet II: extended theory and practice",
      "author" : [ "Josef Ruppenhofer", "Michael Ellsworth", "Miriam R.L. Petruck", "Christopher R. Johnson", "Collin F. Baker", "Jan Scheffczyk" ],
      "venue" : null,
      "citeRegEx" : "Ruppenhofer et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ruppenhofer et al\\.",
      "year" : 2016
    }, {
      "title" : "FrameSQL: A software tool for FrameNet",
      "author" : [ "Hiroaki Sato." ],
      "venue" : "Proc. of ASIALEX 2003, pages 251– 258, Tokyo, Japan.",
      "citeRegEx" : "Sato.,? 2003",
      "shortCiteRegEx" : "Sato.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "For over a decade, the Berkeley FrameNet (henceforth, simply “FrameNet”) project (Baker et al., 1998) has been documenting the vocabulary of contemporary English with respect to the theory of frame semantics (Fillmore, 1982).",
      "startOffset" : 81,
      "endOffset" : 101
    }, {
      "referenceID" : 4,
      "context" : ", 1998) has been documenting the vocabulary of contemporary English with respect to the theory of frame semantics (Fillmore, 1982).",
      "startOffset" : 114,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "The API is included within recent releases of the popular NLTK suite (Bird et al., 2009), and provides access to nearly all the information in the FrameNet release.",
      "startOffset" : 69,
      "endOffset" : 88
    }, {
      "referenceID" : 5,
      "context" : "The reader is referred to (Fillmore and Baker, 2009) for a contemporary introduction to the resource and the theory of frame semantics upon which it is based.",
      "startOffset" : 26,
      "endOffset" : 52
    }, {
      "referenceID" : 10,
      "context" : "Extensive linguistic details are provided in (Ruppenhofer et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "8In frame semantics, core FEs that are not overt but are conceptually required by a frame are said to be implicit via null instantiation (Fillmore and Baker, 2009).",
      "startOffset" : 137,
      "endOffset" : 163
    }, {
      "referenceID" : 11,
      "context" : "Some of this functionality can be modeled after tools like FrameSQL (Sato, 2003) and Valencer (Kabbach and Ribeyre, 2016).",
      "startOffset" : 68,
      "endOffset" : 80
    }, {
      "referenceID" : 8,
      "context" : "Some of this functionality can be modeled after tools like FrameSQL (Sato, 2003) and Valencer (Kabbach and Ribeyre, 2016).",
      "startOffset" : 94,
      "endOffset" : 121
    }, {
      "referenceID" : 0,
      "context" : "Petruck for helping us to understand the FrameNet annotation process and the technical aspects of the data, and for co-organizing the FrameNet tutorial in which an early version of the API was introduced (Baker et al., 2015).",
      "startOffset" : 204,
      "endOffset" : 224
    } ],
    "year" : 2017,
    "abstractText" : "A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.",
    "creator" : "LaTeX with hyperref package"
  }
}