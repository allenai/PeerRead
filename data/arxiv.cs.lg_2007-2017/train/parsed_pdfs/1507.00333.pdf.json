{
  "name" : "1507.00333.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Notes on Low-rank Matrix Factorization",
    "authors" : [ "Jie Yang" ],
    "emails" : [ "j.yang-3@tudelft.nl." ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 7.\n00 33\n3v 1\n[ cs\n.N A\n] 3\n0 Ju\nn 20\n15\nNotes on Low-rank Matrix Factorization\nJie Yang∗\nFaculty of EEMCS,\nDelft University of Technology,\nMekelweg 4, 2628 CD Delft, the Netherlands.\n∗ Email: j.yang-3@tudelft.nl.\nDedicated to Yuanyuan, Xiao Baobao and Tu Daye."
    }, {
      "heading" : "1 Introduction",
      "text" : "Low-rank matrix factorization (MF) is an important technique in data science. The key idea of MF is that there exists latent structures in the data, by uncovering which we could obtain a compressed representation of the data. By factorizing an original matrix to low-rank matrices, MF provides a unified method for dimesion reduction, clustering, and matrix completion.\nMF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.g., homophily in linked data [19]), thus suitable for various real-world problems; 4) many optimization methods such as (stochastic) gradient-based methods can be applied to find a good solution.\nIn this article we review several important variants of MF, including:\n• Basic MF,\n• Non-negative MF,\n• Orthogonal non-negative MF.\nAs can be seen from their names, non-negativeMF and orthogonal non-negative MF are variants of basic MF with non-negativity and/or orthogonality constraints. Such constraints are useful in specific senarios. In the first part of this article, we introduce, for each of these models, the application scenarios, the distinctive properties, and the optimizing method. Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19]. We will derive the updating rules, and prove the correctness and convergence. For reference, matrix operation and optimization can be referred to [2] and [1] respectively.\nBy properly adapting MF, we can go beyond the problem of clustering and matrix completion. In the second part of this article, we will extend MF to sparse matrix compeletion, enhance matrix compeletion using various regularization methods, and make use of MF for (semi-)supervised learning by introducing latent space reinforcement and transformation. We will see that MF is not only a useful model but also as a flexible framework that is applicable for various prediction problems."
    }, {
      "heading" : "2 Theory",
      "text" : "This section introduces the theory in low-rank matrix factorization. As introduced before, we will go through the following three MF variations: basic MF, non-negative MF, orthogonal non-negative MF."
    }, {
      "heading" : "2.1 Basic MF",
      "text" : "We start with the basic MF model, formulated as\nmin U,V\n‖X−UVT ‖+ L(U,V), (1)\nwhere X ∈ Rm×n is the data matrix to be approximated, and U ∈ Rm×k,V ∈ R\nn×k are two low-dimensional matrices (k ≪ min(m,n)). L(U,V) is a regularization part to avoid overfitting. Regularization is usually necessary in prediction for bias-variance trade-off [9]."
    }, {
      "heading" : "2.1.1 Gradient Descent Optimization",
      "text" : "We instantiate Eq. 1 as follows\nmin U,V\nO = ‖X−UVT ‖2F + α‖U‖ 2 F + β‖V‖ 2 F . (2)\nThe reason of using Frobenius Norm is that it has a Guassian noise interpretation, and that the objective function can be easily transformed to a matrix trace version:\nmin U,V\nO = Tr(XTX+VUTUVT − 2XTUVT )+αTr(UTU)+βTr(VTV). (3)\nHere the matrix calculation rule ‖A‖F = √\nTr(ATA) is used in the transformation. Note that trace has many good properties such as Tr(A) = Tr(AT ) and Tr(AB) = Tr(BA), which will be used in the following derivations.\nAccording to trace derivatives ∂Tr(AB)∂A = B T and the following rules:\n∂ATAB\n∂A = A(BT +B),\n∂AATB\n∂A = (BT +B)A\n(4)\n(see more in [2]), we have the following derivatives for U and V,\n∂O ∂U =\n∂Tr(VUTUVT − 2XTUVT ) + αTr(UTU)\n∂U\n= ∂Tr(UTUVTV − 2UVTXT ) + αTr(UTU)\n∂U\n= 2(UVTV −XV + αU),\n∂O ∂V =\n∂Tr(VUTUVT − 2XTUVT ) + βTr(VTV)\n∂V\n= ∂Tr(VTVUTU− 2VTXTU) + βTr(VTV)\n∂V\n= 2(VUTU−XTU+ βV).\n(5)\nUsing these two derivatives, we can alternatively update U and V in each iteration of gradient descent algorithm.\nNote that the derivation can also be performed elementarily for each entry in matrix U,V – this is, in fact, the original definition of matrix calculus. Such element-wise derivation is especially useful in stochastic optimization. We will touch this in a brief discussion of different algorithm schemes next."
    }, {
      "heading" : "2.1.2 Algorithm Schemes in CF and Others",
      "text" : "For collaborative filtering, usually we take one subset of rated entries in X as training set, and the rest rated entries as validation set. Detailed algorithm can be find in [18]. An important implementation strategy is that, for each rated entry in the training set, we update an entire row of U and an entire column of VT , as the whole row or column is involved in approximating the rated entry. Same updating mechanism could be applied in stochastic algorithm.\nIn the meanwhile, similarly to stochastic algorithm, this type of updating does not fully utilize the data matrix in each updating iteration. The reason is that, not only an entire row of U ( and a column of VT ) is involved in a single entry in data matrix X, but also that a row of U (and a column of VT ) influences an entire row (column) of X. Therefore for faster convergence, we recommend to update the matrix U and V by fully using data matrix X.\nAs the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19]. Detailed algorithm is similar to the one in [19]. Within any of these matrices, updating should be performed simultaneously as in all gradient-based methods. Note that, we still need to choose a small learning rate to ensure that the objective function is monotonically decreasing. Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections."
    }, {
      "heading" : "2.2 Non-negative MF",
      "text" : "Non-negativeMF [13] seeks to approximate data matrixXwith low-dimensional matrices U,V whose entries are all non-negative, i.e., U,V ≥ 0. The new problem becomes:\nmin U,V\nO = ‖X−UVT ‖2F + α‖U‖ 2 F + β‖V‖ 2 F\ns.t. U ≥ 0,V ≥ 0. (6)\nNon-negativity constaint is originated from parts-of-whole interpretation [13]. As we can think of, many real-world data are non-negative, such as link strength, favorite strength, etc. Non-negative MF may uncover the important parts, which sometimes can not be achieved by non-constrained MF [13].\nApart from the advantage of uncovering parts, non-negative MF has its own computational advantage: there is a relatively fixed method to find a learning\nrate larger than common gradient-based methods. To illustrate this, we will first derive the updating rule for Eq. 6 as an example, then show the general approach for proving the convergence of updating rules derived from the relatively fixed method."
    }, {
      "heading" : "2.2.1 Updating Rule Derivation",
      "text" : "The basic idea is using KKT complementary slackness conditions to enforce the non-negativity constraint. Based on this, we can directly obtain updating rules.\nThe Lagrangian function of Eq. 6 is\nL = ‖X−UVT ‖2F + α‖U‖ 2 F + β‖V‖ 2 F − Tr(Λ1U T )− Tr(Λ2V T ). (7)\nWe have the following KKT condition,\nΛ1 ◦U = 0, Λ2 ◦V = 0, (8)\nwhere ◦ denotes the Hadamard product. We then have\n∂L ∂U =\n∂Tr(VUTUVT − 2XTUVT ) + αTr(UTU)− Tr(Λ1U T )\n∂U\n= 2(UVTV −XV + αU)− Λ1,\n∂L ∂V =\n∂Tr(VUTUVT − 2XTUVT ) + βTr(VTV)− Tr(Λ2V T )\n∂V\n= 2(VUTU−XTU+ βV) − Λ2.\n(9)\nLet ∂L∂U = 0 and ∂L ∂V = 0 as another KKT condition, we have\nΛ1 = 2(UV TV −XV + αU), Λ2 = 2(VU TU−XTU+ βV).\n(10)\nNow we combine Eq. 8 and Eq. 10, we have\n(UVTV −XV + αU) ◦U = 0,\n(VUTU−XTU+ βV) ◦V = 0. (11)\nfrom which, we have the final updating rules,\nU(i, j) ← U(i, j)\n√\n(XV)(i, j)\n(UVTV + αU)(i, j) ,\nV(i, j) ← V(i, j)\n√\n(XTU)(i, j)\n(VUTU+ βV)(i, j) .\n(12)\nDetailed algorithm using these rules is similar to the one in [19]. We can see that, instead of manually setting small learning rates Λ’s, Eq. 12 directly offer updating rules that can usually lead to faster convergence.\nThe correctness of these updating rules is straightforward to find out. Taking U as an example, from Eq. 12 we have either U = 0 or UVTV−XV+αU = 0, which combined together, exactly equal to Eq. 11. The convergence, however, is somehow more difficult to be proved. We leave this to the next subsubsection."
    }, {
      "heading" : "2.2.2 Proof of Convergence",
      "text" : "We prove the convergence of the updating rules in Eq. 12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4]. Our proof is mainly based on [5, 4], although the objective function Eq. 6 is slightly different.\nAn auxiliary function G(U,Ut) of function L(U) is a function that satisfies\nG(U,U) = L(U), G(U,Ut) ≥ L(U). (13)\nThen, if we take Ut+1 such that\nUt+1 = arg min U G(U,Ut), (14)\nwe have L(Ut+1) ≤ G(Ut+1,Ut) ≤ G(Ut,Ut ≤ L(Ut)). (15)\nThis proves that L(U) is monotonically decreasing. Turn back to our problem, we need to take two steps using auxiliary function to prove the convergence of updating rules: 1) find an appropriate auxiliary function, and 2) find the global minima of the auxiliary function. As a remark, the auxiliary function approach in principle is similar to Expectation-Maximization approach that is widely used in statistical inference. Now let us complete the proof by taking the above two steps.\nStep 1 - Finding an appropriate auxiliary function needs to take advantage of two inequalities,\nz ≥ 1 + logz, ∀z > 0, (16)\nm ∑\ni=1\nk ∑\nj=1\n(AS′B)(i, j)S(i, j)2\nS′(i, j) ≥ Tr(STASB),\n∀A ∈ Rm×m+ ,B ∈ R k×k + ,S ′ ∈ Rm×k+ ,S ∈ R m×k + . (17)\nThe proof for Eq. 17 can be found in [5] (Proposition 6). After removing irrelevant terms, the objective function Eq. 6 in terms of U\ncan be written as\nTr(VUTUVT − 2XTUVT ) + αTr(UTU)\n=Tr(UTUVTV − 2UTXV) + αTr(UTU) (18)\nWe now propose an auxiliary function\nG(U,Ut) = −2 ∑\ni,j\n(XV)(i, j)Ut(i, j)(1 + log U(i, j)\nUt(i, j) )\n+ ∑\ni,j\n(UtVTV)(i, j)U(i, j)2\nUt(i, j) + α\n∑\ni,j\nUt(i, j)U(i, j)2\nUt(i, j) .\n(19)\nCombining the two inequalities Eq. 16, 17, it is straightforward to see that Eq. 19 is a legal auxiliary function for Eq. 18, i.e., the two conditions in Eq. 13 are satisfied. Now we procceed to find Ut+1 that satisfies condition Eq. 14.\nStep 2 - Finding Ut+1 can be achieved by obtaining the global minima of Eq. 19. First, we have\n∂G(U,Ut)\n∂U(i, j) = −2(XV)(i, j)\nUt(i, j) U(i, j) + 2 (UtVTV)(i, j)U(i, j) Ut(i, j) + 2αU(i, j).\n(20)\nLet ∂G(U,U t)\n∂U(i,j) = 0 we have\n(XV)(i, j) Ut(i, j)\nUt+1(i, j) = (\n(UtVTV)(i, j)\nUt(i, j) + α)Ut+1(i, j), (21)\nfrom which we directly have\nUt+1(i, j) = Ut(i, j)\n√\n(XV)(i, j)\n(UtVTV + αUt)(i, j) , (22)\nwhich is exactly the updating rule for U in Eq. 12. Similar result can be obtained for V.\nGeneral observation If we go over the entire derivation process, by comparing Eq. 22 and Eq. 11, we can observe that the only thing that matters for the final updating rules is the signs of the terms in Eq. 11."
    }, {
      "heading" : "2.3 Orthogonal Non-negative MF",
      "text" : "Orthogonality is another important constraint to MF. First of all, we formulate the problem as\nmin U,V\nO = ‖X−UVT ‖2F\ns.t. U,V ≥ 0,UTU = I,VTV = I. (23)\nNote that here we do not add regularization due to the orthogonality constraint.\nIt is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V′ is an indication matrix with V′(i, j) = 0 if xi belongs to the j th (1 ≤ j ≤ k) cluster. Here V = V′(V′ T V′)−1/2, i.e., V is a normalized version of V′: V′ is a constant scaling of corresponding row of V, and ‖V(:, j)‖22 = 1."
    }, {
      "heading" : "2.3.1 3-factor MF vs. 2-factor MF",
      "text" : "We call Eq. 23 1-sided 2-factor orthogonal non-negative MF, as only one factorized matrix needs to be orthogonal, and there are in total two factorized matrices. It is recommended that, to simultaneously cluster rows and columns in X, we need 3-factor bi-orthogonal non-negative MF, i.e., both U and V being orthogonal:\nmin U,H,V\nO = ‖X−UHVT ‖2F\ns.t. U,H,V ≥ 0,UTU = I,VTV = I. (24)\nIt is proved that, compared to 3-factor bi-orthogonal non-negative MF, 2- factor bi-orthogonal non-negative MF is too restrictive, and will lead to poor approximation [5].\n3-factor bi-orthogonal non-negative MF is useful in document-word clustering [5], outperforming K-means (i.e., 1-sided 2-factor orthogonal non-negative MF). It has been applied for tasks such as sentiment analysis [10]."
    }, {
      "heading" : "2.3.2 Updating Rule Derivation",
      "text" : "We now derive updating rules for Eq. 24, as we did before for non-negative MF.\nThe Lagrangian function for Eq. 24 is\nL =‖X−UHVT ‖2F − Tr(ΛUU T )− Tr(ΛHH T )− Tr(ΛV V T )\n+Tr(ΓU (U TU− I)) + Tr(ΓV (V TV − I)) (25)\nWe then compute the updating rules for H,U,V sequentially. Computation of H\n∂L ∂H =\n∂Tr(VHTUTUHVT − 2XVHTUT )− Tr(ΛHH T )\n∂H\n= 2UTUHVTV − 2UTXV − ΛH ,\n(26)\nWe have the following KKT conditions,\n∂L ∂H = 0\nΛH ◦H = 0. (27)\nCombining the above three equations, we have\n(UTUHVTV −UTXV) ◦H = 0. (28)\nTherefore we have the following updating rule for H,\nH(i, j) ← H(i, j)\n√\n(UTXV)(i, j)\n(UTUHVTV)(i, j) . (29)\nNote that UTU 6= I during the optimizing process. Computation of U,V Due to the orthogonality constraint, obtaining the updating rules for U,V needs to eliminate both Λ and Γ in the final updating rules. This will need the following equality,\nUTΛU = 0 ⇐ ΛU ◦U = 0 (30)\nThe latter will automatically be satisifed according to KKT conditions as we will see below.\n∂L ∂U =\n∂Tr(VHTUTUHVT − 2XVHTUT )− Tr(ΛUU T ) + Tr(ΓU (U TU− I))\n∂U\n= 2UHVTVHT − 2XVHT − ΛU + 2UΓU ,\n(31)\nWe have the following KKT conditions,\n∂L ∂U = 0\nΛU ◦U = 0. (32)\nCombining the above three equations we have\n(UHVTVHT −XVHT +UΓU ) ◦U = 0 (33)\nand\nΓU = U TXVHT −HVTVHT . (34)\nNote that here we can have UTU = I as we only want an expression for ΓU . Further note that for Λ we have the constraint Λ > 0 (according to KKT condition) while for Γ we do not have such constraint. Therefore we need to split Γ into two parts,\nΓU = Γ + U − Γ − U Γ+U = (|ΓU |+ ΓU )/2 Γ−U = (|ΓU | − ΓU )/2.\n(35)\nUsing this division we rewrite Eq. 33, we then have\n(UHVTVHT −XVHT +UΓ+U −UΓ − U ) ◦ ΛU = 0. (36)\nTherefore the final updating rule for U is\nU(i, j) ← U(i, j)\n√\n(XVHT +UΓ−U )(i, j)\n(UHVTVHT +UΓ+U )(i, j) . (37)\nwhere Γ+U and Γ −\nU is defined in Eq. 34 and 35. If we go over the same process again for V, we have the following updating\nrules, Therefore the final updating rule for U is\nV(i, j) ← V(i, j)\n√\n(XTUH+VΓ−V )(i, j)\n(VHTUTUH+VΓ+V )(i, j) . (38)\nwhere Γ+V ,Γ −\nV are defined similarly as in Eq. 35 (replace U with V), and ΓV is defined as\nΓV = V TXTUH+HTUTUH. (39)\nChoice of 2/3-factor MF How do we choose between 2-factor or 3-factor MF in real-world applications? A general principle is that: if we only need to place regularizations on one latent matrix, i.e. either U or V, then we can use 2-factorMF; if both U and V are to be regularized, either explictly or implictly, 3-factor MF might be a better choice."
    }, {
      "heading" : "3 Adapatations and Applications",
      "text" : "MF has been used for a wide range of applications in social computing, including collaborative filtering (CF), link prediction (LP), sentiment analysis, etc. It can not only provide as a single model for matrix completeion or clutering, but also as a framework for solving almost all categories of prediction problems.\nIn this part we will extend MF to highly sparse cases. For the cases in which we have additional data, e.g. link data between users (in CF, or addtional links in LP) or description data of users and items, we can incorporate different regularization techniques to enhace the matrix completion performance. Moreover, by properly manipulating latent factors derived from MF, we can adapt MF to (semi-)supervised learning."
    }, {
      "heading" : "3.1 Sparse Matrix Completion",
      "text" : "Here we address the problem of using MF for collborative filtering, link prediction and clustering. We start with a basic assumption, which makes the\npreviously introduced models unsuitable. This basic assumption is: high portion of the data is missing, i.e. data matrix is incomplete. Such assumption is very common in real-world cases [12].\nThe problem is solved by modeling directly the observed data. Eq. 1 is modified as follows:\nmin U,V\nO = ‖O ◦ (X−UV T )‖2F + α‖U‖ 2 F + β‖V‖ 2 F , (40)\nin which O poses constraints on only these observed data entries, i.e. O(i, j) = 1 if entry (i, j) is observed, and O(i, j) = 0 otherwise.\nIn this case, the objective function is transformed as follows:\nmin U,V\nO = Tr((OT ◦XT )(O ◦X) + (OT ◦VUT )(O ◦UVT )\n− 2(OT ◦XT )(O ◦UVT )) + αTr(UTU) + βTr(VTV). (41)\nAnd the gradients become:\n∂O ∂U =\n∂Tr((OT ◦VUT )(O ◦UVT )− 2(OT ◦XT )(O ◦UVT )) + αTr(UTU)\n∂U\n= ∂Tr(UT (O ◦O ◦UVT )V − 2(OT ◦OT ◦XT )UVT ) + αTr(UTU)\n∂U\n= 2((O ◦O ◦UVT )V − (O ◦O ◦X)V + αU),\n∂O ∂V = 2((OT ◦OT ◦VUT )U− (OT ◦OT ◦XT )U+ βV).\n(42)\nIn the derivation above we use the following rule of Hadamard product:\n(OT ◦AT )(O ◦A) = AT (O ◦O ◦A). (43)\nThe upodating rules for non-negative MF and orthogonal non-negative MF is straightforward: the methods of getting Λ,Γ are exactly the same as what we did in Theory Section. For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively."
    }, {
      "heading" : "3.1.1 Calculating Memory Occupation",
      "text" : "Note that the updating rules above are again purely matrix-wise – this is to be consistent with the style of this article. In matrix completion, however, sometimes the size of the data matrix is bigger than memory size, making stochasitc gradient descent algorithm more suitable than the matrix-wise method.\nThe question here is, how do we calculate the size of a matrix to see if it fits to memory. Here is a easy way to make such a calculation. Assume we have a 10K × 10K matrix, with each entry allocated a 32bit float (e.g. float32 in python), then the memory allocation for the whole matrix can be roughtly calculated as\n(104 × 104 × 4)/106 = 400M.\nSo for a computer with 4G memory, we can fit a matrix 100K× 10K matrix into memory. For a computer with 32G memory, we can fit a matrix of size 100K × 80K (10× 8× 400M = 32G)."
    }, {
      "heading" : "3.2 Enhanced Matrix Completion",
      "text" : "We looked atMF with different constraints, e.g. non-negativity and orthogality, and one type of regularization which prevents the entries in low-rank matrices being too large. This subsection considers other kinds of regularization when external data source becomes avaiable, i.e. goes beyond the data matrix X. Usually this is the real-world case, since most social media data contains rich data sources.\nIn this subsection we consider two types of regularization with corresponding addtional data:\n1. self-regularization when we have additional linked data between users (in CF, or addtional link type in LP);\n2. 2-sided regularization when we have description data of users and items.\nWe further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively."
    }, {
      "heading" : "3.2.1 Enhancing Matrix Completion with Self-regularization",
      "text" : "By self-reguarization, we refer to the regularization of rows in low-rank matrix U or V. Assume now we are dealing with a LP problem, in which we would like to predict if a user trust another – trust relation are common in review sites like Epinions. Usually there exist another type of links between users, i.e. social relation. Can we use social relation to boost the performance of trust relation prediction? This is exactly the research question proposed in [19].\nIt turns out the answer is yes – as expected, users with social relation tend to share similar preferences. The basic idea to incorporate this into trust prediction is by adding the regularization term Eq. 44 into the general MF framework. In Eq. 44, ξ is the entries in the additional link matrix Z and D is the diagonal matrix with D(i, i) = Zmj=1(j, i), thus L is the Laplacian matrix of D. It is interesting that, using trace operator, the regularization Eq. 44 become such simple.\nSocial relation is common in social computing, the similarity in people with social relation has a specific name in social theory - ‘homophily’, making this type of regularization applicable to a lot of social computing scenarios. If we generalize a bit, we may assume that many linked objects, not necessarily web users, have similarities, in terms of their entries of data matrix X that we would like to predict. For instance, while predicting the sentiment of articles, we may assume that articles authored by the same users tend to express similar sentiment, e.g. political reviewers expressing negative sentiment in their news\nreviewing articles. We will see that this type of regularization is used in a sentiment analysis paper [10], which we will analyze later.\n1\n2\nm ∑\ni=1\nm ∑\nj=1\nξ(i, j)‖U(i, :)−U(j, :)‖22\n= 1\n2\nm ∑\ni=1\nm ∑\nj=1\nk ∑\nd=1\nξ(i, j)(U(i, k)−U(j, k))2\n= 1\n2\nm ∑\ni=1\nm ∑\nj=1\nk ∑\nd=1\nξ(i, j)(U2(i, k)− 2U(i, k)U(j, k) +U2(j, k))\n= m ∑\ni=1\nm ∑\nj=1\nk ∑\nd=1\nξ(i, j)U2(i, k)− m ∑\ni=1\nm ∑\nj=1\nk ∑\nd=1\nξ(i, j)U(i, k)U(j, k)\n=\nk ∑\nd=1\nUT (:, k)(D−Z)U(:, k)\n=Tr(UTLU)\n(44)\nRegularization and Sparseness More regularization sometimes can conquer the data sparsity problem, to some extent. On the other hand, modelling the error only on observed data entries, as what O does in previous subsection, could be also very effective."
    }, {
      "heading" : "3.2.2 Enhancing Matrix Completion with 2-sided regularization",
      "text" : "Here we consider placing regularization on both U and V together, which we call 2-sided regularization.\nBefore we start, we review orthogonal non-negative MF a bit. Orthogonality constraint in orthogonal non-negative MF is similar to a 2-sided regularization:\nTr(ΓTU (U TU− I)), T r(ΓTV (V TV − I))\nare two equality constraints over low-rank matrices. Such equality needs to be strictily satisfied. Regularization, differing from constraints, however can be viewed as a soft type of constraints: it only needs to be satisfied to some extend, while constraints need to be strictly satisified. This is the reason why we consider non-negativity and orthogonality constraints, while call homophily regularization.\nNow let us turn our attention back to 2-sided regularization, basing the example from [8], which considers POI recommendation in location-based social network (LBSN). The first data we have is a check-in data X that encodes the interaction between users and POI’s. We are further given some desription data A of user interest, and B of POI property, both in the form of word vectors.\nQuestion here is, how do we make use of A and B to enhance the matrix completion problem for interacting matrix X?\nSince we are coping with 2-sided regularization, we use 3-factor MF:\nmin U,H,V\nO = ‖X−UHVT ‖2F − Tr(ΛUU T )− Tr(ΛHH T ) +R′s. (45)\nThe only thing here is, how to add the 2-sided regularization terms R’s, as we did for orthogonality constraints.\nTo utilize A and B, we assume that there are some connections between them, such that they can be used to regularize U and V. In the context of LBSN, we may assume that A and B have similar vocabulary, in which the words have similar latent space. Therefore we can approximate A and B with 2-factor MF:\nA ≈ UGT ,B ≈ VG∗T (46)\nwith connection ‖G−G∗‖1 ≈ 0. (47)\nEq. 47 is important since it really connect U with V, forming a 2-sided regularization. The final objective function now becomes:\nmin U,H,V\nO = ‖X−UHVT ‖2F − Tr(ΛUU T )− Tr(ΛHH T )\n+ λA‖A−UG T ‖2F + λB‖B−UG ∗T ‖2F + δ‖G−G ∗‖1 + α(‖U‖2F + ‖V‖ 2 F + ‖H‖ 2 F + ‖G‖ 2 F ).\n(48)\nThe last line is to regularize in approximating A,B; note that since here we use regularization, instead of constraints as in non-negative orthogonal MF, we can add regualrization to U,V,H.\nFactorization vs. Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16]. A interesting comparative study between collective facterization and self-regularization can be found in [20]."
    }, {
      "heading" : "3.3 From Clustering to (Semi-)supervised Learning",
      "text" : "Although different type of extra data is used in enhanced MF, the purpose remains to be matrix completion. This subsection, however, considers other types of machine learning problems, i.e. (semi-)supervised learning. The essential assumption of using MF for (semi-)supervised learning is that the latent row(column) is predictable for some response.\nTo make use of the predictability, we need mechanisms to connect the latent vectors to responses. Following are the two mechanisms:\n1. reinforcement directly enforce the latent space to be the response space;\n2. transformation transform the latent space to response space. This is similar as what people do in machine learning.\nWe point to publications [10] and [6] for the demonstration of the above two methods, respectively."
    }, {
      "heading" : "3.3.1 Enforcing Latent Factor to be Response",
      "text" : "In previous regularizations, we do not force the latent space to be interpretable space. For instance, in the 2-sided regularization, we do not specify the meaning of U that is used in both X and A factorization. However, (un,semi-)supervised learning requires the latent space to be interpretable. The method, still, is regularization.\n[10] deals with the problem of sentiment analysis, for which the authors use 3-factor non-negative orthogonal MF. The input is a post-word matrix X. In addition, we are given emotion indication in some of the posts. “The key idea of modeling post-level emotion indication is to make the sentiment polarity of a post as close as possible to the emotion indication of the post.”, formulated as\nGu‖U−U0‖ 2 F ,\nin which U ∈ Rm×2 is the post-sentiment matrix, i.e. U(i, :) = (1, 0) representing that the ith post has a positive sentiment, and U0 ∈ R\nm×2 is the post-emotion indication matrix, i.e. U0(i, :) = (1, 0) meaning the ith post contains positive emotion indication. Similar regularization is applied to V as well.\nSuch an idea is quite simple, however it explictly poses a notable question: is it computationally feasible that we strictly enforce the U,V to any pre-defined space, i.e. sentiment space in this case. Based on Proposition 1 in [5], we know that the answer is no. However, as we see in this sentiment analysis work [10], regularization is always possible!\nIn fact, the enforcement regularization that we see in this work is the most constrained regularization: it is 2-sided regularization for both U,V, and it is enforcement without any transformation coefficients. We will see next how to regularize for supervised learning by tranformation."
    }, {
      "heading" : "3.3.2 Transforming Latent Factor to Response",
      "text" : "As we pointed out, the essential idea of supervised learning is to transform the latent variables to some response variable. To see this, we start directly with the application of [6]. We would like to model a user’ attitude towards some controversial topic, reflected by his opinion, sentiment and retweeting action. We are given a retweeting matrix X representing users’ retweeting action to some tweets, and we would like to predict users’ opinion O and sentiment P, and the task is to predict these three variables given the user feature F.\nWe first introduce how the model is built in [6], then discuss other alternatives. To train such a model, the authors propose the following model\nmin W,V\nO = ‖X− (FWT )VT ‖2F + λ1‖FW T −O‖2F + λ2‖(FW T )S−P‖2F\n+ λ3‖W‖1 + α‖W‖ 2 F + β‖V‖ 2 F + γ‖S‖ 2 F − Tr(Λ1U T )− Tr(Λ2V T ),\n(49)\nin which λ1‖FW T −O‖2F and λ3‖W‖1 models opinion from the user feature by bringing in the classical linear regression model lasso. We can see that modelling the sentiment is also straightforward: λ2‖FW\nTS−P‖2F simply transfers again the user feature with a linear transformation S. The retweeting matrix X, similarily, also using FWT as the latent vectors.\nTo summarize, the model Eq. 49 bases the prediction of retweeting action, opinion and sentiment all on the user feature. If we make λ1 to be infinitely large, meaning that we enforce FWT = O, we can see that in fact, X ≈ OVT and OS ≈ P. Such choice is based on the assumption that opinion drives both the retweeting action and sentiment.\nModel Eq. 49 is an unified model, in the sense that the subtask of matrix completion, supervised learning are fused together, by basing all prediction on user feature transformation. What if we are not given the use feature information, instead, we directly model the relation between retweeting action, opinion and sentiment. A straightforward model could be\nmin U,V\nO = ‖X−UVT ‖2F + λ1‖U−O‖ 2 F + λ2‖US−P‖ 2 F\n+ α‖U‖2F + β‖V‖ 2 F + γ‖S‖ 2 F − Tr(Λ1U T )− Tr(Λ2V T ).\n(50)\nIn this model, the relation between the three response variable is more clearly shown. Futhermore, the difference between reinforcement and transformation is also straightforward: λ1‖U − O‖ 2 F is reinforcement, while λ2‖US − P‖ 2 F is transformation."
    } ],
    "references" : [ {
      "title" : "The matrix reference manual",
      "author" : [ "Mike Brookes" ],
      "venue" : "Imperial College London,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2005
    }, {
      "title" : "On the equivalence of nonnegative matrix factorization and spectral clustering",
      "author" : [ "Chris Ding", "Xiaofeng He", "Horst D Simon" ],
      "venue" : "In SDM’05,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2005
    }, {
      "title" : "Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching, and clique finding",
      "author" : [ "Chris Ding", "Tao Li", "Michael I Jordan" ],
      "venue" : "In ICDM’08,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2008
    }, {
      "title" : "Orthogonal nonnegative matrix t-factorizations for clustering",
      "author" : [ "Chris Ding", "Tao Li", "Wei Peng", "Haesun Park" ],
      "venue" : "In KDD’06,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Modeling user attitude toward controversial topics in online social media",
      "author" : [ "Huiji Gao", "Jalal Mahmud", "Jilin Chen", "Jeffrey Nichols", "Michelle Zhou" ],
      "venue" : "In ICWSM’14,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "Exploring temporal effects for location recommendation on location-based social networks",
      "author" : [ "Huiji Gao", "Jiliang Tang", "Xia Hu", "Huan Liu" ],
      "venue" : "In RecSys’13,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "Content-aware point of interest recommendation on location-based social networks",
      "author" : [ "Huiji Gao", "Jiliang Tang", "Xia Hu", "Huan Liu" ],
      "venue" : "In AAAI’15,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "The elements of statistical learning",
      "author" : [ "Trevor Hastie", "Robert Tibshirani", "Jerome Friedman" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Unsupervised sentiment analysis with emotional signals",
      "author" : [ "Xia Hu", "Jiliang Tang", "Huiji Gao", "Huan Liu" ],
      "venue" : "In WWW’13,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
      "author" : [ "Yehuda Koren" ],
      "venue" : "In KDD’08,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Matrix factorization techniques for recommender systems",
      "author" : [ "Yehuda Koren", "Robert Bell", "Chris Volinsky" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Learning the parts of objects by non-negative matrix factorization",
      "author" : [ "Daniel D Lee", "H Sebastian Seung" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1999
    }, {
      "title" : "Algorithms for non-negative matrix factorization",
      "author" : [ "Daniel D Lee", "H Sebastian Seung" ],
      "venue" : "In NIPS’01,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2001
    }, {
      "title" : "Probabilistic matrix factorization",
      "author" : [ "Andriy Mnih", "Ruslan Salakhutdinov" ],
      "venue" : "In NIPS’07,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Collaborative filtering beyond the user-item matrix: A survey of the state of the art and future challenges",
      "author" : [ "Yue Shi", "Martha Larson", "Alan Hanjalic" ],
      "venue" : "ACM Computing Surveys (CSUR),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Relational learning via collective matrix factorization",
      "author" : [ "Ajit P Singh", "Geoffrey J Gordon" ],
      "venue" : "In KDD’08,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2008
    }, {
      "title" : "Matrix factorization and neighbor based algorithms for the netflix prize problem",
      "author" : [ "Gábor Takács", "István Pilászy", "Bottyán Németh", "Domonkos Tikk" ],
      "venue" : "In RecSys’08,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2008
    }, {
      "title" : "Exploiting homophily effect for trust prediction",
      "author" : [ "Jiliang Tang", "Huiji Gao", "Xia Hu", "Huan Liu" ],
      "venue" : "In WSDM’13,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2013
    }, {
      "title" : "Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation",
      "author" : [ "Quan Yuan", "Li Chen", "Shiwan Zhao" ],
      "venue" : "In Recsys’11,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "MF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 13,
      "context" : "MF has several nice properties: 1) it uncovers latent structures in the data, while addressing the data sparseness problem [11]; 2) it has an elegant probabilistic interpretation [15]; 3) it can be easily extended with domain specific prior knowledge (e.",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 17,
      "context" : ", homophily in linked data [19]), thus suitable for various real-world problems; 4) many optimization methods such as (stochastic) gradient-based methods can be applied to find a good solution.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 2,
      "context" : "Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19].",
      "startOffset" : 92,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : "Note that for the optimizing method, we mainly use the alternative algorithm, as similar to [4, 19].",
      "startOffset" : 92,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "For reference, matrix operation and optimization can be referred to [2] and [1] respectively.",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 7,
      "context" : "Regularization is usually necessary in prediction for bias-variance trade-off [9].",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 0,
      "context" : "(see more in [2]), we have the following derivatives for U and V,",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 16,
      "context" : "Detailed algorithm can be find in [18].",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 2,
      "context" : "As the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19].",
      "startOffset" : 150,
      "endOffset" : 157
    }, {
      "referenceID" : 17,
      "context" : "As the objective function is non-convex caused by the coupling between U and V, we can choose to alternatively update U and V in each iteration as in [4, 19].",
      "startOffset" : 150,
      "endOffset" : 157
    }, {
      "referenceID" : 17,
      "context" : "Detailed algorithm is similar to the one in [19].",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 11,
      "context" : "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.",
      "startOffset" : 93,
      "endOffset" : 107
    }, {
      "referenceID" : 12,
      "context" : "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.",
      "startOffset" : 93,
      "endOffset" : 107
    }, {
      "referenceID" : 3,
      "context" : "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.",
      "startOffset" : 93,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "Interestingly, the alternative optimization scheme is even more suitable for non-negative MF [13, 14, 5, 4], as we will see in the following subsections.",
      "startOffset" : 93,
      "endOffset" : 107
    }, {
      "referenceID" : 11,
      "context" : "2 Non-negative MF Non-negativeMF [13] seeks to approximate data matrixXwith low-dimensional matrices U,V whose entries are all non-negative, i.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 11,
      "context" : "Non-negativity constaint is originated from parts-of-whole interpretation [13].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 11,
      "context" : "Non-negative MF may uncover the important parts, which sometimes can not be achieved by non-constrained MF [13].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "Detailed algorithm using these rules is similar to the one in [19].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 12,
      "context" : "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 3,
      "context" : "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].",
      "startOffset" : 92,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "12 with the standard auxiliary function approach, which is proposed in [14] and extended in [5, 4].",
      "startOffset" : 92,
      "endOffset" : 98
    }, {
      "referenceID" : 3,
      "context" : "Our proof is mainly based on [5, 4], although the objective function Eq.",
      "startOffset" : 29,
      "endOffset" : 35
    }, {
      "referenceID" : 2,
      "context" : "Our proof is mainly based on [5, 4], although the objective function Eq.",
      "startOffset" : 29,
      "endOffset" : 35
    }, {
      "referenceID" : 3,
      "context" : "17 can be found in [5] (Proposition 6).",
      "startOffset" : 19,
      "endOffset" : 22
    }, {
      "referenceID" : 1,
      "context" : "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 ≤ j ≤ k) cluster.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 ≤ j ≤ k) cluster.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "It is proved in [3, 5] ([5] gives more mature proof) that this problem is equivalent to K-means clustering: V is an indication matrix with V(i, j) = 0 if xi belongs to the j th (1 ≤ j ≤ k) cluster.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "It is proved that, compared to 3-factor bi-orthogonal non-negative MF, 2factor bi-orthogonal non-negative MF is too restrictive, and will lead to poor approximation [5].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 3,
      "context" : "3-factor bi-orthogonal non-negative MF is useful in document-word clustering [5], outperforming K-means (i.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 8,
      "context" : "It has been applied for tasks such as sentiment analysis [10].",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 10,
      "context" : "Such assumption is very common in real-world cases [12].",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 5,
      "context" : "For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively.",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 6,
      "context" : "For updating rules of non-negative MF and orthogonal non-negative MF, the reader can refer to [7] and [8], respectively.",
      "startOffset" : 102,
      "endOffset" : 105
    }, {
      "referenceID" : 17,
      "context" : "We further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "We further point to two publications [19] and [8], to demonstrate the above two types of regularization, respectively.",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 17,
      "context" : "Can we use social relation to boost the performance of trust relation prediction? This is exactly the research question proposed in [19].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "We will see that this type of regularization is used in a sentiment analysis paper [10], which we will analyze later.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 6,
      "context" : "Now let us turn our attention back to 2-sided regularization, basing the example from [8], which considers POI recommendation in location-based social network (LBSN).",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : "Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 14,
      "context" : "Regularization We remark here that the idea of cofactoring two matrices (X,A) with shared factors (U) originates from collective matrix facterization [17], which has many applications in CF [16].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 18,
      "context" : "A interesting comparative study between collective facterization and self-regularization can be found in [20].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 8,
      "context" : "We point to publications [10] and [6] for the demonstration of the above two methods, respectively.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "We point to publications [10] and [6] for the demonstration of the above two methods, respectively.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 8,
      "context" : "[10] deals with the problem of sentiment analysis, for which the authors use 3-factor non-negative orthogonal MF.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "Based on Proposition 1 in [5], we know that the answer is no.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "However, as we see in this sentiment analysis work [10], regularization is always possible! In fact, the enforcement regularization that we see in this work is the most constrained regularization: it is 2-sided regularization for both U,V, and it is enforcement without any transformation coefficients.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 4,
      "context" : "To see this, we start directly with the application of [6].",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 4,
      "context" : "We first introduce how the model is built in [6], then discuss other alternatives.",
      "startOffset" : 45,
      "endOffset" : 48
    } ],
    "year" : 2017,
    "abstractText" : null,
    "creator" : "LaTeX with hyperref package"
  }
}