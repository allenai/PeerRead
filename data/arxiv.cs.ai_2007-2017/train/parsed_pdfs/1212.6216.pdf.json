{
  "name" : "1212.6216.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Masood Amoozgar" ],
    "emails" : [ "masood.moozgar@cs.sharif.ir.", "heydariaan@cs.sharif.ir.", "nokhbeh100}@gmail.com.", "bagheri-s@sharif.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION HE research in distributed Multi Agent Systems and Artificial Intelligence and their applications is one of\ncommon fields of study in recent years. A major focus of machine learning research is to learn and imitate complex patterns and make intelligent decisions based on sampled data. Some machine learning systems attempt to eliminate the need for human-intuition in data analysis, while others adopt a collaborative approach between human-intuition and machine. Human-intuition cannot, however, be entirely eliminated, since the system's designer must specify how the data is going to be represented and what mechanisms will be used to search for a characterization of the data. One other reason for collaborative human-machine approach is due to complexity and difficulty of a pure machine analysis. In this study we are going to use a collaborative humanmachine approach for designing a motion trajectory. Regarding to the fact that the way a mobile agent treating is somehow unpredictable before online stage, human’s intuition can be so effective for generating an initial dribbling behavior.\nIn this paper as a complex problem, analyzing the avoidance of a mobile obstacle is focused on. Obviously it is comparable with traditional obstacle avoidance problem.\nMasood Amoozgar and Milad Heydarian are with Computer Science department, Sharif University of Technology. Email: {masood.moozgar,heydariaan}@cs.sharif.ir. Daniel Khashabi and Mohammad Nokhbeh are with Electrical Engineering Department, Amirkabir University of Technology. Email: {d.khashabi, nokhbeh100}@gmail.com. Saeed Bagheri Shouraki is associate professor of Sharif University of Technology, Electrical Engineering department. Email: bagheri-s@sharif.edu\nThe manner of obstacle in which it behaves has enormous effect on how the algorithm must be designed. The most important concern in this paper is the case in which obstacle agent tries to harden motion task. The most glorious example of this problem is encountered in soccer environment, where a ball-holder agent wants to dribble (avoid) a (several) defender agent(s), simultaneously reach a specific position or dribble toward specific direction.\nIn this paper, we propose a hybrid computational geometry and evolutionary computation approach for generating motion trajectories to avoid a mobile obstacle. Offline stage is when the agent is out of competition, hence there is no strong limitation on competition time during this step. So it tries to explore better behaviors. In online stage, an agent must exploit what it has learnt before. In fact it is the time when it tries to act in desired manner, so online stage is limited to whole game time that there is a limitation of process in this stage. Transferring the process of calculation of the desired motion to offline stage, results in reduction of computational cost of online stage, which causes increment in agent’s performance. In offline stage the goal is to find desired trajectory plan using evolutionary computation. A trajectory plan consists of nodes which approximate information of each trajectory plan. In online stage a linear interpolation along with Delaunay triangulation in xy-plan is applied to trajectory plan to get desired action.\nIn the rest of the paper, we first present some issues on dribbling a mobile agent. Then offline stage and online stage parts of method are discussed. At the end of the paper, several results of proposed method are shown. Software is used for designing motion trajectories which is called Dribble Editor (DEdit in brief). By using this software it is possible to design motion patterns and simulate their results. As it will be mentioned in detail in the rest of paper, one can apply GA to any dribble trajectory using equipments deserved in DEdit. More pictures are depicted in (Fig. 4). The latest version of software which was designed to implement the method (DEdit) and its source codes (in Java) and all information about it, are available on this address: http://cs.sharif.edu/~amoozgar/focus/dedit"
    }, {
      "heading" : "II. DRIBBLING A MOBILE AGENT",
      "text" : "Dribbling is a sequence of several decisions which they overall determine an agent’s position on a plan. So every decision by changing agent’s relative position to other agents would make a significant change in agent’s next performance. Therefore it is a complicated task.\nAs mentioned, the center of attention is on special case of dribbling a mobile agent/obstacle. In traditional obstacle avoidance, the main focus is allocated to minimize time\nT\nneeded to achieve one specific destination meanwhile considering algorithm’s complexity and time cost. In some cases environmental position of an obstacle changes dynamically and algorithms must be as adaptive as possible with real-time environment. But the way that obstacles behave is so important. In fact if rate of intelligence for an obstacle agent is low, the obstacle agent won’t do its job to grab the ball, hence it’s a conventional obstacle avoidance problem and with less time and energy cost, target of dribbling agent will be achieved. On the other hand if it is high, it will try to grab dribbler agent’s ball. So the ballholder agent must avoid ball from defender at least with a distance a little more than kickable distance of obstacle agent. Obstacle agent could be more intelligent and learn the way dribbler is acting. So the actions of dribbler agent must be adjusted greedier."
    }, {
      "heading" : "III. OFFLINE STAGE",
      "text" : ""
    }, {
      "heading" : "A. Trajectory plan Generation",
      "text" : "For generating a dribble trajectory we need to make an structure for defining a dribble pattern. In fact, this structure is a function which gives information about dribble in every position of the field. The optimization process which will be discussed in further parts will be applied to this structure. In defining such a structure we have used Delaunay triangulation and linear interpolation which is going to be described in next parts.\n1) Delaunay triangulation: Delaunay triangulation is one of the most promising methods to triangulate the plate region, based on a given point-set. Delaunay triangulation for a point-set P is DT (P) such that there is no point member of P, inside circum circle of any triangle member of DT(P). For every set of points more than 3, there is a unique Delaunay triangulation. In our data extraction method, vertices of triangles are agent’s relative position to obstacle agent. For every vertex (position in xy-plan), information of dribbler agent is generated, e.g. direction of motion, direction of ball and acceleration of motion.\n2) Linear Interpolation: For finding information of specific point Ps inside of triangle Tn (Fig. 1) we use simple linear interpolation. If Pa , Pb and Pc are assumed as vertices of triangle, each containing information of Ia , Ib and Ic , we can simply use a weighted average for getting information of point Is :\n, , , 1 1 1 , , ,\na b C\ns a s b s c s\ns a s b s c\nI I I P P P P P P\nI\nP P P P P P\n+ + =\n+ +\n(1)\nThe formula (1) can be considered as a conventional weighted mean of three values where |Pi , Pj| is distance between two points Pi and Pj. This kind of function approximation using Delaunay triangulation has following advantages [1]:\n--High approximation accuracy: It is claimed that this method of approximation is more accurate than other methods.\n--Locally adjustable: Even if an existing data modified, the triangle region where the data is not in, is not affected. --Simple and fast: Regarding to time complexity of triangulation (O(nlogn) see [2] ) and linear interpolation, it is possible to use it in a real-time environment. There are some other works that use combination of Delaunay triangulation and linear interpolation as a function approximation. In [1] and [3] a method is proposed to approximate positioning of a multi-agent system based on combination of Delaunay triangulation and linear interpolation. It’s claimed that this method is fast, accurate and simple."
    }, {
      "heading" : "B. Designing trajectory plans",
      "text" : "Human intuition used in trajectory plan design can be so effective. One can design his desired trajectory (Fig. 4). In defining every pattern, one can define these specifications:\n--Position of an agent relative to opponent agent’s position. --Direction of agent’s movement relative to field’s global zero direction. --Direction of ball relative to field’s global zero direction. --Acceleration of agent in specified direction. Position of ball just depends on its relative direction. After inserting every new node to a trajectory plan, DEdit triangulates plan. It is possible to edit specifications of all predefined nodes.\nFor testing a trajectory plan, a simulation engine is devised which simulates agent’s movement when starting from a specific initial position and with a specific initial velocity given by user. One example of a trajectory generated by user is shown in (Fig.2)."
    }, {
      "heading" : "C. Optimizing strategy of trajectory plan",
      "text" : "For using Genetic Algorithm, the problem requires to be defined as a generation and then it is possible to use evolution over this generation. The first stage is to define individuals. Each trajectory plan is defined as an individual. Practically, there exist complex of nodes in each individual that every node includes 5 parameters: x, y, acceleration, ball-direction and body-direction. Parameters x and y are just for specifying each point from others and are not used in evolution process.\nThere is a process of generating individuals based on human-generated trajectory plan. This is done until reaching a population in number of population-size which will be used as initial population. The main process of GA will be repeated in generation-count times. In next parts, steps of evolution process will be described:\n[Step 1] Selecting several individuals as parents and copying them into mating pool: Parent selection basically should better be a random process for diverging individuals in search space. Moreover, better individuals (which are ranked by their fitness value) should gain more chance to be selected. Therefore, four algorithms are assumed: -- Roulette Wheel -- Rank -- Stochastic Universal Sampling -- Tournament\nA parameter called parent-selection-probability controls the selection process. [Step 2] Applying crossover on individuals: The crossover process consists of selecting two random parents and making two new individuals using parents. This process is repeated over and over until reaching the desired quantity. To control crossover process, a parameter crossover-probability is applied.\nWhen two random individuals Pi(gt-1) and Pj(gt-1) are chosen from previous generation parent group P(gt-1), two offspring Pi(gt-1)child and Pj(gt-1)child are generated by the crossover. This is carried out using the weighted mean, so kth parameter of offspring is:\n1\n1 1\n( ) .\n( ) . ( ) .\nt c h i ld i k\nt t i i k j j k\ni j\nP g p a r a m\nw P g p a r a m w P g p a r a m w w\n−\n− −\n=\n× + × +\n(2)\n1\n1 1\n( ) .\n( ) . ( ) .\nt ch i ld j k\nt t j i k i j k\ni j\nP g p a ra m\nw P g p a ra m w P g p a ra m w w\n−\n− −\n=\n× + × +\n(3)\nThe parameters w1 and w2 are two random numbers between 0.8 and 1.2. [Step 3] Mutating on population and creating new individuals and adding them into population: Mutation process is defined by adding a Gaussian Random Number (GRN) to all parameters of each individual. These small random numbers are limited to 1% of maximum value of the parameters, e.g. for bodydirection and ball-direction, maximum value is 180◦ and corresponding GNR is a number between -1.8 and 1.8. In order to mutate individuals, an initial mutation coefficient is applied to create first generation with an individual by mutation, so mutation-coefficient is multiplied by the small random number to make difference between primary mutation (which was applied on first individual to generate first population) and recent mutation. If 1( )t mutatediP g\n− is a mutated individual, the value of kth parameter of individual under mutation will be:\n(4)\n1 1\n1\n( ) . ( ) .\nm a x ( ) . 1 0 0\nt m u ta te d t i k i k\nt k\nP g p a ra m P g p a ra m\nP g p a ra m G R N m u ta tio n C o e ff ic ie n t\n− −\n−\n= +\n⎛ ⎞⎡ ⎤ × ×⎣ ⎦⎜ ⎟ ⎜ ⎟ ⎝ ⎠\n[Step 4] Selecting individuals from the population and transferring them to next generation: Selection of the individuals is a deterministic process i.e. transferring best generation-number of individuals to next generation. This is done after evaluating individuals by using a fitness function. Hence, this process results in maximizing fitness value of best individual, which leads to optimize the behavior.\nIn next part, structure of proposed fitness function is discussed."
    }, {
      "heading" : "D. Fitness function",
      "text" : "Design of a fitness function, lets us find a desired behavior plan in every position and every condition of plan. It is supposed that positions of nodes in all trajectory plans are the same. So the fitness function of a trajectory plan tp is sum of fitness function of the nodes.\n#\n1 ( ) ( . )\nnodes\ni i planFitness tp fitnessFunction tp node = = ∑ (5)\nAnd fitness function for every node in trajectory plan is:\n2 ( ) exp( ( ) ) fitnessFunction node desiredFunction node π =\n(6)\n2 2\n2 2\n( ) ( . ) ( . . )\n( . ) ( . )\ndesiredFunction node node bodyDir node bodyDir node bodyRlObs\nnode ballDir node ballRlObs α β π\n=\n− − − − −\n(7)\n( ) ( ) 0.1 50 exp( 2 ) 0.1 50 exp( 2 ) user user dist dist α α β β = + − = + − (8)\nWhere in (7) bodyDir and ballDir are direction of agent’s body and direction of ball relative to global zero direction, respectively. ballRlObs is the angle between ball and obstacle agent. bodyRlObs is the angle between dribbler agent and obstacle. Two factors are considered in designing this fitness function. The first is considering variables which will cause in low outcome i.e. straight motion and the other one, variables which are involved in generating safe motion for dribbler agent. These factors behave against each other. This is similar to what happens in real soccer match. Direct movement is the fastest and low cost course and increases excellence of ball control whereas moving spirally increases safety of motion and of course motion’s energy and time cost. Therefore, balancing effectiveness of these factors in fitness function, will lead to desired motion.\nIn order to adjust values of bodyDir and ballDir to desired ones, two factors are included for each of variables. First factor maximizes each variable in the function and the other one minimizes it. Rate of effectiveness for each of factors, depends on their coefficients (α and β). Meanwhile αuser and βuser are coefficients, which are applied by user. Increment of α encourages agent to move smoothly which results in wasting less stamina and increment of β encourages agent to keep ball in front of its body which results in maximum control on it, and decrement of α and β makes agent more sensitive to the opponent. For achieving a more similar behavior to the real agent, parameters α and β should be dependent on distance between agent and obstacle (parameter dist in (8))."
    }, {
      "heading" : "IV. ONLINE STAGE",
      "text" : ""
    }, {
      "heading" : "A. Using calculated values",
      "text" : "In online stage, dribbling action is done based on generated pattern. Depending on the position, in any cycle a trajectory plan determines agent’s acceleration, bodydirection and ball-direction using linear interpolation. The reasons that linear interpolation is proposed as a default algorithm for calculating values of agent’s movement action is discussed; this means local approximation and low\ncomputational cost. One can use other interpolating methods especially nonlinear approximators (e.g. Neural Networks ) or Fuzzy approach depending on desired complexity.\nTrajectory plans are obstacle-centric, which means position and direction of any trajectory plan in the digital soccer field, depends on obstacle (Fig. 3). Therefore, in order to acquire an algorithm for choosing the best trajectory plan for agent’s motion, Delaunay triangulation is used again. But in this layer of processing, nodes are assumed to be obstacles. In fact the trajectory plan in every position of the field is calculated based on what is explained before. This is because of the fact that in different positions of the field, different manners of dribbling is desirable; this means that there is a region on the field that more safely action is needed while in another region of field low-cost and rapid action is more desirable. This will cause in dynamic manner of motion based in where the agent is acting. By encountering any obstacle, desired trajectory plan will be retrieved by applying linear interpolation on Delaunay mesh of soccer field based on saved trajectory plans, which is calculated in offline stage for various obstacle positions."
    }, {
      "heading" : "V. RESULTS & FUTURE WORKS",
      "text" : "In this study we proposed a method for designing motion trajectories where the goal is to dribble a moving agent. As mentioned a special case that is most concerned is where a ball-holder agent wants to dribble a defender agent. The proposed method is a Genetic Algorithm which is applied on solutions that are saved using Delaunay Triangulation. Even though there is no strong proof on optimality of this trajectory generation, the results depicted in previous parts show that by adjusting fitness function and the use of offline dribble data-set, it is possible to achieve trustable solutions. There are some other points in this work:\n--Delaunay triangulation can be u approximator where there is a need fo approximation. Here we showed its u motion patterns.\n--Even though dribbling is a sequent method is free from sequential analysis fact that defining final results for dribb is too difficult to apply methods Learning to solve these kinds of pr generating desired patterns are shown i (Fig. 7)\nating motion patterns in INSERT mode (b) EDIT mode (c) PLAY m , edit and test the trajectory plans. Every trajectory plan contains no eleration, body-direction and ball-direction (e) Resulted motion traj ction and acceleration in every position of field. It is similar to an e\nsed as a function r local and smooth sefulness for saving\nial action, proposed . It is referring to the ling is so hard. So it like Reinforcement oblems. Results of n (Fig. 5), (Fig. 6) and\nTAB PARAMETERS OF G\nParent selection algorithm Crossover probability Mu coef\nRoulette wheel 0.8\nMax acceleration\nRange of bodyDir\n3 [m/s2] [ , ] 2 2 π π−\node. (d) adjusting GA des which they consists of ectories when agent started lectric field!\nLE I. ENETIC ALGORITHM\ntation ficient\nParent selection\ncoefficient\nGeneration count\n4 0.6 1000\nRange of ballDir userα userβ\n[ , ] 2 2 π π− 0.66 0.33\nGetting more optimal results is what should be considered for future works. Online stage adaptive behavior is an important issue, where the dribbler agent changes its behavior based on its failures and successes. Because agent needs to learn in real-time, computational load of this updating is so important. In general, the real world problems are dynamic and basis of action selection is to deceive the opponent. The performing algorithm must be probabilistic, regarding to reactions of the opponents. In advance steps, as the defense goes along legislating attacker’s behavior, the reactions must be changed. So we are encountered with a dynamic action."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "The authors would like to thank Mojtaba Khalidji for his illuminating comments and discussions. They also acknowledge Pooya Abedi and Iman Esmaili and Seyed Hossein Khasteh for their reviews and helpful comments."
    } ],
    "references" : [ {
      "title" : "Multi-agent Positioning Mechanism in the Dynamic Environment",
      "author" : [ "H. Akiyama", "I. Noda" ],
      "venue" : "Robocup2007,LNA 5001, vol. 5001/2008, pp. 377-384, 2008.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Training of Agent Positioning Using Human’s Instruction",
      "author" : [ "H.Akiyama", "D.Katagami", "K.Nitta" ],
      "venue" : "Journal of Advanced Computational Intelligence and Intelligant Informatics, vol. 11, no. 8, pp. 998-1006, 2007.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Handbook of Genetic Algorithms.",
      "author" : [ "L.D. Davis", "Melanie Mitchell" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1991
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "This kind of function approximation using Delaunay triangulation has following advantages [1]: --High approximation accuracy: It is claimed that this method of approximation is more accurate than other methods.",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "In [1] and [3] a method is proposed to approximate positioning of a multi-agent system based on combination of Delaunay triangulation and linear interpolation.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 1,
      "context" : "In [1] and [3] a method is proposed to approximate positioning of a multi-agent system based on combination of Delaunay triangulation and linear interpolation.",
      "startOffset" : 11,
      "endOffset" : 14
    } ],
    "year" : 2010,
    "abstractText" : "Dribbling an opponent player in digital soccer environment is an important practical problem in motion planning. It has special complexities which can be generalized to most important problems in other similar Multi Agent Systems. In this paper, we propose a hybrid computational geometry and evolutionary computation approach for generating motion trajectories to avoid a mobile obstacle. In this case an opponent agent is not only an obstacle but also one who tries to harden dribbling procedure. One characteristic of this approach is reducing process cost of online stage by transferring it to offline stage which causes increment in agents’ performance. This approach breaks the problem into two offline and online stages. During offline stage the goal is to find desired trajectory using evolutionary computation and saving it as a trajectory plan. A trajectory plan consists of nodes which approximate information of each trajectory plan. In online stage, a linear interpolation along with Delaunay triangulation in xy-plan is applied to trajectory plan to retrieve desired action.",
    "creator" : "'Certified by IEEE PDFeXpress at 12/07/2010 4:21:00 PM'"
  }
}