{
  "name" : "1511.01419.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Train and Test Tightness of LP Relaxations in Structured Prediction",
    "authors" : [ "Ofer Meshi", "Mehrdad Mahdavi", "Adrian Weller", "David Sontag" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many applications of machine learning can be formulated as prediction problems over structured output spaces (Bakir et al., 2007; Nowozin et al., 2014). In such problems output variables are predicted jointly in order to take into account mutual dependencies between them, such as high-order correlations or structural constraints (e.g., matchings or spanning trees). Unfortunately, the improved expressive power of these models comes at a computational cost, and indeed, exact prediction and learning become NP-hard in general.\n†Toyota Technological Institute at Chicago ‡University of Cambridge §New York University\nar X\niv :1\n51 1.\n01 41\n9v 3\n[ st\nat .M\nL ]\n2 7\nDespite this worst-case intractability, efficient approximations often achieve very good performance in practice. In particular, one type of approximation which has proved effective in many applications is based on linear programming (LP) relaxation. In this approach the prediction problem is first cast as an integer LP (ILP), and then the integrality constraints are relaxed to obtain a tractable program. In addition to achieving high prediction accuracy, it has been observed that LP relaxations are often tight in practice. That is, the solution to the relaxed program happens to be optimal for the original hard problem (an integral solution is found). This is particularly surprising since the LPs have complex scoring functions that are not constrained to be from any tractable family. A major open question is to understand why these real-world instances behave so differently from the theoretical worst case.\nThis paper aims to address this question and to provide a theoretical explanation for the tightness of LP relaxations in the context of structured prediction. In particular, we show that the approximate training objective, although designed to produce accurate predictors, also induces tightness of the LP relaxation as a byproduct. Our analysis also suggests that exact training may have the opposite effect. To explain tightness of test instances, we prove a generalization bound for tightness. Our bound implies that if many training instances are integral, then test instances are also likely to be integral. Our results are consistent with previous empirical findings, and to our knowledge provide the first theoretical justification for the wide-spread success of LP relaxations for structured prediction in settings where the training data is not linearly separable."
    }, {
      "heading" : "2 Related Work",
      "text" : "Many structured prediction problems can be represented as ILPs (Roth and Yih, 2005; Martins et al., 2009a; Rush et al., 2010). Despite being NPhard in general (Roth, 1996; Shimony, 1994), various effective approximations have been proposed. Those include both search-based methods (Daumé III et al., 2009; Zhang et al., 2014), and natural LP relaxations to the hard ILP (Schlesinger, 1976; Koster et al., 1998; Chekuri et al., 2004; Wainwright et al., 2005). Tightness of LP relaxations for special classes of problems has been studied extensively in recent years and include restricting either the structure of the model or its score function. For example, the pairwise LP relaxation is known to be tight for tree-structured models and for super-\nLP is often tight for structured prediction!Non-Projective Depe dency Parsing *0 John1 saw2 a3 movie4 today5 that6 he7 liked8\n*0 John1 saw2 a3 movie4 today5 that6 he7 liked8\nImportant problem in many languages.\nProblem is NP-Hard for all but the simplest models. For example, in non-projective dependency parsing, we found that the LP relaxation is exact for over 95% of sentences\n(Martins et al. ACL ’09, Koo et al., EMNLP ’10)\nHow often do we exactly solve the problem?\n90\n92\n94\n96\n98\n100\nCze Eng Dan Dut Por Slo Swe Tur\nI Percentage of examples where the dual decomposition finds\nan exact solution.\nLanguage\nPercentage of integral solutions\nEven when the local LP relaxation is not tight, often still possible to solve exactly and quickly (e.g., Sontag et al. ‘08, Rush & Collins ‘11)\nFigure 1: Percentage of in egral olutions for dependency parsing from Koo et al. (2010).\nmodular scores (see, e.g., Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures.\nHowever, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.88% of the test data on a dependency parsing problem (see Table 2 therein). Koo et al. (2010) observed a similar behavior for dependency parsing on a number of languages, as can be seen in Fig. 1 (kindly provided by the authors). The same phenomenon has been observed for a multi-label classification task, where test integrality reached 100% (Finley and Joachims, 2008, Table 3).\nLearning structured output predictors from labeled data was proposed in various forms by Collins (2002); Taskar et al. (2003); Tsochantaridis et al. (2004). These formulations generalize training methods for binary classifiers, such as the Perceptron algorithm and support vector machines (SVMs), to the case of structured outputs. The learning algorithms repeatedly perform prediction, necessitating the use of approximate inference within training as\nwell as at test time. A common approach, introduced right at the inception of structured SVMs by Taskar et al. (2003), is to use LP relaxations for this purpose.\nThe most closely related work to ours is Kulesza and Pereira (2007), which showed that not all approximations are equally good, and that it is important to match the inference algorithms used at train and test time. The authors defined the concept of algorithmic separability which refers to the setting when an approximate inference algorithm achieves zero loss on a data set. The authors studied the use of LP relaxations for structured learning, giving generalization bounds for the true risk of LP-based prediction. However, since the generalization bounds in Kulesza and Pereira (2007) are focused on prediction accuracy, the only settings in which tightness on test instances can be guaranteed are when the training data is algorithmically separable, which is seldom the case in real-world structured prediction tasks (the models are far from perfect). Our paper’s main result (Theorem 4.1), on the other hand, guarantees that the expected fraction of test instances for which a LP relaxation is integral is close to that which was estimated on training data. This then allows us to talk about the generalization of computation. For example, suppose one uses LP relaxation-based algorithms that iteratively tighten the relaxation, such as Sontag and Jaakkola (2008); Sontag et al. (2008), and observes that 20% of the instances in the training data are integral using the pairwise relaxation and that after tightening using cycle constraints the remaining 80% are now integral too. Our generalization bound then guarantees that approximately the same ratio will hold at test time (assuming sufficient training data).\nFinley and Joachims (2008) also studied the effect of various approximate inference methods in the context of structured prediction. Their theoretical and empirical results also support the superiority of LP relaxations in this setting. Martins et al. (2009b) established conditions which guarantee algorithmic separability for LP relaxed training, and derived risk bounds for a learning algorithm which uses a combination of exact and relaxed inference.\nFinally, recently Globerson et al. (2015) studied the performance of structured predictors for 2D grid graphs with binary labels from an informationtheoretic point of view. They proved lower bounds on the minimum achievable expected Hamming error in this setting, and proposed a polynomial-time algorithm that achieves this error. Our work is different since we focus on LP relaxations as an approximation algorithm, we handle the most general form without making any assumptions on the model or error measure (ex-\ncept score decomposition), and we concentrate solely on the computational aspects while ignoring any accuracy concerns."
    }, {
      "heading" : "3 Background",
      "text" : "In this section we review the formulation of the structured prediction problem, its LP relaxation, and the associated learning problem. Consider a prediction task where the goal is to map a real-valued input vector x to a discrete output vector y = (y1, . . . , yn). A popular model class for this task is based on linear classifiers. In this setting prediction is performed via a linear discriminant rule: y(x;w) = argmaxy′ w\n>φ(x, y′), where φ(x, y) ∈ Rd is a function mapping input-output pairs to feature vectors, and w ∈ Rd is the corresponding weight vector. Since the output space is often huge (exponential in n), it will generally be intractable to maximize over all possible outputs.\nIn many applications the score function has a particular structure. Specifically, we will assume that the score decomposes as a sum of simpler score functions: w>φ(x, y) = ∑ cw > c φc(x, yc), where yc is an assignment to a (non-exclusive) subset of the variables c. For example, it is common to use such a decomposition that assigns scores to single and pairs of output variables corresponding to nodes and edges of a graph G: w>φ(x, y) =∑\ni∈V (G)w > i φi(x, yi) + ∑ ij∈E(G)w > ijφij(x, yi, yj). Viewing this as a function\nof y, we can write the prediction problem as: maxy ∑\nc θc(yc;x,w) (we will sometimes omit the dependence on x and w in the sequel).\nDue to its combinatorial nature, the prediction problem is generally NPhard. Fortunately, efficient approximations have been proposed. Here we will be particularly interested in approximations based on LP relaxations. We begin by formulating prediction as the following ILP:1\nmax µ∈ML µ∈{0,1}q ∑ c ∑ yc µc(yc)θc(yc) + ∑ i ∑ yi µi(yi)θi(yi) = θ >µ\nwhere ML = { µ ≥ 0 : ∑ yc\\i\nµc(yc) = µi(yi) ∀c, i ∈ c, yi∑ yi µi(yi) = 1 ∀i\n} .\nHere, µc(yc) is an indicator variable for a factor c and local assignment yc, and q is the total number of factor assignments (dimension of µ). The set\n1For convenience we introduce singleton factors θi, which can be set to 0 if needed.\nML is known as the local marginal polytope (Wainwright and Jordan, 2008). First, notice that there is a one-to-one correspondence between feasible µ’s and assignments y’s, which is obtained by setting µ to indicators over local assignments (yc and yi) consistent with y. Second, while solving ILPs is NP-hard in general, it is easy to obtain a tractable program by relaxing the integrality constraints (µ ∈ {0, 1}q), which may introduce fractional solutions to the LP. This relaxation is the first level of the Sherali-Adams hierarchy (Sherali and Adams, 1990), which provides successively tighter LP relaxations of an ILP. Notice that since the relaxed program is obtained by removing constraints, its optimal value upper bounds the ILP optimum.\nIn order to achieve high prediction accuracy, the parameters w are learned from training data. In this supervised learning setting, the model is fit to labeled examples {(x(m), y(m))}Mm=1, where the goodness of fit is measured by a task-specific loss ∆(y(x(m);w), y(m)). In the structured SVM (SSVM) framework (Taskar et al., 2003; Tsochantaridis et al., 2004), the empirical risk is upper bounded by a convex surrogate called the structured hinge loss, which yields the training objective:2\nmin w ∑ m max y [ w> ( φ(x(m), y)− φ(x(m), y(m)) ) + ∆(y, y(m)) ] . (1)\nThis is a convex function of w and hence can be optimized in various ways. But, notice that the objective includes a maximization over outputs y for each training example. This loss-augmented prediction task needs to be solved repeatedly during training (e.g., to evaluate subgradients), which makes training intractable in general. Fortunately, as in prediction, LP relaxation can be applied to the structured loss (Taskar et al., 2003; Kulesza and Pereira, 2007), which yields the relaxed training objective:\nmin w ∑ m max µ∈ML [ θ>m(µ− µm) + `>mµ ] , (2)\nwhere θm ∈ Rq is a score vector in which each entry represents w>c φc(x(m), yc) for some c and yc, similarly `m ∈ Rq is a vector with entries3 ∆c(yc, y(m)c ), and µm is the integral vector corresponding to y (m).\n2For brevity, we omit the regularization term, however, all of our results below still hold with regularization.\n3We assume that the task-loss ∆ decomposes as the model score."
    }, {
      "heading" : "4 Analysis",
      "text" : "In this section we present our main results, proposing a theoretical justification for the observed tightness of LP relaxations used for inference in models learned by structured prediction, both on training and held-out data. To this end, we make two complementary arguments: in Section 4.1 we argue that optimizing the relaxed training objective of Eq. (2) also has the effect of encouraging tightness of training instances; in Section 4.2 we show that tightness generalizes from train to test data."
    }, {
      "heading" : "4.1 Tightness at Training",
      "text" : "We first show that the relaxed training objective in Eq. (2), although designed to achieve high accuracy, also induces tightness of the LP relaxation. In order to simplify notation we focus on a single training instance and drop the index m. Denote the solutions to the relaxed and integer LPs as:\nµL ∈ argmax µ∈ML θ>µ µI ∈ argmax µ∈ML µ∈{0,1}q θ>µ\nAlso, let µT be the integral vector corresponding to the ground-truth output y(m). Now consider the following decomposition:\nθ>(µL − µT ) relaxed-hinge = θ>(µL − µI) integrality gap + θ>(µI − µT ) exact-hinge\n(3)\nThis equality states that the difference in scores between the relaxed optimum and ground-truth (relaxed-hinge) can be written as a sum of the integrality gap and the difference in scores between the exact optimum and the groundtruth (exact-hinge) (notice that all terms are non-negative). This simple decomposition has several interesting implications.\nFirst, we can immediately derive the following bound on the integrality gap:\nθ>(µL − µI) = θ>(µL − µT )− θ>(µI − µT ) (4) ≤ θ>(µL − µT ) (5) ≤ θ>(µL − µT ) + `>µL (6)\n≤ max µ∈ML\n( θ>(µ− µT ) + `>µ ) , (7)\nwhere Eq. (7) is precisely the relaxed training objective from Eq. (2). Therefore, optimizing the approximate training objective of Eq. (2) minimizes an upper bound on the integrality gap. Hence, driving down the approximate objective also reduces the integrality gap of training instances. One case where the integrality gap becomes zero is when the data is algorithmically separable. In this case the relaxed-hinge term vanishes (the exact-hinge must also vanish), and integrality is assured.\nHowever, the bound above might sometimes be loose. Indeed, to get the bound we have discarded the exact-hinge term (Eq. (5)), added the task-loss (Eq. (6)), and maximized the loss-augmented objective (Eq. (7)). At the same time, Eq. (4) provides a precise characterization of the integrality gap. Specifically, the gap is determined by the difference between the relaxed-hinge and the exact-hinge terms. This implies that even when the relaxed-hinge is not zero, a small integrality gap can still be obtained if the exact-hinge is also large. In fact, the only way to get a large integrality gap is by setting the exact-hinge much smaller than the relaxed-hinge. But when can this happen?\nA key point is that the relaxed and exact hinge terms are upper bounded by the relaxed and exact training objectives, respectively (the latter additionally depend on the task loss ∆). Therefore, minimizing the training objective will also reduce the corresponding hinge term (see also Section 5). Using this insight, we observe that relaxed training reduces the relaxed-hinge term without directly reducing the exact-hinge term, and thereby induces a small integrality gap. On the other hand, this also suggests that exact training may actually increase the integrality gap, since it reduces the exact-hinge without also reducing directly the relaxed-hinge term. This finding is consistent with previous empirical evidence. Specifically, Martins et al. (2009b, Table 2) showed that on a dependency parsing problem, training with the relaxed objective achieved 92.88% integral solutions, while exact training achieved only 83.47% integral solutions. An even stronger effect was observed by Finley and Joachims (2008, Table 3) for multi-label classification, where relaxed training resulted in 99.57% integral instances, with exact training attaining only 17.7% (‘Yeast’ dataset).\nIn Section 5 we provide further empirical support for our explanation, however, we next also show its possible limitations by providing a counterexample. The counter-example demonstrates that despite training with a relaxed objective, the exact-hinge can in some cases actually be smaller than the relaxed-hinge, leading to a loose relaxation. Although this illustrates the\nlimitations of the explanation above, we point out that the corresponding learning task is far from natural; we believe it is unlikely to arise in realworld applications.\nSpecifically, we construct a learning scenario where relaxed training obtains zero exact-hinge and non-zero relaxed-hinge, so the relaxation is not tight. Consider a model where x ∈ R3, y ∈ {0, 1}3, and the prediction is given by:\ny(x;w) = argmax y\n( x1y1 + x2y2 + x3y3\n+ w [1{y1 6= y2}+ 1{y1 6= y3}+ 1{y2 6= y3}] ) .\nThe corresponding LP relaxation is then:\nmax µ∈ML\n( x1µ1(1) + x2µ2(1) + x3µ3(1) + w[µ12(01) + µ12(10)\n+ µ13(01) + µ13(10) + µ23(01) + µ23(10)] ) .\nNext, we construct a trainset where the first instance is: x(1) = (2, 2, 2), y(1) = (1, 1, 0), and the second is: x(2) = (0, 0, 0), y(2) = (1, 1, 0). It can be verified that w = 1 minimizes the relaxed objective (Eq. (2)). However, with this weight vector the relaxed-hinge for the second instance is equal to 1, while the exact-hinge for both instances is 0 (the data is separable w.r.t. w = 1). Consequently, there is an integrality gap of 1 for the second instance, and the relaxation is loose (the first instance is actually tight).\nFinally, note that our derivation above (Eq. (4)) holds for any integral µ, and not just the ground-truth µT . In other words, the only property of µT we are using here is its integrality. Indeed, in Section 5 we verify empirically that training a model using random labels still attains the same level of tightness as training with the ground-truth labels. On the other hand, accuracy drops dramatically, as expected. This analysis suggests that tightness is not related to accuracy of the predictor. Finley and Joachims (2008) explained tightness of LP relaxations by noting that fractional solutions always incur a loss during training. Our analysis suggests an alternative explanation, emphasizing the difference in scores (Eq. (4)) rather than the loss, and decoupling tightness from accuracy."
    }, {
      "heading" : "4.2 Generalization of Tightness",
      "text" : "Our argument in Section 4.1 concerns only the tightness of train instances. However, the empirical evidence discussed above pertains to test data. To bridge this gap, in this section we show that train tightness implies test tightness. We do so by proving a generalization bound for tightness based on Rademacher complexity.\nWe first define a loss function which measures the lack of integrality (or, fractionality) for a given instance. To this end, we consider the discrete set of vertices of the local polytope ML (excluding its convex hull), denoting by MI and MF the sets of fully-integral and non-integral (i.e., fractional) vertices, respectively (so MI ∩ MF = ∅, and MI ∪ MF consists of all vertices of ML). Considering vertices is without loss of generality, since linear programs always have a vertex that is optimal. Next, let θx ∈ Rq be the mapping from weights w and inputs x to scores (as used in Eq. (2)), and let I∗(θ) = maxµ∈MI θ >µ and F ∗(θ) = maxµ∈MF θ >µ be the best integral and fractional scores attainable, respectively. By convention, we set F ∗(θ) = −∞ whenever MF = ∅. The fractionality of θ can be measured by the quantity D(θ) = F ∗(θ)− I∗(θ). If this quantity is large then the LP has a fractional solution with a much better score than any integral solution. We can now define the loss:\nL(θ) =\n{ 1 D(θ) > 0\n0 otherwise . (8)\nThat is, the loss equals 1 if and only if the optimal fractional solution has a (strictly) higher score than the optimal integral solution.4 Notice that this loss ignores the ground-truth y, as expected. In addition, we define a ramp loss parameterized by γ > 0 which upper bounds the fractionality loss:\nϕγ(θ) =  0 D(θ) ≤ −γ 1 +D(θ)/γ −γ < D(θ) ≤ 0 1 D(θ) > 0 , (9)\nFor this loss to be zero, the best integral solution has to be better than the best fractional solution by at least γ, which is a stronger requirement than mere tightness. In Section 4.2.1 we give examples of models that are guaranteed to satisfy this stronger requirement, and in Section 5 we also show\n4Notice that the loss will be 0 whenever the non-integral and integral optima are equal, but this is fine for our purpose, since we consider the relaxation to be tight in this case.\nthis often happens in practice. We point out that ϕγ(θ) is generally hard to compute, as is L(θ) (due to the discrete optimization involved in computing I∗(θ) and F ∗(θ)). However, here we are only interested in proving that tightness is a generalizing property, so we will not worry about computational efficiency for now. We are now ready to state the main theorem of this section.\nTheorem 4.1. Let inputs be independently selected according to a probability measure P (X), and let Θ be the class of all scoring functions θX with ‖w‖2 ≤ B. Let ‖φ(x, yc)‖2 ≤ R̂ for all x, c, yc, and q is the total number of factor assignments (dimension of µ). Then for any number of samples M and any 0 < δ < 1, with probability at least 1− δ, every θX ∈ Θ satisfies:\nEP [L(θX)] ≤ ÊM [ϕγ(θX)] +O\n( q1.5BR̂\nγ √ M\n) + √ 8 ln(2/δ)\nM (10)\nwhere ÊM is the empirical expectation.\nProof. Our proof relies on the following general result from Bartlett and Mendelson (2002).\nTheorem 4.2 (Bartlett and Mendelson (2002), Theorem 8). Consider a loss function L : Y × Θ 7→ [0, 1] and a dominating function ϕ : Y × Θ 7→ [0, 1] (i.e., L(y, θ) ≤ ϕ(y, θ) for all y, θ). Let F be a class of functions mapping X to Θ, and let {(x(m), y(m))}Mm=1 be independently selected according to a probability measure P (x, y). Then for any number of samples M and any 0 < δ < 1, with probability at least 1− δ, every f ∈ F satisfies:\nE[L(y, f(x))] ≤ ÊM [ϕ(y, f(x))] +RM (ϕ̃ ◦ f) + √ 8 ln(2/δ)\nM ,\nwhere ÊM is the empirical expectation, ϕ̃◦f = {(x, y) 7→ ϕ(y, f(x))−ϕ(y, 0) : f ∈ F}, and RM(F) is the Rademacher complexity of the class F .\nTo use this result, we define Θ = Rq, f(x) = θx, and F to be the class of all such functions satisfying ‖w‖2 ≤ B and ‖φ(x, yc)‖2 ≤ R̂. In order to obtain a meaningful bound, we would like to bound the Rademacher term RM(ϕ̃◦f). Theorem 12 in Bartlett and Mendelson (2002) states that if ϕ̃ is Lipschitz with constant L and satisfies ϕ̃(0) = 0, then RM(ϕ̃ ◦ f) ≤ 2LRM(F). In addition, Weiss and Taskar (2010) show that RM(F) = O( qBR̂√M ). Therefore, it remains to compute the Lipschitz constant of ϕ̃, which is equal to the Lipschitz constant of ϕ. For this purpose, we will bound the Lipschitz constant\nof D(θ), and then use L(ϕγ(θ)) ≤ L(D(θ))/γ (from Eq. (9)). Let µI ∈ argmaxµ∈MI θ>µ and µF ∈ argmaxµ∈MF θ>µ, then:\nD(θ1)−D(θ2) = (µ1F − µ1I) · θ1 − (µ2F − µ2I) · θ2 = (µ1F · θ1 − µ2F · θ2) + (µ2I · θ2 − µ1I · θ1) = (µ1F · θ1 − µ2F · θ2) + (µ1F · θ2 − µ1F · θ2)\n+ (µ2I · θ2 − µ1I · θ1) + (µ2I · θ1 − µ2I · θ1) = µ1F · (θ1 − θ2) + (µ1F − µ2F ) · θ2\n+ µ2I · (θ2 − θ1) + (µ2I − µ1I) · θ1\n≤ (µ1F − µ2I) · (θ1 − θ2) [optimality of µ2F and µ1I ] ≤ ‖µ1F − µ2I‖2‖θ1 − θ2‖2 [Cauchy-Schwarz] ≤ √q‖θ1 − θ2‖2\nTherefore, L = √ q/γ.\nCombining everything together, and dropping the spurious dependence on y, we obtain the bound in Eq. (10). Finally, we point out that when using an L2 regularizer at training, we can actually drop the assumption ‖w‖2 ≤ B and instead use a bound on the norm of the optimal solution (as in the analysis of Shalev-Shwartz et al. (2011)).\nTheorem 4.1 shows that if we observe high integrality (equivalently, low fractionality) on a finite sample of training data, then it is likely that integrality of test data will not be much lower, provided sufficient number of samples.\nOur result actually applies more generally to any two disjoint sets of vertices, and is not limited to MI and MF . For example, we can replace MI by the set of vertices with at most 10% fractional values, andMF by the rest of the vertices of the local polytope. This gives a different meaning to the loss D(θ), and the rest of our analysis holds unchanged. Consequently, our generalization result implies that it is likely to observe a similar portion of instances with at most 10% fractional values at test time as we did at training."
    }, {
      "heading" : "4.2.1 γ-tight relaxations",
      "text" : "In this section we study the stronger notion of tightness required by our surrogate fractionality loss (Eq. (9)), and show examples of models that\nsatisfy it. We use the following definition. Definition An LP relaxation is called γ-tight if I∗(θ) ≥ F ∗(θ) + γ (so ϕγ(θ) = 0). That is, the best integral value is larger than the best nonintegral value by at least γ.5\nWe focus on binary pairwise models and show two cases where the model is guaranteed to be γ-tight. Proofs are provided in Appendix A. Our first example involves balanced models, which are binary pairwise models that have supermodular scores, or can be made supermodular by “flipping” a subset of the variables (for more details, see Appendix A).\nProposition 4.3. A balanced model with a unique optimum is (α/2)-tight, where α is the difference between the best and second-best (integral) solutions.\nThis result is of particular interest when learning structured predictors where the edge scores depend on the input. Whereas one could learn supermodular models by enforcing linear inequalities, we know of no tractable means of restricting the model to be balanced. Instead, one could learn over the full space of models using LP relaxation. If the learned models are balanced on the training data, Prop. 4.3 together with Theorem 4.1 tell us that the pairwise LP relaxation is likely to be tight on test data as well.\nOur second example regards models with singleton scores that are much stronger than the pairwise scores. Consider a binary pairwise model6 in minimal representation, where θ̄i are node scores and θ̄ij are edge scores in this representation (see Appendix A for full details). Further, for each variable i, define the set of neighbors with attractive edges N+i = {j ∈ Ni|θ̄ij > 0}, and the set of neighbors with repulsive edges N−i = {j ∈ Ni|θ̄ij < 0}.\nProposition 4.4. If all variables satisfy the condition: θ̄i ≥ − ∑ j∈N−i θ̄ij + β, or θ̄i ≤ − ∑ j∈N+i θ̄ij − β\nfor some β > 0, then the model is (β/2)-tight.\nFinally, we point out that in both of the examples above, the conditions can be verified efficiently and if they hold, the value of γ can be computed efficiently.\n5Notice that scaling up θ will also increase γ, but our bound in Eq. (10) also grows with the norm of θ (via BR̂). Therefore, we assume here that ‖θ‖2 is bounded.\n6This case easily generalizes to non-binary variables."
    }, {
      "heading" : "5 Experiments",
      "text" : "In this section we present some numerical results to support our theoretical analysis. We run experiments for both a multi-label classification task and an image segmentation task. For training we have implemented the blockcoordinate Frank-Wolfe algorithm for structured SVM (Lacoste-Julien et al., 2013), using GLPK as the LP solver.7 In all of our experiments we use a standard L2 regularizer, chosen via cross-validation.\nMulti-label classification For multi-label classification we adopt the experimental setting of Finley and Joachims (2008). In this setting labels are represented by binary variables, the model consists of singleton and pairwise factors forming a fully connected graph over the labels, and the task loss is the normalized Hamming distance.\nFig. 2 shows relaxed and exact training iterations for the ‘Yeast’ dataset (14 labels). We plot the relaxed and exact hinge terms (Eq. (3)), the exact and relaxed SSVM training objectives8 (Eq. (1) and Eq. (2), respectively), fraction of train and test instances having integral solutions, as well as test accuracy (measured by F1 score). Whenever a fractional solution was found with relaxed inference, a simple rounding scheme was applied to obtain a valid\n7http://www.gnu.org/software/glpk 8The displayed objective values are averaged over train instances and exclude regular-\nization.\nprediction. First, we note that the relaxed-hinge values are nicely correlated with the relaxed training objective, and likewise the exact-hinge is correlated with the exact objective (left and middle, top). Second, observe that with relaxed training, the relaxed-hinge and the exact-hinge are very close (left, top), so the integrality gap, given by their difference, remains small (almost 0 here). On the other hand, with exact training the exact-hinge is reduced much more than the relaxed-hinge, which results in a large integrality gap (middle, top). Indeed, we can see that the percentage of integral solutions is almost 100% for relaxed training (left, bottom), and close to 0% with exact training (middle, bottom). To get a better understanding, we show a histogram of the difference between the optimal integral and fractional values, i.e., the integrality margin (I∗(θ) − F ∗(θ)), under the final learned model for all training instances (right). It can be seen that with relaxed training this margin is positive (although small), while exact training results in larger negative values. Third, we notice that train and test integrality levels are very close to each other, almost indistinguishable (left and middle, bottom), which provides some empirical support to our generalization result from Section 4.2.\nWe next train a model using random labels (with similar label counts as the true data). In this setting the learned model obtains 100% tight training instances (not shown), which supports our claim that any integral solution can be used in place of the ground-truth, and that accuracy is not important for tightness. Finally, in order to verify that tightness is not coincidental,\nwe tested the tightness of the relaxation induced by a random weight vector w. We found that random models are never tight (in 20 trials), which shows that tightness of the relaxation does not come by chance.\nWe now proceed to perform experiments on the ‘Scene’ dataset (6 labels). The results, in Fig. 3, are quite similar to the ‘Yeast’ results, except for the behavior of exact training (middle) and the integrality margin (right). Specifically, we observe that in this case the relaxed-hinge and exact-hinge are close in value (middle, top), as for relaxed training (left, top). As a consequence, the integrality gap is very small and the relaxation is tight for almost all train (and test) instances. These results show that sometimes optimizing the exact objective can reduce the relaxed objective (and relaxedhinge) as well. Further, in this setting we observe a larger integrality margin (right), which means that the integral optimum is strictly better than the fractional one.\nWe conjecture that the LP instances are easy in this case due to the dominance of the singleton scores.9 Specifically, the features provide a strong signal which allows label assignment to be decided mostly based on the local score, with little influence coming from the pairwise terms. To test this conjecture we repeat the experiment while injecting Gaussian noise into the input features, forcing the model to rely more on the pairwise interactions. We find that with the noisy singleton scores the results are indeed similar to the ‘Yeast’ dataset, where a large integrality gap is observed and fewer instances are tight (see Appendix B in the supplement).\nImage segmentation Finally, we conduct experiments on a foregroundbackground segmentation problem using the Weizmann Horse dataset (Borenstein et al., 2004). The data consists of 328 images, of which we use the first 50 for training and the rest for testing. Here a binary output variable is assigned to each pixel, and there are ∼ 58K variables per image on average. We extract singleton and pairwise features as described in Domke (2013). Fig. 4 shows the same quantities as in the multi-label setting, except for the accuracy measure – here we compute the percentage of correctly classified pixels rather than F1. We observe a very similar behavior to that of the ‘Scene’ multi-label dataset (Fig. 3). Specifically, both relaxed and exact training produce a small integrality gap and high percentage of tight instances. Un-\n9With ILP training, the condition in Prop. 4.4 is satisfied for 65% of all variables, although only 1% of the training instances satisfy it for all their variables.\nlike the ‘Scene’ dataset, here only 1.2% of variables satisfy the condition in Prop. 4.4 (using LP training). In all of our experiments the learned model scores were never balanced (Prop. 4.3), although for the segmentation problem we believe the models learned are close to balanced, both for relaxed and exact training."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper we propose an explanation for the tightness of LP relaxations which has been observed in many structured prediction applications. Our analysis is based on a careful examination of the integrality gap and its relation to the training objective. It shows how training with LP relaxations, although designed with accuracy considerations in mind, also induces tightness of the relaxation. Our derivation also suggests that exact training may sometimes have the opposite effect, increasing the integrality gap.\nTo explain tightness of test instances, we show that tightness generalizes from train to test instances. Compared to the generalization bound of Kulesza and Pereira (2007), our bound only considers the tightness of the instance, ignoring label errors. Thus, for example, if learning happens to settle on a set of parameters in a tractable regime (e.g., supermodular potentials or stable instances (Makarychev et al., 2014)) for which the LP relaxation\nis tight for all training instances, our generalization bound guarantees that with high probability the LP relaxation will also be tight on test instances. In contrast, in Kulesza and Pereira (2007)’s bound, tightness on test instances can only be guaranteed when the training data is algorithmically separable (i.e., LP-relaxed inference predicts perfectly).\nOur work suggests many directions for further study. Our analysis in Section 4.1 focuses on the score hinge and ignores the task loss ∆. It would be interesting to further study the effect of various task losses on tightness of the relaxation at training. Next, our bound in Section 4.2 is intractable to compute due to the hardness of the surrogate loss ϕ. It is therefore desirable to derive a tractable alternative which could be used to obtain a useful guarantee in practice. The upper bound on integrality shown in Section 4.1 holds for other convex relaxations which have been proposed for structured prediction, such as semi-definite programming relaxations (Kumar et al., 2009). However, it is less clear how to extend the generalization result to such non-polyhedral relaxations. Finally, we hope that our methodology will be useful for shedding light on tightness of convex relaxations in other learning problems.\nAppendix"
    }, {
      "heading" : "A γ-Tight LP Relaxations",
      "text" : "In this section we provide full derivations for the results in Section 4.2.1. We make extensive use of the results in Weller et al. (2016) (some of which are restated here for completeness). We start by defining a model in minimal representation, which will be convenient for the derivations that follow. Specifically, in the case of binary variables (yi ∈ {0, 1}) with pairwise factors, we define a value ηi for each variable, and a value ηij for each pair. The mapping between the over-complete vector µ and the minimal vector η is as follows. For singleton factors, we have:\nµi = ( 1− ηi ηi ) Similarly, for the pairwise factors, we have:\nµij =\n( 1 + ηij − ηi − ηj ηj − ηij ,\nηi − ηij ηij\n)\nThe corresponding mapping to minimal parameters is then: θ̄i = θi(1)− θi(0) + ∑ j∈Ni (θij(1, 0)− θij(0, 0))\nθ̄ij = θij(1, 1) + θij(0, 0)− θij(0, 1)− θij(1, 0)\nIn this representation, the LP relaxation is given by (up to constants):\nmax η∈L f(η) := n∑ i=1 θ̄iηi + ∑ ij∈E θ̄ijηij\nwhere L is the appropriate transformation of ML to the equivalent reduced space of η:\n0 ≤ ηi ≤ 1 ∀i max(0, ηi + ηj − 1) ≤ ηij ≤ min(ηi, ηj) ∀ij ∈ E\nIf θ̄ij > 0 (θ̄ij < 0), then the edge is called attractive (repulsive). If all edges are attractive, then the LP relaxation is known to be tight (Wainwright and Jordan, 2008). When not all edges are attractive, in some cases it is possible to make them attractive by flipping a subset of the variables (yi ← 1− yi).10 In such cases the model is called balanced.\nIn the sequel we will make use of the known fact that all vertices of the local polytope are half-integral (take values in {0, 1\n2 , 1}) (Wainwright and\nJordan, 2008). We are now ready to prove the propositions (restated here for convenience).\nA.1 Proof of Proposition 4.3\nProposition 4.3 A balanced model with a unique optimum is (α/2)-tight, where α is the difference between the best and second-best (integral) solutions.\nProof. Weller et al. (2016) define for a given variable i the function F iL(z), which returns for every 0 ≤ z ≤ 1 the constrained optimum:\nF iL(z) = max η∈L ηi=z f(η)\n10The flip-set, if exists, is easy to find by making a single pass over the graph (see Weller (2015) for more details).\nGiven this definition, they show that for a balanced model, F iL(z) is a linear function (Weller et al., 2016, Theorem 6).\nLet m be the optimal score, let η1 be the unique optimum integral vertex in minimal form so f(η1) = m, and any other integral vertex has value at most m − α. Denote the state of η1 at coordinate i by z∗ = η1i , and consider computing the constrained optimum holding ηi to various states. By assumption, any other integral vertex has value at most m−α, therefore,\nF iL(z ∗) = m\nF iL(1− z∗) ≤ m− α\n(the second line holds with equality if there exists a second-best solution η2 s.t. η2i 6= η1i ). Since F iL(z) is a linear function, we have that:\nF iL(1/2) ≤ m− α/2 (11)\nNext, towards contradiction, suppose that there exists a fractional vertex ηf with value f(ηf ) > m− α/2. Let j be a fractional coordinate, so ηfj = 12 (since vertices are half-integral). Our assumption implies that F jL(1/2) > m − α/2, but this contradicts Eq. (11). Therefore, we conclude that any fractional solution has value at most f(ηf ) ≤ m− α/2.\nIt is possible to check in polynomial time if a model is balanced, if it has a unique optimum, and compute α. This can be done by computing the difference in value to the second-best. In order to find the second-best: one can constrain each variable in turn to differ from the state of the optimal solution, and recompute the MAP solution; finally, take the maximum over all these trials.\nA.2 Proof of Proposition 4.4\nProposition 4.4 If all variables satisfy the condition: θ̄i ≥ − ∑ j∈N−i θ̄ij + β, or θ̄i ≤ − ∑ j∈N+i θ̄ij − β\nfor some β > 0, then the model is (β/2)-tight.\nProof. For any binary pairwise models, given singleton terms {ηi}, the optimal edge terms are given by (for details see Weller et al., 2016):\nηij(ηi, ηj) =\n{ min(ηi, ηj) if θ̄ij > 0\nmax(0, ηi + ηj − 1) if θ̄ij < 0\nNow, consider a variable i and let Ni be the set of its neighbors in the graph. Further, define the sets N+i = {j ∈ Ni|θ̄ij > 0} and N−i = {j ∈ Ni|θ̄ij < 0}, corresponding to attractive and repulsive edges, respectively. We next focus on the parts of the objective affected by the value at ηi (recomputing optimal edge terms); recall that all vertices are half-integral:\nηi = 1 ηi = 1/2 ηi = 0 θ̄i + ∑\nj∈N+i ηj=1\nθ̄ij + 1 2 ∑ j∈N+i ηj=\n1 2\nθ̄ij + ∑\nj∈N−i ηj=1\nθ̄ij + 1 2 ∑ j∈N−i ηj=\n1 2\nθ̄ij 1 2 θ̄i + 1 2 ∑ j∈N+i\nηj∈{ 12 ,1}\nθ̄ij + 1 2 ∑ j∈N−i ηj=1 θ̄ij 0\nIt is easy to verify that the condition θ̄i ≥ − ∑\nj∈N−i θ̄ij + β guarantees that\nηi = 1 in the optimal solution. We next bound the difference in objective values resulting from setting ηi = 1/2.\n∆f = 1\n2 θ̄i + ∑ j∈N+i ηj=1 θ̄ij + ∑ j∈N−i\nηj∈{ 12 ,1}\nθ̄ij  ≥ 12 θ̄i + ∑\nj∈N−i\nθ̄ij  ≥ β/2 Similarly, when θ̄i ≤ − ∑ j∈N+i\nθ̄ij−β, then ηi = 0 in any optimal solution. The difference in objective values from setting ηi = 1/2 in this case is:\n∆f = −1 2 θ̄i + ∑ j∈N+i\nηj∈{ 12 ,1}\nθ̄ij + ∑ j∈N−i ηj=1 θ̄ij\n ≥ −12 θ̄i + ∑\nj∈N+i\nθ̄ij  ≥ β/2 Notice that for more fractional coordinates the difference in values can only increase, so in any case the fractional solution is worse by at least β/2."
    }, {
      "heading" : "B Additional Experimental Results",
      "text" : "In this section we present additional experimental results for the ‘Scene’ dataset. Specifically, we inject random Gaussian noise to the input features in order to reduce the signal in the singleton scores and increase the role of the pairwise interactions. This makes the problem harder since the prediction needs to account for global information.\nIn Fig. 5 we observe that with exact training the exact loss is minimized, causing the exact-hinge to decrease, since it is upper bounded by the loss (middle, top). On the other hand, the relaxed-hinge (and relaxed loss) increase during training, which results in a large integrality gap and fewer tight instances. In contrast, with relaxed training the relaxed loss is minimized, which causes the relaxed-hinge to decrease. Since the exact-hinge is upper bounded by the relaxed-hinge it also decreases, but both hinge terms decrease similarly and remain very close to each other. This results in a small integrality gap and tightness of almost all instances.\nFinally, in contrast to other settings, in Fig. 5 we observe that with exact training the test tightness is noticeably higher (about 20%) than the train tightness (Fig. 5, middle, bottom). This does not contradict our bound from Theorem 4.1, since in fact the test fractionality is even lower than the bound suggests. On the other hand, this result does entail that train and test tightness may sometimes behave differently, which means that we might need to increase the size of the trainset in order to get a tighter bound."
    } ],
    "references" : [ {
      "title" : "Predicting Structured Data",
      "author" : [ "G.H. Bakir", "T. Hofmann", "B. Schölkopf", "A.J. Smola", "B. Taskar", "S.V.N. Vishwanathan" ],
      "venue" : null,
      "citeRegEx" : "Bakir et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bakir et al\\.",
      "year" : 2007
    }, {
      "title" : "On cuts and matchings in planar graphs",
      "author" : [ "F. Barahona" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Barahona.,? \\Q1993\\E",
      "shortCiteRegEx" : "Barahona.",
      "year" : 1993
    }, {
      "title" : "Rademacher and gaussian complexities: Risk bounds and structural results",
      "author" : [ "P.L. Bartlett", "S. Mendelson" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Bartlett and Mendelson.,? \\Q2002\\E",
      "shortCiteRegEx" : "Bartlett and Mendelson.",
      "year" : 2002
    }, {
      "title" : "Combining top-down and bottom-up segmentation",
      "author" : [ "E. Borenstein", "E. Sharon", "S. Ullman" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "Borenstein et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Borenstein et al\\.",
      "year" : 2004
    }, {
      "title" : "A linear programming formulation and approximation algorithms for the metric labeling problem",
      "author" : [ "C. Chekuri", "S. Khanna", "J. Naor", "L. Zosin" ],
      "venue" : "SIAM J. on Discrete Mathematics,",
      "citeRegEx" : "Chekuri et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Chekuri et al\\.",
      "year" : 2004
    }, {
      "title" : "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms",
      "author" : [ "M. Collins" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Collins.,? \\Q2002\\E",
      "shortCiteRegEx" : "Collins.",
      "year" : 2002
    }, {
      "title" : "Search-based structured prediction",
      "author" : [ "H. Daumé III", "J. Langford", "D. Marcu" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "III et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "III et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning graphical model parameters with approximate marginal inference",
      "author" : [ "J. Domke" ],
      "venue" : "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
      "citeRegEx" : "Domke.,? \\Q2013\\E",
      "shortCiteRegEx" : "Domke.",
      "year" : 2013
    }, {
      "title" : "Training structural SVMs when exact inference is intractable",
      "author" : [ "T. Finley", "T. Joachims" ],
      "venue" : "In Proceedings of the 25th International Conference on Machine learning,",
      "citeRegEx" : "Finley and Joachims.,? \\Q2008\\E",
      "shortCiteRegEx" : "Finley and Joachims.",
      "year" : 2008
    }, {
      "title" : "How hard is inference for structured prediction",
      "author" : [ "A. Globerson", "T. Roughgarden", "D. Sontag", "C. Yildirim" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Globerson et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Globerson et al\\.",
      "year" : 2015
    }, {
      "title" : "Dual decomposition for parsing with non-projective head automata",
      "author" : [ "T. Koo", "A.M. Rush", "M. Collins", "T. Jaakkola", "D. Sontag" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Koo et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Koo et al\\.",
      "year" : 2010
    }, {
      "title" : "The partial constraint satisfaction problem: Facets and lifting theorems",
      "author" : [ "A. Koster", "S. van Hoesel", "A. Kolen" ],
      "venue" : "Operations Research Letters,",
      "citeRegEx" : "Koster et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Koster et al\\.",
      "year" : 1998
    }, {
      "title" : "Structured learning with approximate inference",
      "author" : [ "A. Kulesza", "F. Pereira" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Kulesza and Pereira.,? \\Q2007\\E",
      "shortCiteRegEx" : "Kulesza and Pereira.",
      "year" : 2007
    }, {
      "title" : "An analysis of convex relaxations for MAP estimation of discrete MRFs",
      "author" : [ "M.P. Kumar", "V. Kolmogorov", "P.H.S. Torr" ],
      "venue" : null,
      "citeRegEx" : "Kumar et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2009
    }, {
      "title" : "Block-coordinate FrankWolfe optimization for structural SVMs",
      "author" : [ "S. Lacoste-Julien", "M. Jaggi", "M. Schmidt", "P. Pletscher" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Lacoste.Julien et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lacoste.Julien et al\\.",
      "year" : 2013
    }, {
      "title" : "Bilulinial stable instances of max cut and minimum multiway cut",
      "author" : [ "K. Makarychev", "Y. Makarychev", "A. Vijayaraghavan" ],
      "venue" : "Proc. 22nd Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "Makarychev et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Makarychev et al\\.",
      "year" : 2014
    }, {
      "title" : "Concise integer linear programming formulations for dependency parsing",
      "author" : [ "A. Martins", "N. Smith", "E.P. Xing" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Martins et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Martins et al\\.",
      "year" : 2009
    }, {
      "title" : "Polyhedral outer approximations with application to natural language parsing",
      "author" : [ "A. Martins", "N. Smith", "E.P. Xing" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "Martins et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Martins et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning max-margin tree predictors",
      "author" : [ "O. Meshi", "E. Eban", "G. Elidan", "A. Globerson" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Meshi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Meshi et al\\.",
      "year" : 2013
    }, {
      "title" : "Advanced Structured Prediction",
      "author" : [ "S. Nowozin", "P.V. Gehler", "J. Jancsary", "C. Lampert" ],
      "venue" : null,
      "citeRegEx" : "Nowozin et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Nowozin et al\\.",
      "year" : 2014
    }, {
      "title" : "On the hardness of approximate reasoning",
      "author" : [ "D. Roth" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Roth.,? \\Q1996\\E",
      "shortCiteRegEx" : "Roth.",
      "year" : 1996
    }, {
      "title" : "Integer linear programming inference for conditional random fields",
      "author" : [ "D. Roth", "W. Yih" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Roth and Yih.,? \\Q2005\\E",
      "shortCiteRegEx" : "Roth and Yih.",
      "year" : 2005
    }, {
      "title" : "On dual decomposition and linear programming relaxations for natural language processing",
      "author" : [ "A.M. Rush", "D. Sontag", "M. Collins", "T. Jaakkola" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Rush et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Rush et al\\.",
      "year" : 2010
    }, {
      "title" : "Pegasos: Primal estimated sub-gradient solver for svm",
      "author" : [ "S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter" ],
      "venue" : "Mathematical programming,",
      "citeRegEx" : "Shalev.Shwartz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Shalev.Shwartz et al\\.",
      "year" : 2011
    }, {
      "title" : "A hierarchy of relaxations between the continuous and convex hull representations for zero-one programming problems",
      "author" : [ "H.D. Sherali", "W.P. Adams" ],
      "venue" : "SIAM J. on Disc. Math.,",
      "citeRegEx" : "Sherali and Adams.,? \\Q1990\\E",
      "shortCiteRegEx" : "Sherali and Adams.",
      "year" : 1990
    }, {
      "title" : "Finding the MAPs for belief networks is NP-hard",
      "author" : [ "Y. Shimony" ],
      "venue" : "Aritifical Intelligence,",
      "citeRegEx" : "Shimony.,? \\Q1994\\E",
      "shortCiteRegEx" : "Shimony.",
      "year" : 1994
    }, {
      "title" : "New outer bounds on the marginal polytope",
      "author" : [ "D. Sontag", "T. Jaakkola" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Sontag and Jaakkola.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sontag and Jaakkola.",
      "year" : 2008
    }, {
      "title" : "Max-margin Markov networks",
      "author" : [ "B. Taskar", "C. Guestrin", "D. Koller" ],
      "venue" : "In Advances in Neural Information Processing Systems. MIT Press,",
      "citeRegEx" : "Taskar et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Taskar et al\\.",
      "year" : 2003
    }, {
      "title" : "Learning associative Markov networks",
      "author" : [ "B. Taskar", "V. Chatalbashev", "D. Koller" ],
      "venue" : "In Proc. ICML. ACM Press,",
      "citeRegEx" : "Taskar et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Taskar et al\\.",
      "year" : 2004
    }, {
      "title" : "Živný. The power of linear programming for valued CSPs",
      "author" : [ "S.J. Thapper" ],
      "venue" : "In FOCS,",
      "citeRegEx" : "Thapper,? \\Q2012\\E",
      "shortCiteRegEx" : "Thapper",
      "year" : 2012
    }, {
      "title" : "Support vector machine learning for interdependent and structured output spaces",
      "author" : [ "I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Tsochantaridis et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Tsochantaridis et al\\.",
      "year" : 2004
    }, {
      "title" : "Graphical Models, Exponential Families, and Variational Inference",
      "author" : [ "M. Wainwright", "M.I. Jordan" ],
      "venue" : "Now Publishers Inc.,",
      "citeRegEx" : "Wainwright and Jordan.,? \\Q2008\\E",
      "shortCiteRegEx" : "Wainwright and Jordan.",
      "year" : 2008
    }, {
      "title" : "MAP estimation via agreement on trees: message-passing and linear programming",
      "author" : [ "M. Wainwright", "T. Jaakkola", "A. Willsky" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Wainwright et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Wainwright et al\\.",
      "year" : 2005
    }, {
      "title" : "Structured Prediction Cascades",
      "author" : [ "D. Weiss", "B. Taskar" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Weiss and Taskar.,? \\Q2010\\E",
      "shortCiteRegEx" : "Weiss and Taskar.",
      "year" : 2010
    }, {
      "title" : "Bethe and related pairwise entropy approximations",
      "author" : [ "A. Weller" ],
      "venue" : "In Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Weller.,? \\Q2015\\E",
      "shortCiteRegEx" : "Weller.",
      "year" : 2015
    }, {
      "title" : "Tightness of LP relaxations for almost balanced models",
      "author" : [ "A. Weller", "M. Rowland", "D. Sontag" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Weller et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Weller et al\\.",
      "year" : 2016
    }, {
      "title" : "Greed is good if randomized: New inference for dependency parsing",
      "author" : [ "Y. Zhang", "T. Lei", "R. Barzilay", "T. Jaakkola" ],
      "venue" : "In EMNLP,",
      "citeRegEx" : "Zhang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Many applications of machine learning can be formulated as prediction problems over structured output spaces (Bakir et al., 2007; Nowozin et al., 2014).",
      "startOffset" : 109,
      "endOffset" : 151
    }, {
      "referenceID" : 19,
      "context" : "Many applications of machine learning can be formulated as prediction problems over structured output spaces (Bakir et al., 2007; Nowozin et al., 2014).",
      "startOffset" : 109,
      "endOffset" : 151
    }, {
      "referenceID" : 21,
      "context" : "Many structured prediction problems can be represented as ILPs (Roth and Yih, 2005; Martins et al., 2009a; Rush et al., 2010).",
      "startOffset" : 63,
      "endOffset" : 125
    }, {
      "referenceID" : 22,
      "context" : "Many structured prediction problems can be represented as ILPs (Roth and Yih, 2005; Martins et al., 2009a; Rush et al., 2010).",
      "startOffset" : 63,
      "endOffset" : 125
    }, {
      "referenceID" : 20,
      "context" : "Despite being NPhard in general (Roth, 1996; Shimony, 1994), various effective approximations have been proposed.",
      "startOffset" : 32,
      "endOffset" : 59
    }, {
      "referenceID" : 25,
      "context" : "Despite being NPhard in general (Roth, 1996; Shimony, 1994), various effective approximations have been proposed.",
      "startOffset" : 32,
      "endOffset" : 59
    }, {
      "referenceID" : 36,
      "context" : "Those include both search-based methods (Daumé III et al., 2009; Zhang et al., 2014), and natural LP relaxations to the hard ILP (Schlesinger, 1976; Koster et al.",
      "startOffset" : 40,
      "endOffset" : 84
    }, {
      "referenceID" : 11,
      "context" : ", 2014), and natural LP relaxations to the hard ILP (Schlesinger, 1976; Koster et al., 1998; Chekuri et al., 2004; Wainwright et al., 2005).",
      "startOffset" : 52,
      "endOffset" : 139
    }, {
      "referenceID" : 4,
      "context" : ", 2014), and natural LP relaxations to the hard ILP (Schlesinger, 1976; Koster et al., 1998; Chekuri et al., 2004; Wainwright et al., 2005).",
      "startOffset" : 52,
      "endOffset" : 139
    }, {
      "referenceID" : 32,
      "context" : ", 2014), and natural LP relaxations to the hard ILP (Schlesinger, 1976; Koster et al., 1998; Chekuri et al., 2004; Wainwright et al., 2005).",
      "startOffset" : 52,
      "endOffset" : 139
    }, {
      "referenceID" : 5,
      "context" : "‘08, Rush & Collins ‘11) Figure 1: Percentage of in egral olutions for dependency parsing from Koo et al. (2010).",
      "startOffset" : 12,
      "endOffset" : 113
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al.",
      "startOffset" : 218,
      "endOffset" : 234
    }, {
      "referenceID" : 35,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016).",
      "startOffset" : 266,
      "endOffset" : 287
    }, {
      "referenceID" : 8,
      "context" : "However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010).",
      "startOffset" : 196,
      "endOffset" : 305
    }, {
      "referenceID" : 10,
      "context" : "However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010).",
      "startOffset" : 196,
      "endOffset" : 305
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al.",
      "startOffset" : 219,
      "endOffset" : 411
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures.",
      "startOffset" : 219,
      "endOffset" : 462
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures. However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.",
      "startOffset" : 219,
      "endOffset" : 828
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures. However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.88% of the test data on a dependency parsing problem (see Table 2 therein). Koo et al. (2010) observed a similar behavior for dependency parsing on a number of languages, as can be seen in Fig.",
      "startOffset" : 219,
      "endOffset" : 1006
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures. However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.88% of the test data on a dependency parsing problem (see Table 2 therein). Koo et al. (2010) observed a similar behavior for dependency parsing on a number of languages, as can be seen in Fig. 1 (kindly provided by the authors). The same phenomenon has been observed for a multi-label classification task, where test integrality reached 100% (Finley and Joachims, 2008, Table 3). Learning structured output predictors from labeled data was proposed in various forms by Collins (2002); Taskar et al.",
      "startOffset" : 219,
      "endOffset" : 1397
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures. However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.88% of the test data on a dependency parsing problem (see Table 2 therein). Koo et al. (2010) observed a similar behavior for dependency parsing on a number of languages, as can be seen in Fig. 1 (kindly provided by the authors). The same phenomenon has been observed for a multi-label classification task, where test integrality reached 100% (Finley and Joachims, 2008, Table 3). Learning structured output predictors from labeled data was proposed in various forms by Collins (2002); Taskar et al. (2003); Tsochantaridis et al.",
      "startOffset" : 219,
      "endOffset" : 1419
    }, {
      "referenceID" : 1,
      "context" : ", Wainwright and Jordan, 2008; Thapper and Živný, 2012), and the cycle relaxation (equivalently, the second-level of the SheraliAdams hierarchy) is known to be tight both for planar Ising models with no external field (Barahona, 1993) and for almost balanced models (Weller et al., 2016). To facilitate efficient prediction, one could restrict the model class to be tractable. For example, Taskar et al. (2004) learn supermodular scores, and Meshi et al. (2013) learn tree structures. However, the sufficient conditions mentioned above are by no means necessary, and indeed, many score functions that are useful in practice do not satisfy them but still produce integral solutions (Roth and Yih, 2004; Sontag et al., 2008; Finley and Joachims, 2008; Martins et al., 2009b; Koo et al., 2010). For example, Martins et al. (2009b) showed that predictors that are learned with LP relaxation yield integral LPs on 92.88% of the test data on a dependency parsing problem (see Table 2 therein). Koo et al. (2010) observed a similar behavior for dependency parsing on a number of languages, as can be seen in Fig. 1 (kindly provided by the authors). The same phenomenon has been observed for a multi-label classification task, where test integrality reached 100% (Finley and Joachims, 2008, Table 3). Learning structured output predictors from labeled data was proposed in various forms by Collins (2002); Taskar et al. (2003); Tsochantaridis et al. (2004). These formulations generalize training methods for binary classifiers, such as the Perceptron algorithm and support vector machines (SVMs), to the case of structured outputs.",
      "startOffset" : 219,
      "endOffset" : 1449
    }, {
      "referenceID" : 21,
      "context" : "A common approach, introduced right at the inception of structured SVMs by Taskar et al. (2003), is to use LP relaxations for this purpose.",
      "startOffset" : 75,
      "endOffset" : 96
    }, {
      "referenceID" : 10,
      "context" : "The most closely related work to ours is Kulesza and Pereira (2007), which showed that not all approximations are equally good, and that it is important to match the inference algorithms used at train and test time.",
      "startOffset" : 41,
      "endOffset" : 68
    }, {
      "referenceID" : 10,
      "context" : "The most closely related work to ours is Kulesza and Pereira (2007), which showed that not all approximations are equally good, and that it is important to match the inference algorithms used at train and test time. The authors defined the concept of algorithmic separability which refers to the setting when an approximate inference algorithm achieves zero loss on a data set. The authors studied the use of LP relaxations for structured learning, giving generalization bounds for the true risk of LP-based prediction. However, since the generalization bounds in Kulesza and Pereira (2007) are focused on prediction accuracy, the only settings in which tightness on test instances can be guaranteed are when the training data is algorithmically separable, which is seldom the case in real-world structured prediction tasks (the models are far from perfect).",
      "startOffset" : 41,
      "endOffset" : 591
    }, {
      "referenceID" : 10,
      "context" : "The most closely related work to ours is Kulesza and Pereira (2007), which showed that not all approximations are equally good, and that it is important to match the inference algorithms used at train and test time. The authors defined the concept of algorithmic separability which refers to the setting when an approximate inference algorithm achieves zero loss on a data set. The authors studied the use of LP relaxations for structured learning, giving generalization bounds for the true risk of LP-based prediction. However, since the generalization bounds in Kulesza and Pereira (2007) are focused on prediction accuracy, the only settings in which tightness on test instances can be guaranteed are when the training data is algorithmically separable, which is seldom the case in real-world structured prediction tasks (the models are far from perfect). Our paper’s main result (Theorem 4.1), on the other hand, guarantees that the expected fraction of test instances for which a LP relaxation is integral is close to that which was estimated on training data. This then allows us to talk about the generalization of computation. For example, suppose one uses LP relaxation-based algorithms that iteratively tighten the relaxation, such as Sontag and Jaakkola (2008); Sontag et al.",
      "startOffset" : 41,
      "endOffset" : 1272
    }, {
      "referenceID" : 10,
      "context" : "The most closely related work to ours is Kulesza and Pereira (2007), which showed that not all approximations are equally good, and that it is important to match the inference algorithms used at train and test time. The authors defined the concept of algorithmic separability which refers to the setting when an approximate inference algorithm achieves zero loss on a data set. The authors studied the use of LP relaxations for structured learning, giving generalization bounds for the true risk of LP-based prediction. However, since the generalization bounds in Kulesza and Pereira (2007) are focused on prediction accuracy, the only settings in which tightness on test instances can be guaranteed are when the training data is algorithmically separable, which is seldom the case in real-world structured prediction tasks (the models are far from perfect). Our paper’s main result (Theorem 4.1), on the other hand, guarantees that the expected fraction of test instances for which a LP relaxation is integral is close to that which was estimated on training data. This then allows us to talk about the generalization of computation. For example, suppose one uses LP relaxation-based algorithms that iteratively tighten the relaxation, such as Sontag and Jaakkola (2008); Sontag et al. (2008), and observes that 20% of the instances in the training data are integral using the pairwise relaxation and that after tightening using cycle constraints the remaining 80% are now integral too.",
      "startOffset" : 41,
      "endOffset" : 1294
    }, {
      "referenceID" : 8,
      "context" : "Finley and Joachims (2008) also studied the effect of various approximate inference methods in the context of structured prediction.",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 8,
      "context" : "Finley and Joachims (2008) also studied the effect of various approximate inference methods in the context of structured prediction. Their theoretical and empirical results also support the superiority of LP relaxations in this setting. Martins et al. (2009b) established conditions which guarantee algorithmic separability for LP relaxed training, and derived risk bounds for a learning algorithm which uses a combination of exact and relaxed inference.",
      "startOffset" : 0,
      "endOffset" : 260
    }, {
      "referenceID" : 8,
      "context" : "Finley and Joachims (2008) also studied the effect of various approximate inference methods in the context of structured prediction. Their theoretical and empirical results also support the superiority of LP relaxations in this setting. Martins et al. (2009b) established conditions which guarantee algorithmic separability for LP relaxed training, and derived risk bounds for a learning algorithm which uses a combination of exact and relaxed inference. Finally, recently Globerson et al. (2015) studied the performance of structured predictors for 2D grid graphs with binary labels from an informationtheoretic point of view.",
      "startOffset" : 0,
      "endOffset" : 497
    }, {
      "referenceID" : 31,
      "context" : "ML is known as the local marginal polytope (Wainwright and Jordan, 2008).",
      "startOffset" : 43,
      "endOffset" : 72
    }, {
      "referenceID" : 24,
      "context" : "This relaxation is the first level of the Sherali-Adams hierarchy (Sherali and Adams, 1990), which provides successively tighter LP relaxations of an ILP.",
      "startOffset" : 66,
      "endOffset" : 91
    }, {
      "referenceID" : 27,
      "context" : "In the structured SVM (SSVM) framework (Taskar et al., 2003; Tsochantaridis et al., 2004), the empirical risk is upper bounded by a convex surrogate called the structured hinge loss, which yields the training objective:",
      "startOffset" : 39,
      "endOffset" : 89
    }, {
      "referenceID" : 30,
      "context" : "In the structured SVM (SSVM) framework (Taskar et al., 2003; Tsochantaridis et al., 2004), the empirical risk is upper bounded by a convex surrogate called the structured hinge loss, which yields the training objective:",
      "startOffset" : 39,
      "endOffset" : 89
    }, {
      "referenceID" : 27,
      "context" : "Fortunately, as in prediction, LP relaxation can be applied to the structured loss (Taskar et al., 2003; Kulesza and Pereira, 2007), which yields the relaxed training objective:",
      "startOffset" : 83,
      "endOffset" : 131
    }, {
      "referenceID" : 12,
      "context" : "Fortunately, as in prediction, LP relaxation can be applied to the structured loss (Taskar et al., 2003; Kulesza and Pereira, 2007), which yields the relaxed training objective:",
      "startOffset" : 83,
      "endOffset" : 131
    }, {
      "referenceID" : 8,
      "context" : "Finley and Joachims (2008) explained tightness of LP relaxations by noting that fractional solutions always incur a loss during training.",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 2,
      "context" : "Our proof relies on the following general result from Bartlett and Mendelson (2002). Theorem 4.",
      "startOffset" : 54,
      "endOffset" : 84
    }, {
      "referenceID" : 2,
      "context" : "Our proof relies on the following general result from Bartlett and Mendelson (2002). Theorem 4.2 (Bartlett and Mendelson (2002), Theorem 8).",
      "startOffset" : 54,
      "endOffset" : 128
    }, {
      "referenceID" : 2,
      "context" : "Theorem 12 in Bartlett and Mendelson (2002) states that if φ̃ is Lipschitz with constant L and satisfies φ̃(0) = 0, then RM(φ̃ ◦ f) ≤ 2LRM(F).",
      "startOffset" : 14,
      "endOffset" : 44
    }, {
      "referenceID" : 2,
      "context" : "Theorem 12 in Bartlett and Mendelson (2002) states that if φ̃ is Lipschitz with constant L and satisfies φ̃(0) = 0, then RM(φ̃ ◦ f) ≤ 2LRM(F). In addition, Weiss and Taskar (2010) show that RM(F) = O( qBR̂ M ).",
      "startOffset" : 14,
      "endOffset" : 180
    }, {
      "referenceID" : 23,
      "context" : "Finally, we point out that when using an L2 regularizer at training, we can actually drop the assumption ‖w‖2 ≤ B and instead use a bound on the norm of the optimal solution (as in the analysis of Shalev-Shwartz et al. (2011)).",
      "startOffset" : 197,
      "endOffset" : 226
    }, {
      "referenceID" : 14,
      "context" : "For training we have implemented the blockcoordinate Frank-Wolfe algorithm for structured SVM (Lacoste-Julien et al., 2013), using GLPK as the LP solver.",
      "startOffset" : 94,
      "endOffset" : 123
    }, {
      "referenceID" : 8,
      "context" : "Multi-label classification For multi-label classification we adopt the experimental setting of Finley and Joachims (2008). In this setting labels are represented by binary variables, the model consists of singleton and pairwise factors forming a fully connected graph over the labels, and the task loss is the normalized Hamming distance.",
      "startOffset" : 95,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : "Image segmentation Finally, we conduct experiments on a foregroundbackground segmentation problem using the Weizmann Horse dataset (Borenstein et al., 2004).",
      "startOffset" : 131,
      "endOffset" : 156
    }, {
      "referenceID" : 3,
      "context" : "Image segmentation Finally, we conduct experiments on a foregroundbackground segmentation problem using the Weizmann Horse dataset (Borenstein et al., 2004). The data consists of 328 images, of which we use the first 50 for training and the rest for testing. Here a binary output variable is assigned to each pixel, and there are ∼ 58K variables per image on average. We extract singleton and pairwise features as described in Domke (2013). Fig.",
      "startOffset" : 132,
      "endOffset" : 440
    }, {
      "referenceID" : 15,
      "context" : ", supermodular potentials or stable instances (Makarychev et al., 2014)) for which the LP relaxation",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "Compared to the generalization bound of Kulesza and Pereira (2007), our bound only considers the tightness of the instance, ignoring label errors.",
      "startOffset" : 40,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : "1 holds for other convex relaxations which have been proposed for structured prediction, such as semi-definite programming relaxations (Kumar et al., 2009).",
      "startOffset" : 135,
      "endOffset" : 155
    }, {
      "referenceID" : 12,
      "context" : "In contrast, in Kulesza and Pereira (2007)’s bound, tightness on test instances can only be guaranteed when the training data is algorithmically separable (i.",
      "startOffset" : 16,
      "endOffset" : 43
    }, {
      "referenceID" : 34,
      "context" : "We make extensive use of the results in Weller et al. (2016) (some of which are restated here for completeness).",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 31,
      "context" : "If all edges are attractive, then the LP relaxation is known to be tight (Wainwright and Jordan, 2008).",
      "startOffset" : 73,
      "endOffset" : 102
    }, {
      "referenceID" : 31,
      "context" : "In the sequel we will make use of the known fact that all vertices of the local polytope are half-integral (take values in {0, 1 2 , 1}) (Wainwright and Jordan, 2008).",
      "startOffset" : 137,
      "endOffset" : 166
    }, {
      "referenceID" : 34,
      "context" : "Weller et al. (2016) define for a given variable i the function F i L(z), which returns for every 0 ≤ z ≤ 1 the constrained optimum: F i L(z) = max η∈L ηi=z f(η)",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 34,
      "context" : "The flip-set, if exists, is easy to find by making a single pass over the graph (see Weller (2015) for more details).",
      "startOffset" : 85,
      "endOffset" : 99
    } ],
    "year" : 2016,
    "abstractText" : "Structured prediction is used in areas such as computer vision and natural language processing to predict structured outputs such as segmentations or parse trees. In these settings, prediction is performed by MAP inference or, equivalently, by solving an integer linear program. Because of the complex scoring functions required to obtain accurate predictions, both learning and inference typically require the use of approximate solvers. We propose a theoretical explanation to the striking observation that approximations based on linear programming (LP) relaxations are often tight on real-world instances. In particular, we show that learning with LP relaxed inference encourages integrality of training instances, and that tightness generalizes from train to test data.",
    "creator" : "LaTeX with hyperref package"
  }
}