{
  "name" : "1204.5859.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On the Complexity of Second-Best Abductive Explanations",
    "authors" : [ "Paolo Liberatore", "Marco Schaerf" ],
    "emails" : [ "liberato@dis.uniroma1.it,", "marco.schaerf@uniroma1.it" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n20 4.\n58 59\nv3 [\ncs .L\nO ]\nWhen we look for abductive explanations of a given set of manifestations, an ordering between possible solutions is often assumed. While the complexity of optimal solutions is already known, in this paper we consider second-best solutions with respect to different orderings, and different definitions of what a second-best solution is.\nKeywords: Abduction; Propositional logic; Knowledge representation techniques; Knowledge-based systems"
    }, {
      "heading" : "1 Introduction",
      "text" : "The three basic reasoning mechanisms used in computational logic are deduction, induction, and abduction [25]. Deduction is the process of drawing conclusions from information and assumptions representing our knowledge of the world, so that the fact “battery is down” together with the rule “if the battery is down, the car will not start” allows concluding “car will not start”. Induction, on the other hand, derives rules from the facts: from the fact that the battery is down and that the car is not starting up, we may conclude the rule relating these two facts. Abduction is the inverse of deduction (to some\n∗DIAG - Sapienza University of Rome, Via Ariosto 25, 00185 Rome, email: liberato@dis.uniroma1.it, phone: +39 347 6906915, corresponding author. †DIAG - Sapienza University of Rome, Via Ariosto 25, 00185 Rome, email: marco.schaerf@uniroma1.it\nextent [7]): from the fact that the car is not starting up, we conclude that the battery is down. In a more complete formalization of this environment there are many explanations for a car not starting up. This is an important difference between abduction and deduction, making the former, in general, more computationally complex.\nA given problem of abduction may have one, none, or even many possible solutions (explanations). Moreover, we need to perform both a consistency check and an inference just to verify an explanation. These facts intuitively explain why abduction is to be expected to be computationally harder than deduction. This observation has indeed been confirmed by theoretical results. Selman and Levesque [28, 27] and Bylander et al. [3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al. [20] analyzed the problem from the point of view of parametrized complexity. All these results proved that abduction is, in general, harder than deduction. The analysis has also shown that several problems are of interest in abduction. Not only the problem of finding an explanation is relevant, but also the problems of checking an explanation, or whether a hypothesis is in some, or all, of the explanations (relevance). Some work on the complexity of abduction from non-classical theories has also been done [16, 15, 6].\nAbduction is also related to the ATMS [10, 26] and to the set of prime implicates of a propositional formula. Indeed, Levesque [22] has proved that ATMS and prime implicates can be used to find the abductive explanations of a literal from a Horn theory. As a result, ATMS and algorithms for finding prime implicants of a formula can be seen as algorithms that solve the problem of abduction; moreover, finding the prime implicates can be seen as a preprocessing phase. Kernel resolution [11] exploits the particular literals of the observation to drive the clause generation process. Using this algorithm, Del Val has been able to derive upper bounds on the number of generated clauses, and to prove that some restricted classes of abduction problems are polynomial [13, 12].\nContrarily to deduction, abduction is driven by heuristic principles to best explain the given observations. This means that even if the best possible\nsolution to a given problem is found, there is no warranty that it represents the actual state. As an example, a light bulb may not turn on because it is broken, but also because a complex set of circumstances caused a black out in the whole town; while the first explanation is more likely and should therefore be the preferred solution to the corresponding abduction problem, it may still be wrong. Therefore, it may make sense not to stop at the first explanation, or even at the set of all possible best explanations, but continue the search for other, less likely solutions.\nOther works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found. The difference is that:\n• in previous works, a problem of abduction is given and the task is to find a solution;\n• in this article, a problem of abduction and a set of its solutions are given, and the aim is to find another solution.\nThe difference is that the solution to be found has to be different from the previous ones. Whenever an ordering of likeliness of explanations is given, these solutions are assumed to be among the best ones, and the task is to find another best explanation. The meaning of “another best” in this definition may take two meaning: in the first one, we exclude the given solutions and search for a best one among the remaining ones; in the second, we search for another best solution of the original (unrestricted) problem. A third question arises from the assumption that the search for the known solutions has produced some additional data that can be used while looking for another one. The complexity under such an assumption can be established using compilability classes [5] and monotonic reductions [23]. These classification frameworks concern decision problems, which have yes/no solutions. The specific problems considered in this article are: check if a set of hypothesis is a solution, and check if a specific hypothesis is in some solution."
    }, {
      "heading" : "2 Definitions",
      "text" : "The process of abduction starts from three elements: a propositional formula T formalizing the domain of interest, a set of variables M representing the\ncurrent manifestations, and another set of variables H representing their possible explanations. In this article, abduction is formally defined as follows.\nDefinition 1 A problem of abduction is a triple 〈H,M, T 〉, where T is a propositional formula, M is a set of propositional variables called manifestations and H is a set of propositional variables called hypotheses, with H ∩M = ∅.\nIntuitively, T describes how the assumptions and manifestations are related. We know that the manifestations M occur, and we want their most likely explanation, where an explanation is a set of assumptions A ⊆ H that implies M and is consistent with T .\nDefinition 2 The set of solutions or explanations of a problem of abduction 〈H,M, T 〉 is the set of all sets of assumptions A ⊆ H such that A ∪ {T} is consistent and A ∪ {T} |= M :\nSOL(〈H,M, T 〉) = {A ⊆ H | A ∪ {T} is consistent and A ∪ {T} |= M}\nIt is easy to show instances having exponentially many solutions. Ideally, each instance should have a single solution, the assumptions that have – in the real world – caused the manifestations. At least, there should be a way for eliminating solutions that are known to be less likely than other ones.\nThis is achieved by employing a preorder over the subsets of H . Given two subsets A,A′ ⊆ H , they are related by A A′ if A is considered more likely than A′. The three preorders considered in this article are:\n• the cardinality-based preorder: A ≤ A′ if and only if |A| ≤ |A′|, where |.| denotes the cardinality of a set; in other words, A is preferred if it contains fewer assumptions than A′;\n• the subset-based preorder: A ⊆ A′; a set of assumptions contained in another one is more likely than it;\n• the void preorder: AEA′ for no pair A,A′ ⊆ H ; it captures the case of no assumption about the relative likeliness of the candidate solutions.\nInstead of considering all solutions to a problem of abduction, one may restrict attention to the most likely ones. Since likeliness is formalized by , this amounts to consider only the minimal solutions.\nDefinition 3 The set of minimal solutions of a problem of abduction 〈H,M, T 〉 with respect to the preorder is:\nSOL (〈H,M, T 〉) = min(SOL(〈H,M, T 〉), )\nIn this definition, min(R, ) is the set of elements of R that are minimal with respect to , that is, the elements r ∈ R such that no r′ exists with r′ r and r 6 r′.\nThe void preorder makes all solutions minimal: SOLE(〈H,M, T 〉) = SOL(〈H,M, T 〉). This allows for the notational simplification of considering only minimal solutions, where the preorder may be E, ≤ or ⊆."
    }, {
      "heading" : "2.1 Second-Best Solution",
      "text" : "In the conditions of perfect knowledge, the set of minimal solutions of a problem of abduction would always contain a single element: the hypotheses that actually caused the manifestations to happen. Unfortunately, such complete information may not be available, leading to more than one minimal solution. Once one is found, it makes sense to continue the search for other ones. This process is formalized as follows.\nDefinition 4 Given a nonempty set of minimal solutions {A1, . . . , Am} ⊆ SOL (〈H,M, T 〉) of a problem of abduction, the set of second-best solutions is:\nNEXT SOL (〈H,M, T 〉, {A1, . . . , Am})\n= min(SOL(〈H,M, T 〉)\\{A1, . . . , Am}), )\nThe case of empty set of given minimal solutions {A1, . . . , Am} is excluded from consideration because it makes second-best solutions the same as the minimal solutions."
    }, {
      "heading" : "2.2 Other Best Solutions",
      "text" : "A second-best solution may not be a minimal solution of the original problem. For example, if {A1, . . . , Am} includes all minimal solutions, all secondbest solutions are not minimal. This is because the definition first excludes\n{A1, . . . , Am} from the set of solutions, and then takes the minimal ones among the remaining ones. If only minimal solutions are of interest, a different definition is more appropriate: given a set of minimal solution, an other-best solution is a minimal solution not in the set of the given ones.\nDefinition 5 Given a nonempty set of minimal solutions {A1, . . . , Am} ⊆ SOL (〈H,M, T 〉) of a problem of abduction, the set of other-best solutions is:\nMIN SOL (P, {A1, . . . , Am}) = SOL (P )\\{A1, . . . , Am}"
    }, {
      "heading" : "2.3 Use of Additional Information",
      "text" : "In the formulation of the two problems of second-best solutions and otherbest solutions, we assumed that some solutions are already known. Of the computation done to find them, what is assumed known is only the final result, that is, the solutions. This is like discarding every intermediate data, even if it could have been useful in the subsequent search for other solutions. For instance, if we were able to prove (during the search for the first solutions) that an assumption h is in all solutions of the problem, then the problem of checking other solutions is simplified (i.e., if a candidate solution does not contain h, it is not a solution).\nIn general, we may assume that the result of the initial search is composed not only of the first solutions, but also of some polynomially sized data structure. This is formalized as follows: given a problem of abduction P = 〈H,M, T 〉 and a set of previous solutions {A1, . . . , Am}, is there a polynomialsized data structure D, depending only on P and the known solutions, such that verifying whether A is a second-best or other best solution is easier than the same check in which D is not known?\nThis problem cannot be solved using the standard complexity classes, because it involves a generic polynomially sized data structure D. The compilability classes [5, 23] characterize this kind of problems. These are summarized in Section 2.5."
    }, {
      "heading" : "2.4 Computational Problems of Abduction",
      "text" : "There are several computational problems that are relevant for abduction, here we list the ones considered in this article.\n• Existence: Decide whether a problem of abduction P = 〈H,M, T 〉 admits a (minimal) solution, that is, SOL(〈H,M, T 〉) is non-empty;\n• Checking: Decide whether a set of hypotheses A is a minimal explanation, that is, whether A ∈ SOL (〈H,M, T 〉);\n• Relevance: Decide whether a hypothesis h belongs to at least a minimal solution of a problem of abduction P = 〈H,M, T 〉, that is, ∃A ∈ SOL (〈H,M, T 〉) such that h ∈ A;\nFinding a solution can be iteratively solved using the Relevance problem: for every h ∈ H , if it is relevant then add it to T , and remove it from H regardless of its relevance. The set of the relevant hypotheses iteratively found in this manner is a solution for the abduction problem. This is therefore a Turing reduction from solution finding to relevance checking, and gives an upper bound to the former problem."
    }, {
      "heading" : "2.5 Computational complexity",
      "text" : "The complexity analysis of the problems of second-best explanation is done in the framework of the polynomial hierarchy and many-one polynomial reductions. A number of books on the topic exist [2, 29, 1]. Decision problems (problems having a yes/no answer) are partitioned in classes of increasing complexity. In summary, the class P contains all problems having solving algorithm that run in time polynomial in the size of their inputs. The class NP is defined in a similar way with the algorithm running on a nondeterministic Turing machine. The class coNP contains all problems whose complement (the problem with reverse yes/no answer of the original problem) is in NP. The class DP contains all problems that can be split into a subproblem in NP and one in coNP, so that the answer is yes if and only if the answers of the two subproblems are yes. The other classes of the polynomial hierarchy considered in this article are defined in terms of oracles, which are subroutines whose running time is neglected. In particular, the class Σp2 contains all problems that are in NP assuming the availability of an oracle solving a subproblem in NP. The class containing all complementary problems is Πp2. The class of problems solvable in polynomial time with a logarithmic number of calls to an oracle for Σp2 is ∆ p 3[log n].\nWhile membership to a complexity class is established by showing an appropriate algorithm (running on deterministic or nondeterministic machines,\nusing oracles or not), proving non-membership a more difficult task. Currently, even the existence of problems in NP that are not in P has never been unconditionally proved, but only under the assumption P6=NP. In particular, that assumption implies that a problem is not in P if every other problem in NP can be reduced to it via a polynomial-time reduction. Such problems are called NP-hard. If they also belong to NP, they are NP complete. The same definitions apply to DP and Πp2. More details about complexity classes and reductions can be found in the cited books on computational complexity [2, 29, 1].\nMost hardness results in this article are proved by translating a problem of abduction to another: for example, the problem of checking a solution to that of checking a second-best solution. The reduction involves proving that certain solutions of the first are turned into solutions of the second. Since being a solution is defined in terms of satisfiability and unsatisfiability, the proofs employ modifications that do not affect these conditions:\n1. if a set implies a formula, the formula can be added to the set;\n2. a formula entailed by the rest of a set can be removed from the set;\n3. if a set contains a literal l and a clause containing l, the latter can be removed; clauses containing the negation of l can be removed this literal; when considering the sign of a literal, a clause written l → s is actually ¬l ∨ s; therefore, l is negated in it;\n4. if a variable b only occurs in formulae that are clauses, and is negated in all of them, these can be removed; the same if b only occurs unnegated;\n5. in particular, if a variable only occurs in a single clause, that clause can be removed;\n6. if a set can be partitioned in subsets not sharing variables, it is satisfiable if and only if each of the subsets is;\n7. renaming variables does not affect satisfiability: if X and X ′ are two sets of variables in bijective correspondence and T a formula, the formula T [X ′/X ] obtained from T by replacing each variable in X with its corresponding variable in X ′ is satisfiable if and only if T is.\nCompilability classes characterize the complexity when preprocessing part of the data is possible [5, 23]. In fact, many computationally hard problems, such as abduction in logical knowledge bases, are such that part of an instance is known well before the rest of it, and remains the same for several subsequent instances of the problem. In these cases, it might be useful to preprocess off-line (compile) this known part so as to simplify the remaining on-line problem. Compilability classes aim at characterizing the complexity of problems when preprocessing is allowed for free (it does not contribute to the complexity). For example, since P is the class of problem solved in polynomial time, the class ‖ P contains all problems that can be solved in polynomial time after preprocessing part of the data. Hardness of these classes are defined in a different way than for the usual complexity classes. However, in many cases hardness can be established as follows: to prove that a problem B, composed of a fixed part and a varying part, is hard for some class of compilability, exhibit a problem A that is hard for the corresponding class of complexity (for example, NP for ‖ NP), such that:\n1. there exists three polynomial-time functions Class : S → N, Repr : N → S and Exte : S ×N → S, where N is the set of natural numbers and S the set of valid inputs to A, such that Class(s) is between 0 and the size of s ∈ S, Class(Repr(n)) = n for every n ∈ N, the answer of A on Exte(s, n) is yes if and only if this is the case for s;\n2. there exists a polynomial-time reduction from A to B such that, the fixed part f of B can be replaced by Repr(Class(f)) without altering the solutions of B.\nThe three functions are called classification, representative and extension functions. The second condition is called representative equivalence. As an example, let B be the problem of deciding whether a clause c is a consequence of a propositional formula F (F |= c), where F is the fixed part (the part that is known in advance and can be preprocessed) and c is the varying part (only known online), and A the problem of deciding whether a 3CNF formula T is satisfiable. In this case, we can define the classification function Class(T ) as the function that returns the number of propositional variables in T , Repr(n) is the function that computes the formula containing all possible distinct 3-clauses over n propositional variables. By construction, Class(Repr(n)) = n for every n ∈ N. We can define Exte(T, n) as follows: let m < n be the number of variables of T , we introduce k = n − m new\nvariables and add to T the clause v ∨ ¬v for each of them. The existence of classification, representative and extension functions together with the representative equivalence property guarantee that it is possible to transform any instance (f, v) of the problem B into one (Repr(Class(f)), v) where the fixed part only depends on the size of f but is otherwise constant. This property allows us to show that, if the problem B is compilable than the problem A would become polynomial. More details would make this introduction longer than the original content of this article. The reader is therefore referred to other articles on compilability classes [5, 23] for more explanations and for examples.\nFor both complexity and compilability, the analysis is performed by turning search problems into decision problems: from finding a solution to verifying it. In the case of abduction, a decision problem is to check whether a subset of H is a minimal solution; finding a solution may instead be solved by repeated solving the problem of relevance: checking the existence of a minimal solution containing a given h ∈ H . This and the corresponding problem of dispensability (no minimal solution contains h) have been analyzed by Eiter and Gottlob [14]. In this article, the problem of relevance is considered with the additional assumption that some solutions are already known, possibly with additional information attached."
    }, {
      "heading" : "3 Second-Best Solution",
      "text" : "In this section we consider the problem of the second-best solutions, as formalized by Definition 4: given a set of minimal solutions, find one that is minimal among the other ones. As common in computational complexity studies, this search problem is turned into a verification problem in order to evaluate its complexity: given an instance of abduction, a set of solutions and a candidate solution, check whether the latter is a second-best solution. A solution can be found by repeatedly solving problems of relevance, which are also analyzed.\nThe technical means to prove the hardness of these problems is the following lemma, showing how to introduce a new minimal solution to a problem of abduction.\nLemma 1 For every problem of abduction P not containing variables s and r, a different problem P ′ can be built in polynomial time such that:\nSOL(P ′) = {s} ∪ {A ∪ {r} | A ∈ SOL(P )}\nProof. Let P = 〈H,M, T 〉 be the original problem of abduction not containing the variables s and r. The problem P ′ = 〈H ′,M ′, T ′〉 is defined as follows, where t is a fresh variable and H ′′ is a set of fresh variables in bijective correspondence to H :\nH ′ = H ∪ {r, s}\nM ′ = {t}\nT ′ = (T [H ′′/H ] ∨ ¬r) ∧ ∧ {h → h′′ | h ∈ H} ∧ ((r ∧ ∧ M) → t) ∧\n(¬s ∨ t) ∧ (¬s ∨ ¬r) ∧ ∧ {¬s ∨ ¬h | h ∈ H}\nThe claim is proved in three steps: first, s is a solution of P ′; second, every solution of P is also a solution of P ′ with the addition of r; third, every solution of P ′ is either s or a solution of P with r added to it.\nSince T ′ contains ¬s ∨ t and ¬s ∨ ¬r, the union {s} ∪ {T ′} implies t and ¬r, and can therefore be by removing all clauses containing one of these literals, resulting in a satisfiable set:\n{s} ∪ {T ′} ≡ s ∧ ∧ {h → h′′ | h ∈ H} ∧ t ∧ ¬r ∧ ∧ {¬h | h ∈ H}\n≡ s ∧ t ∧ ¬r ∧ ∧ {¬h | h ∈ H}\nThe second part of the proof shows that if A ∈ SOL(P ) then A ∪ {r} ∈ SOL(P ′). Since T ′ contains ¬s ∨ ¬r, the union {r} ∪ {T ′} implies ¬s. All clauses containing ¬s can therefore be removed, as well as ¬r from the clauses containing it: A∪{r}∪{T ′} ≡ ∧ A∧r∧T [H ′′/H ]∧ ∧ {h → h′′ | h ∈ H}∧¬s∧(( ∧ M) → t)\nSince A is a solution of P , then A ∪ {T} has a model. This model can be extended to satisfy A ∪ {r, T} by setting each r to true, s to false and h′′ ∈ H ′′ to the same value of the corresponding h ∈ H .\nSince A∪{T} |= M and A∪{r, T ′} imply h → h′′, T [H ′′/H ] and ( ∧\nM) → t, it follows that A ∪ {r, T ′} |= t. This proves that A ∪ {r} is a solution of P ′.\nThe final part of the proof is to show that P ′ has no other solution beside {s} and A ∪ {r} where A is a solution of P . Since T ′ includes ¬s ∨ ¬r and ¬s ∨ ¬h for every h ∈ H , it follows that {s} ∪ {T ′} entails the negation of every variable in H ′ but s; therefore, no solution contains s except {s}.\nRegarding the other solutions, it is now proved that a subset A′ ⊂ H ′ that is satisfiable with T ′ but contains neither s nor r is not a solution. Indeed, if s, r 6∈ A′ then these two variables only occur negated in A′∪{T ′}, and all the clauses containing them can therefore be removed, leading to the following formula:\n∧ A′ ∧ ∧ {h → h′′ | h ∈ H}\nThis formula does not contain t, therefore it does not imply it. This proves that every solutions contain either s or r. Since no solution contain both variables thanks to ¬s ∨ ¬r, a solution not containing s is in the form A∪{r} with A ⊆ H . Remains to be proved that A is a solution of P , in this case.\nSince T ′ contains ¬s∨¬r, it follows that A∪{r, T ′} implies ¬s. Therefore, all clauses containing ¬s can be removed:\n{A} ∪ {r, T ′} ≡\n≡ ∧ A ∧ r ∧ (T [H ′′/H ] ∨ ¬r) ∧ ∧ {h → h′′ | h ∈ H} ∧ ((r ∧ ∧ M) → t) ≡ ∧ A ∧ r ∧ T [H ′′/H ] ∧ ∧ {h → h′′ | h ∈ H} ∧ (( ∧ M) → t) ≡ ∧ A ∧ r ∧ T [H ′′/H ] ∧ ∧\n{h′′ | h ∈ A} ∧ ∧\n{h → h′′ | h ∈ H\\A} ∧ (( ∧ M) → t) (1)\nSince renaming does not affect satisfiability, variables H and H ′′ can be swapped, making {h′′ | h ∈ A} become A and T [H ′′/H ] become T . What results is a set containing A∪ {T}, which is therefore satisfiable. This is the first condition for A being a solution of P .\nThe second part is A ∪ {T} |= M . Since A ∪ {r, T ′} |= t, the set A ∪ {r, T ′,¬t} is inconsistent. Thanks to Equivalence (1), it can be rewritten:\nA ∪ {r, T ′,¬t} ≡\n≡ ∧ A ∧ r ∧ T [H ′′/H ] ∧ ∧\n{h′′ | h ∈ A} ∧ ∧\n{h → h′′ | h ∈ H\\A} ∧ (( ∧ M) → t) ∧ ¬t\n≡ ∧ A ∧ r ∧ T [H ′′/H ] ∧ ∧\n{h′′ | h ∈ A} ∧ ∧\n{h → h′′ | h ∈ H\\A} ∧ ¬( ∧ M) ∧ ¬t\nFormulae ∧\nA, r, ¬s, ¬t and h → h′′ with h 6∈ A contain variables occurring only once in the set. Removing them results in T [H ′′/H ]∧¬\n∧ M∧∧\n{h′′ | h ∈ A}. By renaming H ′′ to H , this is ∧ A ∧ T ∧ ¬ ∧\nM . Its unsatisfiability implies A ∪ {T} |= M .\nThis lemma shows how to add the new solution {s} to a given problem of abduction. This addition makes the problem of finding a solution in the old instance equivalent to finding a solution different from {s} in the new one. The solution {s} is minimal with respect to the three considered orderings, since no solution of the form {r} ∪ A is contained or has less literals than it. Since the problem modification can be performed in polynomial time, it shows that if the problem of checking a minimal solution is hard for some complexity class, then the corresponding problem of second-best solution checking is hard for the same class. As a result, in the following complexity characterizations of the second-best solution problems the hardness parts are all proved by a simple reference to this lemma.\nThis lemma provides a reduction from the problem of checking whether H ∈ SOLE(〈H,M, T 〉) to that of checking whether H ∈ NEXT SOLE(〈H,M, T 〉, {A1, . . . , Am}), therefore proving the hardness of the second problem from the hardness of the first. Verifying a solution with the empty preorder is mentioned to be DP-hard by Eiter and Gottlob [14], but as far it was possible to verify no formal proof was published to date. The claim is proved for the particular candidate solution ∅; since this is minimal if it is a solution, hardness holds for all considered orderings.\nLemma 2 Checking whether ∅ ∈ SOL(〈H,M, T 〉) is DP-hard.\nProof. This property is stated by Eiter and Gottlob [14] for an arbitrary candidate solution as an easy corollary of their results, but as far as we know,\nno proof has been published, possibly because of its extreme simplicity: by translating formulae F and G over variables X into the problem of abduction 〈∅, {m}, T 〉, where T = F ∧ (¬G[X ′/X ] → m), X ′ is a set of fresh variables in one-to-one correspondence with X and m a fresh variable. This is a reduction from the sat-unsat problem of checking whether F is satisfiable and G is unsatisfiable to the problem of checking whether ∅ is a solution of 〈∅, {m}, T 〉. Indeed, ∅ ∪ {T} is equivalent to F ∧ (¬G[X ′/X ] → m). This formula is satisfiable if and only if F is satisfiable, since the rest is satisfied by the model where m is true. This means that ∅ is a solution if and only if F is satisfiable and ∅ ∪ {T} |= m. The latter condition is equivalent to the unsatisfiability of F ∧ (¬G[X ′/X ] → m) ∧ ¬m, which is equivalent to F ∧G[X ′/X ] ∧ ¬m. Since F is satisfiable and does not share variables with the rest of the formula, and the same for ¬m, the formula is unsatisfiable if and only if G[X ′/X ] is unsatisfiable. Since satisfiability is unaffected by variable name change, this proves that ∅ is a solution of 〈∅, {m}, T 〉 if and only if F is satisfiable and G is unsatisfiable. This reduction proves that the problem is DP-hard.\nThe complexity of checking whether a set of hypotheses is a solution is an easy consequence of this lemma.\nTheorem 1 Checking whether A ∈ SOL(〈H,M, T 〉) is DP-complete.\nProof. Membership follows from the problem being defined as the satisfiability of A ∪ {T} and the unsatisfiability of A ∪ {T,¬ ∧ M}. Lemma 2 proves that the problem is hard even in the particular case A = ∅.\nTogether with Lemma 1, this result proves that the second-best solution problem is DP-hard for E. It is also a member of this class, as the following theorem proves.\nTheorem 2 Deciding whether A ∈ NEXT SOLE(〈H,M, T 〉, {A1, . . . , Am}) is DP-complete.\nProof. By definition, E is the empty preorder: AEA′ never holds. All solutions are minimal according to this preorder. Reworded: the set of minimal solutions coincides with the set of all solutions.\nThe problem is in DP because it can be solved by first checking whether A∪{T} |= M and then whether A∪{T} is consistent and A is different from each element of {A1, . . . , Am}. The subproblem A ∪ {T} |= M is in coNP.\nThe rest of the problem can be solved by nondeterministically generating every possible propositional model over the considered variables and checking whether it satisfies A∪ {T} and whether A is different from each element of {A1, . . . , Am}; both steps can be done in polynomial time; as a result, the problem is in DP.\nHardness is a consequence of Lemma 2, since ∅ is minimal with respect to set cardinality. As a result, ∅ is a solution if and only if it is a ≤-minimal solution.\nRelevance is harder than verification. Intuitively, the complexity increase is due to the necessity of searching for a solution, among the possibly many ones, that contains the hypothesis h to be checked for relevance.\nTheorem 3 Given 〈H,M, T 〉 and h ∈ H, deciding the existence of A such that h ∈ A and A ∈ NEXT SOLE(〈H,M, T 〉, {A1, . . . , Am}) is Σ p 2-complete.\nProof. The problem can be solved by a nondeterministic algorithm employing an oracle for the propositional satisfiability problem. The algorithm nondeterministically generates each possible A ⊆ H and calls the oracle for the satisfiability of A ∪ {T} and of A ∪ {T,¬ ∧ M}. If the first is satisfiable, the second is unsatisfiable, h ∈ A and A is different than each element of {A1, . . . , Am}, the algorithm returns yes: h is relevant. Since the nondeterministic machine returns yes if some of its nondeterministic runs return yes, this algorithm establishes the existence of a solution containing h.\nHardness is a consequence of a result by Eiter and Gottlob [14, Theorem 4.1.1] and Lemma 1. Indeed, the lemma shows how a problem of abduction P can be used to build another one P ′ that has the same solutions of P with {r} added to each, plus the single new solution {s}. This provides a reduction: h is in some solutions of P if and only if h is in some solutions of P ′ different from {s}. Since the first problem is Σp2-hard [14, Theorem 4.1.1], the latter is Σp2-hard as well.\nThe containment preorder ⊆ limits the solutions to those that do not include any hypothesis that could be removed, that is, the unnecessary ones. This for example rules out {h1, h2} if {h1} is a solution. The additional requirement of minimality does not increase the cost of verifying a solution, which remains DP-complete as for the case of the empty preorder.\nTheorem 4 Checking whether A ∈ SOL⊆(〈H,M, T 〉) is DP-complete.\nProof. The problem is in DP because it can be solved by a number of parallel satisfiability and unsatisfiability checks. Indeed, that A is a solution is equivalent to the satisfiability of A ∪ {T} and the unsatisfiability of A ∪ {T,¬ ∧ M}. The first condition implies the satisfiability of A′∪{T} for every A′ ⊆ A. As a result, A is not a minimal solution only if there exists A′ ⊂ A such that A′∪{T} |= M . This implies A\\{h}∪{T} |= M for every h ∈ A\\A′ by monotonicity of |=. The converse also holds: A is not minimal if such h exists, since A\\{h} ⊂ A for every h ∈ A. As a result, A is a minimal solution if and only if:\n• A ∪ {T} is consistent; • A\\{h} ∪ {T,¬ ∧ M} is consistent for every h ∈ A; • A ∪ {T,¬ ∧ M} is inconsistent.\nThese tests are in polynomial number and can be done in parallel by renaming the variables. As a result, the whole problem amounts to checking whether a formula is satisfiable and another is not.\nHardness is a direct consequence of Lemma 2, which proves that establishing whether ∅ ∈ SOL(〈H,M, T 〉) is DP-hard. Since ∅ is contained in every other subset of H , if any, it is a minimal solution if and only if it is a solution. As a result, ∅ ∈ SOL⊆(〈H,M, T 〉) is DP-hard.\nGiven this result, the problem of checking a second-best solution can be proved to be complete for the same class.\nTheorem 5 Deciding whether A ∈ NEXT SOL⊆(〈H,M, T 〉, {A1, . . . , Am}〉) is DP-complete.\nProof. Membership is proved as in the previous theorem, with two variants. First, A is not a second-best solution if is in {A1, . . . , Am}. Second, the check for consistency of A\\{h}∪{T,¬ ∧ M} is skipped if A\\{h} is in {A1, . . . , Am}.\nHardness is proved by Lemma 1 and the previous theorem, showing the problem with no given solution DP-hard. The lemma proves that A′ is in SOL(〈H ′,M ′, T ′〉) if and only if either A′ = {s} or A′ = A ∪ {r} with A ∈ SOL(〈H,M, T 〉), which means that the solution {s} is minimal. As a result, in NEXT SOL⊆(〈H\n′,M ′, T ′〉, {{s}}) the second argument {{s}} is a set of minimal solutions of the first, 〈H ′,M ′, T ′〉. The solutions of 〈H ′,M ′, T ′〉 not in {{s}} are those A ∪ {r} with A ∈ SOL(〈H,M, T 〉). Since s is not\nin 〈H,M, T 〉, a solution A ∪ {r} does not contain s, which means that it is minimal if and only if A is minimal. This is therefore a reduction from checking a minimal solution of 〈H,M, T 〉 to that of checking a second-best solution in NEXT SOL⊆(〈H\n′,M ′, T ′〉, {{s}}). Since the former proved is DP-hard by the previous theorem, the latter is hard for the same class.\nThis result establishes the complexity of verifying a solution of an abduction problem in presence of other minimal solutions. Searching for a solution can be turned into the decision problem of relevance (checking the existence of solutions with a given h ∈ H) as already explained. Relevance for the subset preorder is Σp2-complete [14, Theorem 4.2.1]. Lemma 1 shows how to carry the hardness part of this result to the case where other minimal solutions are known.\nTheorem 6 Existence of a solution in NEXT SOL⊆(〈H,M, T 〉, {A1, . . . , Am}) containing a given h ∈ H is Σp2-complete.\nProof. Membership can be proved by nondeterministically generating all possible subsets A ofH and then checking (possibly using the oracle) whether h ∈ A, whether A 6∈ {A1, . . . , Am}, whether A ∪ {T} is consistent, whether A∪{T} |= M and whether A\\{h′}∪{T} 6|= M for all A\\{h′} 6∈ {A1, . . . , Am} with h′ ∈ A.\nHardness is a consequence of the hardness result without the given solutions {A1, . . . , Am}, since Lemma 1 implies that A ∈ SOL⊆(〈H,M, T 〉) if and only if A ∪ {r} ∈ NEXT SOL⊆(〈H\n′,M ′, T ′〉, {{s}}). As a result, h is in some element of SOL⊆(〈H,M, T 〉) if and only if it is in some element of NEXT SOL⊆(〈H\n′,M ′, T ′〉, {{s}}). This is a reduction from relevance without given solutions to relevance for second-best solutions, proving the Σp2-hardness of the latter.\nLet ≤ be the preorder of solution defined by cardinality. As for E and ⊆, the hardness of the problems of verification and relevance is proved by reducing to the them the corresponding problems without the given solutions. The following theorem shows the complexity of the verification problem.\nTheorem 7 Checking whether A ∈ SOL≤(〈H,M, T 〉) is Π p 2-complete.\nProof. Non-membership can be verified with a nondeterministic algorithm employing an oracle for solving the satisfiability problem. Given an abduction problem and a subset A ⊆ H , the algorithm nondeterministically generates\neach possible A′ ⊆ H . After this A′ is produced, the following checks are done, with the help of the oracle: that either A ∪ {T} is unsatisfiable, or A ∪ {T,¬ ∧ M} is satisfiable, or the following three conditions hold: |A′| < |A|, A′ ∪ {T} is consistent and A′ ∪ {T,¬ ∧\nM} is inconsistent. If all these hold, then either A is not a solution or smaller solution A′ exists.\nHardness is proved by reduction from the problem of non-relevance, which Eiter and Gottlob [14, Theorem 4.2.1] proved to be Σp2-complete even if the formula T is consistent [14, Definition 2.1.1]. Given a problem of abduction 〈H,M, T 〉 and h ∈ H , a ≤-minimal solution of 〈H,M, T 〉 containing h exists if and only if S is not a ≤-minimal solution of the problem 〈H ′,M ′, T ′〉 defined as follows.\nH ′ = H ∪ Z ∪ S\nM ′ = M ∪ {w}\nT ′ = T [h′′/h][M ′′/M ] ∧ ∧ {m′′ → m | m ∈ M} ∧\n(h → h′′) ∧ (h → w) ∧ ( ∧ S → ∧ M ′)\nIf |H| = n, then S is a set of n+1 fresh variables. Also h′′ and w are fresh variables and M ′′ is a set of fresh variables in one-to-one correspondence with M .\nRegardless of the original problem, S is a solution of 〈H ′,M ′, T ′〉. Indeed, S ∪{T ′} contains S and ∧ S → M ′, which imply M ′. Remains to prove that S ∪ {T ′} is consistent. By definition, M ′ = M ∪ {w}. All subformulae of T ′ are entailed by M ′ but T [h′′/h][M ′′/M ] and h → h′′ and can therefore be removed without affecting consistency. Since S is a set of fresh variables, none is in T [h′′/h][M ′′/M ] ∧ (h → h′′). This formula is consistent because T is consistent. As a result, S ∪ {T ′} is consistent, proving that S is a solution of 〈H ′,M ′, T ′〉.\nThe solutions of 〈H ′,M ′, T ′〉 are further characterized (as proved below) to contain one of the following:\n1. a solution of 〈H,M, T 〉 that contains h;\n2. S.\nSince |S| = n+1 while a solution of the original problem has size between 0 and |H| = n, it follows that S is a minimal-size solution if and only if the original problem has no solution containing h. This is therefore a reduction from non-relevance to solution checking. Since relevance is Σp2-hard, the problem of solution checking would be Πp2-hard. Remains to prove that every solution of 〈H ′,M ′, T ′〉 contains one of the two sets above.\nLet A′ be a solution of 〈H ′,M ′, T ′〉. If A′ does not contain si ∈ S then si only occur negated in A ′ ∪ {T ′} and A′ ∪ {T ′,¬ ∧ M}, in particular in\nthe formula ∧ S → ∧\nM . Therefore, this formula can be removed without affecting consistency. The other variables of S may only occur once (in A′). They can therefore be removed as well. This proves that if a solution of 〈H ′,M ′, T ′〉 does not contain all of S then removing all elements of S from it leads to another solution.\nIf A′ is a solution not intersecting S, then A′ ∩ H is a solution of the original problem. This is proved as follows. The set A′ ∪ {T ′} contains (A′ ∩ H) ∪ {T [h′′/h][M ′′/M ], h → h′′}. Since the first is consistent, the second is consistent as well. Replacing each m′′ with m and swapping h and h′′ transforms T [h′′/h][M ′′/M ] into T . Since variable name changes do not affect satisfiability, the resulting set (A′ ∩H) ∪ {T, h′′ → h} is consistent. It contains (A′ ∩H) ∪ {T}, whose consistency is the first condition for A′ ∩H being a solution of 〈H,M, T 〉.\nThe second is (A′∩H)∪{T} |= m for every m ∈ M . Since A′∪{T ′} |= M ′ and M ⊆ M ′, it also holds A′∪{T ′} |= m for every m ∈ M . This is the same as the inconsistency of A′ ∪ {T ′,¬m}. Since w only occurs in the clauses h → w and ∧ S → w, and is positive in both, these can be removed without affecting satisfiability. The same for the variables of S, which only occur negated, and the variables of M\\{m}, which only occur unnegated. Some further simplifications can be done:\nA′ ∪ {T [h′′/h][M ′′/M ]} ∪ {h → h′′, m′′ → m,¬m} ≡\n≡ A′ ∪ {T [h′′/h][M ′′/M ], h → h′′,¬m′′,¬m}\nIn this formula, h and m only occur once and can therefore be removed. What remains is A′∪{T [h′′/h][M ′′/M ],¬m′′}. Renaming M ′′ to M and h′′ to h does not affect satisfiability; therefore, the set A′∪{T,¬m} is unsatisfiable.\nSince the variables in S may only occur once in this set, in A′, they can be removed. The result is (A′ ∩ H) ∪ {T,¬m}. Since the changes did not\naffect satisfiability and the original set was unsatisfiable, so is this one. As a result, (A′ ∩ H) ∪ {T} |= m. Since this holds for every m ∈ M , and the satisfiability of (A′ ∩ H) ∪ {T} was already proved, A′ ∩ H is a solution of 〈H,M, T 〉.\nWhat remains to be proved is that either A′ contains h or the whole S. To the contrary, assume that A′ does not contain h and does not contain some si ∈ S. Since w ∈ M\n′, formula A′∪{T ′}∧¬w is unsatisfiable. If A′ does not contain h and does not contain si, these variables occur in A\n′ ∪ {T ′} ∧ ¬w only in the clauses h → w and ∧ S → ∧ M ′. All these occurrences of h and si are negated; therefore, these clauses can be removed without affecting satisfiability. Since these are the only subformulae ofA′∪{T ′}∧¬w containing w, what remains is a subformula of A′∪{T ′}, which is consistent because A′ is a solution. This contradiction proves that every solution of 〈H ′,M ′, T ′〉 contains either h or the whole S.\nThe following theorem shows the complexity of the second best solution verification problem with the cardinality-based preorder.\nTheorem 8 Deciding whether A ∈ NEXT SOL≤(〈H,M, T 〉, {A1, . . . , Am}〉) is Πp2-complete.\nProof. Membership is proved as follows: A is a second-best solution if it is in SOL(〈H,M,R〉) and for every A′ ⊆ H such that |A′| < |A| it holds that either A′ ∪ {T} is inconsistent, A′ ∪ {T} 6|= M or A′ ∈ {A1, . . . , Am}. All these checks can be done with an NP oracle, once a subset A′ ⊆ H is nondeterministically generated.\nHardness is proved by the reduction of Lemma 1, using m = 1 and {A1, . . . , Am} = {{s}}. As the lemma proves, {s} is indeed a solution, and is also among its minimal ones because all other ones (if any) have the form H ∪ {r}, so they have cardinality larger or equal than one.\nThe lemma also proves that every solution to the original problem is translated into a solution of the new one. This reduction preserves the relative size of explanations, as they are all added one element. As a result, the solutions are not only all translated, but maintain their relative size. Therefore, A∪ {r} ∈ NEXT SOL≤(〈H\n′,M ′, T ′〉, {{s}}) holds if and only if"
    }, {
      "heading" : "A ∈ SOL≤(〈H,M, T 〉) holds.",
      "text" : "The problem of existence of a second-best solution with a given element of H can be shown to be ∆p3[log n]-complete.\nTheorem 9 Existence of a solution in NEXT SOL≤(〈H,M, T 〉, {A1, . . . , Am}) containing a given h ∈ H is ∆p3[log n]-complete.\nProof. The problem of checking for the existence of a solution A with size bounded by a number k and containing h is in Σp2, as it amounts to nondeterministically generating a solution and then checking it for being a second best-solution and for its size being less than or equal to k. The problem of relevance can be therefore solved by a binary search for the minimal size of solutions [14, Theorem 4.3.2]: start with k = |H|/2, and if the result is positive change k = |H|3/4, otherwise k = |H|/4. Once the minimal size is found, the problem can be solved by nondeterministically generating all solutions of this size not being in {A1, . . . , Am} and then checking whether h is in some of them.\nHardness follows from Lemma 1: h is ≤-relevant to 〈H,M, T 〉 if and only if a solution of NEXT SOL≤(〈H\n′,M ′, T ′〉, {{s}}) containing h exists; this is proved like in the previous theorem. Since ≤-relevance is ∆p3[logn]-hard [14, Theorem 4.3.2], also checking for solutions of NEXT SOL≤(〈H,M, T 〉, {A1, . . . , Am}) containing a given h ∈ H is ∆p3[logn]-hard."
    }, {
      "heading" : "4 Other Minimal Solution",
      "text" : "The implicit assumption in second-best solutions is that non-minimal solutions are taken into account once all minimal ones have been considered. Indeed, the definition of NEXT SOL(〈H,M, T 〉, {A1, . . . , Am}) includes all solutions that are minimal once A1, . . . , Am are removed from consideration. A different approach is to only allow minimal solutions. This is different in that:\n• second-best solutions are solutions that are minimal among the ones different from the given ones;\n• other minimal solutions are solutions that are minimal and are not among the given ones.\nThe difference is that the first definition allows non-minimal solutions if the minimal ones are all among the given ones. The second definition does not. The difference only concerns non-minimal solutions. Therefore, it\ndisappears when the void preorder E is considered, as no solution is nonminimal according to it.\nWhen using ⊆ or ≤, the two definitions may lead to different results, like in the problem:\nH = {s, r}\nM = {t}\nT = {s → t}\nThe problem 〈H,M, T 〉 has two explanations: {s} and {s, r}. Only the first one is minimal in the two considered preorders; this is also intuitively correct, as r does not really contribute to entail t. However, the second-best solutions include this non-minimal one: NEXT SOL≤(〈H,M, T 〉, {{s}}) = {{s, r}}. Such a possibility is excluded when considering the other minimal solutions: no one exists apart from {s}.\nWhen ⊆ is used as the preorder, the complexity of checking another minimal solution is the same as that for a second-best solution. This can be proved as for the proof of Theorem 5 with minimal changes: for membership, sets A\\{h} are checked even if they are in {A1, . . . , Am}; hardness is proved with the very same reduction, which maps minimal solutions of the original problem into solutions of the new problems that are both second-best solutions and other solutions.\nOther best solutions are easier than second-best, if using ≤: DP-complete. The following lemma shows how to relate the solutions of a problem to the minimal solutions of another problem. This property will be used to prove that we can reduce the problem of checking a solution to the problem of checking another minimal solution.\nLemma 3 Let P = 〈H,M, T 〉 be a problem of abduction, where H = {h1, . . . , hn}. Let P\n′ = 〈H ′,M ′, T ′〉 be the problem defined as follows, where"
    }, {
      "heading" : "C, D, and E are sets of n fresh variables each.",
      "text" : "H ′ = C ∪D\nM ′ = M ∪ E\nT ′ = T ∪ {ci → hi, ci → ei, di → ei | 1 ≤ i ≤ n}\nIt holds:\nSOL≤(〈H ′,M ′, T ′〉) = {{ci | hi ∈ A}∪{di | hi 6∈ A} | A ∈ SOL(〈H,M, T 〉)}\nProof. Intuitively, ei ∈ M ′ enforces either ci or di to be in every solution, and minimization excludes solutions containing both. Since every ci entails hi, M is entailed only if the ci’s correspond to the original solutions. Since a solution not containing ci contains di, each solution of P is mapped into a minimal solution of P ′.\nFormally, the claim is proved in three steps: in the first, every solution of P is proved to be translatable into a solution of P ′; in the second, every solution of P ′ can be translated back to a solution of P ; in the third, every minimal solution of P ′ is shown to contain di if and only if it does not contain ci. These three steps prove the claim.\nLet A be a solution of P , and A′ = {ci ∈ C | hi ∈ A}∪{di ∈ D | hi 6∈ A}. The first step of the proof is to show that A′ is a solution of P ′. Since A∪{T} is consistent, it has a model. It can be extended to the new variables by setting ci to the same value of hi and all di’s and ei’s to true. This model satisfies A and T , and also all implications ci → hi because ci is true if and only if hi is true, and ci → ei and di → ei because ei is true. Therefore, A′ ∪ {T ′} is consistent.\nEntailment A′ ∪ {T ′} |= M ∪ E also holds. Since A is a solution of the original problem, A ∪ {T} |= M holds. Since A′ contains every ci such that hi ∈ A, and T ′ contains ci → hi, it follows that A ′ ∪ {T ′} |= A. As a result, A′ ∪ {T ′} |= M . Since A′ contains either ci or di for every i ∈ {1, . . . , n} by construction, and T ′ contains ci → ei and di → ei, it follows that A\n′∪{T ′} |= E. This proves that A′ is a solution of P ′.\nThe second step is to prove that every solution A′ of P ′ can be translated back to a solution of P . In particular, this holds with A = {hi | ci ∈ A\n′}. Consistency of A∪{T} is a consequence of the consistency of A′∪{T ′}, since this formula contains T , A′ ∩ C and {ci → hi}, the latter two implying A.\nEntailment A ∪ {T} |= M is a consequence of A′ ∪ {T ′} |= M ′ and M ⊆ M ′, which imply A′∪{T ′} |= M . This holds if and only if A′∪{T ′,¬mi} is inconsistent for every mi ∈ M . In this set, ei only occurs in ci → ei and di → ei, unnegated in both. As a result, these two clauses can be removed without affecting consistency. After this operation, if di still occurs is in A ′,\nunnegated. It can therefore be removed. What remains is the following set, which can be simplified by the usual methods:\n(A′ ∩ C) ∪ {ci → hi | 1 ≤ i ≤ n} ∪ {T,¬mi}\n≡ (A′ ∩ C) ∪ {hi | ci ∈ A ′} ∪ {ci → hi | ci 6∈ A} ∪ {T,¬mi} ≡ (A′ ∩ C) ∪ A ∪ {ci → hi | ci 6∈ A ′} ∪ {T,¬mi}\nEach ci occurs in a single clause: if ci ∈ A ′ then ci is only in A ′ ∩ C; if ci 6∈ A\n′ then it is only in ci → hi. As a result, all clauses containing ci can be removed without affecting consistency, leading to A∪{T,¬mi}. This proves that A ∪ {T} |= mi. This holds for every mi ∈ M ; therefore, A ∪ {T} |= M .\nThe final part of the proof is to show that all minimal solutions contain either ci or di but not both. This claim can be divided in two: that no solution lacks both ci and di for some i, and that every solution that contains both is not minimal.\nLet A′ be a solution that contains neither ci nor di for an arbitrary index i. The set A′ ∪ {T ′,¬ei} contains ci and di only in the clauses ci → hi, ci → ei and di → ei, negated in all. As a result, these clauses can be removed without affecting consistency. The consequence of this deletion is that ei only occurs negated, and can therefore be removed. What remains is a subet of A′∪{T ′}, which is consistent because A′ is a solution. This proves that ei is not entailed, contradicting the assumption that A\n′ is a solution. Solutions of P ′ may contain both ci and di for some i. However, this solution is not minimal, since di can be removed from it. Let A ′ be a solution containing both ci and di. Since A ′ ∪ {T ′} is consistent, so is A′\\{di} ∪ {T ′}. Remains to prove that A′\\{h} ∪ {T ′} |= M ′, which amounts to the inconsistency of A′\\{h}∪{T ′,¬ ∧ M ′}. Since ci ∈ A, then ci → ei implies ei. As a result, ei can be added to the set, and di → ei removed. What remains is a formula that contains di only unnegated, as part of A\n′. It can therefore be removed without affecting inconsistency.\nThis lemma maps each solution of P into a ≤-minimal solution of P ′, and viceversa. It therefore provides a reduction from the problem of second-best solutions with the void preorder E to the problem of other minimal solution with the cardinality preorder ≤.\nTheorem 10 The problem of checking another minimal solution w.r.t. ≤ is DP-complete.\nProof. Given {A1, . . . , Am} with m ≥ 1, one can check whether A is another minimal solution by expressing |A| = |A1| as a propositional formula F using fresh variables. Then, the problem amounts to the satisfiability of A∪{T, F} and the unsatisfiabity of A ∪ {T,¬ ∧ M}.\nHardness follows the DP-hardness of the problem of verifying A ∈ NEXT SOLE(〈H,M, T 〉, {A1, . . . , Am}). Indeed, Lemma 3 proves that solutions A,A1, . . . , Am of 〈H,M, T 〉 can be turned into ≤-minimal solutions A′, A′1, . . . , A ′ m of 〈H\n′,M ′, T ′〉. As a result, A is a solution of 〈H,M, T 〉 not in {A1, . . . , Am} if and only if A\n′ is a minimal solution of 〈H ′,M ′, T ′〉 not in {A′1, . . . , A ′ m}. Since the first problem is DP-hard, the second is DP-hard as well."
    }, {
      "heading" : "5 Using Additional Information",
      "text" : "In the previous sections we have shown that the abduction problems remain intractable even if we know a first solution. It seems that knowing a solution does not help in reducing the computational complexity. In this section we investigate whether during the search for the first solution, we could obtain and store additional information (not just the solution) that allows for a faster search for another solution. The complexity of such a problem can be evaluated using compilability classes [5] and self reductions [23].\nIn short, a problem has the same complexity with and without additional information if the part of the problem instance the additional information derives from can be “moved” to the rest of the instance; this is called a compilability self reduction; more details are in Section 2.5 and the cited articles. For abduction, the additional information comes from 〈H,M, T 〉, the rest of the instance is the subset A ⊆ H to check.\nThe problems analyzed in the previous sections have the same complexity if T is restricted to be a 3CNF: a set of clauses, each comprising exactly three literals. Since T is now a set, γ ∈ T can be used to indicate that the clause γ is in T . Let Var(T ) be the set of all propositional variables used by T , that is, the alphabet of T .\nGiven a set of variables X (for example, X = Var(T ) ∪ H ∪ M in the following proofs), ΠX denotes the set of all possible clauses of three literals over alphabet X . If |X| = n, the number of possible literals is 2n; this means that the number of possible clauses of three literals is less than 2n×2n×2n = 8 × n3, a polynomial in n. The clauses of ΠX are considered enumerated,\nand called γ1, γ2, γ3, . . .. Self reductions for problems of logics usually employ this construction.\nThe first application of this concept is to the problem of verification with the void preorder.\nLemma 4 If P = 〈H,M, T 〉 is a problem of abduction with T in 3CNF and A ⊆ H let P ′ = 〈H ′,M ′, T ′〉 and A′ be defined as follows, where X = Var(T ) ∪ H ∪ M (hence, T ⊆ ΠX) and C is a set of fresh variables in one-to-one correspondence with ΠX .\nA′ = A ∪ {ci | γi ∈ T} H ′ = H ∪ C\nM ′ = M\nT ′ = {ci → γi | γi ∈ ΠX}"
    }, {
      "heading" : "It holds:",
      "text" : "A ∈ SOL(〈H,M, T 〉) iff A′ ∈ SOL(〈H ′,M ′, T ′〉)\nProof. The first part of the proof is that A ∪ T is consistent if and only if A′ ∪ T ′ is consistent. Since {ci, ci → γi} is equivalent to {ci, γi}, it holds:\nA′ ∪ T ′ ≡ A ∪ {ci | γi ∈ T} ∪ {ci → γi | γi ∈ ΠX}\n≡ A ∪ {ci | γi ∈ T} ∪ {ci → γi | γi ∈ T} ∪ {ci → γi | γi ∈ ΠX\\T}\n≡ A ∪ {ci | γi ∈ T} ∪ {γi | γi ∈ T} ∪ {ci → γi | γi ∈ ΠX\\T}\n≡ A ∪ {ci | γi ∈ T} ∪ T ∪ {ci → γi | γi ∈ ΠX\\T}\nIn this formula, each ci appears once, either in {ci | . . .} or in {ci → γi | . . .}. As a result, these clauses can be removed without affecting satisfiability. The result is A ∪ {T}, proving that this set and A′ ∪ {T ′} are equisatisfiable.\nThe second part of the proof is that A ∪ T ∪ {¬ ∧\nM} is consistent if and only if A′ ∪ T ′ ∪ {¬ ∧ M} is consistent. Thanks to the above chain of equivalences, A′ ∪ T ′ can be rewritten as A ∪ {ci | γi ∈ T} ∪ {T} ∪ {ci → γi | γi ∈ ΠX\\T}. Therefore: A′∪T ′∪{¬ ∧ M} ≡ A∪{ci | γi ∈ T}∪T∪{ci → γi | γi ∈ ΠVar(T )\\T}∪{¬ ∧ M}\nAgain, each ci only occur once in this formula. Therefore, all clauses containing it can be removed, leading to the equisatisfiable formula A ∪ T ∪ {¬ ∧ M}. Therefore, A′ ∪ T ′ |= M if and only if A ∪ T |= M .\nThis lemma provides a self-reduction for the problem of solution checking for the empty preorder. In order to derive a proof of compilability hardness from it, the three functions of classification, representativeness and extensions are needed.\nIn this section, all abduction problems are assumed to be built over an alphabet Hn ∪Mn ∪Xn for some n, where:\nH = {h1, . . . , hn}\nM = {m1, . . . , mn}\nX = {x1, . . . , xn}\nThis is not a restriction: if the variables are not these ones, they can be renamed; if |H| < |M | new variables can be added to H ; if |Var(T )\\H\\M | < |H| new variables can be added to T ; for M , the new variables are also added to T .\nThe classification, representative and extension functions are defined over pairs 〈A, 〈H,M, T 〉〉 where 〈H,M, T 〉 is a problem of abduction and A ⊆ H a candidate solution for it. The class of the pair I = 〈A, 〈H,M, T 〉〉 is its number of assumptions, why coincide with its number of manifestations and the number of other variables in the instance.\nClass(I) = |H|\nThe representative instance of the class n has n variables of each type:\nRepr(m) = 〈∅, 〈Hn,Mn,ΠHn∪Mn∪Xn〉〉\nThe extension function is obtained by adding new variables. If Class(I) = n and m > n then:\nExt(〈A, 〈H,M, T 〉〉, m) = 〈A, 〈H ′,M ′, T ′〉〉 where:\nH ′ = H ∪ {hn+1, . . . , hm} M ′ = M ∪ {mn+1, . . . , mm}\nT ′ = T ∪ {mn+1, . . . , mm} ∪ {xn+1, . . . , xm}\nThis instance has m assumptions, meaning that Class(〈A, 〈H,M, T 〉〉) = m, as required to the extension function. The second requirement is that of equivalence: A is a solution of 〈H,M, T 〉 if and only if A is a solution of 〈H ′,M ′, T ′〉. This holds because in A ∪ T ′ and A ∪ T ′ ∪ {¬ ∧ M} the new variables hn+1, . . . , hm only occur once (in A), the new variables xn+1, . . . , xm only once (in T ), and the new variables mn+1, . . . , mm in T and M but unnegated in both. All these new variables can therefore be removed without affecting consistency.\nThis proves the existence of the classification, representative and extension function for the problem of second-best solution verification. Since solutions are not changed by the extension function, these can be used with all of the considered preorders: void, set-based and cardinality-based.\nThe following results require problems of abductions to be restricted to the case where the formula T is in 3CNF. Lemma 2 and Theorem 7 instead employ reductions that produce come clauses that have more than three literals. In particular, the first turns G into ¬G[X ′/X ] → m and the second introduces ∧ S → ∧ M ′. Both can be turned into clauses, but in general with more than three literals. The following lemma shows how to turn a formula in 3CNF without altering the abductive solutions.\nLemma 5 If l1 and l2 are two literals, C a clause and x a fresh variable, then SOL(〈H,M, T∧(l1∨l2∨C)〉) = SOL(〈H,M, T∧(l1∨l2∨x)∧(¬x∨C)〉).\nProof. Every model M of T ∧ (l1 ∨ l2 ∨ C) satisfies either l1 ∨ l2 or C. A model of (l1 ∨ l2 ∨ x) ∧ (¬x ∨C) can be constructed by setting x to false in the first case and to false in the second. In the other way around, if M is a model of (l1 ∨ l2 ∨ x) ∧ (¬x ∨ C) then it assigns x to either true or flase. In the first case M satisfies C, in the second l1 ∨ l2.\nThis not only proves that the two formulae are equisatisfiable, but that they have the same models apart from the value of x. Since x 6∈ H and x 6∈ M , it follows that B∪{T∧(l1∨l2∨C)} and B∪{(l1∨l2∨x)∧(¬x∨C)} are also equisatisfiable for every B ⊆ H ∪ {¬m | m ∈ M}. Since the abductive solutions are defined in terms of the satisfiability of T with a subset of H with possibly the negation of an element of M , the claim is proved.\nA simple iteration of this lemma to all clauses of T made of more than three literals proves that the problems of abduction are unchanged by the restriction to clauses of three literals.\nTheorem 11 The problem of deciding whether A ⊆ H is in SOL(〈H,M, T 〉) is ‖ DP-complete.\nProof. Membership follows from that in DP, which was proved in a previous section, and the fact that every compilability class ‖ C contains the relative complexity class C [5].\nLet 〈A, 〈Hn,Mn, T 〉〉 be a pair of class n. By definition, the representative element of the class n is a pair 〈A′, 〈H ′,M ′, T ′〉〉 in the same class n. The class being the same implies that H ′ = Hn, M ′ = Mn and Var(T ′)\\H ′\\M ′ = Var(T ′)\\H ′\\M ′. In other words, 〈H ′,M ′, T ′〉 has the same hypotheses Hn, manifestations Mn and other variables Xn of 〈H,M, T 〉.\nA reduction satisfies representative equivalence if and only if 〈A, 〈Hn,Mn, T 〉〉 and 〈A, 〈H\n′,M ′, T ′〉〉 are translated into equivalent instances. In both pairs the candidate solution is A, but in the second the problem of abduction 〈H,M, T 〉 is replaced by the one of the representative instance 〈H ′,M ′, T 〉. The reduction of the previous lemma translates 〈A, 〈Hn,Mn, T 〉〉 and 〈A, 〈H\n′,M ′, T ′〉〉 into the same pair 〈A, 〈H ′′,M ′′, T ′′〉〉, since A is translated into A and the problem of abduction into one that depends only on its variables; since 〈H,M, T 〉 and 〈H ′,M ′, T 〉 have the same variables, they are translated into the same problem. The results of translation are therefore the same instance, which means that it is a self reduction. Since the problem of checking whether A is a solution of 〈H,M, T 〉 is DPhard even in the restriction of clauses of three literals thanks to Lemma 5 and has the required classification, representativeness and extension functions, it is also ‖ DP-hard.\nThe lemma provides a reduction from solutions to solutions, but cannot be used with ⊆ and ≤, as A may not be minimal because of another explanation A′ that does not contain a ci ∈ A. The point is that ci ∈ A indicates the presence of γi ∈ T , and should therefore not be included in the minimization.\nThe problem is solved using a construction similar to that of Lemma 3: for each ci introduce an hypothesis di and a manifestation ei, and the clauses ci → ei and di → ei in T . This way, the variables ci are not considered in the minimization.\nLemma 6 Given P = 〈H,M, T 〉 and A ⊆ H, construct P ′ and A′ as follows.\nA′ = A ∪ {ci | γi ∈ T} ∪ {di | γi 6∈ T}\nH ′ = H ∪ C ∪D\nM ′ = M ∪ E\nT ′ = {ci → ei | ci ∈ C} ∪ {di → ei | di ∈ D} ∪ {ci → γi | γi ∈ ΠVar(T )}\nThe sets C, D, and E are sets new variables in one-to-one correspondence with ΠVar(T ), where Var(T ) is the set of propositional variables of T . It holds:\nA ∈ SOL⊆(〈H,M, T 〉) iff A ′ ∈ SOL⊆(〈H ′,M ′, T ′〉)\nThe proof is omitted because of its similarity with that of Lemma 3. The instance that results from this transformation can be further modified as explained above to make the number of assumptions, manifestations and other variables to be the same.\nThe following theorem shows that the case of set-containment is not different from the case of the empty preorder, in the sense that compiling 〈H,M, T 〉 does not lower complexity.\nTheorem 12 The problem of checking solutions using ⊆ is ‖ Πp2 complete.\nProof. The problem is in Πp2; therefore, it is also in ‖ Π p 2. Hardness is proved by the reduction in the previous lemma: since 〈H ′,M ′, T ′〉 only depends on the class of 〈A, 〈H,M, T 〉〉, this translation satisfies the condition of representative equivalence. The classification, representative, and extension functions are the ones shown before. Since the problem is Πp2-hard this proves that it is also ‖ Πp2-hard\nThe problem with ≤ is ‖ DP-complete. Indeed, from 〈H,M, T 〉 one can calculate the size of its minimal solutions, and then use this number to determine whether a set of hypotheses is a minimal solution. The previous lemma provides a proof of hardness for the same class, in the same way as in the previous theorem. The proof is omitted because of its similarity with the previous one.\nTheorem 13 Checking whether a solution is minimal w.r.t. ≤ is ‖ DPcomplete."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this article, we have investigated the problem of finding a solution to a given abduction problem when some solutions have already been found. The results show that the analyzed problems are computationally intractable, but this does not rule out the possibility of tackling them. It only suggests the most appropriate tools to use. Polynomial problems are best attacked using deterministic polynomial algorithms, while problems in NP can be solved using reduction to the propositional satisfiability problem (SAT) and then passed to a state of the art SAT solver (for example, one of the contestants in the SAT competition http://www.satcompetition.org/). Problems in higher classes of the polynomial hierarchy (such as all the problems shown in the paper) can be solved by a reduction to the Quantified Boolean Formulae problem (QBF) and the use of QBF solvers (http://qbf.satisfiability.org/gallery/). Problems higher up in the polynomial hierarchy are more complex to solve, but, by identifying the precise complexity, we can better take advantage of the solvers.\nThere are some open questions and some possible future directions of work. It makes sense to establish the complexity of finding a k-th best solution, at least in the case of ordering based on cardinality. This can be seen as a variant of the problems studied in this article where the given solutions are not known.\nAnother question left open by this article is to find a reduction from the problem of second-best solutions to simple abductions that preserve the explanations. What is needed is the opposite of Lemma 1, which shows how to add a given explanation to an abduction problem: a reduction that eliminates some given solutions from an abduction problem while leaving the other ones unchanged."
    } ],
    "references" : [ {
      "title" : "Computational Complexity: A Modern Approach",
      "author" : [ "S. Arora", "B. Barak" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Introduction to the Theory of Complexity. Prentice-Hall international series in computer science",
      "author" : [ "D. Bovet", "P. Crescenzi" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1994
    }, {
      "title" : "Some results concerning the computational complexity of abduction",
      "author" : [ "T. Bylander", "D. Allemang", "M.C. Tanner", "J.R. Josephson" ],
      "venue" : "In Proceedings of the First International Conference on the Principles of Knowledge Representation and Reasoning",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1989
    }, {
      "title" : "The computational complexity of abduction",
      "author" : [ "T. Bylander", "D. Allemang", "M.C. Tanner", "J.R. Josephson" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1991
    }, {
      "title" : "Preprocessing of intractable problems",
      "author" : [ "M. Cadoli", "F.M. Donini", "P. Liberatore", "M. Schaerf" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2002
    }, {
      "title" : "The complexity of conjunctive query abduction in DL-Lite",
      "author" : [ "D. Calvanese", "M. Ortiz", "M. Simkus", "G. Stefanoni" ],
      "venue" : "In Proceedings of the twentyfourth International Workshop on Description Logics",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Abduction is not deduction-in-reverse",
      "author" : [ "M. Cialdea Mayer", "F. Pirri" ],
      "venue" : "Journal of the IGPL,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1996
    }, {
      "title" : "Complexity classifications for propositional abduction in post’s framework",
      "author" : [ "N. Creignou", "Schmidt. J", "M. Thomas" ],
      "venue" : "J. Log. Comput.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "A complete classification of the complexity of propositional abduction",
      "author" : [ "N. Creignou", "B. Zanuttini" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2006
    }, {
      "title" : "An assumption-based TMS",
      "author" : [ "J. de Kleer" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1986
    }, {
      "title" : "A new method for consequence finding and compilation in restricted languages",
      "author" : [ "A. Del Val" ],
      "venue" : "In Proceedings of the Sixteenth National Conference on Artificial Intelligence",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "The complexity of restricted consequence finding and abduction",
      "author" : [ "A. Del Val" ],
      "venue" : "In Proceedings of the Seventeenth National Conference on Artificial Intelligence (AAAI",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2000
    }, {
      "title" : "On some tractable classes in deduction and abduction",
      "author" : [ "A. Del Val" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2000
    }, {
      "title" : "The complexity of logic-based abduction",
      "author" : [ "T. Eiter", "G. Gottlob" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1995
    }, {
      "title" : "Abduction from logic programs: Semantics and complexity",
      "author" : [ "T. Eiter", "G. Gottlob", "N. Leone" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1997
    }, {
      "title" : "Semantics and complexity of abduction from default theories",
      "author" : [ "T. Eiter", "G. Gottlob", "N. Leone" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1997
    }, {
      "title" : "On computing all abductive explanations",
      "author" : [ "T. Eiter", "K. Makino" ],
      "venue" : "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Abduction and the dualization problem",
      "author" : [ "T. Eiter", "K. Makino" ],
      "venue" : "In Discovery Science,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2003
    }, {
      "title" : "Generating all abductive horn theories",
      "author" : [ "T. Eiter", "K. Makino" ],
      "venue" : "In Seventeenth International Workshop on Computer Science Logic,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "The parameterized complexity of abduction",
      "author" : [ "M.R. Fellows", "A. Pfandler", "F.A. Rosamond", "S. Rümmele" ],
      "venue" : "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Counting complexity of propositional abduction",
      "author" : [ "M. Hermann", "R. Pichler" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2010
    }, {
      "title" : "A knowledge-level account of abduction",
      "author" : [ "H.J. Levesque" ],
      "venue" : "In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1989
    }, {
      "title" : "Monotonic reductions, representative equivalence, and compilation of intractable problems",
      "author" : [ "P. Liberatore" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2001
    }, {
      "title" : "What makes propositional abduction tractable",
      "author" : [ "G. Nordh", "B. Zanuttini" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2008
    }, {
      "title" : "Abduction and induction",
      "author" : [ "C.S. Peirce" ],
      "venue" : "Philosophical Writings of Peirce,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1955
    }, {
      "title" : "Foundations of assumption-based truth maintenace systems: Preliminary report",
      "author" : [ "R. Reiter", "J. de Kleer" ],
      "venue" : "In Proceedings of the Sixth National Conference on Artificial Intelligence",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1987
    }, {
      "title" : "Support set selection for abductive and default reasoning",
      "author" : [ "B. Selman", "H. Levesque" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1996
    }, {
      "title" : "Abductive and default reasoning: A computational core",
      "author" : [ "B. Selman", "H.J. Levesque" ],
      "venue" : "In Proceedings of the Eighth National Conference on Artificial Intelligence",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1990
    }, {
      "title" : "Introduction to the Theory of Computation",
      "author" : [ "M. Sipser" ],
      "venue" : "International Thomson Publishing,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "The three basic reasoning mechanisms used in computational logic are deduction, induction, and abduction [25].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 6,
      "context" : "extent [7]): from the fact that the car is not starting up, we conclude that the battery is down.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 27,
      "context" : "Selman and Levesque [28, 27] and Bylander et al.",
      "startOffset" : 20,
      "endOffset" : 28
    }, {
      "referenceID" : 26,
      "context" : "Selman and Levesque [28, 27] and Bylander et al.",
      "startOffset" : 20,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 3,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 13,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 8,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 7,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 189,
      "endOffset" : 192
    }, {
      "referenceID" : 23,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 272,
      "endOffset" : 276
    }, {
      "referenceID" : 16,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 344,
      "endOffset" : 356
    }, {
      "referenceID" : 17,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 344,
      "endOffset" : 356
    }, {
      "referenceID" : 18,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 344,
      "endOffset" : 356
    }, {
      "referenceID" : 20,
      "context" : "[3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of computing all abductive explanations, Hermann and Pichler [21] proved the complexity of counting the number of solutions, Fellow et al.",
      "startOffset" : 441,
      "endOffset" : 445
    }, {
      "referenceID" : 19,
      "context" : "[20] analyzed the problem from the point of view of parametrized complexity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "Some work on the complexity of abduction from non-classical theories has also been done [16, 15, 6].",
      "startOffset" : 88,
      "endOffset" : 99
    }, {
      "referenceID" : 14,
      "context" : "Some work on the complexity of abduction from non-classical theories has also been done [16, 15, 6].",
      "startOffset" : 88,
      "endOffset" : 99
    }, {
      "referenceID" : 5,
      "context" : "Some work on the complexity of abduction from non-classical theories has also been done [16, 15, 6].",
      "startOffset" : 88,
      "endOffset" : 99
    }, {
      "referenceID" : 9,
      "context" : "Abduction is also related to the ATMS [10, 26] and to the set of prime implicates of a propositional formula.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 25,
      "context" : "Abduction is also related to the ATMS [10, 26] and to the set of prime implicates of a propositional formula.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 21,
      "context" : "Indeed, Levesque [22] has proved that ATMS and prime implicates can be used to find the abductive explanations",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 10,
      "context" : "Kernel resolution [11] exploits the particular literals of the observation to drive the clause generation process.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 12,
      "context" : "Using this algorithm, Del Val has been able to derive upper bounds on the number of generated clauses, and to prove that some restricted classes of abduction problems are polynomial [13, 12].",
      "startOffset" : 182,
      "endOffset" : 190
    }, {
      "referenceID" : 11,
      "context" : "Using this algorithm, Del Val has been able to derive upper bounds on the number of generated clauses, and to prove that some restricted classes of abduction problems are polynomial [13, 12].",
      "startOffset" : 182,
      "endOffset" : 190
    }, {
      "referenceID" : 27,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 26,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 2,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 3,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 13,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 8,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 7,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 23,
      "context" : "Other works studied the complexity of finding a solution for a problem of abduction [28, 27, 3, 4, 14, 9, 8, 24]; this one considers the problem of finding another solution once some other ones have been found.",
      "startOffset" : 84,
      "endOffset" : 112
    }, {
      "referenceID" : 4,
      "context" : "The complexity under such an assumption can be established using compilability classes [5] and monotonic reductions [23].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 22,
      "context" : "The complexity under such an assumption can be established using compilability classes [5] and monotonic reductions [23].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 4,
      "context" : "pilability classes [5, 23] characterize this kind of problems.",
      "startOffset" : 19,
      "endOffset" : 26
    }, {
      "referenceID" : 22,
      "context" : "pilability classes [5, 23] characterize this kind of problems.",
      "startOffset" : 19,
      "endOffset" : 26
    }, {
      "referenceID" : 1,
      "context" : "A number of books on the topic exist [2, 29, 1].",
      "startOffset" : 37,
      "endOffset" : 47
    }, {
      "referenceID" : 28,
      "context" : "A number of books on the topic exist [2, 29, 1].",
      "startOffset" : 37,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "A number of books on the topic exist [2, 29, 1].",
      "startOffset" : 37,
      "endOffset" : 47
    }, {
      "referenceID" : 1,
      "context" : "More details about complexity classes and reductions can be found in the cited books on computational complexity [2, 29, 1].",
      "startOffset" : 113,
      "endOffset" : 123
    }, {
      "referenceID" : 28,
      "context" : "More details about complexity classes and reductions can be found in the cited books on computational complexity [2, 29, 1].",
      "startOffset" : 113,
      "endOffset" : 123
    }, {
      "referenceID" : 0,
      "context" : "More details about complexity classes and reductions can be found in the cited books on computational complexity [2, 29, 1].",
      "startOffset" : 113,
      "endOffset" : 123
    }, {
      "referenceID" : 4,
      "context" : "Compilability classes characterize the complexity when preprocessing part of the data is possible [5, 23].",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 22,
      "context" : "Compilability classes characterize the complexity when preprocessing part of the data is possible [5, 23].",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 4,
      "context" : "The reader is therefore referred to other articles on compilability classes [5, 23] for more explanations and for examples.",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 22,
      "context" : "The reader is therefore referred to other articles on compilability classes [5, 23] for more explanations and for examples.",
      "startOffset" : 76,
      "endOffset" : 83
    }, {
      "referenceID" : 13,
      "context" : "This and the corresponding problem of dispensability (no minimal solution contains h) have been analyzed by Eiter and Gottlob [14].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 13,
      "context" : "Verifying a solution with the empty preorder is mentioned to be DP-hard by Eiter and Gottlob [14], but as far it was possible to verify no formal proof was published to date.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : "This property is stated by Eiter and Gottlob [14] for an arbitrary candidate solution as an easy corollary of their results, but as far as we know,",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : "The complexity of such a problem can be evaluated using compilability classes [5] and self reductions [23].",
      "startOffset" : 78,
      "endOffset" : 81
    }, {
      "referenceID" : 22,
      "context" : "The complexity of such a problem can be evaluated using compilability classes [5] and self reductions [23].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "Membership follows from that in DP, which was proved in a previous section, and the fact that every compilability class ‖ C contains the relative complexity class C [5].",
      "startOffset" : 165,
      "endOffset" : 168
    } ],
    "year" : 2015,
    "abstractText" : "When we look for abductive explanations of a given set of manifestations, an ordering between possible solutions is often assumed. While the complexity of optimal solutions is already known, in this paper we consider second-best solutions with respect to different orderings, and different definitions of what a second-best solution is.",
    "creator" : "LaTeX with hyperref package"
  }
}