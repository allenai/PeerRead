{"conference": "ICLR 2017 conference submission", "title": "A Context-aware Attention Network for Interactive Question Answering", "abstract": "We develop a new model for Interactive Question Answering (IQA), using Gated-Recurrent-Unit recurrent networks (GRUs) as encoders for statements and questions, and another GRU as a decoder for outputs. Distinct from previous work, our approach employs context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. Employing these mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input. When available, user's feedback is encoded and directly applied to update sentence-level attention to infer the answer. Extensive experiments on QA and IQA datasets demonstrate quantitatively the effectiveness of our model with significant improvement over conventional QA models.", "reviews": [{"is_meta_review": true, "comments": "This paper proposes an \"interactive\" version of the bAbI dataset by adding supporting questions/answers to the dataset in cases where there is not enough information to answer the question. Interactive QA is certainly an interesting problem and is well-motivated by the paper. However, I don't feel like the bAbI extension is adequately explained. For example, the baseline DMN and MemN2N models on the IQA task are \"take both statements and question as input and then\nestimate an answer.\" Their task is then fundamentally more difficult from the CAN's because they do not distinguish \"feedback\" from the original context; perhaps a more fair approach would be to treat **every** question (both supporting and original questions) as individual instances. Also, how were the supporting questions and the user feedback generated? How many templates / words were used to create them? The dataset creation details are missing, and if space is an issue, a lot of basic exposition on things like GRU / sentence encodings can be cut (or at least greatly shortened) and replaced with pointers to the original papers. \n\nAnother issue I had is that the model attempts to generate these synthetic questions; if there are just one or two templates, why not just predict the values that fill these templates? So instead of generating \"Which bedroom, master one or guest one?\" with an RNN decoder, just predict \"which\" or \"which bedroom\"... isn't this sufficient? In the end, these just seem like more supporting facts, not actual interaction with users, and the fact that it is run on only three of the original twenty tasks make the conclusions hard to trust.\n\nIn conclusion, I think the paper has a strong idea and motivation, but the experiments are not convincing for the paper to be accepted at ICLR.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "The program committee appreciates the authors' response to concerns raised in the reviews. Unfortunately, all reviewers are leaning against accepting the paper. Authors are encouraged to incorporate reviewer feedback in future iterations of this work.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "No Title", "is_meta_review": false, "comments": "1. the QA model is not novel, very similar to the existing model.\n2. The IQA model is very confusing. If it needs human interactive in the training process, how could it be practical to ask human to join the training in each iteration? It sounds impractical. If the human interactive questions are predefined, then it is not interactive at all, since it is not based on the current state of model output.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "20 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "No Title", "is_meta_review": false, "comments": "This work describes \n\n1: a two stage encoding of stories in bAbI like setups, where a GRU is used to encode a sentence, word by word, conditioned on a sentence level GRU, and the sentence level GRU keeps track of a sentence level encoding.  Each is used\n\n2: modifying the bAbI tasks so it is necessary to ask a question to correctly solve the problem\n\nI am not convinced by the papers results:\n\n1:   The new architecture does not do significantly better than DMN+, and in my view, is similar to DMN+.   What problem with DMN+ does your architecture solve?   \n\n2:  There are now several papers doing the second thing, for example \"Dialog-based Language Learning\" by Weston and  \"Learning End-to-End Goal-Oriented Dialog\" by Bordes and Weston, and I think doing it more carefully and in more compelling ways.   In the current work, the correct answer to the question seems given independent of the what the agent asks, so any model that can output \"unknown\" and then input the extra response has an advantage.  Essentially all of the architectures that are used to solve bAbI can be modified to do this...  Indeed, the enc-dec* accuracies in appendix A show that this sort of module can be appended to any other model.  All of the standard models can be trained to output questions as a sequence of words.    Furthermore, I suspect you could generate the questions  in the authors' setting just by enumerating all the questions that occur in training, and taking a softmax over them, instead of generating word-by-word.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "review", "is_meta_review": false, "comments": "This paper proposes an \"interactive\" version of the bAbI dataset by adding supporting questions/answers to the dataset in cases where there is not enough information to answer the question. Interactive QA is certainly an interesting problem and is well-motivated by the paper. However, I don't feel like the bAbI extension is adequately explained. For example, the baseline DMN and MemN2N models on the IQA task are \"take both statements and question as input and then\nestimate an answer.\" Their task is then fundamentally more difficult from the CAN's because they do not distinguish \"feedback\" from the original context; perhaps a more fair approach would be to treat **every** question (both supporting and original questions) as individual instances. Also, how were the supporting questions and the user feedback generated? How many templates / words were used to create them? The dataset creation details are missing, and if space is an issue, a lot of basic exposition on things like GRU / sentence encodings can be cut (or at least greatly shortened) and replaced with pointers to the original papers. \n\nAnother issue I had is that the model attempts to generate these synthetic questions; if there are just one or two templates, why not just predict the values that fill these templates? So instead of generating \"Which bedroom, master one or guest one?\" with an RNN decoder, just predict \"which\" or \"which bedroom\"... isn't this sufficient? In the end, these just seem like more supporting facts, not actual interaction with users, and the fact that it is run on only three of the original twenty tasks make the conclusions hard to trust.\n\nIn conclusion, I think the paper has a strong idea and motivation, but the experiments are not convincing for the paper to be accepted at ICLR.", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Few questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}, {"TITLE": "One or two typos", "OTHER_KEYS": "Erfan Noury", "comments": "Hello,\n\nIt's an interesting paper. However, I think there are a number of typos in the paper that fixing them would make the paper more clear.\n1. In Equation 14, both 't' should be uppercase, to indicate transpose operation, i.e. it should be changed to $\\mathbf{u}^T \\mathbf{s}_t + \\mathbf{u}^T \\mathbf{r}$.\n2. In section 4.5, \"Training Procedure\", you have indicated that a single GRU is used to encode the question, input sentences, and user's feedback. However, above Equation 11 you indicate that hidden state size of feedback sentence is $K_f$. As it is not indicated that $K_f$ is equal to $K_h$, therefore it is either a typo or you should indicate in section 4.5 that by taking these two hidden sizes to be equal you have been able to use a single GRU to encode all these sequences.", "IS_META_REVIEW": false, "DATE": "19 Nov 2016", "is_meta_review": false}], "SCORE": 4, "authors": "Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav", "KEYWORDS": "A self-adaptive QA model aware of what it knows and what it does not know for interactive question answering.", "accepted": false, "id": ""}
