{
  "name" : "1602.08313.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Enhancing Genetic Algorithms using Multi Mutations",
    "authors" : [ "Ahmad B. A. Hassanat", "Esra’a Alkafaween", "Nedal A. Al-Nawaiseh", "Mohammad A. Abbadi", "Mouhammd Alkasassbeh", "Mahmoud B. Alhasanat" ],
    "emails" : [ "Ahmad.hassanat@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Mutation is one of the most important stages of the genetic algorithm because of its impact on the exploration of global optima, and to overcome premature convergence. There are many types of mutation, and the problem lies in selection of the appropriate type, where the decision becomes more difficult and needs more trial and error. This paper investigates the use of more than one mutation operator to enhance the performance of genetic algorithms. Novel mutation operators are proposed, in addition to two selection strategies for the mutation operators, one of which is based on selecting the best mutation operator and the other randomly selects any operator. Several experiments on some Travelling Salesman Problems (TSP) were conducted to evaluate the proposed methods, and these were compared to the well-known exchange mutation and rearrangement mutation. The results show the importance of some of the proposed methods, in addition to the significant enhancement of the genetic algorithm’s performance, particularly when using more than one mutation operator. Keywords: Genetic algorithms, evolutionary algorithms, Multi Mutations, TSP."
    }, {
      "heading" : "Introduction",
      "text" : "Genetic algorithms (GA) are adaptive heuristic random search techniques(1), and are part of what is known as the evolutionary algorithm (EA) that mimics the theory of evolution and natural selection. The basic principles of genetic algorithm were presented by John Holland in the 1970’s(2), (3). Genetic algorithms have proved their superiority in solving many problems, therefore they are considered an optimization tool by many researchers(4), (5) and (6). There are many applications of genetic algorithms in various areas, such as image processing (7), software engineering(8), computer networks (9), robotics(10), and speech recognition (11).\nGenetic algorithms are concerned, in general, with how to produce new chromosomes (individuals) that possess certain features through recombination (crossover) and mutation operators; thus the good individuals have the strongest chance of survival and adaptation, while the weak individuals become extinct. This simulates the Darwinian Theory of “survival of the fittest” (12), (13) and(14).\nGAs have a number of alternative solutions, and the resulting solution is closer to the optimal, where it begins with a number of random solutions (population). These solutions (individuals) are then encoded according to the current problem, and the quality of each individual is evaluated through a fitness function, after which the current population changes to a new population by applying three basic operators: selection, crossover and mutation. The efficiency of a genetic algorithm is based on the appropriate choice of those operators and strategy parameters(15) associated with ratios, such as crossover ratio and mutation ratio (16). Many researchers have shown the effect of the two operators – crossover and mutation – on the success of the GA, and where success lies in both, whether crossover is used alone or mutation alone or both together, as in (17) and(18).\nOne of the difficulties of the genetic algorithm is so-called premature convergence(19) and the reason for this is directly related to the loss of diversity(20). Achieving population diversity is the desired goal, and according to it the search path becomes better, and also avoids trapping into a suboptimal solution. According to Holland, mutation is considered an important mechanism for maintaining diversity(21)(22), which explores new areas in the search space, thus avoiding the convergence of the local optimum(23). The need for mutation is to prevent loss of genetic material, where the crossover does not\nguarantee access to the new search space(24); therefore, random changes in the gene through mutation helps in providing variations in the population(16).\nToday, genetic algorithms have evolved from what was prevalent in the era of Holland(25). Classical mutation (Bit-flip Mutation) developed by Holland with different encoding problems (e.g. TSP) no longer fits (26), therefore, several types of mutation of various types of encoding have been proposed, including: Exchange Mutation(27), Displacement Mutation(28), Uniform Mutation and Creep Mutation (29), Inversion Mutation(30) and some other types. The problem lies in our selection of which type(s) to solve the specific problem, and our decision becomes more difficult and needs more trial and error. In order to overcome this problem, several researchers have developed new types of GA that use more than one mutation operator at the same time(31) , (32) and (33). Our paper contributes to the previous work to fill this gap.\nThis paper aims to provide information about new mutation operators, and investigates the effect of using more than one mutation operator on the performance of the GA.\nThe rest of this paper presents some of the related previous work and the proposed methods, in addition to discussing the experimental results, which were designed to evaluate the proposed methods. The conclusions and future work are presented at the end of the paper."
    }, {
      "heading" : "Related Work",
      "text" : "In order to render the algorithm more effective in tackling the problems, the main topic of many researchers has become improvement of the performance of the genetic algorithm by overcoming premature convergence problems.\nSoni and Kumar studied many types of mutations that solve the problem of a travelling salesman(29). Larrañaga et al. presented a review of how to represent travelling salesman problems and the advantages and disadvantages of different crossover and mutation operators(26). Louis and Tang proposed a new mutation called greedy-swap mutation, so that two cities are chosen randomly in the same chromosome, and switching between them if the length of the new tour obtained is shorter than the previous ones (34).\nHong et al. proposed an algorithm called the Dynamic Genetic Algorithm (DGA) to apply more than crossover and mutation at the same time. This algorithm automatically selects the appropriate crossover and appropriate mutation, and also adjusts the crossover and mutation ratios automatically, based on the evaluation results of the respective children in the next generation. In comparing this algorithm with the simple genetic algorithm that commonly uses one crossover process and one process of mutation, the results showed the success of the proposed algorithm in performance (31).\nDeep and Mebrahtu proposed an Inverted Exchange mutation and Inverted Displacement mutation, which combine inverted mutation with exchange mutation and also combine inverted mutation with displacement mutation. The experiment was performed on the TSP problem and the results were compared with several operators that already exist (24).\nHong et al. proposed a Dynamic Mutation Genetic Algorithm (DMGA) to apply more than one mutation at the same time to generate the next generation. The mutation ratio is also dynamically adjusted according to the progress value that depends on the fitness of the individual, and so decreasing the ratio of mutation if the mutation operator is inappropriate, and vice versa, increasing the ratio of mutation if the operator is appropriate (35) (32). Dynamically adjusting of the mutation ratio is studied and used later by several researchers such as (36) and (37).\nHilding and Ward proposed an Automated Operator Selection (AOS) technique, by which they eliminated the difficulties that appear when choosing crossover or mutation operators for any problem. In this work, they allowed the genetic algorithm to use more than one crossover and mutation operators, and took advantage of the most effective operators to solve problems. The operators were automatically chosen based on their performance, and therefore the time spent choosing the most suitable operator was reduced. The experiments were performed on the 01-Knapsack problem. This approach proved its effectiveness as compared with the traditional genetic algorithm (33).\nDong and Wu proposed a dynamic mutation probability, where the mutation rate is calculated by the ratio between the fitness of the individual and the most fit in the population. This ratio helps the algorithm to get out of local optima and also leads to diversification of the population (38). Patil and Bhende presented a study of the various mutation-based operators in terms of performance, improvement and quality of solution. A comparison was made between Dynamic Mutation algorithm, Schema Mutation Genetic Algorithm, Compound Mutation algorithm, Clustered-based Adaptive Mutation algorithm, and Hyper Mutation-Based Dynamic Algorithm (39) ."
    }, {
      "heading" : "Methods",
      "text" : "Many researchers have resorted to preventing local convergence in different ways, and because mutation is a key operation in the search process, we found several mutation methods in the literature. The question is: what is the best method to use?\nTo answer this question, and in the hope of avoiding local optima and increasing the diversification of the population, we have proposed and implemented several types of mutations, to be compared with two of the well-known types, namely: Exchange mutation and Rearrangement mutation (40).\nIn the following we describe each operator. It is important to note that mutation methods described in subsections 3.4 to 3.10 were designed specifically for the TSP problem. However, they can be customized to fit some other problems, such as the knapsack problem.\nWorst gene with random gene mutation (WGWRGM) To perform this mutation we need to search for the worst gene in the chromosome from index 0 to L-1, where L is the length of the chromosome. The worst gene varies depending on the definition of the “worst” for each problem; the worst gene is the point that contributes the maximum to increase the cost of the fitness function of a specific chromosome. For example, the worst gene in the TSP problem is the city with the maximum distance from its left neighbour, while the worst gene in the Knapsack problem (for instance) is the point with the lowest value to weight ratio, and so on.\nAfter the worst gene is identified, we select another gene at random, and swap both genes as in the Exchange mutation. Fig. (1) shows an example of (WGWRGM).\nThe worst gene (WG) can be calculated for a minimization problem such as TSP using: = argmax ( ( , + 1 ) (1) and for the maximization problem such as the Knapsack problem using: = argmin ( ( , + 1 ) (2) where C represents the chromosome, i is the index of a gene within a chromosome, and the distance function for the TSP can be calculated using either Euclidian distance or the distances table between cities.\nIn the case of TSP, searching for the WG starts at index 1, assuming that the route index 0, while this is not the case for other problems such as the Knapsack problem (e\nThe previous equations are used for the chromosome, and the worst gene of this chromosome that exhibits the maximum distance is used for the mutation operation.\nExample 1. (TSP problem)\nSuppose that the chromosome chosen to be mutated"
    }, {
      "heading" : "CHR1: A B E D C A,",
      "text" : "To apply WGWRGM:\n• Step 1: Find the worst gene in the parent • Step 2: Suppose that the city which ha • Step 3: Apply the Exchange mutation\ncities (see Fig.\nWorst gene with worst gene mutation (WGWWGM) This type is similar to the WGWRGM, the only difference being that we search for genes. Both worst genes exchange positions with each the two maximum values algorithms if the problem being dealt with is a minimization problem, and for the maximization problem, finding the two minimum values of the algorithm can be used, as the definit the worst gene concept is different from one problem to another.\n-starting city is located at\nis:\nWGWRGM to a specific chromosome of particular TSP\n; according to the graph, the worst gene is (D). s been selected at random is (C). in this chromosome by swapping the\n2 (b)). The output offspring is: A B E C D A.\nother. Finding both worst genes is similar to finding\nquation (2)).\npositions of the two\nthe two worst\nion of\nWorst LR gene with random gene mutation (WLRGWRGM)\nThis method is also similar to the WGWRGM, the only difference being that the found by calculating the distance between both its neighbours: the left and the The worst gene (WLRgene) can be calculated\n!\"#$ $ = argmax\n!\"#$ $ argmin\nEquation (3) can be used for minimization problems, and Equation (4) for maximization problems. The extreme genes (the first and last ones) can be handled in a circular way, i.e. the left of the first gene is the last gene.\nThe worst gene (for minimization problems) and right neighbours which is the maximum among all round for minimization problems position of another gene chosen\nExample 2. (TSP problem)\nFig. 4 (a) represents the chromosome chos\nChromosome: A B E H\nAccording to Fig. 4 (a), the and from city D to city C is the maximum applying WLRGWRGM mutation\nFig. 4. Example of applying\nright. for the TSP using:\n%& , ' 1 ,\n%& , ' 1 ,\nis the one that is the sum of the distances with its left genes within a chromosome\n. In this mutation, the position of the worst gene randomly.\nen to be mutated, which is:\nF D C A.\n(WLRgene) is the city (D) because the total distance from city . If city (H) is chosen randomly, the output\nis: A B E D F H C A (see Fig. 4 (b)).\nWLRGWRGM on a specific chromosome of particular TSP\nworst gene is\n1 (3)\n1 (4)\n, and the other way is altered with the\nD to city F offspring after\nWorst gene with nearest neighbour mutation (WGWNNM) This method uses the idea of the nearest neighbour cities (knowledge-based method), where it provides an heuristic search process for mutation, and is performed as follows:\n• Step 1: Search for the gene (city) in a tour characterized by the worst with its left and right neighbours (WLRgene) as in WLRGWRGM mutation; this city is called “worst city”. • Step 2: Find the nearest city to the worst city (from the graph), and call it Ncity. Then search for the index of that city in the chromosome, calling it Ni.\nWe need to replace the “worst city” with another one around the “Ncity” other than the “Ncity”. The term “around” is defined by a predefined range, centred at the “Ncity”. We arbitrarily used (Ni ± 5) as a range around the index of the “Ncity”. The out-of-range problem with the extreme points is solved by dealing with the chromosome as a circular structure.\n• Step 3: Select a random index within the range; the city at that index is called “random city”. • Step 4: Swap between “worst city” and “random city”.\nExample 3. (TSP problem)\nSuppose that the chromosome chosen to be mutated is:\nTo apply WGWNNM:\n• Step 1: Find the (WLRgene) in the chromosome; according to the graph, the worst city is (F). • Step 2: Find the nearest city to the worst city, which is (E); this city is called Ncity. • Step 3: Search for a city around Ncity at random in the range (± 5); suppose we choose city (C). • Step 3: Apply the Exchange mutation in this chromosome by swapping the position of the two\ncities (see Fig. 5 (b). The output offspring: A B C D E F H A.\nWorst gene with the worst around the nearest neighbour mutation (WGWWNNM)\nThis mutation is similar to the WGWNNM; the only difference is in the selection of the swapped city. The swapped city is not selected randomly around the nearest city as in WGWNNM, but rather is chosen based on its distance from the nearest city. By considering the furthest city from the nearest city to be swapped with the worst city, this bring nearest cities together, and sends furthest cities far away.\nWorst gene inserted beside nearest neighbour mutation (WGIBNNM)\nThis type of mutation is similar to the its nearest city. The worst city is moved to neighbo shifted either left or right depending on the locations of the worst city and\nIn other words, if the worst city was found to the right of its nearest city, the worst city is moved to the left of its nearest city, and the other citie worst city was found to the left of its nearest neighbo location of its nearest city, and the rest of the cities between this locat worst city are shifted to the right\nRandom gene inserted beside nearest neighbour mutation (RGIBNNM)\nThis mutation is almost the same as randomly, and is not based on its negative contribution to the fitness of the chromosome RGIBNNM is an enhancement of the\nSwap worst gene locally mutation (SWGLM) This mutation is performed as follows:\n• Search for the “worst gene • Swap the left neighbour of the “\nof the new child (F1).\n• Swap the “worst gene (F2). • If C1 > C2, then return legitimate child and delete\nWGWNNM, after finding the indices ur its nearest city, and the rest of the cities are\nits nearest city.\ns are shifted to the right of the location of the worst city. If the ur, the worst city is moved to the location prior to the\nion and the previous of that location, and the other way round otherwise.\nthe WGIBNNM, except that the “worst city”\nWGIBNNM to enforce some randomness.\n”, the same as for WLRGWRGM.\nworst gene” with its left neighbour, and calculate the fitness (C1)\n” with its right neighbour, and calculate the fitness\nF2 as the legitimate child and delete F1, otherwise F2 (see Fig. (6)).\nof the worst city and then\nlocation of the\nis selected . We reckon that\n(C2) of the new child\nreturn F1 as the\nExample 4. (TSP problem)\nSuppose that the chromosome chosen to be mutated is:\nChromosome: A B F E H D C A, as depicted in Fig. 7(a).\nTo apply SWGLM:\n• Step 1: Find the “worst gene” in the chromosome. According to the graph, the worst city is (E). • Step 2: Swap between two left neighbours of E, which are (B and F); the first offspring is:\nA F B E H D C A, and the cost of this offspring is C1 (see Fig.7(b)). • Step 3: Swap between worst city (E) and it right neighbour. The second offspring is:\nA B F H E D C A. The cost of this offspring is C1 (see Fig.7(c)).\n• Step 4: Compare the cost (C1, C2) and the least among them are the legitimate children.\nInsert best random gene before worst gene mutation (IBRGBWGM)\nThis mutation works as follows: 1. Search for the city that is characterized by the worst city as in WGWRGM and find the index of its\nprevious city. 2. Select a certain number of random cities (in this work we chose 5 random cities arbitrarily\nexcluding the “worst city” and its previous neighbour (PN)). 3. For each random city calculate the distance to the “worst city” (D1) and the distance to PN (D2). 4. Find the “best city” from the random cites, which is the one with the minimum (D1+D2). 5. Move the “best city” to be inserted between the “worst city” and PN. 6. Shift cities which are located between the old and the new location of “best city” to legitimize the\nchromosome.\nExample 4. (TSP problem)\nFig. 8(a) represents the chromosome chosen to be mutated, which is:\nChromosome: A B E D C A.\nAccording to Fig.8 (a), the worst gene is the city (E). According to the graph, the best city is (C), and the output offspring after applying IBRGBWGM mutation is: A B C E D A (see Fig.8 (b)).\nInsert best random gene before rand gene mutation (IBRGBRGM)\nThis mutation is similar to IBRGBWGM, the only difference being that the “worst city” is not chosen based on any distance; rather it is chosen randomly to impose some diversity among the new offspring."
    }, {
      "heading" : "Multi Mutation Operators Algorithms",
      "text" : "A traditional genetic algorithm commonly used is one mutation operator. We propose using more than one mutation operation, and this is the different mutation operators that hopefully lead to different directions in the search space, thus increasing diversification in the population, and improving the performance of the genetic algorithm. To do this we opted for two selection approaches: the best mutation, and a randomly chosen mutation.\nSelect the best mutation algorithm (SBM) This algorithm applies multiple mutation operators at the same time to the same chromosome, and considers the best one child to be added to the population, to prevent duplication; only the best and not found in population is added. In this work, from the beginning, we define mutation methods to be applied. This algorithm implements all the aforementioned methods (WGWRGM, WGWWGM, WLRGWRGM, WGWNNM, WGWWNNM, WGIBNNM, RGIBNNM, SWGLM, IBRGBWGM and IBRGBRGM) one after the other, and from each method produces one offspring; the best child (that does not already exist in the population) is added. This anticipates that such a process encourages diversity in the population, and thus avoids convergence to local optimal."
    }, {
      "heading" : "Select any mutation algorithm (SAM)",
      "text" : "This algorithm tries to apply multi mutation operators each time. The selection strategy is random, and it randomly chooses one of the aforementioned operators in a certain generation. Therefore, we reckon that in each generation a different operator of mutation is chosen. This means that there is a different direction of the search space, and this is what we are aiming for, increasing diversification, and attempting to enhance the performance of the genetic algorithm."
    }, {
      "heading" : "Experiment and Discussion",
      "text" : "To evaluate the proposed methods, we conducted two sets of experiments on different TSP problems. The aim of the first set of experiments was to examine convergence to a minimum value of each method separately. The second set of experiments was designed to examine the efficiency of the SBM and\nSAM algorithms and compare their performance with the proposed mutation operators (WGWRGM, WGWWGM, WLRGWRGM, WGWNNM, WGWWNNM, WGIBNNM, RGIBNNM, SWGLM, IBRGBWGM and IBRGBRGM) using real data. The results of these experiments were compared to the two alreadying existing mutations, namely: Exchange mutation(27), and Rearrangement mutation(40). In the first set of experiments, the mutation operators were tested using three test data (real data) taken from TSPLIB(41), including: “eil51“,“pr76” and “a280”, each of them consisting of 51, 76, and 280 cities respectively. The genetic algorithm parameters used: population size = 100, the probability of crossover = (0%), mutation probability = (100%), and the maximum number of generations = 1600. The algorithm was applied five times, and the average for each generation was taken, starting from generation 100 up to generation 1600. Results from the first test indicated that the best performance was recorded by the SBM, followed by the SAM. This compared well with the rest of the mutation methods, because it showed good convergence to a minimum value. The efficiency of each one of the fourteen mutations is shown in Figures (9-11). A closer look at these figures reveals that the SBM and SAM algorithms outperformed all other methods in the speed of convergence. The results are analyzed as follows:\nAs can be observed from Fig. (9), the results indicate the superiority of the SBM and SAM algorithms, where the speed of convergence of a near optimal solution with the progress of the generations is faster than the use of a certain type of mutation alone. The WGWRGM followed by WLRGWRGM and exchange mutations also showed the extent of their influence on the quality of the solution. One result in Fig. (10) indicates that the SBM algorithm showed faster convergence to the minimum value followed by SAM, and these algorithms showed better performance than the remaining mutations. At the level of mutation alone, the exchange mutation followed by Exchange and WGWRGM in addition to WLRGWRGM, showed better performance than the other mutations.\nAs can be seen from Fig. (11), the best performance was recorded by the SBM algorithm, and this showed faster convergence to the minimum value than any other mutation, followed by the SAM\nalgorithm. At the level of mutations alone, RGIBNNM, WGWNNM and WGWRGM mutations showed better performance than the rest of the mutations. Because of the slow convergence of the SWGLM and WGWWGM mutations, they achieved the worst result. The reason behind the superiority of the SBM is that it tries several mutations and chooses the best among them; however, this of course comes at the cost of time consumed. Although the SBM outperformed the SAM, SAM is still better than SBM in terms of time spent, because SBM tries all mutations available and chooses the best, while SAM selects any one randomly. Moreover, the difference between the two results is sometimes not significant. The good performance of the SAM is due to using a different mutation each time, and this leads to an increase in the diversity of the solutions, and thus enhances the overall performance of the GA. The second set of experiments attempted to measure the effectiveness of the SBM and SAM in converging to an optimal solution. These methods and all the proposed operators, in addition to the Exchange mutation and Rearrangement mutation, were tested using eleven real TSP problems taken from the TSPLIB, including: rat783, a280, u159, ch130 bier127, kroA100, pr76, berlin52, att48, eil51, pr144. The genetic algorithm parameters that were selected were the same as in the first test; however, the recorded results were the average of the last generation (1600) after executing the algorithm five times (see Table (1)).\nas: a280, rat87, berlin52, bier127, ch130, pr76, pr144, u159. It converges to the optimal faster than the exchange method, and the rest of the test data (cities) were outperformed by the SAM algorithm, such as: att84, eil51, kroA100. Considering methods that use one mutation only, the Exchange mutation followed by WGWRGM mutation performed better than the other methods. The Exchange mutation was the best in four problems, and the WGWRGM was the best in three problems. At the same time, both methods converged to a minimum value faster than the other methods. WLRGWRGM and RGIBNNM also showed convergence in the rest of the cities better than other methods; both were the best in two problems.\nIn this experiment, SWGLM showed weak results, followed by WGWWGM which showed slow convergence to a minimum value. However, the importance of these operators has emerged in the diversity of the population, where both helped to achieve new areas for searching to be used by (SAM and SBM). Although the aim of this paper was not to find the optimal solution for TSP problems, the solutions of the proposed algorithms were close to optimal solutions in some cases, and none could achieve an optimal solution. Perhaps using crossover operators and increasing the number of generations would enhance the solutions of the proposed methods. This shows the importance of using appropriate parameters along with mutation (such as population size, crossover ratio, number of generations, etc.), due to the effective impact of their convergence to a optimal (or near optimal) solution."
    }, {
      "heading" : "Conclusion",
      "text" : "We have proposed several mutation methods (WGWRGM, WGWWGM, WLRGWRGM, WGWNNM, WGWWNNM, WGIBNNM, RGIBNNM, SWGLM, IBRGBWGM and IBRGBRGM), in addition to proposing selection approaches (SBM and SAM). Several experiments were conducted to evaluate those methods on several TSP problems, which showed the superiority of some of the proposed methods over the well-known Exchange mutation and Rearrangement mutation methods. The proposed mutations can be used for other problems with some modifications and not only oriented to the TSP problem. This study also shows that using more than one mutation method in the GA is preferable, because it allows the GA to avoid local optima; the proposed SBM and SAM strategies enhance the performance of the GA. This approach (using more than one mutation for GA) is supported by (31), (32) and (35). For the use of each mutation alone, some mutations showed better performance than others, and this does not mean that the rest of the mutations have been proved to fail. They can be effective in dealing with other problems, because every problem has a different search space; in this work we found them effective in SBM and SAM, where they encouraged diversity and hence increased the efficiency of both algorithms. Our future work will include the development of some types of new crossovers, to support the proposed mutations, attempting to further enhance the results, in addition to applying the proposed methods to different problems using different benchmark data."
    } ],
    "references" : [ {
      "title" : "Exploring Travelling Salesman Problem using Genetic Algorithm",
      "author" : [ "A Singh", "R. Singh" ],
      "venue" : "International Journal of Engineering Research & Technology (IJERT)",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Genetic Algorithms: Concepts and Applications",
      "author" : [ "KF Man", "KS Tang", "S. Kwong" ],
      "venue" : "IEEE Transactions on Industrial Electronics",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1996
    }, {
      "title" : "An overview of methods maintaining diversity in genetic algorithms",
      "author" : [ "D Gupta", "S. Ghafir" ],
      "venue" : "International journal of emerging technology and advanced engineering",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Genetic algorithms in search, optimization, and machine learning",
      "author" : [ "Golberg DE" ],
      "venue" : "Addion wesley",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1989
    }, {
      "title" : "A genetic algorithm for projective invariant object recognition",
      "author" : [ "Tsang PW", "Au AT" ],
      "venue" : "In TENCON'96. Proceedings.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1996
    }, {
      "title" : "A survey of genetic algorithms applications for image enhancement and  15  segmentation",
      "author" : [ "M Paulinas", "A. Ušinskas" ],
      "venue" : "Information Technology and control",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "Optimal Routing In Ad-Hoc Network Using Genetic Algorithm",
      "author" : [ "AA Mohammed", "G. Nagib" ],
      "venue" : "International Journal of Advanced Networking and Applications",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Tuning of PID controller based on a multiobjective genetic algorithm applied to a robotic manipulator",
      "author" : [ "HVH Ayala", "L. dos Santos Coelho" ],
      "venue" : "Expert Systems with Applications",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2012
    }, {
      "title" : "Speech feature extraction and recognition using genetic algorithm",
      "author" : [ "Gupta H", "Wadhwa DS" ],
      "venue" : "International Journal of Emerging",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Comparison of performance between different selection strategies on simple genetic algorithms",
      "author" : [ "J Zhong", "X Hu", "M Gu", "J. Zhang" ],
      "venue" : "In Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2005
    }, {
      "title" : "Introduction to evolutionary computing: Springer Science & Business Media",
      "author" : [ "Eiben AE", "Smith JE" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Parameter control in evolutionary algorithms",
      "author" : [ "AE Eiben", "Z Michalewicz", "M Schoenauer", "JE. Smith" ],
      "venue" : "In Parameter setting in evolutionary algorithms",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Adaptive non-uniform mutation based on statistics for genetic algorithms",
      "author" : [ "S. Yang" ],
      "venue" : "In Proceedings of the 2002 Genetic and Evolutionary Computation,GECCO’02,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2002
    }, {
      "title" : "Crossover or mutation",
      "author" : [ "Spears WM" ],
      "venue" : "Foundations of genetic algorithms",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1992
    }, {
      "title" : "Understanding interactions among genetic algorithm parameters",
      "author" : [ "K Deb", "S. Agrawal" ],
      "venue" : "Foundations of Genetic Algorithms",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1999
    }, {
      "title" : "Mechanisms to avoid the premature convergence of genetic algorithms. Petroleum–Gas University of Ploieşti Bulletin, Math.–Info.–Phys",
      "author" : [ "Nicoară ES" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Incorporating heuristic Information into Genetic Search",
      "author" : [ "JY Suh", "D. Van Gucht" ],
      "venue" : "In Proceedings of the Second International Conference on Genetic Algorithms;",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1987
    }, {
      "title" : "Mutation effects in genetic algorithms with offspring selection applied to combinatorial optimization problems",
      "author" : [ "S Wagner", "M Affenzeller", "A Beham", "GK Kronberger", "SM. Winkler" ],
      "venue" : "European modeling and simulation symposium EMSS;",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2010
    }, {
      "title" : "Multi-Population Methods with Adaptive Mutation for Multi-Modal Optimization Problems",
      "author" : [ "I Korejo", "S Yang", "K Brohi", "ZUA. Khuhro" ],
      "venue" : "International Journal on Soft Computing, Artificial Intelligence and Applications (IJSCAI)",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "Genetic algorithms for the travelling salesman problem: A review of representations and operators",
      "author" : [ "P Larrañaga", "CMH Kuijpers", "RH Murga", "I Inza", "S. Dizdarevic" ],
      "venue" : "Artificial Intelligence Review",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1999
    }, {
      "title" : "The “molecular” traveling salesman",
      "author" : [ "W. Banzhaf" ],
      "venue" : "Biological Cybernetics",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1990
    }, {
      "title" : "Genetic Algorithms+ data Structures=",
      "author" : [ "T I MZ" ],
      "venue" : "Evolutionary Programs Berlin: Springer;",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1992
    }, {
      "title" : "A parallel processing approach to a multiple travelling salesman problem using evolutionary programming",
      "author" : [ "Fogel DA" ],
      "venue" : "In Proceedings of the Fourth annual Symposium on Parallel Processing;",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1990
    }, {
      "title" : "Evolution of appropriate crossover and mutation operators in a genetic process",
      "author" : [ "TP Hong", "HS Wang", "WY Lin", "WY. Lee" ],
      "venue" : "Applied Intelligence",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2002
    }, {
      "title" : "Simultaneously applying multiple mutation operators in genetic algorithms",
      "author" : [ "TP Hong", "HS Wang", "WC. Chen" ],
      "venue" : "Journal of heuristics",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2000
    }, {
      "title" : "Automated Crossover and Mutation Operator Selection on Genetic Algorithms",
      "author" : [ "F Hilding", "K. Ward" ],
      "venue" : "In Proceedings of the 9th International Conference on Knowledge-Based and Intelligent Information and Engineering",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2005
    }, {
      "title" : "Interactive genetic algorithms for the traveling salesman problem",
      "author" : [ "SJ Louis", "R. Tang" ],
      "venue" : "In Genetic and Evolutionary Computation",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1999
    }, {
      "title" : "A Dynamic Mutation Genetic Algorithm",
      "author" : [ "Hong TP", "Wang HS" ],
      "venue" : "In Systems, Man, and Cybernetics,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 1996
    }, {
      "title" : "Natural Selection Fails to Optimize Mutation Rates for Long-Term Adaptation on Rugged Fitness Landscapes",
      "author" : [ "J Clune", "D Misevic", "C Ofria", "RE Lenski", "SF Elena", "R. Sanju" ],
      "venue" : null,
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2008
    }, {
      "title" : "Correction: Improved Lower Bounds of DNA Tags Based on a  17  Modified Genetic Algorithm",
      "author" : [ "B Wang", "X Wei", "J Dong", "Q. Zhang" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2015
    }, {
      "title" : "Dynamic Crossover and Mutation Genetic Algorithm Based on Expansion Sampling",
      "author" : [ "M Dong", "Y. Wu" ],
      "venue" : "In Artificial Intelligence and Computational Intelligence",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2009
    }, {
      "title" : "An improved genetic algorithm to solve the traveling salesman problem",
      "author" : [ "OM Sallabi", "Y. El-Haddad" ],
      "venue" : "World Academy of Science, Engineering and Technology",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2009
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : null,
    "creator" : "PDFCreator Version 1.7.3"
  }
}