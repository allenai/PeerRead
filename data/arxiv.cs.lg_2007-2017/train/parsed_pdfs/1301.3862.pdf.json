{
  "name" : "1301.3862.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Dependency Networks for Collaborative Filtering and Data Visualization",
    "authors" : [ "David Heckerman", "David Maxwell Chickering", "Christopher Meek", "Robert Rounthwaite", "Carl Kadie" ],
    "emails" : [ "heckerma@microsoft.com", "dmax@microsoft.com", "meek@microsoft.com", "robertro@microsoft.com", "carlk@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We describe a graphical representation of probabilistic relationships-an alternative to the Bayesian network-called a dependency network. Like a Bayesian network, a depen dency network has a graph and a probabil ity component. The graph component is a (cyclic) directed graph such that a node's parents render that node independent of all other nodes in the network. The probabil ity component consists of the probability of a node given its parents for each node (as in a Bayesian network) . We identify several ba sic properties of this representation, and de scribe its use in collaborative filtering (the task of predicting preferences) and the visu alization of predictive relationships.\nKeywords: Dependency networks, graphical models, inference, data visualization, exploratory data analy sis, collaborative filtering, Gibbs sampling\n1 Introduction\nThe Bayesian network has proven to be a valuable tool for encoding, learning, and reasoning about probabilis tic relationships. In this paper, we introduce another graphical representation of such relationships called a dependency network. The representation can be thought of as a collection of regression/classification models among variables in a domain that can be com bined using Gibbs sampling to define a joint distribu tion for that domain. The dependency network has several advantages and disadvantages with respect to the Bayesian network. For example, a dependency net work is not useful for encoding causal relationships and is difficult to construct using a knowledge-based ap proach. Nonetheless, in our three years of experience with this representation, we have found it to be easy to\nlearn from data and quite useful for encoding and dis playing predictive (i.e., dependence and independence) relationships. In addition, we have empirically verified that dependency networks are well suited to the task of predicting preferences-a task often referred to as col laborative filtering. Finally, the representation shows promise for density estimation and probabilistic infer ence.\nThe representation was conceived independently by Hofmann and Tresp (1997), who used it for density es timation; and Hofmann (2000) investigated several of its theoretical properties. In this paper, we summarize their work, further investigate theoretical properties of the representation, and examine its use for collabora tive filtering and data visualization.\nIn Section 2, we define the representation and describe several of its basic properties. In Section 3, we de scribe algorithms for learning a dependency network from data, concentrating on the case where the local distributions of a dependency network (similar to the local distributions of a Bayesian network) are encoded using decision trees. In Section 4, we describe the task of collaborative filtering and present an empirical study showing that dependency networks are almost as accurate as and computationally more attractive than Bayesian networks on this task. Finally, in Sec tion 5, we show how dependency networks are ideally suited to the task of visualizing predictive relationships learned from data.\n2 Dependency Networks\nTo describe dependency networks and how we learn them, we need some notation. We denote a variable by a capitalized token (e.g., X, X;, 0, Age), and the state or value of a corresponding variable by that same token in lower case (e.g., x, x;, 8, age). We denote a set of variables by a bold-face capitalized token (e.g., X, X;, Pa;) . We use a corresponding bold-face lower case token (e.g., x, x;, pa;) to denote an assignment of\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 265\nstate or value to each variable in a given set. We use p(X = xiY = y) (or p(xiy) as a shorthand) to denote the probability that X = x given Y = y. We also use p(x iy) to denote the probability distribution for X given Y (both mass functions and density functions). Whether p(xiy) refers to a probability, a probability density, or a probability distribution will be clear from context.\nConsider a domain of interest having variables X = (X 1 , ... , X n ) . A dependency network for X is a pair (9, P) where q is a (cyclic) directed graph and P is a set of probability distributions. Each node in q corre sponds to a variable in X. We use X; to refer to both the variable and its corresponding node. The parents of node X;, denoted Pa;, correspond to those variables Pa; that satisfy\n(1)\nThe distributions in P are the local probability distributions p(x; jpa;) , i = 1, . . . , n. We do not require the distributions p(x; lx1, ... ,Xi-1,Xi+1, ... , xn) , i = 1, .. . , n to be obtainable (via inference) from a sin gle joint distribution p(x). If they are, we say that the dependency network is consistent with p(x). We shall say more about the issue of consistency later in this section.\nA Bayesian network for X defines a joint distribution for X via the product of its local distributions. A dependency network for X also defines a joint distri bution for X, but in a more complicated way via a Gibbs sampler (e.g., Gilks, Richardson, and Spiegel halter, 1996). In this Gibbs sampler, we initial ize each variable to some arbitrary value. We then repeatedly cycle through each variable X 1 , ... , X n, in this order, and resample each X; according to p(x;ix1, ... , Xi-1, Xi+1, ... , Xn) = p(x; lpa; ) . We call this procedure an ordered Gibbs sampler. As described by the following theorem (also proved in Hofmann, 2000), this ordered Gibbs sampler defines a joint dis tribution for X.\nTheorem 1: An ordered Gibbs sampler applied to a dependency network for X, where each X; is discrete and each local distribution p ( x; IPa;) is positive, has a unique stationary joint distribution for X.\nProof: Let xt be the sample of x after the tth iteration of the ordered Gibbs sampler. The sequence x1, x2, . . . can be viewed as samples drawn from a homogenous Markov chain with transition matrix M having ele ments Mjli = p (xt+1 = jlxt = i). (We use the termi nology of Feller, 1957.) It is not difficult to see that M is the product M1 · . . . · Mn, where Mk is the \"lo cal\" transition matrix describing the resampling of Xk\naccording to the local distribution p(xk IPak)· The pos itivity of local distributions guarantees the positivity of M, which in turn guarantees (1) the irreducibility of the Markov chain and (2) that all of the states are ergodic. Consequently, there exists a unique joint dis tribution that is stationary with respect to M. 0\nBecause the Markov chain described in the proof is irreducible and ergodic, after a sufficient number of iterations, the samples in the chain will be drawn from the stationary distribution for X. Consequently, these samples can be used to estimate this distribution.\nNote that the Theorem holds for both consistent and inconsistent dependency networks. Furthermore, the restriction to discrete variables can be relaxed, but will not be discussed here. In the remainder of this paper, we assume all variables are discrete and each local distribution is positive.\nIn addition to determining a joint distribution, a de pendency network for a given domain can be used to compute any conditional distribution of interest that is, perform probabilistic inference. We discuss an algorithm for doing so, which uses Gibbs sampling, in Heckerman, Chickering, Meek, Rounthwaite, and Kadie (2000). That Gibbs sampling is used for in ference may appear to be a disadvantage of depen dency networks with respect to Bayesian networks. When we learn a Bayesian network from data, how ever, the resulting structures are typically complex and not amenable to exact inference. In such situations, Gibbs sampling (or even more complicated Monte Carlo techniques) are used for inference in Bayesian networks, thus weakening this potential advantage.\nIn fact, when we have data and can learn a model for X, dependency networks have an advantage over Bayesian networks. Namely, we can learn each local distribution in a dependency network independently, without regard to acyclicity constraints.\nBayesian networks have one clear advantage over de pendency networks. In particular, dependency net works are not suitable for the representation of causal relationships. For example, if X causes Y (so that X and Y are dependent), the corresponding depen dency network is X +-+ Y -that is, X is a parent of Y and vice versa. It follows that dependency networks are difficult to elicit directly from experts. Without an underlying causal interpretation, knowledge-based elicitation is cumbersome at best.\nAnother important observation about dependency net works is that, when we learn one from data as we have described-learning each local distribution independently-the model is likely to be inconsistent. (In an extreme case, where (1) the true joint distribu-\n266 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\ntion lies in one of the possible models, (2) the model search procedure finds the true model, and (3) we have essentially an infinite amount of data, the learned model will be consistent.) A simple approach to avoid this difficulty is to learn a Bayesian network and apply inference to that network to construct the dependency network. This approach, however, will eliminate the advantage associated with learning dependency net works just described, is likely to be computationally inefficient, and may produce extremely complex local distributions. When ordered Gibbs sampling is applied to an inconsistent dependency network, it is important to note that the joint distribution so defined will de pend on the order in which the Gibbs sampler visits the variables. For example, consider the inconsistent dependency network X +- Y. If we draw sample-pairs (x, y)-that is, x and then y-then the resulting sta tionary distribution will have X and Y independent. In contrast, if we draw sample-pairs (y, x), then the resulting stationary distribution may have X and Y dependent.\nThe fact that we obtain a joint distribution from any dependency network, consistent or not, is comforting. A more important question, however, is what distri bution do we get? The following theorem, proved in Heckerman et al. ( 2000) , provides a partial answer.\nTheorem 2: If a dependency network for X is con sistent with a positive distribution p(x), then the sta tionary distribution defined in Theorem 1 is equal to p(x).\nWhen a dependency network is inconsistent, the situa tion is even more interesting. If we start with learned local distributions that are only slight perturbations (in some sense) of the true local distributions, will Gibbs sampling produce a joint distribution that is a slight perturbation of the true joint distribution? Hof mann (2000) argues that, for discrete dependency net works with positive local distributions, the answer to this question is yes when perturbations are measured with an L2 norm. In addition, Heckerman et al. (2000) show empirically using several real datasets that the joint distributions defined by a Bayesian network and dependency network, both learned from data, are sim ilar.\nWe close this section with several facts about consis tent dependency networks, proved in Heckerman et al. (2000). We say that a dependency network for X is bi-directional if X; is a parent of Xj if and only if Xj is a parent of X; , for all X; and Xj in X. We say that a distribution p(x) is consistent with a dependency net work structure if there exists a consistent dependency network with that structure that defines p(x).\nTheorem 3: The set of positive distributions consis tent with a dependency network structure is equal to the set of positive distributions defined by a Markov network structure with the same adjacencies.\nNote that, although dependency networks and Markov networks define the same set of distributions, their rep resentations are quite different. In particular, the de pendency network includes a collection of conditional distributions, whereas the Markov network includes a collection of joint potentials.\nLet pa{ be the lh parent of node X; . A consistent de pendency network is minimal if and only if, for every node X; and for every parent pa{ , X; is not indepen dent of pa{ given the remaining parents of X; .\nTheorem 4: A minimal consistent dependency net work for a positive distribution p(x) must be bi directional.\n3 Learning Dependency Networks\nIn this section, we mention a few important points about learning dependency networks from data.\nWhen learning a dependency network for X, each local distribution for X; is simply a regression/classification model (with feature selection) for x; with X\\ {xi} as inputs. If we assume that each local distribution has a parametric model p( x; !Pa;, B;), and ignore the de pendencies among the parameter sets Bt, ... , ()n, then we can learn each local distribution independently us ing any regression/classification technique for mod els such as a generalized linear model, a neural net work, a support-vector machine, or an embedded re gression/classification model (Heckerman and Meek, 1997). From this perspective, the dependency network can be thought of as a mechanism for combining re gression/classification models via Gibbs sampling to determine a joint distribution.\nIn the work described in this paper, we use decision trees for the local distributions. A good discussion of methods for learning decision trees is given in Breiman, Friedman, Olshen, and Stone (1984). We learn a deci sion tree using a simple hill-climbing approach in con junction with a Bayesian score as described in Fried man and Goldszmdit (1996) and Chickering, Hecker man, and Meek (1997). To learn a decision tree for X; , we initialize the search algorithm with a single ton root node having no children. Then, we replace each leaf node in the tree with a binary split on some variable Xj in X \\ X; , until no such replacement in creases the score of the tree. Our binary split on Xj is\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 267\na decision-tree node with two children: one of the chil dren corresponds to a particular value of Xj, and the other child corresponds to all other values of Xj. Our Bayesian scoring function uses a uniform prior distri bution for all decision-tree parameters, and a structure prior proportional to KJ, where K > 0 is a tunable pa rameter and f is the number of free parameters in the decision tree. In studies that predated those described in this paper, we have found that the setting K = 0.01 yields accurate models over a wide variety of datasets. We use this same setting in our experiments.\nFor comparison in these experiments, we also learn Bayesian networks with decision trees for local distri butions using the algorithm described in Chickering, Heckerman, and Meek (1997). When learning these networks, we use the same parameter and structure priors used for dependency networks.\nWe conclude this section by noting an interesting fact about the decision-tree representation of local distri butions. Namely, there will be a split on variable X in the decision tree for Y if and only if there is an arc from X to Y in the dependency network that in cludes these variables. As we shall see in Section 5, this correspondence helps the visualization of data.\n4 Collaborative Filtering\nIn the remainder of this paper, we consider useful ap plications of dependency networks, whether they be consistent or not.\nThe first application is collaborative filtering ( CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what new stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket.\nCollaborative filtering was introduced by Resnick, la covou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of al gorithms for this task. The class of algorithms they described was based on the informal mechanisms peo ple use to understand their own preferences. For ex ample, when we want to find a good movie, we talk to other people that have similar tastes and ask them what they like that we haven't seen. The type of algo rithm introduced by Resnik et al. (1994), sometimes called a memory-based algorithm, does something simi-\nlar. Given a user's preferences on a series of items, the algorithm finds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user.\nAs done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative filtering-that is, preference prediction. In their pa per, Breese et al. (1998) describe several CF sce narios, including binary versus non-binary preferences and implicit versus explicit voting. An example of explicit voting would be movie ratings provided by a user. An example of implicit voting would be know ing only whether a person has or has not purchased a product. Here, we concentrate on one scenario im portant for e-commerce: implicit voting with binary preferences-for example, the task of predicting what products a person will buy, knowing only what other products they have purchased.\nA simple approach to this task, described in Breese et al. (1998), is as follows. For each item (e.g., prod uct), define a variable with two states corresponding to whether or not that item was preferred (e.g., pur chased). We shall use \"0\" and \"1\" to denote not preferred and preferred, respectively. Next, use the dataset of ratings to learn a Bayesian network for the joint distribution of these variables X= (X1, ... , Xn)· The preferences of each user constitutes a case in the learning procedure. Once the Bayesian network is constructed, make predictions as follows. Given a new user's preferences x, use the Bayesian network to determine p(Xi = 1lx \\Xi = 0) for each prod uct Xi not purchased. That is, infer the probability that the user would have purchased the item had we not known he did not. Then, return a list of recom mended products-among those that the user did not purchase-ranked by this probability.\nBreese et al. (1998) show that this approach out performs memory-based and cluster-based methods on several implicit rating datasets. Specifically, the Bayesian-network approach was more accurate and yielded faster predictions than did the other methods.\nWhat is most interesting about this algorithm in the context of this paper is that only the probabilities p(X; = 1lx \\X; = 0) are needed to produce the recom mendations. In particular, these probabilities may be obtained by a direct lookup in a dependency network:\np(Xi = 1lx \\X;= 0) = p(Xi = 1lpa;) (2)\nwhere pai is the instance of Pai consistent with X. Thus, dependency networks are a natural model on which to base CF predictions. In the remainder of this section, we compare this approach with that based\n268 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nWe evaluated Bayesian networks and dependency net works on three datasets: (1) Nielsen, which records whether or not users watched five or more minutes of network TV shows aired during a two-week period in 1995 (made available courtesy of Nielsen Media Re search) , (2) MS. COM, which records whether or not users of microsoft.com on one day in 1996 visited ar eas ( \"vroots\" ) of the site (available on the Irvine Data Mining Repository) , and (3) MSNBC, which records whether or not visitors to MSNBC on one day in 1998 read stories among the most popular 1001 stories on the site. The MSNBC dataset contains 20,000 users sampled at random from the approximate 600,000 users that visited the site that day. In a separate anal ysis on this dataset, we found that the inclusion of ad ditional users did not produce a substantial increase in accuracy. Table 4.1 provides additional information about each dataset. All datasets were partitioned into training and test sets at random.\n4.2 Evaluation Criteria and Experimental Procedure\nWe have found the following three criteria for collab orative filtering to be important: (1) the accuracy of the recommendations, (2) prediction time-the time it takes to create a recommendation list given what is known about a user, and (3) the computational re sources needed to build the prediction models. We measure each of these criteria in our empirical com parison. In the remainder of this section, we describe our evaluation criterion for accuracy.\nOur criterion attempts to measure a user's expected utility for a list of recommendations. Of course, dif ferent users will have different utility functions. The measure we introduce provides what we believe to be a good approximation across many users.\nThe scenario we imagine is one where a user is shown\na ranked list of items and then scans that list for pre ferred items starting from the top. At some point, the user will stop looking at more items. Let p(k) denote the probability that a user will examine the kth item on a recommendation list before stopping his or her scan, where the first position is given by k = 0. Then, a reasonable criterion is\ncfaccuracyt (list) = LP(k) c5k (3) k\nwhere c5k is 1 if the item at position k is preferred and 0 otherwise. To make this measure concrete, we assume that p (k) is an exponentially decaying function: p(k) = Tk/a (4) where a is the \"half-life\" position-the position at which an item will be seen with probability 0.5. In our experiments, we use a= 5.\nIn one possible implementation of this approach, we could show recommendations to a series of users and ask them to rate them as \"preferred\" or \"not preferred\" . We could then use the average of cfaccuarcy1 (list) over all users as our criterion. Be cause this method is extremely costly, we instead use an approach that uses only the data we have. In par ticular, as already described, we randomly partition a dataset into a training set and a test set. Each case in the test set is then processed as follows. First, we randomly partition the user's preferred items into in put and measurement sets. The input set is fed to the CF model, which in turn outputs a list of recommen dations. Finally, we compute our criterion as\nN . 100 \"'\"' Lk cS;k p(k) cfaccuracy (hst) = N L... K 1 i=l L:k,;,; p(k)\n(5)\nwhere N is the number of users in the test set, K; is the number of preferred items in the measurement set for user i, and c5;k is 1 if the kth item in the recommen dation list for user i is preferred in the measurement set and 0 otherwise. The denominator in Equation 5 is a per-user normalization factor. It is the utility of a list where all preferred items are at the top. This nor malization allows us to more sensibly combine scores across measurement sets of different size.\nWe performed several experiments reflecting differing numbers of ratings available to the CF engines. In the first protocol, we included all but one of the preferred items in the input set. We term this protocol all but 1. In additional experiments, we placed 2, 5, and 10 pre ferred items in the input sets. We call these protocols given 2, given 5, and given 10.\nThe all but 1 experiments measure the algorithms' per formance when given as much data as possible from\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 269\neach test user. The various given experiments look at users with less data available, and examine the perfor mance of the algorithms when there is relatively little known about an active user. When running the given m protocols, if an input set for a given user had less than m preferred items, the case was eliminated from the evaluation. Thus the number of trials evaluated under each protocol varied.\nAll experiments were performed on a 300 MHz Pen tium II with 128 MB of memory, running the NT 4.0 operating system.\n4.3 Results\nTable 2 shows the accuracy of recommendations for Bayesian networks and dependency networks across the various protocols and three datasets. For a com parison, we also measured the accuracy of recommen dation lists produced by sorting items on their overall popularity, p(X; = 1). The accuracy of this approach is shown in the row labeled \"Baseline.\" A score in boldface corresponds to a significantly significant win ner. We use ANOVA (e.g., McClave and Dietrich, 1988) with a = 0.1 to test for statistical significance. When the difference between two scores in the same column exceed the value of RD (required difference), the difference is significant.\nFrom the table, we see that Bayesian networks are more accurate than dependency networks. This re sult is interesting, because there are reasons to ex pect that dependency networks will be more accurate than Bayesian networks and vice versa. On the one hand, the search process that learns Bayesian net works is constrained by acyclicity, suggesting that de pendency networks may be more accurate. On the other hand, the conditional probabilities used to sort the recommendations are inferred from the Bayesian network, but learned directly in the dependency net work. Therefore, dependency networks may be less accurate, because they waste data in the process of learning what could otherwise be inferred. For this or perhaps other reasons, the Bayesian networks are more accurate.\nThe magnitudes of accuracy differences, however, are not that large. In particular, the ratio of ( cfac curacy (BN) - cfaccuracy (DN)) to ( cfaccuracy (BN) - cfaccuracy(Baseline)) averages 4 ± S percent across the datasets and protocols.\nTables 3 and 4 compare the two methods with the remaining criteria. Here, dependency networks are a clear winner. They are significantly faster at prediction-sometimes by almost an order of magnitude-and require substantially less time and memory to learn."
    }, {
      "heading" : "MS.COM",
      "text" : ""
    }, {
      "heading" : "MSNBC",
      "text" : "Overall, Bayesian networks are slightly more accurate but much less attractive from a computational per spective.\n5 Data Visualization\nBayesian networks are well known to be useful for visualizing causal relationships. In many circum stances, however, analysts are only interested in predictive-that is, dependency and independency relationships. In our experience, the directed-arc se mantics of Bayesian networks interfere with the visu alization of such relationships.\nAs a simple example, consider the Bayesian network X --+ Y. Those familiar with the semantics of Bayesian networks immediately recognize that observ ing Y helps to predict X. Unfortunately, the untrained individual will not. In our experience, this person will interpret this network to mean that only X helps to predict Y, and not vice versa. Even people who are expert in d-separation semantics will sometimes have difficulties visualizing predictive relationships using a Bayesian network. The cognitive act of identifying a node's Markov blanket seems to interfere with the vi sualization experience.\nDependency networks are a natural remedy to this\n270 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nproblem. If there is no arc from X to Y in a depen dency network, we know immediately that X does not help to predict Y.\nFigure 1 shows a dependency network learned from a dataset obtained from Media Metrix. The dataset contains demographic and internet-use data for about 5,000 individuals during the month of January 1997. On first inspection of this network, an interest ing observation becomes apparent: there are many (predictive) dependencies among demographics, and many dependencies among frequency-of-use, but there are few dependencies between demographics and frequency-of-use.\nOver the last three years, we have found numerous interesting dependency relationships across a wide va riety of datasets using dependency networks for visu alization. In fact, we have given dependency networks this name because they have been so useful in this regard.\nThe network in Figure 1 is displayed in DNViewer, a dependency-network visualization tool developed at Microsoft Research. The tool allows a user to display both the dependency-network structure and the de cision tree associated with each variable. Navigation between the views is straightforward. To view a de cision tree for a variable, a user simply double clicks on the corresponding node in the dependency network. Figure 2 shows the tree for Shopping.Freq.\nAn inconsistent dependency net learned from data of fers an additional advantage for visualization. If there is an arc from X to Y in such a network, we know that X is a significant predictor of Y -significant in what ever sense was used to learn the network. Under this interpretation, a uni-directional link between X and Y is not confusing, but rather informative. For example, in Figure 1, we see that Sex is a significant predictor of Socioeconomic status, but not vice versa-an in teresting observation. Of course, when making such interpretations, one must always be careful to recog nize that statements of the form \"X helps to predict Y\" are made in the context of the other variables in the network.\nIn DNViewer, we enhance the ability of dependency networks to reflect strength of dependency by includ ing a slider (on the left). As a user moves the slider from bottom to top, arcs are added to the graph in the order in which arcs are added to the dependency net work during the learning process. When the slider is in its upper-most position, all arcs (i.e., all significant dependencies) are shown.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 271\nFigure 1: A dependency network for Media Metrix data. The dataset contains demographic and internet-use data for about 5,000 individuals during the month of January 1997. The node labeled Overall.Freq represents the overall frequency-of-use of the internet during this period. The nodes Search.Freq, Edu.Freq, and so on represent frequency-of-use for various subsets of the internet.\n� /\nr.',:, � 101·200(701] �\n(20C>l) J (2802) 01'-(20� 3<51·0<50(�'1!!!i':J � ahw(1373] � �\n051·100� ..\n� . � other(865) ott..r(567) . Low(181) �� � 201·3150� NoM(�\nFigure 2: The decision tree for Shopping.Freq obtained by double-clicking that node in the dependency network. The histograms at the leaves correspond to probabilities of Shopping.Freq use being zero, one, and greater than one visit per month, respectively.\n272 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nr\nI I I\nI -s� irko\nFigure 3: The dependency network in Figure 1 with the slider set at half position.\nFigure 3 shows the dependency network for the Media Metrix data with the slider at half position. At this setting, we find the interesting observation that the dependencies between Sex and XXX.Freq (frequency of hits to pornographic pages) are the strongest among all dependencies between demographics and internet use.\n6 Summary and Future Work\nWe have described a new representation for probabilis tic dependencies called a dependency network. We have shown that a dependency network (consistent or not) defines a joint distribution for its variables, and that models in this class are easy to learn from data. In particular, we have shown how a dependency network can be thought of as a collection of regres sion/classification models among variables in a domain that can be combined using Gibbs sampling to define a joint distribution for the domain. In addition, we have shown that this representation is useful for col laborative filtering and the visualization of predictive relationships.\nOf course, this research is far from complete. There are many questions left to be answered. For example,\nwhat are useful models (e.g., generalized linear models, neural networks, support-vector machines, or embed ded regression/classification models) for a dependency network's local distributions? Another example of par ticular theoretical interest is Hofmann's (2000) result that small 12-norm perturbations in the local distribu tions lead to small 12-norm perturbations in the joint distributions defined by the dependency network. Can this result be extended to norms more appropriate for probabilities such as cross entropy?\nFinally, the dependency network and Bayesian net work can be viewed as two extremes of a spectrum. The dependency network is ideal for situations where the conditionals p(x;lx \\ x;) are needed. In con trast, when we require the joint probabilities p(x), the Bayesian network is ideal because these probabil ities may be obtained simply by multiplying condi tional probabilities found in the local distributions of the variables. In situations where we need probabili ties of the form p(y lx \\ y), where Y is a proper subset of the domain X, we can build a network structure that enforces an acyclicity constraint among only the variables Y. In so doing, the conditional probabilities p(ylx \\ y) can be obtained by multiplication.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 273\nAcknowledgments\nWe thank Reimar Hofmann for useful discussions. Datasets for this paper were generously provided by Media Metrix, Nielsen Media Research (Nielsen), Mi crosoft Corporation (MS.COM), and Steven White and Microsoft Corporation (MSNBC).\nReferences\nBreese, J. S., Heckerman, D., and Kadie, C. (1998). Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of Four teenth Conference on Uncertainty in Artificial\nIntelligence, Madison, Wisconsin. Morgan Kauf mann.\nChickering, D., Heckerman, D., and Meek, C. (1997). A Bayesian approach to learning Bayesian net works with local structure. In Proceedings of Thirteenth Conference on Uncertainty in Artifi\ncial Intelligence, Providence, Rl. Morgan Kauf mann.\nDieterich, F. and McClave, J. (1988). Statistics. Dellen Publishing Company.\nFeller, W. (1957). An Introduction to Probability The ory and Its Applications. Wiley and Sons, New York.\nFriedman, N. and Goldszmidt, M. (1996). Learning Bayesian networks with local structure. In Pro ceedings of Twelfth Conference on Uncertainty in\nArtificial Intelligence, Portland, OR, pages 252- 262. Morgan Kaufmann.\nGilks, W., Richardson, S., and Spiegelhalter, D. (1996). Markov Chain Monte Carlo in Practice. Chapman and Hall.\nHeckerman, D., Chickering, D., Meek, C., Rounth waite, R., and Kadie, C. (2000). Dependency networks for inference, collaborative filtering, and data visualization. Technical Report MSR TR-00-16, Microsoft Research, Redmond, WA.\nHeckerman, D. and Meek, C. (1997). Models and selec tion criteria for regression and classification. In Proceedings of Thirteenth Conference on Uncer\ntainty in Artificial Intelligence, Providence, Rl. Morgan Kaufmann.\nHofmann, R. (2000). Inference in Markov blanket net works. Technical Report FKI-235-00, Technical University of Munich.\nHofmann, R. and Tresp, V. (1997). Nonlinear Markov networks for continuous variables. In Mozer, M., Jordan, M., and Petsche, T., editors, Ad vances in Neural Information Processing Sys\ntems 9. MIT Press.\nResnik, P., lacovou, N., Suchak, M., Bergstrom, P., and Riedl, J. (1994). Grouplens: An open ar chitecture for collaborative filtering of netnews. In Proceedings of the A CM 1994 Conference on Computer Supported Cooperative Work, pages 175-186. ACM."
    } ],
    "references" : [ {
      "title" : "Empirical analysis of predictive algorithms for collaborative filtering",
      "author" : [ "J.S. Breese", "D. Heckerman", "C. Kadie" ],
      "venue" : "Proceedings of Four­ teenth Conference on Uncertainty in Artificial Intelligence, Madison, Wisconsin. Morgan Kauf­",
      "citeRegEx" : "Breese et al\\.,? 1998",
      "shortCiteRegEx" : "Breese et al\\.",
      "year" : 1998
    }, {
      "title" : "A Bayesian approach to learning Bayesian net­ works with local structure",
      "author" : [ "D. Chickering", "D. Heckerman", "C. Meek" ],
      "venue" : "Proceedings of Thirteenth Conference on Uncertainty in Artifi­ cial Intelligence, Providence, Rl. Morgan Kauf­",
      "citeRegEx" : "Chickering et al\\.,? 1997",
      "shortCiteRegEx" : "Chickering et al\\.",
      "year" : 1997
    }, {
      "title" : "Statistics",
      "author" : [ "F. Dieterich", "J. McClave" ],
      "venue" : "Dellen Publishing Company.",
      "citeRegEx" : "Dieterich and McClave,? 1988",
      "shortCiteRegEx" : "Dieterich and McClave",
      "year" : 1988
    }, {
      "title" : "An Introduction to Probability The­ ory and Its Applications",
      "author" : [ "W. Feller" ],
      "venue" : "Wiley and Sons, New York.",
      "citeRegEx" : "Feller,? 1957",
      "shortCiteRegEx" : "Feller",
      "year" : 1957
    }, {
      "title" : "Learning Bayesian networks with local structure",
      "author" : [ "N. Friedman", "M. Goldszmidt" ],
      "venue" : "Pro­ ceedings of Twelfth Conference on Uncertainty in Artificial Intelligence, Portland, OR, pages 252262. Morgan Kaufmann.",
      "citeRegEx" : "Friedman and Goldszmidt,? 1996",
      "shortCiteRegEx" : "Friedman and Goldszmidt",
      "year" : 1996
    }, {
      "title" : "Markov Chain Monte Carlo in Practice",
      "author" : [ "W. Gilks", "S. Richardson", "D. Spiegelhalter" ],
      "venue" : "Chapman and Hall.",
      "citeRegEx" : "Gilks et al\\.,? 1996",
      "shortCiteRegEx" : "Gilks et al\\.",
      "year" : 1996
    }, {
      "title" : "Dependency networks for inference, collaborative filtering, and data visualization",
      "author" : [ "D. Heckerman", "D. Chickering", "C. Meek", "R. Rounth­ waite", "C. Kadie" ],
      "venue" : "Technical Report MSR­ TR-00-16,",
      "citeRegEx" : "Heckerman et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 2000
    }, {
      "title" : "Models and selec­ tion criteria for regression and classification",
      "author" : [ "D. Heckerman", "C. Meek" ],
      "venue" : "Proceedings of Thirteenth Conference on Uncer­ tainty in Artificial Intelligence, Providence, Rl. Morgan Kaufmann.",
      "citeRegEx" : "Heckerman and Meek,? 1997",
      "shortCiteRegEx" : "Heckerman and Meek",
      "year" : 1997
    }, {
      "title" : "Inference in Markov blanket net­ works",
      "author" : [ "R. Hofmann" ],
      "venue" : "Technical Report FKI-235-00, Technical University of Munich.",
      "citeRegEx" : "Hofmann,? 2000",
      "shortCiteRegEx" : "Hofmann",
      "year" : 2000
    }, {
      "title" : "Nonlinear Markov networks for continuous variables",
      "author" : [ "R. Hofmann", "V. Tresp" ],
      "venue" : "Mozer, M., Jordan, M., and Petsche, T., editors, Ad­ vances in Neural Information Processing Sys­ tems 9. MIT Press.",
      "citeRegEx" : "Hofmann and Tresp,? 1997",
      "shortCiteRegEx" : "Hofmann and Tresp",
      "year" : 1997
    }, {
      "title" : "Grouplens: An open ar­ chitecture for collaborative filtering of netnews",
      "author" : [ "P. Resnik", "N. lacovou", "M. Suchak", "P. Bergstrom", "J. Riedl" ],
      "venue" : "In Proceedings of the A CM",
      "citeRegEx" : "Resnik et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Resnik et al\\.",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The representation was conceived independently by Hofmann and Tresp (1997), who used it for density es­",
      "startOffset" : 50,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : "timation; and Hofmann (2000) investigated several of its theoretical properties.",
      "startOffset" : 14,
      "endOffset" : 29
    }, {
      "referenceID" : 6,
      "context" : "In addition, Heckerman et al. (2000) show empirically using several real datasets that the joint distributions defined by a Bayesian network and dependency network, both learned from data, are sim­",
      "startOffset" : 13,
      "endOffset" : 37
    }, {
      "referenceID" : 6,
      "context" : "We close this section with several facts about consis­ tent dependency networks, proved in Heckerman et al. (2000). We say that a dependency network for X is bi-directional if X; is a parent of Xj if and only if Xj is a parent of X; , for all X; and Xj in X.",
      "startOffset" : 91,
      "endOffset" : 115
    }, {
      "referenceID" : 10,
      "context" : "The type of algo­ rithm introduced by Resnik et al. (1994), sometimes called a memory-based algorithm, does something similar.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "In their pa­ per, Breese et al. (1998) describe several CF sce­ narios, including binary versus non-binary preferences and implicit versus explicit voting.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "A simple approach to this task, described in Breese et al. (1998), is as follows.",
      "startOffset" : 45,
      "endOffset" : 66
    }, {
      "referenceID" : 8,
      "context" : "ticular theoretical interest is Hofmann's (2000) result that small 12-norm perturbations in the local distribu­ tions lead to small 12-norm perturbations in the joint distributions defined by the dependency network.",
      "startOffset" : 32,
      "endOffset" : 49
    } ],
    "year" : 2011,
    "abstractText" : "We describe a graphical representation of probabilistic relationships-an alternative to the Bayesian network-called a dependency network. Like a Bayesian network, a depen­ dency network has a graph and a probabil­ ity component. The graph component is a (cyclic) directed graph such that a node's parents render that node independent of all other nodes in the network. The probabil­ ity component consists of the probability of a node given its parents for each node (as in a Bayesian network) . We identify several ba­ sic properties of this representation, and de­ scribe its use in collaborative filtering (the task of predicting preferences) and the visu­ alization of predictive relationships.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}