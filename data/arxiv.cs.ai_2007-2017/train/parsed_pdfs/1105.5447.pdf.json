{
  "name" : "1105.5447.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Diane J. Cook", "Craig Varnell" ],
    "emails" : [ "cook@cse.uta.edu", "cvarnell@sfasu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Journal of Arti cial Intelligence Research 9 (1998) 139-166 Submitted 4/98; published 10/98 Adaptive Parallel Iterative Deepening SearchDiane J. Cook cook@cse.uta.eduDepartment of Computer Science and EngineeringUniversity of Texas at ArlingtonBox 19015, Arlington, TX 76019 USAR. Craig Varnell cvarnell@sfasu.eduDepartment of Computer ScienceStephen F. Austin State UniversityBox 13063, Nacogdoches, TX 75962 USA AbstractMany of the arti cial intelligence techniques developed to date rely on heuristic searchthrough large spaces. Unfortunately, the size of these spaces and the corresponding com-putational e ort reduce the applicability of otherwise novel and e ective algorithms. Anumber of parallel and distributed approaches to search have considerably improved theperformance of the search process.Our goal is to develop an architecture that automatically selects parallel search strate-gies for optimal performance on a variety of search problems. In this paper we describeone such architecture realized in the Eureka system, which combines the bene ts of manydi erent approaches to parallel heuristic search. Through empirical and theoretical anal-yses we observe that features of the problem space directly a ect the choice of optimalparallel search strategy. We then employ machine learning techniques to select the optimalparallel search strategy for a given problem space. When a new search task is input to thesystem, Eureka uses features describing the search space and the chosen architecture toautomatically select the appropriate search strategy. Eureka has been tested on a MIMDparallel processor, a distributed network of workstations, and a single workstation usingmultithreading. Results generated from fteen puzzle problems, robot arm motion prob-lems, arti cial search spaces, and planning problems indicate that Eureka outperformsany of the tested strategies used exclusively for all problem instances and is able to greatlyreduce the search time for these applications.1. IntroductionBecause of the dependence AI techniques demonstrate upon heuristic search algorithms,researchers continually seek more e cient methods of searching through the large spacescreated by these algorithms. Advances in parallel and distributed computing o er poten-tially large increases in performance to such compute-intensive tasks. In response, a numberof parallel approaches have been developed to improve various search algorithms includingdepth- rst search (Kumar & Rao, 1990), branch-and-bound search (Agrawal, Janakiram,& Mehrotra, 1988), A* (Evett, Hendler, Mahanti, & Nau, 1995; Mahapatra & Dutt, 1995),IDA* (Mahanti & Daniels, 1993; Powley, Ferguson, & Korf, 1993; Powley & Korf, 1991),and game tree search (Feldmann, Mysliwietz, & Monien, 1994), as well as to improve therun time of speci c applications such as the fteen puzzle problem (Kumar & Rao, 1990)and robot arm path planning (Challou, Gini, & Kumar, 1993). In addition to MIMDc 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nCook and Varnelldistributed-memory algorithms, parallel search algorithms have been developed for MIMDshared-memory systems (Kale & Saletore, 1990; Kumar & Rao, 1990) and SIMD archi-tectures (Cook & Lyons, 1993; Evett et al., 1995; Karypis & Kumar, 1992; Mahanti &Daniels, 1993; Powley et al., 1993). While existing approaches to parallel search have manycontributions to o er, comparing these approaches and determining the best use of eachcontribution is di cult because of the diverse search algorithms, implementation platforms,and applications reported in the literature.In response to this problem, we have developed the Eureka parallel search enginethat combines many of these approaches to parallel heuristic search. Eureka (Cook &Varnell, 1997) is a parallel IDA* search architecture that merges multiple approaches totask distribution, load balancing, and tree ordering, and can be run on a MIMD sharedmemory or distributed memory parallel processor, a distributed network of workstations,or a single machine with multithreading. Using our collection of search algorithms, weperform theoretical and empirical comparisons and observe that performance trends doexist as search space features are varied. To capitalize on these trends, Eureka uses amachine learning system to predict the optimal set of parallel search strategies for a givenproblem, which are then used to complete the search task.2. Parallel Search ApproachesA number of researchers have explored methods for improving the e ciency of search usingparallel hardware. We will focus in this paper on parallel search techniques that can beapplied to IDA* search. IDA* performs a series of incrementally-deepening depth- rstsearches through the search space. In each iteration through the space, the depth of thesearch is controlled by an A* cost threshold. If a goal node is not found during a giveniteration, search begins at the root node with a cost threshold set to the minimum f(n)value in the search space that exceeded the previous threshold. IDA* is an admissible searchalgorithm which requires an amount of memory linear in the depth of the solution.In this section we will review existing methods for parallelizing IDA* search. In particu-lar, we will consider alternative techniques for task distribution, for dynamically balancingwork between processors, and for changing the left-to-right order of the search tree.2.1 Task DistributionA search algorithm implemented on a parallel system requires a balanced division of workbetween contributing processors to reduce idle time and minimize redundant or wastede ort. One method of dividing up the work in IDA* search is with a parallel windowsearch (PWS), introduced by Powley and Korf (1991). Using PWS, each processor is givena copy of the entire search tree and a unique cost threshold. The processors search thesame tree to di erent thresholds simultaneously. If a processor completes an iterationwithout nding a solution, it is given a new unique threshold (deeper than any thresholdyet searched) and begins a new search pass with the new threshold. When an optimalsolution is desired, processors that nd a goal node must remain idle until all processorswith lower cost thresholds have completed their current iteration. A typical division of workusing PWS is illustrated in Figure 1. 140\nAdaptive Parallel Iterative Deepening Search\n= expanded by processors 2 and 3\nGOAL\nINITIAL\n= expanded by processors 1, 2, and 3\n= expanded by processor 3Figure 1: Division of work in parallel window searchOne advantage of parallel window search is that the redundant search inherent in IDA* isnot performed serially. During each non-initial iteration of IDA*, all of the nodes expandedin the previous iteration are expanded again. Using multiple processors, this redundant workis performed concurrently. A second advantage of parallel window search is the improvedtime in nding a rst solution. If a search space holds many goal nodes, IDA* may nd adeep solution much more quickly than an optimal solution. Parallel window search can takeadvantage of this type of search space. Processors that are searching beyond the optimalthreshold may nd a solution down the rst branch they explore, and can return thatsolution long before other processors nish their iteration. This may result in superlinearspeedup because the serial algorithm conservatively increments the cost threshold and doesnot look beyond the current threshold.On the other hand, parallel window search can face a decline in e ciency when thenumber of processors is signi cantly greater than the number of iterations required to ndan optimal (or a rst) solution, causing all remaining processors to sit idle. This situationwill occur when many processors are available, yet few iterations are required because theheuristic estimate is fairly accurate.An alternative parallel search approach relies on distributing the tree among the pro-cessors (Kumar & Rao, 1990; Rao, Kumar, & Ramesh, 1987). With this approach, the rootnode of the search space is given to the rst processor and other processors are assignedsubtrees of that root node as they request work. As an alternative, the distributed treesearch algorithm (DTS) employs breadth- rst expansion until there are at least as manyexpanded leaf nodes as available processors. Processors receive unique nodes from the ex-panding process and are responsible for the entire subtree rooted at the received node.Communication-free versions of this distribution scheme have also been reported (Mahapa-tra & Dutt, 1995; Reinefeld & Schnecke, 1994). In all of these tree distribution approaches,the processors perform IDA* on their unique subtrees simultaneously. All processors searchto the same threshold. After all processors have nished a single iteration, they begin a newsearch pass through the same set of subtrees using a larger threshold. A sample distributionof the search space is shown in Figure 2. 141\nCook and Varnell\nOne advantage of this distribution scheme is that no processor is performing wastedwork beyond the goal depth. Because the algorithm searches the space completely to onethreshold before starting the search to a new threshold, none of the processors is eversearching at a level beyond the level of the optimal solution. It is possible, however, forDTS to perform wasted work at the goal depth. For example, in Figure 2 processor 3searches nodes at the goal level that would not be searched in a serial search algorithmmoving left-to-right through the tree.A disadvantage of this approach is the fact that processors are often idle. To ensureoptimality, a processor that quickly nishes one iteration must wait for all other processors to nish before starting the next iteration. This idle time can make the system very ine cientand reduce the performance of the search application. The e ciency of this approach canbe improved by performing load balancing between neighboring processors working on thesame iteration.These described approaches o er unique bene ts. Parallel window search is e ectivewhen many iterations of IDA* are required, when the tree is so imbalanced that DTS willrequire excessive load balancing, or when a deep, non-optimal solution is acceptable. Onthe other hand, dividing the search space among processors can be more e ective whenthe branching factor is very large and the number of IDA* iterations is relatively small.A compromise between these approaches divides the set of processors into clusters (Cook,1997). Each cluster is given a unique cost threshold, and the search space is divided betweenprocessors within each cluster, as shown in Figure 3. Setting the number of clusters to onesimulates distributed tree search, and setting the number of clusters to the number ofavailable processors simulates parallel window search.142\nAdaptive Parallel Iterative Deepening Search Cluster 1\nINITIAL\nCluster 2 INITIAL\nProcessor 1 Processor 2 Processor 3 Processor 4 Processor 5 Processor 6Figure 3: Space searched by two clusters, each with 3 processors2.2 Load BalancingWhen a problem is broken into disjoint subtasks the workload will likely vary among pro-cessors. Because one processor may run out of work before others, load balancing is used toactivate the idle processor. The rst phase of load balancing involves selecting a processorfrom which to request work. One example is the nearest neighbor approach (Mahapatra& Dutt, 1995); alternative approaches include selecting random processors or allowing amaster processor to keep track of processor loads and send the ID of a heavily loaded pro-cessor to one that is idle. During the second phase of load balancing, the donating processordecides which work, if any, to give. A search algorithm typically stores nodes which havenot been fully expanded on an Open list. When giving work to another processor, nodescan be given from the head of the list (deep in the tree), the tail (near the root), or from asampling of all levels (Kumar & Rao, 1990).A number of approaches have been introduced for reducing processor idle time using aload balancing operation. Using the quality equalizing strategy (Mahapatra & Dutt, 1995),processors anticipate idle time by sending out a work request when their load is almostempty, so that they can continue processing remaining nodes while waiting for a response.Alternative approaches are not receiver based, but allow an overly-loaded processor toinitiate a load balance operation (Furuichi, Taki, & Ichyoshi, 1990; Rajpal & Kumar, 1993)or allow all processors to periodically shift work to keep the average load within acceptablebounds (Anderson & Chen, 1987; Saletore, 1990).2.3 Tree OrderingProblem solutions can exist anywhere in the search space. Using IDA* search, the childrenare expanded in a depth- rst manner from left to right, bounded in depth by the costthreshold. If the solution lies on the right side of the tree, a far greater number of nodes143\nCook and Varnell 0 1 2 3\n0 1 2 3 0 1 2 3\n0 1 2 3\nOriginal Ordering: 0123 New Ordering: 1320 0 1 2 3\n*\n0 1 2 3\n. . .\nMost promising node* Figure 4: Operator ordering examplemust be expanded than if the solution lies on the left side of the tree. If information canbe found to re-order the operators in the tree from one search iteration to the next, theperformance of IDA* can be greatly improved.Powley and Korf suggest two methods of ordering the search space (1991). First, childrenof each node can be ordered and expanded by increasing heuristic distance to a goal node.Alternatively, the search algorithm can expand the tree a few levels and sort the frontierset (the set of nodes at that level in the tree) by increasing h value. Search begins eachiteration from the frontier set and this frontier set is updated each iteration. In both ofthese cases, although the nodes may have the same f value, nodes with smaller h valuesgenerally re ect a more accurate estimated distance and are preferred.Instead of ordering individual nodes, Cook et al. (1993) order the set of operators toguide the next IDA* iteration to the most promising node. The most promising node isthe node from the cut-o set (a child node not expanded in the previous iteration) withthe smallest h value. As an example, Figure 4 shows a search tree expanded using oneiteration of IDA* with operator ordering 0, 1, 2, 3. The path to the most promising leafnode (indicated with a star) is 1 3 2 3 0. The new operator ordering is computed usingthe order of operators as they appear in this path after removing duplicates. Operatorsnot appearing in the path are added to the end of the operator list, retaining their originalrelative ordering. Thus the ordering of operators for the example in Figure 4 changes from0, 1, 2, 3 (try operator 0 rst, operator 1 next, operator 2 next, and operator 3 last forevery node in the tree) to 1, 3, 2, 0. 144\nAdaptive Parallel Iterative Deepening SearchThis section describes a number of alternative approaches to parallel search. Our theo-retical empirical analyses in the following sections demonstrate that many of the reportedapproaches o er some bene t in certain conditions, but no single approach is always themost e ective at scaling AI algorithms.3. Comparison of Alternative Approaches to Parallel SearchOne method of determining the comparative bene ts of parallel search approaches is bydetermining the theoretical bounds on possible speedup obtained using each approach.A second method is to perform empirical comparisons between the approaches. In thissection we will draw on theoretical analyses and empirical comparisons to determine whereperformance trends exist and to illustrate conditions under which alternative approachescan perform best.3.1 Theoretical AnalysisIn the literature we nd theoretical analyses for the alternative approaches to one aspectof parallel search, namely task distribution. Kumar and Rao (1990) provide an analysisof the speedup of distributed tree search, and Powley and Korf (1991) provide an analysisof parallel window search. In this section we summarize these analyses with a unifyingrepresentation, and empirically compare the performance of the techniques using the derivedequations.These analyses assume that the average branching factor b remains constant throughoutthe search space and that the least-cost goal is located at a depth d. We also let b representthe heuristic branching factor, or the ratio of nodes generated during one iteration of IDA*to the number of nodes generated during the previous iteration of IDA*. Forcing theheuristic branching factor to be equal to the average branching allows the analysis to bethe same as for incremental-deepening depth- rst search.For the distributed tree search analysis, we assume that a breadth- rst expansion is usedto generate enough nodes, n, to distribute one node to each of P processors. Since n = bxand n P , we can assume that the tree is expanded to depth x where x logbP .We will assume a time of 2bx 2P to perform the node distribution and to collect thesolution results from each processor. The speedup of distributed tree search, measuredas the run time of the serial algorithm divided by the run time of the parallel algorithm,can be computed here as the number of serial nodes generated (assuming a constant nodeexpansion time) divided by the number of serial node expansions performed by the parallelalgorithm. This is derived in the literature (Kumar & Rao, 1990; Varnell, 1997) asS = P bd + bd 1 + bd 2 + + b2 + bbd + bd 1 + bd 2 + + bx+1 !+ 12bx : (1)As d increases, the leftmost fractional part of this equation approaches 1 and can beignored. The 1=2bx term contributes a minimal amount to the nal value and can also beignored. In this case, speedup approaches P , which represents linear speedup.Figure 5 shows the performance of the distributed tree search algorithm based on theseequations on a perfectly balanced tree and on a heavily imbalanced tree for P = 10, b = 3,145\nCook and Varnell\n0\n1e+07\n2e+07\n3e+07\n4e+07\n5e+07\n6e+07\n7e+07\n8e+07\n0 0.2 0.4 0.6 0.8 1 N\no d e s G\ne n e ra\nte d\nGoal Position\nPerfect Balance Imbalanced\nSingle processor\nFigure 5: Distributed Tree Search Contrasting Tree Balanceand d = 10. In the imbalanced case, the size of the processors' search spaces varies as anexponential function where the rst processor is assigned a majority of the work and theload decreases as the processor number increases. In this graph, the goal position rangesfrom the far left side of the tree (position = 0) to the far right side of the tree (position =1). Performance of the search algorithm always peaks when the goal is on the far left sideof a processor's portion of the search space. For the case of an imbalanced tree, much ofthe search space is assigned to a single processor, which increases the resulting amount ofserial e ort required.We next consider the theoretical performance of the parallel window search algorithm.Recall that parallel window search operates by distributing the window sizes, or cost thresh-olds, to each available processor so each processor performs one iteration of IDA*. Sincethresholds are not explored sequentially, the rst solution found may not represent an op-timal path. To ensure an optimal solution, all processors with a lower threshold mustcomplete their current iteration of IDA*. In the worst case, this can make the performanceof parallel window search equal to that of a serial version of IDA*.In this analysis the assumption is made that a su cient number of processors exists suchthat the goal iteration will start without delay. Speedup of parallel window search can becalculated as the ratio of the number of non-goal plus goal iteration nodes to the number ofnodes generated by the processor performing the goal iteration. Powley and Korf generatethis ratio using the notion of the left-to-right goal position a, de ned as the fraction of thetotal number of nodes in the goal iteration that must be expanded before reaching the rstgoal node (1991). Speedup of parallel window search can thus be expressed asS = bd 1 bb 1 2 + abd bb 1 abd bb 1 = 1 + 1a(b 1) : (2)Given this formula, we can empirically compare the performance of distributed treesearch and parallel window search for P = 10, b = 6, and d = 10. From the graph inFigure 6 we can see that parallel window search will outperform distributed tree search onlyif the goal is located on the far left of the search space. We also observe that performance146\nAdaptive Parallel Iterative Deepening Search\n0\n5\n10\n15\n20\n25\n30\n0 0.2 0.4 0.6 0.8 1 %\nP e rf\no rm\na n c e I m\np ro\nv e m\ne n t\nGoal Position\nParallel Window Search Distributed Tree Search\nFigure 6: Distributed Tree Search vs. Parallel Window Searchof distributed tree search peaks whenever the goal node is located on the far left of thesubspace assigned to a particular processor.Similar analyses have been provided to compare node ordering techniques and to de-termine the optimal number of clusters (Cook et al., 1993; Powley & Korf, 1991; Varnell,1997). These analyses do indicate trends in the performance of alternative strategies basedon features of the problem space, and can also be used to determine the theoretical perfor-mance of a particular technique for a given problem. However, the terms used to predict theperformance in many of these analyses are not always measurable and many assumptionsmade are too constraining for real-world problems.3.2 Empirical AnalysisA second method of determining the comparative bene ts of parallel search approaches isvia empirical analyses. We have implemented a number of the approaches to parallel searchdescribed earlier in this paper in the Eureka system. We have also constructed an arti cialsearch space generator to provide a testbed for these experiments. Search space parameterscan be established by the user, including: the cost of the optimal solution, the left-to-right position of the goal node in the space, the branching factor, the tree imbalance, the solution density (fraction of nodes at or beyond the optimal solution cost thatrepresent goal nodes), and the heuristic error (the di erence between the estimated and true distances to thenearest goal node). 147\nCook and Varnell\n0\n1\n2\n3\n4\n5\n2 2.5 3 3.5 4 4.5 5 # C\nlu s te rs Branching FactorFigure 7: Branching Factor and Optimal Number of Clusters\n0\n2\n4\n6\n8\n10\n0 0.2 0.4 0.6 0.8 1\n# C\nlu s te\nrs\nImbalanceFigure 8: Tree Imbalance and Optimal Number of ClustersAll of the experiments described here were run on an nCUBE II message-passing multipro-cessor using 32 processors.In our rst experiment we consider how the optimal number of clusters may be a ectedby features of the problem space including branching factor, tree imbalance, and solutionposition. Figures 7, 8, and 9 demonstrate that the optimal number of clusters increases asthe branching factor decreases (with a balanced tree, an optimal cost of 16, and the goalon the far right side of the tree), as the imbalance increases (with a branching factor of 3,an optimal cost of 15, and the goal in the middle of the tree), or as the goal node movesto the right side of the tree (with a balanced tree, a branching factor of 3, and an optimalcost of 15). In no case did one single number of clusters always perform best.In the next experiment we focus on the e ects of operator ordering. Figure 10a demon-strates that employing operator ordering causes an increase in the optimal number of clus-ters, and Figure 10b shows that operator ordering (using perfect ordering information)results in a more signi cant improvement over no ordering as the solution node is posi-tioned farther to the right in the tree. In this experiment the search trees are balanced with148\nAdaptive Parallel Iterative Deepening Search\n0\n2\n4\n6\n8\n10\n0 0.2 0.4 0.6 0.8 1 # C\nlu s te rs Solution PositionFigure 9: Goal Position and Optimal Number of Clusters\nC ha\nng e\nin O\npt im\nal #\nC lu\nst er\ns\n20 10\n0.8\nSolution Position\n0 0.0 0.4\nSp ee\ndu p\n1.8 1.4\nSolution Position 0.0 0.4 0.8\n1.0\n1.2\n1.6\na) Ordering effect on optimal #clusters b) Solution position effect on speedupFigure 10: Ordering e ectsa branching factor of 4 and an optimal cost of 12. The dip in the plot occurs when the goalis positioned on the far left of a particular processor's subspace.4. The EUREKA SystemThe empirical and theoretical comparisons presented in the previous section indicate thatalternative parallel search strategies perform well under di erent conditions, and that per-formance trends do exist which can be used to automatically select strategies and parametersettings for new problems. However, the results of these studies are not su cient for auto-matically determining the appropriate set of strategies. One limitation is that informationused to generate the formulas and to control the experiments, such as goal position, is notknown in advance. Another limitation is that some of the assumptions, such as a constantbranching factor, are not realistic for many applications. As a result, we need a method149\nCook and Varnellto automatically select optimal strategies for real-world problems given information that isavailable.In response to this need, we add a machine learning component to the Eureka sys-tem. Eureka merges many of the approaches to parallel search discussed the previoussection. Parameters can be set that control the task distribution strategy, the load balanc-ing strategies, and the ordering techniques. In particular, the strategies that can be selectedinclude: Distribution strategy [Kumar and Rao, Breadth- rst] Number of clusters [1 : : : #processors] Load balancing [On, O ] Processor selection [Neighbor, Random] Percentage of stack distributed upon request [0% : : : 100%] Donating strategy [HeadOfList, TailOfList] Anticipatory load balancing trigger [0..stack size] Ordering [Fixed, Local, TOIDA]The user is allowed to determine the types of strategies to be used for a given problem.However, because such a decision is di cult to make without signi cant information aboutthe search space, Eureka also has the capability of making all necessary strategy selections.Based on the characteristics of a search space, Eureka automatically con gures itself tooptimize performance on a particular application. Sample problems are fed as trainingexamples to a machine learning system, which in turn learns the optimal strategies to applyto particular classes of search spaces. Applying machine learning to optimize softwareapplications has been pursued in other areas of research. For example, Minton (1996)has applied a similar technique to automatically synthesize problem-speci c versions ofconstraint-satisfaction algorithms. Research in other areas of computer science has yieldedsimilar ideas of customizable environments applied to computer networks (Bhattacharjee,Calvert, & Zegura, 1997; Steenkiste, Fisher, & Zhang, 1997) and to interactive human-computer interfaces (Frank, Sukavirija, & Foley, 1995; Lieberman, 1998). This work isunique in allowing both problem-speci c and architecture-speci c features to in uence thechoice of strategies and in applying adaptive software techniques to parallel search. Eurekaalso o ers a framework that can potentially automate both static and dynamic softwarecustomization.To perform parallel search, Eureka executes the following steps:1. Timings from sample problem instances are captured, varying each strategy parameterindependently. In order to acquire an e ective sample set, problems are selected froma variety of domains and parallel architectures.2. For each problem instance, Eureka captures features of the problem space that areknown to a ect the optimal choice of strategy. These features include:150\nAdaptive Parallel Iterative Deepening SearchBranching Factor (b): The average branching factor of the search tree.Heuristic Error (herror): The di erence, on average, between the estimated dis-tance to a goal node and the true distance to the closest goal node. This isestimated from the shallow search by computing the di erence between the es-timated distance to the goal at the beginning of the search and the smallestestimated distance to the goal for all leaf nodes of the shallow search, minus theactual distance from the root node to the leaf node.Imbalance (imb): The degree to which nodes are unevenly distributed among sub-trees in the search space.Goal Location (loc): The left-to-right position of the rst optimal solution node.This is estimated from the shallow search by determining which subtree containsnodes with the lowest estimated distances to the goal.Heuristic Branching Factor (hbf): The ratio of nodes expanded between the cur-rent and previous IDA* iterations.Features from the non-goal iterations represent attributes for the test case, and thestrategy that results in the best performance (shortest run time) represents the correctclassi cation of the problem instance for a given strategy choice.3. Problem attributes are combined with the corresponding classes and are fed as trainingexamples to a machine learning system. We use C4.5 (Quinlan, 1993) to induce adecision tree from the pre-classi ed cases. A rule base is generated for each conceptto be learned, corresponding to each of the strategy decisions listed above that needto be made.4. To solve a new problem, Eureka performs a shallow search through the space untilroughly 200,000 nodes are expanded. If a goal is not found during the shallow search,the features of the tree are calculated at this point and used to index appropriaterules from the C4.5 database.5. The learned rules recommend strategy choices given the features of the new problemspace. Eureka then initiates a parallel search from the root of the space, employingthe selected strategies. For many applications, the initial expansion takes only a fewseconds and does not greatly a ect the runtime of the search algorithm.The described set of features and the amount of time to spend on the initial Eurekaiteration are chosen based on our experimental data to yield the most helpful informationin the shortest time. Searching enough iterations of the problem space until 200,000 nodesare generated takes less than 10 seconds on the problem domains we tested. Spendingless time than this may yield erroneous information because features of the tree do notstabilize until several levels down in the tree. Searching additional iterations in generaldoes not signi cantly improve the quality of information and the time requirements growexponentially. Improved approaches may include performing the initial search until thestability of the space reaches a prescribed level, or periodically updating the C4.5 choicesand adjusting the parallel search approaches dynamically during execution.151\nCook and Varnell Deviation Within Problems Deviation Between ProblemsDomain Stat Bf Herror Imb Hbf Bf Herror Imb Hbf15puzzle Std Dev 0.000 1.748 0.001 2.839 0.002 2.577 0.008 4.889Avg Value 1.509 3.039 0.286 6.938 1.509 3.039 0.286 6.938RMP Std Dev 0.050 9.331 0.001 0.002 0.205 43.400 0.002 0.138Avg Value 2.643 11.265 0.148 1.105 2.643 11.265 0.148 1.105Table 1: Problem Feature Value DeviationsPerforming an initial shallow search has also been shown to be e ective in other parallelsearch research. For example, Suttner (1997) performs parallel search of the rst few IDA*iterations twice during parallel search in order to determine the number of individual tasksthat should be distributed to each processor. Cook et al. (1993) also perform an initialshallow search in order to obtain more accurate operator ordering information to use inreordering the search space. In each case, the amount of time required to perform the extrainitial search is minimal yet greatly improves the performance of the overall search task.The selected features each demonstrate a signi cant in uence on the optimal searchstrategy. Although feature values can change dramatically from one problem to the next,each feature remains fairly stable between levels of the same tree. As a result, computing thevalues of these features at a low level in the tree provides a good indication of the structureof the entire tree. The \\Deviation Within Problems\" entries in Table 1 show the standarddeviation of each feature value over all search tree levels. The results are averaged over98 problem instances in the fteen puzzle domain1 and 20 problem instances in the robotarm motion planning domain. Both of these test domains are described in the next section.The low values in these columns indicate that the features provide a good indicator of thestructure of the problem space at all levels in the tree. In contrast, the \\Deviation BetweenProblems\" table entries show the standard deviation of the average feature value (averagedover all levels in each tree) over all problem spaces. The larger values in these columnsindicate that the features can e ectively distinguish between di erent problem spaces.Eureka is written in C and is currently implemented on an nCUBE 2, on Linux work-stations using the Parallel Virtual Machine (PVM) communication software, on a DECAlpha using an implementation of Posix threads, on Windows NT running Java threadsand Cilk threads, and as a distributed Java system using RMI. We are also currently inves-tigating means of dynamically switching between strategies during execution as the problemstructure or environment changes.1. The two largest fteen puzzle problem instances were not included due to the amount of time requiredto generate this data for these problems. 152\nAdaptive Parallel Iterative Deepening Search5. Experimental ResultsIn this section we will present experimental results that compare the performance of ouradaptive parallel search strategy with each xed strategy used exclusively for all probleminstances. In particular, we will verify the following hypotheses in this section: Eureka's adaptive search techniques can be used to achieve speedup over a varietyof applications, and can demonstrate improved results over using a xed strategy forall problem instances. The adaptive search technique can employ training examples from multiple applica-tions to improve overall performance. We will demonstrate this using testing andtraining examples combined from two application domains. The learning component of Eureka is able to signi cantly outperform any of thetested xed strategies in terms of predicting the best strategy for a given probleminstance. In addition to e ectively making one strategy choice for a new problem, Eureka ismost e ective of all tested approaches at making all strategy decisions for a givenproblem instance. A variety of learning techniques can be used to assist in strategy selection and o erspeedup over serial search, though performance will vary from one learning techniqueto another.5.1 Test DomainsOne of our test domains is the well-known fteen puzzle problem. This problem consists of a4 4 grid containing tiles numbered one to fteen, and a single empty tile position called theblank tile. A tile can be moved into the blank position from an adjacent position, resultingin the four operators up, down, left, and right. Given the initial and goal con gurations,the problem is to nd a sequence of moves to reach the goal. A sample goal con gurationis shown in Figure 11. The Manhattan Distance Function provides an admissible heuristicfor this problem, and we use the 100 problem instances provided in Korf's test data (1991).2 Our second application domain is the robot arm motion planning problem. Traditionalmotion planningmethods are very costly when applied to a robot arm, because each joint hasan in nite number of angles to which it can move from a given con guration, and becausecollision checking must be performed for each arm segment. Craig provides a detaileddescription of the calculations necessary to determine the position of the end e ector inthe 3D workspace given the current joint angles (1989). For our experiments, we use theparameters de ned for the Puma 560 robot arm with six degrees of freedom shown inFigure 12. The size and layout of the room is the same for each of our test problems,but we vary the initial and goal arm con gurations to generate 20 problem instances. The2. Because of time constraints, we estimated the serial run time for the two largest fteen puzzle probleminstances using the number of required node expansions for these problems published in Korf's paperand the mean node expansion time averaged over the next ve largest problem instances.153\nCook and Varnell 1 2 3\n4 5 6 7 8 9 10 11\n12 13 14 15Figure 11: Fifteen puzzle problem instance\nFigure 12: Robot arm motion planning problem instancerobot arm path planning problem is particularly di cult because considering every possiblearm movement results in a search space with an in nite branching factor. We encode onepossible move size for each joint, resulting in a branching factor of 6. The resolution of themoves can be determined by the user, and for these experiments we choose a resolution of1 degree.Our third test domain uses the arti cial search space in which parameters includingbranching factor, tree imbalance, solution cost, heuristic error, and left-to-right goal positioncan be speci ed by the user. We generate 20 problem instances for use in the experiments.For our fourth test domain, we integrate our own C-based version of the SNLP nonlinearplanner (Barrett & Weld, 1992) into Eureka. To conform with the Eureka architecture,the integrated planner utilizes IDA* search instead of the Best-First search method em-ployed by SNLP. Each plan repair step ( lling an open condition or handling a threat) istreated as a separate node in the search space to be explored. We compute the cost of a plansolution as the number of operations and constraints in the plan, and the distance to thegoal is estimated using the number of remaining aws. We select 20 problem instances forour experiments from the blocks-world, Towers of Hanoi, and monkey-and-bananas planningdomains.To create test cases, we run each problem instance multiple times, once for each parallelsearch strategy in isolation. The search strategy that produces the best speedup is consid-ered to be the \\correct\" classi cation of the corresponding search tree for C4.5 to learn.Test cases are run on 64 processors of an nCUBE 2 and on 8 distributed workstations using154\nAdaptive Parallel Iterative Deepening Search Approach 15Puzzle Fil-15P RMP Fil-RMPKumar and Rao 52.02 65.89 63.10 57.46Breath- rst 53.03 65.82 59.77 55.90C4.5 52.31 79.17 64.15 61.08Combined-C4.5 61.30Table 2: Distributed Tree Search Speedup ResultsPVM. In the rst set of experiments we x all strategy choices but one and vary the strategychoice under consideration. The default parameter choices are: Distribution strategy = Distributed Tree Search Number of clusters = 1 Load balancing = On Processor selection = Neighbor Percentage of stack distributed upon request = 30% Donating strategy = TailOfList Anticipatory load balancing trigger = 0 Ordering = FixedWe compare the results of C4.5-selected strategies to each strategy used exclusivelyfor all problem instances. Speedup results for various strategy decisions averaged overall problem instances are shown in the following sections. The best average speedup ishighlighted in each case. The C4.5 results are captured by performing a ten-fold crossvalidation on the fteen puzzle data and a three-fold cross validation on the robot armmotion planning, arti cial, and nonlinear planning data sets. Speci cally, a decision treeis created from the training cases and used to select the strategy for the test cases. C4.5speedup is averaged over all test cases for one iteration of this process, and the nal valuesare averaged over cross-validation iterations.5.2 Distribution ResultsTest results are obtained for the two alternative distribution approaches. The fteen puzzle,the robot arm motion planning problem, and the arti cial search space serve as problemdomains. Experimental results are shown in Table 2. For each domain, the control variableis indicated under the \\Approach\" column.The breadth- rst distribution performs slightly better than C4.5 for the fteen puzzledata set; however, the C4.5 recommendations outperform the breadth- rst approach for therobot motion problem domain. The row labeled Combined-C4.5 is the result of merging155\nCook and Varnell Stat Small Medium LargeAvg Coef Var 1.32 8.82 9.95Avg Speedup 7.23 52.40 54.09Table 3: Average Speedup Standard Deviationthe fteen puzzle results with the robot motion planning results and running the combineddata set through C4.5. The performance is better than for the fteen puzzle but slightlyworse than for the robot motion planning domain.Note that using the ltered 15 puzzle data, Eureka achieves a speedup of 79.17 al-though the number of processors used is only 64. These parallel search algorithms canproduce superlinear speedup (speedup greater than the number of processors) because theparallel algorithms do not completely imitate the serial algorithm. For example, using dis-tributed tree search individual subtrees are assigned to separate processors. If a goal nodeis located on the far left side of the rightmost subtree in the search space, the processorsearching this subtree will quickly nd the goal node, thus terminating search after onlya few node expansions. In contrast, the serial algorithm in a left-to-right search will com-pletely search all other subtrees to the cost threshold before searching and nding the goalnode in the rightmost subtree. Thus the serial algorithm will perform disproportionatelymore search than all processors combined using the parallel algorithm. Each type of par-allel search approach described in this paper can yield superlinear speedup under certainconditions. Some algorithms more closely imitate serial search, but at a potential loss ofoverall performance (Kale & Saletore, 1990).Eureka's selection of strategies in the fteen puzzle domain does not perform consis-tently better than using some of the strategies in isolation. One reason for this disappointingperformance is the nature of the training data. Although we use the strategy that achievesthe best run time as the correct \\classi cation\" for a given problem instance, there doesnot always exist a clear winner for each problem instance. On some problem instances onestrategy dramatically outperforms the others. On other problem instances two or morestrategy selections perform almost equally well.This problem is exacerbated by the fact that there is some noise inherent in the collectedrun times. To demonstrate the amount of error that can be present in the timings we selecttwelve instances of the fteen puzzle problem (four small, four medium, and four largeinstances), and time ve runs of each instance with identical strategy parameters on annCUBE 2. We compute the standard deviation of the speedups for ve runs of the sameproblem instance, and then divide the result by the sample mean to ensure the result is nota ected by the magnitude of the speedup values. This coe cient of variation averaged overall problem instances in the category is listed in Table 3 along with the average speedupfor the instances in the problem category. As shown, the amount of error present in thetimings can be quite large, and when two strategies perform almost equally well, the winnerfor any given run can be almost arbitrary.To account for such misleading data, we sort all problem instances in the fteen puzzledomain by the amount of variance of the strategy timing results. Those problem instances156\nAdaptive Parallel Iterative Deepening Search Approach 15Puzzle Fil-15P RMP Fil-RMPKumar & Rao .6033 (.07) .5809 (.00) .5079 (.34) .2000 (.03)Breadth- rst .3967 (.14) .4190 (.01) .4921 (.11) .8000 (.01)C4.5 .4533 .1619 .6429 .0667Table 4: Distributed Tree Search Classi cation Resultsthat yield a clear strategy winner are placed at the top of the list. We then lter the dataset to keep only the top third of the sorted problem instances. The instances in the topthird of this ltered data set are duplicated in the training set. The results of Eureka'sperformance on this ltered training set is shown for each experiment in the Fil-15P column.We perform a similar ltering step to the robot arm motion planning domain data.This approach can be used in each domain in which problem instances do not alwaysyield a clear strategy winner. For example, problem instances drawn from the planningdomain and arti cial domain all demonstrate high variance of strategy timings, thus allproblem instances are utilized. For any given domain, the number and type of test casesto use as training data can be selected based on the amount of variance of strategy results.The disadvantage of the ltered-data method is that cases in which two strategies yieldsimilar timings may be discarded, even when the two strategies perform much better thanother possible strategies.The results in Table 3 verify that Eureka can automatically select parallel searchstrategies that yield greater speedup than using any single strategy for all problem instancespulled from the ltered data sets. However, this table does not indicate how well themachine learning component is performing at the classi cation task. One danger in listingonly speedup results is that the numbers may be biased by the magnitude of several largeproblem instances in which Eureka correctly picks the best strategy.In Table 4 we measure how well the system classi es each new test problem. Once againwe perform ten-fold cross validation and show mean classi cation error for each approach.The xed strategies (Kumar and Rao, Breadth- rst) always pick the correct classi cationof a problem instance as their own, and C4.5 uses its decision tree to pick the classi cationof the problem instance. Signi cance values are gathered using a paired student t-testand are shown in parentheses following the mean error. In each of the ltered data sets,C4.5 signi cantly outperforms either xed approach (p 0.03) when predicting the correctclassi cation of unseen problem instances.5.3 Clustering ResultsIn this experiment Eureka selects the optimal number of clusters to use for each probleminstance. By combining the features of distributed tree search and parallel window search,it is possible to achieve better performance than when each approach is used in isolation.The clustering algorithm is tested using 1, 2, and 4 clusters on 64 processors of annCUBE 2 for the fteen puzzle, robot motion planning, and SNLP domains, and using 1and 2 clusters for the fteen puzzle domain on a distributed network of 8 PCs. Test resultsfor the clustering algorithm are presented in Table 5.157\nCook and Varnell Approach 15Puzzle Fil-15P RMP Fil-RMP Planning PVM-15P1 Cluster 52.02 65.21 60.01 62.75 108.46 7.692 Clusters 57.04 64.97 80.09 79.98 145.0 7.034 Clusters 56.83 49.57 162.86 153.17 129.15 |C4.5-nCUBE 58.90 86.76 126.32 164.96 195.19 7.72Combined-C4.5 73.90 |Table 5: Clustering Speedup ResultsApproach 15Puzzle Fil-15P RMP Fil-RMP1 Cluster .5556 (.04) .4595 (.00) .7540 (.11) .7778 (.01)2 Clusters .6956 (.32) .6738 (.00) .9048 (.04) .7778 (.02)4 Clusters .7489 (.18) .8667 (.00) .3413 (.11) .4444 (.01)C4.5 .6756 .2333 .4921 .1481Table 6: Clustering Classi cation ResultsTable 5 demonstrates that Eureka's automatic strategy selection using C4.5 outper-forms any xed strategy in almost all domains, and always performs best when the ltereddata sets are used. The table also indicates that the optimal number of clusters on averagevaries from one domain to another, thus reinforcing the need for automatic selection of thisparameter. In the PVM experiments, because only eight processors are available we exper-imented with 1 or 2 clusters for each problem instance. The combined results are againcollected from the test cases for the fteen puzzle and robot arm motion planning domains.The classi cation results for choice of number of clusters are shown in Table 6. On the ltered data set, C4.5 outperforms all xed strategies at a signi cance level of p 0.02.5.4 Ordering ResultsIn this experiment we demonstrate Eureka's ability to pick a method of ordering the treefor expansion. Table 7 shows the results of this experiment. For the fteen puzzle, thetwo tested xed orderings are (Up, Left, Right, Down) and (Down, Left, Right, Up). Forthe robot arm motion planning domain, two xed orderings are tested corresponding toordering joint moves from the base of the arm to the end e ector, and ordering joint movesfrom the end e ector rst down to the base of the arm last. Only one ordering is used forthe arti cial domain.In this experiment, C4.5 yields the best speedup results for all databases, ltered orun ltered. In the arti cial domain, because perfect ordering information is available theTOIDA strategy also yields the best possible speedup results. The combined results aregenerated using the fteen puzzle and robot arm motion planning problem instances.Table 8 shows the results of classifying ordering problems on the ltered and un ltereddata sets. While C4.5 always yields the best average speedup, the learning system does158\nAdaptive Parallel Iterative Deepening Search Approach 15Puzzle Fil-15P RMP Fil-15P Arti cialOrdering 1 49.58 49.58 64.79 58.42 59.22Ordering 2 52.02 65.41 65.41 80.05 |TOIDA 50.77 66.13 73.30 79.30 61.03Local 50.75 68.92 75.37 82.25 60.62C4.5 50.97 123.79 78.52 87.28 61.03Combined-C4.5 55.28 |Table 7: Ordering Speedup ResultsApproach 15Puzzle Fil-15P RMP Fil-RMPFixed .6972 (.44) .7667 (.00) 1.000 (.01) 1.000 (.00)TOIDA .6194 (.07) .7167 (.00) .3016 (.21) .3000 (.02)Local .6833 (.34) .5167 (.00) .6984 (.02) .7000 (.00)C4.5 .7069 .1429 .4444 .0000Table 8: Ordering Classi cation Resultsnot yield the best classi cation accuracy on un ltered data, though it does achieve the bestresults on the ltered data sets. On the ltered data sets, C4.5 outperforms xed strategiesat a signi cance value of p 0.02 or better.5.5 Load Balancing ResultsLoad balancing signi cantly a ects the performance of a majority of parallel algorithms.When work is divided evenly among processors, no load balancing is necessary. Heuristicsearch frequently creates highly irregular search spaces, which results in load imbalancebetween processors. Eureka permits load balancing operations during iterations of IDA*.A processor with nodes available on its open list may donate some or all of the nodes toa requesting processor. Decisions that a ect system performance include deciding when tobalance the load, identifying a processor from which to request work, and deciding howmuch work to donate.In the rst load balancing experiment we test Eureka's ability to select the appropriateprocessor polling strategy. We have implemented the asynchronous round robin and therandom polling approaches. On the nCUBE 2, a processor's D neighbors are polled forwork (using the nCUBE's hypercube topology, D corresponds to log2P ) whereas in thePVM environment, a processor's right and left neighbors are polled (D = 2 because theworkstations are connected with a ring topology). The results of this experiment are listedin Table 9.Table 9 shows that once again C4.5 yields the best speedup in most cases and alwaysyields the best speedup on ltered data sets. Among the xed results, no single approachoutperforms the others on all data sets. 159\nCook and Varnell Approach 15Puzzle Fil-15P RMP Fil-RMPNeighbor 52.02 65.21 58.81 57.67Random 55.35 70.75 58.17 56.03C4.5 50.55 75.01 61.31 60.84Combined-C4.5 56.71Table 9: Load Balancing Speedup ResultsApproach 15Puzzle Fil-15P RMP Fil-RMPNeighbor .5306 (.08) .5762 (.00) .2937 (.21) .2000 (.04)Random .4694 (.03) .4238 (.00) .7063 (.03) .8000 (.00)C4.5 .3806 .1429 .4048 .0000Table 10: Load Balancing Classi cation ResultsTable 10 summarizes the classi cation results of the xed strategies in comparison to theC4.5 classi cations. For each of the ltered data sets, C4.5 outperforms any xed strategywith a signi cance of p 0.04 or better.The second load balancing experiment demonstrates Eureka's ability to determinethe optimal amount of work to donate upon request. If too little work is donated, therequesting processor will soon return for more work. If too much work is donated, thegranting processor will soon be in danger of becoming idle. Table 11 lists the results ofthis experiment, demonstrating once again that the learning system is capable of e ectivelyselecting load balancing strategies, except when the un ltered test cases from the fteenpuzzle are used (on the nCUBE and on the distributed network of workstations). Thecombined results are generated using training cases from the fteen puzzle and robot armmotion planning nCUBE examples.Table 12 lists the classi cation accuracy results. C4.5 does not perform signi cantlybetter than the xed strategies for the un ltered data, but does perform signi cantly better(p 0.04) than the xed strategies for the ltered data.Approach 15Puzzle Fil-15P RMP Fil-RMP PVM-15P30%-nCUBE 52.02 65.21 63.10 55.49 7.6950%-nCUBE 53.68 61.95 61.26 60.13 7.49C4.5-nCUBE 51.28 76.35 63.67 62.13 7.50Combined-C4.5 55.44 |Table 11: Distribution Amount Speedup Results160\nAdaptive Parallel Iterative Deepening Search Approach 15Puzzle Fil-15P RMP Fil-RMP30% .5639 (.26) .5333 (.00) .1984 (.00) .3000 (.04)50% .4361 (.17) .4667 (.00) .8016 (.01) .7000 (.01)C4.5 .5056 .1429 .1984 .0667Table 12: Distribution Amount Classi cation ResultsApproach SpeedupEureka 74.24Random Processor LB 70.75Local Ordering 68.92Transformation Ordering 66.13Kumar and Rao 65.89Distributed Tree 65.82Fixed Evaluation 1 65.411 Cluster 65.21Neighbor LB 65.2130% Distribution 65.212 Clusters 64.9750% Distribution 61.94Fixed Evaluation 2 49.584 Clusters 49.57Avg. of Fixed Strategies 63.43Table 13: Combination of C4.5 Recommendations5.6 Combining C4.5 RecommendationsUp to this point, all experiments have shown the results of Eureka selecting a singlestrategy, all other strategy results being xed. In this experiment we allow Eureka toselect all strategy choices at once for a given problem and execute the parallel search withthe recommended strategies. We then compare the results to each xed strategy (the xedstrategy choice is averaged over all problem instances and all possible choices of otherstrategy decisions). A random set of 50 problems from the fteen puzzle domain is selectedand run on 64 processors of the nCUBE 2. Table 13 summarizes the speedup for eachapproach.These results indicate that Eureka can e ectively make all strategy choices at once.The learned rules achieve better performance than that obtained by any one of these strategychoices. These rules also outperform any single xed strategy choice averaged over all otherparameter options. 161\nCook and Varnell Method ErrorID3 0.1067CN2 0.1133C4.5 0.1657Bayesian 0.4471Majority 0.4714Backprop 0.7657Table 14: Machine Learning Comparison5.7 Machine Learning ComparisonIn the current version of the Eureka system, we use C4.5 to induce a decision tree basedon the training data. C4.5 has proven to be e ective in predicting the strategy choices forthese test domains. In addition, the output of the system is available as a symbolic rulebase, which may allow the system developer to determine the factors that a ect strategyselection for a given application domain.Other machine learning approaches can also be used to perform strategy selection inthe Eureka system. To test the results of various existing approaches, we supplied thedata from all of the 15 Puzzle classi cation experiments described in the previous sectionas input to versions of C4.5, the ID3 decision tree induction algorithm (Quinlan, 1986), theCN2 sequential covering algorithm (Clark & Niblett, 1989), a backpropagation neural net(Rumelhart & McClelland, 1986), a Bayesian classi er (Cestnik, 1990), and a majority-winsclassi er. As with the other experiments, results are based on ten-fold cross-validation.Table 14 shows that the decision tree algorithms performed best on this particular dataset. Ultimately, the best machine learning algorithm in this context is the algorithm thatconsistently yields the best speedup. If we consider normalized problem speedups, thealgorithm that produces the best classi cation on average will also produce the greatestspeedup. We will continue to explore various machine learning methods to determine theapproach that will work best for this type of application.6. Conclusions and Future WorkThis paper reports on work performed to combine the bene ts of parallel search approachesin the Eureka system. Experimentation reveals that strategies developed over the lastfew years o er distinct bene ts to improving the performance of AI applications. However,while any particular algorithm can provide signi cant speedup for one type of problem,on other problems these algorithms can actually produce worse results than using a serialversion of the search algorithm. As a result, these strategies need to be carefully chosenbased on the characteristics of a particular problem.In this paper we demonstrate the ability of Eureka to automatically select paral-lel search strategies and set appropriate parameters. Eureka employs the C4.5 machinelearning system to make an intelligent choice of strategies for each new problem instance.Experiments from the domains of the fteen puzzle problem, robot arm motion planning, an162\nAdaptive Parallel Iterative Deepening Searcharti cial search space, and planning problems indicate that Eureka yields both improvedspeedup results and signi cantly improved classi cation accuracies over any strategy used inisolation when high-variance training cases are used. These experiments also demonstrateEureka's ability to select all parameters at once and to outperform any xed strategyover a set of problem instances. In addition, we demonstrate that Eureka can bene t byutilizing training cases drawn from a variety of test domains, thus we would expect theperformance of the system to improve even more as we incorporate data from new problemdomains and architectures.Two of the challenges introduced by our research are the ability to determine discrim-inating features and the ability to provide clear classi cations for training examples. Inour experiments we veri ed that the features we chose could be measured early during thesearch process and still be representative of the problem space later on during execution.As we apply our approach to a greater variety of problems we will need to develop a moreformal methodology for selecting representative and discriminating features. In addition,we observed dramatic performance improvements when test cases were drawn from probleminstances with clear classi cations. We would like to pursue methods of learning from in-stances that exhibit low variation in performance of alternative strategies and high variationin problem size.The current implementation of Eureka focuses on an IDA* approach to search. Onereason for this choice of search method is the linear memory requirements of the algorithm.A second advantage of this search method is that an iterative deepening search methodprovides feedback in each iteration that can be used to adjust parameters for the nextsearch iteration. As a result, Eureka can potentially adjust the strategy choices from oneiteration of the search algorithm to the next as features of the space vary. However, in someproblem domains non-iterative search algorithms may be preferred. A future challenge forour research is to re ne the adaptive parallel search algorithm for use in a greater varietyof iterative and non-iterative search algorithms.Eureka implementations are currently available on a variety of architectural platformsincluding MIMD distributed memory and shared memory multiprocessors, a distributednetwork of machines running PVM, Posix multithreading machines, and machines usingJava threads and Cilk threads. Problem domains currently under investigation include ad-ditional combinatorial optimization problems such as the n-Queens problem and integrationof machine learning, theorem proving, and natural language algorithms into this search ar-chitecture. We hope to demonstrate that parallel heuristic search algorithms can yield bothoptimal and scalable approaches to planning, machine learning, natural language, theoremproving, and many other computation-intensive areas of AI.AcknowledgementsThis work was supported by National Science Foundation grants IRI-9308308, IRI-9502260,and DMI-9413923. The authors would like to thank Dan Burns and Matthias Imhof atthe MIT Earth Resources Lab for providing access to their nCUBE 2 to complete theexperiments reported in this paper. 163\nCook and VarnellReferencesAgrawal, D., Janakiram, V., & Mehrotra, R. (1988). A randomized parallel branch andbound algorithm. In Proceedings of the International Conference on Parallel Process-ing, pp. 69{75. The Pennsylvania State University.Anderson, S., & Chen, M. C. (1987). Parallel branch-and-bound algorithms on the hyper-cube. In Proceedings of the Conference on Hypercube Multiprocessors, pp. 309{317.Barrett, A., & Weld, D. (1992). Partial order planning: evaluating possible e ciency gains.Tech. rep. CSE TR 92-05-1, University of Washington.Bhattacharjee, S., Calvert, K., & Zegura, E. W. (1997). An architecture for active network-ing. In Tantawy, A. N. (Ed.), High Performance Networking, pp. 265{279. Chapman& Hall.Cestnik, B. (1990). Estimating probabilities: a crucial task in machine learning. In Pro-ceedings of the Ninth European Conference on Arti cial Intelligence, pp. 174{179.Challou, D., Gini, M., & Kumar, V. (1993). Parallel search algorithms for robot motionplanning. In Geller, J. (Ed.), Proceedings of the AAAI Symposium on InnovativeApplications of Massive Parallelism, pp. 40{47.Clark, P., & Niblett, R. (1989). The CN2 induction algorithm. Machine Learning, 3,261{284.Cook, D. J., & Varnell, R. C. (1997). Maximizing the bene ts of parallel search usingmachine learning. In Proceedings of the National Conference on Arti cial Intelligence,pp. 559{564. AAAI Press.Cook, D. J. (1997). A hybrid approach to improving the performance of parallel search. InParallel Processing for Arti cial Intelligence 3, pp. 120{145. Elsevier.Cook, D. J., Hall, L., & Thomas, W. (1993). Parallel search using transformation-orderingiterative-deepening A*. The International Journal of Intelligent Systems, 8 (8), 855{873.Cook, D. J., & Lyons, G. (1993). Massively parallel IDA* search. Journal of Arti cialIntelligence Tools, 2 (2), 163{180.Craig, J. J. (1989). Introduction to robotics. Addison-Wesley.Evett, M., Hendler, J., Mahanti, A., & Nau, D. (1995). PRA*: massively parallel heuristicsearch. Journal of Parallel and Distributed Computing, 25, 133{143.Feldmann, R., Mysliwietz, P., & Monien, B. (1994). Studying overheads in massively par-allel min/max-tree evaluation. In Proceedings of the Sixth Annual ACM Symposiumon Parallel Algorithms and Architectures, pp. 94{103. Association for Computing Ma-chinery. 164\nAdaptive Parallel Iterative Deepening SearchFrank, M., Sukavirija, P., & Foley, J. D. (1995). Inference bear: designing interactiveinterfaces through before and after snapshots. In Proceedings of the ACM Symposiumon Designing Interactive Systems, pp. 167{175. Association for Computing Machinery.Furuichi, M., Taki, K., & Ichyoshi, N. (1990). A multi-level load balancing scheme foror-parallel exhaustive search programs on the multi-psi. In Proceedings of the SecondACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp.100{106. Association for Computing Machinery.Kale, L. V., & Saletore, V. A. (1990). Parallel state-space search for a rst solution withconsistent linear speedups. International Journal of Parallel Programming, 19 (4),251{293.Karypis, G., & Kumar, V. (1992). Unstructured tree search on SIMD parallel computers.In Proceedings of Supercomputing 92, pp. 453{462. IEEE Computer Society.Kumar, V., & Rao, V. N. (1990). Scalable parallel formulations of depth- rst search. InKumar, Kanal, & Gopalakrishan (Eds.), Parallel Algorithms for Machine Intelligenceand Vision, pp. 1{41. Springer{Verlag.Lieberman, H. (1998). Integrating user interface agents with conventional applications. InProceedings of the ACM Conference on Intelligent User Interfaces, pp. 39{46. Asso-ciation for Computing Machinery.Mahanti, A., & Daniels, C. (1993). SIMD parallel heuristic search. Arti cial Intelligence,60 (2), 243{281.Mahapatra, N. R., & Dutt, S. (1995). New anticipatory load balancing strategies for parallelA* algorithms. In Proceedings of the DIMACS Series on Discrete Mathematics andTheoretical Computer Science, pp. 197{232. American Mathematical Society.Minton, S. (1996). Automatically con guring constraint satisfaction programs: a case study.Constraints, 1 (1), 7{43.Powley, C., Ferguson, C., & Korf, R. E. (1993). Depth- rst heuristic search on a SIMDmachine. Arti cial Intelligence, 60 (2), 199{242.Powley, C., & Korf, R. E. (1991). Single-agent parallel window search. IEEE Transactionson Pattern Analysis and Machine Intelligence, 13 (5), 466{477.Quinlan, J. R. (1993). C4.5: programs for machine learning. Morgan Kaufmann.Quinlan, J. (1986). Induction of decision trees. Machine Learning 1, 1 (1), 81{106.Rajpal, S. P., & Kumar, S. (1993). Parallel heuristic search algorithms for message passingmultiprocessor systems. Computer Science and Informatics, 23 (4), 7{18.Rao, V. N., Kumar, V., & Ramesh, K. (1987). A parallel implementation of iterative-deepening-A*. In Proceedings of the National Conference on Arti cial Intelligence,pp. 178{182. Morgan Kaufmann. 165\nCook and VarnellReinefeld, A., & Schnecke, V. (1994). AIDA* - asynchronous parallel IDA*. In Proceedingsof the Tenth Canadian Conference on Arti cial Intelligence, pp. 295{302. CanadianInformation Processing Society.Rumelhart, D. E., & McClelland, J. L. (1986). Parallel distributed processing: explorationin the microstructure of cognition, Volumes 1 and 2. MIT Press, Cambridge, MA.Saletore, V. A. (1990). A distributed and adaptive dynamic load balancing scheme forparallel processing of medium-grain tasks. In Proceedings of the Fifth DistributedMemory Computing Conference, pp. 231{235.Steenkiste, P., Fisher, A., & Zhang, H. (1997). Darwin: resource management forapplication-aware networks. Tech. rep. CMU-CS-97-195, Carnegie Mellon University.Suttner, C. (1997). Static partitioning with slackness. In Parallel Processing for Arti cialIntelligence 3, pp. 106{120. Elsevier.Varnell, R. C. (1997). An architecture for improving the performance of parallel search.Ph.D. thesis, University of Texas at Arlington.\n166"
    } ],
    "references" : [ {
      "title" : "A randomized parallel branch and",
      "author" : [ "D. Agrawal", "V. Janakiram", "R. Mehrotra" ],
      "venue" : null,
      "citeRegEx" : "Agrawal et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 1988
    }, {
      "title" : "Parallel branch-and-bound algorithms on the hyper",
      "author" : [ "S. Anderson", "M.C. Chen" ],
      "venue" : null,
      "citeRegEx" : "Anderson and Chen,? \\Q1987\\E",
      "shortCiteRegEx" : "Anderson and Chen",
      "year" : 1987
    }, {
      "title" : "Partial order planning: evaluating possible e ciency gains",
      "author" : [ "A. Barrett", "D. Weld" ],
      "venue" : null,
      "citeRegEx" : "Barrett and Weld,? \\Q1992\\E",
      "shortCiteRegEx" : "Barrett and Weld",
      "year" : 1992
    }, {
      "title" : "An architecture for active",
      "author" : [ "S. Bhattacharjee", "K. Calvert", "E.W. Zegura" ],
      "venue" : null,
      "citeRegEx" : "Bhattacharjee et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Bhattacharjee et al\\.",
      "year" : 1997
    }, {
      "title" : "Estimating probabilities: a crucial task in machine learning",
      "author" : [ "B. Cestnik" ],
      "venue" : null,
      "citeRegEx" : "Cestnik,? \\Q1990\\E",
      "shortCiteRegEx" : "Cestnik",
      "year" : 1990
    }, {
      "title" : "Parallel search algorithms for robot motion",
      "author" : [ "D. Challou", "M. Gini", "V. Kumar" ],
      "venue" : null,
      "citeRegEx" : "Challou et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Challou et al\\.",
      "year" : 1993
    }, {
      "title" : "The CN2 induction algorithm",
      "author" : [ "P. Clark", "R. Niblett" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Clark and Niblett,? \\Q1989\\E",
      "shortCiteRegEx" : "Clark and Niblett",
      "year" : 1989
    }, {
      "title" : "Maximizing the bene ts of parallel search",
      "author" : [ "D.J. Cook", "R.C. Varnell" ],
      "venue" : null,
      "citeRegEx" : "Cook and Varnell,? \\Q1997\\E",
      "shortCiteRegEx" : "Cook and Varnell",
      "year" : 1997
    }, {
      "title" : "A hybrid approach to improving the performance of parallel search",
      "author" : [ "D.J. Cook" ],
      "venue" : null,
      "citeRegEx" : "Cook,? \\Q1997\\E",
      "shortCiteRegEx" : "Cook",
      "year" : 1997
    }, {
      "title" : "Parallel search using transformation-ordering",
      "author" : [ "D.J. Cook", "L. Hall", "W. Thomas" ],
      "venue" : null,
      "citeRegEx" : "Cook et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Cook et al\\.",
      "year" : 1993
    }, {
      "title" : "Massively parallel IDA* search",
      "author" : [ "D.J. Cook", "G. Lyons" ],
      "venue" : "Journal of Arti",
      "citeRegEx" : "Cook and Lyons,? \\Q1993\\E",
      "shortCiteRegEx" : "Cook and Lyons",
      "year" : 1993
    }, {
      "title" : "Introduction to robotics",
      "author" : [ "J.J. Craig" ],
      "venue" : null,
      "citeRegEx" : "Craig,? \\Q1989\\E",
      "shortCiteRegEx" : "Craig",
      "year" : 1989
    }, {
      "title" : "PRA*: massively parallel heuristic",
      "author" : [ "M. Evett", "J. Hendler", "A. Mahanti", "D. Nau" ],
      "venue" : null,
      "citeRegEx" : "Evett et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Evett et al\\.",
      "year" : 1995
    }, {
      "title" : "Studying overheads in massively",
      "author" : [ "R. Feldmann", "P. Mysliwietz", "B. Monien" ],
      "venue" : null,
      "citeRegEx" : "Feldmann et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Feldmann et al\\.",
      "year" : 1994
    }, {
      "title" : "Inference bear: designing interactive",
      "author" : [ "M. Frank", "P. Sukavirija", "J.D. Foley" ],
      "venue" : null,
      "citeRegEx" : "Frank et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Frank et al\\.",
      "year" : 1995
    }, {
      "title" : "A multi-level load balancing scheme",
      "author" : [ "M. Furuichi", "K. Taki", "N. Ichyoshi" ],
      "venue" : null,
      "citeRegEx" : "Furuichi et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Furuichi et al\\.",
      "year" : 1990
    }, {
      "title" : "Parallel state-space search for a rst solution with",
      "author" : [ "L.V. Kale", "V.A. Saletore" ],
      "venue" : null,
      "citeRegEx" : "Kale and Saletore,? \\Q1990\\E",
      "shortCiteRegEx" : "Kale and Saletore",
      "year" : 1990
    }, {
      "title" : "Unstructured tree search on SIMD parallel computers",
      "author" : [ "G. Karypis", "V. Kumar" ],
      "venue" : null,
      "citeRegEx" : "Karypis and Kumar,? \\Q1992\\E",
      "shortCiteRegEx" : "Karypis and Kumar",
      "year" : 1992
    }, {
      "title" : "Scalable parallel formulations of depth- rst search",
      "author" : [ "V. Kumar", "V.N. Rao" ],
      "venue" : null,
      "citeRegEx" : "Kumar and Rao,? \\Q1990\\E",
      "shortCiteRegEx" : "Kumar and Rao",
      "year" : 1990
    }, {
      "title" : "Integrating user interface agents with conventional applications",
      "author" : [ "H. Lieberman" ],
      "venue" : null,
      "citeRegEx" : "Lieberman,? \\Q1998\\E",
      "shortCiteRegEx" : "Lieberman",
      "year" : 1998
    }, {
      "title" : "SIMD parallel heuristic search",
      "author" : [ "A. Mahanti", "C. Daniels" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Mahanti and Daniels,? \\Q1993\\E",
      "shortCiteRegEx" : "Mahanti and Daniels",
      "year" : 1993
    }, {
      "title" : "New anticipatory load balancing strategies for parallel",
      "author" : [ "N.R. Mahapatra", "S. Dutt" ],
      "venue" : null,
      "citeRegEx" : "Mahapatra and Dutt,? \\Q1995\\E",
      "shortCiteRegEx" : "Mahapatra and Dutt",
      "year" : 1995
    }, {
      "title" : "Automatically con guring constraint satisfaction programs: a case study",
      "author" : [ "S. Minton" ],
      "venue" : null,
      "citeRegEx" : "Minton,? \\Q1996\\E",
      "shortCiteRegEx" : "Minton",
      "year" : 1996
    }, {
      "title" : "Depth- rst heuristic search on a SIMD",
      "author" : [ "C. Powley", "C. Ferguson", "R.E. Korf" ],
      "venue" : null,
      "citeRegEx" : "Powley et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Powley et al\\.",
      "year" : 1993
    }, {
      "title" : "Single-agent parallel window search",
      "author" : [ "C. Powley", "R.E. Korf" ],
      "venue" : "IEEE Transactions",
      "citeRegEx" : "Powley and Korf,? \\Q1991\\E",
      "shortCiteRegEx" : "Powley and Korf",
      "year" : 1991
    }, {
      "title" : "C4.5: programs for machine learning",
      "author" : [ "J.R. Quinlan" ],
      "venue" : null,
      "citeRegEx" : "Quinlan,? \\Q1993\\E",
      "shortCiteRegEx" : "Quinlan",
      "year" : 1993
    }, {
      "title" : "Induction of decision trees",
      "author" : [ "J. Quinlan" ],
      "venue" : "Machine Learning 1,",
      "citeRegEx" : "Quinlan,? \\Q1986\\E",
      "shortCiteRegEx" : "Quinlan",
      "year" : 1986
    }, {
      "title" : "Parallel heuristic search algorithms for message passing",
      "author" : [ "S.P. Rajpal", "S. Kumar" ],
      "venue" : null,
      "citeRegEx" : "Rajpal and Kumar,? \\Q1993\\E",
      "shortCiteRegEx" : "Rajpal and Kumar",
      "year" : 1993
    }, {
      "title" : "A parallel implementation",
      "author" : [ "V.N. Rao", "V. Kumar", "K. Ramesh" ],
      "venue" : null,
      "citeRegEx" : "Rao et al\\.,? \\Q1987\\E",
      "shortCiteRegEx" : "Rao et al\\.",
      "year" : 1987
    }, {
      "title" : "AIDA* - asynchronous parallel IDA",
      "author" : [ "A. Reinefeld", "V. Schnecke" ],
      "venue" : null,
      "citeRegEx" : "Reinefeld and Schnecke,? \\Q1994\\E",
      "shortCiteRegEx" : "Reinefeld and Schnecke",
      "year" : 1994
    }, {
      "title" : "Parallel distributed processing: exploration",
      "author" : [ "D.E. Rumelhart", "J.L. McClelland" ],
      "venue" : null,
      "citeRegEx" : "Rumelhart and McClelland,? \\Q1986\\E",
      "shortCiteRegEx" : "Rumelhart and McClelland",
      "year" : 1986
    }, {
      "title" : "A distributed and adaptive dynamic load balancing scheme",
      "author" : [ "V.A. Saletore" ],
      "venue" : null,
      "citeRegEx" : "Saletore,? \\Q1990\\E",
      "shortCiteRegEx" : "Saletore",
      "year" : 1990
    }, {
      "title" : "Darwin: resource management",
      "author" : [ "P. Steenkiste", "A. Fisher", "H. Zhang" ],
      "venue" : null,
      "citeRegEx" : "Steenkiste et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Steenkiste et al\\.",
      "year" : 1997
    }, {
      "title" : "Static partitioning with slackness",
      "author" : [ "C. Suttner" ],
      "venue" : "In Parallel Processing for Arti",
      "citeRegEx" : "Suttner,? \\Q1997\\E",
      "shortCiteRegEx" : "Suttner",
      "year" : 1997
    }, {
      "title" : "An architecture for improving the performance of parallel search",
      "author" : [ "R.C. Varnell" ],
      "venue" : null,
      "citeRegEx" : "Varnell,? \\Q1997\\E",
      "shortCiteRegEx" : "Varnell",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Cook and Varnell distributed-memory algorithms, parallel search algorithms have been developed for MIMD shared-memory systems (Kale & Saletore, 1990; Kumar & Rao, 1990) and SIMD architectures (Cook & Lyons, 1993; Evett et al., 1995; Karypis & Kumar, 1992; Mahanti & Daniels, 1993; Powley et al., 1993).",
      "startOffset" : 192,
      "endOffset" : 301
    }, {
      "referenceID" : 23,
      "context" : "Cook and Varnell distributed-memory algorithms, parallel search algorithms have been developed for MIMD shared-memory systems (Kale & Saletore, 1990; Kumar & Rao, 1990) and SIMD architectures (Cook & Lyons, 1993; Evett et al., 1995; Karypis & Kumar, 1992; Mahanti & Daniels, 1993; Powley et al., 1993).",
      "startOffset" : 192,
      "endOffset" : 301
    }, {
      "referenceID" : 8,
      "context" : "A compromise between these approaches divides the set of processors into clusters (Cook, 1997).",
      "startOffset" : 82,
      "endOffset" : 94
    }, {
      "referenceID" : 31,
      "context" : "Alternative approaches are not receiver based, but allow an overly-loaded processor to initiate a load balance operation (Furuichi, Taki, & Ichyoshi, 1990; Rajpal & Kumar, 1993) or allow all processors to periodically shift work to keep the average load within acceptable bounds (Anderson & Chen, 1987; Saletore, 1990).",
      "startOffset" : 279,
      "endOffset" : 318
    }, {
      "referenceID" : 22,
      "context" : "Powley and Korf suggest two methods of ordering the search space (1991). First, children of each node can be ordered and expanded by increasing heuristic distance to a goal node.",
      "startOffset" : 0,
      "endOffset" : 72
    }, {
      "referenceID" : 8,
      "context" : "Instead of ordering individual nodes, Cook et al. (1993) order the set of operators to guide the next IDA* iteration to the most promising node.",
      "startOffset" : 38,
      "endOffset" : 57
    }, {
      "referenceID" : 34,
      "context" : "This is derived in the literature (Kumar & Rao, 1990; Varnell, 1997) as S = P bd + bd 1 + bd 2 + + b2 + b bd + bd 1 + bd 2 + + bx+1 !+ 1 2bx : (1) As d increases, the leftmost fractional part of this equation approaches 1 and can be ignored.",
      "startOffset" : 34,
      "endOffset" : 68
    }, {
      "referenceID" : 18,
      "context" : "Kumar and Rao (1990) provide an analysis of the speedup of distributed tree search, and Powley and Korf (1991) provide an analysis of parallel window search.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 18,
      "context" : "Kumar and Rao (1990) provide an analysis of the speedup of distributed tree search, and Powley and Korf (1991) provide an analysis of parallel window search.",
      "startOffset" : 0,
      "endOffset" : 111
    }, {
      "referenceID" : 24,
      "context" : "Powley and Korf generate this ratio using the notion of the left-to-right goal position a, de ned as the fraction of the total number of nodes in the goal iteration that must be expanded before reaching the rst goal node (1991). Speedup of parallel window search can thus be expressed as S = bd 1 b b 1 2 + abd b b 1 abd b b 1 = 1 + 1 a(b 1) : (2) Given this formula, we can empirically compare the performance of distributed tree search and parallel window search for P = 10, b = 6, and d = 10.",
      "startOffset" : 0,
      "endOffset" : 228
    }, {
      "referenceID" : 9,
      "context" : "Similar analyses have been provided to compare node ordering techniques and to determine the optimal number of clusters (Cook et al., 1993; Powley & Korf, 1991; Varnell, 1997).",
      "startOffset" : 120,
      "endOffset" : 175
    }, {
      "referenceID" : 34,
      "context" : "Similar analyses have been provided to compare node ordering techniques and to determine the optimal number of clusters (Cook et al., 1993; Powley & Korf, 1991; Varnell, 1997).",
      "startOffset" : 120,
      "endOffset" : 175
    }, {
      "referenceID" : 19,
      "context" : "Research in other areas of computer science has yielded similar ideas of customizable environments applied to computer networks (Bhattacharjee, Calvert, & Zegura, 1997; Steenkiste, Fisher, & Zhang, 1997) and to interactive humancomputer interfaces (Frank, Sukavirija, & Foley, 1995; Lieberman, 1998).",
      "startOffset" : 248,
      "endOffset" : 299
    }, {
      "referenceID" : 25,
      "context" : "5 (Quinlan, 1993) to induce a decision tree from the pre-classi ed cases.",
      "startOffset" : 2,
      "endOffset" : 17
    }, {
      "referenceID" : 11,
      "context" : "Craig provides a detailed description of the calculations necessary to determine the position of the end e ector in the 3D workspace given the current joint angles (1989). For our experiments, we use the parameters de ned for the Puma 560 robot arm with six degrees of freedom shown in Figure 12.",
      "startOffset" : 0,
      "endOffset" : 171
    }, {
      "referenceID" : 26,
      "context" : "5, the ID3 decision tree induction algorithm (Quinlan, 1986), the CN2 sequential covering algorithm (Clark & Niblett, 1989), a backpropagation neural net (Rumelhart & McClelland, 1986), a Bayesian classi er (Cestnik, 1990), and a majority-wins classi er.",
      "startOffset" : 45,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "5, the ID3 decision tree induction algorithm (Quinlan, 1986), the CN2 sequential covering algorithm (Clark & Niblett, 1989), a backpropagation neural net (Rumelhart & McClelland, 1986), a Bayesian classi er (Cestnik, 1990), and a majority-wins classi er.",
      "startOffset" : 207,
      "endOffset" : 222
    } ],
    "year" : 2011,
    "abstractText" : null,
    "creator" : "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"
  }
}