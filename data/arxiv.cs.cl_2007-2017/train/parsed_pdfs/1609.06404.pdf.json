{
  "name" : "1609.06404.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "KU-ISPL Language Recognition System for NIST 2015 i-Vector Machine Learning Challenge",
    "authors" : [ "Suwon Shon", "Seongkyu Mun", "John H. L. Hansen", "Hanseok Ko" ],
    "emails" : [ "skmoon}@ispl.korea.ac.kr,", "john.hansen@utdallas.edu,", "hsko@korea.ac.kr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In language recognition, the task of rejecting/differentiating closely spaced versus acoustically far spaced languages remains a major challenge. For confusable closely spaced languages, the system needs longer input test duration material to obtain sufficient information to distinguish between languages. Alternatively, if languages are distinct and not acoustically/linguistically similar to others, duration is not a sufficient remedy. The solution proposed here is to explore duration distribution analysis for near/far languages based on the Language Recognition i-Vector Machine Learning Challenge 2015 (LRiMLC15) database. Using this knowledge, we propose a likelihood ratio based fusion approach that leveraged both score and duration information. The experimental results show that the use of duration and score fusion improves language recognition performance by 5% relative in LRiMLC15 cost.\nIndex Terms: i-vector, language recognition, duration, GMM, DNN, fusion"
    }, {
      "heading" : "1. Introduction",
      "text" : "In recent years, the i-Vector based representation of speech has been used for state-of-the-art modeling with significant progress in the area of speaker and language recognition[1]–[6]. Due to this impact, National Institute of Standards and Technology (NIST) coordinated the Language Recognition iVector Machine Learning Challenge 2015 (LRiMLC15) which was based on the i-Vector paradigm, which differed from previous regular NIST Language Recognition Evaluations that focused on the original audio files for train and test. By providing only the i-Vector data directly, it encouraged participations from researchers not only in the audio processing field but also from the machine learning field. Participants in this evaluation uploaded their solution results to an online leader board in real-time for scoring.\nThe development data provided by NIST for LRiMLC15 was unlabeled. Thus, it opened up a range of opportunities for exploring new ideas with unlabeled data. Another feature of the data provided by NIST is the segment duration. Every data stream has duration information from the original input segment. Therefore, the use of duration information could potentially improve performance for evaluation. Several studies have verified that performance improvement of i-Vector system using duration by calibrating the score when there are duration mismatched conditions [7]–[11]. The statistical characteristic of i-Vector is changed by duration of the original input segment. Thus, for text-independent speaker/language recognition tasks, duration is important information for calibrating the scores. To calibrate a score by compensating for the duration mismatched\ncalibration was considered as an important process [7]–[9].\nIn this study, we propose an alternative approach that utilizes duration as one of the metrics for fusion to reflect the phonetic characteristics of each language. Typically, an i-Vector paradigm is used in both speaker recognition and language recognition. However, the information that the recognition system needs is different between that of speaker versus language. The main purpose of speaker recognition is to obtain speaker’s phonetic characteristics from input speaker’s segment regardless of their language. However, the main purpose of language recognition is to obtain the phonetic characteristics of each language while suppressing the individual speaker’s phonetic characteristics. Therefore, for robust language recognition, the system should model the phonetic characteristics of each language and emphasize the differences among them for effective recognition. So, training i-Vectors for each language is usually modeled by Gaussian Mixture Model (GMM) or Deep Neural Network (DNN) [12]. Finally, the score is evaluated between the language model and input segment. We address this point for performance improvement by using duration information of input segments for robust scoring.\nIn language identification, a cluster based hierarchical\napproach has been studied previously [13], [14]. In these studies, similarities between each language were measured by a distance assessment and clustered by its similarity. Previous work on perceptual as well as acoustic dialect and language distance assessment has resulted in several effective solutions [15]. Though each language has its own phonetic rules, some languages (i.e., dialects) are very similar to other languages from the perspective of phonetic characteristics. Thus, any similar language models will lead to confusion in language recognition, and therefore a longer duration test segment is potentially needed to effectively distinguish the unique language pair. In the score domain, we validate this difference of similarity between each language by associating the duration using the NIST LRiMLC15 database. To reflect the difference for each language, we propose a likelihood ratio based fusion approach using both score and duration information. We validate the performance improvement of the proposed approach using i-Vectors from NIST LRiMLC15 and the online scoreboard of NIST LRiMLC15."
    }, {
      "heading" : "2. Baseline",
      "text" : "All i-Vectors and a baseline system for LRiMLC15 are provided by NIST. From a total variability perspective, a speaker utterance can be defined by both speaker and channel variability in a single space, (i.e., total variability space), as shown in the equation below,\nTωmM  (1)\nwhere M represents the speaker utterance in the GMM supervector space, m denotes the speaker and channel independent GMM supervector from GMM-Universal Background Model (UBM). T is a total variability matrix which is a rectangular matrix of low rank and ω is an i-vector. NIST provided three kinds of i-vector databases as summarized below.\n Development i-Vectors: a total of 6351 i-Vectors are used for estimating the UBM and i-Vector extractor. The\ndatabase have no language label.\n Training i-Vectors: a total of 15,000 i-Vectors are used for enrollment of the 50 languages. The database has\nlabels and each language has 300 i-Vectors.\n Testing i-Vectors: a total of 6500 i-Vectors are used for test with no language label.\nThe database has duration information for each i-Vector as well. For the baseline system, NIST provided a simple recipe using cosine distance scoring. All i-Vectors are centered and whitened by a global mean and covariance of the development i-Vectors. Next, all i-Vectors are projected on to a unit sphere. Training iVectors for each language are averaged and then projected onto the average-language i-Vector in the unit sphere again. Finally, the cosine score is obtained by the inner product between all the average-language i-Vectors and testing i-Vectors."
    }, {
      "heading" : "3. Subsystems",
      "text" : "Fusion of subsystems in the past have shown good performance in speaker recognition challenges. Here, we also fuse different systems to improve results. Two kinds of state-of-art posteriors [12] are used for language recognition, one employing a GMM and the other using a DNN."
    }, {
      "heading" : "3.1. GMM posterior based LR system",
      "text" : "For the GMM posterior based LR system, we use a general GMM-UBM framework. Using the development i-Vector data, a universal background i-vector model λbkg is trained with a GMM algorithm and each i-vector model λlang for each language is created from λbkg using maximum a posteriori (MAP) estimation. For each input i-Vector, the score can be calculated by the likelihood ratio between the universal background language model λbkg and each language model λlang."
    }, {
      "heading" : "3.2. DNN posterior based LR system",
      "text" : "For the DNN posterior based LR system, we follow a successive method using DNN posterior for SR based on Deep Belief Networks (DBN) [16]. At first, i-Vectors for DNN input are prepared from the train database. Next, a Universal DBN (UDBN) is trained using unlabeled speaker i-Vectors. After the UDBN is trained in an unsupervised manner, a label layer is added on top of the network and a stochastic gradient descent backpropagation is carried out for overall fine tuning of the DNN."
    }, {
      "heading" : "4. Proposed duration and score fusion",
      "text" : "In this section, we introduce duration and score fusion based on likelihood ratio for reflecting phonetic characteristics of the languages. We assume that every language has its own phonetic characteristics, however some languages are similar to each other. In such cases, the duration would be much more important to distinguish between similar languages.\nIn the case of speaker recognition, duration is important for obtaining sufficient information of unique phonemes. The number of unique phonemes increases by duration exponentially, so that the statistical characteristics of the iVectors is altered by duration [9]. Thus, duration is a significant value in determining a score for the input test utterance.\nHowever, in the case of language recognition, duration is significant from a different perspective compared with speaker recognition. Suppose there is a limited number of languages for a system to recognize. If one language is very unique and not similar (i.e., far acoustic distance) to other languages, duration is not important because the phonetic characteristics of the smaller test set are sufficiently different. However, if the phonetic characteristics of a language are very similar to other languages in the system, duration is much more important to leverage information of the input segment in distinguishing the differences between languages. It would be possible to explore this through a score by duration distribution analysis.\nThe score can be calculated by a GMM posterior as noted in Sec. 3.1 and specific parameters for obtaining GMM score is described in Sec. 5. Leave-one-out Cross-validation method is used for obtaining scores among the train i-Vectors, because the training i-Vectors only have language labels. For one i-Vector, we can obtain the 1 target score and the 49 non-target language scores. In total, we obtain 15,000 target scores and 735,000 non-target scores and all duration is converted to a logarithmic scale. Fig. 1 shows a scatter plot of the score duration distribution of target scores and non-target scores of all language train i-Vectors. In general, the shorter duration iVector will be difficult to classify as target or non-target. For the longer duration, the scores are easier to classify as target or not. At this step, by using a calibration approach based on using duration, the target and non-target score can be calibrated for an overall optimal decision threshold as previous studies [7]–[9]\nHowever, if we look at the specific languages, for example, Arabic and Romanian as below Fig. 2 and 3 respectively, it is clear that the score distribution is totally different for these languages. For the Romanian language, the target scores show constant high value regardless of duration. For the Arabic language, a long test duration is necessary to achieve the same consistent high score.\nFrom these analyses, we can verify that some languages which are more confusable require longer test duration than languages which are more acoustically separable. By utilizing this difference of score distribution, it could achieve a robust score through fusion of duration and score values for each language. One possible reason for success of this approach is that in language recognition, we typically have a sufficient size enrollment (i.e., training i-Vectors) database for each language to model the score densities, while, for speaker recognition, the number of enrollment entries in the database is small for each speaker. The other reason is that there is a limited number of classes (language) to recognize, so it is possible to establish the target class score density models in advance.\nSuppose xl is the score of l language class using an input speech utterance x of d duration. The joint densities of score and duration given the target and non-target classes are f(xl,d|λtar) and f(xl,d|λnon) respectively. Here, a GMM is successfully used to estimate the arbitrary densities in [17], [18]. Thus, the estimates of the joint densities of score and duration are:\n),|,()|,( ,, 1 , itaritar\nC\ni litartarl dxwdxf Σμ \n g (2)\n),|,()|,( ,, 1 , inoninon\nC\ni linonnonl dxwdxf Σμ \n g (3)\nwhere λtar and λnon is target and non-target score GMM model, μ and Σ and w are the mean, covariance and weight of the GMM respectively. C is total number of components. The likelihood ratio is then,\n)|,(\n)|,( ),(\nnonl\ntarl l\ndxf\ndxf dxLR\n\n  (4)\nand the system output is likelihood ratio vector as below,\n]),(,,...),(),,([ 21 dxLRdxLRdxLRoutputsystem Llll  (5)\nwhere total number of language L=50. We assume input x to l language class if LR(xl, d) > η, and out of set if all LR(·) < η\nwhere η is threshold. For reflecting each of the language characteristics, the joint density can be revised using λltar and λlnon which are score models of l language class as follows,\n),|,()|,( ,, 1 ,\nl itar l itar\nC\ni\nl\nl itar l\ntarl dxwdxf Σμ \n g (6)\n),|,()|,( ,, 1 ,\nl inon l inon\nC\ni\nl\nl inon l\nnonl dxwdxf Σμ \n g (7)\n)|,(\n)|,( ),(\nl\nnonl\nl\ntarl ll\ndxf\ndxf dxLR\n\n  (8)\n]),(,...),(),,([ 502211 dxLRdxLRdxLRoutputsystem Lllllll  (9)\nFor estimating the GMM parameters of λltar and λlnon for each language, we employ a GMM-UBM paradigm [19]. Universal target score model can be estimated by target score of all languages. Next, the each language target score model can be\nadapted by MAP as shown in Fig. 7. This process is also done to obtain the non-target score model. The number of optimal GMM component, can be estimated by a minimum message length criterion which is proposed in [20] for GMM fitting algorithm.\nWe can assess the effect of the proposed approach as Fig. 4 to 6. Figure 4 shows the target and non-target scores distribution of all languages. We can check the distance between target and non-target scores, which are clearly farther than before. For the each language’s score distribution as Fig. 5 and 6, the nontarget scores decrease while the target scores increase compare to the original score distribution seen in Fig. 3 and 4. This changes will affect the false positive rate of the system significantly. We can verify these improvements with a Detection Error Trade-off (DET) curve in Fig. 8. From these analyses, using duration for fusion to reflect the phonetic characteristics of each language shows promising performance improvement in language recognition."
    }, {
      "heading" : "5. KU-ISPL system",
      "text" : "In this section, we describe the specification of Korea University – Intelligent Signal Processing Laboratory (KUISPL) system used in NIST LRiMLC15.\nAt first, the dimension of the i-Vectors was reduced from 400 to 49 using Linear Discriminant Analysis (LDA). The LDA transformation matrix is calculated by training i-Vectors which have language labels. The scores were calculated by both GMM and DNN posteriors as discussed in Sec. 3. For the GMM, 49 dimension i-Vector is trained with a 64 component GMM. The DNN used here consists of an input layer with 49 nodes, 2 hidden layers with 600 nodes and an output layer with 50 nodes. The sigmoid and softmax are the activation function of all hidden layers and top label layer, respectively.\nThe proposed score and duration fusion was done using both GMM and DNN posterior scores. The optimal number of GMM\ncomponents was 4 for both universal target and non-target score model by minimum message length criterion [20]. The two subsystem was fused based on the linear model [21]. Next, quality calibration was done based on QMF [11] and suitable threshold η is determined based on training i-Vectors database"
    }, {
      "heading" : "6. Performance assessment",
      "text" : "The performance was assessed using the progress set of the test i-Vectors. A progress set comprised of randomly selected 30% among 6500 testing i-Vectors for preventing empirical optimization of recognition system. The score metric is defined in LRiMLC15 as follows [22],\n    n\nk\nerrorooserror oos oosPPkP\nn\nP Cost )(*)(* )1( (10)\nwhere Perror=(#errors_class_k / #trials_class_k), n=50, Poos=0.23 and oos for “out of set”. All cost values were calculated in the NIST server by uploading the estimated language labels of test i-Vectors. For validating the proposed approach, costs were compared between the systems that applied the proposed approach and not. Table 1 shows the costs of several systems in our study. The baseline represents the system described in Sec. 2. The GMM and DNN reflect subsystems described in Sec. 3. Fusion stands for the system described in Sec 5.\nFor a single subsystem, the GMM subsystem shows better performance than other systems such as baseline and DNN subsystem. The systems with the proposed duration and score fusion approach shows overall better performance than systems without the proposed approach in both subsystems and fusion systems."
    }, {
      "heading" : "7. Conclusion",
      "text" : "This study has explored score and duration fusion for language recognition. Though score calibration using duration has been proposed in recent studies, the analysis of similarity between language classes based on duration has not been explored. The purpose of this study has been to show that score distribution by duration is discriminative between each language. Based on original phonetic characteristics, each language might be similar to other languages or not. Using these differences, we proposed a likelihood ratio based fusion approach which leverages score and duration. From analysis and online score results from the NIST LRiMLC15 leader board, we have validated the performance improvement of the fused GMM and DNN language recognition system. Therefore, it is clear that using duration for fusion with the score on each language is effective for improving overall language recognition performance."
    }, {
      "heading" : "8. References",
      "text" : "[1] N. Dehak, P. J. Kenny, R. Dehak, P. Dumouchel, and P. Ouellet,\n“Front-End Factor Analysis for Speaker Verification,” IEEE Trans. Audio, Speech, Lang. Process., vol. 19, no. 4, pp. 788–798, May 2011.\n[2] J. H. L. Hansen and T. Hasan, “Speaker Recognition by Machines and Humans,” IEEE Signal processing magazine, pp. 74–99, 2015.\n[3] P. Matejka, O. Glembek, F. Castaldo, M. J. Alam, O. Plchot, P.\nKenny, L. Burget, and J. Cernocky, “Full-covariance UBM and heavy-tailed PLDA in i-vector speaker verification,” in IEEE ICASSP, 2011, pp. 4828–4831.\n[4] S. Shon, S. Mun, D. K. Han, and H. Ko, “Maximum likelihood Linear Dimension Reduction of heteroscedastic feature for robust\nSpeaker Recognition,” in IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2015, pp. 1–5.\n[5] P. M. Bousquet, D. Matrouf, and J. F. Bonastre, “Intersession\ncompensation and scoring methods in the i-vectors space for speaker recognition,” in Interspeech, 2011, no. 1, pp. 485–488.\n[6] D. Garcia-Romero and C. Y. Espy-Wilson, “Analysis of i-vector\nLength Normalization in Speaker Recognition Systems.,” in Interspeech, 2011, no. August, pp. 249–252.\n[7] M. I. Mandasari, R. Saeidi, M. McLaren, and D. A. Van Leeuwen,\n“Quality measure functions for calibration of speaker recognition systems in various duration conditions,” IEEE Trans. Audio, Speech Lang. Process., vol. 21, no. 11, pp. 2425–2438, 2013.\n[8] M. I. Mandasari, R. Saeidi, and D. A. van Leeuwen, “Quality\nmeasures based calibration with duration and noise dependency for speaker recognition,” Speech Commun., vol. 72, pp. 126–137, 2015.\n[9] T. Hasan, R. Saeidi, J. H. L. Hansen, and D. A. van Leeuwen,\n“Duration mismatch compensation for i-Vector based speaker recognition systems,” in IEEE ICASSP, 2013, pp. 7663–7667.\n[10] T. Hasan, S. O. Sadjadi, G. Liu, N. Shokouhi, H. Boril, and J. H. .\nL. . Hansen, “CRSS Systems for 2012 NIST Speaker Recognition Evaluation,” in IEEE ICASSP, 2013, pp. 6783–6787.\n[11] M. I. Mandasari, R. Saeidi, and D. A. van Leeuwen, “Calibration\nbased on duration quality measure function in noise robust speaker recognition for NIST SRE’12,” in Biometric Technologies in Forensic Science, 2013, pp. 1–5.\n[12] F. Richardson, S. Member, D. Reynolds, and N. Dehak, “Deep\nNeural Network Approaches to Speaker and Language Recognition,” IEEE Signal Process. Lett., vol. 22, no. 10, pp. 1671–1675, 2015.\n[13] E. Ambikairajah, “Improvements on hierarchical language identification based on automatic language clustering,” in IEEE\nICASSP, 2008, pp. 4241–4244.\n[14] B. Yin, E. Ambikairajah, and F. Chen, “Hierarchical language identification based on automatic language clustering,” in\nInterspeech, 2007, pp. 178–181.\n[15] M. Mehrabani and J. H. L. Hansen, “Automatic analysis of dialect/language sets,” Int. J. Speech Technol., vol. 18, no. 3, pp.\n277–286, Jan. 2015.\n[16] O. Ghahabi and J. Hernando, “Deep belief networks for i-vector based speaker recognition,” in IEEE ICASSP, 2014, no. 1, pp.\n1700–1704.\n[17] J. Q. Li and A. R. Barron, “Mixture Density Estimation,” Adv. NEURAL Inf. Process. Syst. 12, pp. 279–285, 1999.\n[18] A. Rakhlin, D. Panchenko, and S. Mukherjee, “Risk bounds for\nmixture density estimation,” ESAIM Probab. Stat., vol. 9, pp. 220– 229, Nov. 2005.\n[19] D. A. Reynolds, T. F. Quatieri, and R. B. Dunn, “Speaker\nVerification Using Adapted Gaussian Mixture Models,” Digit. Signal Process., vol. 10, no. 1–3, pp. 19–41, Jan. 2000.\n[20] M. A. F. Figueiredo and A. K. Jain, “Unsupervised learning of\nfinite mixture models,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 3, pp. 381–396, 2002.\n[21] N. Brümmer and E. de Villiers, “The BOSARIS Toolkit: Theory,\nAlgorithms and Code for Surviving the New DCF,” in NIST SRE’11 Analysis Workshop, 2011.\n[22] “The NIST i-Vector Machine Learning Challenge - Language\nRecognition i-Vector Machine Learning Challenge,” 2015. [Online]. Available: http://www.nist.gov/itl/iad/mig/upload/lre_iv ectorchallenge_rel_v2.pdf."
    } ],
    "references" : [ {
      "title" : "Front-End Factor Analysis for Speaker Verification",
      "author" : [ "N. Dehak", "P.J. Kenny", "R. Dehak", "P. Dumouchel", "P. Ouellet" ],
      "venue" : "IEEE Trans. Audio, Speech, Lang. Process., vol. 19, no. 4, pp. 788–798, May 2011.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Speaker Recognition by Machines and Humans",
      "author" : [ "J.H.L. Hansen", "T. Hasan" ],
      "venue" : "IEEE Signal processing magazine, pp. 74–99, 2015.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Full-covariance UBM and heavy-tailed PLDA in i-vector speaker verification",
      "author" : [ "P. Matejka", "O. Glembek", "F. Castaldo", "M.J. Alam", "O. Plchot", "P. Kenny", "L. Burget", "J. Cernocky" ],
      "venue" : "IEEE ICASSP, 2011, pp. 4828–4831.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Maximum likelihood Linear Dimension Reduction of heteroscedastic feature for robust Speaker Recognition",
      "author" : [ "S. Shon", "S. Mun", "D.K. Han", "H. Ko" ],
      "venue" : "IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2015, pp. 1–5.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Intersession compensation and scoring methods in the i-vectors space for speaker recognition",
      "author" : [ "P.M. Bousquet", "D. Matrouf", "J.F. Bonastre" ],
      "venue" : "Interspeech, 2011, no. 1, pp. 485–488.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Analysis of i-vector Length Normalization in Speaker Recognition Systems",
      "author" : [ "D. Garcia-Romero", "C.Y. Espy-Wilson" ],
      "venue" : "Interspeech, 2011, no. August, pp. 249–252.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Quality measure functions for calibration of speaker recognition systems in various duration conditions",
      "author" : [ "M.I. Mandasari", "R. Saeidi", "M. McLaren", "D.A. Van Leeuwen" ],
      "venue" : "IEEE Trans. Audio, Speech Lang. Process., vol. 21, no. 11, pp. 2425–2438, 2013.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Quality measures based calibration with duration and noise dependency for speaker recognition",
      "author" : [ "M.I. Mandasari", "R. Saeidi", "D.A. van Leeuwen" ],
      "venue" : "Speech Commun., vol. 72, pp. 126–137, 2015.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Duration mismatch compensation for i-Vector based speaker recognition systems",
      "author" : [ "T. Hasan", "R. Saeidi", "J.H.L. Hansen", "D.A. van Leeuwen" ],
      "venue" : "IEEE ICASSP, 2013, pp. 7663–7667.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "CRSS Systems for 2012 NIST Speaker Recognition Evaluation",
      "author" : [ "T. Hasan", "S.O. Sadjadi", "G. Liu", "N. Shokouhi", "H. Boril", "J.H. . L. . Hansen" ],
      "venue" : "IEEE ICASSP, 2013, pp. 6783–6787.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Calibration based on duration quality measure function in noise robust speaker recognition for NIST SRE’12",
      "author" : [ "M.I. Mandasari", "R. Saeidi", "D.A. van Leeuwen" ],
      "venue" : "Biometric Technologies in Forensic Science, 2013, pp. 1–5.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Deep Neural Network Approaches to Speaker and Language Recognition",
      "author" : [ "F. Richardson", "S. Member", "D. Reynolds", "N. Dehak" ],
      "venue" : "IEEE Signal Process. Lett., vol. 22, no. 10, pp. 1671–1675, 2015.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Improvements on hierarchical language identification based on automatic language clustering",
      "author" : [ "E. Ambikairajah" ],
      "venue" : "IEEE ICASSP, 2008, pp. 4241–4244.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Hierarchical language identification based on automatic language clustering",
      "author" : [ "B. Yin", "E. Ambikairajah", "F. Chen" ],
      "venue" : "Interspeech, 2007, pp. 178–181.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Automatic analysis of dialect/language sets",
      "author" : [ "M. Mehrabani", "J.H.L. Hansen" ],
      "venue" : "Int. J. Speech Technol., vol. 18, no. 3, pp. 277–286, Jan. 2015.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Deep belief networks for i-vector based speaker recognition",
      "author" : [ "O. Ghahabi", "J. Hernando" ],
      "venue" : "IEEE ICASSP, 2014, no. 1, pp. 1700–1704.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Mixture Density Estimation",
      "author" : [ "J.Q. Li", "A.R. Barron" ],
      "venue" : "Adv. NEURAL Inf. Process. Syst. 12, pp. 279–285, 1999.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Risk bounds for mixture density estimation",
      "author" : [ "A. Rakhlin", "D. Panchenko", "S. Mukherjee" ],
      "venue" : "ESAIM Probab. Stat., vol. 9, pp. 220– 229, Nov. 2005.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Speaker Verification Using Adapted Gaussian Mixture Models",
      "author" : [ "D.A. Reynolds", "T.F. Quatieri", "R.B. Dunn" ],
      "venue" : "Digit. Signal Process., vol. 10, no. 1–3, pp. 19–41, Jan. 2000.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Unsupervised learning of finite mixture models",
      "author" : [ "M.A.F. Figueiredo", "A.K. Jain" ],
      "venue" : "IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 3, pp. 381–396, 2002.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "The BOSARIS Toolkit: Theory, Algorithms and Code for Surviving the New DCF",
      "author" : [ "N. Brümmer", "E. de Villiers" ],
      "venue" : "NIST SRE’11 Analysis Workshop, 2011.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In recent years, the i-Vector based representation of speech has been used for state-of-the-art modeling with significant progress in the area of speaker and language recognition[1]–[6].",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 5,
      "context" : "In recent years, the i-Vector based representation of speech has been used for state-of-the-art modeling with significant progress in the area of speaker and language recognition[1]–[6].",
      "startOffset" : 182,
      "endOffset" : 185
    }, {
      "referenceID" : 6,
      "context" : "Several studies have verified that performance improvement of i-Vector system using duration by calibrating the score when there are duration mismatched conditions [7]–[11].",
      "startOffset" : 164,
      "endOffset" : 167
    }, {
      "referenceID" : 10,
      "context" : "Several studies have verified that performance improvement of i-Vector system using duration by calibrating the score when there are duration mismatched conditions [7]–[11].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 6,
      "context" : "To calibrate a score by compensating for the duration mismatched condition, a Quality Measure Function (QMF) based score calibration was considered as an important process [7]–[9].",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 8,
      "context" : "To calibrate a score by compensating for the duration mismatched condition, a Quality Measure Function (QMF) based score calibration was considered as an important process [7]–[9].",
      "startOffset" : 176,
      "endOffset" : 179
    }, {
      "referenceID" : 11,
      "context" : "So, training i-Vectors for each language is usually modeled by Gaussian Mixture Model (GMM) or Deep Neural Network (DNN) [12].",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 12,
      "context" : "In language identification, a cluster based hierarchical approach has been studied previously [13], [14].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 13,
      "context" : "In language identification, a cluster based hierarchical approach has been studied previously [13], [14].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 14,
      "context" : "Previous work on perceptual as well as acoustic dialect and language distance assessment has resulted in several effective solutions [15].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 11,
      "context" : "Two kinds of state-of-art posteriors [12] are used for language recognition, one employing a GMM and the other using a DNN.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : "For the DNN posterior based LR system, we follow a successive method using DNN posterior for SR based on Deep Belief Networks (DBN) [16].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 8,
      "context" : "The number of unique phonemes increases by duration exponentially, so that the statistical characteristics of the iVectors is altered by duration [9].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 6,
      "context" : "At this step, by using a calibration approach based on using duration, the target and non-target score can be calibrated for an overall optimal decision threshold as previous studies [7]–[9]",
      "startOffset" : 183,
      "endOffset" : 186
    }, {
      "referenceID" : 8,
      "context" : "At this step, by using a calibration approach based on using duration, the target and non-target score can be calibrated for an overall optimal decision threshold as previous studies [7]–[9]",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 16,
      "context" : "Here, a GMM is successfully used to estimate the arbitrary densities in [17], [18].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 17,
      "context" : "Here, a GMM is successfully used to estimate the arbitrary densities in [17], [18].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 18,
      "context" : "For estimating the GMM parameters of λtar and λnon for each language, we employ a GMM-UBM paradigm [19].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 19,
      "context" : "The number of optimal GMM component, can be estimated by a minimum message length criterion which is proposed in [20] for GMM fitting algorithm.",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 19,
      "context" : "The optimal number of GMM components was 4 for both universal target and non-target score model by minimum message length criterion [20].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 20,
      "context" : "The two subsystem was fused based on the linear model [21].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "Next, quality calibration was done based on QMF [11] and suitable threshold η is determined based on training i-Vectors database",
      "startOffset" : 48,
      "endOffset" : 52
    } ],
    "year" : 2016,
    "abstractText" : "In language recognition, the task of rejecting/differentiating closely spaced versus acoustically far spaced languages remains a major challenge. For confusable closely spaced languages, the system needs longer input test duration material to obtain sufficient information to distinguish between languages. Alternatively, if languages are distinct and not acoustically/linguistically similar to others, duration is not a sufficient remedy. The solution proposed here is to explore duration distribution analysis for near/far languages based on the Language Recognition i-Vector Machine Learning Challenge 2015 (LRiMLC15) database. Using this knowledge, we propose a likelihood ratio based fusion approach that leveraged both score and duration information. The experimental results show that the use of duration and score fusion improves language recognition performance by 5% relative in LRiMLC15 cost.",
    "creator" : "Microsoft® Word 2013"
  }
}