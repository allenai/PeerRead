{
  "name" : "1105.5457.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Derek Long", "Maria Fox" ],
    "emails" : [ "d.p.long@dur.ac.uk", "maria.fox@dur.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Journal of Arti cial Intelligence Research 10 (1999) 87-115 Submitted 9/98; published 2/99E cient Implementation of the Plan Graph in STANDerek LongMaria FoxDepartment of Computer ScienceUniversity of Durham, UK d.p.long@dur.ac.ukmaria.fox@dur.ac.ukAbstractStan is a Graphplan-based planner, so-called because it uses a variety of STate ANal-ysis techniques to enhance its performance. Stan competed in the AIPS-98 planningcompetition where it compared well with the other competitors in terms of speed, ndingsolutions fastest to many of the problems posed. Although the domain analysis techniquesStan exploits are an important factor in its overall performance, we believe that the speedat which Stan solved the competition problems is largely due to the implementation ofits plan graph. The implementation is based on two insights: that many of the graphconstruction operations can be implemented as bit-level logical operations on bit vectors,and that the graph should not be explicitly constructed beyond the x point. This paperdescribes the implementation of Stan's plan graph and provides experimental results whichdemonstrate the circumstances under which advantages can be obtained from using thisimplementation.1. IntroductionStan is a domain-independent planner for STRIPS domains, based on the graph construc-tion and search method of Graphplan (Blum & Furst, 1997). Its name is derived from thefact that it performs a number of preprocessing analyses, or STate ANalyses, on the domainbefore planning, using the Type Inference Module Tim described by Fox and Long (1998).Stan competed in the AIPS-98 planning competition and achieved an excellent overallperformance in both rounds. The results of the competition, which can be found at theURL given in Appendix A, show that Stan was able to solve some problems notablyquickly and that it could nd optimal parallel solutions to some problems which could notbe solved optimally by any other planner in the competition, for example in the Gripperdomain. The problems posed in the competition did not give Stan much opportunity toexploit its domain analysis techniques, so this performance is due mainly to the underlyingimplementation of the plan graph that Stan constructs and searches. A more detaileddiscussion of the competition, from the competitors' point of view, is in preparation.The design of Stan's plan graph is based on two insights. First, we observe that actionpre- and post-conditions can be represented using bit vectors. Checking for mutual exclusionbetween pairs of actions which directly interact can be implemented using logical operationson these bit vectors. Mutual exclusion (mutex relations) between facts can be implementedin a similar way. In order to best exploit the bit vector representation of informationwe construct a two-layer graph called a spike which avoids unnecessary copying of dataand allows layer-dependent information about a node to be clearly separated from layer-independent information about that node. The spike allows us to record mutex relationsc 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nLong & Foxusing bit vectors, making mutex testing for indirect interaction much more e cient (wedistinguish between direct and indirect interaction in Section 2.1). Second, we observe thatthere is no advantage in explicit construction of the graph beyond the stage at which the x point is reached. Our plan graph maintains a wave front which keeps track of all of thegoal sets remaining to be considered during search. Since no new facts, actions or mutexrelations are added beyond the x point these goal sets can be considered without explicitcopying of the fact and action layers. The wave front mechanism allows Stan to solve verylarge problem instances using a fraction of the time and space consumed by Graphplan andIpp (Koehler, Nebel, & Dimopoulos, 1997). For example, using a heuristic discussed inSection 5.1, Stan can solve the 10-disc Towers of Hanoi problem (a 1023 step plan) in lessthan 9 minutes.In this paper we describe the spike and wave front mechanisms and provide experimentalresults indicating the performance advantages obtained.2. The Spike Graph StructureGraphplan (Blum & Furst, 1997) uses constraint satisfaction techniques to search a lay-ered graph which represents a compressed reachability analysis of a domain. The layerscorrespond to snapshots of possible states at instants on a time line from the initial to thegoal state. Each layer in the graph comprises a set of facts that represents the union ofstates reachable from the preceding layer. This compression guarantees that the plan graphcan be constructed in time polynomial in the number of action instances in the domain.The expansion of the graph, from which solutions can be extracted, is partially encoded inbinary mutex relations computed during the construction of each layer. STAN implementsan e cient representation of the graph in which a wave front, discussed in Section 4, furthersupports its compression. In Graphplan-style planners the search for a plan, from layer k,involves the selection and exploration of a collection of action choices to see whether a plancan be constructed, using those actions at the kth time step. If no plan is found the plannerbacktracks over the action choices. Two important landmarks arise during the constructionof the plan graph. The rst is the point at which the graph opens in the sense that theproblem becomes, in principle, solvable. This is the layer at which all of the top level goals rst become pairwise non-mutex and is referred to here as the opening layer. The secondis the x point, referred to as level o by Blum and Furst (1997), the layer after which nofurther changes can be made to either the action, fact or mutex information recorded in thegraph at each layer.In the original implementation of Graphplan the graph was implemented as an alter-nating sequence of layers of fact nodes and action nodes, with arcs connecting actions totheir preconditions in the previous layer and their postconditions in the subsequent layer.The layers were constructed explicitly involving the repeated copying of large portions ofthe graph at each stage in maintaining the graph structure. This copying was due to twofeatures of the graph. First, since actions with satis ed preconditions in one layer continueto have satis ed preconditions in all subsequent layers, actions that have once been addedto a layer will appear in every successive action layer with the same name and the samepre- and post-conditions. Second, since facts that have once been achieved by the e ectsof an action will always be achieved by that action, they will continue to appear in every88\nEfficient Implementation of the Plan Graph in STANsuccessive fact layer after the layer in which they rst appeared. Although the layers canget deeper at every successive stage they each duplicate information present in the previouslayer, so there is only a small amount of new information added at every stage. The pro-portion of new material, relative to copied material, decreases progressively as the graphdevelops.In the original Graphplan, mutex relations were checked for by maintaining lists of facts,corresponding to the pre- and post-conditions of actions, and checking for membership offacts within these lists. Because of the need to copy information at each new layer, the pre-and post-conditions of actions were duplicated even though this information did not varyfrom layer to layer (it can be determined once and for all at the point of instantiation ofthe schema). It is possible to identify layer-independent information, with each node in thegraph, which can be stored just once using a di erent representation of the graph structure.The spike representation reimplements the graph as a single fact array, called the factspike, and a single action array, called the action spike, each divided into ranks correspondingto the layers in the original Graphplan graph structure. The observations leading to thiscompressed implementation of the plan graph were made independently by Smith and Weld(1998). In Stan, a fact rank is a consecutive sequence of fact headers storing the layer-independent information associated with their associated facts in the corresponding factlayer. Similarly, an action rank is a consecutive sequence of action headers storing layer-independent information about their associated actions in the corresponding action layer.Each header is a tuple containing, amongst other things, the name of the fact or action itis associated with and a structure which stores the layer-dependent information relevant tothat fact or action. In the case of fact headers this structure is called a fact level packageand in the case of action headers it is an action level package. Figure 1 shows how a simplegraph structure can be viewed as a spike.In the spike the positions of all fact and action headers are xed and can be referred toby indexing into the appropriate array. At any point, the sizes of the arrays are referredto using the constant MaxSize, a large number setting an upper bound on the size of thespike. All of the vectors allocated are also initialised to this size, although they are usedin word-sized increments. This saves the e ort of re-allocating and copying vectors as thespike increases in size towards MaxSize. We now de ne the data types so far introduced.De nition 1 A spike vector is a bit vector of size MaxSize.De nition 2 A fact header is a tuple of six components: a name which is the predicateand arguments that comprise the fact itself; an index, i, giving the position of the fact inthe fact array; a bit mask which is a spike vector in which the ith bit is set and all other bitsare unset; a reference identifying its achieving no-op; a spike vector consumers with bits setfor all the actions which use this fact as a precondition and a fact level package storing thelayer-dependent information about that fact.De nition 3 An action header is a tuple of eight components: the name of the action;an index, i, giving the position of the action in the action array; a bit mask which is aspike vector in which the ith bit is set and all other bits are unset; a ag indicating whetherthe action is a no-op; three spike vectors, called precs, adds and dels and an action levelpackage storing the layer-dependent information about that action. Each bit in precs, adds89\nLong & Fox P Q R\nop1 op2\nNoop Noop Noop\nP Q R S T U V W\nNoop Noop Noop Noop Noop Noop\nrank 0 rank 1\nrank 2\nrank 1\nrank 2\nop1 op2 op3\nP Q R S T U\nP Q R S T U V W\nNoop P Noop Q Noop R op1\nFact Spike and Fact Level Packages\nAction Spike and Action Level Packages\nop2 Noop S Noop T Noop U op3\nFact Layer 0 Fact Layer 1 Fact Layer 2Action Layer 1 Action Layer 2\nFigure 1: Representation of a plan graph as a spike. In the fact spike, ranks 0, 1 and 2correspond to fact layers 0, 1 and 2 respectively. In the action spike, ranks 1 and2 correspond to action layers 1 and 2 respectively.90\nEfficient Implementation of the Plan Graph in STANand dels corresponds to an index into the fact array and is set in precs if the fact at thatindex is a precondition (and unset otherwise), in adds if the fact at that index is an add listelement (and unset otherwise) and in dels if the fact at that index is a delete list elementof the action (and unset otherwise).De nition 4 A fact mutex vector (FMV) for a fact, f , is a spike vector in which the bitscorrespond to the indices into the fact array and a bit is set if the corresponding fact ismutex with f .De nition 5 An action mutex vector (AMV) for an action, a, is a spike vector in whichthe bits correspond to the indices into the action array and a bit is set if the correspondingaction is mutex with a.De nition 6 A fact level package for a fact, f , is an array of pairs, one for each rank inthe spike, each containing a fact mutex vector for f and a vector of achievers, called theachievement vector (AV), in the previous action rank.De nition 7 An action level package for an action, a, is an array of triples, one for eachrank in the spike, each containing an action mutex vector for a and a list of actions mutexwith a (MAs).Using these de nitions we can now provide a detailed description of the spike construc-tion process.2.1 The Spike Construction ProcessWe will make use of these header access functions in the following discussion:mvec : fact! factmutex vectorprecs of : action! precsadds of : action! addsdels of : action! delsThe spike construction process takes place within a loop which stops when all goals arepairwise achievable, and thereafter alternates with search until the x point is reached andthe wave front mechanism takes over. The use of the wave front is discussed in Section 4.The key component of the process is the rank construction algorithm which builds a factrank and an action rank by extending the previous fact and action ranks in the spike. Theaction rank is started by adding no-ops for each of the fact headers in the previous factrank. As soon as these are added, the fact headers can be updated to refer, by index intothe action rank, to their achieving no-ops. This information allows Stan to give preference,when searching, to plans that use the no-op to achieve a goal rather than some otherachiever. In Graphplan this preference was ensured by keeping all of the no-ops at the topof the graph layers and considering the achievers in order during search.All possible action instances are then considered. All applicable action instances areenacted and then removed so that they will never be reconsidered for enactment. We thenidentify mutex relations between the actions in the new action rank, and between facts inthe new fact rank. 91\nLong & FoxAs in Graphplan, an action instance is applicable in a rank if all of its preconditions arepresent and non-mutex in the previous rank. The way in which preconditions are tested formutual exclusion in Stan is based on our bit vector representation of fact mutex relations.We take the logical or of all of the fact mutex vectors of the preconditions, and logicallyand the result with the precondition vector of the action. If the result is non-zero thenthere are mutex preconditions and the action is not applicable. This test corresponds tochecking whether the action being considered is mutex with itself - a condition we de ne asbeing self-mutex.De nition 8 An action a, with preconditions ap1::apn, is self-mutex if:(mvec(ap1) _mvec(ap2) _ :::_mvec(apn))^ precs of(a)is non-zero.An applicable action is enacted by adding an action header to the new rank and settingits name to the name of the action and its bit mask to record its position in the spike.In Figures 2 and 3 no-ops are given the names of the facts they achieve and are identi edas no-ops by the ag components of their headers. We allocate space for the action levelpackage and create and set its pres, adds and dels vectors. We then add any new facts onthe add list of the action to the corresponding new fact rank. The addition of new factsrequires new fact headers to be initialised.We then identify mutex actions and mutex facts in the new ranks. Mutex actionsare identi ed in two phases. Actions which were non-mutex in the previous rank remainnon-mutex and are not considered at this stage. First, existing action mutex relations arechecked to see whether they hold in the new rank. Second, new action mutex relationsmust be deduced from the addition of new actions in the construction of this rank. We rstconsider the existing action mutex relations.Two actions are mutex, as in Graphplan, if they have con icting add and delete lists,con icting precondition and delete lists or mutex preconditions. In the rst two casesthe actions are directly, or permanently, mutex and never need to be re-tested althoughtheir mutex relationship must be recorded at each rank. In the third case the actions areindirectly, or temporarily, mutex and must be retried at subsequent ranks. We keep track ofwhich actions to retry in order to avoid unnecessary retesting. We con rm that two actions,a and b, which were temporarily mutex in the previous rank are still temporarily mutexusing the following logical operations on the fact mutex vectors for the action preconditions.We rst logically or together the mutex vectors for a's preconditions then and the resultwith the precondition vector for b. If the result is non-zero then a and b are mutex. Thisprocedure, which is expressed concisely in De nition 9, is identical to that for checkingwhether an action is self-mutex except that, in this case, the result of oring the fact mutexvectors of the preconditions of one action is anded with the precondition vector of the otheraction. Since mutex relations are symmetric it is irrelevant which action plays which rolein the test.De nition 9 Two actions a (with n preconditions ap1::apn) and b are temporarily mutexif (mvec(ap1) _mvec(ap2) _ :::_mvec(apn))^ precs of(b)92\nEfficient Implementation of the Plan Graph in STANis non-zero.We now consider what new mutex relations can be inferred from the introduction ofthe new actions. It is necessary to check all new actions against all actions in the spike.This check is done in only one direction - low-indexed actions against high-indexed actions- so that the test is done only once for each pair. We check for both permanent andtemporary mutex relations. The permanent mutex test is done rst, because if two actionsare permanently mutex it is of no interest to nd that they are also temporarily mutex.De nition 10 provides the logical operation used to con rm that two actions are permanentlymutex. Temporary mutex relations are checked for using the logical operation de ned inDe nition 9.De nition 10 Two actions a and b are permanently mutex if the result of((precs of(a) _ adds of(a))^ dels of(b))_((precs of(b) _ adds of(b))^ dels of(a))is non-zero.We add these mutex relations by setting the appropriate bits in the mutex vectors ofeach of the new actions. This is done by oring the mutex vector of the rst action with thebit mask of the second action, and vice versa. A list of mutex actions is also maintained foruse during search of the spike.A re nement of the action mutex checking done by Stan is the use of a record of actionswhose preconditions have lost mutex relations since the last layer of the graph. This recordenables Stan to avoid retesting temporary mutex relations between actions when the mutexrelations between their preconditions cannot have changed. We use a bit vector calledchangedActs to record this information. Each fact which loses mutex relations betweenlayers adds its consumers to changedActs. The impact of this re nement on e ciency isdiscussed in Section 3.This concludes the construction of the new action rank. The new fact rank has alreadybeen partially constructed by the addition to the spike of fact headers for any add listelements, of the new actions, that were not already present. Now it is necessary to determinemutex relations between all pairs of facts in the spike. To do this we must rst completethe achievement vectors for all of the fact headers in the new rank. Any non-mutex pairsremain non-mutex, as with actions, so e ort is focussed on deciding whether previouslymutex facts are still mutex following the addition of the new actions, and whether newfacts induce new mutex relations. Two facts are mutex if the only way of achieving bothof them involves the use of mutex actions. We therefore consider every new fact with everyother fact, in only one direction. The pair f , g is mutex in the new rank if every possibleachiever of f is mutex with every possible achiever for g. The test for this exclusion is doneusing g's achievement vector and the result of logically anding the action mutex vectors forall possible achievers of f . the following de nition gives the details:De nition 11 Two facts, f and g, are mutex if:vecg ^ all mutexf = vecg93\nLong & Foxwhere vecg is g's achievement vector and all mutexf is the consequence of anding all of theaction mutex vectors of all of f 's possible achievers.It does not matter in which order f and g are treated. The computation of the abovecondition corresponds to testing the truth of8a 8b (achiever(a; f)^ achiever(b; g)! mutex(a; b))Since mutex relations are symmetric and the quanti ers can be freely reordered the expres-sion equally corresponds to vecf ^ all mutexg = vecfIf f and g are found to be mutex then we set the fact mutex vector of f by oring itwith g's bit mask and the fact mutex vector of g is set conversely. This concludes the rankconstruction process and one iteration of the spike construction process.2.2 Subset Memoization in StanMost of the search machinery used in Stan is essentially identical to that of Graphplan.That is, a goal set is considered by identifying appropriate achieving actions in the previouslayer and propagating their preconditions back through the graph. The use of the spikeand bit vector representations does not impact on the search algorithm. We experimentedwith using bit vector representations of bad goal sets in the memoization process, in orderto exploit logical bit operations to test for subset relations between sets of goals, but thisproved too expensive and we now rely upon a trie data structure. This bene ts marginallyfrom the spike because goal sets do not need to be sorted for subset testing. The orderin which the goals are generated in the spike can be taken as the canonical ordering sincegoal sets are formed by a simple sweep through the spike at each successive layer. Stanimplements an improvement on the goal set memoization of Graphplan. In the originalGraphplan, when a goal set could not be achieved at a particular layer the entire set wasmemoized as a bad set for that layer. In Stan version 2, only the subset of goals thathave been satis ed at the point of failure, within a layer, are actually memoized. More goalsets are likely to contain the smaller memoized subset than would be likely to contain thecomplete original failing goal set. This therefore allows us to prune search branches earlier.This method is a weak version of Kambhampati's (1998, 1999) EBL (Explanation-BasedLearning) modi cations. EBL allows the identi cation of the subset of a goal set that isreally responsible for its failure to yield a plan. Memoization of smaller sets increases thee ciency of the planner by reducing the overhead necessary in identifying failing goal sets.DDB (Dependency-Directed Backtracking) improves the search performance by ensuringthat backtracking returns to the point at which the last choice responsible for failure wasmade. These modi cations result in smaller sets being memoized and a more e cient searchbehaviour which, in combination with the trie, ensure that a higher proportion of failingsearch paths are terminated early.We have experimented with an implementation of the full EBL/DDB modi cationsproposed by Kambhampati, but there is an interaction between the EBL/DDB machineryand the wave front of Stan which we are currently attempting to resolve. Our experimentsso far indicate that both the wave front and EBL/DDB have signi cant bene cial impact94\nEfficient Implementation of the Plan Graph in STANon search, but not consistently across the same problems. We believe that we can enhancethe advantages of the wave front by full integration with EBL/DDB, but this remains tobe demonstrated.2.3 A Worked ExampleWe now demonstrate the spike construction process in action on a simple blocks world ex-ample in which there are two blocks and two table positions. In the initial state, both blocksare on the table, one in each of the two positions. Consequently there are no clear tablepositions. The initial spike consists of a fact rank containing fact headers for the four factsthat describe the initial state. There is a single operator schema, puton(Block; To; From),as follows: puton(X,Y,Z)Pre: on(X,Z), clear(X), clear(Y)Add: on(X,Y), clear(Z)Del: on(X,Z), clear(Y)The action rank is initially empty. On the rst iteration of the loop the rst action rankis constructed by creating no-ops for every fact in the zeroth fact rank. Two further actionsare applicable and are enacted, and the facts on their addlists are used to create a new factrank. This results in the partially developed spike shown in Figure 2.It can be observed from Figure 2 that, following enactment, the fact headers associatedwith the newly added facts are incomplete, and although the new fact level and action levelpackages have been allocated they do not yet contain any values. The new fact headers aremissing references to the no-ops that will be used to achieve them in the next action rank.The new fact level packages are blank because their corresponding fact headers will haveno level information for rank 0.After identi cation of mutex actions and mutex facts, the picture is as shown in Figure 3.In the action level packages, the lists of mutex actions are given as lists of indices for thesake of clarity. In fact they are lists of pointers to actions, in order to avoid the indirectioninvolved in the use of indices. None of the action pairs are temporarily mutex at rank 1because all of the fact mutex vectors from rank 0 are zero-valued.3. Empirical ResultsIn this section we present results demonstrating the e ciency of the spike and vector rep-resentation of the plan graph used by Stan. We consider graph construction only in thissection { the e ciency of search in Stan will be demonstrated in Section 4. We show thee ciency of graph construction in Stan by showing relative performance gures for Stanand the competition version of Ipp in several of the competition domains and two furtherstandard bench mark domains. These are the Graphplan version of the Travelling Salesmandomain (Blum & Furst, 1997), which uses a complete graph and is referred to here as theComplete-Graph Travelling Salesman domain, and the Ferry domain available in the PDDLrelease.We compare Stan with Ipp because, to the best of our knowledge, Ipp is the onlyother fast Graphplan-based planner currently publicly available. We use the competition95\nLong & Fox name: on(a,t1) index: 0 noop: 0 name: on(b,t2) index: 1 msk 01000000 noop: 1 name: clear(a) index: 2 msk 00100000 msk 10000000 noop: 2 name: clear(b) index: 3 msk 00010000 noop: 3 name: on(a,b) index: 4 msk 00001000 noop: name: clear(t1) index: 5 msk 00000100 noop: name: clear(t2) index: 6 msk 00000010 noop: name: on(b,a) index: 7 msk 00000001 noop: index: 0 msk: 10000000 noop?: True precs: 10000000 adds: 10000000 index: 1 msk: 01000000 noop?: True precs: 01000000 adds: 01000000 dels: 00000000 dels: 00000000 index: 2 msk: 00100000 noop?: True precs: 00100000 adds: 00100000 dels: 00000000 index: 3 msk: 00010000 noop?: True precs: 00010000 adds: 00010000 dels: 00000000 index: 4 noop?: False precs: 10110000 adds: 11000000 dels: 10010000\nindex: 5 msk: 00000100 noop?: False precs: 01110000 adds: 00000011 dels: 01100000\nmsk: 00001000\nFact Spike Action Spike\nFact Level Packages (rank 0)\nAction Level Packages (rank 1 - as yet uninstantiated)\nname: on(a,t1) name: on(b,t2) name: clear(a) name: clear(b) name: puton(a,b,t1) name: puton(b,a,t2) FMV: 0...0 AV: 0...0 FMV: 0...0 AV: 0...0 FMV: 0...0 AV: 0...0 FMV: 0...0 AV: 0...0\nFigure 2: The spike after enactment of the rank 1 actions.96\nEfficient Implementation of the Plan Graph in STAN name: on(a,t1) index: 0 noop: 0 name: on(b,t2) index: 1 msk 01000000 noop: 1 name: clear(a) index: 2 msk 00100000 msk 10000000 noop: 2 name: clear(b) index: 3 msk 00010000 noop: 3 name: on(a,b) index: 4 msk 00001000 noop: name: clear(t1) index: 5 msk 00000100 noop: name: clear(t2) index: 6 msk 00000010 noop: name: on(b,a) index: 7 msk 00000001 noop: index: 0 msk: 10000000 noop?: True precs: 10000000 adds: 10000000 index: 1 msk: 01000000 noop?: True precs: 01000000 adds: 01000000 dels: 00000000 dels: 00000000 index: 2 msk: 00100000 noop?: True precs: 00100000 adds: 00100000 dels: 00000000 index: 3 msk: 00010000 noop?: True precs: 00010000 adds: 00010000 dels: 00000000 name: puton(a,b,t1) index: 4 noop?: False precs: 10110000 adds: 11000000 dels: 10010000\nname: puton(b,a,t2) index: 5 msk: 00000100 noop?: False precs: 01110000 adds: 00000011 dels: 01100000\nmsk: 00001000\nFMV: 0..0 AV: 0..0 FMV: 0..0 AV: 0..0 FMV: 0..0 AV: 0..0 00000100 01000000 00000011 00100000 00001000 00010000\n10000011 00001000 01000011 00001000 00100100 00000100 00101100 00000100\nFact Spike\nFact Level Packages (ranks 0 and 1)\nAction Spike\nMAs: 4\nAction Level Packages (rank 1)\nAMV: 00000100 MAs: 5 AMV: 00000100 MAs: 5 AMV: 00001000 AMV: 10010100 MAs: 0,3,5 AMV: 01101000 MAs: 1,2,4\nname: on(a,t1) name: on(b,t2) name: clear(a) name: clear(b) FMV: 0..0 00001000 AV: 0..0 10000000 AMV: 00001000 MAs: 4\nFigure 3: The spike at the end of the rank 1 construction phase.97\nEfficient Implementation of the Plan Graph in STANversion of Ipp because this is the most up to date version available from the Freiburgwebpage at the time of writing. In order to focus on the graph construction phase, andeliminate the search phase from both planners, we have constructed versions of Stan andIpp which terminate once the graph has opened. We have removed from Stan all of theunnecessary pre-processing, domain analysis and additional features that contribute to latersearch e ciency. However, since Ipp is designed to build one more layer before openingthan is strictly necessary, to include a dummy goal corresponding to the achievement of theconjunction of the top level goal set, we make Stan build one extra layer too so that thetwo systems are comparable. We have removed all of the meta-strategy control from Ipp,forcing Ipp directly into its graph construction. It is possible that a more streamlined graphconstructor could be built from Ipp by elimination of further processing, but we observed,during experimentation with Ipp, that pre-processing accounts for insigni cant proportionsof the timings reported below. We are therefore con dent that any further streamliningwould have minimal e ects on our results. In order to compare Stan and Ipp accurately itwas necessary to modify the timing mechanisms to ensure that precisely the same elementsare timed. A Unix/Linux di le is available at the Stan website, and in Online Appendix1, for anyone interested in reconstructing the Ipp graph construction system we have used.The domains and problems used, and our graph construction version of Stan, can also befound at these locations.All experiments reported in this paper were carried out on a P300 Linux PC, with128Mb of RAM and 128Mb swap space. All of the timings in the data sets reported are inmilliseconds.All the graphs are log-log scaled. This was necessary to combat the long scales caused byvery large timings associated with a few instances in each domain. The graphs show Ipp'sconstruction performance compared with Stan's construction performance measured on thesame problems in each of six domains. The straight line shows where equal performancewould be. Points above the line indicate superior performance by Stan and points belowthe line indicate superior performance by Ipp. In all of the rst ve data sets, Stan clearlyout-performs Ipp. In the last data set (Figure 9), Ipp convincingly out-performs Stan andwe now consider a more detailed analysis of the characteristics of the domains and instanceswhich explain these data sets.The rst four data sets reveal a very similar performance. The points are broadly par-allel to the equal performance line, indicating that Stan performs at a constant multipleof the performance of Ipp. Despite the trend that these data sets reveal, occasional datapoints deviate signi cantly from this behaviour. This re ects the fact that di erent struc-tures of particular problems exercise di erent components of the graph construction system.Components include instantiation of operators, application of individual operator instancesand the corresponding extension of fact layers and checking and re-checking mutex relationsbetween facts and between actions. We observed that in some problem instances, 50 percent or more of the construction time was spent in action mutex checking, whilst in othersinstantiation dominated. The density of permanent mutex relations between actions, andthe degree of persistence of temporary mutex relations between actions, are both very sig-ni cant in determining e ciency of performance. For example in problem 8 in the Mysterydomain, where 21 layers are constructed before the graph opens, only 9 per cent of theaction pairs were discarded as permanently mutex and, of the temporary mutex pairs, the99\nEfficient Implementation of the Plan Graph in STAN 110 1001000 1 10 100 1000IPP STAN3 3\n3 3333333 Figure 8: Graph construction in the Ferry domain. Stan shows polynomially better graphconstruction performance than Ipp.average number of re-tests across the entire graph construction was over 7. The use ofthe changedActs mechanism described in Section 2.1, to avoid retesting actions when theirprecondition mutex relations had not changed from the previous layer, gave us a 50 percent improvement in performance and accounts for a more than 40 second advantage overIpp in the construction phase of this problem.In other problems a much higher percentage of action pairs are permanently mutex,allowing early elimination of many action pairs from further retesting. Where mutex re-lations are not highly persistent a similar elimination rate is possible. This allows muchfaster construction for Stan. Ipp does not bene t in the same way, because it does notdistinguish between temporary and permanent mutex and does not try to identify whichpairs of actions should be retested.In the Ferry domain, Figure 8, 7 layers are constructed to open the graph regardlessof instance size. Analysis reveals that approximately 25 per cent of action pairs are per-manently mutex and the average persistence of temporary mutex relations is slightly morethan 2 layers. Since Ipp does not intelligently eliminate actions from retesting, the implica-tion of this is that Ipp unnecessarily re-checks mutex relations for a polynomially increasingnumber of pairs of actions. This explains the polynomial advantage obtained by Stan inthis domain.The last data set shows a rather di erent pattern of performance from that of theothers. The Complete-Graph Travelling Salesman domain used to produce the data set forFigure 9 is a simpli ed version, in which the graph is fully connected, of the well known101\nLong & Fox 10100 1000 10 100 1000IPP STAN3 3 3 3\n3 3 Figure 9: Graph construction in the Complete-Graph Travelling Salesman domain. Standisplays a polynomially deteriorating graph construction performance. This isfurther discussed in the text.NP-hard TSP. It is, in principle, e ciently solvable. In Figure 9 Ipp's performance appearsto be polynomially better than that of Stan. Analysis of the graph structure built fordi erent instances reveals that, on all instance sizes, the graph opens at layer 3. In thesegraphs an interesting pattern can be observed in the mutex relations between actions: thevast majority of action pairs are mutex after their rst application at layer 2 (because thesalesman can only ever be in one place). These mutex relations are considered, by bothStan and Ipp, to be temporary although they in fact persist. The consequence is that bothStan and Ipp retest all pairs at the next layer. Stan obtains no advantage from the use ofchangedActs or the distinction between temporary and permanent mutex relations in thisdomain. The number of mutex pairs to be checked increases quadratically with increasein instance size, which is in line with Stan's performance. Ipp clearly pays much less forthis retesting, despite the fact that it does the same amount of work. This fact, togetherwith pro ling of both systems, leads us to believe that the disadvantage su ered by Stan isdue to the overhead in supporting object member applications in its C++ implementation.It is worth pointing out that in the Complete-Graph Travelling Salesman domain, as wellas in Gripper and Ferry, the construction time for both planners is under 1 second for allinstances tested so the discrepancies in performance in these three domains are insigni cantcompared with the discrepancies measured in seconds (for large instances) in the otherdomains. 102\nEfficient Implementation of the Plan Graph in STAN Fix Point Buffer\nG1 G2 G3 G4 G5\nG G1\nG2Figure 10: The wave front in Stan.4. The Wave FrontWhen a layer is reached in which all of the top level goals are pairwise non-mutex Graphplan-based planners begin searching for a plan. If no plan can be found, new layers are con-structed alternately with search until the x point of the graph is reached. In Graphplanand Ipp the graph continues to be explicitly constructed beyond the x point, even thoughthe layers which can be built beyond this point are sterile (contain no new facts, actions ormutex relations). Their construction is necessary to allow the conditions for achievement ofgoal sets to be established, between the x point and the current layer. However, this con-stitutes signi cant computational e ort in copying existing structures and in unnecessarysearching of these duplicate structures. Instead of building these sterile layers explicitly,Stan maintains a single layer, called the bu er, beyond the x point together with a queueof goal sets remaining to be considered. Each time a goal set is removed from this queue,to be considered in the bu er, those goal sets it generates in the x point layer, which have103\nLong & Foxnot been previously marked as unsolvable, are added to the queue. The goal sets in thisqueue are considered in order, always for achievement in the bu er layer. Thus, ratherthan constructing a new layer each time the top level goal set proves unsolvable, and thenreconsidering all of the same achievers in the new layer, the goal sets in the queue are simplyconsidered in the bu er layer. We call this mechanism a wave front because it pushes goalsets forward from the x point layer into the bu er, and then recedes to consider anothergoal set from the x point layer. The goal sets generated at the x point, which join thequeue for propagation, are referred to as candidate goal sets. The wave front is depicted inFigure 10. The underlying implementation of the plan graph remains based on the spike,but the gure depicts the graph in the traditional way for simplicity.In the picture, G represents the top level goal set and when it is used to initiate a plansearch from the bu er layer it generates the sequence of goal sets G1, G2 and G3 at the x point layer. Assuming that these all fail, the rst set in this queue, G1, is propagatedforward to the bu er leading to the generation of goal sets G4 and G5 in the x point layer.These are added to the end of the queue and G2 will be the next goal set selected from thequeue to propagate forward.In order to demonstrate that the wave front machinery maintains an appropriate be-haviour there are three questions to be considered.1. Is every goal set that would have been considered in the bu er layer, had the graphbeen constructed explicitly, still considered using the wave front? This question con-cerns completeness of the search process.2. Does every plan generated to achieve a goal set that is considered in the bu er layercorrespond to a plan that would have been generated had the graph been explicitlyconstructed? This question concerns soundness.3. The nal question concerns whether the termination properties of Graphplan aremaintained.De nition 12 A k-level goal tree for goal set G at layer n in a plan graph, GTk;G;n, is ageneral tree of depth k in which the nodes are goal sets and the parent-child relationship isde ned as follows. If the goal set x is in the tree at level i then the goal set y is a child ofx if y is a minimal goal set containing no mutex goal pairs such that achievement of y atlayer n i 1 in the plan graph enables the achievement of x at layer n i in that graph.We take the root to be at level 0 of the tree and the leaves to be at level k 1.Lemma 1 If n k FP then GTk;G;n = GTk;G;n+1, where FP is the number of the xpoint layer in the plan graph.Proof By de nition of the x point, all layers in a plan graph beyond the x point containan exact replica of the information contained at the x point layer. Since, by de nitionof the goal tree, the parent-child relationship depends exclusively upon the relationshipbetween two consective layers in the plan graph, and layers cannot change after the xpoint, it follows that if x is the parent of y at some layer beyond the x point then theparent-child relationship between x and y must hold at any pair of consecutive layers beyondthe x point. Further, no new parent-child relationships can arise beyond the x point. The104\nEfficient Implementation of the Plan Graph in STANrestriction that n k FP ensures that all layers in both goal trees lie in the region beyondthe x point. 2The completeness of Stan follows from the completeness of Graphplan provided thatall of the goal sets that would appear in the layer after the x point in the explicit grapharise as candidates to be considered in the bu er layer using the wave front. We now provethat this condition is satis ed by rst proving that the leaves of goal trees generated atsuccessive layers of a plan graph are all used to generate candidates in Stan. Since the goalsets considered by Graphplan are always subsets of the leaves of goal trees it will be shownthat the completeness of Stan follows.Theorem 1 Given a goal set, G, and a plan graph of n layers, containing no plan for Gof length n 1, with x point at layer FP (n > FP ), all of the leaves of GTn FP;G;n aregenerated as candidates by Stan.Proof The proof is by induction on n, with base case n = FP + 1. In the base case theresult follows trivially because the only leaf in GT1;G;FP+1 is the top level goal set G andthis is generated as the initial candidate by Stan.Suppose n > FP + 1. The inductive hypothesis states that all of the leaves of the treeGTn 1 FP;G;n 1 are generated as candidates by Stan. Since the plan graph constructed byStan is identical to that of Graphplan up to layer FP + 1, and all candidates are used toinitiate search from layer FP +1, the leaves of GTn FP;G;n 1 will also be generated as goalsets in layer FP by Stan. These goal sets are then used by Stan to construct candidates.Stan will not generate multiple copies of candidates, but each new goal set will generate anew candidate.By Lemma 1, GTn FP;G;n = GTn FP;G;n 1 , so that the leaves of GTn FP;G;n are gener-ated as candidates by Stan. 2The de nition of goal trees captures precisely the relationship between goal sets andthe search paths considered by Graphplan. However, because Graphplan memoizes failedgoal sets it can prune parts of a goal tree as it regresses through the explicit plan graphduring search. Whenever a goal set contains a memoized goal set search terminates alongthis branch and none of its children will be generated. It can now be seen that Graphplanwill generate at layer FP + 1 a subset of the leaves of GTn FP;G;n , when searching fromlayer n with goal set G, whereas Theorem 1 demonstrates that Stan will construct all ofthese leaves as candidates.This argument might suggest that Stan engages in unnecessary search by generatingcandidates that Graphplan can prune, using memos, in layers that are not constructedexplicitly by Stan. In fact, Stan generates no more candidates than Graphplan generatesgoal sets at layer FP+1. Indeed, Stan achieves a dramatic reduction in search by exploitingthe correspondence between the goal trees generated at layers n and n 1, demonstrated byLemma 1. Because of this correspondence there is no need to construct the layers betweenFP + 1 and n explicitly, and undertake all of the concommitant search from those layers.105\nLong & Fox G\nLn\nL2\nL1\nG3\nG2\nG1\nG\nLn\nL2\nL1\nG3\nG2\nG1\nLayer 0 FP FP+1 n-1 n\nFigure 11: The sliding window of layers between FP + 1 and n.Graphplan rebuilds the sliding window, shown in Figure 11, of layers between FP and n 1as layers FP + 1 through to n. Stan simply promotes the leaves of the tree, generated atlayer FP in GTn FP;G;n 1 , into layer FP + 1.It is straightforward to show that the wave front maintains soundness. The search thatGraphplan performs generates a goal tree of goal sets, as de ned in De nition 12. In theexample in Figure 10, the tree is rooted at G, with G1, G2 and G3 its children and G4 andG5 the children of G1. It can be seen from the picture that the tree structure generatedby Graphplan, in which each successive layer would be embedded in a separate layer of theexplicitly constructed graph, appears in a spiral of related goal sets between the x pointand bu er layers. All of the candidate goal sets lie in this same search tree and therefore noadditional goal sets are generated. Graphplan constructs the nal plan by reading o thesequence of action choices at each layer in the nal graph. In Stan, the plan is obtainedby reading o the initial fragment of the plan in the same way, from the layers precedingthe x point. The rest of the plan is extracted from the spiral. This extraction processyields the same path of action choices from the top level goal set to the candidate goal setas would be recorded explicitly in the Graphplan plan graph.The only question remaining to be considered is whether the wave front has the sametermination properties as Graphplan. It can be seen that it does since, if no new unsolvablegoal sets are generated at the x point, the queue will become empty and the plannerterminates. This corresponds exactly to the termination conditions of Graphplan.A subtlety concerns the interaction between the wave front and the subset memoizationdiscussed in Section 2.2. In principle, subset memoization could cause the loss of all three ofthe desired properties of the graph. The way that Stan generates candidate goal sets is by106\nEfficient Implementation of the Plan Graph in STANsimultaneously generating a candidate set whenever a goal set is memoized at the x point.If the candidate set and the memoized set are one and the same, then the memoization ofa subset of a goal set will lead to the propagation of only a subset of the actual candidategoals into the bu er and soundness might be undermined. If we use subset memoization atthe wave front then the question arises whether sets that contain a memoized subset shouldbe propagated forward as candidates. If they are not, then completeness is potentiallylost, since there might be action sequences that could have been constructed followingpropagation that will not now be found. If they are, then termination is potentially lost,since the set that led to the construction of the memoized subset might itself be generatedas a candidate. This could happen, for example in Figure 10, if G1 is unsolvable at the xpoint but is generated again by consideration of a later candidate at the bu er.To avoid these problems we have restored full subset memoization at the wave front.An alternative solution, which we are currently exploring, is to separate the subsets ofgoals memoized from the identi cation of the candidate sets. Both solutions avoid the lossof soundness because candidates are constructed from entire goal sets rather than fromsubsets. In the rst solution, termination is preserved because memoizing full goal setsensures that repeated candidates can be correctly identi ed as they recur. In the secondsolution, we would separately memoize candidates as they were generated to avoid repeatedgeneration, thereby maintaining termination. In both cases, completeness is preserved bypropagating goal-sets forward as new candidates provided only that they do not containpreviously encountered candidates as subsets. If a potential candidate is a superset of anentire memoized candidate then it is correct not to propagate that potential candidate intothe bu er because if the memoized candidate cannot be solved at the bu er then no supersetof it can be solved there either.5. Experimental ResultsThe results presented here use Stan version 2 (available at our website). We have performedexperiments comparing Stan with and without the wavefront in order to demonstrate theadvantages obtained by the use of the wave front. We have performed further experimentsto compare Stan with the competition version of Ipp. There are some minor discrepanciesin the timing mechanisms of these two systems. Stan measures elapsed time for the entireexecution, whereas Ipp measures user+system time for graph construction and search butnot for parsing of the problem domain and instance. On a single user machine as used forthese experiments the discrepancy is negligible.The problem domains used in this section have been selected to emphasise the bene tso ered by the wave front. The important characteristic is that there should be an early x point relative to the length of plan as instances grow. In the comparisons with Ipp thewave front accounts for the trends in performance, although Stan employs a range of othermechanisms which give it some minor advantages. Amongst these is the Tim machinery,which we have not decoupled as the problem domains used are the standard typed onesso that no signi cant advantage is obtained from inferring type structures automatically.Only the resource invariants inferred by Tim are exploited by Stan version 2, and wehave indicated where this gives us an advantage over Ipp. Our ablation data sets con rm107\nLong & Fox 101001000 10000100000 10 100 1000 10000IPP STAN3 3 3\n3 3 Figure 12: Stan compared with Ipp: solving Towers of Hanoi problems of 3-7 discs.that the wave front is the most signi cant component in the performance of Stan in theseexperiments.Stan is capable of e ciently solving larger Towers of Hanoi instances than are presentedin the graph in Figure 12, which accounts for the additional point in Figure 13. Stan withthe wave front found the 511-step plan for the 9-disc problem in less than 7 minutes usingabout 15Mb of memory. During the experiments reported here, Ipp was terminated after15 minutes having reached layer 179 out of 255 layers in the 8-disc problem. We observethat on a machine with 1Gb of RAM, Ipp has solved this problem in 8 minutes.The results for the Gripper domain demonstrate only a small advantage for Stan. Thereason is because the search space grows exponentially in the size of the graph in the Gripperdomain, so that the cost of searching dominates everything else. Although the search spacesfor Towers of Hanoi instances also grow exponentially, they grow as 2x whereas Gripperinstances grow as xx (where x is the number of discs or balls respectively). Although thewave front helps under these conditions, the size of the search space dwarfs the bene ts ito ers. The Ferry domain is a less rapidly growing version of the gripper domain since onlyone vehicle can be carried on each journey, reducing the number of choices at each layer.The di erence in bene ts obtained in the Towers of Hanoi domain relative to the Gripperand Ferry domains can be explained by consideration of the table in Figure 16. The bene tsof the wave front are proportional to the number of layers which exist implicitly betweenthe bu er and the layer from which the plan is ultimately found. In the Towers of Hanoithe number of implicit layers is exponential in the number of discs whereas the number oflayers between the initial layer and the bu er is linear in the number of discs. Thereforethe bene ts o ered by the use of the wave front are magni ed exponentially as the problem108\nLong & Fox 10100100010000 1000001e+06 10 100 1000 10000 100000 1e+06STAN no wf STAN wf3 3\n3 3 Figure 15: Stan with and without the wave front: solving Gripper problems of 4-10 balls.Domain Parameter n Plan Length Bu erTowers of Hanoi no. discs 2n 1 n + 3Gripper no. balls 2n 1 5Ferry no. vehicles 4n 1 7Complete-Graph TSP no. cities n 4Figure 16: Relative values of plan length and number of layers to bu er for four domains.instance grows. On the other hand, in both Gripper and Ferry there is only a linear growthin the di erence between plan length and x point layer, so bene ts are magni ed onlylinearly. This analysis can be con rmed by observation of Figures 12, 14 and 17.The bene t of the wave front is measured not only in terms of the cost of constructionthat is avoided by not explicitly building the layers beyond the bu er, but also in termsof the search that is avoided in those layers. Crudely, the bene ts can be measured asthe number of layers not constructed multiplied by the search e ort avoided at each ofthose layers. Thus, the number of layers not constructed magni es the bene ts obtainedby not searching amongst them. This is a simpli cation, since the search e ort avoided atsuccessive layers increases as they get further away from the x point, but it gives a guideto the kind of bene ts that can be expected from the wave front.Stan obtains signi cant advantages over Ipp in the Complete-Graph Travelling Sales-man domain, as Figure 19 demonstrates. Some of these advantages are obtained by ex-110\nLong & Fox 1001000100001000001e+061e+07 1e+081e+091e+10 100 1000 10000IPP STAN3 3 3\n3 3 3 Figure 19: Stan compared with Ipp: solving Complete-Graph Travelling Salesman prob-lems of 10-20 cities.ploiting the resource analysis techniques of Tim (Fox & Long, 1998), whilst a signi cantproportion of the advantage is obtained from the use of the wave front, as Figure 20 shows.Resource analysis allows a lower bound to be determined on the number of layers that mustbe built in a plan graph before it is worth searching for a plan. In the Complete-GraphTravelling Salesman domain this is very powerful, as the calculated bound is n, the numberof cities in the instance, which is precisely the correct plan length. In this domain, if nosearch is done until n layers are constructed, no search needs to be done at all since itdoesn't matter in what order the cities are visited. This would allow the problem to besolved in polynomial time (of course, this only makes sense because the Complete-GraphTSP used here is simpler than the NP-hard TSP). However, when the wave front is used,the bu er is at layer 4 and the only way of nding the plan is to generate all of the candidategoal sets at layer 4, of which there are an exponential number. The use of the wave frontin this domain therefore forces Stan to take exponential time in the size of the instances.Despite this the wave front o ers great advantages. The bene ts increase exponentially asinstance sizes grow although the magni cation of these bene ts at each layer is only linear,see Figure 16, although the bene ts are o set by the exponential growth in the number ofcandidates. It must be observed that in Figure 19, the gures are extrapolated for Ipp forinstances in which n is greater than 14. The extrapolation was based on Ipp's performanceon instance sizes between 2 and 14, which demonstrates a clear exponential growth.It appears that we could allow the resource analysis to over-ride the wave front when adomain is encountered in which it can be guaranteed that explicit construction of the graph112\nEfficient Implementation of the Plan Graph in STAN 1001000 10000 100 1000 10000STAN no wf STAN with wf3 3 3\n3 3 3 Figure 20: Stan with and without the wave front: solving Complete-Graph TSP problems.will be more e cient. In practice the Complete-Graph Travelling Salesman domain seemsexceptional, since search is eliminated if the graph is constructed to layer n, and if this werenot the case the explicit construction and subsequent search would be more costly than theuse of the wave front.5.1 The Wave Front HeuristicThe queue of candidate goal sets considered in the bu er can be implemented as an un-ordered structure in which goal sets are selected for consideration according to more so-phisticated criteria than the order in which they were stored. In principle, this could savemuch searching e ort since it could avoid costly consideration of goal sets which turn out tobe unsolvable before meeting a solvable goal set. We have experimented with a number ofgoal set selection heuristics which favour goal sets for which the search progresses deepestinto the graph structure. These sets are considered to be closer to being solvable than setswhich fail in a layer very close to the bu er. Candidates are evaluated by considering thelength of the plan fragment associated with the candidate and the extent to which the failedsearch penetrated into the graph when initiated from the x point layer when the candidatewas rst generated. The search penetration should be maximized while the plan fragmentlength should be minimized. Considering the goal sets in some order other than that inwhich they are generated does not a ect any of the formal properties of the planner otherthan the optimality of the plans generated. Non-optimal plans can be favoured because113\nLong & Fox 100100010000 1000001e+06 100 1000 10000 100000 1e+06Stanh Stan33 3 3 3\n3 3 Figure 21: Towers of Hanoi with (Stanh) and without the heuristic: 3-9 discs.the balance between fragment length and penetration can cause candidates with shorterfragments to be overlooked.Using the heuristic Stan is able to solve Towers of Hanoi problems very e ciently, asFigure 21 shows. As previously, the graph is log-log scaled. The line indicates at least apolynomial improvement in the size of instances. The heuristic was originally developed byconsideration of blocks world problems, in which it also performs well. However, it does notprovide a reliable advantage so it is not used in Stan version 2. It was used on all problemsin the competition but often represented a heavy overhead for Stan. We are continuing toexperiment with alternative domain-independent evaluation criteria.6. ConclusionThis paper presents two improvements on the representation of the plan graph exploited byGraphplan-based planners. These are: the representation of the graph as a single pair oflayers, called a spike, built around bit vectors and logical operations, and the use of a wavefront which avoids the explicit construction of the graph beyond the x point. We describea highly e cient procedure for checking mutex relations between actions and explain whatcharacteristics of problems allow its full exploitation. The spike and the wave front haveboth been implemented in Stan, a Graphplan based planner version 11 of which competedsuccessfully in the AIPS-98 planning competition. We have presented empirical evidenceto support both improvements. The rst set of data demonstrates the increase in graph1. Version 1 contained implementations of both the spike and the wave front. Version 2 enhances bothof these mechanisms with improved implementation and the addition of the changedActs mechanismdiscussion in Section 2.1. 114\nEfficient Implementation of the Plan Graph in STANconstruction e ciency obtained by the use of the spike. The second set of data shows theadvantages obtained during the search of the plan graph by using the wave front.Stan also employs the state invariant inference machinery of Tim (Fox & Long, 1998),but in version 2 the integration of the invariants into the graph construction process isstill only partial. We observe that the mutex relations generated in the Complete-GraphTSP, in particular, are almost entirely domain invariants of the kind inferred by Tim.Integration of these inferred invariants into the graph would allow these mutex relationsto be identi ed immediately as permanent and eliminate them from retesting, dramaticallyenhancing Stan's graph construction performance in this domain. A similar advantagewould be obtained across other domains since many of the mutex relations inferred duringgraph construction correspond to invariants of the various forms inferred e ciently by Timduring a preprocessing stage.Appendix A. Website AddressesOnline Appendix 1 contains a complete collection of the domains and problems used in thispaper, executables (Linux and Sparc-Solaris binaries) for Stan and the reduced version ofStan for graph construction, and a di le showing how the graph constructing version ofIPP was generated.The results of the AIPS-98 planning competition can be found at:http://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.The Stan website can be found at:http://www.dur.ac.uk/ dcs0www/research/stanstuff/planpage.html.ReferencesBlum, A., & Furst, M. (1997). Fast Planning through Planning Graph Analysis. Arti cialIntelligence, 90, 281{300.Fox, M., & Long, D. (1998). The Automatic Inference of State Invariants in TIM. JAIR,9, 317{371.Kambhampati, S. (1998). EBL and DDB for Graphplan. Tech. rep. ASU CSE TR 98-008,Arizona State University.Kambhampati, S. (1999). On the Relations Between Intelligent Backtracking and Explana-tion Based Learning in Planning and CSP. Arti cial Intelligence, 105 (1-2).Koehler, J., Nebel, B., & Dimopoulos, Y. (1997). Extending Planning Graphs to an ADLSubset. In Proceedings of 4th European Conference on Planning.Smith, D., & Weld, D. (1998). Incremental Graphplan. Tech. rep. TR 98-09-06, Universityof Washington. 115"
    } ],
    "references" : [ {
      "title" : "Fast Planning through Planning Graph Analysis",
      "author" : [ "A. Blum", "M. Furst" ],
      "venue" : null,
      "citeRegEx" : "Blum and Furst,? \\Q1997\\E",
      "shortCiteRegEx" : "Blum and Furst",
      "year" : 1997
    }, {
      "title" : "The Automatic Inference of State Invariants in TIM",
      "author" : [ "M. Fox", "D. Long" ],
      "venue" : null,
      "citeRegEx" : "Fox and Long,? \\Q1998\\E",
      "shortCiteRegEx" : "Fox and Long",
      "year" : 1998
    }, {
      "title" : "EBL and DDB for Graphplan",
      "author" : [ "S. Kambhampati" ],
      "venue" : "Tech. rep. ASU CSE TR 98-008,",
      "citeRegEx" : "Kambhampati,? \\Q1998\\E",
      "shortCiteRegEx" : "Kambhampati",
      "year" : 1998
    }, {
      "title" : "On the Relations Between Intelligent Backtracking and Explana",
      "author" : [ "S. Kambhampati" ],
      "venue" : null,
      "citeRegEx" : "Kambhampati,? \\Q1999\\E",
      "shortCiteRegEx" : "Kambhampati",
      "year" : 1999
    }, {
      "title" : "Extending Planning Graphs to an ADL",
      "author" : [ "J. Koehler", "B. Nebel", "Y. Dimopoulos" ],
      "venue" : null,
      "citeRegEx" : "Koehler et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Koehler et al\\.",
      "year" : 1997
    }, {
      "title" : "Incremental Graphplan",
      "author" : [ "D. Smith", "D. Weld" ],
      "venue" : "Tech. rep. TR 98-09-06,",
      "citeRegEx" : "Smith and Weld,? \\Q1998\\E",
      "shortCiteRegEx" : "Smith and Weld",
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Its name is derived from the fact that it performs a number of preprocessing analyses, or STate ANalyses, on the domain before planning, using the Type Inference Module Tim described by Fox and Long (1998). Stan competed in the AIPS-98 planning competition and achieved an excellent overall performance in both rounds.",
      "startOffset" : 186,
      "endOffset" : 206
    }, {
      "referenceID" : 0,
      "context" : "The second is the x point, referred to as level o by Blum and Furst (1997), the layer after which no further changes can be made to either the action, fact or mutex information recorded in the graph at each layer.",
      "startOffset" : 53,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "The observations leading to this compressed implementation of the plan graph were made independently by Smith and Weld (1998). In Stan, a fact rank is a consecutive sequence of fact headers storing the layerindependent information associated with their associated facts in the corresponding fact layer.",
      "startOffset" : 104,
      "endOffset" : 126
    } ],
    "year" : 2011,
    "abstractText" : null,
    "creator" : "dvips 5.58 Copyright 1986, 1994 Radical Eye Software"
  }
}