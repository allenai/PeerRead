{
  "name" : "1206.5249.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Probabilistic Relational Dynamics for Multiple Tasks",
    "authors" : [ "Ashwin Deshpande", "Brian Milch" ],
    "emails" : [ "ashwind@mit.edu", "milch@csail.mit.edu", "lsz@csail.mit.edu", "lpk@csail.mit.edu" ],
    "sections" : null,
    "references" : [ {
      "title" : "A Bayesian/information theoretic model of learning to learn via multiple task sampling",
      "author" : [ "J. Baxter" ],
      "venue" : "Machine Learning, 28:7–39",
      "citeRegEx" : "Baxter. 1997",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Probabilistic planning in the Graphplan framework",
      "author" : [ "A.L. Blum", "J.C. Langford" ],
      "venue" : "Proc. 5th European Conference on Planning",
      "citeRegEx" : "Blum and Langford. 1999",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Learning probabilistic relational dynamics for multiple tasks",
      "author" : [ "A. Deshpande" ],
      "venue" : "Master’s thesis, Massachusets Institute of Technology",
      "citeRegEx" : "Deshpande. 2007",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "An algorithm for probabilistic planning",
      "author" : [ "N. Kushmerick", "S. Hanks", "D.S. Weld" ],
      "venue" : "Artificial Intelligence, 76:239–286",
      "citeRegEx" : "Kushmerick et al.. 1995",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "The estimation of many parameters",
      "author" : [ "D.V. Lindley" ],
      "venue" : "V. P. Godambe and D. A. Sprott, editors, Foundations of Statistical Inference. Holt, Rinehart and Winston, Toronto",
      "citeRegEx" : "Lindley. 1971",
      "shortCiteRegEx" : null,
      "year" : 1971
    }, {
      "title" : "Transfer learning with an ensemble of background tasks",
      "author" : [ "Z. Marx", "M.T. Rosenstein", "L.P. Kaelbling", "T.G. Dietterich" ],
      "venue" : "NIPS Workshop on Inductive Transfer",
      "citeRegEx" : "Marx et al.. 2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Estimating a Dirichlet distribution",
      "author" : [ "T.P. Minka" ],
      "venue" : "Available at http://research.microsoft.com/ ∼minka/papers/dirichlet",
      "citeRegEx" : "Minka. 2003",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Learning probabilistic relational planning rules",
      "author" : [ "H.M. Pasula", "L.S. Zettlemoyer", "L.P. Kaelbling" ],
      "venue" : "Proc. 14th International Conference on Automated Planning and Scheduling",
      "citeRegEx" : "Pasula et al.. 2004",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Learning Gaussian processes from multiple tasks",
      "author" : [ "K. Yu", "V. Tresp", "A. Schwaighofer" ],
      "venue" : "Proc. 22nd International Conference on Machine Learning",
      "citeRegEx" : "Yu et al.. 2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Learning planning rules in noisy stochastic worlds",
      "author" : [ "L.S. Zettlemoyer", "H.M. Pasula", "L.P. Kaelbling" ],
      "venue" : "Proc. 20th National Conference on Artificial Intelligence",
      "citeRegEx" : "Zettlemoyer et al.. 2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Learning multiple related tasks using latent independent component analysis",
      "author" : [ "J. Zhang", "Z. Ghahramani", "Y. Yang" ],
      "venue" : "Advances in Neural Information Processing Systems 18. MIT Press",
      "citeRegEx" : "Zhang et al.. 2006",
      "shortCiteRegEx" : null,
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Such knowledge can be encoded compactly as a set of probabilistic planning rules [Kushmerick et al., 1995; Blum and Langford, 1999].",
      "startOffset" : 81,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "Such knowledge can be encoded compactly as a set of probabilistic planning rules [Kushmerick et al., 1995; Blum and Langford, 1999].",
      "startOffset" : 81,
      "endOffset" : 131
    }, {
      "referenceID" : 7,
      "context" : "Algorithms have been developed for learning relational probabilistic planning rules by observing the effects of actions [Pasula et al., 2004; Zettlemoyer et al., 2005].",
      "startOffset" : 120,
      "endOffset" : 167
    }, {
      "referenceID" : 9,
      "context" : "Algorithms have been developed for learning relational probabilistic planning rules by observing the effects of actions [Pasula et al., 2004; Zettlemoyer et al., 2005].",
      "startOffset" : 120,
      "endOffset" : 167
    }, {
      "referenceID" : 4,
      "context" : "In statistics, the problem of transferring predictions across related data sets has been addressed with hierarchical Bayesian models [Lindley, 1971].",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 8,
      "context" : "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].",
      "startOffset" : 148,
      "endOffset" : 204
    }, {
      "referenceID" : 5,
      "context" : "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].",
      "startOffset" : 148,
      "endOffset" : 204
    }, {
      "referenceID" : 10,
      "context" : "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].",
      "startOffset" : 148,
      "endOffset" : 204
    }, {
      "referenceID" : 9,
      "context" : "In this section, we present a simplified version of the representation developed by [Zettlemoyer et al., 2005].",
      "startOffset" : 84,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "Noise outcomes allow rule learners to ignore overly complex, rare action effects and have been shown to improve learning in noisy domains [Zettlemoyer et al., 2005].",
      "startOffset" : 138,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "Integrating out the outcome probabilities p in each rule is not a computational bottleneck: we can push the integral inside the sums over a and b, and use a modified version of a standard estimation technique [Minka, 2003] for the Polya (or Dirichlet-multinomial) parameters.",
      "startOffset" : 209,
      "endOffset" : 222
    }, {
      "referenceID" : 9,
      "context" : "Rules can be created by an ExplainExamples procedure [Zettlemoyer et al., 2005] which uses a heuristic search to find high quality potential rules in a data driven manner.",
      "startOffset" : 53,
      "endOffset" : 79
    }, {
      "referenceID" : 7,
      "context" : "This algorithm is a modified version of a previous outcome search procedure [Pasula et al., 2004], which has been changed to ensure that the outcomes do not overlap.",
      "startOffset" : 76,
      "endOffset" : 97
    }, {
      "referenceID" : 7,
      "context" : "Possible additions include any outcomes from the corresponding prototype rule or an outcome derived from concatenating the changes seen as a result of action effects in a training example (following [Pasula et al., 2004]).",
      "startOffset" : 199,
      "endOffset" : 220
    }, {
      "referenceID" : 6,
      "context" : "Estimating the Dirichlet parameters for the Polya distribution does not have a closed form solution, but gradient ascent techniques have been developed for the maximum likelihood solution [Minka, 2003].",
      "startOffset" : 188,
      "endOffset" : 201
    }, {
      "referenceID" : 3,
      "context" : "To see how transfer learning works for more complex rule sets, our next experiment uses a “slippery gripper” domain adapted from [Kushmerick et al., 1995].",
      "startOffset" : 129,
      "endOffset" : 154
    } ],
    "year" : 2009,
    "abstractText" : "The ways in which an agent’s actions affect the world can often be modeled compactly using a set of relational probabilistic planning rules. This paper addresses the problem of learning such rule sets for multiple related tasks. We take a hierarchical Bayesian approach, in which the system learns a prior distribution over rule sets. We present a class of prior distributions parameterized by a rule set prototype that is stochastically modified to produce a task-specific rule set. We also describe a coordinate ascent algorithm that iteratively optimizes the task-specific rule sets and the prior distribution. Experiments using this algorithm show that transferring information from related tasks significantly reduces the amount of training data required to predict action effects in blocks-world domains.",
    "creator" : "Adobe InDesign CS2 (4.0.4)"
  }
}