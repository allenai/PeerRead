{
  "name" : "1302.4984.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Modeling failure priors and persistence in model-based diagnosis",
    "authors" : [ "Sampath Srinivas" ],
    "emails" : [ "srinivas@cs.stanford.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION\nModel-based diagnosis computes the set of possible explanations consistent with a physical system's ob served behavior [Hamscher et a/, 1 992]. A system con sists of a set of interconnected components. Each com ponent has a mode associated with it. The mode is a state variable which takes one of a fixed number of values. In the simplest case, the mode variable may take two states, ok and broken. The ok state de notes a mode where the component is working as it should while the broken state denotes a mode where the component is behaving abnormally. We have avail-\nable some (partial) characterization of the the compo nents input-output behavior. That is, given the state of the mode variable of the component and an input value we have some information about what the out put might be. In the general case, this information amounts to specifying a set of possible values of the output for each mode-input combination. These com ponent characterizations and the interconnections of the components constitute the behavior model of the system.\nAn observation consists of a set of variable-value pairs. Usually, the observation consists of the values of the input variables of the system and the values of some of the intermediate and output variables of the sys tem. A candidate is an assignment of a state to each of the system's mode variables. So for example, say a simple system has two components A and B, with corresponding mode variables MA and MB. Each of the mode variables can take two states, ok and broken. For this system, one possible candidate is (MA = ok, MB =broken).\nThe process of diagnosis consists of computing the set of candidates which are consistent with the observa tion and model. One drawback of strictly logical ap proaches to diagnosis is that there is no notion of plau sibility. For non-trivial systems, the set of consistent candidates can be very large. A mechanism to order the candidates by likelihood is required.\nProbabilistic model-based diagnosis introduces a prior distribution over each component's mode variable. Each component's failure is assumed independent of the failure of other components. For example, the com ponent A might have the prior P(MA = ok) = 0.995 and P(MA =broken) = 0.005. The diagnosis prob lem is now defined as computing a posterior proba bility distribution over the set of possible candidates. Let C be a state variable which ranges over all possi ble candidates and n be an observation. The diagnosis problem now amounts to computing P(CIO) [Geffner & Pearl, 1987; DeKleer & Williams, 1989; Poole, 1991; Srinivas, 1994].\nOne of the drawbacks of probabilistic diagnosis is that the specification of the prior probabilities of failures of\nthe components is difficult. The probabilities are not usually directly available from an expert. One of the reasons for this is that there is an implicit notion of time in the prior. For example, say a system has been running for a week at the time of diagnosis. Say we assess the prior probability of failure of a component A at the time we carry out our diagnosis and find that P(MA =broken)= p1. Now say the system has been running for a month and we assess P(MA =broken) again. Intuitively, the probability in the latter case should be different than p1. Furthermore, it should be larger - the longer the component has been on-line the higher the chances that it has failed.\nA related problem occurs when doing diagnosis with multiple observations, where each observation occurs at a different time. When performing diagnosis with multiple observations we need some model of the per sistence of the state of the system between the observa tions. For example. say we have an observation D[tl] at time t1 and an observation D[t2] at time t2. Let the candidate state variable at time t1 be C[t1] and that at time t2 be C[t2]. We will use c[t1] and c[t2] to denote states of C[tl] and C[t2]. The goal of diagnosis is to compute the distribution P(C(t2] I D[it], D[t2]). This distribution can be computed as:\nP(C[t2] = c[t2] I D[t1], D[t2]) oc P( C[t2] = c[t2], D[tl], D[t2])\noc P(D[t2] I C[t2] = c[t2], n[tl]) X P( C[t2] = C[t2] I D[tl]) P(D[t2] I C[t2] = c[t2]) xP(C[t2] = c[t2] I D[tl]) (1)\nThe last step follows because knowing the state C[t2] of the system renders the observation n[t2] indepen dent of the history. The probability P(D[t2] I C[t2] = c[t2]) can be calculated from the system model. In the above equation we also need the distribution P(C[t2] I D[t1]), i.e., an estimate of the state at time t2 given the observation at time t1. This can be com puted as follows:\nP(C[t2] = c[t2] I D[td) =\n�e[t,]P( C[t2] = c[t2] I C[t1] = c[t1], D[t1])\nx P( C[t1] = c[t1] I D[t1]) = �e[t,]P(C[h] = c[t2] I C[it] = c[tl])\nx P( C[h] = c[h] I D[h]) (2)\nThe last step follows from a Markov assumption that the system state C[t2] is rendered independent of all history upto time h when the state C[h] at time t1 is known. In the above equation, P( C[t1] I D[t1]) is the posterior over the state of the system at time t 1. This can be computed easily as:\nP(C[t1] = c[td I D[td) oc P(D[t1] I C[it] = c[tl]) x P(C[t1] = c[tl])\nThe first term in the RHS of the above equation can be computed from the system model. The second term\nis the prior probability of the candidate. This can be computed as a product from the prior distribution over the mode of the individual components.\nWe see that the distribution P( C[t2] I C[tl]) in Equa tion 2 is still unspecified. This distribution quantifies the persistence of the state of the system. For exam ple, if the system never changed state spontaneously then we would have: ( [ l [ l I [ l [ l { 1 if c[ft] = c[t2] P C t2 = c t2 C t1 = c t1 ) = 0 if c[tl] =F c[t2] However, a more practical situation would be one where components can fail on-line. If we had a model of how the components failed when they were on line, this could be used to compute the distribution P(C[t2] I C[t1]).\nIn this paper we address the problems of specifying failure priors and modeling persistence using tech niques from reliability theory. Reliability theory gives us a model that relates the probability of component failure and the age of the component. We use this model to compute the prior probability of failure from the uptime of component and the Mean Time Between Failure (MTBF) . The MTBF is a summary measure of the reliability of a device and is often available with manufacturer specifications. We also use the compo nent failure model to compute the conditional distri bution over the state of a component at time t2 given the state at time t1. This conditional distribution is used to model persistence.\n2 RELIABILITY MODELS\nReliability theory offers empirically validated models for the failure process of devices. The failure process of a device relates the probability of failure of the device to time (for example, see [Tsokos & Shimi, 1977]). We now describe one standard model of the failure process.\nConsider a device A. It has two states - ok and bro ken. It is initially in the ok state when it is brought on-line. At some point in time it transitions into the broken state. Once it is broken, it stays broken. It is assumed that the failure of A, i.e., the transition of A from the ok to broken state, occurs due to ran dom unmodeled events which occur with a probability that is constant over time. For example, an electronic component may fail due to surges in the power sup ply - these surges may occur randomly with a uniform probability.\nThe modeling assumption is interpreted as follows: Given that the device has not failed at time t, the conditional probability that it will fail in the inter val [t, t + dt] is proportional to the length of the in terval. The probability is thus given by >.dt where >. is a proportionality constant. Say we model the fail ure of A with a continuous real variable X. That is, \"X < t\" denotes the event that A fails in the interval [0, tf Say F(t) is the cumulative distribution of X,\ni.e., F(t) = P(O :::; X :::; t). F(t) is the probability that A fails in the time interval [0, t]. From the modeling assumption, we have:\nP(t < X :::; t + dt I X > t) F(t + dt) - F(t)\n1- F(t) dF(t)\ndt F(t)\n>.dt\n>.dt\n>. (1- F(t))\n1 -.Xt -e\n(3)\n(Since F(O) = 0)\nWe see that the probability of A failing before time t is small when t is small and converges to 1 as t tends to infinity.\nIn general, instead of assuming a constant >. in the equation above, we might have a time varying condi tional density c(t), called the hazard function. This allows us to model various different degradation phe nomena in the device. For example, if we want to model a situation where a component has high prob ability of failure early in its life (called \"wear in\" ) we might choose c(t) to be high for small values oft. If we want to model wear out (and hence, increased chance of failure) of the device as it grows older we might choose c(t) to be high as t becomes large (See Fig 1). The differential equation Equation 3 can be solved for the appropriate choice of hazard function to give the corresponding density function.\nThe expectation of the variable X is called the Mean Time between Failures. In the case of c(t) = >., the MTBF can be shown to be t.\n2.1 COMPUTING PRIOR PROBABILITIES OF FAILURE\nUsing the above model, we can specify more precisely what we mean by the prior distribution over the mode of a component A. The probability that A is broken is a function of time. We will denote this probability at time t by P(MA [t] = broken). Say that the last time we knew that A was certainly not broken was tok. Usually, tok is the time that A first went on-line.\nWe see that P(MA[t] = broken) is the probability that A failed in the interval [tok> t]. Say we assume a constant hazard function. We see that:\nP(MA =broken) P(tok <X :::; t I X > tok) F(t)- F(tok)\n1- F(tok) 1- e->-(t-tok) (4)\nThe above equation allows us to directly relate MTBFs to the prior probabilities that we need.\nNote that when we assume c(t) = >., P(MA = broken) is only a function of t - tok. That is, all we need to know is the length of the interval from the last time at which we were sure that A was not bro ken. However, if we assume more complicated hazard functions c(t), we would also need to know when A first went on-line. This is because we will measure t and tok using that as the start time. Hence in general, we will find that P(MA = broken) = f(t, tok) where f is some function whose form depends on the choice we make for the hazard function c(t).\n2.2 MODELING PERSISTENCE\nConsider the example outlined in Section 1. We saw there that some persistence model was necessary to compute P( C[t2] I C[h]). The reliability model de scribed above gives us a method to compute this dis tribution.\nSay the system has n components, C1, C2, ... , Cn. The mode variable corresponding to component C; is M;. We assume that the failure processes of the individual components are independent. Thus, given the state of C; at time h, we can compute a conditional probability distribution over the state at time t2 without regard to any of the other components. If we assume a constant hazard function >.; for C;, this distribution is given by Table 1.\nThe state c[t] of the variable C[t] consists of a state assignment to each of the mode variables M;. De noting the state of M; [t] by m; [t] we have c[t] = (Ml[t] = ml[t],M2[t] = m2[t], ... ,Mn[t] = mn[t]}. From the independence assumption of the failure pro cesses we have:\nP( C[t2] = c[t2] I C[tl] = c[tt]) = P(Mt [t2] = m1 [t2], ... , Mn [t2] = mn [t2] I\nMt[tt] = ml[t1], ... , Mn[tl] = mn[tt]) IT19:5nP(M;[t2] = m;[t2] I M;[tt] = m;[tl])\nEach of P(M;[t2] = m;[t2] I M;[tt] = m;[tt]) can be computed as shown in Table 1. Thus, the failure pro cesses of the individual components and an assump tion about their independence gives us a model for the persistence of the system state. The distribution P( C[t2] I C[tl]) can be computed using t2, t1 and the MTBFs of the individual components M;.\nWe illustrate the use of reliability models in model based diagnosis with some examples. We will first de scribe a system and a decision theoretic repair model for the system. We will then describe two different scenarios with this system.\nThe first scenario demonstrates how diagnosis/repair depends crucially on when an observation is made. The observation in this case is a \"nothing wrong\" ob servation. That is, the observation does not indicate any discrepancy. We show that if this observation was made when the system was new then the probability of everything being ok is very large (as we would ex pect) and the optimal decision is to do nothing (again, as we would expect). However, if the same observa tion is made instead when the system is older, the posterior probability that everything is ok decreases substantially. In this case, the optimal decision is to actually replace two of the components. This decision can be seen as an example of preventive maintenance.\nThe second scenario demonstrates the need for persis tence models in the presence of multiple observations and actions. We first make an observation at time t1. The corresponding best action is computed and exe cuted and is found to fix the anomaly exhibited by the system. Now, at a later time t2, the same anoma lous observation occurs. A persistence model for the component states is required to compute the posterior probabilities and the optimal decision after the second observation. Though the observation at time t2 and time t1 are the same, the posterior distribution and the optimal decision are very different.\n3.1 THE EXAMPLE SYSTEM\nConsider the digital circuit shown in Fig 2. A is an And gate, 0 is an Or gate and X is an Xor gate. Each of the gates can be ok or broken. When a gate is ok it works as it is supposed to. When it is broken we need a fault model. For the purposes of this ex ample we will assume that we have a fully specified fault model for each gate. Specifically, we will assume stuck-at-0 fault models for A and 0 and a stuck-at-1 fault model for X. That is, when A (or 0) is in the broken state the output of the gate is 0 irrespective of the input. Similarly, when X is broken, its output is 1 irrespective of the input. Say the MTBF of the And gate A is 100 hours, that of the Or gate 0 is 250\nFigure 2: The example circuit.\nWe also have a cost model that describes the repair costs of the system. We associate a repair decision with each component. The decision alternatives are fix and dont-fix. We describe the repair cost for each component with a cost function whose arguments are its mode state and the repair alternative. The cost functions for each of the gates is shown in Table 2. The system repair cost is assumed to be the sum of the repair costs of the components. That is, given a state for each mode variable of the system and a repair decision alternative for each component, we can sum the cost of the repair decision alternative for each component to get the repair cost function Ls for the entire system. The arguments to this cost function are a candidate (i.e., state assignment to each component of the system) and a composite decision. A composite decision consists of a choice of a repair alternative for each component in the system.\nThe cost function L for each component is quite in tuitively assessed. Consider the case where the com ponent A is ok and the decision is dont-fix. We use this as the reference situation and assign it a cost of $0. Hence LA(ok,dont-fix) = $0. When we do decide to fix, say that we throw the old component away and replace it with a new one irrespective of what its ac tual state is. The cost of implementing the fix decision summarizes the temporary downtime cost required to bring the system down to change the component and the cost of the new component. Say we determine this cost to be $2. Hence LA(broken,fix) = LA(ok,fix)\nFigure 3: Bayesian network for Scenario 1.\n= $2. Finally, we assign a cost to the case where the gate is broken but we choose dont-fix. This cost ba sically summarizes the cost of system downtime as a result of this non-operational component. Say we de termine the cost to be $10. Hence LA (broken,dont fix) = $10 . There is an implicit time horizon over which these costs are being measured- say it is 1 hour in this example.\nIn our framework, diagnosis involves computing the posterior distribution over the candidate state variable given observations. We will later see how these calcu lations can be made by translating the system model into a Bayesian network.\nRepair involves choosing the optimal composite deci sion for the entire system given the posterior distribu tion over the candidates. The optimal decision dopt is the one which results in the least expected cost. That IS:\ndopt = mind(L.cP(C = c lfl)Ls (D = d, C = c)) In this equation, d ranges over all possible composite decisions and c ranges over all possible candidates.\n3.2 SCENARIO 1: EFFECT OF TIME ON DIAGNOSIS/REPAIR\nConsider the system of Fig 2. Say that it has been been up for 10 hours and the observation n = (lr = 1, I2 = 1, I3 = 0, h = 0) is recorded. Note that n seems to suggest that there is no problem with the system since the inputs generate the expected output. We assume that the time is counted from the time the system was new. We will further assume that when the system was new every component was certainly ok.\nThe system model can be translated into a Bayesian network as shown in Fig 3 (see [Srinivas, 1994] for details). The node C has 8 states, one corresponding to each combination of states of MA, Mo and Mx. Let mA be a state of MA. We define mo and mx similarly. The conditional distribution of C given its parents is just a deterministic distribution which maps each state combination of its parents to the corresponding state\nof C. That is, we have P(C = (mA, mo, mx) MA = mA, Mo = mo, Mx = mx) = 1. We now perform diagnosis using the observation !l and the time of observation (viz, 10 hours). The prior probability of failure for each component is calculated on the basis of it being up for 10 hours. The evidence n is declared in the network (shown as grayed nodes) and then network inference is performed. We then look up the posterior distribution of C and compute the expected costs of the decisions. These are shown in Table 3. The results confirm our intuitions, viz, the most probable diagnosis is that nothing is wrong. The optimal decision is to not fix anything.\nConsider now a situation where, instead of 10 hours, the system was running for 90 hours when observation n was made. In this case, the prior probability of fail ure of each component is computed on the basis of it being up for 90 hours. We then do the diagnosis and compute the expected value of decisions for this situ ation. The posterior distributions and expected deci sion costs are shown in Table 4. In this situation, the most probable diagnosis is again that everything is ok, the same as when n was observed after 10 hours. How ever, the most probable diagnosis is much less proba ble. The optimal decision in this situation however, is to replace the And gate and Or gate. This is an exam ple of preventive maintenance. The expected costs of replacing now is lower than deferring the replacement. This is because the probability of failure is rising to a critical value.\n3.3 SCENARIO 2: MODELING PERSISTENCE\nSay the system of Fig 2 has been been up for time t1 = 20 hours and the observation !l[ii] = (11 = 0, 12 = 0, 1a = 0, Is = 1) is recorded. Note that !l[t1] indicates some problem with the system - if every thing was working correctly the output h would have value 0. Say we compute the posterior probabilities and the optimal decision. This computation is similar to that of the previous section. The posterior prob abilities and optimal decision are shown in Table 5. The optimal decision is to fix the XOR gate alone. Say we carry out this decision and then observe (im mediately) that the output 16 changes to 0. Thus, the observed discrepancy is fixed. Now say 20 hours more elapse and at time t2 = 40 hours, we observe !l[t2] = (11 = 0, 12 = 0, 1a = 0, 16 = 1) . Note that !l[tl] and !l[t2] have the same values for the input and output variables.\nThe situation is represented by the dynamic Bayesian network of Fig 4. The section of the figure within the boundary marked t1 represents the situation at time t1. The variable M� [td represents the state of the XOR gate immediately after it is replaced. Note that immediately after replacement we know that the gate is in the ok state. This is represented in the Bayesian\nnetwork as evidence (grayed node). The variable I�[tl] represents the output immediately after the replace ment action. As per our scenario, this variable is ob served to have value 0.\nThe section of Fig 4 within the boundary marked t2 represents the situation at time t2. The link between MA[t1] and MA[t2] represents the persistence of the state of the AND gate. We compute the distribution P(MA[t2]IMA[tl]) using Table 1. When using the ta ble, we set AA = MTkFA = 160 and t2 - t1 = 20. The conditional distributions P(Mo[t2]1Mo[ti]) and P(Mx[t2]1M�[tl]) and are computed similarly. The anomalous observation at time t2 is also entered as evidence in the Bayesian network (shown as grayed nodes).\nThe node C[t2] has 8 states each of which corresponds to one joint state of MA [t2], Mx [t2] and Mo [t2]. The conditional distribution of C[t2] is quantified as de scribed in the previous section. The posterior distri bution over the states of the system at time t2 can be computed simply by doing inference in the Bayesian network and looking up the posterior distribution of C[t2]. The posterior distribution at time t2 and the corresponding decision costs are shown in Table 6. The optimal decision now is to replace both the X 0 R and\nSuperficially, the situation at time t1 and t2 seem to be quite similar, viz, that (a) the system has been working for 20 hours since \"things were ok\" (b) the observation (!1 = 0, !2 = 0, Ia = 0, h = 1) is made. However, the situations are actually quite different. At time t2 we have to account for the (a) the observations and ac tions at time h and (b) possible failures of components between time t1 and t2.\nThe persistence model for the system allows us to in corporate this information when computing the pos terior distribution at time t2. Note that the Bayesian network inference is implicitly carrying out the com putation of P( C[t2] I C[t1]) (discussed in Section 1).\n4 DISCUSSION\nModeling persistence in diagnosis has been of interest both in the model-based diagnosis community and in the Bayesian network community. Early work in the model-based diagnosis community has handled per sistence only to the extent of assuming that in the case of multiple observations the state of each com ponent stays the same across all observations. This corresponds, in our framework, to the situation where multiple observations are made very close in time.\n[Portinale, 1992] addresses the problem of temporal evolution of state in model-based diagnosis. The evolu tion is modeled as a discrete time Markov chain. The state transition matrix is assumed to come from re liability measures of components. A uniform initial prior on all possible world states is used. A defini tion of a temporal diagnosis is proposed that general izes the definition of a diagnosis in a static system. A\nmethod of eliminating very unlikely diagnoses is pro posed. Our approach has a similar motivation - viz, to use models of component failure processes to model change of system state. However, our approach is sig nificantly more general. We show that the problem of specification of priors can be addressed within the same framework. The priors are computed directly from the time at which diagnosis takes place and the MTBFs of the components. Our approach also allows modeling of effects of repair actions (as in the example of Section 3.3). Time is considered to be continuous. Finally, rather than eliminating unlikely diagnoses, we compute posterior probabilities over candidates. This is necessary if a decision theoretic scheme for choosing actions is to be used.\nThe model of persistence developed in this paper is closely related to work in modeling persistence in Bayesian networks. [Dean & Kanazawa, 1989] propose a modeling framework for persistence and change using temporal probabilistic networks. A Markov assump tion is employed. The temporal probabilistic network is quantified by specifying the conditional probabil ity of each proposition in the network given the state of the same proposition at the immediately preceding time point and the states of the causes of the propo sition at the previous time point. An exponentially decaying survivor function is proposed to model the probability of a proposition being true if it was true at the previous time and none of the causes that make it untrue are active. The survivor function accounts for unmodeled causes that might change the state of the proposition.\nThe model presented in this paper can be viewed as a specific instantiation of the general framework sug gested by Dean and Kanazawa. We assume that the\n514 Srinivas\nonly system state that persists across time is the mode of the variables and that the failure processes of the components are independent. This allows us to model persistence of system state by simply modeling the per sistence of each component individually. The persis tence model for each component falls directly out of the physical process of failure postulated by the relia bility model. This persistence model is an exponential decay function.\nThe modeling of action (and hence of persistence) in causal probabilistic networks has been a field of active interest [Balke & Pearl, 1994; Darwiche & Goldzmidt, 1994; Heckerman & Shachter, 1994; Pearl, 1994]. When reasoning about actions which occur over separated points in time, one also has to ac count for possible changes in system state occurring due to unmodeled events. This paper advances a spe cific method for doing so in the domain of diagnosis of physical systems.\nOur method for modeling persistence has been devel oped assuming that the behavior of each component is deterministic, both when it is in the ok state and and when it is in the broken state. This allows us to consider only the mode variables of the components as the persisting state of the system. This is because the joint state of the mode variables completely de termines the behavior of the system. In the situation where components are not deterministic1, as a first ap proximation, one might use the same modeling scheme as the one presented in this paper. This would mean, in effect, that we assume that each component \"resam ples\" to compute its output in each observation. Thus, the same component with the same input could possi bly have two different outputs in two observations (if the component were in the broken state). If this ap proximation is inaccurate, modeling extensions along the lines suggested by Darwiche and Goldszmidt can be incorporated.\nThe simplistic decision theoretic repair model set up in this paper is for illustration purposes only. More sophisticated and realistic repair schemes (see [Hecker man et a/, 1995], [Srinivas, 1995]) have been suggested in the literature. These can be used in concert with the persistence model developed in this paper.\nReferences\n[Balke & Pearl, 1994] Balke, A. and Pearl, J. (1994) Counterfactual probabilities: Com putational bounds, methods and applications. In Proceedings of the Tenth conference on Uncertainty in Artificial Intelligence, Seattle, WA.\n[Darwiche & Goldzmidt, 1994] Darwiche, A. and Goldszmidt, M. (1994) Action Networks: A framework for reasoning about actions\n1 For example, we might assume that all outputs are equally likely if the component is broken in the case that no fault model is available.\nand change under uncertainty. In Proceedings of the Tenth conference on Uncertainty in Artificial Intel ligence, Seattle, WA.\n[Dean & Kanazawa, 1989] Dean, T. and Kanazawa, K. (1989) A model for reasoning about persis tence and causation. Computational Intelligence, 5(3):142-150.\n[DeKleer & Williams, 1989] de Kleer, J. and Williams, B. C. (1989) Diagnosis with behavioral modes. In Proceedings of the 11th IJCAI, Detroit, MI pp. 104-109, 1989.\n[Geffner & Pearl, 1987] Geffner, H. and Pearl, J. (1987) Distributed diagnosis of systems with multi ple faults. In Proceedings of the 3rd IEEE Confer ence on AI Applications, Kissimmee, FL, Feb 1987, pp 156-162.\n[Hamscher et a/, 1992] Hamscher, W., Console, L., and de Kleer, J. (eds) (1992) Readings in model based diagnosis. Morgan Kaufmann Publishers, San Mateo, C A, 1992.\n[Heckerman & Shachter, 1994] Heckerman, D. and Shachter, R. (1994) A Decision-based view of causal ity. In Proceedings of the Tenth conference on Un certainty in Artificial Intelligence, Seattle, WA.\n[Heckerman et a/, 1995] Heckerman, D., Breese, J. and Rommelse, K. (1995) Decision-theoretic Trou bleshooting. In Communications of the ACM (to appear)\n[Pearl, 1994] Pearl, J. (1994) A probabilistic calculus of actions. In Proceedings of the Tenth conference on Uncertainty in Artificial Intelligence, Seattle, WA.\n[Poole, 1991] Poole, D. (1991) Representing Diagnos tic Knowledge for Probabilistic Horn Abduction. In Proceedings of the 12th IJCAI, pp. 1129-1135, Syd ney, Australia, 1991.\n[Portinale, 1992] Modeling uncertain temporal evolu tions in model-based diagnosis. In Proceedings of the Eighth conference on Uncertainty in Artificial Intelligence, Stanford, C A, 1992.\n[Srinivas, 1994] Srinivas, S. (1994) A probabilistic ap proach to hierarchical model-based diagnosis. In Proceedings of the Tenth Annual Conference on Un certainty in Artificial Intelligence, Seattle, WA.\n[Srinivas, 1995] Srinivas, S. (1995) A polynomial al gorithm for computing the optimal repair strategy in a system with independent component failures. In Proceedings of the Eleventh conference on Uncer tainty in Artificial Intelligence, Montreal, Canada, 1995.\n[Tsokos & Shimi, 1977] Tsokos, C. P. and Shimi, I. N. (Eds) (1977) The Theory and Applications of Reliability with Emphasis on Bayesian and non parametric methods. Academic Press, Inc, 1977."
    } ],
    "references" : [ {
      "title" : "Action Networks: A framework for reasoning about actions",
      "author" : [ "Darwiche", "Goldzmidt", "A. 1994] Darwiche", "M. Goldszmidt" ],
      "venue" : null,
      "citeRegEx" : "Darwiche et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Darwiche et al\\.",
      "year" : 1994
    }, {
      "title" : "A model for reasoning about persis­ tence and causation",
      "author" : [ "Dean", "Kanazawa", "T. 1989] Dean", "K. Kanazawa" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "Dean et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Dean et al\\.",
      "year" : 1989
    }, {
      "title" : "Diagnosis with behavioral modes",
      "author" : [ "DeKleer", "Williams", "J. 1989] de Kleer", "B.C. Williams" ],
      "venue" : "In Proceedings of the 11th IJCAI,",
      "citeRegEx" : "DeKleer et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "DeKleer et al\\.",
      "year" : 1989
    }, {
      "title" : "Distributed diagnosis of systems with multi­ ple faults",
      "author" : [ "Geffner", "Pearl", "H. 1987] Geffner", "J. Pearl" ],
      "venue" : "In Proceedings of the 3rd IEEE Confer­ ence on AI Applications,",
      "citeRegEx" : "Geffner et al\\.,? \\Q1987\\E",
      "shortCiteRegEx" : "Geffner et al\\.",
      "year" : 1987
    }, {
      "title" : "and de Kleer",
      "author" : [ "W. Hamscher", "L. Console" ],
      "venue" : "J. (eds) (1992) Readings in model­ based diagnosis. Morgan Kaufmann Publishers, San Mateo, C A,",
      "citeRegEx" : "Hamscher et a.. 1992",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "A Decision-based view of causal­ ity",
      "author" : [ "Heckerman", "Shachter", "D. 1994] Heckerman", "R. Shachter" ],
      "venue" : "In Proceedings of the Tenth conference on Un­ certainty in Artificial Intelligence,",
      "citeRegEx" : "Heckerman et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 1994
    }, {
      "title" : "Decision-theoretic Trou­ bleshooting",
      "author" : [ "D. Heckerman", "J. Breese", "K. Rommelse" ],
      "venue" : "[Heckerman et a/,",
      "citeRegEx" : "Heckerman et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 1995
    }, {
      "title" : "D",
      "author" : [ "Poole" ],
      "venue" : "(1991) Representing Diagnos­ tic Knowledge for Probabilistic Horn Abduction. In Proceedings of the 12th IJCAI, pp. 1129-1135, Syd­ ney, Australia,",
      "citeRegEx" : "Poole. 1991",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Eds) (1977) The Theory and Applications of Reliability with Emphasis on Bayesian and non­ parametric methods",
      "author" : [ "C.P. Tsokos", "Shimi", "I. N" ],
      "venue" : "Academic Press, Inc,",
      "citeRegEx" : "Tsokos . Shimi. 1977",
      "shortCiteRegEx" : null,
      "year" : 1977
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "The diagnosis problem now amounts to computing P(CIO) [Geffner & Pearl, 1987; DeKleer & Williams, 1989; Poole, 1991; Srinivas, 1994].",
      "startOffset" : 54,
      "endOffset" : 132
    }, {
      "referenceID" : 8,
      "context" : "The failure process of a device relates the probability of failure of the device to time (for example, see [Tsokos & Shimi, 1977]).",
      "startOffset" : 107,
      "endOffset" : 129
    } ],
    "year" : 2011,
    "abstractText" : "Probabilistic model-based diagnosis com­ putes the posterior probabilities of failure of components from the prior probabilities of component failure and observations of sys­ tem behavior. One problem with this method is that such priors are almost never directly available. One of the reasons is that the prior probability estimates include an implicit no­ tion of a time interval over which they are specified for example, if the probability of failure of a component is 0.05, is this over the period of a day or is this over a week? A sec­ ond problem facing probabilistic model-based diagnosis is the modeling of persistence. Say we have an observation about a system at time it and then another observation at a later time t2. To compute posterior probabil­ ities that take into account both the observa­ tions, we need some model of how the state of the system changes from time t1 to t2. In this paper, we address these problems using tech­ niques from Reliability theory. We show how to compute the failure prior of a component from an empirical measure of its reliability the Mean Time Between Failure (MTBF). We also develop a scheme to model persis­ tence when handling multiple time tagged ob­ servations.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}