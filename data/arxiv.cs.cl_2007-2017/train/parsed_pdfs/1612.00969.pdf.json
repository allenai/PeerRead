{
  "name" : "1612.00969.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Unit Dependency Graph and its Application to Arithmetic Word Problem Solving",
    "authors" : [ "Subhro Roy", "Dan Roth" ],
    "emails" : [ "danr}@illinois.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Understanding election results, sport commentaries and financial news, all require reasoning with respect to quantities. Math word problems provide a natural abstraction to these quantitative reasoning problems. As a result, there has a been a growing interest in developing methods which automatically solve math word problems (Koncel-Kedziorski et al. 2015; Kushman et al. 2014; Roy and Roth 2015; Mitra and Baral 2016).\nUnits associated with numbers or the question often provide essential information to support the reasoning required in math word problems. Consider the arithmetic word problem in Example 1. The units of “66” and “10” are both “flowers”, which indicate they can be added or subtracted. Although unit of “8” is also “flower”, it is associated with a rate, indicating the number of flowers in each bouquet. As a result, “8” effectively has unit “flowers per bouquet”. Detecting such rate units help understand that “8” will more\nCopyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nExample 1 Isabel picked 66 flowers for her friends wedding. She was making bouquets with 8 flowers in each one. If 10 of the flowers wilted before the wedding, how many bouquets could she still make?\nlikely be multiplied or divided to arrive at the solution. Finally, the question asks for the number of “bouquets”, indicating “8” will likely be divided, and not multiplied. Knowing such interactions could help understand the situation and perform better quantitative reasoning. In addition, given that unit extraction is a noisy process, this can make it more robust via global reasoning.\nIn this paper, we introduce the concept of unit dependency graph (UDG) for math word problems, to represent the relationships among the units of different numbers, and the question being asked. We also introduce a strategy to extract annotations for unit dependency graphs, with minimal additional annotations. In particular, we use the answers to math problems, along with the rate annotations for a few selected problems, to generate complete annotations for unit dependency graphs. Finally, we develop a decomposed model to predict UDG given an input math word problem.\nWe augment the arithmetic word problem solver of (Roy and Roth 2015) to predict a unit dependency graph, along with the solution expression of the input arithmetic word problem. Forcing the solver to respect the dependencies of the unit dependency graph enables us to improve unit extractions, as well as leverage the domain knowledge about unit dependencies in math reasoning. The introduction of unit dependency graphs reduced the error of the solver by over 10%, while also making it more robust to reduction in lexical and template overlap of the dataset."
    }, {
      "heading" : "2 Unit Dependency Graph",
      "text" : "We first introduce the idea of a generalized rate, and its unit representation. We define rate to be any quantity which is some measure corresponding to one unit of some other quantity. This includes explicit rates like “40 miles per hour”, as well as implicit rates like the one in “Each student has 3 books”. Consequently, units for rate quantities take the form “A per B”, where A and B refer to different entities. We refer to A as Num Unit (short for Numerator Unit), and B as Den\nar X\niv :1\n61 2.\n00 96\n9v 1\n[ cs\n.C L\n] 3\nD ec\n2 01\n6\nUnit (short for denominator unit). Table 1 shows examples of Num and Den Units for various rate mentions.\nA unit dependency graph (UDG) of a math word problem is a graph representing the relations among quantity units and the question asked. Fig. 1 shows an example of a math word problem and its unit dependency graph. For each quantity mentioned in the problem, there exists a vertex in the unit dependency graph. In addition, there is also a vertex representing the question asked. Therefore, if a math problem mentions n quantities, its unit dependency graph will have n + 1 vertices. In the example in Fig 1, there is one vertex corresponding to each of the quantities 66, 8 and 10, and one vertex representing the question part “how many bouquets could she still make ?”.\nA vertex representing a number, is labeled RATE, if the corresponding quantity describes a rate relationship (according to the aforementioned definition). In fig 1, “8” is labeled as a RATE since it indicates the number of flowers in each bouquet. Similarly, a vertex corresponding to the question is marked RATE if the question asks for a rate.\nEdges of a UDG can be directed as well as undirected. Each undirected edge has the label SAME UNIT, indicating that the connected vertices have the same unit. Each directed edge going from vertex u to vertex v can have one of the following labels:\n1. NUM UNIT : Valid only for directed edges with source vertex u labeled as RATE, indicates that Num Unit of u matches the unit of the destination vertex v.\n2. DEN UNIT : Valid only for directed edges with source vertex labeled as RATE, indicates that Den Unit of source vertex u matches the unit of the destination vertex v.\nIf no edge exists between a pair of vertices, they have unrelated units.\nSeveral dependencies exist between the vertex and edge labels of the unit dependency graph of a problem, and its solution expression. Sec 4 discusses these dependencies and how they can be leveraged to improve math problem solving."
    }, {
      "heading" : "3 Learning to Predict UDGs",
      "text" : "Predicting UDG for a math word problem is essentially a structured prediction problem. However, since we have limited training data, we develop a decomposed model to predict parts of the structure independently, and then perform joint inference to enforce coherent predictions. This has been shown to be an effective method for structured prediction in the presence of limited data (Punyakanok et al. 2005; Sutton and McCallum 2007). Empirically, we found our decomposed model to be superior to jointly trained alternatives (see Section 5).\nOur decomposed model for UDG prediction uses the following two classifiers.\n1. Vertex Classifier : This is a binary classifier, which takes a vertex of the UDG as input, and decides whether it denotes a rate.\n2. Edge Classifier : This is a multiclass classifier, which takes as input a pair of nodes of the UDG, and predicts the properties of the edge connecting those nodes.\nFinally, a constrained inference module combines the output of the two classifiers to construct a UDG. We provide details of the components in the following subsections."
    }, {
      "heading" : "Vertex Classifier",
      "text" : "In order to detect rate quantities, we train a binary classifier. Given problem text P and a vertex v of the UDG, the classifier predicts whether v represents a rate. It predicts one of two labels - RATE or NOT RATE. The vertex v is either a quantity mentioned in P , or the question of P . The features used for the classification are as follows :\n1. Context Features: We add unigrams, bigrams, part of speech tags, and their conjunctions from the neighborhood of v.\n2. Rule based Extraction Features: We add a feature indicating whether a rule based approach can detect v as a rate."
    }, {
      "heading" : "Edge Classifier",
      "text" : "We train a multiclass classifier to determine the properties of the edges of the UDG. Given problem text P and a pair of vertices vi and vj (i < j), the classifier predicts one of the six labels :\n1. SAME UNIT : Indicates that vi and vj should be connected by an undirected edge labeled SAME UNIT.\n2. NO RELATION : Indicates no edge exists between vi and vj . 3. RATE→Num : Indicates that vi is a rate, and the Num Unit of vi matches the unit of vj . 4. RATE←Num : Indicates that vj is a rate, and the Num Unit of vj matches the unit of vi. 5. We similarly define RATE→Den and RATE ← Den.\nThe features used for the classification are :\n1. Context Features: For each vertex v in the query, we add the context features described for Vertex classifier.\n2. Rule based Extraction Features: We add a feature indicating whether each of the queried vertices is detected as a rate by the rule based system. In addition, we also add features denoting whether there are common tokens in the units of vi and vj .\nConstrained Inference Our constrained inference module takes the scores of the Vertex and Edge classifiers, and combines them to find the most probable unit dependency graph for a problem. We define VERTEX(v, l) to be the score predicted by the Vertex classifier for labeling vertex v of a UDG with label l, where l ∈ {RATE,NOT RATE}. Similarly, we define\nEDGE(vi, vj , l) to be the score predicted by the Edge classifier for the assignment of label l to the edge between vi and vj . Here the label l is one of the six labels defined for the edge classifier.\nLet G be a UDG with vertex set V . We define the score for G as follows:\nSCORE(G) = ∑ v∈V\nLABEL(G,v)=RATE\nVERTEX(v,RATE)+\nλ× ∑\nvi,vj∈V,i<j EDGE(vi, vj , LABEL(G, vi, vj))\nwhere λ is a scaling factor, and LABEL maps labels of the UDG, to the labels of the corresponding classifiers. LABEL(G, v) maps to RATE, if v is a rate, otherwise it maps to NOT RATE. Similarly, if no edge exists between vi and vj , LABEL(G, vi, vj) maps to NO RELATION, if Num Unit of vi matches the unit of vj , LABEL(G, vi, vj) maps to RATE→Num, and so on. Finally, the inference problem has the following form:\narg max G∈GRAPHS SCORE(G)\nwhere GRAPHS is the set of all valid unit dependency graphs for the input problem."
    }, {
      "heading" : "4 Joint Inference With An Arithmetic Solver",
      "text" : "In this section, we describe our joint inference procedure to predict both a UDG and the solution of an input arithmetic word problem. Our model is built on the arithmetic word problem solver of (Roy and Roth 2015), and we briefly describe it in the following sections. We first describe the concept of expression trees, and next describe the solver, which leverages expression tree representation of the solutions."
    }, {
      "heading" : "Monotonic Expression Tree",
      "text" : "An expression tree is a binary tree representation of a mathematical expression, where leaves represent numbers, and all non-leaf nodes represent operations. Fig 1 shows an example of an arithmetic word problem and the expression tree of the solution mathematical expression. A monotonic expression tree is a normalized expression tree representation\nfor math expressions, which restricts the order of combination of addition and subtraction nodes, and multiplication and division nodes. The expression tree in Fig 1 is monotonic."
    }, {
      "heading" : "Arithmetic Word Problem Solver",
      "text" : "We now describe the solver pipeline of (Roy and Roth 2015). Given a problem P with quantities q1, q2, . . . , qn, the solver uses the following two classifiers.\n1. Irrelevance Classifier : Given as input, problem P and quantity qi mentioned in P , the classifier decides whether qi is irrelevant for the solution. The score of this classifier is denoted as IRR(q).\n2. LCA Operation Classsifier : Given as input, problem P and a pair of quantities qi and qj (i < j), the classifier predicts the operation at the lowest common ancestor (LCA) node of qi and qj , in the solution expression tree of problem P . The set of possible operations are +, −, −r,×,÷ and÷r (the subscript r indicates reverse order). Considering only monotonic expression trees for the solution makes this operation unique for any pair of quantities. The score of this classifier for operation o is denoted as LCA(qi, qj , o).\nThe above classifiers are used to gather irrelevance scores for each number, and LCA operation scores for each pair of numbers. Finally, constrained inference procedure combines these scores to generate the solution expression tree.\nLet I(T ) be the set of all quantities in P which are not used in expression tree T , and λIRR be a scaling parameter. The score SCORE(T ) of an expression tree T is defined as:\nSCORE(T ) = λIRR ∑\nq∈I(T )\nIRR(q)+\n∑ qi,qj /∈I(T ) LCA(qi, qj , LCA(qi, qj , T ))\nwhere LCA(qi, qj , T ) denotes the operation at the lowest common ancestor node of qi and qj in monotonic expression tree T . Let TREES be the set of valid expressions that can be\nformed using the quantities in a problem P , and also give positive solutions. The inference algorithm now becomes:\narg max T∈TREES SCORE(T )\nJoint Inference We combine the scoring functions of UDG prediction and the ones from the solver of (Roy and Roth 2015), so that we can jointly predict the UDG and the solution of the problem. For an input arithmetic word problem P , we score tuples (G,T ) (where G is a candidate UDG for P , and T is a candidate solution expression tree of P ) as follows :\nSCORE(G,T ) = λIRR ∑\nq∈I(T )\nIRR(q)+\n∑ qi,qj /∈I(T ) LCA(qi, qj , LCA(qi, qj , T ))+\nλVERTEX ∑ v∈V\nLABEL(G,v)=RATE\nVERTEX(v,RATE)+\nλEDGE ∑\nvi,vj∈V,i<j EDGE(vi, vj , LABEL(G, vi, vj))\nwhere λIRR, λVERTEX and λEDGE are scaling parameters. This is simply a scaled addition of the scores for UDG prediction and solution expression generation. Finally, the inference problem is\narg max (G,T )∈TUPLES SCORE(G,T )\nwhere TUPLES is the set of all tuples (G,T ), such that G ∈ GRAPHS, T ∈ TREES, and G is a consistent UDG for the solution tree T ."
    }, {
      "heading" : "Consistent Rate Unit Graphs",
      "text" : "We have a set of conditions to check whether G is a consistent UDG for monotonic tree T . Most of these conditions are expressed in terms of PATH(T, vi, vj), which takes as input a pair of vertices vi, vj of the UDG G, and a monotonic expression tree T , and returns the following. 1. If both vi and vj are numbers, and their corresponding\nleaf nodes in T are ni and nj respectively, then it returns the nodes in the path connecting ni and nj in T .\n2. If only vi denotes a number (implying vj represents the question), the function returns the nodes in the path from ni to the root of T , where ni is the corresponding leaf node for vi.\nFor the unit dependency graph and solution tree T of Fig 1, PATH(T, 66, 8) is {−,÷}, whereas PATH(T, 8, question) is {÷}. Finally, the conditions for consistency between a UDG G and an expression tree T are as follows: 1. If vi is the only vertex labeled RATE and it is the question,\nthere should not exist a path from some leaf n to the root of T which has only addition, subtraction nodes. If that exists, it implies n can be added or subtracted to get the answer, that is, the corresponding vertex for n in G has same unit as the question, and should have been labeled RATE.\n2. If vi is labeled RATE and the question is not, the path from ni (corresponding leaf node for vi) to the root of T cannot have only addition, subtraction nodes. Otherwise, the question will have same rate units as vi.\n3. We also check whether the edge labels are consistent with the vertex labels using Algorithm 1, which computes edge labels of UDGs, given the expression tree T , and vertex labels. It uses heuristics like if a rate r is being multiplied by a non-rate number n, the Den Unit of r should match the unit of n, etc.\nAlgorithm 1 EDGELABEL Input: Monotonic expression tree T , vertex pairs vi, vj , and their\ncorresponding vertex labels Output: Label of edge between vi and vj 1: path← PATH(T, vi, vj) 2: CountMulDiv ← Number of Multiplication and Division\nnodes in path 3: if vi and vj have same vertex label, and CountMulDiv = 0\nthen 4: return SAME UNIT 5: end if 6: if vi and vj have different vertex labels, and CountMulDiv =\n1 then 7: if path contains × and vi is RATE then 8: return RATE→Den 9: end if\n10: if path contains × and vj is RATE then 11: return RATE←Den 12: end if 13: if path contains ÷ and vi is RATE then 14: return RATE→Num 15: end if 16: if path contains ÷r and vj is RATE then 17: return RATE←Num 18: end if 19: end if 20: return Cannot determine edge label\nThese consistency conditions prevent the inference procedure from considering any inconsistent tuples. They help the solver to get rid of erroneous solutions which involve operations inconsistent with all high scoring UDGs.\nFinally, in order to find the highest scoring consistent tuple, we have to enumerate the members of TUPLES, and score them. The size of TUPLES however is exponential in the number of quantities in the problem. As a result, we perform beam search to get the highest scoring tuple. We first enumerate the members of TREES, and next for each member of TREES, we enumerate consistent UDGs."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "Dataset",
      "text" : "Existing evaluation of arithmetic word problem solvers has several drawbacks. The evaluation of (Roy and Roth 2015) was done separately on different types of arithmetic problems. This does not capture how well the systems can distinguish between these different problem types. Datasets released by (Roy and Roth 2015) and (Koncel-Kedziorski et\nal. 2015) mention irrelevant quantities in words, and only the relevant quantities are mentioned in digits. This removes the challenge of detecting extraneous quantities.\nIn order to address the aforementioned issues, we pooled arithmetic word problems from all available datasets (Hosseini et al. 2014; Roy and Roth 2015; Koncel-Kedziorski et al. 2015), and normalized all mentions of quantities to digits. We next prune problems such that there do not exist a problem pair with over 80% match of unigrams and bigrams. The threshold of 80% was decided manually by determining that problems with around 80% overlap are sufficiently different. We finally ended up with 831 problems. We refer to this dataset as AllArith.\nWe also create subsets of AllArith using the MAWPS system (Koncel-Kedziorski et al. 2016). MAWPS can generate subsets of word problems based on lexical and template overlap. Lexical overlap is a measure of reuse of lexemes among problems in a dataset. High lexeme reuse allows for spurious associations between the problem text and a correct solution (Koncel-Kedziorski et al. 2015). Evaluating on low lexical overlap subset of the dataset can show the robustness of solvers to lack of spurious associations. Template overlap is a measure of reuse of similar equation templates across the dataset. Several systems focus on solving problems under the assumption that similar equation templates have been seen at training time. Evaluating on low template overlap subset can show the reliance of systems on the reuse of equation templates. We create two subsets of 415 problems each - one with low lexical overlap called AllArithLex, and one with low template overlap called AllArithTmpl.\nWe report random 5-fold cross validation results on all these datasets. For each fold, we choose 20% of the training data as development set, and tune the scaling parameters on this set. Once the parameters are set, we retrain all the models on the entire training data. We use a beam size of 200 in all our experiments."
    }, {
      "heading" : "Data Acquisition",
      "text" : "In order to learn the classifiers for predicting vertex and edge labels for UDGs, we need annotated data. However, gathering vertex and edge labels for UDGs of problems, can be expensive. In this section, we show that vertex labels for a subset of problems, along with annotations for solution expressions, can be sufficient to gather high quality annotations for vertex and edge labels of UDGs.\nGiven an arithmetic word problem P , annotated with the monotonic expression tree T of the solution expression, we try to acquire annotations for the UDG of P . First, we try to determine the labels for the vertices, and next the edges of the graph.\nWe check if T has any multiplication or division node. If no such node is present, we know that all the numbers in the leaves of T have been combined via addition or subtraction, and hence, none of them describes a rate in terms of the units of other numbers. This determines that none of T ’s leaves is a rate, and also, the question does not ask for a rate. If a multiplication or division node is present in T , we gather annotations for the numbers in the leaves of T as well as the question of P . Annotators were asked to mark whether each\nnumber represents a rate relationship, and whether the question in P asks for a rate. This process determines the labels for the vertices of the UDG. Two annotators performed these annotations, with an agreement of 0.94(kappa).\nOnce we have the labels for the vertices of the UDG, we try to infer the labels for the edges using Algorithm 1. When the algorithm is unable to infer the label for a particular edge, we heuristically label that edge to be NO RELATION.\nThe above process allowed us to extract high quality annotations for UDGs with minimal manual annotations. In particular, we only had to annotate vertex labels for 300 problems, out of the 831 problems in AllArith. Obviously some of the extracted NO RELATION edge labels are noisy; this can be remedied by collecting annotations for these cases. However, in this work, we did not use any manual annotations for edge labels."
    }, {
      "heading" : "UDG Prediction",
      "text" : "Table 2 shows the performance of the classifiers and the contribution of each feature type. The results indicate that rule-based techniques are not sufficient for robust extraction, there is a need to take context into account. Table 3 shows the performance of our decomposed model (DECOMPOSE) in correctly predicting UDGs, as well as the contribution of constraints in the inference procedure. Having explicit constraints for the graph structure provides 3-5% improvement in correct UDG prediction.\nWe also compare against a jointly trained model (JOINT), which learns to predict all vertex and edge labels together. Note that JOINT also uses the same set of constraints as DECOMPOSE in the inference procedure, to ensure it only predicts valid unit dependency graphs. We found that JOINT does not outperform DECOMPOSE, while taking significantly more time to train. The worse performance of joint learning is due to: (1) search space being too large for the joint model to do well given our relatively small dataset size, and (2) our independent classifiers being good enough, thus supporting better joint inference. This tradeoff is strongly supported in the literature (Punyakanok et al. 2005; Sutton and McCallum 2007).\nNote, that all these evaluations are based on noisy edges annotations. This was done to reduce further annotation effort. Also, less than 15% of labels were noisy (indicated by fraction of NO RELATION labels), which makes this evaluation reasonable."
    }, {
      "heading" : "Solving Arithmetic Word Problems",
      "text" : "Here we evaluate the accuracy of our system in correctly solving arithmetic word problems. We refer to our system as UNITDEP. We compare against the following systems:\n1. LCA++ : System of (Roy and Roth 2015) with feature set augmented by neighborhood features, and with only positive answer constraint. We found that augmenting the released feature set with context features, and removing the integral answer constraint, were helpful. Our system UNITDEP also uses the augmented feature set for Relevance and LCA operation classifiers, and only positive constraint for final solution value.\n2. TEMPLATE : Template based algebra word problem solver of (Kushman et al. 2014).\n3. SINGLEEQ : Single equation word problem solver of (Koncel-Kedziorski et al. 2015).\nIn order to quantify the gains due to vertex and edge information of UDGs, we also run two variants of UNITDEP - one with λVERTEX = 0, and one with λEDGE = 0. Table 4 shows the performance of these systems on AllArith, AllArithLex and AllArithTmpl.\nUNITDEP outperforms all other systems across all datasets. Setting either λVERTEX = 0 or λEDGE = 0 leads to a drop in performance, indicating that both vertex and edge information of UDGs assist in math problem solving. Note that setting both λVERTEX and λEDGE to 0, is equivalent to LCA++. SINGLEEQ performs worse than other systems, since it does not handle irrelevant quantities in a problem.\nIn general, reduction of lexical overlap adversely affects the performance of most systems. The reduction of template overlap does not affect performance as much. This is due to the limited number of equation templates found in arithmetic problems. Introduction of UDGs make the system more robust to reduction of both lexical and template overlap. In particular, they provide an absolute improvement of 5% in both AllArithLex and allArithTmpl datasets (indicated by difference of LCA++ and UNITDEP results).\nFor the sake of completeness, we also ran our system on the previously used datasets, achieving 1% and 4% absolute improvements over LCA++, in the Illinois dataset (Roy, Vieira, and Roth 2015) and the Commoncore dataset (Roy and Roth 2015) respectively."
    }, {
      "heading" : "Discussion",
      "text" : "Most of gains of UNITDEP over LCA++ came from problems where LCA++ was predicting an operation or an expression that was inconsistent with the units. A small gain (10%) also comes from problems where UDGs help detect certain irrelevant quantities, which LCA++ cannot recognize. Table 5 lists some of the examples which UNITDEP gets correct but LCA++ does not.\nMost of the mistakes of UNITDEP were due to extraneous quantity detection (around 50%). This was followed by errors due to the lack of math understanding (around 23%). This includes comparison questions like “How many more pennies does John have?”."
    }, {
      "heading" : "6 Related Work",
      "text" : "There has been a recent interest in automatically solving math word problems. (Hosseini et al. 2014; Mitra and Baral 2016) focus on addition-subtraction problems, (Roy, Vieira, and Roth 2015) look at single operation problems, (Roy and Roth 2015) as well as our work look at arithmetic problems with each number in question used at most once in the answer, (Koncel-Kedziorski et al. 2015) focus on single equation problems, and finally (Kushman et al. 2014) focus on algebra word problems. None of them explicitly model the relations between rates, units and the question asked. In contrast, we model these relations via unit dependency graphs. Learning to predict these graphs enables us to gain robustness over rule-based extractions. Other than those related to math word problems, there has been some work in extracting units and rates of quantities (Roy, Vieira, and Roth 2015; Kuehne 2004a; Kuehne 2004b). All of them employ rule based systems to extract units, rates and their relations."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we introduced the concept of unit dependency graphs, to model the dependencies among units of numbers mentioned in a math word problem, and the question asked. The dependencies of UDGs help improve performance of an existing arithmetic word problem solver, while also making it more robust to low lexical and template overlap of the dataset. We believe a similar strategy can be used to incorporate various kinds of domain knowledge in math word problem solving. Our future directions will revolve around this, particularly to incorporate knowledge of entities, transfers and math concepts. Code and dataset are available at http://cogcomp.cs.illinois.edu/page/publication view/804."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work is funded by DARPA under agreement number FA8750-13-2-0008, and a grant from the Allen Institute for Artificial Intelligence (allenai.org)."
    } ],
    "references" : [ {
      "title" : "Learning to solve arithmetic word problems with verb categorization",
      "author" : [ "Hosseini" ],
      "venue" : null,
      "citeRegEx" : "Hosseini,? \\Q2014\\E",
      "shortCiteRegEx" : "Hosseini",
      "year" : 2014
    }, {
      "title" : "Parsing Algebraic Word Problems into Equations. TACL",
      "author" : [ "Koncel-Kedziorski" ],
      "venue" : null,
      "citeRegEx" : "Koncel.Kedziorski,? \\Q2015\\E",
      "shortCiteRegEx" : "Koncel.Kedziorski",
      "year" : 2015
    }, {
      "title" : "Mawps: A math word problem repository",
      "author" : [ "Koncel-Kedziorski" ],
      "venue" : null,
      "citeRegEx" : "Koncel.Kedziorski,? \\Q2016\\E",
      "shortCiteRegEx" : "Koncel.Kedziorski",
      "year" : 2016
    }, {
      "title" : "Learning to automatically solve algebra word problems",
      "author" : [ "Kushman" ],
      "venue" : null,
      "citeRegEx" : "Kushman,? \\Q2014\\E",
      "shortCiteRegEx" : "Kushman",
      "year" : 2014
    }, {
      "title" : "Learning to use formulas to solve simple arithmetic problems",
      "author" : [ "Mitra", "A. Baral 2016] Mitra", "C. Baral" ],
      "venue" : null,
      "citeRegEx" : "Mitra et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mitra et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning and inference over constrained output",
      "author" : [ "Punyakanok" ],
      "venue" : "In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "Punyakanok,? \\Q2005\\E",
      "shortCiteRegEx" : "Punyakanok",
      "year" : 2005
    }, {
      "title" : "Solving general arithmetic word problems",
      "author" : [ "Roy", "S. Roth 2015] Roy", "D. Roth" ],
      "venue" : "In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "citeRegEx" : "Roy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Roy et al\\.",
      "year" : 2015
    }, {
      "title" : "Reasoning about quantities in natural language",
      "author" : [ "Vieira Roy", "S. Roth 2015] Roy", "T. Vieira", "D. Roth" ],
      "venue" : "Transactions of the Association for Computational Linguistics",
      "citeRegEx" : "Roy et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Roy et al\\.",
      "year" : 2015
    }, {
      "title" : "Piecewise pseudolikelihood for efficient training of conditional random fields",
      "author" : [ "Sutton", "C. McCallum 2007] Sutton", "A. McCallum" ],
      "venue" : null,
      "citeRegEx" : "Sutton et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Math word problems provide a natural abstraction to a range of natural language understanding problems that involve reasoning about quantities, such as interpreting election results, news about casualties, and the financial section of a newspaper. Units associated with the quantities often provide information that is essential to support this reasoning. This paper proposes a principled way to capture and reason about units and shows how it can benefit an arithmetic word problem solver. This paper presents the concept of Unit Dependency Graphs (UDGs), which provides a compact representation of the dependencies between units of numbers mentioned in a given problem. Inducing the UDG alleviates the brittleness of the unit extraction system and allows for a natural way to leverage domain knowledge about unit compatibility, for word problem solving. We introduce a decomposed model for inducing UDGs with minimal additional annotations, and use it to augment the expressions used in the arithmetic word problem solver of (Roy and Roth 2015) via a constrained inference framework. We show that introduction of UDGs reduces the error of the solver by over 10%, surpassing all existing systems for solving arithmetic word problems. In addition, it also makes the system more robust to adaptation to new vocabulary and equation forms .",
    "creator" : "LaTeX with hyperref package"
  }
}