{"conference": "ICLR 2017 conference submission", "title": "Fast Adaptation in Generative Models with Generative Matching Networks", "abstract": "Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. Both problems may be addressed by conditional generative models that are trained to adapt the generative distribution to additional input data. So far this idea was explored only under certain limitations such as restricting the input data to be a single object or multiple objects representing the same concept.   In this work we develop a new class of deep generative model called generative matching networks which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks and the ideas from meta-learning. By conditioning on the additional input dataset, generative matching networks may instantly learn new concepts that were not available during the training but conform to a similar generative process, without explicit limitations on the number of additional input objects or the number of concepts they represent.  Our experiments on the Omniglot dataset demonstrate that generative matching networks can significantly improve predictive performance on the fly as more additional data is available to the model and also adapt the latent space which is beneficial in the context of feature extraction.", "reviews": [{"is_meta_review": true, "comments": "The paper explores a VAE architecture and training procedure that allows to generate new samples of a concept based on several exemplars that are shown to the model. The proposed architecture processes the set of exemplars with a recurrent neural network and aggregation procedure similar to the one used in Matching Networks. The resulting \"summary\" is used to condition a generative model (a VAE) that produces new samples of the same kind as the exemplars shown. The proposed aggregation and conditioning procedure are better suited to sets of exemplars that come from several classes than simple averaging.\nPerhaps surprisingly the model generalizes from generation conditioned on samples from 2 classes to generation conditioned on samples from 4 classes.\nThe experiments are conducted on the OMNIGLOT dataset and are quite convincing. An explicit comparison to previous works is lacking, but this is explained in the appendices, and a comparison to architectures similar to previous work is presented.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "This work extends variational autoencoders to adapt to a new dataset containing a small number of examples. While this work is promising, two of the reviewers had serious concerns about clarity. A new version of the paper has been submitted, however I still find it too hard to follow and would find it hard to accurately describe what was done having read the main body of the paper.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"TITLE": "Update", "OTHER_KEYS": "Sergey Bartunov", "comments": "We would like to thank the reviewers for their efforts!\n\nWe received many useful comments that helped us to improve the text.\nUsing the provided feedback, we have edited the paper and uploaded a new version which, hopefully, addresses the issues raised in reviews.\n\nWe have also sent our response to all three reviews and would be glad to continue the discussion.", "IS_META_REVIEW": false, "DATE": "13 Jan 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "reasonable approach, but the exposition is hard to follow, and it's not clear what is novel", "is_meta_review": false, "comments": "This paper presents a meta-learning algorithm which learns to learn generative models from a small set of examples. It\u2019s similar in structure to the matching networks of Vinyals et al. (2016), and is trained in a meta-learning framework where the inputs correspond to datasets. Results are shown on Omniglot in terms of log-likelihoods and in terms of generated samples. \n\nThe proposed idea seems reasonable, but I\u2019m struggling to understand various aspects of the paper. The exposition is hard to follow, partly because existing methods are described using terminology fairly different from that of the original authors. Most importantly, I can\u2019t tell which aspects are meant to be novel, since there are only a few sentences devoted to matching networks, even though this work builds closely upon them. (I brought this up in my Reviewer Question, and the paper has not been revised to make this clearer.)\n\nI\u2019m also confused about the meta-learning setup. One natural formulation for meta-learning of generative models would be that the inputs consist of small datasets X, and the task is to predict the distribution from which X was sampled. But this would imply a uniform weighting of data points, which is different from the proposed method. Based on 3.1, it seems like one additionally has some sort of query q, but it\u2019s not clear what this represents. \n\nIn terms of experimental validation, there aren\u2019t any comparisons against prior work. This seems necessary, since several other methods have already been proposed which are similar in spirit. \n", "IS_META_REVIEW": false, "RECOMMENDATION": 4, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Interesting idea, but clarity issues make the paper difficult to follow", "is_meta_review": false, "comments": "This paper proposes an interesting idea for rapidly adapting generative models in the low data regime. The idea is to use similar techniques that are used in one-shot learning, specifically ideas from matching networks. To that end, the authors propose the generative matching networks model, which is effectively a variational auto-encoder that can be conditioned on an input dataset. Given a query point, the model matches the query point to points in the conditioning set using an attention model in an embedding space (this is similar to matching networks). The results on the Omniglot dataset show that this method is successfully able to rapidly adapt to new input distributions given few examples.\n\nI think that the method is very interesting, however the major issue for me with this paper is a lack of clarity. I outline more details below, but overall I found the paper somewhat difficult to follow. There are a lot of details that I feel are scattered throughout, and I did not get a sense after reading this paper that I would be able to implement the method and replicate the results. My suggestion is to consolidate the major implementation details into a single section, and be explicit about the functional form of the different embedding functions and their variants.\n\nI was a bit disappointed to see that weak supervision in the form of labels had to be used. How does the method perform in a completely unsupervised setting? This could be an interesting baseline.\n\nThere is a lack of definition of the different functions. Some basic insight into the functional forms of f, g, \\phi, sim and R would be nice. Otherwise it is very unclear to me what\u2019s going on.\n\nSection 3.2: \u201conly state of the recurrent controller was used for matching\u201d, my reading of this section (after several passes) is that the pseudo-input is used in the place of a regular input. Is this correct? Otherwise, this sentence/section needs more clarification. I noticed upon further reading in section 4.2 that there are two versions of the model: one in which a pseudo input is used, and one in which a pseudo input is not used (the conditional version). What is the difference in functional form between these? That is, how do the formulas for the embeddings f and g change between these settings?\n\n\u201csince the result was fully contrastive we did not apply any further binarization\u201d what does it mean for a result to be fully contrastive?\n\nFor clarity, the figures and table refer to the number of shots, but this is never defined. I assume this is T here. This should be made consistent.\n\nFigure 2: why is the value of T only 9 in this case? What does it mean for it to be 0? It is stated earlier that T should go up to 20 (I assume #shot corresponds to T). It also looks like the results continue to improve with an increased number of steps, I would like to see the results for 5 and maybe 6 steps as well. Presumably there will come a point where you get diminishing returns.\n\nTable 1: is the VAE a fair baseline? You mention that Ctest affects Pd() in the evaluation. The fact that the VAE does not have an associated Ctest implies that the two models are being evaluated with a different metric. Can the authors clarify this? It\u2019s important that the comparison is apples-to-apples.\n\nMNIST is much more common than Omniglot for evaluating generative models. Would it be possible to perform similar experiments on this dataset? That way it can be compared with many more models.\n\nFurther, why are the negative log-likelihood values monotonically decreasing in the number of shots? That is, is there ever a case where increasing the number of shots can hurt things? What happens at T=30? 40?\n\nAs a minor grammatical issue, the paper is missing determiners in several sentences. At one point, the model is referred to as \u201cshe\u201d instead of \u201cit\u201d. \u201cOn figure 3\u201d should be changed to \u201cin figure 3\u201d in the experiments section.\n", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 3}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "Interesting paper, good experiments", "is_meta_review": false, "comments": "The paper explores a VAE architecture and training procedure that allows to generate new samples of a concept based on several exemplars that are shown to the model. The proposed architecture processes the set of exemplars with a recurrent neural network and aggregation procedure similar to the one used in Matching Networks. The resulting \"summary\" is used to condition a generative model (a VAE) that produces new samples of the same kind as the exemplars shown. The proposed aggregation and conditioning procedure are better suited to sets of exemplars that come from several classes than simple averaging.\nPerhaps surprisingly the model generalizes from generation conditioned on samples from 2 classes to generation conditioned on samples from 4 classes.\nThe experiments are conducted on the OMNIGLOT dataset and are quite convincing. An explicit comparison to previous works is lacking, but this is explained in the appendices, and a comparison to architectures similar to previous work is presented.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "16 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "Averaging", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}, {"TITLE": "relationship with matching networks?", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "29 Nov 2016", "is_meta_review": false}], "SCORE": 7, "authors": "Sergey Bartunov, Dmitry P. Vetrov", "KEYWORDS": "A nonparametric conditional generative model with fast small-shot adaptation", "accepted": false, "id": ""}
