{
  "name" : "1706.01606.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "DeepKey: An EEG and Gait Based Dual-Authentication System",
    "authors" : [ "XIANG ZHANG", "LINA YAO", "KAIXUAN CHEN", "XIANZHI WANG", "QUAN Z. SHENG", "TAO GU", "Xiang Zhang", "Lina Yao", "Kaixuan Chen", "Xianzhi Wang", "an Z. Sheng" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "39\nDeepKey: An EEG and Gait Based Dual-Authentication System\nXIANG ZHANG, University of New South Wales LINA YAO, University of New South Wales KAIXUAN CHEN, University of New South Wales XIANZHI WANG, University of New South Wales QUAN Z. SHENG, Macquarie University TAO GU, RMIT University\nBiometric authentication involves various technologies to identify individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, biometric authentication systems (e.g., face recognition, iris, retina, voice, and ngerprint) are increasingly facing the risk of being tricked by biometric tools such as anti-surveillance masks, contact lenses, vocoders, or ngerprint lms. In this regard, we design a multimodal biometric authentication system named DeepKey which uses both gait and Electroencephalography (EEG) signals to provide be er protection against such risks. DeepKey consists of three key components: an Invalid ID Filter Model to block invalid subjects, a Gait Identi cation Model to recognize Gait IDs and an EEG Identi cation Model to recognize EEG IDs. In particular, the rst two models employ a one-class SVM algorithm and a Recurrent Neural Network based deep learning model, respectively. e third model combines autoregressive coe cients, an RNN structure, and an SVM classi er. DeepKey is trained with a gait dataset of 160,000 samples and an EEG dataset of 108,000 samples. Experimental results show DeepKey outperforms a series of comparison methods and achieves an overall accuracy of 0.983 along with an overall false acceptance rate (FAR) of 0.0 and a false rejection rate (FRR) of 0.019.\nCCS Concepts: •Security and privacy→ Biometrics; Biometrics; •Computing methodologies→Machine learning algorithms;\nGeneral Terms: Gait, EEG, Biometric authentication System, Deep Learning\nAdditional Key Words and Phrases: Gait, EEG, biometric authentication, multimodal, deep learning\nACM Reference format: Xiang Zhang, Lina Yao, Kaixuan Chen, Xianzhi Wang, an Z. Sheng, and Tao Gu. 2017. DeepKey: An EEG and Gait Based Dual-Authentication System. ACM J. Comput. Cult. Herit. 9, 4, Article 39 (March 2017), 20 pages. DOI: 0000001.0000001"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "Over the past decade, biometric authentication systems have gained more acceptance due to its reliability and adaptability. Existing biometric authentication systems generally include physiological and behavioral ones. e former is based on individuals’ unique intrinsic features (e.g., face [14], iris [29], retina [40], voice [15], and ngerprint [46]) and the la er is based on individuals’ behavior pa erns such as gait analysis [5] and mobile phone usage pa ern [52]. Within these systems, EEG signal-based cognitive biometrics and gait-based systems probably represent the most advantageous approaches.\nACM acknowledges that this contribution was authored or co-authored by an employee, or contractor of the national government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. Permission to make digital or hard copies for personal or classroom use is granted. Copies must bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. To copy otherwise, distribute, republish, or post, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. © 2017 ACM. XXXX-XXXX/2017/3-ART39 $15.00 DOI: 0000001.0000001\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nar X\niv :1\n70 6.\n01 60\n6v 1\n[ cs\n.L G\n] 6\nJ un\n2 01\n7\ne EEG signal-based system is an emerging approach in physiological biometrics in recent years. Such systems measure brain’s response to a number of stimuli in the form of EEG signals, which record the electromagnetic, invisible, and untouchable electrical neural oscillations. Lots of research e orts have been made on EEG-based biometric authentication. For instance, Chuang et al. [8]propose a single-channel EEG-based authentication system, which achieves an accuracy of 0.99. Sarineh Keshishzadeh et al. [23] employ a statistical model for analyzing EEG signals and achieves an accuracy of 0.974. Generally, EEG signals have the following inherent advantages:\n• Uniqueness. EEG data are unique for each person and almost impossible to be cloned and duplicated. EEG signals are individual-dependent. erefore, an EEG-based authentication system has the potential to verify human identity and ingenious enough to protect against faked identities[8]. • Reliability. An EEG-based authentication system can prevent the subjects under abnormal situations\n(e.g., dramatically spiritual uctuating, hysterical, drunk, or under threaten) since EEG signals are not sensitive to human stress and mood. • Feasibility. We have seen an important trend to build authentication systems based on EEG because the\nequipment for collecting EEG data is cheap and easy to acquire, and it is expected to be more precise, accessible, and economical in the future.\nIn comparison, the gait-based authentication systems have been an active direction for years. Gait data are more generic and can be gathered easily from the popular inertial sensors. Gait data are also unique because they are determined by intrinsic factors (e.g., gender, age, height, limb length), temporal factors [6] (e.g., step length, step width, walking speed, and cycle time) and kinematic factors (e.g., joint rotation of the hip, knee, and ankle, mean joint angles of the hip/knee/ankle, and thigh/trunk/foot angles). In addition, a person’s gait behavior is established inherently in long term and therefore di cult to be faked. Hoang et al. [20] propose a gait-based authentication biometric system to analyze the gait data gathered by mobile device, adopt error correcting codes to process the variation in gait measurement and nally achieve a false acceptance rate (FAR) of 3.92% and a false rejection rate (FRR) of 11.76%. Cola et al. [9] collect wrist signals and train gait pa erns to detect invalid subjects (authenticated people). e proposed method achieves an EER (equal error rate) of 2.9%.\nAlthough both the Gait-based and EEG-based authentication systems have promising characteristics, all those systems face the threat of being deceived as a result of the rapidly development of manufacturing industry and technologies. For example, people can easily trick a ngerprint-based authentication system by using a fake ngerprint lm 1 or an expensive face recognition-based authentication systems by simply wearing a 200 dollars’ worth anti-surveillance mask 2. Besides, various other challenges still remain: (i) the performance of the gait-based authentication system does not scaled well with the increase in the number of authorized subjects [42]; (ii) many biometric authentication systems are working on a single modality, the FAR of which is higher than 0.03. It is not precise enough for high degree con dential places such as military bases, the treasuries of banks and political o ces which require an authentication system with high precision since any tiny misjudge will provoke great economic or political catastrophes; (iii) the authentication system may result in wrong decisions if disturbed by the environmental factors.\nIn this paper, we propose a two-factor biometric authentication system, DeepKey, which enables the dualauthentication to leverage the advantages of both the gait-based and the EEG-based systems. Compared with either gait-based or EEG-based authentication system, the two-factor authentication system o ers more reliable and precise identi cation. Table 1 summarizes the overall comparison of DeepKey with some representative works on 7 key aspects. DeepKey consists of three main components: the Invalid ID Filter Model to eliminate invalid or outlier targets; the Gait Identi cation Model to identify targets’ gait IDs; and the EEG Identi cation Model\n1h p://www.instructables.com/id/How-To-Fool-a-Fingerprint-Security-System-As-Easy-/ 2h p://www.urmesurveillance.com/urme-prosthetic/\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nto identify targets’ EEG IDs. A target is granted access only a er she/he passes two separate authentications. Our main contributions of this paper are highlighted as follows:\n• We present DeepKey, a dual-authentication system that exploits both gait and EEG biological traits. To the best of our knowledge, DeepKey is the rst two-factor authentication system which combines EEG and gait signals for person authentication. To further enhance the performance, DeepKey includes an Invalid ID Filter Model that achieves a FAR of 0 to eliminate impostors with 100% security guaranteed. • We design a robust recurrent neural network that simultaneously detection and classi cation of multi-\nmodal sensor data, to decode the large diversity in how people perform gaits and how people perform brain activities. • Together a cropped training strategy, Orthogonal Array Experiment Method, we validate and evaluate\nDeepKey on real-datasets. Our results show that DeepKey signi cantly outperforms a series of baseline models and the-state-of-the-art methods, achieving a FAR of 0 and a FRR of 0.019.\nNote that all the necessary reusable codes and datasets in this paper have been open-sourced for reproduction, please refer to this link. 3 e remainder of this paper is organized as follows. Section 2 introduces the EEG-based, gait-based, and multimodal biometric systems brie y. Section 3 details the methodology and three key models (Invalid ID Filter Model, Gait Identi cation Model, and EEG Identi cation Model) of the DeepKey authentication system. Section 4 evaluates the proposed approach on the public Gait and EEG dataset and provides analysis of the experimental results. Finally, Section 5 summarizes this paper and points out our future work."
    }, {
      "heading" : "2 RELATED WORK",
      "text" : ""
    }, {
      "heading" : "2.1 Biometric authentication technologies",
      "text" : "Since biometric features cannot be stolen or duplicated easily, biometric authentication [4] is becoming increasingly a commonplace. Currently, the most mature biometric authentication technology is ngerprint-based authentication which has been demonstrated to high matching accuracy and been used for decades [32]. Iris recognition is another popular approach for biometric authentication owing to its unique and stable pa ern [39]. In 1993, Daugman [10] proposes to use Gabor phase information and Hamming distance for iris code matching, which still is the most classic iris recognition method. Based on [10], a urry of research [39] has emerged o ering solutions to ameliorate iris authentication problems. For example, Pillai et al. [39] introduce\n3h ps://github.com/xiangzhang1015/DeepKey\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nkernel functions to represent transformations of iris biometrics. is method restrains both the intra-class and inter-class variability to solve the sensor mismatch problem. Face recognition techniques [12, 18, 53] are the most common used and accepted by the public for its unique features and non-intrusiveness. Since face recognition systems require tackling di erent challenges including expression, image quality, illumination, and disguise to achieve high accuracy, infrared (IR) [18] and 3D [12] systems have a racted much a ention. According to [53], multimodal recognition combining traditional visual textual features and IR or 3D systems can achieve higher accuracy than single modal systems."
    }, {
      "heading" : "2.2 Gait based authentication",
      "text" : "As the most basic activity in our daily lives, walking is an advanced research hotspot for activity recognition [21, 36, 51]. Di ering from previous work, our work focuses on human gait, a spatiotemporal biometric that measures a person’s manner on walking. On the one hand, gait can be collected remotely without human interaction when compared with other aforementioned biometric features [47]. On the other hand, it is challenging to eliminate the in uence of exterior factors including clothing, walking surface, shoes, carrying stu , and other environmental factors. Existing gait recognition approaches sit in two categories. One is model-based approach [38], which models gait information with a mathematical structures, and the other is appearance-based approach, which extracts features in a straightforward way irrespective of the mathematical structure. Due to its high e ciency and remarkable performance, Gait Energy Image (GEI) [33] has become one of the most popular appearance-based methods in recent years. Based on GEIs, Guan et al. [16] employ a Random Subspace Method (RSM) [19] and model the in uence of exterior factors as the unknown partial feature corruption to decrease the in uence. With the prevalence of WiFi devices, WiFiU [48], a method utilizing two WiFi devices to extract discriminating gait features is proposed. To address the challenges of distinguishing di erent body parts and representing walking pa erns, the system generates spectrograms and conduct enhancing process and autocorrelation on the contour pro le. Besides, the cross-view variance is also a concern of gait identi cation [27, 28]. For example, Wu et al. [49] consider not only the cross-view variance but also deep convolutional neural networks (CNNs) for robust gait identi cation."
    }, {
      "heading" : "2.3 EEG based authentication",
      "text" : "Since EEG can be gathered in a safe and non-intrusive way, researchers have paid great a ention to exploring this kind of brain signals. For person authentication, EEG is promising for being con dential and fake-resistant but on the other hand, complex and hard to be analyzed. Marcel and Millán [35] use Gaussian Mixture Models and train client models with MaxIMUsm A Posteriori (MAP). Ashby et al. [2] extract ve sets of features from EEG electrodes and inter-hemispheric data, combine them together, and process the nal features with support vector machine (SVM). e study shows that EEG authentication is also feasible with less-expensive devices. Altahat et al. [1] select Power Spectral Density (PSD) as the feature instead of the widely used autoregressive (AR) models to get higher accuracy. ey also conduct channel selection to determine contributing channels among all 64 channels. omas and Vinod [44] take advantage of individual alpha frequency (IAF) and delta band signals to compose speci c feature vector. ey also prefer PSD features but only perform the extraction merely on gamma band."
    }, {
      "heading" : "2.4 Multimodal biometric authentication",
      "text" : "Since traditional unimodal authentication su ers from the negative in uence of loud noise, low universality, and intra-class variation, it can no longer meet the higher accuracy requirement by a wide range of applications. To address this concern, multimodal biometric authentication which combines and uses biometric traits in di erent ways becoming poplular. Taking the commonness into consideration, most works choose two biometrics from face, iris, and ngerprints and make the fusion [24, 26, 43]. In [11], an innovative combination between gait and\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nelectrocardiogram (ECG) is shown to be e ective. Manjunathswamy et al. [34] combine ECG and ngerprint at the score level. To the best of our knowledge, the approach proposed in this paper is the rst one to combine EEG and gait for person authentication. Taking advantages of both EEG and gait signals, the combination is expected to improve the reliability of any authentication systems."
    }, {
      "heading" : "2.5 Summary",
      "text" : "As a summary, traditional authentication techniques only consider common and easily accessible biometrics devices. Nevertheless, with advanced scienti c technologies, these biometrics systems are exposed to the danger of being faked. Relying upon the fake-resistance power of both approaches, an innovative combination of EEG and gait guarantees the safety and correctness of authentication systems. Furthermore, most of the works do not mention their solutions to dealing with invalid subjects (e.g., an imposter). On the contrary, our work presents a complete Invalid ID Filter Model and achieves a high Invalid ID Filter performance."
    }, {
      "heading" : "3 THE PROPOSED APPROACH",
      "text" : "In this section, we rst give an overview of the DeepKey system and then present the technical details for each component, namely Invalid ID Filter, Gait-based Identi cation, EEG-based Identi cation and Decision Making."
    }, {
      "heading" : "3.1 System Overview",
      "text" : "e DeepKey system is supposed to be deployed in front of the access to the con dential location (e.g., bank vouchers, military bases and government con dential residences). It includes an aisle for gait data collection and an EEG helmet for EEG data collection (as shown in the le part of Figure 1). e procedure of DeepKey can be described as follows. e person goes through the aisle for gait data collection and puts on the EEG helmet for EEG data collection at the end of the aisle. A er that, the nal decision (Approval or Rejection) can be made according to both the gait and the EEG identi cation results.\nAll data including the ground truth (the ID label of the target subject), gait component, and EEG data component are input into the DeepKey system for future analysis:\nInputdata = {ID |[Gaitdata : EEGdata]}\nAs shown in Figure 1, the analysis contains four steps: (1) Firstly, the Invalid ID Filter Model judges based on the gait data if the subject is an impostor or a genuine\nperson. If the answer is yes (impostor), the Decision Making step will deny the request. e algorithm for the Invalid Detection Model is a one-class SVM (Section 3.2). (2) If the individual is determined as genuine, the Gait Identi cation Model will identify the individual’s authorized ID based on the gait data. is model is pre-trained o -line with the Recurrent Neural Networks (RNN) based model (Section 3.3). e output is the ID number associated with the person’s detailed personal information. (3) e third step is EEG Identi cation. Similar to the prior step, this step identi es the subject’s EEG ID based on the EEG input data. e pre-trained EEG ID Model consists of three components: Autoregressive coe cient, RNN and SVM (Section 3.4). (4) e nal step is to check the consistency of the gait ID and the EEG ID. If they are identical (e.g., both ID numbers are 2), the decision-making section will grant an approval, otherwise deny the subject and take corresponding security measures.\nOne key component of DeepKey is Invalid ID Filter Model as both the Gait Identi cation Model and the EEG Identi cation Model do not contain a threshold to lter invalid outlier subjects. A er the person goes through the aisle for gait data collection and puts on the EEG helmet for EEG data collection at the end of the aisle, the decision\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\n(Approval or Rejection) can be made according to both the gait and the EEG identi cation results. erefore, the lter section takes the responsibility for avoiding misidentifying invalid subjects as genuine. Another one is Recurrent Neural Networks (RNN), the core algorithm of DeepKey. With deep architectures, DeepKey can avoid the time-consuming pre-processing and feature extraction in data processing. Moreover, RNN plays two important roles in Algorithm 1 and Algorithm 2. RNN mainly takes classi cation function in Algorithm 1 and works as a feature extraction machine and sends re ned features to SVM for classi cation in Algorithm 2. All the important parameters mentioned in this paper are listed in Table 2."
    }, {
      "heading" : "3.2 Invalid ID Filter Model",
      "text" : "e subjects in an authentication system are categorized into two classes: authorized and unauthorized. We apply one-class SVM to sort out the unauthorized subjects.\nGiven a set of authorized subjects S = {Si , i = 1, 2, · · · ,L◦} , Si ∈ Rns , where L◦ denotes the number of authorized subjects and ns denotes the number of features in input data. e input data consists of gait data G = {Gi , i = 1, 2, · · · ,L◦} ,Gi ∈ Rnд and EEG data E = {Ei , i = 1, 2, · · · ,L◦} ,Ei ∈ Rne . nд and ne denote the number of features in gait data and EEG data, respectively, and\nns = nд + ne\n. In the Invalid ID Filter Model, only the gait data Gi is utilized. e Rnд is called the input space. A nonlinear function Φ(Gi ) maps vector Gi to a higher dimensional feature space F , which provides a hyper-plane\nf (G) = { L◦∑ i=1 αiK(G,Gi ) − ρ }\nas the boundary of the mapped vector {Φ(Gi ), i = 1, 2, · · · ,L◦} to enclose as many samples as possible into a hyper sphere area with a minIMUsm volume. αi denotes the Lagrange multiplier obtained by optimizing\nmin α { 1 2αiα jK(Gi ,G j ) } , s .t .0 ≤ αi ≤ 1 νm , i=1∑ L◦ αi = 1\n. ρ denotes the distance between the feature space and the input space. ν denotes the threshold, which determines the sensitivity of the model to invalid samples. m is the number of training data. e kernel function is an\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\noperation mapping samples from the input space to the feature space, described by K(G,Gi ) = Φ(G)TΦ(Gi )\ne kernel function is de ned as a RBF kernel, K(G,Gi ) = exp {−γd(G,Gi )}\n, where d(G,Gi ) is the distance between the learned common pa ern G and a speci c sample Gi . γ denotes the parameter of RBF kernel. e test samples will be accepted as normal samples if f (G) > 0; otherwise, they will be regarded as invalid subjects. e testing data are divided into a number of fragments where each fragment includes a number of samples (rows). e nal judgment result is the number of the judgment on all the samples. For example, given a fragment of 200 samples, if 150 of them are classi ed to be normal and 50 to be invalid, then the nal result of this fragment is normal."
    }, {
      "heading" : "3.3 Gait Identification Model",
      "text" : "RNN is a supervised deep learning algorithm that performs well in classi cation and regression models. It gives each neuron and neuron connection a modi able real-valued weight and explores the mapping relationship between the input features and the expected output results. By exploiting the time series relationship between\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nsamples and adjusting the weights of all the neurons of all layers, the RNN structure can imitate any mapping relationship. e RNN structure contains three components: the input layer, the hidden layer and the output layer. e input layer receives the input features, with each node corresponding to one feature. e hidden layer can be one or more layers. Specially, a model is considered a deep learning model when its hidden layer is more than one layer, where more nodes and layers can potentially enhance the performance of the mapping between the input layer and the output layer. e output layer produces the results of the algorithm with each node in this layer corresponding to one output feature.\nIn our system, the Gait Identi cation Model employs a 7-layer RNN model including an input layer, ve hidden layers, two of which are composed of LSTM (Long Short Term Memory), and an output layer.\nSupposeG is the input data of the Gait Identi cation Model and it has the shape of [nin ,nд], where nin denotes the rows of gait data. e input data are divided into several mini-batches for less memory occupation since every iteration has fewer samples and faster training since the parameters of the network update a er every iteration. bs denotes the number of samples in each mini-batches.\nParameters of the model include lr which denotes the learning rate in the learning model and nk ,k ∈ {1, 2, · · · , 7} which denotes the number of the nodes in the k-th layer. e output of the deep learning model is one hot ID label of the subjects which means that the label of a sample is represented by a list of binary units, L units. e data in the k-th layer are denoted by Xk ∈ R[nin,nk ],k ∈ {1, 2, · · · , 7}. For instance, X1 denotes the data in layer 1 (input layer). e weights between layer k and layer k + 1 are denoted by Wk (k+1) ∈ R[nk ,nk+1],k ∈ {1, 2, · · · , 6}. bk ∈ Rnk denotes the biases of k-th layer. Each input sample can be 2-D when ns > 1 or 1-D when ns = 1.\nSuppose the input data are 3-dimensional tuples in the form of [bs,ns ,nin], which consist of bs samples in the form of [ns ,nin], they are reshaped to [bs ∗ ns ,nin].\nXk = X(k−1) ∗Wk(k+1) + bk ,k ∈ 1, 2, · · · , 6 Note that both the fourth and the h layers are LSTM layers and the sizes of Xk ,Wk (k+1) and bk must match.\nTo increase the non-linearity of this model, we use a sigmoid function as the activation function. rough pre-experiments, we nd the model performs the best when the sigmoid function works on the second layer. So X2 becomes the following:\nX2 = siдmoid(X1 ∗W12 + b1) To make the di erence between categories more apparent, a so max function is employed on the results X7\ndescribed by the following formula:\nX ′7i j = X7i j∑nl i=1 X7i j , i ∈ 1, 2, · · · ,nl\nwhere X ′7 ∈ R[bs,nl ], X ′Ki j is the i-th value in the j-th sample’s outputs (the classi cation result of the j-th sample), nl is the number of the elements in a sample label, nl = nc + 1. Besides, the nodes of the output layer and the elements in the single label should be of the same number, i.e., nl = nK . We choose the objective as a Log loss function with a modi ed L2 norm loss 4 to avoid over- ing,\ncost = − 1 N N∑ j=1 nl∑ i=1 (yi jloд(X ′Ki j )] + (1 − yi j )loд(1 − X ′Ki j ))) + L2\n4h ps://github.com/tensor ow/tensor ow/blob/master/tensor ow/g3doc/api docs/python/functions and classes/shard4/tf.nn.l2 loss.md\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nwhere N is the number of samples in this batch (N = bs), y ∈ R[bs,nl ], yi j is the i-th element in the j-th sample’s true label. e modi ed L2 loss is calculated as:\nL2 = λ nh1∑ h1=1 ∑nh2 h2=1v 2 h2 2\nwhere λ is the coe cient, v is trainable variables in the network, nh1 is the number of variable tensors in the network, and nh2 is the number of values in each speci c tensor. e Adam optimizer 5 is employed to optimize the cost. is optimizer uses moving averages of the parameters and enables to choose a bigger e ective step and convergence to the step size even without ne tuning. e forecast results (X ′K ) of the model is a list of values of length nl . For example, suppose one single sample’s classi cation result is [0.067, 0.134, 0.067, 0.402, 0.052, 0.134], and we use an argmax function to nd the position of the maxIMUsm and get the largest value 0.402 at the position 3 (the position is counted from zero). e prediction result of this sample is also 3. If the true label of this sample is 3, the number of true labels is added by 1; otherwise, by 0. At the end, the accuracy of this batch samples is the average of all counts:\nacc = bs∑ j=1 α j\nα j = { 1 Yj = labelj 0 other\nwhere labelj is the true label of the j-th sample. e common structure of L-layer LSTM will be introduced (L=2 in this paper). Each layer of the Multilayer LSTM is connected by several single LSTM cells. e output of the cell is not only related to the input of this cell but also related to the previous cell’s output. e multilayer LSTM layers are connected by L layers of LSTM cells. Every layer should have the same number of basic cells. For the cells in the same order in di erent layers, the input of the later layer’ cell equals to the output of the previous layer’s cell, represented by ILt = OL−1t . Every LSTM cell (e.g., Cell t in Layer L) has three inputs (two from the same layer (e.g., OLt−1, cLt−1 ) and one from previous layer (e.g., OL−1t )) and two outputs (cLt are sent to the (t + 1)-cell in Layer L, while OLt is sent to both the (t + 1)-cell in Layer L and the t-cell in Layer L + 1).\nSuppose OLt is the output of the t-th LSTM cell in L layer, cLt denotes the state (memory) of the t-th LSTM cell in L layer, ILt denotes the Input of the t-th LSTM cell in L layer,T denotes an operation (Wx +b) for some weights W and biases b, and denotes element-wise multiplication, since L is the number of LSTM cell layers. A LSTM cell 6 has three inputs and two outputs as follows:\nLSTMcell : OLt , cLt ← OL−1t ,OLt−1, cLt−1 e speci c equations are described as the following:\ni = siдmoid(T (OL−1t ,OLt−1)) f = siдmoid(T (OL−1t ,OLt−1)) o = siдmoid(T (OL−1t ,OLt−1)) m = tanh(T (OL−1t ,OLt−1)) cLt = f cLt−1 + i д OLt = o tanh(cLt )\n5h ps://arxiv.org/pdf/1412.6980v8.pdf 6h ps://www.tensor ow.org/versions/r0.10/api docs/python/rnn cell/rnn cells for use with tensor ow s core rnn methods# BasicLSTMCell\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nALGORITHM 1: Gait Identi cation Model Input: Gait data G and corresponding parameters lr ,bs, λ,nk ,niter Output: Gait ID number, Yj\n1: while iteration < niter do 2: for k ∈ {1, 2, · · · , 7} do 3: Xk ← f (X1,Wk (k+1)),bk ) 4: Yj ← arдmax(so f tmax(X7i j )) 5: end for 6: end while 7: Gait ID = Yj 8: return Gait ID\nwhere i, f ,o andm represent the input gate, forget gate, output gate and input modulation gate 7, respectively. Each gait sample is a single row vector in the Gait Identi cation Model. We set state is tuple as True, and activiation as None."
    }, {
      "heading" : "3.4 EEG Identification Model",
      "text" : "Compared to gait data, the EEG data contain more noise which are more challenging to handle. Given the complexity of EEG signals, the data pre-processing is necessary. e EEG Identi cation Model is constructed by three components: AR for pre-processing, RNN for feature extracting, and SVM for classi cation. EEG signals are time series signals, which mean that the current samples’ EEG value is related to the values of previous samples and the relationship of EEG signal di ers from one subject to another. Auto-regressive Coe cients (AR) is one of the most widely used pre-processing methods on EEG data. e classical classi er SVM is employed with RNN due to its insensitive to the hyper-parameters and can o set the high sensitive character of RNN.\nAs the rst step of extracting subject-speci c pa erns, the input EEG data E = {Ei , i = 1, 2, · · · ,L◦} ,E ∈ Rne are segmented to di erent fragments. Suppose that E has the shape [p,ne ] where p denotes the rows of input EEG data and ne denotes the number of EEG raw data columns. E can be divided into r fragments with each fragment having the shape [q,ne ], where p = q ∗ r . r denotes the number of fragments in Input EEG data whilst q denotes the number of EEG samples in each fragment (each sample means single row in EEG data). en, the model calculates the auto-regressive coe cients for each column in each fragment (with shape [q, 1]). For instance, if the column is a q-dimension vector [x[1],x[2], · · · ,x[q]], the θ order auto-regressive formula is\nx[q] = θ∑\nh=1 αhx[h] + ε,h = 1, 2, · · · ,θ\nwhere αh denotes the corresponding coe cients of x[h] and ε denotes the constant. Auto-regressive coe cients are calculated following the Burg method [13], where θ auto-regressive coe cients and ε (totally θ +1 coe cients) can represent the original [q, 1] vector. erefore, the original fragment with shape [q,ne ] can be replaced by the AR coe cients fragment with shape [θ + 1,ne ]. Each AR coe cients fragment is considered as an EEG sample to be fed into the RNN model. e AR coe cients matrix data is denoted by C . e RNN in EEG Identi cation Model has the same structure as the RNN model in the Gait Identi cation Model (details in Section 3.3). However, the function of RNN structure in the EEG Identi cation Model is to re ne the feature and extract the useful and dominate features so that the SVM classi er can clearly distinguish them. To distinguish the parameters in two RNN structures, subscript e is added to the EEG Identi cation Model’s RNN parameters. For example, in this RNN model, suppose lre denotes learning rate, bse denotes batch size, λ 7More details about the LSTM structure can be found in h p://colah.github.io/posts/2015-08-Understanding-LSTMs/\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nALGORITHM 2: EEG Identi cation Model Input: EEG raw data E and corresponding parameters p,q,θ , lre ,bse , λ e,nk e ,niter e Output: EEG ID number\n1: for q do 2: Autoregressive Coe cients, C ← E 3: end for 4: while iteration < niter e do 5: for kд ∈ {1, 2, · · · , 7} do 6: Xk e ← f (X1 e ,Wk e(k e+1)) e ,bk e ) 7: Yj e ← arдmax(so f tmax(X7i j e )) 8: end for 9: end while\n10: for Yj e do 11: Linear SVM, EEG ID number← Yj e 12: end for 13: return EEG ID\ndenotes the coe cient of L2 norm, nk e denotes the number of neurons in the ke -th layer and niter e denotes the iterations of learning progress. A linear SVM classi er is employed to classify the subject’s ID number of input EEG data.\nUp to this point, the Decision Making module makes the nal decision based on both the Gait ID and the EEG ID results. e decision of Approval is granted only when the input data successfully pass the Invalid ID Filter and the Gait Identi cation and the EEG Identi cation models identify the subject as the same person. Otherwise, Rejection is declared."
    }, {
      "heading" : "4 EXPERIMENTS AND RESULTS",
      "text" : ""
    }, {
      "heading" : "4.1 Experimental Se ings",
      "text" : "e proposed DeepKey system is trained and evaluated using two public datasets: a Gait dataset and an EEG dataset. Physical ActivityMonitoring Dataset. e Gait data is extracted from a PAMAP2 physical activity monitoring dataset 8 of the UCI Machine Learning Repository. 18 di erent physical activities performed by 9 subjects who wear 3 inertial measurement units (IMUs) and a heart rate monitor. e data are collected with sampling rates of 100Hz from devices deployed over the wrist on the dominant arm, chest and the dominant side’s ankle. Each IMU contains 5 sensors and totally 17 channels: a temperature sensor with 1 channel, two 3D-acceleration sensors with 3 channels each, a 3D-gyroscope sensor with 3 channels, 3D-magnetometer with 3 channels and an orientation sensor with 4 channels. Since most of heart rate data are NaN, we select 3 IMUs with totally 51 channels and 8 subjects, each with 20,000 walking gesture data to evaluate our DeepKey method. EEGMotorMovement/ImageryDataBase. e EEG data used in this paper come from PhysioNet eegmmidb (EEG motor movement/imagery database) dataset 9, which is collected with the BCI2000 (Brain Computer Interface) instrumentation system 10 [41]. e eegmmidb dataset contains around 26.4 million samples collected from 109 subjects and the BCI 2000 system has 64 channels and the sampling rate is 160 Hz. According to the tasks,\n8h ps://archive.ics.uci.edu/ml/datasets/PAMAP2+Physical+Activity+Monitoring 9h ps://www.physionet.org/pn4/eegmmidb/ 10h p://www.schalklab.org/research/bci2000\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\ndi erent annotations are labeled and can be downloaded from PhysioBank ATM. 11 e actions in di erent tasks are as follows:\n• Task 1: A target appears on either the le or the right side of the screen. e subject imagines to open and close the corresponding st as the target appears and disappears. • Task 2: A target appears on either the top or the bo om of the screen. e subject imagines open and\nclose either both sts (if the target is on top) or both feet (if the target is on the bo om) until the target disappears.\nIn these tasks, the condition is labeled as the rest representing the relax state of subjects. 108,000 samples collected in a calm state of 8 subjects, that is, 13,500 for each, are selected for our experiments. Every sample is one list including 64 elements corresponding to 64 channels."
    }, {
      "heading" : "4.2 System Evaluation",
      "text" : "We extensively evaluate the DeepKey system, along with three key components, Invalid ID Filter, Gaid ID Identi cation, and EEG ID Identi cation, respectively.\nGenerally, the reliability and performance of biometric systems are measured by two evaluation standards: False Acceptance Rate (FAR) which means the rate of the system accepting impostors as genuine, and False Rejection Rate (FRR) which means the rate of the system rejecting genuine subjects as impostors. Because of the threshold in the invalid ID lter machine, both FAR and FRR are continuous lines along with the change of threshold. FAR and FRR are calculated as:\nFAR = impostor numbers exceedinд threshold\nall impostor numbers (1)\nFRR = дenuine numbers exceedinд threshold\nall дenuine numbers (2)\nFor instance, assuming that we have 100 impostor samples, 90 of which are classi ed to be impostors while 10 of which are falsely classi ed to be genuine. Similarly, we have 200 genuine samples, 150 of which are classi ed correctly while 50 of which are mistakenly classi ed to be impostors. In this case, FAR = 50/200=0.25 and FRR = 10/100=0.1. e Results of Invalid ID Filter. In the Invalid ID Filter experiment, we select 6 subjects randomly to be genuine subjects and as the training set while the other two to be impostors and as the test set. In our system, the Invalid ID Filter Model of DeepKey achieves an FAR of 0, denoted by PFAR , and a FRR of 0.0036, denoted by PFRR . It should be noted that for a con dential authentication system, FAR is always regarded more important than FRR and the zero FAR means all the invalid subjects can be blocked out by DeepKey. e Results of DeepKey. For the whole system, the subjects passing the Invalid ID Filter are regarded as genuine only if their recognized IDs are consistent, that is, Gait ID = EEG ID. It can be inferred easily that the FAR of DeepKey is 0 as well. However, for FRR, the situation is more complex. e false reject decision depends on one or more of these three components: the false rejection of Invalid ID Filter, the incorrect classi cation of Gait Identi cation, and the incorrect classi cation of EEG Identi cation. For PFRR denotes the Invalid ID Filter’s FRR and PFAR = 0; ¯PFRR denotes the rate of the Invalid ID Filter working correctly, and PGF , PGT , PEF and PET denote the rates of false classi cation of Gait ID, true classi cation of Gait ID, false classi cation of EEG ID and true classi cation of EEG ID, respectively. erefore, the FRR of DeepKey is calculated by\nFRR = PFRR + ¯PFRR × (PGF × PET + PGT × PEF + PGF × PEF ) Another evaluation standard, EER (Equal Error Rate), refers to the point at which the threshold leads to FAR = FRR, which therefore means the biometric system gets the best trade-o between rejection and acceptance. 11h ps://www.physionet.org/cgi-bin/atm/ATM\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\ne lower the EER is, the be er the system achieves. In our system, for FAR remains to be 0, only FAR and a selected FRR are used for evaluation, while existing research use EER together with FRR and FAR as evaluation measurements.\nAll the variables can be found in Table 3. In terms of the performance of the DeepKey system, it obtains the FAR of 0 and the FRR of 0.019, which ensures that the DeepKey system will never grant an incorrect person with authority and the probability of the authorized subjects being blocked out is approximately 0.019. Since DeepKey includes both Gait and EEG Identi cation components, which achieves the accuracy of 0.999 and 0.984, and the overall accuracy of the fusion system is 0.999 × 0.984 ≈ 0.983."
    }, {
      "heading" : "4.3 Comparison",
      "text" : "In this section, we compare the performance of DeepKey with several other classi cation methods. For Gait classi cation, the proposed Gait Identi cation Model includes a 7-layer RNN structure while for EEG classi cation, the EEG Identi cation Model mainly contains Auto-regressive coe cient extraction, feature extraction with RNN and classi cation with SVM. e performance of related approaches are listed in Table 4.\nIn Table 4, XGB means the XGBoosting method [7]. DWT 12 (Discrete Wavelet Transform) is the wavelet transformation with the wavelets discretely sampled. DWT is a data processing method which enables to capture both frequency and time-domain information. AE 13 (Autoencoder) is an unsupervised neural network which is used in feature extraction and generally for dimensionality reduction. DWT(a) means one layer wavelet decomposition while DWT(aa) denotes two layers. Auto denotes auto-regressive coe cients. AR means Autoregressive coe cients and AR (0.5) means there is a 50% overlap in the segmentation of EEG samples. All the methods working on Gait data are evaluated by the same dataset, so as EEG data.\nTable 5 shows the comparison between the state-of-the-art authentication systems. Electrocardiography (ECG) describes the electrical activity of hearts over a period of time. e results show that the Gait Identi cation Model (accuracy of 0.999) and EEG Identi cation (accuracy of 0.984) outperform their counterparts, respectively. e proposed DeepKey authentication system gains the lowest FAR (0) and the acceptable FRR (0.019). Although some literature achieves slightly lower FRR than DeepKey, their FAR is much higher. As mentioned before, FAR has higher signi cance than FRR for a con dential chamber. Overall, DeepKey has be er performance than the state-of-the-art authentication systems.\n12h ps://en.wikipedia.org/wiki/Discrete wavelet transform 13h ps://en.wikipedia.org/wiki/Autoencoder\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017."
    }, {
      "heading" : "4.4 Invalid ID Filter Results",
      "text" : "In this section, gait data, EEG data, and the combination of gait and EEG data from the PAMAP2 and eegmmidb dataset are separately used to train a one-class SVM model. ese lters are called the gait-based lter, the EEG-based lter, and the combined lter, respectively. Still, 6 subjects are regarded as authorized subjects and the other 2 subjects are regarded as invalid subjects. e gait based lter is established with 120,000 training gait samples and 40,000 test gait samples. No sample label is required since one-class SVM classi er is an unsupervised algorithm. To enhance the accuracy and robustness of the classi er, gait samples are separated into di erent gait segments, each segment with 200 continuous samples. All the 120,000 training gait samples are input to the one-class SVM classi er in training stage and 1,000 segments are randomly selected to test the performance in the test stage. e kernel in classi er is set as rbf, дamma = 0.1 and all of other parameters are set as default values but nu. Specially, nu (an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors) is the most signi cant parameter in this classi er because it represents the classi cation threshold. Di erent nu value (from 0.01 to 1) is\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\nFig. 2. The relationship between FRR, the training time and the size of segment 0 1000 2000 3000 4000 5000 The number of test segments\n0 2 4 8 16\nThe number of mini-batches\n0.986\n0.988\n0.99\n0.992\n0.994\n0.996\n0.998\n1\nA c c u\nra c y\nFig. 4. Accuracy of Gait Identification with error bars 0 2 4 8 16 The number of mini-batches\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\n1\nA c c u\nra c y\nFig. 5. Accuracy of EEG Identification with error bars\ntried and the performance shows that the FRR achieves the lowest point 0.0036 when nu = 0.15. For any nu, the FAR always remains at 0. e Invalid ID lter results are shown in Table 6.\nBefore the experiment, two parameters (a number of testing segments and the number of samples in each segment) are pre-trained. Firstly, the number of testing segments is set to be 1,000. Figure 2 illustrates that the larger size of segments leads to lower FRR. However, the larger size requires longer training time. It is easy to observe that the gap is the minimum when the size of segments equals to 200. us we choose 200 samples as a trade-o between FRR and training time. Secondly, the experiment is repeated 5 times with the number of testing segments is 1,000, 2,000, 3,000, and 4,000, respectively. e error bars are shown in Figure 3. Finally, 1,000 test segments, each with 200 samples, are utilized to run the Invalid ID Filter Model. It should be noted that the default size of segments, 200, is the trade-o value in this paper but may not be the optimal values in practice. e training time has less e ect on the running time while DeepKey works on-line. e EEG-based lter and the combined lter are built in the same way. While the number of segments is 1,000 and the number of samples in each segment from 200 to 600, the results of three lters are listed in Table 7 . Clearly, FAR is 0 for all the three lters and the FRR of the gait-based lter is hundreds of times of the FRR of the EEG-based and the combined lter, which is why we choose the gait-based lter as the Invalid ID Filter.\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017."
    }, {
      "heading" : "4.5 Gait Identification Results",
      "text" : "In this section, Gait Identi cation Model is evaluated by 160,000 gait samples from 8 subjects as mentioned before. e gait data are normalized before input to the model. In this speci c experiment, 160,000 samples are randomly divided into 8 mini-batches and each mini-batch has 20,000 samples for test. 7 mini-batches (140,000 samples) are trained as the training set and another mini-batch (20,000 samples) is treated as the test set. All the samples are randomly allocated both in training and test sets. Every single mini-batch is in the shape of [20000, 1, 51] so that the rst layer of RNN structure has 51 nodes for there are 51 input features. e Gait ID (from 0 to 7) of the subject is regarded as labels. e one-hot label is deployed and each label is a list of 8 elements. e output of RNN model should have the shape of [20000, 8], which means that the output layer has 8 output features and the output layer (7-th layer) has 8 nodes. Every other layer has 32 nodes and the lambda is set as 0.001 while learning rate is set as 0.001. e Orthogonal Array Experiment Method, which is widely used to tuning hyper-parameters in experiment designs, is a statistically structured experiment in which several factors are applied to each experimental unit at varying levels. Range analysis on the results of experiments helps to optimize the factors and levels. All the hyper-parameters are selected by the Orthogonal Array Experiment Method [30].\nInitially, the input mini-batch data have the shape of [20000, 1, 51] and are reshaped to be a 2-D matrix ([20000, 51]) for the multiplication operation. e 2-D matrix multiplies with the weight between the rst and the second layer (with the weights in the shape of [51, 32] where 32 is the number of nodes in the second layer), and then add the biases ([1, 32]) in the rst layer. e produced matrix with shape [20000, 32] is the data in the second layer. Similarly, the data in the second layer stream to the third layer and get the data in the third layer. At last, the 7-th layer outputs the predict one-hot label with shape [2000, 8].\nTo explore the optimal number of mini-batches, the experiment is repeated 5 times with the number of the mini-batch as 2, 4, 8, and 16. e error bars are shown in Figure 4, which shows the Gait Identi cation Model is stable at the accuracy of 0.999 = 19, 980/20, 000 on the classi cation of 20,000 samples. e confusion matrix is shown in Table 8, where the lowest precision is 0.9964 and the lowest recall is 0.9968. e de nitions of Recall and Precision are given as follows:\nRecall = TP\nTP + FN\nPrecision = TP\nTP + FP\nwhere TP means true positives, FN means false negatives while FP means false positives.\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017."
    }, {
      "heading" : "4.6 EEG Identification Results",
      "text" : "We set the segment window of the EEG input data as 90 samples without overlapping. erefore, each subject (13,500 samples) has 150 = 13, 500/90 segments and there are totally 1, 200 segments for all the 8 subjects. e segments are labeled from 0 to 7 to indicate the order of each subject, forming a total of 1, 200 labels.\nA er the segmentation, the data has the shape of [1200, 90, 64], that is, 1,200 segments where each segment has 90 rows and each row has 64 features. e segments will be processed by auto-regressive before being used for RNN feature extraction. e autoregressive coe cients are extracted by the statsmodels .tsa.ar model .AR package. 14 e autoregressive coe cients extraction is implemented on each column in each segment with all the parameters set as default values. e pre-processed sequence has 90 elements and the auto-regressive order is 12; therefore, totally 13 coe cients (constant coe cient is added) are produced for each column in each segment. Finally, we get the auto-regressive coe cients with shape [1200, 13, 64] and the coe cients are regarded as the input EEG data of RNN feature extraction. 14h p://www.statsmodels.org/devel/generated/statsmodels.tsa.ar model.AR.html\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\ne structure of RNN feature extraction section is described in Section 3.4. e RNN model contains 7 layers. e input layer has 64 nodes since each segment of the auto-regressive coe cients has 64 features. We use the subject ID as the training label, where the ID label (from 0 to 7) is represented as one-hot label vector. One-hot refers to a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0). erefore, the output layer (7-th layer) contains 8 nodes. e 1,200 segments from 8 subjects are randomly split into 8 mini-batch (7 mini-batch as the training dataset and 1 as the testing dataset) and each mini-batch has the shape of [150, 13, 64]. For the other 5 layers in RNN, each layer has 64 nodes. e lambda is set as 0.004 while learning rate is set as 0.005. Similar with the parameters tuning in Section 4.5, all the hyper-parameters are selected by the Orthogonal Array Experiment Method. e SVM classi er takes the features extracted by RNN as the input. e random state is set as 0 and other parameters set as default. We explore the performance of two classi ers: RNN and SVM, while the input data is re ned by RNN structure. For a mini-batch with 150 segments, in RNN, the input EEG data (with the shape of [150, 13, 64]) ow through 7 layers RNN model and produce the ID results (with shape [150, 8]); for SVM, the input EEG data (with the shape of [150, 13, 64]) is passed through the rst 6 layers of RNN structure and produce the re ned feature with the shape of [150, 13, 64] (the 6-th layer has 64 nodes), and then the re ned feature enters the SVM classi er and produces the ID results with the shape of [150, 1].\nTo explore the optimal number of mini-batches, the experiment is repeated 5 times with the number of the mini-batch set to 2, 4, 8, and 16, respectively. e error bars are shown in Figure 5. e results show the highest accuracy classi cation of the EEG ID from 8 subjects achieves 0.9841 when the number of mini-batches equals to 7. e SVM classi er works on 150 test segments and 149 among of them are classi ed correctly. e confusion matrix is shown in Table 9."
    }, {
      "heading" : "5 CONCLUSION AND FUTURE WORK",
      "text" : "Taking the advantages of both gait- and EEG-based systems for fake-resistance, we propose Deepkey, a multimodal biometric authentication system, to overcome the limitations of traditional unimodal biometric authentication systems. is authentication system contains three independent models: an Invalid ID Filter Model, a Gait Identi cation Model, and an EEG Identi cation Model, to detect invalid gait data, recognize the Gait ID and the EEG ID, respectively. All the three models can be pre-trained e ciently o -line as the number of authorized subjects is usually limited. In particular, the Invalid ID Filter Model employs a one-class SVM to recognize invalid gait signals and achieves a FRR of 0.0036 and a FAR of 0. e Gait Identi cation Model adopts a 7-layer deep learning model to process gait data and classify subjects’ IDs, achieving an accuracy of 0.999. e EEG Identi cation Model combines three components (auto-regressive coe cients, the RNN structure, and an SVM classi er) and achieves the accuracy of 0.9841 on a public dataset. Overall, the DeepKey authentication system obtains a FAR of 0 and a FRR of 0.019. is work sheds the light on further research on multimodal biometric authentication systems based on the gait and EEG data. Our future work will focus on enhancing the performance of the invalid ID lter component. In addition, the gait signals currently are gathered by three wearable IMUs, which may obstruct the large scale deployment in industry. erefore, another direction is to collect gait data from non-wearable gait solutions (e.g., sensors deployed in environments).\nACKNOWLEDGMENTS\nREFERENCES [1] Salahiddin Altahat, Girija Che y, Dat Tran, and Wanli Ma. 2015. Analysing the Robust EEG Channel Set for Person Authentication. In\nInternational Conference on Neural Information Processing. Springer, 162–173. [2] Corey Ashby, Amit Bhatia, Francesco Tenore, and Jacob Vogelstein. 2011. Low-cost electroencephalogram (eeg) based authentication. In\nNeural Engineering (NER), 2011 5th International IEEE/EMBS Conference on. IEEE, 442–445.\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\n[3] Md Khayrul Bashar, Ishio Chiaki, and Hiroaki Yoshida. 2016. Human identi cation from brain EEG signals using advanced machine learning method EEG-based biometrics. In Biomedical Engineering and Sciences (IECBES), 2016 IEEE EMBS Conference on. IEEE, 475–479. [4] Jorge Blasco, omas M Chen, Juan Tapiador, and Pedro Peris-Lopez. 2016. A Survey of Wearable Biometric Recognition Systems. ACM Computing Surveys (CSUR) 49, 3 (2016), 43. [5] Nikolaos V Boulgouris, Dimitrios Hatzinakos, and Konstantinos N Plataniotis. 2005. Gait recognition: a challenging signal processing technology for biometric identi cation. IEEE Signal Processing Magazine 22, 6 (2005), 78–90. [6] Michele L Callisaya, Leigh Blizzard, Michael D Schmidt, Jennifer L McGinley, Stephen R Lord, and Velandai K Srikanth. 2009. A population-based study of sensorimotor factors a ecting gait in older people. Age and ageing 38, 3 (2009), 290–295. [7] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 785–794. [8] John Chuang, Hamilton Nguyen, Charles Wang, and Benjamin Johnson. 2013. I think, therefore i am: Usability and security of authentication using brainwaves. In International Conference on Financial Cryptography and Data Security. Springer, 1–16. [9] Guglielmo Cola, Marco Avvenuti, Fabio Musso, and Alessio Vecchio. 2016. Gait-based authentication using a wrist-worn device. In Proceedings of the 13th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services. ACM, 208–217. [10] John G Daugman. 1993. High con dence visual recognition of persons by a test of statistical independence. IEEE transactions on pa ern analysis and machine intelligence 15, 11 (1993), 1148–1161. [11] Mohammad Derawi and Iurii Voitenko. 2014. Fusion of gait and ECG for biometric user authentication. In Biometrics Special Interest Group (BIOSIG), 2014 International Conference of the. IEEE, 1–4. [12] Hassen Drira, Boulbaba Ben Amor, Anuj Srivastava, Mohamed Daoudi, and Rim Slama. 2013. 3D face recognition under expressions, occlusions, and pose variations. IEEE Transactions on Pa ern Analysis and Machine Intelligence 35, 9 (2013), 2270–2283. [13] Modern Spectral Estimation. 1988. eory and Application. Bock, HG, Carra (1988). [14] Geof H Givens, J Ross Beveridge, Yui Man Lui, David S Bolme, Bruce A Draper, and P Jonathon Phillips. 2013. Biometric face recognition:\nfrom classical statistics to future challenges. Wiley Interdisciplinary Reviews: Computational Statistics 5, 4 (2013), 288–308. [15] Steven Goldstein. 2016. Methods and systems for voice authentication service leveraging networking. (March 8 2016). US Patent\n9,282,096. [16] Yu Guan, Chang-Tsun Li, and Fabio Roli. 2015. On reducing the e ect of covariate factors in gait recognition: a classi er ensemble\nmethod. IEEE transactions on pa ern analysis and machine intelligence 37, 7 (2015), 1521–1528. [17] Qiong Gui, Zhanpeng Jin, and Wenyao Xu. 2014. Exploring EEG-based biometrics for user identi cation and authentication. In Signal\nProcessing in Medicine and Biology Symposium (SPMB), 2014 IEEE. IEEE, 1–6. [18] Ana M Guzman, Mohammed Goryawala, Jin Wang, Armando Barreto, Jean Andrian, Naphtali Rishe, and Malek Adjouadi. 2013. ermal\nimaging as a biometrics approach to facial signature authentication. IEEE journal of biomedical and health informatics 17, 1 (2013), 214–222. [19] Tin Kam Ho. 1998. e random subspace method for constructing decision forests. IEEE transactions on pa ern analysis and machine intelligence 20, 8 (1998), 832–844. [20] ang Hoang and Deokjai Choi. 2014. Secure and privacy enhanced gait authentication on smart phone. e Scienti c World Journal 2014 (2014). [21] Baoqi Huang, Guodong Qi, Xiaokun Yang, Long Zhao, and Han Zou. 2016. Exploiting cyclic features of walking for pedestrian dead reckoning with unconstrained smartphones. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 374–385. [22] Isuru Jayarathne, Michael Cohen, and Senaka Amarakeerthi. 2016. BrainID: Development of an EEG-based biometric authentication system. In Information Technology, Electronics and Mobile Communication Conference (IEMCON), 2016 IEEE 7th Annual. IEEE, 1–6. [23] Sarineh Keshishzadeh, Ali Fallah, and Saeid Rashidi. 2016. Improved EEG based human authentication system on large dataset. In Electrical Engineering (ICEE), 2016 24th Iranian Conference on. IEEE, 1165–1169. [24] Ne ssa Khiari-Hili, Christophe Montagne, Sylvie Lelandais, and Kamel Hamrouni. 2016. ality dependent multimodal fusion of face and iris biometrics. In Image Processing eory Tools and Applications (IPTA), 2016 6th International Conference on. IEEE, 1–6. [25] Shinsuke Konno, Yoshitaka Nakamura, Yoh Shiraishi, and Osamu Takahashi. 2015. Gait-based authentication using trouser front-pocket sensors. (2015). [26] Pavan K Kumar, PESN Krishna Prasad, MV Ramakrishna, and BDCN Prasad. 2013. Feature extraction using sparse SVD for biometric fusion in multimodal authentication. International Journal of Network Security & Its Applications 5, 4 (2013), 83. [27] Worapan Kusakunniran, Qiang Wu, Jian Zhang, Hongdong Li, and Liang Wang. 2014. Recognizing gaits across views through correlated motion co-clustering. IEEE Transactions on Image Processing 23, 2 (2014), 696–709. [28] Worapan Kusakunniran, Qiang Wu, Jian Zhang, Yi Ma, and Hongdong Li. 2013. A new view-invariant feature for cross-view gait recognition. IEEE Transactions on Information Forensics and Security 8, 10 (2013), 1642–1653. [29] Neal S Latman and Emily Herb. 2013. A eld study of the accuracy and reliability of a biometric iris recognition system. Science & Justice 53, 2 (2013), 98–102.\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017.\n[30] Xiangtao Li, Jianan Wang, and Minghao Yin. 2014. Enhancing the performance of cuckoo search algorithm using orthogonal learning method. Neural Computing and Applications 24, 6 (2014), 1233–1247. [31] Tran Long, Le ai, and Tran Hanh. 2012. Multimodal biometric person authentication using ngerprint, face features. PRICAI 2012: Trends in Arti cial Intelligence (2012), 613–624. [32] Dario Maio, Davide Maltoni, Ra aele Cappelli, James L Wayman, and Anil K Jain. 2002. FVC2002: Second ngerprint veri cation competition. In Pa ern recognition, 2002. Proceedings. 16th international conference on, Vol. 3. IEEE, 811–814. [33] Ju Man and Bir Bhanu. 2006. Individual recognition using gait energy image. IEEE transactions on pa ern analysis and machine intelligence 28, 2 (2006), 316–322. [34] BE Manjunathswamy, Appaji M Abhishek, J riveni, KR Venugopal, and LM Patnaik. 2015. Multimodal biometric authentication using ECG and ngerprint. International Journal of Computer Applications 111, 13 (2015). [35] Sebastien Marcel and José del R Millán. 2007. Person authentication using brainwaves (EEG) and maximum a posteriori model adaptation. IEEE transactions on pa ern analysis and machine intelligence 29, 4 (2007). [36] Sarah Mennicken, Oliver Zihler, Frida Juldaschewa, Veronika Molnar, David Aggeler, and Elaine May Huang. 2016. It’s like living with a friendly stranger: perceptions of personality traits in a smart home. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 120–131. [37] Daigo Muramatsu, Akira Shiraishi, Yasushi Makihara, Md Zasim Uddin, and Yasushi Yagi. 2015. Gait-based person recognition using arbitrary view transformation model. IEEE Transactions on Image Processing 24, 1 (2015), 140–154. [38] Mark Nixon and others. 2009. Model-based gait recognition. (2009). [39] Jaishanker K Pillai, Maria Puertas, and Rama Chellappa. 2014. Cross-sensor iris recognition through kernel learning. IEEE transactions\non pa ern analysis and machine intelligence 36, 1 (2014), 73–85. [40] Fahreddin Sadikoglu and Selin Uzelaltinbulat. 2016. Biometric Retina Identi cation Based on Neural Network. Procedia Computer\nScience 102 (2016), 26–33. [41] Gerwin Schalk, Dennis J McFarland, ilo Hinterberger, Niels Birbaumer, and Jonathan R Wolpaw. 2004. BCI2000: a general-purpose\nbrain-computer interface (BCI) system. IEEE Transactions on biomedical engineering 51, 6 (2004), 1034–1043. [42] Torkjel Søndrol. 2005. Using the human gait for authentication. Master’s thesis. [43] Rupali L Telgad, PD Deshmukh, and Almas MN Siddiqui. 2014. Combination approach to score level fusion for Multimodal Biometric\nsystem by using face and ngerprint. In Recent Advances and Innovations in Engineering (ICRAIE), 2014. IEEE, 1–8. [44] Kavitha P omas and AP Vinod. 2016. Utilizing individual alpha frequency and delta band power in EEG based biometric recognition.\nIn Systems, Man, and Cybernetics (SMC), 2016 IEEE International Conference on. IEEE, 004787–004791. [45] Kavitha P omas and AP Vinod. 2017. EEG-Based Biometric Authentication Using Gamma Band Power During Rest State. Circuits,\nSystems, and Signal Processing (2017), 1–13. [46] JA Unar, Woo Chaw Seng, and Almas Abbasi. 2014. A review of biometric technology along with trends and prospects. Pa ern\nrecognition 47, 8 (2014), 2673–2688. [47] Chen Wang, Junping Zhang, Liang Wang, Jian Pu, and Xiaoru Yuan. 2012. Human identi cation using temporal information preserving\ngait template. IEEE Transactions on Pa ern Analysis and Machine Intelligence 34, 11 (2012), 2164–2176. [48] Wei Wang, Alex X Liu, and Muhammad Shahzad. 2016. Gait recognition using wi signals. In Proceedings of the 2016 ACM International\nJoint Conference on Pervasive and Ubiquitous Computing. ACM, 363–373. [49] Zifeng Wu, Yongzhen Huang, Liang Wang, Xiaogang Wang, and Tieniu Tan. 2017. A comprehensive study on cross-view gait based\nhuman identi cation with deep cnns. IEEE transactions on pa ern analysis and machine intelligence 39, 2 (2017), 209–226. [50] Vitor Yano, Alessandro Zimmer, and Lee Luan Ling. 2012. Multimodal biometric authentication based on iris pa ern and pupil light\nre ex. In Pa ern Recognition (ICPR), 2012 21st International Conference on. IEEE, 2857–2860. [51] Lina Yao, Feiping Nie, an Z Sheng, Tao Gu, Xue Li, and Sen Wang. 2016. Learning from less for be er: semi-supervised activity\nrecognition via shared structure discovery. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 13–24. [52] Sha Zhao, Julian Ramos, Jianrong Tao, Ziwen Jiang, Shijian Li, Zhaohui Wu, Gang Pan, and Anind K Dey. 2016. Discovering di erent kinds of smartphone users through their application usage behaviors. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 498–509. [53] Hailing Zhou, Ajmal Mian, Lei Wei, Doug Creighton, Mo Hossny, and Saeid Nahavandi. 2014. Recent advances on singlemodal and multimodal face recognition: A survey. IEEE Transactions on Human-Machine Systems 44, 6 (2014), 701–716.\nACM J. Comput. Cult. Herit., Vol. 9, No. 4, Article 39. Publication date: March 2017."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "Biometric authentication involves various technologies to identify individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, biometric authentication systems (e.g., face recognition, iris, retina, voice, and ngerprint) are increasingly facing the risk of being tricked by biometric tools such as anti-surveillance masks, contact lenses, vocoders, or ngerprint lms. In this regard, we design a multimodal biometric authentication system named DeepKey which uses both gait and Electroencephalography (EEG) signals to provide beer protection against such risks. DeepKey consists of three key components: an Invalid ID Filter Model to block invalid subjects, a Gait Identication Model to recognize Gait IDs and an EEG Identication Model to recognize EEG IDs. In particular, the rst two models employ a one-class SVM algorithm and a Recurrent Neural Network based deep learning model, respectively. e third model combines autoregressive coecients, an RNN structure, and an SVM classier. DeepKey is trained with a gait dataset of 160,000 samples and an EEG dataset of 108,000 samples. Experimental results show DeepKey outperforms a series of comparison methods and achieves an overall accuracy of 0.983 along with an overall false acceptance rate (FAR) of 0.0 and a false rejection rate (FRR) of 0.019.",
    "creator" : "LaTeX with hyperref package"
  }
}