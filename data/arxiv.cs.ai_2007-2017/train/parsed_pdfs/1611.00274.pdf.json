{
  "name" : "1611.00274.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Detecting Affordances by Visuomotor Simulation",
    "authors" : [ "Wolfram Schenck", "Hendrik Hasenbein", "Ralf Möller" ],
    "emails" : [ "wolfram.schenck@fh-bielefeld.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "a cognitive architecture for the detection of affordances in the visual modality. This model is based on the internal simulation of movement sequences. For each movement step, the resulting sensory state is predicted by a forward model, which in turn triggers the generation of a new (simulated) motor command by an inverse model. Thus, a series of mental images in the sensory and in the motor domain is evoked. Starting from a real sensory state, a large number of such sequences is simulated in parallel. Final affordance detection is based on the generated motor commands. We apply this model to a real–world mobile robot which is faced with obstacle arrangements some of which are passable (corridor) and some of which are not (dead ends). The robot’s task is to detect the right affordance (“pass–through–able” or “non–pass–through–able”). The required internal models are acquired in a hierarchical training process. Afterwards, the robotic agent is able to distinguish reliably between corridors and dead ends. This real–world result enhances the validity of the proposed mental simulation approach. In addition, we compare several key factors in the simulation process regarding performance and efficiency.\nFunding statement: This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.\nar X\niv :1\n61 1.\n00 27\n4v 1\n[ cs\n.A I]"
    }, {
      "heading" : "1 Introduction",
      "text" : "The term “mental imagery” describes the process of activating sensory and/or motor representations within the cognitive system of an agent without actual sensory inflow and without actually executing motor actions. Introspective experience suggests that humans are able to generate mental images, and neuroimaging studies have shown that these mental images have neural correlates in the corresponding cortical areas which are usually involved in visual and motor processing (Jeannerod, 2001; Kosslyn et al., 1993). One commonly accepted function of mental imagery is the mental practice of movement tasks, e.g. in sports (Martin et al., 1999) or rehabilitation (Jackson et al., 2001).\nWe suggest that mental imagery — at the subconscious level — could be the basis for the detection of affordances (Gibson, 1979) in visual perception. Affordances are the behavior–related properties of entities in an agent’s environment; for example, surfaces can be “stand-on-able”, “climb-on-able”, or “sit-on-able”. Accordings to Gibson (Gibson, 1979; Norman, 2002), visual perception means to directly perceive these behavioral meanings by picking up certain “invariants” from the visual information, and through active exploration of the environment without preceding object recognition. Quite the contrary, the object is “recognized” by its affordances. Our approach closely follows these lines of thought, however, the active exploration of the environment is replaced by an internal simulation of movement sequences in which mental images of sensory states and motor commands are generated: The sensory outcome in these simulated sequences is evaluated to guide the simulation process, and a final set of movement sequences serves to determine the behavioral meaning. In the end, object recognition is based on the internally generated motor commands (and optionally on the evaluation of the predicted sensory states) and not on sensory features (even though low–level features may be used in the simulation). This approach has been termed “perception through anticipation” (PtA) in previous publications (e.g., Möller, 1999). It replaces the rather vague statements of Gibson’s theory on how affordances are detected by a clearly described computional mechanism.\nDuring the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009). For example, Hesslow (2002) argued that thinking consists of a simulated interaction with the environment, and Grush (2004) suggested the “emulation theory of representation” which links imagery and perception to motor simulation (see also Jeannerod, 2001). Marques and Holland (2009) analyzed the necessary and sufficient requirements for cognitive architectures which are based on internal simulation: Such systems have to be capable of holding covert motor states and internally generated sensory states (i.e., mental imagery), they have to be able to predict future sensory states, and they require goals and mech-\nanisms for the evaluation of sensory states and for action selection (see also Hesslow, 2002). In consequence, the whole simulation approach rests on the assumption that the human cognitive system fulfills these preconditions, and any computational model from this area has to meet these requirements. This is the case for the PtA approach. Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008).\nIn the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands.\nLinking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999).\nRelated studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al. (1999) and Hoffmann (2007) are especially close to our own work: Gross et al. (1999) trained a robotic agent to predict the optical flow caused by self–motion, and by this predictive ability the system could generate collision-free movement sequences. The mobile robot system developed by Hoffmann (2007) could even predict how the whole image of an obstacle arrangement would look like after a movement (although these images were of rather small size). Based on this ability, dead ends and corridors were distinguished by internal simulation. Our own work goes beyond these approaches by using more complex scenarios, a hierarchical learning approach, and by putting a strong emphasis on the question of how to generate movement\nsequences during internal simulation in an effective way. Our cognitive architecture has already been tested in a pure simulation study (Möller and Schenck, 2008). The achievement of the present work is to demonstrate that dead end recognition in the real world with a real robot setup can be successfully implemented based on the same principles, enhancing the validity of the overall approach. Furthermore, we extend our previous work by a more thorough experimental analysis in which we consider, for example, different types of inverse models.\nThe remainder of this article is organized as follows: In Sect. 2, robot setup and image processing are described, Sect. 3 explains the computational model and its components, Sect. 4 the experimental study and its results, and Sect. 5 contains the discussion."
    }, {
      "heading" : "2 Setup and Image Processing",
      "text" : ""
    }, {
      "heading" : "2.1 Setup",
      "text" : "The mobile robot in this study is based on the Pioneer 3DX platform. The mounted camera records images from a mirror surface which reflects a complete 360◦–view of the environment (Fig. 1). These images are unfolded to show a horizontal panoramic view. Afterwards, the obstacles within an arrangement are detected through color segmentation\nand some filtering rules (second row in Fig. 1). The obstacle colors are either yellow, green, or red. The obstacles have a diameter of 40 cm (roughly the same as the robot) and a height of 30 cm. The obstacle arrangements can extend over an area up to the size of 3 × 4 m. Beyond this distance, the resolution of the camera is not sufficient for reliable obstacle identification. An exemplary obstacle arrangement in our laboratory is shown in the upper middle of Fig. 1.\nThe final sensory features are the width, the horizontal position, and the vertical offset of each obstacle i: si,t = (wi,t, xi,t, yi,t) in time/simulation step t. Furthermore, the height hi of each obstacle i is recorded in the beginning of movement sequences for the correction of the sensory state (see Sect. 2.2.2). The overall sensory state st is a collection of the vectors si,t for all detected obstacles. For the movements mt the robot has three different commands available: It can either move forward by ca. 10 cm, or it can rotate left or right by ca. 15 degrees."
    }, {
      "heading" : "2.2 Image Processing",
      "text" : ""
    }, {
      "heading" : "2.2.1 General Processing",
      "text" : "The camera images of the robot have PAL resolution (720×576 pixels). They are slightly denoised and unfolded by a polar mapping to a horizontal panoramic view with a size of wIM × hIM pixels (with wIM = 1571 and hIM = 214). In this horizontal panoramic view, the obstacles are identified by color segmentation based on saturation and hue in the HSV color space. During segmentation, the leftmost and rightmost image columns are handled as if they were directly neighboured, i. e. the panoramic image is closed horizontally. All segments below the horizon, with a minimum fill ratio (number of colored pixels devided by area of bounding box larger than 0.4), and with a minimum area (150 pixels) are included in the set of detected obstacles."
    }, {
      "heading" : "2.2.2 Correction of Sensory States",
      "text" : "Specific problems arise if obstacles partly occlude each other. In theory, the upper part of the rear obstacle should be fully visible because the height of the obstacles was chosen such that they appear completely below the horizon in the panoramic images. However, for far–away objects this is not always the case: If two obstacles are close to each other, the upper part of the rear obstacle might cover only one row of pixels which is easily destroyed during denoising and color segmentation. In such a case, the rear obstacle appears as if\nit was much slimmer than it is in reality. This is illustrated in Fig. 3. The red obstacle marked with an arrow appears far too small in the processed image. Because the obstacle width is an important indicator of its distance to the robot, this is a fatal misperception. For this reason, we incorporated a correction step which adjusts wi based on yi and hi because these three parameters encode the distance between robot and obstacle in a redundant way.\nThis correction is based on an analysis of the images which were collected as training data for the visual forward model (see Sect. 3.2). Overall, 13, 000 obstacles were recorded in these images, all of them completely visible; color and position relative to the robot were partly systematically, partly randomly varied. Fig. 4 depicts the relationships between vertical offset y, height h, and width w for the corresponding 13, 000 segments. First of all, the data is devided into two parts based on the relationship between y und h (uppermost plot in Fig. 4): Segments with small y values (y ≤ 135, red dots) are far away from the robot’s chassis and fully visible while segments with large y values (y > 135, green dots) are close to the robot and partly hidden by its chassis. For this reason, with\nincreasing y values (robot gets closer) h increases first and then starts to decrease as soon as the robot’s chassis begins to hide part of the obstacle.\nFor each part of the data both the relationships between h and w and between y and w (lower left and right plot in Fig. 4) are close to linear. For this reason, linear models incorporating y and h were fitted to these data points:\nŵ = 2.12y + 1.35h− 197.6 , y ≤ 135 (R2 = 0.97) ŵ = 3.53y − 0.039h− 291.4 , y > 135 (R2 = 0.80)\nBased on these models, the corrected width value w̃ is computed by w̃ = (w + ŵ)/2, giving half weight to the original value and half weight to the estimation based on y and h. Afterwards, the y value is adjusted to match the new width value w̃:\nỹ = 0.265w̃ + 87.0 (1)\nThis linear model was obtained from the combined data (see lower right plot in Fig. 4; R2 = 0.98). In this way, the corrected sensory state s̃i,0 = (w̃i,0, xi,0, ỹi,0) for each obstacle i in the first time step of a simulated movement sequence is obtained (directly after acquisition of the initial real camera image). Note that this correction is only applied at the start of long–term simulations (Sect. 3.4), but neither on the training data for the visual forward model (Sect. 3.2) nor while generating training data through short–term simulation for the inverse model (Sect. 3.3)."
    }, {
      "heading" : "3 Computational Model",
      "text" : ""
    }, {
      "heading" : "3.1 Overview",
      "text" : "The main components of the computational architecture are adaptive forward and inverse models (FMs and IMs). The visual FM predicts for each obstacle the change ∆ŝi of its sensory state from the previous sensory state si,t and a motor commandmt. The estimated new sensory state ŝi,t+1 is computed by ŝi,t+1 = si,t + ∆ŝi. The overall prediction ŝt+1 is composed from the single predictions ŝi,t+1. The visual FM is acquired by collecting a large amount of training data from random movements of the robot with obstacles placed systematically at different distances. The tactile FM predicts if a collision with an obstacle would occur given si,t and the scheduled motor command mt. The evaluation system of the cognitive architecture takes only the tactile events into account: Collisions are bad, sensory states without collision are good.\nThe IM generates motor commands mt in response to a wholistic sensory input. This input is a variation of the image shown in the second row of Fig. 1: All obstacles appear – regardless of their original color – as white filled circles on a black background (topmost image in Fig. 6). The purpose of this processing step is to enable the generation of these wholistic images during the internal simulation when only the predictions\nof the visual FM are available and not a real segmented panoramic image. The IM is adapted to a movement strategy which favors forward movements as long as possible and turns in the appropriate direction when obstacles appear in the vicinity of the robot. Training data for the IM is generated by internal short–term simulations based on the already trained FMs, starting from several different real–world situations. These simulations reveal which movement sequence would result in the least curved trajectory without collisions. The first movement of this sequence is the motor output mt which is linked to the wholistic sensory state of the initial real–world situation. A large number of such learning examples is used to train the IM. An important conceptual aspect of this procedure is that the predictive abilities of the agent have to be already available when motor training starts, because this training is based on internal simulation and mental imagery.\nAfter both FMs and the IM are trained, long–term internal simulations can be carried out which are guided by the motor commands from the IM. In this iterative long–term simulation, predictions by the FMs generate new sensory states which trigger new motor commands from the IM which in turn lead to new predictions (see Fig. 7). To classify an obstacle arrangement, the robot first processes the real visual input to detect the image features (obstacles) si,0. Starting from s0, several long-term simulations are carried out. If the motor commands in any of the generated movement sequences indicate that a passage is possible, this arrangement is classified as corridor, otherwise as dead end. Thus, the final recognition of the behavioral meaning is purely based on the motor commands in the simulated movement sequences."
    }, {
      "heading" : "3.2 Forward Models",
      "text" : ""
    }, {
      "heading" : "3.2.1 Visual Forward Model",
      "text" : "For the visual FM, ca. 13, 000 learning examples were collected in 120 random motor sequences with an average length of 55 steps. The distance between robot and obstacles and the initial orientation of the robot were varied systematically between sequences. A maximum number of two obstacles was used in each sequence. Each learning example has the structure [(si,t,mt) −→ ∆si] with ∆si = si,t+1− si,t. The training set for forward movements consists of ca. 6300 learning examples, for left rotations of ca. 3100 examples, and for right rotations of ca. 3600 examples.\nWe tested different implementations for the visual FM (e.g., multi–layer perceptron; Rumelhart et al., 1986), but in the end the best results were obtained by fitting analytical functions to the training data. For rotations, the output of the visual FM is constant:\n∆sleft = (∆wleft,∆xleft,∆yleft) = (0, 60, 0)\n∆sright = (∆wright,∆xright,∆yright) = (0,−60, 0)\nThis simple approach already provides a good fit to the data; it means that rotation commands to the robot are executed as nearly pure rotations on the spot. However, the data\nalso shows that the robot does not turn by ±15 degrees as commanded, but just by ±13.7 degrees (60/wIM · 360◦ ≈ 13.7◦).\nFor forward movements, the following functions were fitted to the data:\n∆wforw = cos\n( 2πx\nwIM\n)( 0.00501y2 − 0.482y ) ∆xforw = sin ( 2πx\nwIM\n)( 0.00555y2 − 0.473y ) (2)\n∆yforw = cos\n( 2πx\nwIM\n)( 0.00123y2 − 0.118y ) (3)\nwith w, x, y being components of si,t. Figure 5 shows the underlying data points and the fitted functions for ∆xforw and ∆yforw. The output of the visual FM for forward movements is ∆sforw = (∆wforw,∆xforw,∆yforw).\nTo test the visual FM, the 120 random motor sequences for the collection of training data were used again. The FM had to iteratively predict the sensory state for each obstacle in the data (iteratively means here that the input of the FM in each movement step is identical to the output of the FM from the previous step, except for the very first step in which real data is fed into the FM). After 50 movement steps, the result of the iterative prediction was compared to the real sensory state. The average prediction error for x amounted to 35.5 pixels, for y to 4.75 pixels, and for w to 17.0 pixels (for x and y, this corresponds to a single–step error of ca. 0.05% relative to wIM/hIM, for w to ca. 0.13% relative to the maximum segment width in the training data). For an iterative prediction over 50 steps, this is a well acceptable performance."
    }, {
      "heading" : "3.2.2 Correction Step",
      "text" : "Although the visual FM predicts on average with good precision, it exhibits an undesired extrapolation behavior for far–away obstacles close to the horizon. It was observed in long–term simulations (see Sect. 3.4) that such objects move away from the robot during forward movements and become larger at the same time. To suppress this unnatural behavior, the predicted width ŵ is used to correct the predicted vertical offset ŷ and vice versa (the obstacle and time step indices are left out here for simplicity). This correction is based on the linear model in (1) which represents the relationship between w and y for observed obstacles. If the relationship between ŵ and ŷ starts to deviate from this model, this is a clear sign that predictions get into an uncontrolled extrapolation area. To stop this extrapolation, ŵ and ŷ are corrected by the linear model:\nŵ′ = 3.68ŷ − 318.2 (inverse of (1)) ŵcorr = (ŵ + ŵ ′)/2\nŷcorr = 0.265ŵcorr + 87.0\nŵcorr and ŷcorr are the corrected predictions which replace the original ones in further calculations. The original values ŵ and ŷ get the same weight as information sources in the correction process. Note that this additional correction stage is only applied for internal long–term simulations (Sect. 3.4) and not in any other part of this study.\nWith enabled correction stage, the average errors after 50 iterative predictions change slightly: The average prediction error for x amounts to 40.6 pixels, for y to 4.16 pixels, and for w to 16.3 pixels. Compared with prediction without correction, the results for x get slightly worse while they improve for y and w. The latter improvement seems to be crucial to stabilize long–term simulations."
    }, {
      "heading" : "3.2.3 Tactile Forward Model",
      "text" : "Because the robot lacks a tactile sensor, collisions are detected by estimating the obstacle distance from the visual data; if an obstacle is too close, this is interpreted as collision. We decided to define a virtual bumper ring around the robot with a diameter of 60 cm. At a distance of 30 cm to the robot’s center, obstacles appear in the panoramic image as\nsegments with a width of 215 pixels. For this reason, the tactile FM signals a collision if any prediction ŵi,t by the visual FM is larger than this value."
    }, {
      "heading" : "3.3 Inverse Model",
      "text" : ""
    }, {
      "heading" : "3.3.1 Structure",
      "text" : "As stated in Sect. 3.1, the IM decides about the motor command mt: forward translation, left turn, or right turn. As input, it receives a variation of the panoramic view: All obstacles appear as white filled circles on a black background (topmost image in Fig. 6). Size and position of each circle depends on si,t. The generated image has a size of 197 × 42 pixels, therefore the input data space of the IM has 8274 dimensions.\nThe IM has two distinct properties: It has to solve a three–fold classification task, and it receives rather high–dimensional input. For this reason, we implemented it by a set of three binary classificators, each of which is a simple linear model (because of the high dimensionality of the data, chances are good that a linear seperation works well). The three binary classification tasks are forward vs. left, forward vs. right, and left vs. right. The IM contains three regression modules referring to these three classification tasks (see also Möller and Schenck, 2008, pp. 518). The first movement m1 in each combination m1–m2 (with m1,m2 ∈ {forward, left, right}) is assigned the output value q = 1 in the regression, the second movement m2 the output value q = 0. Regression prediction in each module produces an output value q̂(m1,m2) that can be used to decide between the two movements. Given an image x (organized as vector), the average of the training images x(m1,m2), and the regression coefficients β(m1,m2) for the movement combination m1–m2, the output value is obtained from\nq̂(m1,m2) = 0.5 + β(m1,m2) T · [x− x(m1,m2)]. (4)\nIn the reverse direction, we set q̂(m2,m1) = 1 − q̂(m1,m2). Equation (4) describes a plane for each pair of movements. We can use the plane equation to decide which of the movements m1 and m2 should be executed for a given image x. Now, each of the three alternative actions is assigned a goodness g(m) from\ng(m1) = minm2 m2 6=m1 q̂(m1,m2). (5)\nThis operation joins two linear functions by forming a ridge. While equation (4) decides between two movements, the goodness computed in equation (5) establishes a border between the movement m1 and the two other movements. The movement suggested by the IM is the one with maximal goodness g."
    }, {
      "heading" : "3.3.2 Training",
      "text" : "The conceptual role of the IM in the cognitive architecture is to generate foresighted obstacle avoidance behavior while staying at a straight track as long as possible. According\nto this goal, training data for the IM is obtained from an internal simulation process using the already trained visuo-tactile FM (for a detailed description see Möller and Schenck, 2008, pp. 520). Short sequences of movements starting from a true image are simulated to find the sequence with minimal costs. The total costs of a sequence contain collision and motor costs. A sequence with collisions can never be the one with minimal costs and is therefore discarded. The motor costs of a simulated sequence are determined from the sum of the costs of each movement in the sequence (forward 0, rotations 20), and the sum of the costs when two subsequent movements differ (10 when switching from translation to rotation or vice versa, 1000 when switching between rotations). The first movement of the best sequence found is stored together with the initial image of this sequence in the training set for the corresponding regression modules. Then the robot performs a real movement and initiates a new search.\nTraining data for the IM was collected in 6 different arrangements of around 10 obstacles, starting from 8 different viewing directions per arrangement. From each of these 48 different initial situations, a random movement sequence with 100 steps was executed. In each of these overall 4800 movement steps, one learning example for the IM was generated in the way described above (with short–term simulations over 7 steps). For the training of the regression modules, ca. 1, 300 data points for forward movements, ca. 2, 400 for left turns, and ca. 1, 100 for right turns were collected.\nEach regression module was adapted to the training data by partial least squares regression (PLS) (Wold et al., 1984). The resulting mean vectors x and regression coefficients β are illustrated in Fig. 6. The coefficients β(m1,m2) found by PLS are plausible and can at least partly be interpreted from the images: For example, the coefficients in the forward-left selector module contain a black region (negative values) close to the center,\nbut slightly misplaced to the right. If an obstacle is present in this region, the module will favor left turns over forward movements."
    }, {
      "heading" : "3.4 Internal Simulation",
      "text" : "The final goal of the cognitive architecture is to reveal by sensorimotor simulation if an obstacle arrangement is “pass–through–able” (corridor) or “non–pass–through–able” (dead end). A simulation trial always starts from a real–world situation in which the agent detects the existing obstacles, resulting in the initial sensory state s0. Afterwards, the simulation is performed by iteratively applying the IM and the visual and tactile FM. The IM suggest the next motor command, and the FMs predict the resulting new visual state ŝt+1 and the tactile state (see Fig. 7). Afterwards the next iteration starts, this time based on the predicted visual state. In our experiments, the maximum number of iterations amounted to 60.\nWhether an obstacle arrangement is “pass–through–able”, is recognized based on the motor commands in the simulated sequence: If such a sequence is collision–free, contains only up to 20 turns, and the absolute difference between left and right turns does not exceed 10, an obstacle arrangement can be classified as corridor. Thus, the “corridor criterion” does not rely on sensory features, but on motor data gathered during the sensorimotor simulation. As soon as the corridor criterion is violated during a simulation trial, it is prematurely terminated.\nSo far, we have only considered a single simulation trial. In the following, we will introduce the additional term “simulation run”. A simulation run consists of a number of simulation trials, all starting from the same real–world situation and initial sensory state s0. In our experiments, a simulation run consisted of up to 30 simulation trials. Since\nthe output of the IM is deterministic in its basic version, it is necessary to inject some randomness into the simulation process to arrive at a different movement sequence in each trial (see Sects. 4.1.1/4.1.3). If any of the trials within the run fulfills the corridor criterion, the obstacle arrangement is classified as corridor, otherwise as dead end. After a classification as corridor, the simulation run is prematurely terminated. By using several simulation trials instead of only one, the final classification is based on a more substantial amount of (internally generated) sensorimotor data."
    }, {
      "heading" : "4 Experimental Results",
      "text" : ""
    }, {
      "heading" : "4.1 Task Conditions",
      "text" : "In the final experiments, the overall architecture was tested regarding its perceptual performance, i.e. its ability to distinguish dead ends from corridors by internal simulation. In these experiments, we varied three aspects of the internal simulation process systematically: (1) the type of IM; (2) how to deal with oscillations (left turn followed by right turn followed by left turn. . . ); (3) how to (re-)start a simulation trial."
    }, {
      "heading" : "4.1.1 Variations of the Inverse Model",
      "text" : "We compared three different types of IMs: The IM as described in Sect. 3.3 with deterministic output (called DET), a probabilistic interpretation of this IM (called PROB), and a random walk (called RANDOM).\nIn the probabilistic version, the outputs of the three regression modules are interpreted as likelihoods that the corresponding motor commands are the optimum choice. First each value q̂(mi,mj) (with m1 = forward,m2 = left,m3 = right, i 6= j) is clamped to the range [0; 1]. Afterwards, intermediate (yet unnormalized) probabilities are computed:\np̃(mi) = q̂(mi,mj) · q̂(mi,mk) with i 6= j, i 6= k, j 6= k; i, j, k ∈ {1, 2, 3}\nFinal probabilities are determined by normalizing the p̃(mi) values:\np(mi) = p̃(mi)∑3 j=1 p̃(mj)\nBased on the probabilities p(mi), the output of IM–PROB is randomly generated. IM–RANDOM generates a pure random walk with the following basic probabilities: p(forward) = 2/3, p(left) = 1/6, p(right) = 1/6. In this way, the probabilities for the occurence of each motor command in the simulated sequences match the corridor criterion (a maximum number of 20 turns is allowed within a sequence of 60 steps). This is a necessary prerequisite for a fair comparison with the other types of IMs. The purpose of IM–RANDOM is to serve as baseline condition."
    }, {
      "heading" : "4.1.2 Anti–Oscillation Mode",
      "text" : "Whenever an IM generates a turn which counteracts the turn directly before, this leads in case of IM–DET to a deadlock, and in case of IM–PROB and IM–RANDOM to frequent violations of the corridor criterion because the maximum number of allowed turns is more quickly exceeded. We tested four ways to counteract this problem (called anti–oscillation modes in the following). In the first mode (NONE), no countermeasures are taken. In the second mode (CONTINUE), we proceed as in the original study by Möller and Schenck (2008): Whenever two subsequent turns cancel each other out, the second turn is changed to a turn into the same direction as the first one. In the third mode (FORWARD), both turns are deleted from the movement sequence (the second rotation undoes the first rotation; the predicted sensory state is kept consistent by executing the visual FM for the second turn). If a collision–free forward movement is now possible (tested with the FMs), this single forward movement is inserted into the movement sequence instead of the two deleted turns. Otherwise, the IM has to directly determine the next movement step. This leads in case of IM–DET to a deadlock; for this reason, a simulation trial is stopped after 300 invocations of the IM. The fourth mode (FORWARD–CONTINUE) works very similar to the third mode. After the deletion of both turns a forward movement is tested. If this is collision–free, it is inserted into the movement sequence, otherwise two equal turns in direction of the first deleted turn. This anti–oscillation mode basically combines the FORWARD and the CONTINUE strategy and avoids deadlocks."
    }, {
      "heading" : "4.1.3 Restart Mode",
      "text" : "Whenever a simulation trial is stopped because the movement sequence indicates a dead end or because the maximum iteration depth is reached, a new trial has to be started. In case of the restart mode ”FULL”, the whole movement sequence from the previous trial is discarded; the internal simulation starts again from scratch. This works well for IMs with a probabilistic component, while IM–DET produces always the same movement sequence. However, for completeness the combination of IM–DET with FULL was included in the experiments. The second restart mode is taken from the original study by Möller and Schenck (2008). In this mode, each movement sequence is identical to the one from the previous trial up to a randomly selected step within the first two thirds of the sequence (therefore this mode is called PARTIAL). At that point, the new sequence is modified by performing 3 subsequent rotations either to the left or to the right (random decision). For all subsequent steps, the internal simulation follows again the suggestions of the IM. By inserting random rotations, the PARTIAL restart mode injects randomness into the simulation process and is thus especially suited for IM–DET."
    }, {
      "heading" : "4.2 Experimental Procedure",
      "text" : "Overall, they are 24 task conditions (3 types of IMs× 4 anti–oscillation modes× 2 restart modes). In each task condition, we carried out 600 simulation runs based on the robot’s camera images of 60 different real–world obstacle arrangements; thus the image of every obstacle arrangement ist presented 10 times in each task condition as initial real–world state. The 60 obstacle arrangements are devided into 20 dead ends and 40 corridors. Each one consists of 10 obstacles which are distributed over an area of about 3 × 4 meters (see Figs. 2 and 8 for some examples). The robot was placed close to the entrance of each dead end or corridor situation. We ensured that in every of these 60 scenarios all obstacles were detected in the image processing stage (however, specific properties like their width might have been misperceived, see Fig. 3). Dead ends were arranged such that the maximum gap between obstacles amounted to 65 cm. In corridor scenarios, there were one (or rarely two) gaps with a minimum width of 85 cm. The maximum gap size was 110 cm."
    }, {
      "heading" : "4.3 Results",
      "text" : "We report for each task condition the success rates (correctly identified corridors and dead ends in Tab. 1), the average number of simulation trials per run in case of successful corridor detection (Tab. 2), and the overall number of FM invocations over all 600 simulation runs (Tab. 3)."
    }, {
      "heading" : "4.3.1 Success Rates",
      "text" : "The success rates in Tab. 1 show that the cognitive architecture is well suited to reveal the affordances of obstacle arrangements — at least in some task conditions. Dead ends are nearly always correctly classified, and corridor detection works well for IM–DET and IM–PROB if combined with the appropriate anti–oscillation mode (FORWARD/FORW.–CONTINUE) and the appropriate restart mode (PARTIAL for IM–DET, FULL for IM–PROB). In these task conditions, the success rates for corridor detection are about 90%. The best result (91.3%) is obtained from the combination IM–DET/FORW.–CONTINUE/PARTIAL. In comparison, the combination IM– DET/CONTINUE/PARTIAL which was applied by Möller and Schenck (2008) reaches only 65.8%. This is surprising but illustrates the value of real–world experiments in complementing pure simulation studies. Another unexpected result is the rather good performance of the random walk (IM–RANDOM): It reaches in combination with FORWARD/FULL a corridor success rate of 76.5%. Furthermore, IM–RANDOM even finds passages through some dead end scenarios. A close inspection of these cases reveals that this is caused by misperceived obstacles. This misperception has already been discussed in Sect. 2.2.2 and is illustrated in Fig. 3. Even with the mentioned correction steps, the\nwidth and vertical offset of segments is sometimes wrongly estimated. In this case, artifical gaps may open in dead ends as shown in in Fig. 3 (see the caption of Fig. 8 on how the illustration from the bird’s eye view was generated).\nFor probabilistic IMs, the FULL restart mode is generally better suited as the original PARTIAL strategy. Most likely, because by a full restart a bad movement sequence in the beginning is always completely discarded, and the occurence of such bad sequences might be more likely in case of probabilistic movement decisions. Comparing the anti– oscillation modes, the CONTINUE strategy performs nearly as bad as working without any strategy (NONE). The FORWARD and FORW.–CONTINUE strategies work both rather well; the FORWARD strategy is superior if combined with IM–RANDOM. This is most likely the case because it leaves more room for random decisions and the revision of previously executed bad decisions."
    }, {
      "heading" : "4.3.2 Average Number of Trials",
      "text" : "The random walk was rather successful given the number of correctly classified scenarios which questions the necessity of sophisticated IMs. However, the average number of trials for successfully detected corridors in Tab. 2 shows clearly that this is a premature conclusion. In its most precise task condition FORWARD/FULL, IM–RANDOM needs on average 8.56 simulation trials, compared with approx. 4.5 required by IM–PROB and only about 2.5 required by IM–DET! This proves convincingly that sophisticated IMs in general and the deterministic variant in particular are far superior to a pure random walk."
    }, {
      "heading" : "4.3.3 Average Number of FM Invocations",
      "text" : "In addition, we analyzed the average number of FM invocations over all 600 simulation runs (Tab. 3). This measure also reflects how costly it is to generate movement sequences in case of dead ends. Again, the random walk is very expensive compared to the more sophisticated IMs (3698 invocations for IM–RANDOM/FORWARD/FULL in contrast to 929 invocations for IM–PROB/FORW.–CONTINUE/FULL and 686 invocations for IM– DET/FORW.–CONTINUE/PARTIAL). This further corroborates the impression that the success of random strategies depends on a large number of tested movement steps while sophisticated IMs are more efficient because their output is goal–directed.\nGenerally, the anti–oscillation modes CONTINUE and FORW.–CONTINUE are the most economic ones while FORWARD leads in contrast to the largest number of FM invocations. For this reason, the combination IM–PROB/FORW.–CONTINUE/FULL is more appealing than IM–PROB/FORWARD/FULL although the latter has a slightly better success rate. However, in the end the deterministic version of the IM is the most preferable one. Combined with FORW.–CONTINUE/PARTIAL it shows consistently very good results in all considered measures. The striking difference to the previous pure simulation\nstudy (Möller and Schenck, 2008) is that the pure CONTINUE mode does not result in good success rates for corridor detection."
    }, {
      "heading" : "4.3.4 Visualization",
      "text" : "Fig. 8 illustrates the output of the different types of IMs from a bird’s eye perspective for one dead end and three corridors. Admittedly, these examples were purposefully picked by the authors, but they show nevertheless the different characteristics of the generated movement sequences.\nIM–RANDOM produces many different sequences within a simulation run which cover a wide area. Nevertheless, rather obvious exits as in the second row of images are missed. In contrast, IM–DET produces gently curved movement sequences, and sometimes even a single one suffices to find the passage through a corridor. The characteristics of IM–PROB are in between. In the third row it does not identify the passage despite many attempts, most likely because the probability of a right turn is far too low at the crucial position within the arrangement. Here, the random injection of three subsequent right rotations by the PARTIAL strategy helps IM–DET to find the exit very quickly (of course, this is a lucky incident in this case)."
    }, {
      "heading" : "5 Discussion",
      "text" : "Within its practical and technical limits, the proposed architecture enables the robotic agent to successfully recognize the behavioral meaning of obstacle arrangements as either dead ends or corridors. This is a non–trivial task, as Fig. 2 illustrates: For an outside observer, the difference between dead end and corridor is obvious (images in first row); however, from the robot’s perspective (images in second and third row) this distinction is not obvious at all. The crucial step for the solution of this recognition problem is the transformation of the sensory task into a sensorimotor task by internal simulation based on mental imagery. It is remarkable that during this transition a proximal sense (touch) starts to serve as basis for the interpretation of the data from a distal sense (vision). The internal simulation is a “projection” from the distal visual sense onto the proximal tactile sense and onto motor commands and from there onto the assessment signals (“collisions are bad”), and this projection is what ultimately provides behavioral meaning to the visual image.\nThe hierarchical approach — learning prediction by the forward models first, learning motor control by the inverse model afterwards — is a very important aspect of the architecture. The way in which the inverse model is acquired can partly be characterized as mental training in which the mental images are produced by the already trained forward model. The general principle “prediction before control” is consistent with results from psychological experiments (e.g., Flanagan et al., 2003). In the final internal simulation\nfor affordance detection, the inverse model plays an important role to guide the generation of movement sequences. Thus, the motor competence of the agent is an important prerequisite for its perceptual competence (see Witt and Proffitt, 2008, for corresponding results from psychology).\nThe study in this paper builds upon our previous work (Möller and Schenck, 2008) in which we developed the cognitive architecture and tested it in a pure simulation study. In Möller and Schenck (2008), we already discussed the basic design decisions and insights for cognitive science in–depth. We won’t repeat this here with the same comprehensiveness, instead we will focus on the differences and on the insights from the new experiments. First of all, the transfer to a real–world setup is a considerable step forward on our way from a “computerized thought experiment” to real applications of the “perception through anticipation” (PtA) approach. Working with real–world data poses some additional challenges, in our case especially noise and uncertainties in the feature detection process. As stated earlier, each single obstacle is interpreted as a feature of the whole obstacle arrangement. In the sensory domain, these features appear as segments with specific properties like width and position. However, because of noisy image data and partial occlusions these parameters are sometimes wrongly registered. Errors like this can even change the behavioral meaning of the whole obstacle arrangement (i.e., a dead end becomes a corridor and vice versa). For this reason, we had to introduce an additional correction step in the feature acquisition process which is based on the overall distribution statistics of the parameters. This correction is not perfect but yields much better results in affordance detection than without (result from pre–tests). The general lesson from this is that the quality of the internal simulations depends on the precise registration of the initial real–world state, and that this precision can be enhanced by exploiting redundancy and by reconstructing incomplete features through implicit knowledge about typical feature characteristics — without abandoning the basic principle of the PtA approach that pure sensory processing has to be kept at a rather simple level.\nFurthermore, we extended our previous work (Möller and Schenck, 2008) by comparing different types of inverse models and other aspects of the simulation process in a systematic experimental study. The most important results can be summarized as follows: Although random walks can be rather successful in generating useful movement sequences, this comes at the price of a considerably larger simulation effort (required number of simulation trials, invocations of the forward model) compared to purposefully trained inverse models. This shows that the inverse model is not a dispensable part of the cognitive architecture, but instead a very important one (even more so if one considers the possibility of a hierarchy over several forward and inverse models at more and more abstract processing levels). For the injection of randomness into the simulation process, we compared two different methods: (1) Using a deterministic inverse model whose output is from time to time complemented by some random motor commands, or (2) by interpreting the output of the inverse model in a probabilistic way. In our view, the lat-\nter method is more elegant, however, the results show that the first method is superior (performance–wise only slightly, but regarding simulation effort rather significantly). Although this finding is most likely task–dependent, the general lesson from this is that the question on how to create some random variety in the simulation process deserves high attention because it can have a strong impact on the efficiency.\nA third difference concerns the implementation of the forward model. In our previous work (Möller and Schenck, 2008), we used a set of multi–layer perceptrons to approximate the training data. In the real–world setting with more noisy training data, an approach with a very strong regularization was more successful: fitting analytical functions with only a very small number of free parameters to the data. On the downside, this caused undesired extrapolation behavior which was counteracted by projecting the predicted parameters of the obstacle segments back onto the distribution of these parameters in the training data. This is conceptually similar to the approach by Hoffmann (2007) who projected patches of predicted images back onto the distribution of these patches by a Gaussian mixture model (also for the purpose of avoiding “catastrophic extrapolation” in the internal multi–step simulation). We assume that such a predictor–corrector scheme is generally very useful to stabilize long–term simulations because it can partly compensate inprecise predictions.\nIn this way the present study identifies several important principles which can be used to successfully create robot implementations of computational models which are based on the concept of internal simulation (e.g., simulation theories of perception and cognition; Hesslow, 2002; Cruse, 2003; Grush, 2004). With regard to its conceptual underpinnings and basic methodology, our work belongs to the fields of “embodied cognition” and “developmental robotics” (Lungarella et al., 2003; Pfeifer and Iida, 2004) in that it aims on a sensorimotor foundation of cognition and puts a strong emphasis on learning. The final goal of the PtA approach is to explain the direct perception of more complex affordances in real–world settings (e.g., “sit–on–able” for a humanoid robot, or “bimanually– graspable” for a setup with two robot arms). One day affordance detection could complement or maybe even replace classical object recognition algorithms which work solely on sensory data. The presented research is a further advancement in this direction."
    } ],
    "references" : [ {
      "title" : "The proactive brain: Using analogies and associations to generate predictions",
      "author" : [ "M. Bar" ],
      "venue" : "Trends in Cognitive Sciences,",
      "citeRegEx" : "Bar,? \\Q2007\\E",
      "shortCiteRegEx" : "Bar",
      "year" : 2007
    }, {
      "title" : "How and why the brain lays the foundations for a conscious self",
      "author" : [ "M. Butz" ],
      "venue" : "Constructivist Foundations,",
      "citeRegEx" : "Butz,? \\Q2008\\E",
      "shortCiteRegEx" : "Butz",
      "year" : 2008
    }, {
      "title" : "The evolution of cognition — a hypothesis",
      "author" : [ "H. Cruse" ],
      "venue" : "Cognitive Science,",
      "citeRegEx" : "Cruse,? \\Q2003\\E",
      "shortCiteRegEx" : "Cruse",
      "year" : 2003
    }, {
      "title" : "From primitive behaviors to goal-directed behavior using affordances",
      "author" : [ "M.R. Dogar", "M. Cakmak", "E. Ugur", "E. Sahin" ],
      "venue" : "In Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems,",
      "citeRegEx" : "Dogar et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Dogar et al\\.",
      "year" : 2007
    }, {
      "title" : "Learning about objects through action — Initial steps towards artificial cognition",
      "author" : [ "P. Fitzpatrick", "G. Metta", "L. Natale", "S. Rao", "G. Sandini" ],
      "venue" : "In IEEE International Conference on Robotics and Automation,",
      "citeRegEx" : "Fitzpatrick et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Fitzpatrick et al\\.",
      "year" : 2003
    }, {
      "title" : "Prediction precedes control in motor learning",
      "author" : [ "J.R. Flanagan", "P. Vetter", "R.S. Johansson", "D.M. Wolpert" ],
      "venue" : "Current Biology,",
      "citeRegEx" : "Flanagan et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Flanagan et al\\.",
      "year" : 2003
    }, {
      "title" : "The Ecological Approach to Visual Perception",
      "author" : [ "J.J. Gibson" ],
      "venue" : null,
      "citeRegEx" : "Gibson,? \\Q1979\\E",
      "shortCiteRegEx" : "Gibson",
      "year" : 1979
    }, {
      "title" : "Generative character of perception: A neural architecture for sensorimotor anticipation",
      "author" : [ "Gross", "H.-M", "A. Heinze", "T. Seiler", "V. Stephan" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Gross et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Gross et al\\.",
      "year" : 1999
    }, {
      "title" : "The emulation theory of representation: Motor control, imagery, and perception",
      "author" : [ "R. Grush" ],
      "venue" : "Behavioral and Brain Sciences,",
      "citeRegEx" : "Grush,? \\Q2004\\E",
      "shortCiteRegEx" : "Grush",
      "year" : 2004
    }, {
      "title" : "Conscious thought as simulation of behaviour and perception",
      "author" : [ "G. Hesslow" ],
      "venue" : "Trends in Cognitive Sciences,",
      "citeRegEx" : "Hesslow,? \\Q2002\\E",
      "shortCiteRegEx" : "Hesslow",
      "year" : 2002
    }, {
      "title" : "Perception through visuomotor anticipation in a mobile robot",
      "author" : [ "H. Hoffmann" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Hoffmann,? \\Q2007\\E",
      "shortCiteRegEx" : "Hoffmann",
      "year" : 2007
    }, {
      "title" : "Robots with internal models",
      "author" : [ "O. Holland", "R. Goodman" ],
      "venue" : "Journal of Consciousness Studies,",
      "citeRegEx" : "Holland and Goodman,? \\Q2003\\E",
      "shortCiteRegEx" : "Holland and Goodman",
      "year" : 2003
    }, {
      "title" : "Potential role of mental practice using motor imagery in neurologic rehabilitation",
      "author" : [ "P.L. Jackson", "A.F. Lafleur", "F. Malouin", "C. Richards", "J. Doyon" ],
      "venue" : "Archives of Physical Medicine and Rehabilitation,",
      "citeRegEx" : "Jackson et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Jackson et al\\.",
      "year" : 2001
    }, {
      "title" : "Neural simulation of action: A unifying mechanism for motor cognition. NeuroImage, 14(1):S103–S109",
      "author" : [ "M. Jeannerod" ],
      "venue" : null,
      "citeRegEx" : "Jeannerod,? \\Q2001\\E",
      "shortCiteRegEx" : "Jeannerod",
      "year" : 2001
    }, {
      "title" : "Visual mental-imagery activates topographically organized visual-cortex — PET investigations",
      "author" : [ "S.M. Kosslyn", "N.M. Alpert", "W.L. Thompson", "V. Maljkovic", "S.B. Weise", "C.F. Chabris", "S.E. Hamilton", "S.L. Rauch", "F.S. Buonanno" ],
      "venue" : "Journal of Cognitive Neuroscience,",
      "citeRegEx" : "Kosslyn et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Kosslyn et al\\.",
      "year" : 1993
    }, {
      "title" : "Developmental robotics: a survey",
      "author" : [ "M. Lungarella", "G. Metta", "R. Pfeifer", "G. Sandini" ],
      "venue" : "Connection Science,",
      "citeRegEx" : "Lungarella et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lungarella et al\\.",
      "year" : 2003
    }, {
      "title" : "Architectures for functional imagination",
      "author" : [ "H.G. Marques", "O. Holland" ],
      "venue" : null,
      "citeRegEx" : "Marques and Holland,? \\Q2009\\E",
      "shortCiteRegEx" : "Marques and Holland",
      "year" : 2009
    }, {
      "title" : "Imagery use in sport: A literature review and applied model",
      "author" : [ "K.A. Martin", "S.E. Moritz", "C.R. Hall" ],
      "venue" : "Sport Psychologist,",
      "citeRegEx" : "Martin et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Martin et al\\.",
      "year" : 1999
    }, {
      "title" : "Perception through anticipation — a behavior-based approach to visual perception",
      "author" : [ "R. Möller" ],
      "venue" : null,
      "citeRegEx" : "Möller,? \\Q1999\\E",
      "shortCiteRegEx" : "Möller",
      "year" : 1999
    }, {
      "title" : "Bootstrapping cognition from behavior — a computerized thought experiment",
      "author" : [ "R. Möller", "W. Schenck" ],
      "venue" : "Cognitive Science,",
      "citeRegEx" : "Möller and Schenck,? \\Q2008\\E",
      "shortCiteRegEx" : "Möller and Schenck",
      "year" : 2008
    }, {
      "title" : "Learning object affordances: From sensory-motor coordination to imitation",
      "author" : [ "L. Montesano", "M. Lopes", "A. Bernardino", "J. Santos-Victor" ],
      "venue" : "IEEE Transactions on Robotics,",
      "citeRegEx" : "Montesano et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Montesano et al\\.",
      "year" : 2008
    }, {
      "title" : "Two visual systems and two theories of perception: An attempt to reconcile the constructivist and ecological approaches",
      "author" : [ "J. Norman" ],
      "venue" : "Behavioral and Brain Sciences,",
      "citeRegEx" : "Norman,? \\Q2002\\E",
      "shortCiteRegEx" : "Norman",
      "year" : 2002
    }, {
      "title" : "Thinking as the control of imagination: a conceptual framework for goal-directed systems",
      "author" : [ "G. Pezzulo", "C. Castelfranchi" ],
      "venue" : "Psychological Research,",
      "citeRegEx" : "Pezzulo and Castelfranchi,? \\Q2009\\E",
      "shortCiteRegEx" : "Pezzulo and Castelfranchi",
      "year" : 2009
    }, {
      "title" : "Embodied artificial intelligence: Trends and challenges",
      "author" : [ "R. Pfeifer", "F. Iida" ],
      "venue" : "In Embodied Artificial Intelligence,",
      "citeRegEx" : "Pfeifer and Iida,? \\Q2004\\E",
      "shortCiteRegEx" : "Pfeifer and Iida",
      "year" : 2004
    }, {
      "title" : "Learning internal representations by error propagation",
      "author" : [ "D.E. Rumelhart", "G. Hinton", "R. Williams" ],
      "venue" : "Parallel distributed processing: Explorations in the microstructure of cognition",
      "citeRegEx" : "Rumelhart et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "Rumelhart et al\\.",
      "year" : 1986
    }, {
      "title" : "Space perception through visuokinesthetic prediction",
      "author" : [ "W. Schenck" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Schenck,? \\Q2009\\E",
      "shortCiteRegEx" : "Schenck",
      "year" : 2009
    }, {
      "title" : "Prediction of external events with our motor system: Towards a new framework",
      "author" : [ "R.I. Schubotz" ],
      "venue" : "Trends in Cognitive Sciences,",
      "citeRegEx" : "Schubotz,? \\Q2007\\E",
      "shortCiteRegEx" : "Schubotz",
      "year" : 2007
    }, {
      "title" : "Learning the affordances of tools using a behavior-grounded approach",
      "author" : [ "A. Stoytchev" ],
      "venue" : "Towards Affordance-Based Robot Control,",
      "citeRegEx" : "Stoytchev,? \\Q2008\\E",
      "shortCiteRegEx" : "Stoytchev",
      "year" : 2008
    }, {
      "title" : "Learning to perceive the world as articulated: An approach for hierarchical learning in sensory-motor systems",
      "author" : [ "J. Tani", "S. Nolfi" ],
      "venue" : "Neural Networks,",
      "citeRegEx" : "Tani and Nolfi,? \\Q1999\\E",
      "shortCiteRegEx" : "Tani and Nolfi",
      "year" : 1999
    }, {
      "title" : "Action-specific influences on distance perception: A role for motor simulation",
      "author" : [ "J.K. Witt", "D.R. Proffitt" ],
      "venue" : "Journal of Experimental Psychology: Human Perception and Performance,",
      "citeRegEx" : "Witt and Proffitt,? \\Q2008\\E",
      "shortCiteRegEx" : "Witt and Proffitt",
      "year" : 2008
    }, {
      "title" : "The collinearity problem in linearregression — the partial least-squares (PLS) approach to generalized inverses",
      "author" : [ "S. Wold", "A. Ruhe", "H. Wold", "W.J. Dunn" ],
      "venue" : "Siam Journal on Scientific and Statistical Computing,",
      "citeRegEx" : "Wold et al\\.,? \\Q1984\\E",
      "shortCiteRegEx" : "Wold et al\\.",
      "year" : 1984
    }, {
      "title" : "A unifying computational framework for motor control and social interaction",
      "author" : [ "D.M. Wolpert", "K. Doya", "M. Kawato" ],
      "venue" : "Philosophical Transactions of the Royal Society of London. Series B,",
      "citeRegEx" : "Wolpert et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Wolpert et al\\.",
      "year" : 2003
    }, {
      "title" : "Internal simulation of perception: A minimal neuro-robotic model",
      "author" : [ "T. Ziemke", "Jirenhed", "D.-A", "G. Hesslow" ],
      "venue" : null,
      "citeRegEx" : "Ziemke et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Ziemke et al\\.",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Introspective experience suggests that humans are able to generate mental images, and neuroimaging studies have shown that these mental images have neural correlates in the corresponding cortical areas which are usually involved in visual and motor processing (Jeannerod, 2001; Kosslyn et al., 1993).",
      "startOffset" : 260,
      "endOffset" : 299
    }, {
      "referenceID" : 14,
      "context" : "Introspective experience suggests that humans are able to generate mental images, and neuroimaging studies have shown that these mental images have neural correlates in the corresponding cortical areas which are usually involved in visual and motor processing (Jeannerod, 2001; Kosslyn et al., 1993).",
      "startOffset" : 260,
      "endOffset" : 299
    }, {
      "referenceID" : 17,
      "context" : "in sports (Martin et al., 1999) or rehabilitation (Jackson et al.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : ", 1999) or rehabilitation (Jackson et al., 2001).",
      "startOffset" : 26,
      "endOffset" : 48
    }, {
      "referenceID" : 6,
      "context" : "We suggest that mental imagery — at the subconscious level — could be the basis for the detection of affordances (Gibson, 1979) in visual perception.",
      "startOffset" : 113,
      "endOffset" : 127
    }, {
      "referenceID" : 6,
      "context" : "Accordings to Gibson (Gibson, 1979; Norman, 2002), visual perception means to directly perceive these behavioral meanings by picking up certain “invariants” from the visual information, and through active exploration of the environment without preceding object recognition.",
      "startOffset" : 21,
      "endOffset" : 49
    }, {
      "referenceID" : 21,
      "context" : "Accordings to Gibson (Gibson, 1979; Norman, 2002), visual perception means to directly perceive these behavioral meanings by picking up certain “invariants” from the visual information, and through active exploration of the environment without preceding object recognition.",
      "startOffset" : 21,
      "endOffset" : 49
    }, {
      "referenceID" : 9,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 2,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 31,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 11,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 8,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 22,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009).",
      "startOffset" : 215,
      "endOffset" : 338
    }, {
      "referenceID" : 2,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009). For example, Hesslow (2002) argued that thinking consists of a simulated interaction with the environment, and Grush (2004) suggested the “emulation theory of representation” which links imagery and perception to motor simulation (see also Jeannerod, 2001).",
      "startOffset" : 231,
      "endOffset" : 368
    }, {
      "referenceID" : 2,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009). For example, Hesslow (2002) argued that thinking consists of a simulated interaction with the environment, and Grush (2004) suggested the “emulation theory of representation” which links imagery and perception to motor simulation (see also Jeannerod, 2001).",
      "startOffset" : 231,
      "endOffset" : 464
    }, {
      "referenceID" : 2,
      "context" : "During the last decade several “simulation theories” were proposed in cognitive science (and related areas) which basically state that simulation is an important foundation for perception and higher–level cognition (Hesslow, 2002; Cruse, 2003; Wolpert et al., 2003; Holland and Goodman, 2003; Grush, 2004; Pezzulo and Castelfranchi, 2009). For example, Hesslow (2002) argued that thinking consists of a simulated interaction with the environment, and Grush (2004) suggested the “emulation theory of representation” which links imagery and perception to motor simulation (see also Jeannerod, 2001). Marques and Holland (2009) analyzed the necessary and sufficient requirements for cognitive architectures which are based on internal simulation: Such systems have to be capable of holding covert motor states and internally generated sensory states (i.",
      "startOffset" : 231,
      "endOffset" : 625
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008).",
      "startOffset" : 187,
      "endOffset" : 226
    }, {
      "referenceID" : 26,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008).",
      "startOffset" : 187,
      "endOffset" : 226
    }, {
      "referenceID" : 1,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008).",
      "startOffset" : 187,
      "endOffset" : 226
    }, {
      "referenceID" : 10,
      "context" : "Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way.",
      "startOffset" : 90,
      "endOffset" : 106
    }, {
      "referenceID" : 29,
      "context" : "For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009).",
      "startOffset" : 89,
      "endOffset" : 129
    }, {
      "referenceID" : 25,
      "context" : "For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009).",
      "startOffset" : 89,
      "endOffset" : 129
    }, {
      "referenceID" : 18,
      "context" : "In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999).",
      "startOffset" : 123,
      "endOffset" : 137
    }, {
      "referenceID" : 18,
      "context" : "And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999).",
      "startOffset" : 168,
      "endOffset" : 182
    }, {
      "referenceID" : 3,
      "context" : "Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008).",
      "startOffset" : 140,
      "endOffset" : 233
    }, {
      "referenceID" : 20,
      "context" : "Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008).",
      "startOffset" : 140,
      "endOffset" : 233
    }, {
      "referenceID" : 27,
      "context" : "Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008).",
      "startOffset" : 140,
      "endOffset" : 233
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al.",
      "startOffset" : 188,
      "endOffset" : 2293
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al.",
      "startOffset" : 188,
      "endOffset" : 2318
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al. (1999) and Hoffmann (2007) are especially close to our own work: Gross et al.",
      "startOffset" : 188,
      "endOffset" : 2354
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al. (1999) and Hoffmann (2007) are especially close to our own work: Gross et al.",
      "startOffset" : 188,
      "endOffset" : 2374
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al. (1999) and Hoffmann (2007) are especially close to our own work: Gross et al. (1999) trained a robotic agent to predict the optical flow caused by self–motion, and by this predictive ability the system could generate collision-free movement sequences.",
      "startOffset" : 188,
      "endOffset" : 2432
    }, {
      "referenceID" : 0,
      "context" : "Furthermore, current neurophysiological and psychological studies and computational models provide converging evidence that the brain is actually an ubiquitous predictor of future states (Bar, 2007; Schubotz, 2007; Butz, 2008). In the present study, a robotic agent, a mobile robot with omnidirectional camera (see Fig. 1), learns to distinguish between two types of obstacle arrangements: dead ends and corridors. One example for a dead end and one for a corridor are shown in Fig. 2. It is important to note that the obstacle arrangement as a whole is interpreted here as one single entity whose behavioral meaning has to be uncovered, while each obstacle on its own serves only as a low–level feature. The behavioral meanings would be “pass–through– able” for a corridor and “non–pass–through–able” for a dead end. Another important feature of the presented cognitive architecture (beyond internal simulation and mental imagery) is the decomposition into sub–models which are aquired through sensorimotor learning in a hierarchical way: visual and tactile “forward models” for the prediction of sensory states and an “inverse model” for the generation of motor commands. Linking perception to sensorimotor simulation has two additional interesting implications (Hoffmann, 2007): First, the observer’s body size and behavior determine what is perceived in which way. For example, distance is not understood as a metrical measurement but as movement effort (Witt and Proffitt, 2008; Schenck, 2009). In the context of dead end recognition, a dead end is defined as an arrangement of obstacles that cannot be passed through (Möller, 1999). This definition implies that it depends on the size of the observer’s body what is perceived as dead end and what as corridor. And second, sensorimotor simulation allows for viewpoint invariance: A dead end is recognized by its behavioral meaning and independent from the observer’s perspective (Möller, 1999). Related studies on the detection of affordances have been carried out by various research groups on mobile robots and with robot arm setups (e.g., Fitzpatrick et al., 2003; Dogar et al., 2007; Montesano et al., 2008; Stoytchev, 2008). Iterative sensory anticipation on (simulated) robots has been studied among others by Tani and Nolfi (1999) and Ziemke et al. (2005). The studies by Gross et al. (1999) and Hoffmann (2007) are especially close to our own work: Gross et al. (1999) trained a robotic agent to predict the optical flow caused by self–motion, and by this predictive ability the system could generate collision-free movement sequences. The mobile robot system developed by Hoffmann (2007) could even predict how the whole image of an obstacle arrangement would look like after a movement (although these images were of rather small size).",
      "startOffset" : 188,
      "endOffset" : 2652
    }, {
      "referenceID" : 19,
      "context" : "Our cognitive architecture has already been tested in a pure simulation study (Möller and Schenck, 2008).",
      "startOffset" : 78,
      "endOffset" : 104
    }, {
      "referenceID" : 24,
      "context" : "We tested different implementations for the visual FM (e.g., multi–layer perceptron; Rumelhart et al., 1986), but in the end the best results were obtained by fitting analytical functions to the training data.",
      "startOffset" : 54,
      "endOffset" : 108
    }, {
      "referenceID" : 30,
      "context" : "Each regression module was adapted to the training data by partial least squares regression (PLS) (Wold et al., 1984).",
      "startOffset" : 98,
      "endOffset" : 117
    }, {
      "referenceID" : 18,
      "context" : "In the second mode (CONTINUE), we proceed as in the original study by Möller and Schenck (2008): Whenever two subsequent turns cancel each other out, the second turn is changed to a turn into the same direction as the first one.",
      "startOffset" : 70,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "The second restart mode is taken from the original study by Möller and Schenck (2008). In this mode, each movement sequence is identical to the one from the previous trial up to a randomly selected step within the first two thirds of the sequence (therefore this mode is called PARTIAL).",
      "startOffset" : 60,
      "endOffset" : 86
    }, {
      "referenceID" : 18,
      "context" : "In comparison, the combination IM– DET/CONTINUE/PARTIAL which was applied by Möller and Schenck (2008) reaches only 65.",
      "startOffset" : 77,
      "endOffset" : 103
    }, {
      "referenceID" : 19,
      "context" : "study (Möller and Schenck, 2008) is that the pure CONTINUE mode does not result in good success rates for corridor detection.",
      "startOffset" : 6,
      "endOffset" : 32
    }, {
      "referenceID" : 19,
      "context" : "The study in this paper builds upon our previous work (Möller and Schenck, 2008) in which we developed the cognitive architecture and tested it in a pure simulation study.",
      "startOffset" : 54,
      "endOffset" : 80
    }, {
      "referenceID" : 19,
      "context" : "Furthermore, we extended our previous work (Möller and Schenck, 2008) by comparing different types of inverse models and other aspects of the simulation process in a systematic experimental study.",
      "startOffset" : 43,
      "endOffset" : 69
    }, {
      "referenceID" : 18,
      "context" : "The study in this paper builds upon our previous work (Möller and Schenck, 2008) in which we developed the cognitive architecture and tested it in a pure simulation study. In Möller and Schenck (2008), we already discussed the basic design decisions and insights for cognitive science in–depth.",
      "startOffset" : 55,
      "endOffset" : 201
    }, {
      "referenceID" : 19,
      "context" : "In our previous work (Möller and Schenck, 2008), we used a set of multi–layer perceptrons to approximate the training data.",
      "startOffset" : 21,
      "endOffset" : 47
    }, {
      "referenceID" : 9,
      "context" : "In this way the present study identifies several important principles which can be used to successfully create robot implementations of computational models which are based on the concept of internal simulation (e.g., simulation theories of perception and cognition; Hesslow, 2002; Cruse, 2003; Grush, 2004).",
      "startOffset" : 211,
      "endOffset" : 307
    }, {
      "referenceID" : 2,
      "context" : "In this way the present study identifies several important principles which can be used to successfully create robot implementations of computational models which are based on the concept of internal simulation (e.g., simulation theories of perception and cognition; Hesslow, 2002; Cruse, 2003; Grush, 2004).",
      "startOffset" : 211,
      "endOffset" : 307
    }, {
      "referenceID" : 8,
      "context" : "In this way the present study identifies several important principles which can be used to successfully create robot implementations of computational models which are based on the concept of internal simulation (e.g., simulation theories of perception and cognition; Hesslow, 2002; Cruse, 2003; Grush, 2004).",
      "startOffset" : 211,
      "endOffset" : 307
    }, {
      "referenceID" : 15,
      "context" : "With regard to its conceptual underpinnings and basic methodology, our work belongs to the fields of “embodied cognition” and “developmental robotics” (Lungarella et al., 2003; Pfeifer and Iida, 2004) in that it aims on a sensorimotor foundation of cognition and puts a strong emphasis on learning.",
      "startOffset" : 151,
      "endOffset" : 200
    }, {
      "referenceID" : 23,
      "context" : "With regard to its conceptual underpinnings and basic methodology, our work belongs to the fields of “embodied cognition” and “developmental robotics” (Lungarella et al., 2003; Pfeifer and Iida, 2004) in that it aims on a sensorimotor foundation of cognition and puts a strong emphasis on learning.",
      "startOffset" : 151,
      "endOffset" : 200
    }, {
      "referenceID" : 7,
      "context" : "This is conceptually similar to the approach by Hoffmann (2007) who projected patches of predicted images back onto the distribution of these patches by a Gaussian mixture model (also for the purpose of avoiding “catastrophic extrapolation” in the internal multi–step simulation).",
      "startOffset" : 48,
      "endOffset" : 64
    } ],
    "year" : 2016,
    "abstractText" : "The term “affordance” denotes the behavioral meaning of objects. We propose a cognitive architecture for the detection of affordances in the visual modality. This model is based on the internal simulation of movement sequences. For each movement step, the resulting sensory state is predicted by a forward model, which in turn triggers the generation of a new (simulated) motor command by an inverse model. Thus, a series of mental images in the sensory and in the motor domain is evoked. Starting from a real sensory state, a large number of such sequences is simulated in parallel. Final affordance detection is based on the generated motor commands. We apply this model to a real–world mobile robot which is faced with obstacle arrangements some of which are passable (corridor) and some of which are not (dead ends). The robot’s task is to detect the right affordance (“pass–through–able” or “non–pass–through–able”). The required internal models are acquired in a hierarchical training process. Afterwards, the robotic agent is able to distinguish reliably between corridors and dead ends. This real–world result enhances the validity of the proposed mental simulation approach. In addition, we compare several key factors in the simulation process regarding performance and efficiency. Funding statement: This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors. 1 ar X iv :1 61 1. 00 27 4v 1 [ cs .A I] 1 N ov 2 01 6",
    "creator" : "LaTeX with hyperref package"
  }
}