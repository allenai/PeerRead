{
  "name" : "1406.0941.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Augmentative Message Passing for Traveling Salesman Problem and Graph Partitioning",
    "authors" : [ "Siamak Ravanbakhsh", "Reihaneh Rabbany" ],
    "emails" : [ "mravanba@ualberta.ca", "rabbanyk@ualberta.ca", "rgreiner@ualberta.ca" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Probabilistic Graphical Models (PGMs) provide a principled approach to approximate constraint optimization for NP-hard problems. This involves a message passing procedure (such as max-product Belief Propagation; BP) to find an approximation to maximum a posteriori (MAP) solution. Message passing methods are also attractive as they are easily mass parallelize. This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].\nThe applicability of PGMs to discrete optimization problems is limited by the size and number of factors in the factor-graph. While many recent attempts have been made to reduce the complexity of message passing over high-order factors [7, 8, 9], to our knowledge no published result addresses the issues of dealing with large number of factors. We consider a scenario where a large number of factors represent hard constraints and ask whether it is possible to find a feasible solution by considering only a small fraction of these constraints.\nThe idea is to start from a PGM corresponding to a tractible subsset of constraints, and after obtaining an approximate MAP solution using min-sum BP, augment the PGM with the set of constraints that are violated in the current solution. This general idea has been extensively studied under the\nar X\niv :1\n40 6.\n09 41\nv1 [\ncs .A\nterm cutting plane methods in different settings. Dantzig et al. [10] first investigated this idea in the context of TSP and Gomory et al.[11] provided a elegant method to generate violated constraints in the context of finding integral solutions to linear programs (LP). It has since been used to also solve a variety of nonlinear optimization problems.\nThe requirements of the cutting plane method are 1) availability of an optimal solver; often an LP solver, 2) a procedure to obtain violated constraints and 3) operating in real domain <d; hence the term “plane”. Recent studies show that message passing – which finds integral solutions – can be much faster than LP in finding approximate MAP assignments for structured optimization problems [12]. This further motivates our inquiry regarding the viability of augmentation for message passing. We present an affirmative answer to this question in application to two combinatorial problems. Section 2 introduces our factor-graph formulations for Traveling Salesman Problem (TSP) and graph-partitioning. Section 3 derives simple message update equations for these factor-graphs and reviews our augmentation scheme. Finally, Section 4 presents experimental results for both applications."
    }, {
      "heading" : "2 Background and Representation",
      "text" : "Let x = {x1, . . . , xD} ∈ X = X1×X2 . . .×XD denote an instance of a tuple of discrete variables. Let xI refer to a sub-tuple, where I ⊆ {1, . . . , D} indexes a subset of these variables. Define the energy function f(x) , ∑ I∈F fI(xI) where F denotes the set of factors. Here the goal of inference is to find an assignment with minimum energy x∗ = argxmin f(x). This model can be conveniently represented using a bipartite graph, known as factor-graph [13], where a factor node fI(xI) is connected to a variable node xi iff i ∈ I."
    }, {
      "heading" : "2.1 Traveling Salesman Problem",
      "text" : "A Traveling Salesman Problem (TSP) seeks the minimum length tour of N cities that visits each city exactly once. TSP is NP-hard, and for general distances, no constant factor approximation to this problem is possible [14]. The best known exact solver, due to Held et al.[15], uses dynamic programming to reduce the cost of enumerating all orderings from O(N !) to O(N22N ). The development of many (now) standard optimization techniques, such as simulated annealing, mixed integer linear programming, dynamic programming, and ant colony optimization are closely linked with advances in solving TSP. Since Dantzig et al.[10] manually applied the cutting plane method to 49-city problem, a combination of more sophisticated cuts, used with branch-and-bound techniques [16], has produced the state-of-the-art TSP-solver, Concorde [17]. Other notable results on very large instances have been reported by LinKernighan heuristic [18] that continuously improves a solution by exchanging nodes in the tour. In a related work, Wang et al.[19] proposed a message passing solution to TSP. However their method does not scale beyond small toy problems (authors experimented withN = 5 cities). For a readable historical background of the state-of-the-art in TSP and its various applications, see [20]."
    }, {
      "heading" : "2.1.1 TSP Factor-Graph",
      "text" : "Let G = (V, E) denote a graph, where V = {v1, . . . , vN} is the set of nodes and the set of edges E contains ei−j iff vi and vj are connected. Let x = {xe1 , . . . , xeM } ∈ X = {0, 1}M be a set of binary variables, one for each edge in the graph (i.e., M = |E|) where we will set xem = 1 iff em is in the tour. For each node vi, let ∂vi = {ei−j | ei−j ∈ E} denote the edges adjacent to vi. Given a distance function d : E → <, define the local factors for each edge e ∈ E as fe(xe) = xe d(e) – so this is either d(e) or zero. Any valid tour satisfies the following necessary and sufficient constraints – a.k.a. Held-Karp constraints [21]:\n1. Degree constraints: Exactly two edges that are adjacent to each vertex should be in the tour. Define the factor f∂vi(x∂vi) : {0, 1}|∂vi| → {0,∞} to enforce this constraint\nf∂vi(x∂vi) , I∞ (∑ e∈∂vi xe = 2 ) ∀vi ∈ V\nwhere I∞(condition) , 0 iff the condition is satisfied and +∞ otherwise.\n2. Subtour constraints: Ensure that there are no short-circuits – i.e., there are no loops that contain strict subsets of nodes. To enforce this, for each S ⊂ V , define δ(S) , {ei−j ∈ E | vi ∈ S, vj /∈ S} to be the set of edges, with one end in S and the other end in V \\ S. We need to have at least two edges leaving each subset S. The following set of factors enforce these constraints\nfδ(S)(xδ(S)) = I∞ (∑ xe∈S xe ≥ 2 ) ∀S ⊂ V, S 6= ∅\nThese three types of factors define a factor-graph, whose minimum energy configuration is the smallest tour for TSP."
    }, {
      "heading" : "2.2 Graph Partitioning",
      "text" : "Graph partitioning –a.k.a. community mining– is an active field of research that has recently produced a variety of community detection methods (e.g., see [22] and its references), a notable one of which is Modularity maximization [23]. However, exact optimization of Modularity is NP-hard [24]. Modularity is closely related to fully connected Potts graphical models [25]. However, due to full connectivity of PGM, message passing is not able to find good solutions. Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29]. We introduce a factor-graph representation of this problem that has a large number of factors. We then discuss a stochastic but sparse variation of modularity that enables us to efficiently partition relatively large sparse graphs."
    }, {
      "heading" : "2.2.1 Clustering Factor-Graph",
      "text" : "Let G = (V, E) be a graph, with a weight function ω̃ : V × V → <, where ω̃(vi, vj) 6= 0 iff ei:j ∈ E . Let Z = ∑ v1,v2∈V ω̃(v1, v2) and ω(vi, vj) , ω̃ 2Z be the normalized weights.\nAlso let ω(∂vi) , ∑ vj ω(vi, vj) denote the normalized degree of node vi. Graph clustering using modularity optimization seeks a partitioning of the nodes into unspecified number of clusters C = {C1, . . . , CK}, maximizing\nq(C) = ∑ Ci∈C ∑ vi,vj∈Ci ( ω(vi, vj) − ω(∂vi)ω(∂vj) ) (1)\nThe first term of modularity is proportional to within-cluster edge-weights. The second term is proportional to the expected number of within cluster edge-weights for a null model with the same weighted node degrees for each node vi.\nHere the null model is a fully-connected graph. We generate a random sparse null model with Mnull < αM weighted edges (Enull), by randomly sampling two nodes, each drawn independently from P(vi) ∝ √ ω(∂vi), and connecting them with a weight proportional to ω̃null(vi, vj) ∝√\nω(∂vi)ω(∂vj). If they have been already connected, this weight is added to their current weight. We repeat this process αM times, however since some of the edges are repeated, the total number of edges in the null model may be under αM . Finally the normalized edge-weight in the sparse null model is ωnull(vi, vj) , ω̃null(vi,vj) 2 ∑\nvi,vj ω̃null(vi,vj)\n. It is easy to see that this generative process in\nexpectation produces the fully connected null model.1\nHere we use the following binary-valued factor-graph formulation. Let x = {xi1:j1 , . . . , xiL:jL} = {0, 1}L be a set of binary variables, one for each edge ei:j ∈ E ∪ Enull – i.e., |E ∪ Enull| = L. Define the local factor for each variable as fi:j(xi:j) = −xi−j(ω(vi, vj) − ωnull(vi, vj)). The idea is to enforce formation of cliques, while minimizing the sum of local factors. By doing so the negative sum of local factors evaluates to modularity (eq 1). For each three edges ei:j , ej:k, ei:k ∈ E ∪ Enull, i < j < k that form a triangle, define a clique constraint as\nf{i:j,j:k,i:k}(xi:j , xj:k, xi:k) , I∞(xi:j + xj:k + xi:k 6= 2) 1The choice of using square root of weighted degrees for both sampling and weighting is to reduce the variance. One may also use pure importance sampling (i.e., use the product of weighted degrees for sampling and set the edge-weights in the null model uniformly), or uniform sampling of edges, where the edge-weights of the null model are set to the product of weighted degrees.\nThese factors ensure the formation of cliques – i.e., if the weights of two edges that are adjacent to the same node are non-zero, the third edge in the triangle should also have non-zero weight. The computational challenge here is the large number of clique constraints. Brandes et al.[24] use a similar LP formulation. However, since they include all the constraints from the beginning and the null model is fully connected, their method is only applied to small toy problems."
    }, {
      "heading" : "3 Message Passing",
      "text" : "Min-sum belief propagation is an inference procedure, in which a set of messages are exchanged between variables and factors. The factor-to-variable (νI→e) and variable-to-factor (νe→I) messages are defined as\nνe→I(xe) , ∑\nI′3e,I′ 6=I\nνI′→e(xe) (2)\nνI→e(xe) , min { fI(xI\\e, xe) ∑ e′∈I\\e νe′→I(xe′) } xI\\e\n(3)\nwhere I 3 e indexes all factors that are adjacent to the variable xe on the factor-graph. Starting from an initial set of messages, this recursive update is performed until convergence.\nThis procedure is exact on trees, factor-graphs with single cycle as well as some special settings [4]. However it is found to produce good approximations in general loopy graphs. When BP is exact, the set of local beliefs µe(xe) , ∑ I3e νI→e(xe) indicate the minimum value that can be obtained for a particular assignment of xe. When there are no ties, the joint assignment x∗, obtained by minimizing individual local beliefs, is optimal.\nWhen BP is not exact or the marginal beliefs are tied, a decimation procedure can improve the quality of final assignment. Decimation involves fixing a subset of variables to their most biased values, and repeating the BP update. This process is repeated until all variables are fixed.\nAnother way to improve performance of BP when applied to loopy graphs is to use damping, which often prevents oscillations: νI→e(xe) = λν̃I→e(xe) + (1 − λ)νI→e(xe). Here ν̃I→e is the new message as calculated by eq 3 and λ ∈ (0, 1] is the damping parameter. Damping can also be applied to variable-to-factor messages.\nWhen applying BP equations eqs 2, 3 to the TSP and clustering factor-graphs, as defined above, we face two computational challenges: (a) Degree constraints for TSP can depend on N variables, resulting in O(2N ) time complexity of calculating factor-to-variable messages. For subtour constraints, this is even more expensive as fS(xδ(S)) depends on O(M) (recall M = |E| which can be O(N2)) variables. (b) The complete TSP factor-graph hasO(2N ) subtour constraints. Similarly the clustering factor-graph can contain a large number of clique constraints. For the fully connected null model, we needO(N3) such factors and even using the sparse null model – assuming a random edge probability a.k.a. Erdos-Reny graph – there are O( L 3\nN6N 3) = O( L\n3\nN3 ) triangles in the graph (recall that L = |E ∪ Enull|). In the next section, we derive the compact form of BP messages for both problems. In the case of TSP, we show how to exploit the sparsity of degree and subtour constraints to calculate the factor-to-variable messages in O(N) and O(M) respectively."
    }, {
      "heading" : "3.1 Closed Form of Messages",
      "text" : "For simplicity we work with normalized message νI→e , νI→e(1)− νI→e(0), which is equivalent to assuming νI→e(0) = 0 ∀I, e. The same notation is used for variable-to-factor message, and marginal belief. We refer to the normalized marginal belief, µe = µe(1)− µ(0)e as bias. Despite their exponentially large tabular form, both degree and subtour constraint factors for TSP are sparse. Similar forms of factors is studied in several previous works [7, 8, 9]. By calculating the closed form of these messages for TSP factor-graph, we observe that they have a surprisingly simple form. Rewriting eq 3 for degree constraint factors, we get:\nν∂vi→e(1) = min{νe′→∂vi}e′∈∂vi\\e , ν∂vi→e(0) = min{νe′→∂vi + νe′′→∂vi}e′,e′′∈∂vi\\e (4)\nwhere we have dropped the summation and the factor from eq 3. For xe = 1, in order to have f∂vi(x∂i) < ∞, only one other xe′ ∈ x∂vi should be non-zero. On the other hand, we know that messages are normalized such that νe→∂vi(0) = 0 ∀vi, e ∈ ∂vi, which means they can be ignored in the summation. For xe = 0, in order to satisfy the constraint factor, two of the adjacent variables should have a non-zero value. Therefore we seek two such incoming messages with minimum values. Let min[k]A denote the kth smallest value in the set A – i.e., minA ≡ min[1]A. We combine the updates above to get a “normalized message”, ν∂vi→e, which is simply the negative of the second largest incoming message (excluding νe→∂vi ) to the factor f∂vi :\nν∂vi→e = ν∂vi→e(1)− ν∂vi→e(0) = −min[2]{νe′→∂vi}e′∈∂vi\\e (5)\nFollowing a similar procedure, factor-to-variable messages for subtour constraints is given by\nνδ(S)→e = −max{0,min[2]{νe′→δ(S)}e′∈δ(S)\\e}} (6)\nHere while we are searching for the minimum incoming message, if we encounter two messages with negative or zero values, we can safely assume νδ(S)→e = 0, and stop the search. This results in significant speedup in practice. Note that both eq 5 and eq 6 only need to calculate the second smallest message in the set {νe′→δ(S)}e′∈δ(S)\\e. In the asynchronous calculation of messages, this minimization should be repeated for each outgoing message. However in a synchronous update by finding three smallest incoming messages to each factor, we can calculate all the factor-to-variable messages at the same time.\nFor the clustering factor-graph, the clique factor is satisfied only if either zero, one, or all three of the variables in its domain are non-zero. The factor-to-variable messages are given by\nν{i:j,j:k,i:k}→i:j(0) = min{0, νj:k→{i:j,j:k,i:k}, νi:k→{i:j,j:k,i:k}} ν{i:j,j:k,i:k}→i:j(1) = min{0, νj:k→{i:j,j:k,i:k} + νi:k→{i:j,j:k,i:k}} (7)\nFor xi:j = 0, the minimization is over three feasible cases (a) xj:k = xi:k = 0, (b) xj:k = 1, xi:k = 0 and (c) xj:k = 0, xi:k = 1. For xi:j = 1, there are two feasible cases (a) xj:k = xi:k = 0 and (b) xj:k = xi:k = 1. Normalizing these messages we have\nν{i:j,j:k,i:k}→i:j =min{0, νj:k→{i:j,j:k,i:k} + νi:k→{i:j,j:k,i:k}}− (8) min{0, νj:k→{i:j,j:k,i:k}, νi:k→{i:j,j:k,i:k}}"
    }, {
      "heading" : "3.2 Finding Violations",
      "text" : "Due to large number of factors, message passing for the full factor-graph in our applications is not practical. Our solution is to start with a minimal set of constraints. For TSP, we start with no subtour constraints and for clustering, we start with no clique constraint. We then use message passing to find marginal beliefs µe and select the edges with positive bias µe > 0.\nWe then find the constraints that are violated. For TSP, this is achieved by finding connected components C = {Si ⊂ V} of the solution in O(N) time and define new subtour constraints for each Si ∈ C (see Figure 1(left)).\n101 102 103 nodes\n10-3\n10-2\n10-1\n100\n101\n102\n103\ntim e\n(s ec\n)\n20 0 40 0 60 0 80 0 10 00\nnodes\n1.0\n1.1\n1.2\n1.3\n1.4\n1.5\n1.6\n1.7\n1.8\nop tim\nal ity\nBP NN greedy\n101 102 103 nodes\n100\n101\n102\n103\nau gm\nen ta\ntio n\nite rs\n.\n101 102 103 nodes\n100\n101\n102\n103\n104\nsu bt\nou r f\nac to\nrs .\nTSPLIB Instances\n101 102 103 nodes\n10-3\n10-2\n10-1\n100\n101\n102\n103\ntim e\n(s ec\n)\n20 0 40 0 60 0 80 0 10 00\nnodes\n1.0\n1.1\n1.2\n1.3\n1.4\n1.5\nop tim\nal ity\n101 102 103 nodes\n100\n101\n102\n103\nau gm\nen ta\ntio n\nite rs\n.\n101 102 103 nodes\n100\n101\n102\n103\n104\nsu bt\nou r f\nac to\nrs .\nRandom 2D Euclidean Distance\n101 102 103 nodes\n10-3\n10-2\n10-1\n100\n101\n102\n103\ntim e\n(s ec\n)\n50 0 10 00 15 00 20 00 25 00 30 00 35 00 40 00\nnodes\n0.98\n1.00\n1.02\n1.04\n1.06\n1.08\n1.10\nop tim\nal ity\n101 102 103 nodes\n10-1\n100\n101\n102\nau gm\nen ta\ntio n\nite rs\n.\n101 102 103 nodes\n100\n101\n102\n103\nsu bt\nou r f\nac to\nrs .\nHamming Distance\n101 102 103 nodes\n10-3\n10-2\n10-1\n100\n101\n102\ntim e\n(s ec\n)\n20 0 40 0 60 0 80 0 10 00\nnodes\n1.0\n1.1\n1.2\n1.3\n1.4\n1.5\n1.6\n1.7\n1.8\nop tim\nal ity\n101 102 103 nodes\n10-1\n100\n101\n102\nau gm\nen ta\ntio n\nite rs\n.\n101 102 103 nodes\n100\n101\n102\n103\nsu bt\nou r f\nac to\nrs .\nCorrelation Distance\nRandom Distance Matrix\nFor graph partitioning, we simply look at pairs of positively fixed edges around each node and if the third edge of the triangle is not positively fixed, we add the corresponding clique factor to the factor-graph; see Appendix A for more details."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 TSP",
      "text" : "Here we evaluate our method over five benchmark datasets: (I) TSPLIB, which contains a variety of real-world benchmark instances, the majority of which are 2D or 3D Euclidean or geographic distances.2 (II) Euclidean distance between random points in 2D. (III) Random (symmetric) distance matrices. (IV) Hamming distance between random binary vectors with fixed length (20 bits).\n2Geographic distance is the distance on the surface of the earth as a large sphere.\nThis appears in applications such as data compression [31] and radiation hybrid mapping in genomics [32]. (V) Correlation distance between random vectors with 5 random features (e.g., using TSP for gene co-clustering [33]). In producing random points and features as well as random distances (in (III)), we used uniform distribution over [0, 1].\nFor each of these cases, we report the (a) run-time, (b) optimality, (c) number of iterations of augmentation and (d) number of subtour factors at the final iteration. In all of the experiments, we use Concorde [17] with its default settings to obtain the optimal solution.3 Since there are very large number of TSP solvers, comparison with any particular method is pointless. Instead we evaluate the quality of message passing against the “optimal” solution. The results in Figure 2(2nd column from left) reports the optimality ratio – i.e., ratio of the tour found by message passing, to the optimal tour. To demonstrate the non-triviality of these instance, we also report the optimality ratio for two heuristics that have optimality guarantees for metric instances [34]: (a) nearest neighbour heuristic (O(N2)), which incrementally adds the to any end of the current path the closest city that does not form a loop; (b) greedy algorithm (O(N2 log(N))), which incrementally adds a lowest cost edge to the current edge-set, while avoiding subtours.\nIn all experiments, we used the full graph G = (V, E), which means each iteration of message passing is O(N2τ), where τ is the number of subtour factors. All experiments use Tmax = 200 iterations, max = median{d(e)}e∈E and damping with λ = .2. We used decimation, and fixed 10% of the remaining variables (out of N ) per iteration of decimation.4 This increases the cost of message passing by an O(log(N)) multiplicative factor, however it often produces better results. All the plots in Figure 2, except for the second column, are in log-log format. When using log-log plot, a linear trend shows a monomial relation between x and y axes – i.e., y = axm. Here m indicates the slope of the line in the plot and the intercept corresponds to log(a). By studying the slope of the linear trend in the run-time (left column) in Figure 2, we observe that, for almost all instances, message passing seems to grow with N3 (i.e., slope of ∼ 3). Exceptions are TSPLIB instances, which seem to pose a greater challenge, and random distance matrices which seem to be easier for message passing. A similar trend is suggested by the number of subtour constraints and iterations of augmentation, which has a slope of ∼ 1, suggesting a linear dependence on N . Again the exceptions are TSPLIB instances that grow faster than N and random distance matrices that seem to grow sub-linearly.5 Finally, the results in the second column suggests that message passing is able to find near optimal (in average ∼ 1.1-optimal) solutions for almost all instances and the quality of tours does not degrade with increasing number of nodes.\n3For many larger instances, Concorde (with default setting and using CPLEX as LP solver) was not able to find the optimal solution. Nevertheless we used the upper-bound on the optimal produced by Concord in evaluating our method.\n4Note that here we are only fixing the top N variables with positive bias. The remaining M −N variables are automatically clamped to zero.\n5Since we measured the time in milliseconds, the first column does not show the instances that had a running time of less than a millisecond."
    }, {
      "heading" : "4.2 Graph Partitioning",
      "text" : "For graph partitioning, we experimented with a set of classic benchmarks6. Since the optimization criteria is modularity, we compared our method only against best known “modularity optimization” heuristics: (a) FastModularity[26], (b) Louvain [29], (c) Spin-glass [25] and (d) Leading eigenvector [27]. For message passing, we use λ = .1, max = median{|ω(e) − ωnull(e)|}e∈E∪Enull and Tmax = 10. Here we do not perform any decimation and directly fix the variables based on their bias µe > 0⇔ xe = 1. Table 1 summarizes our results (see also Figure 1(middle,right)). Here for each method and each data-set, we report the time (in seconds) and the Modularity of the communities found by each method. The table include the results of message passing for both full and sparse null models, where we used a constant α = 20 to generate our stochastic sparse null model. For message passing, we also included L = |E + Enull| and the saving in the cost using augmentation. This column shows the percentage of the number of all the constraints considered by the augmentation. For example, the cost of .14% for the polblogs data-set shows that augmentation and sparse null model meant using .0014 times fewer clique-factors, compared to the full factor-graph.\nOverall, the results suggest that our method is comparable to state-of-the-art in terms both time and quality of clustering. But more importantly it shows that augmentative message passing is able to find feasible solutions using a small portion of the constraints."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We investigate the possibility of using cutting-plane-like, augmentation procedures with message passing. We used this procedure to solve two combinatorial problems; TSP and modularity optimization. In particular, our polynomial-time message passing solution to TSP often finds near-optimal solutions to a variety of benchmark instances.\nDespite losing the guarantees that make cutting plane method very powerful, our approach has several advantages: First, message passing is more efficient than LP for structured optimization [12] and it is highly parallelizable. Moreover by directly obtaining integral solutions, it is much easier to find violated constraints. (Note the cutting plane method for combinatorial problems operates on fractional solutions, whose rounding may eliminate its guarantees.) For example, for TSPs, our method simply adds violated constraints by finding connected components. However, due to non-integral assignments, cutting plane methods require sophisticated tricks to find violations [20]. Although powerful branch-and-cut methods, such as Concorde, are able to exactly solve instances with few thousands of variables, their general run-time on benchmark instances remains exponential [17, p495], while our approximation appears to be O(N3). Overall our studies indicate that augmentative message passing is an efficient procedure for constraint optimization with large number of constraints."
    }, {
      "heading" : "A Factor-Graphs and PseudoCodes",
      "text" : "Algorithms 1 and 2 present the pseudocode for both TSP and graph-partitioning by message passing. Note that the scheduling of message updates in these two algorithms is very different. This difference in scheduling is mainly due to the presense of high-order factors in TSP factor-graph and intends to minimize the time complexity. Also, while TSP message passing is re-using the messages from the previous augmentation iteration, for clustering, we initialize the messages to zero. This is because the number of factors in each augmentation step for clustering is relatively large and in practice initializing the messages to zero is more efficient. For both problems, we have included the message from local factors in the marginals and therefore they are ignored during the message update. In practice we do not need to store any of the messages for TSP. Instead we can only keep the three smallest incoming messages to each factor and calculate factor-to-variable messages using these values. The variable-to-factor messages can also be recomputed as required using the marginals and factor-to-variable messages: νe→I(xe) = µe(xe)− νI→e(xe)."
    } ],
    "references" : [ {
      "title" : "Analytic and algorithmic solution of random satisfiability problems",
      "author" : [ "M. Mezard", "G. Parisi", "R. Zecchina" ],
      "venue" : "Science, 2002.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Perturbed message passing for constraint satisfaction problems",
      "author" : [ "S. Ravanbakhsh", "R. Greiner" ],
      "venue" : "arXiv preprint arXiv:1401.6686, 2014.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Clustering by passing messages between data points",
      "author" : [ "B. Frey", "D. Dueck" ],
      "venue" : "Science, 2007.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Maximum weight matching via max-product belief propagation",
      "author" : [ "M. Bayati", "D. Shah", "M. Sharma" ],
      "venue" : "ISIT, 2005.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Min-max problems on factor-graphs",
      "author" : [ "S. Ravanbakhsh", "C. Srinivasa", "B. Frey", "R. Greiner" ],
      "venue" : "ICML, 2014.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Approximating the permanent with belief propagation",
      "author" : [ "B. Huang", "T. Jebara" ],
      "venue" : "arXiv preprint arXiv:0908.1769, 2009. Obtained form Mark Newman’s website: http://www-personal.umich.edu/ ̃mejn/ netdata/ 8",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Efficient belief propagation for higher-order cliques using linear constraint nodes",
      "author" : [ "B. Potetz", "T.S. Lee" ],
      "venue" : "Computer Vision and Image Understanding, vol. 112, no. 1, pp. 39–54, 2008.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Efficient inference with cardinality-based clique potentials",
      "author" : [ "R. Gupta", "A.A. Diwan", "S. Sarawagi" ],
      "venue" : "ICML, 2007.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Hop-map: Efficient message passing with high order potentials",
      "author" : [ "D. Tarlow", "I.E. Givoni", "R.S. Zemel" ],
      "venue" : "International Conference on Artificial Intelligence and Statistics, pp. 812–819, 2010.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Solution of a large-scale traveling-salesman problem",
      "author" : [ "G. Dantzig", "R. Fulkerson", "S. Johnson" ],
      "venue" : "J Operations Research society of America, 1954.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1954
    }, {
      "title" : "Outline of an algorithm for integer solutions to linear programs",
      "author" : [ "R.E. Gomory" ],
      "venue" : "Bulletin of the American Mathematical Society, vol. 64, no. 5, pp. 275–278, 1958.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1958
    }, {
      "title" : "Linear programming relaxations and belief propagation–an empirical study",
      "author" : [ "C. Yanover", "T. Meltzer", "Y. Weiss" ],
      "venue" : "JMLR, 2006.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Factor graphs and the sum-product algorithm",
      "author" : [ "F. Kschischang", "B. Frey" ],
      "venue" : "Information Theory, IEEE, 2001.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "The euclidean travelling salesman problem is np-complete",
      "author" : [ "C.H. Papadimitriou" ],
      "venue" : "Theoretical Computer Science, vol. 4, no. 3, pp. 237–244, 1977.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "A dynamic programming approach to sequencing problems",
      "author" : [ "M. Held", "R.M. Karp" ],
      "venue" : "Journal of the Society for Industrial & Applied Mathematics, vol. 10, no. 1, p. 196210, 1962.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1962
    }, {
      "title" : "A branch-and-cut algorithm for the resolution of large-scale symmetric traveling salesman problems",
      "author" : [ "M. Padberg", "G. Rinaldi" ],
      "venue" : "SIAM review, vol. 33, no. 1, pp. 60–100, 1991.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Concorde TSP solver",
      "author" : [ "D. Applegate", "R. Bixby", "V. Chvatal", "W. Cook" ],
      "venue" : "2006.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "General k-opt submoves for the lin–kernighan tsp heuristic",
      "author" : [ "K. Helsgaun" ],
      "venue" : "Mathematical Programming Computation, 2009.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The traveling salesman problem: a computational study",
      "author" : [ "D. Applegate" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "The traveling-salesman problem and minimum spanning trees",
      "author" : [ "M. Held", "R. Karp" ],
      "venue" : "Operations Research, 1970.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1970
    }, {
      "title" : "Empirical comparison of algorithms for network community detection",
      "author" : [ "J. Leskovec", "K. Lang", "M. Mahoney" ],
      "venue" : "WWW, 2010.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Finding and evaluating community structure in networks",
      "author" : [ "M. Newman", "M. Girvan" ],
      "venue" : "Physical Review E, 2004.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "on clustering",
      "author" : [ "U. Brandes", "D. Delling" ],
      "venue" : "IEEE KDE, 2008.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Detecting fuzzy community structures in complex networks with a potts model",
      "author" : [ "J. Reichardt", "S. Bornholdt" ],
      "venue" : "Physical Review Letters, vol. 93, no. 21, p. 218701, 2004.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Finding local community structure in networks",
      "author" : [ "A. Clauset" ],
      "venue" : "Physical Review E, 2005.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Finding community structure in networks using the eigenvectors of matrices",
      "author" : [ "M. Newman" ],
      "venue" : "Physical review E, 2006.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Local resolution-limit-free potts model for community detection",
      "author" : [ "P. Ronhovde", "Z. Nussinov" ],
      "venue" : "Physical Review E, vol. 81, no. 4, p. 046114, 2010.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Fast unfolding of communities in large networks",
      "author" : [ "V. Blondel", "J. Guillaume" ],
      "venue" : "J Statistical Mechanics, 2008.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Tspliba traveling salesman problem library",
      "author" : [ "G. Reinelt" ],
      "venue" : "ORSA journal on computing, vol. 3, no. 4, pp. 376–384, 1991.",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Compressing large Boolean matrices using reordering techniques",
      "author" : [ "D. Johnson", "S. Krishnan", "J. Chhugani", "S. Kumar", "S. Venkatasubramanian" ],
      "venue" : "VLDB, 2004.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "On constructing radiation hybrid maps",
      "author" : [ "A. Ben-Dor", "B. Chor" ],
      "venue" : "J Computational Biology, 1997.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Take a walk and cluster genes: A TSP-based approach to optimal rearrangement clustering",
      "author" : [ "S. Climer", "W. Zhang" ],
      "venue" : "ICML, 2004.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 116,
      "endOffset" : 122
    }, {
      "referenceID" : 1,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 116,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 3,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 4,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 5,
      "context" : "This has contributed to their application in approximating many NP-hard problems, including constraint satisfaction [1, 2], constrained optimization [3, 4], min-max optimization [5], and integration [6].",
      "startOffset" : 199,
      "endOffset" : 202
    }, {
      "referenceID" : 6,
      "context" : "While many recent attempts have been made to reduce the complexity of message passing over high-order factors [7, 8, 9], to our knowledge no published result addresses the issues of dealing with large number of factors.",
      "startOffset" : 110,
      "endOffset" : 119
    }, {
      "referenceID" : 7,
      "context" : "While many recent attempts have been made to reduce the complexity of message passing over high-order factors [7, 8, 9], to our knowledge no published result addresses the issues of dealing with large number of factors.",
      "startOffset" : 110,
      "endOffset" : 119
    }, {
      "referenceID" : 8,
      "context" : "While many recent attempts have been made to reduce the complexity of message passing over high-order factors [7, 8, 9], to our knowledge no published result addresses the issues of dealing with large number of factors.",
      "startOffset" : 110,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "[10] first investigated this idea in the context of TSP and Gomory et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] provided a elegant method to generate violated constraints in the context of finding integral solutions to linear programs (LP).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "Recent studies show that message passing – which finds integral solutions – can be much faster than LP in finding approximate MAP assignments for structured optimization problems [12].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 12,
      "context" : "This model can be conveniently represented using a bipartite graph, known as factor-graph [13], where a factor node fI(xI) is connected to a variable node xi iff i ∈ I.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 13,
      "context" : "TSP is NP-hard, and for general distances, no constant factor approximation to this problem is possible [14].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 14,
      "context" : "[15], uses dynamic programming to reduce the cost of enumerating all orderings from O(N !) to O(N2 ).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[10] manually applied the cutting plane method to 49-city problem, a combination of more sophisticated cuts, used with branch-and-bound techniques [16], has produced the state-of-the-art TSP-solver, Concorde [17].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[10] manually applied the cutting plane method to 49-city problem, a combination of more sophisticated cuts, used with branch-and-bound techniques [16], has produced the state-of-the-art TSP-solver, Concorde [17].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 16,
      "context" : "[10] manually applied the cutting plane method to 49-city problem, a combination of more sophisticated cuts, used with branch-and-bound techniques [16], has produced the state-of-the-art TSP-solver, Concorde [17].",
      "startOffset" : 208,
      "endOffset" : 212
    }, {
      "referenceID" : 17,
      "context" : "Other notable results on very large instances have been reported by LinKernighan heuristic [18] that continuously improves a solution by exchanging nodes in the tour.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 18,
      "context" : "For a readable historical background of the state-of-the-art in TSP and its various applications, see [20].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 19,
      "context" : "Held-Karp constraints [21]: 1.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 20,
      "context" : ", see [22] and its references), a notable one of which is Modularity maximization [23].",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 21,
      "context" : ", see [22] and its references), a notable one of which is Modularity maximization [23].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 22,
      "context" : "However, exact optimization of Modularity is NP-hard [24].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 23,
      "context" : "Modularity is closely related to fully connected Potts graphical models [25].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 24,
      "context" : "Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29].",
      "startOffset" : 72,
      "endOffset" : 92
    }, {
      "referenceID" : 25,
      "context" : "Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29].",
      "startOffset" : 72,
      "endOffset" : 92
    }, {
      "referenceID" : 23,
      "context" : "Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29].",
      "startOffset" : 72,
      "endOffset" : 92
    }, {
      "referenceID" : 26,
      "context" : "Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29].",
      "startOffset" : 72,
      "endOffset" : 92
    }, {
      "referenceID" : 27,
      "context" : "Many have proposed various other heuristics for modularity optimization [26, 27, 25, 28, 29].",
      "startOffset" : 72,
      "endOffset" : 92
    }, {
      "referenceID" : 22,
      "context" : "[24] use a similar LP formulation.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "This procedure is exact on trees, factor-graphs with single cycle as well as some special settings [4].",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 6,
      "context" : "Similar forms of factors is studied in several previous works [7, 8, 9].",
      "startOffset" : 62,
      "endOffset" : 71
    }, {
      "referenceID" : 7,
      "context" : "Similar forms of factors is studied in several previous works [7, 8, 9].",
      "startOffset" : 62,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : "Similar forms of factors is studied in several previous works [7, 8, 9].",
      "startOffset" : 62,
      "endOffset" : 71
    }, {
      "referenceID" : 28,
      "context" : "Figure 1: (left) The message passing results after each augmentation step for the complete graph of printing board instance from [30].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : ", minA ≡ min[1]A.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 1,
      "context" : "We combine the updates above to get a “normalized message”, ν∂vi→e, which is simply the negative of the second largest incoming message (excluding νe→∂vi ) to the factor f∂vi : ν∂vi→e = ν∂vi→e(1)− ν∂vi→e(0) = −min[2]{νe′→∂vi}e′∈∂vi\\e (5)",
      "startOffset" : 213,
      "endOffset" : 216
    }, {
      "referenceID" : 1,
      "context" : "νδ(S)→e = −max{0,min[2]{νe′→δ(S)}e′∈δ(S)\\e}} (6) Here while we are searching for the minimum incoming message, if we encounter two messages with negative or zero values, we can safely assume νδ(S)→e = 0, and stop the search.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 29,
      "context" : "This appears in applications such as data compression [31] and radiation hybrid mapping in genomics [32].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 30,
      "context" : "This appears in applications such as data compression [31] and radiation hybrid mapping in genomics [32].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 31,
      "context" : ", using TSP for gene co-clustering [33]).",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "In producing random points and features as well as random distances (in (III)), we used uniform distribution over [0, 1].",
      "startOffset" : 114,
      "endOffset" : 120
    }, {
      "referenceID" : 16,
      "context" : "In all of the experiments, we use Concorde [17] with its default settings to obtain the optimal solution.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 24,
      "context" : "Since the optimization criteria is modularity, we compared our method only against best known “modularity optimization” heuristics: (a) FastModularity[26], (b) Louvain [29], (c) Spin-glass [25] and (d) Leading eigenvector [27].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 27,
      "context" : "Since the optimization criteria is modularity, we compared our method only against best known “modularity optimization” heuristics: (a) FastModularity[26], (b) Louvain [29], (c) Spin-glass [25] and (d) Leading eigenvector [27].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 23,
      "context" : "Since the optimization criteria is modularity, we compared our method only against best known “modularity optimization” heuristics: (a) FastModularity[26], (b) Louvain [29], (c) Spin-glass [25] and (d) Leading eigenvector [27].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 25,
      "context" : "Since the optimization criteria is modularity, we compared our method only against best known “modularity optimization” heuristics: (a) FastModularity[26], (b) Louvain [29], (c) Spin-glass [25] and (d) Leading eigenvector [27].",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 11,
      "context" : "Despite losing the guarantees that make cutting plane method very powerful, our approach has several advantages: First, message passing is more efficient than LP for structured optimization [12] and it is highly parallelizable.",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 18,
      "context" : "However, due to non-integral assignments, cutting plane methods require sophisticated tricks to find violations [20].",
      "startOffset" : 112,
      "endOffset" : 116
    } ],
    "year" : 2014,
    "abstractText" : "The cutting plane method is an augmentative constrained optimization procedure that is often used with continuous-domain optimization techniques such as linear and convex programs. We investigate the viability of a similar idea within message passing – which produces integral solutions in the context of two combinatorial problems: 1) For Traveling Salesman Problem (TSP), we propose a factor-graph based on Held-Karp formulation, with an exponential number of constraint factors, each of which has an exponential but sparse tabular form. 2) For graph-partitioning (a.k.a. community mining) using modularity optimization, we introduce a binary variable model with a large number of constraints that enforce formation of cliques. In both cases we are able to derive surprisingly simple message updates that lead to competitive solutions on benchmark instances. In particular for TSP we are able to find near-optimal solutions in the time that empirically grows with N, demonstrating that augmentation is practical and efficient.",
    "creator" : "LaTeX with hyperref package"
  }
}