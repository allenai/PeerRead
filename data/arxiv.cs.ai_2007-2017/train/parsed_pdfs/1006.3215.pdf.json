{
  "name" : "1006.3215.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Solving Functional Constraints by Variable Substitution",
    "authors" : [ "YUANLIN ZHANG" ],
    "emails" : [ "yzhang@cs.ttu.edu)", "ryap@comp.nus.edu.sg)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 6.\n32 15\nv1 ["
    }, {
      "heading" : "To appear in Theory and Practice of Logic Programming (TPLP).",
      "text" : "KEYWORDS: constraint logic programming, constraint satisfaction problem, functional constraints, variable substitution, arc consistency"
    }, {
      "heading" : "1 Introduction",
      "text" : "Functional constraints are a common class of constraints occurring in Constraint Satisfaction Problem(s) (CSP) (Stallman and Sussman 1977; Van Hentenryck et al. 1992; Kirousis 1993). Roughly speaking, a constraint c(x, y) is functional if the value of variable y is some function of the value of variable x (see Definition 1). Functional constraints arise in two ways, they may occur quite naturally since one may have “functions” or “equations” in the constraint model. Functional constraints also occur systematically in in Constraint Programming (CP) when the system is a Constraint Logic Programming (CLP) system.\nFunctional constraints arise naturally in CLP in two ways. Firstly, the equations which arise from matching the head of a rule with an atom in the body are functional constraints. Secondly, the basic (or primitive) constraints in a particular instance of a CLP language will often include functional constraints. Consider, one of the most widely used and successful constraint domains for CLP, namely, finite domains which we will call CLP(FD). The basic constraints in a CLP(FD) system, for example, CHIP (Van Hentenryck et al. 1992), can express functional constraints. An example would be the finite domain constraint, 3X + 2Y = 10, with finite domain variables for X and Y .1 Matching the head and body, gives rise to a number of equations, and in a FD system, the equations are functional constraints. For example, when matching p(Z2+1) with a rule on p(X) where both X and Z are finite domain variables, a functional constraint X = Z2+1 is produced.2 We remark that in logic programming, the equations are solved by unification but in the general setting, constraint solving over the particular domain is required. Recognizing and exploiting functional constraints can facilitate the development of more efficient constraint solvers for CLP systems.\nMost work on solving functional constraints follows the approach in CSP which is based on arc or path consistency (Van Hentenryck et al. 1992; David 1995). We remark that, in many papers, “functional constraints” are actually what we call bifunctional constraints (Definition 2), a special case of functional constraints. In this paper, we propose a new method — variable substitution — to process functional constraints. The idea is that if a constraint is functional on a variable, this variable in another constraint can be substituted away using the functional constraint without losing any solution.3\nGiven a variable, the variable elimination method substitutes this variable in all constraints involving it such that it is effectively “eliminated” from the problem. This idea is applied to reduce any problem containing non-functional constraints into a canonical form where some variables can be safely ignored when solving the problem. We design an efficient algorithm to reduce, in O(ed2) where e is the number of constraints and d the size of the largest domain of the variables, a general binary CSP containing functional constraints into a canonical form. This reduction simplifies the problem and makes the functional portion trivially solvable. When the functional constraints are also bi-functional, then the algorithm is linear in the size of the CSP.\nMany CLP systems with finite domains make use of constraint propagation algorithms such as arc consistency. Unlike arc consistency, our elimination method completely solves the functional portion of the problem, hence the functional constraints are eliminated and their consequences are incorporated into the reduced problem. Our experiments show that the substitution based “global” treatment of functional constraints can significantly speed up propagation based solvers.\n1 Note that the examples which involve CLP use uppercase for variables as per the logic programming convention. In a more general context, we will use lowercase variables like x and y for variables. 2 Notice that this is not a “linear” constraint in the arithmetic sense. 3 A preliminary version of this paper appeared in (Zhang et al. 2008).\nIn the rest of the paper, background on CSPs and functional constraints is given in Section 2. Variable substitution for binary functional constraints is introduced and studied in Section 3. Section 4 presents several results on algorithms for variable elimination in general CSPs containing functional constraints. Section 5 presents an experimental study on the effectiveness of the variable elimination algorithm and explains why functional elimination leads to a smaller problem with a reduced search space. In Section 6, we extend binary functional constraints to non-binary functional constraints and we discuss substitution for general problems where there are non-binary constraints which may be in extensional and intensional form. Related work is discussed in Section 7, and the paper is concluded in Section 8."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We begin with the basic concepts and notation used in this paper.\nA binary Constraint Satisfaction Problem (CSP) (N, D, C) consists of a finite set of variables N = {v1, · · · , vn}, a set of domains D = {D1, · · · , Dn}, where Di is the domain of variable i , and a set of constraints each of which is a binary relation between two variables in N .\nA constraint between two variables i and j is denoted by cij . Symbols a and b possibly with subscript denote the values in a domain. A constraint cij is a set of allowed tuples. We assume testing whether a tuple belongs to a constraint takes constant time. For a ∈ Di and b ∈ Dj , we use either (a, b) ∈ cij or cij(a, b) to denote that values a and b satisfy the constraint cij . For the problems of interest here, we require that for all a ∈ Di and b ∈ Dj , (a, b) ∈ cij if and only if (b, a) ∈ cji. If there is no constraint on i and j, cij denotes a universal relation, i.e., Di ×Dj .\nA constraint graph G = (V,E) where V = N and E = {{i, j} | ∃cij ∈ C}. The constraint graph is usually used to describe the topological structure of a CSP. A solution of a constraint satisfaction problem is an assignment of a value to each variable such that the assignment satisfies all the constraints in the problem. A CSP is satisfiable if it has a solution. The solution space of a CSP is the set of all its solutions. Two CSPs are equivalent if and only if they have the same solution space. Throughout this paper, n represents the number of variables, d the size of the largest domain of the variables, and e the number of constraints in C.\nWe need two operations on constraints in this paper. One is the intersection of two constraints (intersection of the sets of tuples) that constrain the same set of variables. The other operation is the composition, denoted by the symbol “◦” of two constraints sharing a variable. The composition of two relations is:\ncjk ◦ cij = {(a, c) | ∃b ∈ Dj , such that (a, b) ∈ cij ∧ (b, c) ∈ cjk}.\nComposition is a basic operation in our variable substitution method. Composing cij and cjk leads to a new constraint on variables i and k.\nExample 1 Consider constraints cij = {(a1, b1), (a2, b2), (a2, b3)} and cjk = {(b1, c1), (b2, c2), (b3, c2)}. The composition of cij and cjk is a constraint on i and k: cik = {(a1, c1), (a2, c2)}.\nDefinition 1\nA constraint cij is functional on variable j if for any a ∈ Di there exists at most one b ∈ Dj such that cij(a, b). cij is functional on variable i if cji is functional on i. Given a constraint cij functional on variable j and a value a ∈ Di, we assume throughout the paper that in constant time we can find the value b ∈ Dj , if there is one, such that (a, b) ∈ cij .\nA special case of functional constraints are equations. These are ubiquitous in CLP. A typical functional constraint in arithmetic is a binary linear equation like 2x = 5− 3y which is functional on x and on y. Functional constraints do not need to be linear. For example, a nonlinear equation x2 = y2 where x, y ∈ 1..10 is also functional on both x and y. In scene labeling problems (Kirousis 1993), there are many functional constraints and other special constraints.\nWhen a constraint cij is functional on variable j, for simplicity, we say cij is functional by making use of the fact that the subscripts of cij are an ordered pair. When cij is functional on variable i, cji is said to be functional. That cij is functional does not mean cji is functional. In this paper, the definition of functional constraints is different from the one in (Zhang et al. 1999; Van Hentenryck et al. 1992) where constraints are functional on each of its variables, leading to the following notion.\nDefinition 2\nA constraint cij is bi-functional if cij is functional on variable i and also on variable j.\nA bi-functional constraint is called bijective in (David 1995). For functional constraints, we have the following property on their composition and intersection: 1) If cij and cjk are functional on variables j and k respectively, their composition remains functional; and 2) The intersection of two functional constraints remains functional.\nExample 2\nThe constraint cij = {(a1, b1), (a2, b1), (a3, b2)} is functional, while the constraint cij = {(a1, b3), (a2, b1), (a3, b2)} is both functional and bi-functional. An example of a non-functional constraint is cij = {(a1, b1), (a1, b2), (a2, b1), (a3, b2)}.\nIn the remainder of the paper, rather than writing vi, we will simply refer to a\nvariable by its subscript, i.e. i rather than vi."
    }, {
      "heading" : "3 Variable Substitution and Elimination Using Binary Functional Constraints",
      "text" : "We introduce the idea of variable substitution. Given a CSP (N,D,C), a constraint cij ∈ C that is functional on j, and a constraint cjk in C, we can substitute j by i in cjk by composing cij and cjk. If there is already a constraint cik ∈ C, the new constraint on i and k is simply the intersection of cik and cjk ◦ cij .\nDefinition 3 Consider a CSP (N,D,C), a constraint cij ∈ C functional on j, and a constraint cjk ∈ C. To substitute j by i in cjk, using cij , is to get a new CSP where cjk is replaced by c′ik = cik ∩ (cjk ◦ cij). The variable i is called the substitution variable.\nA fundamental property of variable substitution is that it preserves the solution\nspace of the problem.\nProperty 1 Given a CSP (N,D,C), a constraint cij ∈ C functional on j, and a constraint cjk ∈ C, the new problem obtained by substituting j by i in cjk is equivalent to (N,D,C).\nProof Let the new problem after substituting j by i in cjk be (N,D,C ′) where C′ = (C − {cjk}) ∪ {c ′ ik} and c ′ ik = cik ∩ (cjk ◦ cij).\nAssume (a1, a2, · · · , an) is a solution of (N,D,C). We need to show that it satisfies C′. The major difference between C′ and C is that C′ has new constraint c′ik. It is known that (ai, aj) ∈ cij , (aj , ak) ∈ cjk, and if there is cik in C, (ai, ak) ∈ cik. The fact that c′ik = (cjk ◦ cij) ∩ cik implies (ai, ak) ∈ c ′ ik. Hence, c ′ ik is satisfied by (a1, a2, · · · , an).\nConversely, we need to show that any solution (a1, a2, · · · , an) of (N,D,C ′) is a solution of (N,D,C). Given the difference between C′ and C, it is sufficient to show the solution satisfies cjk. We have (ai, aj) ∈ cij and (ai, ak) ∈ c ′ ik. Since c′ik = (cjk◦cij)∩cik, there must exist b ∈ Dj such that (ai, b) ∈ cij and (b, ak) ∈ cjk. As cij is functional, b has to be aj . Hence, aj and ak satisfy cjk.\nBased on variable substitution, we can eliminate a variable from a problem so that no constraint will be on this variable (except the functional constraint used to substitute it).\nDefinition 4 Given a CSP (N,D,C) and a constraint cij ∈ C functional on j, to eliminate j using cij is to substitute j by i, using cij , in every constraint cjk ∈ C (except cji).\nWe can also substitute j by i in cji to obtain c ′ ii and then intersect c ′ ii with the identity relation onDi, equivalent to a direct revision of the domain of i with respect to cij . This would make the algorithms presented in this paper more uniform, i.e., only operations on constraints are used. Since in most algorithms we want to make domain revision explicit, we choose not to substitute j by i in cji.\nGiven a functional constraint cij of a CSP (N,D,C), let Cj be the set of all constraints involving j, except cij . The elimination of j using cij results in a new problem (N,D,C′) where\nC′ = (C − Cj) ∪ {c ′ ik | c ′ ik = (cjk ◦ cij) ∩ cik, cjk ∈ C}.\nIn the new problem, there is only one constraint cij on j and thus j can be regarded as being “eliminated”.\nExample 3 Consider a problem with three constraints whose constraint graph is shown in Figure 1(a). Let cij be functional which this is indicated by the arrow in the diagram. The CSP after j has been eliminated using cij is shown in Figure 1(b). In the new CSP, constraints cjk and cjl are discarded, and new constraints cik = cjk ◦ cij and cil = cjl◦cij are added. Note that the other edges are not directed as the constraints cjk, cjl, cik, cil may not be functional.\nThe variable elimination involves “several” substitutions and thus preserves the\nsolution space of the original problem by Property 1.\nCorollary 1 Given a CSP (N,D,C) and a functional constraint cij ∈ C, the new problem (N,D,C′) obtained by the elimination of variable j using cij is equivalent to (N,D,C)."
    }, {
      "heading" : "4 Elimination Algorithms for CSPs with Functional Constraints and Non-Functional Constraints",
      "text" : "We now extend variable elimination to general CSPs with functional and nonfunctional constraints. The idea of variable elimination (Definition 4 in Section 3) can be used to reduce a CSP to the following canonical functional form.\nDefinition 5 A CSP (N,D,C) is in canonical functional form if for any constraint cij ∈ C functional on j, the following conditions are satisfied: 1) if cji is also functional on i(i.e., cij is bi-functional), either i or j is not constrained by any other constraint in C; 2) otherwise, j is not constrained by any other constraint in C.\nAs a trivial example, a CSP without any functional constraint is in canonical functional form. If a CSP contains some functional constraints, it is in canonical functional form intuitively if for any functional constraint cij , there is only one constraint on j. As an exception, the first condition in the definition implies that when cij is bi-functional, one variable of {i, j} might have several bi-functional constraints on it.\nIn a canonical functional form CSP, the functional constraints form disjoint star graphs. A star graph is a tree where there exists a node, called the center, which we\ncall the free variable, such that there is an edge between this center node and every other node, which we call and eliminated variable. The constraint between the free variable and eliminated variable is that it is functional on the eliminated variable. In Figure 1(a), assuming cjk and cjl are functional on k and l respectively, then there would be directed edges (arrows) from j to k and j to l. After eliminating j, we get a star graph in Figure 1(b), since i will be the free variable at the center of the star graph, with free variables k and l. Notice that before eliminating j, Figure 1(a) is a star graph, but the constraints are not in a canonical form.\nThe constraint between a free variable i and an eliminated variable j is functional on j, but it may or may not be functional on i. In the special case that the star graph contains only two variables i and j and cij is bi-functional, one of the variables can be called a free variable while the other is called an eliminated variable.\nIf a CSP is in canonical functional form, all functional constraints and the eliminated variables can be ignored when we try to find a solution for this problem. Thus, to solve a CSP (N,D,C) in canonical functional form whose non-eliminated variables are NE, we only need to solve a smaller problem (NE,D′, C′) where D′ is the set of domains of the variables NE and C′ = {cij | cij ∈ C and i, j ∈ NE}.\nProposition 1 Consider a CSP P1 = (N,D,C) in a canonical functional form and a new CSP P2 = (NE,D ′, C′) formed by ignoring the eliminated variables in P1. For any free variable i ∈ N and any constraint cij ∈ C functional on j, assume any value of Di has a support in Dj and this support can be found in constant time. Any solution of P2 is extensible to a unique solution of P1 in O(|N −NE|) time. Any solution of P1 can be obtained from a solution of P2.\nProof Let (a1, a2, · · · , a|NE|) be a solution of (NE,D ′, C′). Consider any eliminated variable j ∈ N − NE. In C, there is only one constraint on j. Let it be cij where i must be a free variable. By the assumption of the proposition, the value of i in the solution has a unique support in j. This support will be assigned to j. In this way, a unique solution for (N,D,C) is obtained. The complexity of this extension is O(|N −NE|).\nLet S be a solution of (N,D,C) and S′ the portion of S restricted to the variables in NE. S′ is a solution of (NE,D′, C′) because C′ ⊆ C. S′ can then be extended to S by using the functional constraints on the values of the free variables in S′ to give unique values for the variables in N −NE.\nAny CSP with functional constraints can be transformed into canonical functional form by variable elimination using the algorithm in Figure 2. Given a constraint cij functional on j, line 1 of the algorithm substitutes j by i in all constraints involving j. Note the arc consistency on cik, for all neighbor k of i, is enforced by line 3.\nTheorem 1 Given a CSP (N,D,C), Variable Elimination transforms the problem into a canonical functional form in O(n2d2).\nProof\nAssume Variable Elimination transforms a CSP P1 = (N,D,C) into a new problem P2 = (N,D ′, C′). We show that P2 is in canonical functional form. For any constraint cij ∈ C ′ functional on j, there are two cases. Case 1: j /∈ L when the algorithm terminates. Since j ∈ L when the algorithm starts and line 2 is the only place where j can be removed from L, j must have been eliminated at certain step of the while loop. In line 1 (the component after “∪”), all constraints on j (except cij) are removed. That is cij is the unique constraint on j. Case 2: j ∈ L when the algorithm terminates. Since cij is functional on j, variable i is not in L when the algorithm terminates (otherwise, j will be substituted by line 1 at certain step of the while loop). Therefore, i is removed from L at certain step of the while loop. i is not substituted using cki where k 6= j (otherwise cij 6∈ C ′ because of the elimination of i). This implies that i was substituted using cji, and thus cji is functional on i by the loop condition. Hence, cij is bi-functional, and i is not constrained by any other constraints (thanks to line 1). Therefore, cases 1 and 2 show that P2 is in canonical functional form.\nNext, we prove the complexity of Variable Elimination. The algorithm eliminates any variable in N at most once because once it is eliminated it is removed from L (line 2). Assume, before the algorithm, there is at most one constraint on any pair of variables (otherwise, we take the intersection of all constraints on the same pair of variables as the unique constraint). This property holds during the elimination process because in line 1, the intersection in the component before “∪” guarantees that we have only one copy of constraint on any two variables. So, for each variable j and a constraint cij functional on j, there are at most n− 2 other constraints on j. The variable j in those constraints needs to be substituted (line 1).\nThe complexity of the substitution j in each constraint is O(d2) which is the cost of the composition of a functional constraint and a general constraint. Recall that, for a functional constraint cij , given a value a ∈ Di, we can find its support in Dj in constant time. To compose cij with a general constraint cjk, for each value a ∈ Di, we find its support b ∈ Dj (in constant time). If we take each constraint\nas a matrix, the row of b of cjk will be the row of cjk ◦ cij , which takes d steps. Therefore, the cost of computing cjk ◦ cij is O(d 2).\nFor n−2 constraints, the elimination of j (line 1) takes O(nd2). There are at most n− 1 variables to eliminate and thus the worst case complexity of the algorithm is O(n2d2).\nIt is worth noting that the variable elimination algorithm is able to globally solve\nsome CSPs containing non-functional constraints.\nExample 4 Consider a simple example where there are three variables i, j, and k whose domains are {1, 2, 3} and the constraints are i = j, i = k + 1, and j 6= k. Note that although the constraints are listed in an equational form, the actual constraints are explicit and discrete, thus normal equational reasoning might not be applicable. By eliminating j using cij , cik becomes {(2, 1), (3, 2)}, and the domain of i becomes {2, 3}. The non-functional constraint cjk is gone. The problem is in canonical functional form. A solution can be obtained by letting i be 2 and consequently j = 2 and k = 1.\nBy carefully choosing an ordering of the variables to eliminate, a faster algorithm can be obtained. The intuition is that once a variable i is used to substitute for other variables, i itself should not be substituted by any other variable later.\nExample 5 Consider a CSP with functional constraints cij and cjk. Its constraint graph is shown in Figure 3(a) where a functional constraint is represented by an arrow. If we eliminate k and then j, we first get cjl1 and cjl2 , and then get cil1 and cil2 . Note that k is first substituted by j and then later j is substituted by i. If we eliminate j and then k, we first get cik, and then get cil1 and cil2 . In this way, we reduce the number of compositions of constraints.\nGiven a CSP P = (N,D,C), PF is used to denote its directed graph (V,E) where V = N and E = {(i, j) | cij ∈ C and cij is functional on j}. Non-functional constraints in C do not appear in PF . A subgraph of a directed graph is strongly connected if for any two vertices of the subgraph, any one of them is reachable from the other. A strongly connected component of a directed graph is a maximum subgraph that is strongly connected. To describe our algorithm we need the following notation.\nDefinition 6\nGiven a directed graph (V,E), a sequence of the nodes of V is a functional elimination ordering if for any two nodes i and j, i before j in the sequence implies that there is a path from i and j. A functional elimination ordering of a CSP problem P is a functional elimination ordering of PF .\nThe functional elimination ordering is used to overcome the redundant computation shown in the example on Figure 3(a). Given a directed graph G, a functional elimination ordering can be found by: 1) finding all the strongly connected components of G; 2) modifying G by taking every component as one vertex with edges changed and/or added accordingly; 3) finding a topological ordering of the nodes in the new graph; and 4) replacing any vertex v in the ordering by any sequence of the vertices of the strongly connected component represented by v.\nTo illustrate the process, consider the example in Figure 3(b) which can be taken as PF for some CSP problem P . All strongly connected components are {j1, j2, j3}, denoted by c1, and {i1, i2, i3}, denoted by c2. We construct the new graph by replacing the components by vertices: ({c1, c2}, {(c1, c2)}). We have the edge (c1, c2) because the two components are connected by (j2, i2). The topological ordering of the new graph is 〈c1, c2〉. Now we can replace c1 by any sequence of j’s and c2 by any sequence of i’s. For example, we can have a functional elimination ordering 〈j3, j2, j1, i2, i3, i1〉.\nThe algorithm Linear Elimination in Figure 4 first finds a functional elimination ordering O (line 1). The body of the while loop at line 4 is to process all the variables in O. Every variable i of O is processed as follows: i will be used to substitute for all the variables reachable from i through constraints that are functional in C0 and still exist in the current C. Those constraints are called qualified constraints. Specifically, L initially holds the immediate reachable variables through qualified constraints (line 8). Line 9 is a loop to eliminate all variables reachable from i. The loop at line 11 is to eliminate j using i from the current C. In this loop, if a constraint cjk is qualified (line 14), k is reachable from i through qualified constraints. Therefore, it is put into L (line 15).\nTo illustrate the ideas underlying the algorithm, consider the example in Figure 3(b). Now, we assume the edges in the graph are the only constraints in the problem. Assume the algorithm finds the ordering given earlier: O = 〈j3, j2, j1, i2, i3, i1〉. Next, it starts from j3. The qualified constraints leaving j3 are cj3j2 only. So, the immediate reachable variables through qualified constraints are L = {j2}. Take and delete j2 from L. Substitute j2 by j3 in constraints cj2i2 and cj2j1 . As a result, constraints cj2i2 and cj2j1 are removed from C while cj3j1 = cj3j1 ∩(cj2j1 ◦cj3j2) and new constraint cj3i2 = cj2i2 ◦cj3j2 is introduced to C. One can verify that both cj2j1 and cj2i2 are qualified. Hence, variables j1 and i2 are reachable from j3 and thus are put into L. Assume j1 is selected from L. Since there are no other constraints on j1, nothing is done. Variable i2 is then selected from L. By eliminating i2 using j3, ci2i1 and ci2i3 are removed from C and cj3i1 and cj3i3 are added to C. Constraint ci2i1 is qualified, and thus i1 is added to L. Note that ci2i3 is not qualified because it is not functional on i3 in terms of the graph. We take out the only variable i1 in\nL. After i1 is eliminated using j3, ci1i3 is removed from C, and constraint cj3i3 is updated to be cj3i3 ∩ (ci1i3 ◦ cj3i1). Since ci1i3 is qualified, i3 is added to L. One can see that although i3 was not reachable when i2 was eliminated, it finally becomes reachable because of i1. All the variables in a strongly connected component are reachable from the variable under processing if one of them is reachable. Now, take i3 out of L, and nothing is done because there are no other constraints incident on it. Every variable except j3 is marked as eliminated (line 16), the while loop on O (line 4 and 6) terminates.\nTheorem 2 Given a CSP problem, the worst case time complexity of Linear Elimination is O(ed2) where e is the number of constraints and d the size of the maximum domain in the problem.\nProof To find a functional elimination ordering involves the identification of strongly connected components and topological sorting. Each of the two operations takes linear time. Therefore, line 1 of the algorithm takes O(n+ e).\nThewhile loop of line 4 takesO(ed2). Assume that there is a unique identification number associated with each constraint in C. After some variable of a constraint is substituted, the constraint’s identification number refers to the new constraint.\nFor any identification number α, let its first associated constraint be cjk. Assuming j is substituted by some other variable i, we can show that i will be never be substituted later in the algorithm. By the algorithm, i is selected at line 5. Since\nit is the first element of O now, all variables before i in the original functional ordering have been processed. Since i is not eliminated, it is not reachable from any variable before it (in terms of the original O) through qualified constraints (due to the loop of line 9). Hence, there are two cases: 1) there is no constraint cmi of C such that c0mi is functional on i, 2) there is at least one constraint cmi of C such that c0mi is functional on i. In the first case, our algorithm will never substitute i by any other variable. By definition of functional elimination ordering, case 2 implies that i belongs to a strongly connected component whose variables have not been eliminated yet. Since all variables in the component will be substituted by i, after the loop of line 9, there is no constraint cmi of C such that c 0 mi is functional on i. Hence, i will never be substituted again.\nIn a similar fashion, if variable k is substituted by l, l will never be substituted\nlater by the algorithm.\nSo, there are at most two substitutions occurring to α. Each of these substitutions is a composition that involves a functional constraint. Hence, its complexity is O(d2) in the worst case as shown in the proof of Theorem 1.\nSince there is a unique identification number for each constraint, the total number of the unique identification numbers is e and thus the time taken by the while loop at line 4 is O(ed2). In summary, the worst case time complexity of the algorithm is O(ed2).\nBefore proving some properties of Linear Elimination, we first define trivially\nfunctional constraints.\nDefinition 7 Given a problem P , let C0 be the constraints before applying Linear Elimination and C the constraints of the problem at any moment during the algorithm. A constraint cij of C is trivially functional if it is functional and satisfies the condition: c0ij is functional or there is a path i1(= i), i2, · · · , im(= j) in C0 such that, ∀k ∈ 1..m− 1, c0ikik+1 is functional on ik+1.\nTheorem 3 Algorithm Linear Elimination transforms a CSP (N,D,C) into a canonical functional form if all newly produced functional constraints (due to substitution) are trivially functional.\nThe proof of this result is straightforward and thus omitted here.\nCorollary 2 For a CSP problem with non-functional constraints and bi-functional constraints, the worst case time complexity of algorithm Linear Elimination is linear to the problem size.\nThis result follows the observation below. When the functional constraint involved in a substitution is bi-functional, the complexity of the composition is linear to the constraints involved. From the proof of Theorem 2, the complexity of the algorithm is linear to the size of all constraints, i.e., the problem size.\nCorollary 3\nConsider a CSP with both functional and non-functional constraints. If there is a variable of the problem such that every variable of the CSP is reachable from it in PF , the satisfiability of the problem can be decided in O(ed2) using Linear Elimination.\nFor a problem with the property given in the corollary, its canonical functional form becomes a star graph. So, any value in the domain of the free variable is extensible to a solution if we add (arc) consistency enforcing during Linear Elimination. The problem is not satisfiable if a domain becomes empty during the elimination process."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "We experiment to investigate the effectiveness of variable elimination on problem solving. In our experiments, a problem is solved in two ways: (i) directly by a general solver; and (ii) variable elimination is applied before the solver.\nThere are no publicly available benchmarks on functional constraints. We test the algorithms on random problems which are sufficiently hard so that we can investigate the effect of different numbers of functional constraints and the effect of constraint tightness.\nWe generate random problems 〈n, d, e, nf, t〉 where n is the number of variables, d domain size, e the number of constraints, nf the number of functional constraints, and t the tightness of non-functional constraints. The tightness r is defined as the percentage of allowed tuples over d2. There are nf functional constraints and the rest of the binary constraints are non-functional. Each functional constraint is constructed to have d allowed tuples. In the context of random problems, the tightness factor of 1/d due to the functional constraints is rather tight. When we increase nf, it can be the case that the search space is quickly reduced due to the effect of these very tight constraints. Therefore the “hardness” of the problems drops correspondingly when there is a significant increase of nf . As described below, we try to counter this effect by removing problems which be solved too easily from the benchmarks.\nIn the experiments, we systematically test benchmark problems generated using the following parameters: n, d are 50, e varies from 100 to 710 with step size 122 (710 is ∼ 10% of the total number of possible constraints (1225)), nf varies from 2 to 12, and t varies from 0.2 to 1.0 with step size 0.05. When nf is small (for example, 2), there are so many hard problems that we can only experiment with a small portion of the problems because it is computationally infeasible. When nf is large (for example, 12), even the most difficult problem instances from the set of instances becomes easy and only a small number of backtracks is needed. These instances can be solved too easily and thus are not very useful for benchmarking the elimination algorithm (i.e., we will not expect the elimination algorithm to bring any benefits to these instances). So, we do not include the cases with nf > 12. When nf = 12, the most difficult problems we found are with e = 710. Table 1\nshows the hardness of problems instances, with nf = 12 and e = 710, in terms of the number of backtracks #bt (average of 10 instances) needed. The hardness is measured using an arc consistency solver without using the elimination algorithm. When t is from 0.2 to 0.65, the problems are too easy (#bt is 0). For the most difficult case of t being 0.8, #bt is still rather small (around 1000). On the other hand, when nf is small, one can expect that the application of elimination may not make much difference. Therefore, we do not include the cases when nf is small either.\nDue to the observations above, we evaluate the algorithm only on non-trivial problem instances and where nf is not too tiny. For each nf (varying from 6 to 12), the results of the most difficult problem instances discovered in the exploration process above is shown in Table 2. The results were obtained on a DELL PowerEdge 1850 (two 3.6GHz Intel Xeon CPUs) with Linux. We implement both the elimination algorithm and a general solver in C++. The solver uses the standard backtracking algorithm armed with arc consistency enforcing algorithm after each variable assignment. During the search, the dom/deg heuristic is used to select a variable, and the value selection heuristic is in lexicographical order.4\nIn Table 2, the cpu time is the total time of twenty problem instances for a given combination of e, nf and tightness, and the number of backtracks are their average. For the problem instances used in Table 2, the time to transform the instances into their canonical forms is negligible compared to the time needed for solving the\n4 The dom/deg heuristic is a dynamic variable selection heuristic.\ninstance. There are several reasons. First, the number of constraints involved in the elimination is relatively small compared to the total number of constraints in the problems. Second, the algorithm is as efficient as the optimal general arc consistency algorithm used in the solver. Thirdly, the elimination is applied only once to reduce the problem which can be done before the backtracking search, while the arc consistency algorithm needs to be called at every step during the search, i.e. roughly about the same as the number of backtracks.\nThe results show that the variable elimination can significantly speed up the problem solving in terms of both cpu time and the number of backtracks. It reduces the number of backtracks by two to four times and also reduces the cpu time correspondingly.\nThe statistics (cpu time and number of backtracks) used in Table 2 is for 20 problem instances for each value of the selected parameters (each row in the table). We notice that the hardness of these instances is not uniform, i.e., some instances are significantly harder than the others. To better visualize the performance of the algorithms, we replot the same data from Table 2 in Figure 5. Each data point in Figure 5, represents an instance whose x-coordinate is the number of backtracks with elimination applied while its y-coordinate is that without elimination. Both axis use a log scale.\nThe scatter plot in Figure 5 shows a similar performance improvement resulting from elimination. Note that all points above the line y = x indicate that not using elimination requires more backtracks. We highlight the instances with nf = 7 (the × symbol in the graph), which shows more extreme results as elimination can significantly speed up or slow down the problem solving. The slowing down is an interesting discovery of this experiment. An explanation is that variable elimina-\ntion changes the topology of the problem, which may affect the dynamic variable ordering heuristics of the general solver. It is well known that the performance of a constraint solver may vary significantly with a different variable ordering.\nTo have a better idea on how the elimination algorithm performs, we look at instances with various hardness. We now zoom into the case of nf = 8 and e = 588 — this has a large cpu time and is more tight from the the experiments in Table 2. We remark that our algorithm performs similarly in all these cases, so we just look at the details of a specific one with the results for all configurations where the tightness changes from 0.70 to 0.80 with a step of 0.01. The results are shown in Figure. 6 (cpu time) and Figure 7 (the number of backtracks). Again, the cpu time is the sum of the cost of 20 instances per parameter setting while the number of backtracks is their average. When the tightness is 0.79 and 0.80 the problem instances become very simple with less than 200 backtracks, we do not expect the elimination algorithm to improve the performance of the constraint solver although it reduces the number of backtracks. For most non trivial problems, elimination does help to improve the efficiency (both cpu time and the number of backtracks) significantly. When using 10 instances, we also observed that when the tightness is 0.73, the elimination leads to a worse performance of the general problem solver in terms of both cpu time and the number of backtracks.\nAs observed, when the number of functional constraints in the random problems increases, the problem instances become trivial (i.e., very few backtracks are needed to solve them). This makes it hard to fully evaluate the elimination algorithm. To reduce the potential inconsistency caused by the tight functional constraints which makes the problems easy, we use identity functions (i.e., x = y, a special case\nof functional constraint), instead of arbitrary functional constraints. We remark that we could also have used a permutation form of the identity function but that would have made the problem instance construction more complex. With identity functions, no inconsistency will result directly from functional constraints. The experimental results given in Table 3 show that we can create non trivial problems with much more functional constraints.\nFor this set of instances, the elimination can speed up the problem solving by up to several orders of magnitude (in terms of both cpu time and the number of backtracks). An important observation is that when there is a significant amount of functional constraints, the number of backtracks needed after elimination can be\nas small as 0. However, without elimination, the general problem solving may need a large number of backtracks (up to five orders of magnitude larger).\nIn summary, from our experiments, for non trivial random problems, elimination can improve the efficiency of a general constraint solver by several times to several orders of magnitude. We also observe that the elimination could make a solver slower possibly due to the change of the topological structure of the problems. However, the slowdown only occurs rarely in our experiments."
    }, {
      "heading" : "5.1 Search Space Reduction through Elimination",
      "text" : "The experiments show that the elimination could reduce the search space significantly. In fact, we can show that the elimination can help reduce the size of the search space (in terms of the current domains of the variables).\nProposition 2 Given a CSP problem P , let P ′ be the problem resulting from applying the elimination algorithm to P . After enforcing arc consistency on P ′ and P , for each variable of P ′, its domain in P ′ is a subset of that in P .\nProof Instead of proving the original proposition, we prove the following claim: given a CSP problem P = (V,D,C) and a constraint cij functional on j, let P ′ = (V − {j}, D′, C′) be the problem resulting from the elimination of j. Any value, not from Dj, removed by enforcing arc consistency on P will be removed by enforcing arc consistency on P ′. Let P 1 = (V,D1, C) and P ′1 = (V −{j}, D′1, C′) be the result of enforcing arc consistency on P and P ′ respectively. Equivalently, we will show that there exists D′′j ⊆ Dj such that P ′′ = (V,D′1 ∪ {D′′j }, C) (i.e., “plug” the domains of P ′1 to P ) is arc consistent. If this claim holds, the proposition holds by applying the claim repeatedly (as the elimination proceeds).\nLet the neighbors of j in P be i, k1, . . . , km. For any constraint clk ∈ C−{cij , cjk1 ,\n. . . , cjkm}, clk ∈ C ′. Since clk is arc consistent in P ′1, clk is arc consistent in P ′′.\nWe next show cij ∈ C is arc consistent with respect to D ′1 i and Dj, i.e., for any value a ∈ D′1i , there is a support in Dj . Assume there is no support in Dj , by the definition of substitution, a has no support in any domain of kn (n ∈ 1..m), which contradicts that cikn ∈ C ′ is arc consistent with respect to D′1i and D ′1 kn . Furthermore, let the support of a in Dj be b. We claim b has a support with respect to any constraint cjk (k ∈ {k1, . . . , km}) in P ′1. Otherwise, a has no support with respect to cik ∈ C ′ for some k ∈ {k1, . . . , km}, by the definition of substitution. It contradicts the fact that cik is arc consistent in P ′1. Let D′′j = Dj − {b | b has no support with respect to cji and D ′1 i }. Clearly D ′′ j is not empty (because cij is arc consistent in P ′1). It can be shown that cji is arc consistent over domains D ′ 1 i and D ′′ j and cij is still arc consistent on these domains too. In other words, cij is arc consistent in P ′′.\nSimilarly, we can show that cjk1 , . . . , and cjkm are arc consistent over D ′ 1 kn (n ∈\nk1..km) and D ′′ j , and thus in P ′′.\nFurthermore, after enforcing arc consistency on P and P ′, for some variables of P ′, its domain in P ′ is a proper subset of that in P . Consider the following example: V = {x, y, z}, x, y, z ∈ {1, 2}, and cxy = {(1, 1), (2, 2)}, cyz = {(1, 2), (2, 1)}, czx = {(1, 1), (2, 2)}. This problem is arc consistent and the domains of the variables are {1, 2}. However, the problem P ′ resulting from variable elimination has an empty domain.\nThus, we see that using the elimination algorithm together with arc consistency\nfor the non-functional constraints leads to a “higher amount” of consistency."
    }, {
      "heading" : "6 Beyond Binary Constraints",
      "text" : "Our presentation so far is based on binary constraints. To model real life problems, non-binary constraints are often useful. In this section, we discuss the potential extension of the work reported in this paper. The first subsection is to generalize substitution to non-binary constraints in extensional form, and the second proposes an approach to processing non-binary constraints in intensional form."
    }, {
      "heading" : "6.1 Variable Elimination and Non-binary Functional Constraints",
      "text" : "In this section, we discuss the treatment of the generalization of binary functional constraints and substitution to non-binary constraints. We first generalize the functional property from binary constraints to non-binary constraints. Then, we show how a variable is substituted by a set of variables.\nA non-binary constraint is denoted by cS where S is the set of variables in the constraint. A linear equation x + y + z = 8 with finite domains for {x, y, z} is a non-binary constraint. We now define variable instantiations. An instantiation of a set of variables Y is an assignment of values to the variables in Y . It is usually denoted by a sequence. An instantiation is denoted by a character with a bar, for example, ā.\nDefinition 8 A constraint cS is functional on j(∈ S) if for any instantiation ā of S − {j}, there is at most one value of j such that this value and ā satisfy cS . A constraint cS is functional if it is functional on some variable j ∈ S.\nExample 6 Consider a constraint x + y + z = 8 with x, y, z ∈ {1, 2, 3}. Let ā = (1, 1) and b̄ = (2, 3) be two instantiations of (x, y). For ā, no value for z can be found to satisfy the constraint. For b̄, value 3 is the only value for z to satisfy the constraint. It can be verified that the constraint is functional on z, and similarly on x and on y.\nExample 7 The constraint x2 + y2+ z = 8 with x, y, z ∈ {−1,−2,−3, 0, 1, 2, 3} is functional on z but not functional on x or y.\nThe idea of variable substitution is applicable to the functional non-binary constraints defined above. However, we need more generalised operations to implement variable substitution. Below, we always take a constraint cS as a non-binary relation whose tuples are given explicitly. It is also helpful to recall that a relation is simply a set, and we can apply set operations like intersection to relations. For example, the constraint x+y+z = 8 with x, y, z ∈ {1, 2, 3} is taken as {(2, 3, 3), (3, 2, 3), (3, 3, 2)} where each tuple is an instantiation of variables (x, y, z).\nIn the context of non-binary constraints, the composition of two constraints cS and cT with respect to a variable i ∈ S ∩ T , denoted by “◦i,” is defined below.\ncS ◦i cT = {ā | ā is an instantiation of S ∪ T − {i} and there exists a ∈ Di such that (ā, a) satisfies both cS and cT .}\nIf cS is functional on j and j is a variable of constraint cT , to substitute the\nvariable j in cT in terms of cS is to replace cT by cS ◦j cT .\nDefinition 9 Consider a CSP (N,D,C) and two constraints cS and cT in C. Assume cS is functional on j ∈ S∩T . To substitute j in constraint cT using cS is to get a new CSP (N,D,C′) where C′ = (C−{cT })∪{c ′ S∪T−{j}} and c ′ S∪T−{j} = cS∪T−{j}∩(cS◦jcT ).\nThe variable substitution preserves the solution of a CSP.\nProperty 2 Given a CSP (N,D,C), a constraint cS ∈ C functional on j, and a constraint cT ∈ C where j ∈ T , the new problem obtained after j in cT is substituted using cS is equivalent to (N,D,C).\nProof Let the new problem after j in cT is substituted be (N,D,C ′) where C′ = (C − {cT}) ∪ {c ′ S∪T−{j}} and c ′ S∪T−{j} = cS∪T−{j} ∩ (cS ◦j cT ).\nAssume ā is a solution of (N,D,C). We shall show that ā also satisfies C′. Given a set of variables Y , āY will be used to denote the values in the solution ā for the variables in Y . C′ differs from C in that it has the new constraint c′S∪T−{j}. It is known that āS ∈ cS , āT ∈ cT , and if there is cS∪T−{j} in C, āS∪T−{j} satisfies cS∪T−{j}. The fact that c ′ S∪T−{j} = (cS ◦j cT ) ∩ cS∪T−{j} implies āS∪T−{j} ∈ c′ S∪T−{j}(∈ C ′). Hence, c′ S∪T−{j} is satisfied by ā.\nConversely, we need to show that any solution ā of (N,D,C′) is a solution of (N,D,C). Given the difference between C′ and C, it is only necessary to show ā satisfies cT . To facilitate the following proof, we write āS as (āS−{j}, āj), āT as (āT−{j}, āj). We have (āS−{j}, āj) ∈ cS and āS∪T−{j} ∈ c ′ S∪T−{j}. Assume, by contradiction, (āT−{j}, āj) /∈ cT . Since āS∪T−{j} ∈ c ′ S∪T−{j}, there must exist b ∈ Dj such that b 6= āj , (āT−{j}, b) satisfies cT , and (āS−{j}, b) satisfies cS , contradicting that cS is functional on j. So, āT , that is (āT−{j}, āj), satisfies cT .\nA CSP (N,D,C) with non-binary functional constraints can be reduced by variable substitution in a similar way as developed in this paper. In the non-binary case, we note that the complexity of the algorithm is more expensive due to the composition operation (which is very close to the join operation in relational databases)."
    }, {
      "heading" : "6.2 Variable Elimination and Non-binary Constraints",
      "text" : "Non-binary constraints such as arithmetic or global constraints are common in CP systems. We discuss how variable elimination of functional constraints can be applied to these constraints. Non-binary constraints are either in extensional (defined explicitly) or intensional (defined implicitly) form. To substitute a variable in an extensional non-binary constraint, we can follow the definition given the previous subsection.\nIn most existing CP systems, for intentional constraints, there are usually particular propagators with a specific algorithm associated with them. In this case, the approach using composition is not directly applicable simply because it has to interact with a constraint defined in terms of an arbitrary specific propagation algorithm. We sketch below an approach which allows variable elimination to be employed with generic propagators. Assume we have a linear constraint c1: ax + by + cz < d and a constraint cwy functional on y. To substitute y in c1, we simply modify c1 to be ax + bw + cz < d and mark w as a shadow variable (w needs special treatment by the propagator, which will be clear later). We call y the shadowed variable. Assume we also have cuw functional on w. To eliminate w, c1 is further changed to ax+bu+cz < d. Since w is a shadow variable, we generate a new constraint cuy using cuw and cwy in a standard way as discussed in this paper. Now u becomes the shadow variable while the shadowed variable is still y (variable w is gone). Suppose we need to make c1 arc consistent. First “synchronize the domains” of y and u using cuy, i.e., enforce arc consistency on cuy. (Note that due to elimination, cwy and cuw are no longer involved in the constraint solving.) Next, we enforce arc consistency on c1. During the process, since u is a shadow variable, all domain operations are on y instead of u. After making c1 arc consistent, synchronize the domain of y and u again. (If the domain of u is changed, initiate constraint propagation on constraints involving u.) This approach is rather generic: for any intensional constraints, synchronize the domains of the shadow variables and shadowed variables, apply whatever propagation methods on the shadowed variables (and other non-shadow variables), synchronize the domains of shadow variables and shadowed variables again. In fact, the synchronization of the domains of the shadow and shadowed variables (for example, u and y above) seems be readily implementable using the concept of views (Schulte and Tack 2005)."
    }, {
      "heading" : "7 Related Work",
      "text" : "We now discuss variable substitution in the context of CLP followed by related work in variable substitution algorithms from other domains. Finally, the relationship to functional, bi-functional and other variable elimination approaches in the CSP literature."
    }, {
      "heading" : "7.1 CLP and Constraint Solving",
      "text" : "Logic Programming and CLP (Jaffar and Maher 1994) systems often make use of variable substitution and elimination. The classic unification algorithm discussed below is a good example.\nA more complex example is CLP(R) (Jaffar et al. 1992) which has constraints on finite trees and arithmetic. Variables in arithmetic constraints are substituted out using a parametric normal form which is applied during unification and also when solving arithmetic constraints. Our approach is compatible with such CLP solvers which reduce the constraint store to a normal form using variable substitution. We remark that any CLP language or system which has finite domain constraints will deal with bi-functional constraints simply because of the need to match an atom in the body with the head of a rule. The question is how powerful is the approach used. In this paper, we show that a variable substitution approach is more powerful than just simple finite domain propagation on equations. The consistency of the CSP is increased. Our experiments show that the time to solve the problem can be significantly smaller."
    }, {
      "heading" : "7.2 Unification, Gaussian Elimination, and Elimination Algorithm for Functional Constraints",
      "text" : "The algorithm for unification of finite trees, the Gaussian elimination algorithm for linear constraints and our algorithm for functional constraints share the same key techniques: variable substitution and elimination. Such algorithms are also commonly used in CLP systems. We illustrate this by examples.\nThe first is the unification of finite trees or terms. Unifying two terms f(x, y, z) and f(y, z, g(x)), where x, y and z are variables, results in three term equations: x = y, y = z, z = g(x). These equations can be solved using a variable elimination method. We select a variable and eliminate it from the system by substitution. For example, we can select to eliminate x — substitute all x by y (using the first equation x = y), which results in y = z, z = (g(y)). This process continues until some constant symbols do not match in an equation, the left hand side variable appears in a sub-term on the right hand side (or vice versa), or no new equation can be produced and there is only one term equation left.\nOur second example is equation solving for arithmetic over the real numbers. A system of binary linear constraints on real numbers can be solved by the well known Gaussian elimination method. A major step is to select a variable and eliminate it using an equation. Specifically, to eliminate x using ax + by = c, we substitute all x in the system by (c− by)/a.\nLastly, we look at the case of finite domain constraints considered in this paper. Given a binary CSP, when we have a variable x and a general constraint cyx functional on x, variable x will be eliminated by substituting x in the remainder of the constraints. The substitution here is achieved by (general) composition of relations. One can show that the substitution of x in Gaussian elimination produces an equation (a constraint) which is the result of the composition of the involved equations\n(constraints). In other words, given cyx : x = (c−by)/a and cxz : a1x+b1z = c1, the equation a1(c−by)/a+b1z = c1 is equal to the composition of cyx and cxz. Therefore, the elimination method proposed in this paper can be regarded as a generalization of Gaussian elimination for linear equations to functional constraints defined over discrete domains.\nTo see the further similarity among these algorithms, let us examine the impact of the variable elimination ordering on their efficiency. As shown in the earlier sections, if all the constraints are known a priori, we can find a good ordering to make the elimination algorithm more efficient. The same principle applies to unification algorithm. Consider the set of term equations x = f(a, a), y = f(x, x), z = f(y, y). Direct substitution using the ordering of x, y, z is more expensive than the ordering z, y, x. In fact, given a term equation, it can be unified in linear time by finding a good variable ordering (Paterson and Wegman 1978).\nIn a CLP solver, the constraints are added to the constraint store dynamically. If the newly added constraint is a binary linear equation, it has been observed that one can improve the efficiency by choosing properly a variable to eliminate from the two involved in the equation (Burg et al. 1995). For example, a brand new variable is preferred to an old one (a variable occurring previously in the constraint store). With the new variable, no substitution is necessary. For elimination using bi-functional constraints, the one involved in a lesser number of earlier constraints will be eliminated (Zhang and Yap 2002). In the case of unification, when there are several variables that can be eliminated, we choose the one that is involved in less number of constraints too (for example, (Escala-Imas and Ghallab 1988)). The variable selection idea, together with the disjoint set data structure and union-find algorithm, had led to almost linear algorithms in (Escala-Imas and Ghallab 1988; Zhang and Yap 2002)."
    }, {
      "heading" : "7.3 Functional Constraints and Variable Elimination in CSP",
      "text" : "We now discuss other work related to functional constraints from a CSP perspective.\nBi-functional constraints, a special case of functional constraints, have been studied in the context of arc consistency (AC) algorithms since Van Hentenryck et al. (Van Hentenryck et al. 1992) proposed A worst case optimal AC algorithm with O(ed) was proposed in (Van Hentenryck et al. 1992). (In many of the papers, bifunctional constraints were called functional constraints). The special properties of bi-functional constraints were used to obtain the time complexity better than that of the optimal AC algorithms such as AC2001/3.1 (O(ed2)) (Bessiere et al. 2005) for arbitrary binary constraints. A fast AC algorithm for a special class of increasing bi-functional constraints was also proposed in (Liu 1995). Here, our elimination algorithm solves the consistency of functional constraints and variable substitution incorporates the effect of the functional part of the problem into the rest of the non-functional constraints. Thus, it gives a higher level of consistency as it achieves global consistency for the functional constraints rather than local consistency like arc consistency. At the same time, it may simplify the remainder of the constraints, thus reducing the problem further.\nA new type of consistency, label-arc consistency, was introduced in (Affane and Bennaceur 1996)\nand they showed that bi-functional constraints with limited extensions to other constraints can be (globally) solved, but no detailed analysis of their algorithms is given. In (Zhang et al. 1999), we proposed a variable elimination method to solve bi-functional constraints in O(ed). Bi-functional constraints also belong to the class of “Zero/One/All” constraints which was shown to be one of the earliest classes of tractable constraints (Cooper et al. 1994). The subclass of “One” constraints in the “Zero/One/All” class corresponds to bi-functional constraints. What was not realized in (Cooper et al. 1994; Zhang et al. 1999) was that because the concern was the tractability of the class of Zero/One/All constraints, the importance of variable substitution and class of functional constraints was missed. We also point out that all the papers above deal with the special case of bi-functional constraints rather than functional constraints.\nDavid introduced pivot consistency for binary functional constraints in (David 1995).\nBoth pivot consistency and variable substitution are different ways of reducing a CSP into a special form. However, there are some important differences between pivot consistency and variable substitution in this paper. Firstly, the concept of pivot consistency, a special type of directional path consistency, is quite complex. It is defined in terms of a variable ordering, path (of length 2) consistency, and concepts in directed graphs. As we show in this paper, Variable substitution is a much simpler concept. It is intuitive and simple for binary CSPs, and it extends also simply and naturally to non-binary CSPs. Secondly, by the definition of pivot consistency, to make a CSP pivot consistent, there must be a certain functional constraint on each of the non-root variables. Variable substitution is more flexible. It can be applied whenever there is a functional constraint in a problem. Finally, to reduce a problem, the variable elimination algorithm takes O(ed2) while pivot consistency algorithm takes O((n2−r2)d2), where r is the number of root variables.\nAnother related approach is bucket elimination (Dechter 1999). The idea in common behind bucket elimination and variable substitution is to exclude the impact of a variable on the whole problem. The difference between them lies in the way variable elimination is performed. In each elimination step, substitution does not increase the arity of the constraints while bucket elimination could generate constraints with higher arity (possibly with exponential space complexity). The former may generate more constraints than the latter, but it will not increase the total number of constraints in the problem.\nAnother methodologically related work is bucket elimination (Dechter 1999). The common idea behind bucket elimination and variable substitution is to exclude the impact of a variable on the whole problem. However, they also differ in many aspects. Bucket elimination deals with general constraints while variable substitution is applicable only to functional constraints. Bucket elimination assumes a variable ordering and eliminates the impact of a variable j on all relevant constraints that involve variables before j. In contrast, variable substitution can be used to eliminate the impact of a variable on any number of relevant constraints. The ways to eliminate a variable are different for the two methods. For example, consider the CSP shown in Figure 8(a) where c12, c23, c34, and c45 are functional.\nAssume there is a variable ordering x1, x2, · · · , x5. The variables will be eliminated in the reverse of the variable ordering. When eliminating a variable, say variable x4, bucket elimination considers constraints only involving variables before (including) x4 and ignores other constraints. In this example, c45 is ignored while constraints c14, c24, c34 are considered relevant. After eliminating x4, the new ternary constraint c{1,2,3} on x1, x2, x3 is added to the problem.\nIn the variable substitution method, for variable x4 and the constraint c34 functional on it, we can choose to substitute x4 in one or some of the constraints c41, c42 and c45, depending on a specific setting (for example, a static CSP or incremental CSP). If we choose to substitute x4 in all these constraints, new binary constraints c31, c32, c35 are added and old constraints c41, c42 and c45 are discarded.\nThis example shows that in each elimination step, bucket elimination generates constraints with higher arity than variable substitution while the latter generates more constraints than the former. However, the variable substitution method will not increase the total number of constraints in the problem (because every time a new constraint is added, an old one is discarded). In the case of bi-functional constraints, it decreases the total number of constraints to n after all variables are eliminated."
    }, {
      "heading" : "8 Conclusion",
      "text" : "We have introduced a variable substitution method to reduce a problem with both functional and non-functional constraints. Compared with the previous work on bi-functional and functional constraints, the new method is not only conceptually simple and intuitive but also reflects the fundamental property of functional constraints.\nFor a binary CSP with both functional and non-functional constraints, an algorithm is presented to transform it into a canonical functional form in O(ed2). This leads to a substantial simplification of the CSP with respect to the functional constraints. In some cases, as one of our results (Corollary 2) shows, the CSP is already solved. Otherwise, the canonical form can be solved by ignoring the eliminated variables. For example, this means that search only needs to solve a smaller problem than the one before variable substitution (or elimination).\nOur experiments show that variable elimination can significantly (in some cases\nup to several orders of magnitude) improve the performance of a general solver in dealing with functional constraints. Our experiments also show some evidence that although rarely, the elimination could slow down the general solver in a non trivial way."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Chendong Li for helping implement the elimination algorithm and carrying out some experiments in the earlier stage of this research, and Satyanarayana Marisetti for writing the code for generating random functional constraints and the functional elimination ordering. Portions of this work was supported by National Univ. of Singapore, grant 252-000-303-112."
    } ],
    "references" : [ {
      "title" : "A labelling arc consistency method for functional constraints",
      "author" : [ "M.S. Affane", "H. Bennaceur" ],
      "venue" : "Proceedings of the Second International Conference on Principles and Practice of Constraint Programming. Lecture Notes in Computer Science, vol. 1118. Springer, 16–30.",
      "citeRegEx" : "Affane and Bennaceur,? 1996",
      "shortCiteRegEx" : "Affane and Bennaceur",
      "year" : 1996
    }, {
      "title" : "An optimal coarse-grained arc consistency algorithm",
      "author" : [ "C. Bessiere", "J. Regin", "R.H.C. Yap", "Y. Zhang" ],
      "venue" : "Artificial Intelligence 165, 2, 165–185.",
      "citeRegEx" : "Bessiere et al\\.,? 2005",
      "shortCiteRegEx" : "Bessiere et al\\.",
      "year" : 2005
    }, {
      "title" : "Linear equation solving for constraint logic programming",
      "author" : [ "J. Burg", "P.J. Stuckey", "J. Tai", "R.H.C. Yap" ],
      "venue" : "Proceedings of the 12th International Conference on Logic Programming. MIT Press, 33–47.",
      "citeRegEx" : "Burg et al\\.,? 1995",
      "shortCiteRegEx" : "Burg et al\\.",
      "year" : 1995
    }, {
      "title" : "Characterizing tractable constraints",
      "author" : [ "M.C. Cooper", "D.A. Cohen", "P.G. Jeavons" ],
      "venue" : "Artificial Intelligence 65, 2, 347–361.",
      "citeRegEx" : "Cooper et al\\.,? 1994",
      "shortCiteRegEx" : "Cooper et al\\.",
      "year" : 1994
    }, {
      "title" : "Using pivot consistency to decompose and solve functional CSPs",
      "author" : [ "P. David" ],
      "venue" : "Journal of Artificial Intelligence Research 2, 447–474.",
      "citeRegEx" : "David,? 1995",
      "shortCiteRegEx" : "David",
      "year" : 1995
    }, {
      "title" : "Bucket elimination: A unifying framework for reasoning",
      "author" : [ "R. Dechter" ],
      "venue" : "Artificial Intelligence 113, 1-2, 41–85.",
      "citeRegEx" : "Dechter,? 1999",
      "shortCiteRegEx" : "Dechter",
      "year" : 1999
    }, {
      "title" : "A practically efficient and almost linear unification algorithm",
      "author" : [ "G. Escala-Imas", "M. Ghallab" ],
      "venue" : "Artificial Intelligence 36, 2, 249–263.",
      "citeRegEx" : "Escala.Imas and Ghallab,? 1988",
      "shortCiteRegEx" : "Escala.Imas and Ghallab",
      "year" : 1988
    }, {
      "title" : "Constraint Logic Programming",
      "author" : [ "J. Jaffar", "M.J. Maher" ],
      "venue" : "Journal of Logic Programming 19/20, 503–581.",
      "citeRegEx" : "Jaffar and Maher,? 1994",
      "shortCiteRegEx" : "Jaffar and Maher",
      "year" : 1994
    }, {
      "title" : "The CLP(R) language and system",
      "author" : [ "J. Jaffar", "S. Michaylov", "P.J. Stuckey", "R.H.C. Yap" ],
      "venue" : "ACM Transactions on Programming Languages and Systems 14, 3, 339–395.",
      "citeRegEx" : "Jaffar et al\\.,? 1992",
      "shortCiteRegEx" : "Jaffar et al\\.",
      "year" : 1992
    }, {
      "title" : "Fast parallel constraint satisfaction",
      "author" : [ "L.M. Kirousis" ],
      "venue" : "Artificial Intelligence 64, 1, 147–160.",
      "citeRegEx" : "Kirousis,? 1993",
      "shortCiteRegEx" : "Kirousis",
      "year" : 1993
    }, {
      "title" : "Increasing functional constraints need to be checked only once",
      "author" : [ "B. Liu" ],
      "venue" : "Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence. Morgan Kaufmann, 119–125.",
      "citeRegEx" : "Liu,? 1995",
      "shortCiteRegEx" : "Liu",
      "year" : 1995
    }, {
      "title" : "Linear unification",
      "author" : [ "M.S. Paterson", "M.N. Wegman" ],
      "venue" : "Journal of Computer and System Sciences 16, 2, 158–167.",
      "citeRegEx" : "Paterson and Wegman,? 1978",
      "shortCiteRegEx" : "Paterson and Wegman",
      "year" : 1978
    }, {
      "title" : "Views and iterators for generic constraint implementations",
      "author" : [ "C. Schulte", "G. Tack" ],
      "venue" : "Recent Advances in Constraints, Joint ERCIM/CoLogNET International Workshop on Constraint Solving and Constraint Logic Programming. Lecture Notes in Computer Science, vol. 3978. Springer, 118–132.",
      "citeRegEx" : "Schulte and Tack,? 2005",
      "shortCiteRegEx" : "Schulte and Tack",
      "year" : 2005
    }, {
      "title" : "Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis",
      "author" : [ "R.M. Stallman", "G.J. Sussman" ],
      "venue" : "Artificial Intelligence 9, 2, 135–196.",
      "citeRegEx" : "Stallman and Sussman,? 1977",
      "shortCiteRegEx" : "Stallman and Sussman",
      "year" : 1977
    }, {
      "title" : "A generic arc-consistency algorithm and its specializations",
      "author" : [ "P. Van Hentenryck", "Y. Deville", "C.M. Teng" ],
      "venue" : "Artificial Intelligence 57, 2-3, 291–321.",
      "citeRegEx" : "Hentenryck et al\\.,? 1992",
      "shortCiteRegEx" : "Hentenryck et al\\.",
      "year" : 1992
    }, {
      "title" : "Incrementally solving functional constraints",
      "author" : [ "Y. Zhang", "R.H.C. Yap" ],
      "venue" : "Proceedings of the Eighteenth National Conference on Artificial Intelligence. AAAI press, 973–974.",
      "citeRegEx" : "Zhang and Yap,? 2002",
      "shortCiteRegEx" : "Zhang and Yap",
      "year" : 2002
    }, {
      "title" : "Functional elimination and 0/1/all constraints",
      "author" : [ "Y. Zhang", "R.H.C. Yap", "J. Jaffar" ],
      "venue" : "Proceedings of the Sixteenth National Conference on Artificial Intelligence. AAAI Press, 275–281.",
      "citeRegEx" : "Zhang et al\\.,? 1999",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 1999
    }, {
      "title" : "Efficient algorithms for functional constraints",
      "author" : [ "Y. Zhang", "R.H.C. Yap", "C. Li", "S. Marisetti" ],
      "venue" : "Proceedings of the 24th International Conference on Logic Programming. Lecture Notes in Computer Science, vol. 5366. Springer, 606–620.",
      "citeRegEx" : "Zhang et al\\.,? 2008",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Functional constraints are a common class of constraints occurring in Constraint Satisfaction Problem(s) (CSP) (Stallman and Sussman 1977; Van Hentenryck et al. 1992; Kirousis 1993).",
      "startOffset" : 111,
      "endOffset" : 181
    }, {
      "referenceID" : 9,
      "context" : "Functional constraints are a common class of constraints occurring in Constraint Satisfaction Problem(s) (CSP) (Stallman and Sussman 1977; Van Hentenryck et al. 1992; Kirousis 1993).",
      "startOffset" : 111,
      "endOffset" : 181
    }, {
      "referenceID" : 4,
      "context" : "Most work on solving functional constraints follows the approach in CSP which is based on arc or path consistency (Van Hentenryck et al. 1992; David 1995).",
      "startOffset" : 114,
      "endOffset" : 154
    }, {
      "referenceID" : 17,
      "context" : "3 A preliminary version of this paper appeared in (Zhang et al. 2008).",
      "startOffset" : 50,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "In scene labeling problems (Kirousis 1993), there are many functional constraints and other special constraints.",
      "startOffset" : 27,
      "endOffset" : 42
    }, {
      "referenceID" : 16,
      "context" : "In this paper, the definition of functional constraints is different from the one in (Zhang et al. 1999; Van Hentenryck et al. 1992) where constraints are functional on each of its variables, leading to the following notion.",
      "startOffset" : 85,
      "endOffset" : 132
    }, {
      "referenceID" : 4,
      "context" : "A bi-functional constraint is called bijective in (David 1995).",
      "startOffset" : 50,
      "endOffset" : 62
    }, {
      "referenceID" : 12,
      "context" : "In fact, the synchronization of the domains of the shadow and shadowed variables (for example, u and y above) seems be readily implementable using the concept of views (Schulte and Tack 2005).",
      "startOffset" : 168,
      "endOffset" : 191
    }, {
      "referenceID" : 7,
      "context" : "Logic Programming and CLP (Jaffar and Maher 1994) systems often make use of variable substitution and elimination.",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 8,
      "context" : "A more complex example is CLP(R) (Jaffar et al. 1992) which has constraints on finite trees and arithmetic.",
      "startOffset" : 33,
      "endOffset" : 53
    }, {
      "referenceID" : 11,
      "context" : "In fact, given a term equation, it can be unified in linear time by finding a good variable ordering (Paterson and Wegman 1978).",
      "startOffset" : 101,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "If the newly added constraint is a binary linear equation, it has been observed that one can improve the efficiency by choosing properly a variable to eliminate from the two involved in the equation (Burg et al. 1995).",
      "startOffset" : 199,
      "endOffset" : 217
    }, {
      "referenceID" : 15,
      "context" : "For elimination using bi-functional constraints, the one involved in a lesser number of earlier constraints will be eliminated (Zhang and Yap 2002).",
      "startOffset" : 127,
      "endOffset" : 147
    }, {
      "referenceID" : 6,
      "context" : "In the case of unification, when there are several variables that can be eliminated, we choose the one that is involved in less number of constraints too (for example, (Escala-Imas and Ghallab 1988)).",
      "startOffset" : 168,
      "endOffset" : 198
    }, {
      "referenceID" : 6,
      "context" : "The variable selection idea, together with the disjoint set data structure and union-find algorithm, had led to almost linear algorithms in (Escala-Imas and Ghallab 1988; Zhang and Yap 2002).",
      "startOffset" : 140,
      "endOffset" : 190
    }, {
      "referenceID" : 15,
      "context" : "The variable selection idea, together with the disjoint set data structure and union-find algorithm, had led to almost linear algorithms in (Escala-Imas and Ghallab 1988; Zhang and Yap 2002).",
      "startOffset" : 140,
      "endOffset" : 190
    }, {
      "referenceID" : 1,
      "context" : "1 (O(ed)) (Bessiere et al. 2005) for arbitrary binary constraints.",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 10,
      "context" : "A fast AC algorithm for a special class of increasing bi-functional constraints was also proposed in (Liu 1995).",
      "startOffset" : 101,
      "endOffset" : 111
    }, {
      "referenceID" : 0,
      "context" : "A new type of consistency, label-arc consistency, was introduced in (Affane and Bennaceur 1996) and they showed that bi-functional constraints with limited extensions to other constraints can be (globally) solved, but no detailed analysis of their algorithms is given.",
      "startOffset" : 68,
      "endOffset" : 95
    }, {
      "referenceID" : 16,
      "context" : "In (Zhang et al. 1999), we proposed a variable elimination method to solve bi-functional constraints in O(ed).",
      "startOffset" : 3,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "Bi-functional constraints also belong to the class of “Zero/One/All” constraints which was shown to be one of the earliest classes of tractable constraints (Cooper et al. 1994).",
      "startOffset" : 156,
      "endOffset" : 176
    }, {
      "referenceID" : 3,
      "context" : "What was not realized in (Cooper et al. 1994; Zhang et al. 1999) was that because the concern was the tractability of the class of Zero/One/All constraints, the importance of variable substitution and class of functional constraints was missed.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 16,
      "context" : "What was not realized in (Cooper et al. 1994; Zhang et al. 1999) was that because the concern was the tractability of the class of Zero/One/All constraints, the importance of variable substitution and class of functional constraints was missed.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 4,
      "context" : "David introduced pivot consistency for binary functional constraints in (David 1995).",
      "startOffset" : 72,
      "endOffset" : 84
    }, {
      "referenceID" : 5,
      "context" : "Another related approach is bucket elimination (Dechter 1999).",
      "startOffset" : 47,
      "endOffset" : 61
    }, {
      "referenceID" : 5,
      "context" : "Another methodologically related work is bucket elimination (Dechter 1999).",
      "startOffset" : 60,
      "endOffset" : 74
    } ],
    "year" : 2017,
    "abstractText" : "Functional constraints and bi-functional constraints are an important constraint class in Constraint Programming (CP) systems, in particular for Constraint Logic Programming (CLP) systems. CP systems with finite domain constraints usually employ CSP-based solvers which use local consistency, for example, arc consistency. We introduce a new approach which is based instead on variable substitution. We obtain efficient algorithms for reducing systems involving functional and bi-functional constraints together with other non-functional constraints. It also solves globally any CSP where there exists a variable such that any other variable is reachable from it through a sequence of functional constraints. Our experiments on random problems show that variable elimination can significantly improve the efficiency of solving problems with functional constraints. To appear in Theory and Practice of Logic Programming (TPLP).",
    "creator" : "LaTeX with hyperref package"
  }
}