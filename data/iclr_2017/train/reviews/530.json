{"conference": "ICLR 2017 conference submission", "title": "Discovering objects and their relations from entangled scene representations", "abstract": "Our world can be succinctly and compactly described as structured scenes of objects and relations. A typical room, for example, contains salient objects such as tables, chairs and books, and these objects typically relate to each other by virtue of their correlated features, such as position, function and shape. Humans exploit knowledge of objects and their relations for learning a wide spectrum of tasks, and more generally when learning the structure underlying observed data. In this work, we introduce relation networks (RNs) - a general purpose neural network architecture for object-relation reasoning. We show that RNs are capable of learning object relations from scene description data. Furthermore, we show that RNs can act as a bottleneck that induces the factorization of objects from entangled scene description inputs, and from distributed deep representations of scene images provided by a variational autoencoder. The model can also be used in conjunction with differentiable memory mechanisms for implicit relation discovery in one-shot learning tasks. Our results suggest that relation networks are a powerful architecture for solving a variety of problems that require object relation reasoning.", "histories": [], "reviews": [{"IS_META_REVIEW": true, "comments": "This paper proposes a relation network (RN) to model relations between input entities such as objects.  The relation network is built in two stages.  First a lower-level structure analyzes a pair of input entities.  All pairs of input entities are fed to this structure.  Next, the output of this lower-level structure is aggregated across all input pairs via a simple sum.  This is used as the input to a higher-level structure.  In the basic version, these two structures are each multi-layer perceptrons (MLPs).\n\nOverall, this is an interesting approach to understanding relations among entities.  The core idea is clear and well-motivated -- pooling techniques that induce invariance can be used to learn relations.  The idea builds on pooling structures (e.g. spatial/temporal average/max pooling) to focus on pairwise relations.  The current pairwise approach could potentially be extended to higher-order interactions, modulo scaling issues.\n\nExperiments on scene descriptions and images verify the efficacy of relation networks.  The MLP baselines used are incapable of modeling the structured dependencies present in these tasks.  It would be interesting to know if pooling operators (e.g. across-object max pooling in an MLP) or data augmentation via permutation would be effective for training MLPs at these tasks.  Regardless, the model proposed here is novel and effective at handling relations and shows promise for higher-level reasoning tasks."}, {"DATE": "06 Feb 2017 (modified: 07 Feb 2017)", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes RNs, relational networks, for representing and reasoning about object relations. Experiments show interesting results such as the capability to disentangling scene descriptions. AR3 praises the idea and the authors for doing this nice and involved analysis. AR1 also liked the paper. Indeed, taking a step back and seeing whether we are able to learn meaningful relations is needed in order to build more complex systems.\n \n However, AR2 raised some important issues: 1) the paper is extremely toy; RN has a very simplistic structure, and is only shown to work on synthetic examples that to some extent fit the assumptions of the RN. 2) there is important literature that addresses relation representations that has been entirely overlooked by the authors. The reviewer implied missed citations from a field that is all about learning object relations. In its current form, the paper does not have a review of related work. The AC does not see any citations in a discussion nor in the final revision. This is a major letdown. The reviewer also mentioned the fact that showing results on real datasets would strengthen the paper, which was also brought up by AR3. This indeed would have added value to the paper, although it is not a deal breaker.\n \n The reviewer AR2 did not engage in discussions, which indeed is not appropriate. The AC does weigh this review less strongly.\n \n Give the above feedback, we recommend this paper for the workshop. The authors are advised to add a related work section with a thorough review over the relevant fields and literature.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Well motivated model for relationship prediction in abstract scenes with good experimental analysis in a controlled setting.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "+ Understanding relations between objects is an important task in domains like vision, language and robotics. However, models trained on real-life datasets can often exploit simple object properties (not relation-based) to identify relations (eg: animals of bigger size are typically predators and small-size animals are preys). Such models can predict relations without necessarily understanding them. Given the difficulty of the task, a controlled setting is required to investigate if neural networks can be designed to actually understand pairwise object relations. The current paper takes a significant step in answering this question through a controlled dataset. Also, multiple experiments are presented to validate the \"relation learning\" ability of proposed Relation Networks (RN).\n\n+ The dataset proposed in the paper ensures that relation classification models can succeed only by learning the relations between objects and not by exploiting \"predator-prey\" like object properties.\n\n+ The paper presents very thorough experiments to validate the claim that \"RNs\" truly learn the relation between objects.\n  1. In particular, the ability of the RN to force a simple linear layer to disentangle scene description from VAE latent space and permuted description is very interesting. This clearly demonstrates that the RN learns object relations.\n  2. The one-shot experiments again demonstrate this ability in a convincing manner. This requires the model to understand relations in each run, represent them through an abstract label and assign the label to future samples from the relationship graph.\n\nSome suggestions:\n\n- Is g_{\\psi}(.) permutation invariant as well. Since it works on pairs of objects, how did you ensure that the MLP is invariant to the order of the objects in the pair?\n- The RNs need to operate over pairs of objects in order to identify pairwise interactions. However, in practical applications there are more complicated group interactions. (eg. ternary interaction: \"person\" riding a \"bike\" wears \"helmet\"). Would this require g(.) of RN to not just operate on pairs but on every possible subset of objects in the scene? More generally, is such a pairwise edge-based approach scalable to larger number of objects?\n- The authors mention that \" a deep network with a sufficiently large number of parameters and a large enough training set should be capable of matching the performance of a RN\". This is an interesting point, and could be true in practice. Have the authors investigated this effect by trying to identify the minimum model capacity and/or training examples required by a MLP to match the performance of RN for the provided setup? This would help in quantifying the significance of RN for practical applications with limited examples. In other words, the task in Sec. 5.1 could benefit from another plot: the performance of MLP and RN at different amounts of training samples.\n- While the simulation setup in the current paper is a great first-step towards analyzing the \"relation-learning\" ability of RNs, it is still not clear if this would transfer to real-life datasets. I strongly encourage the authors to experiment on real-life datasets like Coco, visual genome or HICO as stated in the pre-review stage.\n- Minor: Some terminologies in the paper such as \"objects\" and \"scene descriptions\" used to refer to abstract entities can be misleading for readers from the object detection domain in computer vision. This could be clarified early on in the introduction.\n- Minor: Some results like Fig. 8 which shows the ability of RN to generalize to unseen categories are quite interesting and could be moved to the main draft for completeness.\n\nThe paper proposes a network which is capable of understanding relationships between objects in a scene. This ability of the RN is thoroughly investigated through a series of experiments on a controlled dataset. While, the model is currently evaluated only on a simulated dataset, the results are quite promising and could translate to real-life datasets as well.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "16 Dec 2016", "TITLE": "N/A", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "The paper promises much more than it delivers. It ignores completely the litterature and only tackles a toy synthetic example. Clearly below the bar", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes relation networks in order to model the pairwise interactions between objects in a visual scene. \nThe model is very straight forward, first an MLP (with shared weights) is applied to each pair of objects. Finally a prediction is created by an MLP which operates by summing non-linear functions of these pairs of objects. \nExperimental evaluation is done in a synthetic dataset that is generated to fit the architecture hand-crafted in this paper. \n\nThe title of the paper claims much more than the paper delivers. Discovering objects and their relations is a very important task.\nHowever, this paper does not discover objects or their relations, instead, each objects is represented with hand coded ground truth attributes, and only a small set of trivial relationships are \"discovered\", e.g., relative position. \n\nDiscovering objects and their relationships has been tackled for several decades in computer vision (CV). The paper does not cite or compare to any technique in this body of literature. This is typically refer to as \"contextual models\".\n\nCan the proposed architecture help object detection and/or scene classification? would it work in the presence of noise (e.g, missing detections, non accurate detection estimates, complex texture)? would it work when the attributes of objects are estimated from real images? \n \nI'll be more convinced if experiments where done in real scenes. In the case of indoor scenes, datasets such as NYUv2, Sun-RGB-D, SceneNN, Chen et al CVPR 14 (text-to-image-correference) could be used. In outdoor scenes, KITTI and the relationships between cars, pedestrians and cyclist could also serve as benchmark. \n\nWithout showing real scenes, this paper tackles a too toy problem with a very simple model which does not go much further than current context models, which model pairwise relationships between objects (with MRFs, with deep nets, etc). \n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "12 Dec 2016", "TITLE": "Revised paper", "IS_META_REVIEW": false, "comments": "We\u2019ve uploaded a new version of the paper that addresses much of the reviewers\u2019 comments and questions. Additionally, we included a new experiment that sheds light on the modelling power of RNs. Specifically, we tested the RN on withheld, never-before-seen scene classes, and showed that it can successfully classify scenes from these classes. These results suggest that the RN is learning something compositional about the scenes (e.g., the existence of specific object relations). Thus, RNs can infer object relations, and combine them in unique ways to predict scene class membership. They are therefore able to generalize in a combinatorially complex object-relation space, which is a hallmark feature of compositional learning.", "OTHER_KEYS": "Adam Santoro"}, {"TITLE": "Novel modeling of entity relationships in a neural network", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes a relation network (RN) to model relations between input entities such as objects.  The relation network is built in two stages.  First a lower-level structure analyzes a pair of input entities.  All pairs of input entities are fed to this structure.  Next, the output of this lower-level structure is aggregated across all input pairs via a simple sum.  This is used as the input to a higher-level structure.  In the basic version, these two structures are each multi-layer perceptrons (MLPs).\n\nOverall, this is an interesting approach to understanding relations among entities.  The core idea is clear and well-motivated -- pooling techniques that induce invariance can be used to learn relations.  The idea builds on pooling structures (e.g. spatial/temporal average/max pooling) to focus on pairwise relations.  The current pairwise approach could potentially be extended to higher-order interactions, modulo scaling issues.\n\nExperiments on scene descriptions and images verify the efficacy of relation networks.  The MLP baselines used are incapable of modeling the structured dependencies present in these tasks.  It would be interesting to know if pooling operators (e.g. across-object max pooling in an MLP) or data augmentation via permutation would be effective for training MLPs at these tasks.  Regardless, the model proposed here is novel and effective at handling relations and shows promise for higher-level reasoning tasks.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "10 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "08 Dec 2016", "TITLE": "Dataset construction clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "inferring relations from pixels", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}, {"IS_META_REVIEW": true, "comments": "This paper proposes a relation network (RN) to model relations between input entities such as objects.  The relation network is built in two stages.  First a lower-level structure analyzes a pair of input entities.  All pairs of input entities are fed to this structure.  Next, the output of this lower-level structure is aggregated across all input pairs via a simple sum.  This is used as the input to a higher-level structure.  In the basic version, these two structures are each multi-layer perceptrons (MLPs).\n\nOverall, this is an interesting approach to understanding relations among entities.  The core idea is clear and well-motivated -- pooling techniques that induce invariance can be used to learn relations.  The idea builds on pooling structures (e.g. spatial/temporal average/max pooling) to focus on pairwise relations.  The current pairwise approach could potentially be extended to higher-order interactions, modulo scaling issues.\n\nExperiments on scene descriptions and images verify the efficacy of relation networks.  The MLP baselines used are incapable of modeling the structured dependencies present in these tasks.  It would be interesting to know if pooling operators (e.g. across-object max pooling in an MLP) or data augmentation via permutation would be effective for training MLPs at these tasks.  Regardless, the model proposed here is novel and effective at handling relations and shows promise for higher-level reasoning tasks."}, {"DATE": "06 Feb 2017 (modified: 07 Feb 2017)", "TITLE": "ICLR committee final decision", "IS_META_REVIEW": false, "comments": "This paper proposes RNs, relational networks, for representing and reasoning about object relations. Experiments show interesting results such as the capability to disentangling scene descriptions. AR3 praises the idea and the authors for doing this nice and involved analysis. AR1 also liked the paper. Indeed, taking a step back and seeing whether we are able to learn meaningful relations is needed in order to build more complex systems.\n \n However, AR2 raised some important issues: 1) the paper is extremely toy; RN has a very simplistic structure, and is only shown to work on synthetic examples that to some extent fit the assumptions of the RN. 2) there is important literature that addresses relation representations that has been entirely overlooked by the authors. The reviewer implied missed citations from a field that is all about learning object relations. In its current form, the paper does not have a review of related work. The AC does not see any citations in a discussion nor in the final revision. This is a major letdown. The reviewer also mentioned the fact that showing results on real datasets would strengthen the paper, which was also brought up by AR3. This indeed would have added value to the paper, although it is not a deal breaker.\n \n The reviewer AR2 did not engage in discussions, which indeed is not appropriate. The AC does weigh this review less strongly.\n \n Give the above feedback, we recommend this paper for the workshop. The authors are advised to add a related work section with a thorough review over the relevant fields and literature.", "OTHER_KEYS": "ICLR 2017 pcs"}, {"TITLE": "Well motivated model for relationship prediction in abstract scenes with good experimental analysis in a controlled setting.", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "+ Understanding relations between objects is an important task in domains like vision, language and robotics. However, models trained on real-life datasets can often exploit simple object properties (not relation-based) to identify relations (eg: animals of bigger size are typically predators and small-size animals are preys). Such models can predict relations without necessarily understanding them. Given the difficulty of the task, a controlled setting is required to investigate if neural networks can be designed to actually understand pairwise object relations. The current paper takes a significant step in answering this question through a controlled dataset. Also, multiple experiments are presented to validate the \"relation learning\" ability of proposed Relation Networks (RN).\n\n+ The dataset proposed in the paper ensures that relation classification models can succeed only by learning the relations between objects and not by exploiting \"predator-prey\" like object properties.\n\n+ The paper presents very thorough experiments to validate the claim that \"RNs\" truly learn the relation between objects.\n  1. In particular, the ability of the RN to force a simple linear layer to disentangle scene description from VAE latent space and permuted description is very interesting. This clearly demonstrates that the RN learns object relations.\n  2. The one-shot experiments again demonstrate this ability in a convincing manner. This requires the model to understand relations in each run, represent them through an abstract label and assign the label to future samples from the relationship graph.\n\nSome suggestions:\n\n- Is g_{\\psi}(.) permutation invariant as well. Since it works on pairs of objects, how did you ensure that the MLP is invariant to the order of the objects in the pair?\n- The RNs need to operate over pairs of objects in order to identify pairwise interactions. However, in practical applications there are more complicated group interactions. (eg. ternary interaction: \"person\" riding a \"bike\" wears \"helmet\"). Would this require g(.) of RN to not just operate on pairs but on every possible subset of objects in the scene? More generally, is such a pairwise edge-based approach scalable to larger number of objects?\n- The authors mention that \" a deep network with a sufficiently large number of parameters and a large enough training set should be capable of matching the performance of a RN\". This is an interesting point, and could be true in practice. Have the authors investigated this effect by trying to identify the minimum model capacity and/or training examples required by a MLP to match the performance of RN for the provided setup? This would help in quantifying the significance of RN for practical applications with limited examples. In other words, the task in Sec. 5.1 could benefit from another plot: the performance of MLP and RN at different amounts of training samples.\n- While the simulation setup in the current paper is a great first-step towards analyzing the \"relation-learning\" ability of RNs, it is still not clear if this would transfer to real-life datasets. I strongly encourage the authors to experiment on real-life datasets like Coco, visual genome or HICO as stated in the pre-review stage.\n- Minor: Some terminologies in the paper such as \"objects\" and \"scene descriptions\" used to refer to abstract entities can be misleading for readers from the object detection domain in computer vision. This could be clarified early on in the introduction.\n- Minor: Some results like Fig. 8 which shows the ability of RN to generalize to unseen categories are quite interesting and could be moved to the main draft for completeness.\n\nThe paper proposes a network which is capable of understanding relationships between objects in a scene. This ability of the RN is thoroughly investigated through a series of experiments on a controlled dataset. While, the model is currently evaluated only on a simulated dataset, the results are quite promising and could translate to real-life datasets as well.", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "17 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "16 Dec 2016", "TITLE": "N/A", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2"}, {"TITLE": "The paper promises much more than it delivers. It ignores completely the litterature and only tackles a toy synthetic example. Clearly below the bar", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "This paper proposes relation networks in order to model the pairwise interactions between objects in a visual scene. \nThe model is very straight forward, first an MLP (with shared weights) is applied to each pair of objects. Finally a prediction is created by an MLP which operates by summing non-linear functions of these pairs of objects. \nExperimental evaluation is done in a synthetic dataset that is generated to fit the architecture hand-crafted in this paper. \n\nThe title of the paper claims much more than the paper delivers. Discovering objects and their relations is a very important task.\nHowever, this paper does not discover objects or their relations, instead, each objects is represented with hand coded ground truth attributes, and only a small set of trivial relationships are \"discovered\", e.g., relative position. \n\nDiscovering objects and their relationships has been tackled for several decades in computer vision (CV). The paper does not cite or compare to any technique in this body of literature. This is typically refer to as \"contextual models\".\n\nCan the proposed architecture help object detection and/or scene classification? would it work in the presence of noise (e.g, missing detections, non accurate detection estimates, complex texture)? would it work when the attributes of objects are estimated from real images? \n \nI'll be more convinced if experiments where done in real scenes. In the case of indoor scenes, datasets such as NYUv2, Sun-RGB-D, SceneNN, Chen et al CVPR 14 (text-to-image-correference) could be used. In outdoor scenes, KITTI and the relationships between cars, pedestrians and cyclist could also serve as benchmark. \n\nWithout showing real scenes, this paper tackles a too toy problem with a very simple model which does not go much further than current context models, which model pairwise relationships between objects (with MRFs, with deep nets, etc). \n", "IS_META_REVIEW": false, "RECOMMENDATION": 3, "DATE": "15 Dec 2016", "REVIEWER_CONFIDENCE": 5}, {"DATE": "12 Dec 2016", "TITLE": "Revised paper", "IS_META_REVIEW": false, "comments": "We\u2019ve uploaded a new version of the paper that addresses much of the reviewers\u2019 comments and questions. Additionally, we included a new experiment that sheds light on the modelling power of RNs. Specifically, we tested the RN on withheld, never-before-seen scene classes, and showed that it can successfully classify scenes from these classes. These results suggest that the RN is learning something compositional about the scenes (e.g., the existence of specific object relations). Thus, RNs can infer object relations, and combine them in unique ways to predict scene class membership. They are therefore able to generalize in a combinatorially complex object-relation space, which is a hallmark feature of compositional learning.", "OTHER_KEYS": "Adam Santoro"}, {"TITLE": "Novel modeling of entity relationships in a neural network", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "This paper proposes a relation network (RN) to model relations between input entities such as objects.  The relation network is built in two stages.  First a lower-level structure analyzes a pair of input entities.  All pairs of input entities are fed to this structure.  Next, the output of this lower-level structure is aggregated across all input pairs via a simple sum.  This is used as the input to a higher-level structure.  In the basic version, these two structures are each multi-layer perceptrons (MLPs).\n\nOverall, this is an interesting approach to understanding relations among entities.  The core idea is clear and well-motivated -- pooling techniques that induce invariance can be used to learn relations.  The idea builds on pooling structures (e.g. spatial/temporal average/max pooling) to focus on pairwise relations.  The current pairwise approach could potentially be extended to higher-order interactions, modulo scaling issues.\n\nExperiments on scene descriptions and images verify the efficacy of relation networks.  The MLP baselines used are incapable of modeling the structured dependencies present in these tasks.  It would be interesting to know if pooling operators (e.g. across-object max pooling in an MLP) or data augmentation via permutation would be effective for training MLPs at these tasks.  Regardless, the model proposed here is novel and effective at handling relations and shows promise for higher-level reasoning tasks.\n\n", "IS_META_REVIEW": false, "RECOMMENDATION": 7, "DATE": "10 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"DATE": "08 Dec 2016", "TITLE": "Dataset construction clarification", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3"}, {"DATE": "02 Dec 2016", "TITLE": "inferring relations from pixels", "IS_META_REVIEW": false, "comments": "", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1"}], "authors": "David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap, Peter Battaglia", "accepted": false, "id": "530"}