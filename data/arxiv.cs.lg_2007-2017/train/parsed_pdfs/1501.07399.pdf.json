{
  "name" : "1501.07399.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Particle Swarm Optimization for Time Series Motif Discovery",
    "authors" : [ "Joan Serrà", "Josep Lluis Arcos" ],
    "emails" : [ "jserra@iiia.csic.es.", "arcos@iiia.csic.es." ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Particle Swarm Optimization for Time Series Motif Discovery Joan Serrà and Josep Lluis Arcos\nAbstract—Efficiently finding similar segments or motifs in time series data is a fundamental task that, due to the ubiquity of these data, is present in a wide range of domains and situations. Because of this, countless solutions have been devised but, to date, none of them seems to be fully satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution coming from it: an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. By considering data from a variety of domains, we show that this solution is extremely competitive when compared to the state-of-the-art, obtaining comparable motifs in considerably less time using minimal memory. In addition, we show that it is robust to different implementation choices and see that it offers an unprecedented degree of flexibility with regard to the task. All these qualities make the presented solution stand out as one of the most prominent candidates for motif discovery in long time series streams. Besides, we believe the proposed standpoint can be exploited in further time series analysis and mining tasks, widening the scope of research and potentially yielding novel effective solutions.\nIndex Terms—Particle swarm, multimodal optimization, time series streams, motifs, anytime.\nI. INTRODUCTION\nT IME SERIES are sequences of real numbers measuredat successive, usually regular time intervals. Data in the form of time series pervade science, business, and society. Examples range from economics to medicine, from biology to physics, and from social to computer sciences. Repetitions or recurrences of similar phenomena are a fundamental characteristic of non-random natural and artificial systems and, as a measurement of the activity of such systems, time series often include pairs of segments of strikingly high similarity. These segment pairs are commonly called motifs [1], and their existence is unlikely to be due to chance alone. In fact, they usually carry important information about the underlying system. Thus, motif discovery is fundamental for understanding, characterizing, modeling, and predicting the system behind the time series [2]. Besides, motif discovery is a core part of several higher-level algorithms dealing with time series, in particular classification, clustering, summarization, compression, and rule-discovery algorithms (see, e.g., references in [2], [3]).\nIdentifying similar segment pairs or motifs implies examining all pairwise comparisons between all possible segments in a time series. This, specially when dealing with long time series streams, results in prohibitive time and space complexities. It is for this reason that the majority of motif\nJ. Serrà and J. Ll. Arcos are with IIIA-CSIC, the Artificial Intelligence Research Institute of the Spanish National Research Council, Campus de la UAB s/n, 08193 Bellaterra, Barcelona, Spain, email: {jserra,arcos}@iiia.csic.es.\ndiscovery algorithms resort to some kind of data discretization or approximation that allows them to hash and retrieve segments efficiently. Following the works by Lin et al. [1] and Chiu et al. [4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6]. These allow them to achieve a theoretically low computational complexity, but sometimes at the expense of very high constant factors. In addition, approximate algorithms usually suffer from a number of data-dependent parameters that, in most situations, are not intuitive to set (e.g., time/amplitude resolutions, dissimilarity radius, segment length, minimum segment frequency, etc.).\nA few recent approaches overcome some of these limitations. For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al. [9] use concepts from immune memory to deal with different lengths, and Floratou et al. [10] combine suffix trees with segment models to find motifs of any length. Nevertheless, in general, these approaches still suffer from other data-dependent parameters whose correct tuning can require considerable time. In addition, approximate algorithms are restricted to a specific dissimilarity measure between segments (the one implicit in their discretization step) and do not allow easy access to preliminary results, which is commonly known as anytime algorithms [11]. Finally, to the best of our knowledge, only [12]–[14] consider the identification of motif pairs containing segments of different lengths. This can be considered a relevant feature, as it produces better results in a number of different domains [13].\nIn contrast to approximate approaches, algorithms that do not discretize the data have been comparatively much less popular, with low efficiency generally. Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16]. In fact, until the work of Mueen et al. [17], the exact identification of time series motifs was thought to be intractable for even time series of moderate length. In said work, a clever segment ordering was combined with a lower bound based on the triangular inequality to yield the true, exact, most similar motif. According to the authors, the proposed algorithm was more efficient than existing approaches, including all exact and many approximate ones [17]. After Mueen et al.’s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]–[20].\nMueen himself has recently published a variable-length motif discovery algorithm which clearly outperforms the it-\nar X\niv :1\n50 1.\n07 39\n9v 1\n[ cs\n.L G\n] 2\n9 Ja\nn 20\n15\n2 erative search for the optimal length using [17] and, from the reported numbers, also outperforms further approaches such as [18]–[20]. This algorithm, called MOEN [3], is essentially parameter-free, and is believed to be one of the most efficient motif discovery algorithms available nowadays. However, its complexity is still quadratic in the length of the time series [3], and hence its applicability to large-scale time series streams remains problematic. Furthermore, in order to derive the lower bounds used, the algorithm is restricted with regard to the\ndissimilarity measure used to compare time series segments (Euclidean distance after z-normalization). In general, exact motif discovery algorithms have important restrictions with regard to the dissimilarity measure, and many of them still suffer from being non-intuitive and tedious to tune parameters. Moreover, few of them allow for anytime versions and, to the best of our knowledge, not one of them is able to identify motif pairs containing segments of different lengths.\nIn this article, we propose a new standpoint to time series motif discovery by treating the problem as an anytime multimodal optimization task. To the best of our knowledge, this standpoint is completely unseen in the literature. Here, we firstly reason and discuss its multiple advantages (Sec. II). Next, we present SWARMMOTIF (Sec. III), an anytime algorithm for time series motif discovery based on particle swarm optimization (PSO). We subsequently evaluate the performance of the proposed approach using 9 different real-world time series from distinct domains (Sec. IV). Our results show that SWARMMOTIF is extremely competitive when compared to the state-of-the-art, obtaining motif pairs of comparable similarity in considerably less time and with minimum storage requirements (Sec. V). Moreover, we show that SWARMMOTIF is significantly robust against different implementation choices. To conclude, we briefly comment on the application of multimodal optimization techniques to time series analysis and mining, which we believe has great potential (Sec. VI). The data and code used in our experiments will available online."
    }, {
      "heading" : "II. TIME SERIES MOTIF DISCOVERY AS AN ANYTIME MULTIMODAL OPTIMIZATION TASK",
      "text" : ""
    }, {
      "heading" : "A. Definitions and Task Complexity",
      "text" : "From the work by Mueen et al. [3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs. Given a time series z of length n, z = [z1, . . . zn], a normalized segment dissimilarity measure D, and a temporal window of interest between wmin and wmax samples, the topk time series motifs M = {m1, . . .mk} correspond to the k most similar segment pairs zwaa = [za, . . . za+wa−1] and z wb b = [zb, . . . zb+wb−1], for wa, wb ∈ [wmin, wmax], a ∈ [1, n−wa+1], and b ∈ [1, n − wb + 1] where, in order to avoid repeated and trivial matches [1], a + wa < b. Thus, the i-th motif can be fully described by the tuple mi = {a,wa, b, wb}. The motifs in M are non-overlapping1 and ordered from lowest to highest dissimilarity such that D(m1) ≤ D(m2) ≤ · · · ≤ D(mk) where D(mi) = D({a,wa, b, wb}) = D(zwaa , z wb b ).\n1Notice that, following [3], this definition can be trivially extended to different degrees of overlap.\n0 100 200 300 400 500 600 700 800 900\n−21\n−19\n−17\n−15\ni [samples]\nM FC\nC 1\nFig. 1. Example of a time series motif pair found in the WILDLIFE time series of [21] using SWARMMOTIF and normalized dynamic time warping as the dissimilarity measure: a = 248, wa = 244, b = 720, and wb = 235. Note that wa 6= wb and, hence, a warping of the two segments needs to take place. This specific solution cannot be found by any of the approaches mentioned in Sec. I.\nAn example of a time series motif pair from a real data set is shown in Fig. 1.\nIt is important to stress that D needs to normalize with respect to the lengths of the considered segments. Otherwise, we would not be able to compare motifs of different lengths. There are many ways to normalize with respect to the length of the considered segments. Ratanamahatana & Keogh [22] list a number of intuitive normalization mechanisms for dynamic time warping that can easily be applied to other measures. For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.\nFrom the definitions above, we can see that a brute-force search in the motif space for the most similar motifs is of O(n2w∆\n2), where w∆ = wmax − wmin + 1 (for the final time complexity one needs to further multiply by the cost of calculating D). Hence, for instance, in a perfectly feasible case where n = 107 and w∆ = 103, we have 1020 possibilities. Magnitudes like this challenge the memory and speed of any optimization algorithm, specially if we have no clue to guide the search [24]. However, it is one of our main objectives to show here that time series generally provide some continuity to this search space, and that this continuity can be exploited by optimization algorithms."
    }, {
      "heading" : "B. Continuity",
      "text" : "A fundamental property of time series is autocorrelation, implying that consecutive samples in a time series have some degree of resemblance and that, most of the time, we do not observe extremal differences between them3. This property, together with the established ways of computing similarity between time series [23], is what gives continuity to our search space. Consider a typical dissimilarity measure like dynamic time warping between z-normalized segments and the time series of Fig. 1. If we fix the motif starting points a and b to some random values, we can compute D(zia, z j b) for i, j = wmin, . . . , wmax (Fig. 2A). We see that these two dimensions\n2The only exception is with L∞, which could be considered as already being normalized.\n3If a time series had no autocorrelation, we might better treat it as an independent random process.\n3 i [samples] j [ sa m pl es ] 200 210 220 230 240 250 200 210 220 230 240 250 A i [samples] j [ sa m pl es ] 100 200 300 400 500 100 200 300 400 500 B\nFig. 2. Visualizations of the search space obtained with the WILDLIFE time series [21] and dynamic time warping as the dissimilarity measure: (A) fixing a = 110 and b = 602 but i, j = 200, . . . 250 and (B) fixing wa = 222 and wb = 240 but i, j = 1, . . . 500. Darker colors corresponds to more similarity.\nhave a clear continuity, i.e., that D(zia, z j b) ∼ D(zi+1a , z j b) ∼ D(zia, z j+1 b ) ∼ D(zi+1a , z j+1 b ), and so forth. Similarly, if we fix the motif lengths wa and wb to some random values, we can compute D(zwai , z wb j ) for i = 1, . . . n−wa and j = 1, . . . n− wb (Fig. 2B). We see that the remaining two dimensions of the problem also have some continuity, i.e., D(zwai , z wb+j j ) ∼ D(zwai+1, z wb j ) ∼ D(z wa i , z wb j+1) ∼ D(z wa i+1, z wb j+1), and so forth. The result is a four-dimensional, multimodal, continuous but noisy4 motif space, where the dissimilarity D acts as the fitness measure and the top-k valley peaks (considering dissimilarity) correspond to the top-k motifs in M."
    }, {
      "heading" : "C. Anytime Solutions",
      "text" : "Finding an optimization algorithm that can locate the global minima of the previous search spaces faster than existing motif discovery algorithms can be a difficult task. However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]–[27]. Hence, we can intuitively devise a simple strategy: if we keep the best found minima and randomly reinitialize the optimization algorithm every time it stagnates, we should, sooner or later, start locating the global minima. In the meantime, we could have obtained relatively good candidates. This corresponds to the basic paradigm of anytime algorithms [11].\nAnytime algorithms have recently been highlighted as “very beneficial for motif discovery in massive [time series] datasets” [19]. In an anytime algorithm for motif discovery, D(mi) improves over time, until it reaches the top-k dissimilarity values D(mi)∗ obtained by a brute-force search approach. Thus, we gradually improve M until we reach the true exact solution M∗. A good anytime algorithm will quickly find low D(mi), ideally reaching D(mi)∗ earlier than its non-anytime competitors (Fig. 3).\nNote that a sufficiently good M may suffice in most situations, without the need thatM =M∗. This is particularly true for more exploratory tasks, where one is typically interested in data understanding and visual inspection (see [2]), and can also hold for other tasks, as top-k motifs can be very similar among themselves. In the latter situation, given a seed within\n4We use the term noisy here to stress that the continuity of the space may be altered at some points due to potential noise in the time series. It is not the case that we have a noisy, unreliable dissimilarity measurement D that could change in successive evaluations.\n10 −1\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0082\n0.0142\n0.0247\n0.0430\n0.0749\n0.1304\nt [s]\nD (m\ni)\nRandom sampling Baseline reference Anytime algorithm\nFig. 3. Schema of a plot to assess the performance of an anytime motif discovery algorithm (blue curve). Error bars indicate 5 and 95 percentiles of D(mi), their central marker indicates the median, and the isolated dots indicate maximum and minimum values. The gray area at the bottom denotes the area where D(mi)∗ lie. The top-left black error bar acts as a reference and shows the range of D(mi) obtained by random sampling the motif space. The bottom-right red error bar is placed at the time that the baseline algorithm spent in the calculations. Better performing anytime algorithms have a curve closer to the bottom left corner, quickly entering the gray area as their execution time increases. Notice that both axes are logarithmic.\nM∗, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29]. Thus, only non-frequent or singular motifs may be missed. These can be valuable too, as the fact that they are non-frequent does not imply that they cannot carry important information (think for example of extreme events of interest that perhaps only happen twice in a measurement). For those singular motifs, we can wait longer if using an anytime algorithm, or we can resort to the state-of-the-art if that is able to provide its output within an affordable time limit."
    }, {
      "heading" : "D. Particle Swarm Optimization",
      "text" : "The continuity and anytime observations above (Secs. II-B and II-C) relax the requirements for the optimization algorithm to be employed in the considered motif spaces. In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]–[27]. Among them, we choose PSO [30]–[34]. PSO is a populationbased stochastic approach for solving continuous and discrete optimization problems [33] which has been applied to multimodal problems [35]. It is a metaheuristic [27], meaning that it cannot guarantee whether the found solution corresponds to a global optimum. The original PSO algorithm cannot even guarantee the convergence to a local optimum, but adapted versions of it have been proven to solve this issue [36]. Other versions guarantee the convergence to the global optimum, but only with the number of iterations approaching infinity [36].\nPSO has gained increasing popularity among researchers and practitioners as a robust and efficient technique for solving\n4 difficult optimization problems. It makes few or no assumptions about the problem being optimized, does not require it to be differentiable, can search very large spaces of candidate solutions, and can be applied to problems that are irregular, incomplete, noisy, dynamic, etc. (see [30]–[35] and references therein). PSO iteratively tries to improve a candidate solution with regard to a given measure of quality or fitness function. Hence, furthermore, it can be considered an anytime algorithm."
    }, {
      "heading" : "E. Advantages of an Optimization-Based Solution Using Particle Swarms",
      "text" : "Notice that treating time series motif discovery as an optimization problem naturally yields several advantages: 1) We do not require much memory, as we can basically store\nonly the stream time series and preprocess the required segments at every fitness evaluation. 2) We are able to achieve a certain efficiency, as optimization algorithms do not usually explore the full solution space and perform few fitness evaluations [24]. 3) We can employ any dissimilarity measure D as our fitness function. Its only requirements are segment length independence and a minimal search space continuity. Intuitively, this holds for the high majority of time series dissimilarity measures that are currently used (Secs. II-A and II-B). Additionally, we can straightforwardly incorporate notions of ‘interestingness’, hubness, or complexity (see references in [23]). This flexibility is very uncommon in current time series motif discovery algorithms (Sec. I). 4) We do not need to force the two segments of the motif to be of the same length. The dissimilarity function D can expressly handle segments of different lengths or we can simply upsample to the largest length (see [22]). Although considering different segment lengths has been highlighted as an objectively better approach, practically none of the current time series motif discovery algorithms contemplates this option (Sec. I). 5) Since we search for the optimal wa and wb, together with a and b, we do not need to set the exact segment lengths as a parameter. Instead, we can use a more intuitive and easier to set range of lengths wa, wb ∈ [wmin, wmax]. 6) We can easily modify our fitness criterion to work with different task settings. Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc. 7) We can incorporate notions of motif frequency to our fitness function and hence expand our similarity-based definition of motif to incorporate both notions [2]. For instance, instead of optimizing for individual motifs mi, we can optimize sets of motifs M′i of size ri such that 1 ri ∑ mj∈M′i\nD(mj) is minimal. We can choose ri to be a minimum frequency of motif appearance or we can even decide to optimize it following any suitable criterion.\nIn addition, using PSO has a number of interesting properties, some of which may be shared with other metaheurisics: 1) We have a straightforward mapping to the problem at hand\n(Sec. III-A).\n2) By construction, we have an anytime algorithm (Sec. II-D). 3) We can obtain accurate and much faster solutions, as com-\npared to the state-of-the-art in time series motif discovery (Sec. V-C). 4) We have an essentially parameter-free algorithm [33]. As will be shown, all our parameter choices turn out to be non-critical to achieve the most competitive performances (Secs. V-A and V-B). 5) We have an easily parallelizable algorithm. The agentbased nature of PSO naturally yields to parallel implementations [32]. 6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29]. Among others, we may exploit the particles’ best-sofar values or spatially close dissimilarities. 7) All of these use a simple, easy to implement algorithm requiring low storage capabilities (Sec. III-B)."
    }, {
      "heading" : "III. SWARMMOTIF",
      "text" : ""
    }, {
      "heading" : "A. Main Algorithm",
      "text" : "Our PSO approach to time series motif discovery is based on the combination of two well-known extensions to the canonical PSO [31]. On one hand, we employ multiple reinitializations of the swarm on stagnation [39]. On the other hand, we exploit the particles’ “local memories” with the intention of forming stable niches across different local minima [40]. The former emulates a parallel multi-swarm approach [35] without the need of having to define the number of swarms and their communication. The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]). SWARMMOTIF, the implementation of the two extensions, is detailed in Algorithm 1.\nSWARMMOTIF takes a time series z of length n as input, together with a segment dissimilarity measure D, and the range of segment lengths of interest, limited by wmin and wmax. The user also needs to specify k, the desired number of motifs, and tmax, the maximum time spent by the algorithm (in iterations5). SWARMMOTIF outputs a set of k nonoverlapping motifsM. We implementM as a priority queue, which typically stores more than k elements to ensure that it contains k non-overlapping motifs. This way, by sorting the motif candidates as soon as they are found, we allow potential queries toM at any time during the algorithm’s execution. In that case, we only need to dynamically check the candidates’ overlap (Sec. III-B). Notice that n, D, wmin, wmax, k, and tmax are not parameters of the algorithm, but requirements of the task (they depend on the data, the problem, and the available time). The only parameters to be set, as specified in Algorithm 1’s requirements, are the number of particles κ, the topology θ, the constriction constant φ, and the maximum amount of iterations at stagnation τ . Nevertheless, we will show that practically none of the possible parameter choices\n5The number of iterations is easy to infer from the available time as, for the same input, the elapsed time will be roughly directly proportional to the number of iterations.\n5 Algorithm 1 SWARMMOTIF(z,D,wmin,wmax,k,tmax) Input: Time series z of length n, dissimilarity measure D,\nminimum and maximum segment length wmin and wmax, number of motifs k, and maximum amount of time (number of iterations) tmax. Require: Number of particles κ, topology θ, constriction constant φ, and maximum amount of time at stagnation (number of iterations) τ . Output: A set of motifs M. 1: c0, c1, c2 ← GETCONSTANTS(φ) 2: X ,V,S,P ← INITIALIZESWARM(n,wmin,wmax,κ) 3: Θ← INITIALIZETOPOLOGY(θ,κ) 4: s∗ ←∞ 5: M← EMPTYPRIORITYQUEUE() 6: for t = 1, . . . tmax 7: for i = 1, . . . κ 8: if VALIDPOSITION(xi) 9: d← D(xi) 10: if d < si 11: si ← d 12: pi ← xi 13: M.PUSH(d,xi) 14: if d < s∗ 15: s∗ ← d 16: tupdate ← t 17: for i = 1, . . . κ 18: g ← i 19: for j in Θi 20: if sj ≤ sg 21: g ← j 22: vi ← c0vi + c1u1 ⊗ (pi − xi) + c2u2 ⊗ (pg − xi) 23: xi ← xi + vi 24: if t− tupdate = τ 25: X ,V,S,P ← INITIALIZESWARM(n,wmin,wmax,κ) 26: s∗ ←∞ 27: return NONOVERLAPPING(M,k)\nintroduces a significant variation in the reported performance (Sec. V-A).\nHaving clarified SWARMMOTIF’s input, output, and requirements, we now elaborate on its procedures. Algorithm 1 starts by computing the velocity update constants (line 1) following Clerc’s constriction method [43], i.e.,\nc0 = 2∣∣∣2− φ−√φ2 − 4φ∣∣∣\nand c1 = c2 = c0φ/2. (1)\nNext, a swarm with κ particles is initialized (line 2). The swarm is formed by four data structures: a set of particle positions X = {x1, . . . xκ}, a set of particle velocities V = {v1, . . . vκ}, a set of particle best scores S = {s1, . . . sκ}, and a set of particle best positions P = {p1, . . .pκ} (the initialization of these four data structures is detailed in Algorithm 2). Particles’ positions xi and pi completely determine\nAlgorithm 2 INITIALIZESWARM(n,wmin,wmax,κ) Input: Time series length n, minimum and maximum seg-\nment length wmin and wmax, and number of particles κ. Output: Particle positions X , velocities V , best scores S, and\nbest positions P . 1: for i = 1, . . . κ 2: xi,2 ← wmin + (wmax + 1− wmin)u 3: xi,4 ← wmin + (wmax + 1− wmin)u 4: xi,1 ← 1 + (n− xi,2)(1− √ u) 5: xi,3 ← 1 + (n− xi,4 − (xi,1 + xi,2))u 6: x′ ← As in lines 2–5 7: vi ← x′ − xi 8: si ←∞ 9: pi ← xi\n10: return X ,V,S,P\na motif candidate, and have a direct correspondence with mi (see Sec. III-B). A further data structure Θ indicates the indices of the neighbors of each particle according to a given social topology θ (line 3). Apart from the swarm, we also initialize a global best score s∗ (line 4) and the priority queueM (line 5). We then enter the main loop (lines 6–26). In it, we perform three main actions. Firstly, we compute the particles’ fitness and perform the necessary updates (lines 7–16). Secondly, we modify the particles’ position and velocity using their personal and neighborhood best positions (lines 17–23). Thirdly, we control for stagnation and reinitialize the swarm if needed (lines 24–26). Finally, when we exit the loop, we return the first k non-overlapping motif candidates from M (line 27).\nThe particles’ fitness loop (lines 7–16) can be described as follows. For the particles that have a valid position within the ranges used for particle initializations (line 8; see also Algorithm 2 for initializations), we calculate their fitness D (line 9) and, if needed, update their personal bests si and pi (lines 10–12). As mentioned, D needs to be independent of the segments’ lengths, which is typically an easy condition for time series dissimilarity measures (Sec. II-A). In the case that the particles find a new personal best, we save the motif dissimilarity d and its position xi into M (line 13). Next, we update tupdate, the last iteration when an improvement of the global best score s∗ has occurred (lines 14–16).\nThe particles’ update loop (lines 17–23) is straightforward. We first select each particle’s best neighbor g using the neighborhood personal best scores sj (lines 18–21). Then, we use the positions of the best neighbor’s personal best pg and the particle’s personal best pi to compute its new velocity and position (lines 22–23). We employ componentwise multiplication, denoted by ⊗, and two random vectors u1 and u2 whose individual components ui,j = U(0, 1), being U(l, h) a uniform real random number generator such that l ≤ U(l, h) < h. Note that by considering the particles’ neighborhood personal bests pg we follow the aforementioned local neighborhood niching strategy [40]. At the end of the loop we control for stagnation by counting the number of iterations since the last global best update and applying a threshold τ (line 24). Note that this is the mechanism responsible for the\n6 aforementioned multiple reinitialization strategy [39]. The initialization of the swarm used in Algorithm 1 (lines 2 and 25) is further detailed in Algorithm 2. In it, for each particle, two random positions xi and x′ are drawn (lines 2–6) and the initial velocity is computed as the subtraction of the two (line 7). To obtain xi and x′, uniform real random numbers u = U(0, 1) are subsequently generated. The personal best score si is set to infinite (line 8) and xi is taken as the current best position pi (line 9). Note that √ u (line 4) is used to ensure a uniform distribution of the particles across the triangular subspace formed by xi,1 and xi,3 (line 5; see also Sec. II-A).\nB. Implementation Details\nSome implementation details are missing in Algorithms 1 and 2. Firstly, positions xi are floored component-wise inside VALIDPOSITION, D, and M (thus obtaining motif mi). Secondly, the motif priority queue M is implemented as an associative container (logarithmic insertion time) that sorts its elements according to d and stores mi. Thirdly, the last visited positions are cached into a hash table (constant lookup time) in order to avoid some of the possible repeated dissimilarity computations. Fourthly, we incorporate the option to constrain the motif search by specifying a maximum segment stretch in Algorithm 2 and VALIDPOSITION. Finally, the function that returns the non-overlapping top-k motifs employs a boolean array of size n in order to avoid O(k2) comparisons between members of the queue (cf. [3]). Notice that we have a memoryefficient implementation, as we basically only need to store z and the boolean array (both of O(n) space), M (of O(k) space, k n), and X , V , S, P , and Θ (all of them of O(κ) space, κ n). The aforementioned hash table (optional) can be allocated in any predefined, available memory segment. For the sake of brevity, the interested reader is referred to the provided code for a full account of the outlined implementation details.\nC. Variants\nGiven the main Algorithm 1, we consider a number of variations that may potentially improve SWARMMOTIF’s performance without introducing too much algorithmic complexity: • Sociability: We study whether a “cognitive-only” model, a\n“social-only” one, or different weightings of the two yield to some improvements [44]. To do so, we just need to introduce a parameter α ∈ [0, 1] controlling the degree of ‘sociability’ of the particles, and implement lines 1–2 of Algorithm 3 instead of Eq. 1. • Stochastic: We investigate the use of a random inertia weight [39]. This may alleviate the need of using the same c0 in different environments, providing a potentially more adaptive trade-off between exploration and exploitation (also controlled by α in the previous point). To consider this variant, we just need to replace line 22 in Algorithm 1 by line 3 in Algorithm 3. • Velocity clamping: In addition to constriction, we study limiting the maximum velocity of the particles [45]. Empirical studies have shown that the simultaneous consideration of a\nAlgorithm 3 Variations to Algorithm 1: sociability (lines 1–2), stochastic (line 3), velocity clamping (lines 4–6), and craziness (lines 7–10).\n1: c1 ← c0φ(1− α) 2: c2 ← c0φα\n3: vi ← (1−2(1−c0))uvi+c1u1⊗(pi−xi)+c2u2⊗(pg−xi)\n4: vrange ← [n,w∆, n, w∆]/2 5: for vrangej in vrange 6: vi,j ← min(vrangej ,max(−v range j , vi,j))\n7: v′i ← As in Algorithm 2 8: for vi,j in vi 9: if u < ρ\n10: vi,j ← v′i,j .\nconstriction factor and velocity clamping results in improved performance on certain problems [46]. To apply velocity clamping we add lines 4–6 of Algorithm 3 between lines 22 and 23 of Algorithm 1. • Craziness: We introduce so-called “craziness” or “perturbation” in the particles’ velocities, as initially suggested by Kennedy & Eberhart [45]. In such variant, inspired by the sudden direction changes observed in flocking birds, the particles’ velocity is altered with a certain probability ρ, with the aim of favoring exploration by increasing directional diversity and discouraging premature convergence [47]. We coincide with [47] in that, in some sense, this can be seen as a mutation operation. To implement craziness we add lines 7–10 of Algorithm 3 between lines 22 and 23 of Algorithm 1."
    }, {
      "heading" : "IV. EVALUATION METHODOLOGY",
      "text" : "To evaluate SWARMMOTIF’s speed and accuracy we consider plots like the one presented in Fig. 3. As a reference, we draw uniform random samples from the motif search space and compute their dissimilarities (we take as many samples as the length n of the time series). As a baseline, we use the top25 motifs found by MOEN [3], which we will denote byM∗. Existing empirical evidence [3], [17] suggests that MOEN is the most efficient algorithm to retrieve the top exact similaritybased motifs in a range of lengths6 (Sec. I). Notice furthermore that here we are not that interested in obtaining all top-25 true exact motifs, but more concerned on obtaining good seed motifs within these using an anytime approach (Sec. II-C).\nAs its competitors, MOEN has however some limitations (Sec. I). Thus, to fairly compare results, we have to apply some constrains to our algorithm. Since MOEN can only use the Euclidean distance between z-normalized segments, here we also adopt this formulation for D. In addition, as MOEN only considers pairs of segments of the same length (without resampling), we have to constrain SWARMMOTIF so\n6Besides, we could not find any other promising exact or anytime approach with some available code, nor with sufficient detail to allow a reliable implementation.\n7\nthat xi,2 = xi,4. Therefore, the reported motif dissimilarities D(mi) correspond to the Euclidean distance between two znormalized segments of the same length (we divide by the length of the segments to compare different segment lengths, Sec. II-A). In the reported experiments, SWARMMOTIF is run 10 times with k = 10. We stop its execution when we find 95% of D(mi) within M∗. This way, we assess the time taken to retrieve any 10 motifs from those with at least 95% confidence. All experiments are performed using a single core of an Intel R© Xeon R© CPU E5-2620 at 2.00 GHz.\nTo demonstrate that SWARMMOTIF is not biased towards a particular data source, time series length, or motif length, we consider 9 different time series of varying length, coming from distinct domains, and a number of arbitrary but sourceconsistent motif lengths (Table I). As mentioned, we make these time series and our code available online (Sec. I). Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task: 1) DOWJONES: The daily closing values of the Dow Jones\naverage in the USA from May 2, 1885 to April 22, 2014 [49]. 2) CARCOUNT: The number of cars measured for the Glendale on ramp for the 101 North freeway in Los Angeles, CA, USA [50]. The measurement was carried out by the Freeway Performance Measurement System7 and the data was retrieved from the UCI Machine Learning Repository [51]. Segments of missing values were manually interpolated or removed. 3) INSECT: The electrical penetration graph of a beet leafhopper (circulifer tenellus) [17]. The time series was retrieved from Mueen’s website8. 4) EEG: A one hour electroencephalogram (in µV) from a single channel in a sleeping patient [17]. The time series was retrieved from Mueen’s website9 and, according to the authors, was smoothed and filtered using domain-standard procedures. 5) FIELDRECORDING: The spectral centroid (in Hz) of a field recording retrieved from Freesound10 [52]. We used the mean of the stereo channels and the spectral centroid\n7http://pems.dot.ca.gov 8http://www.cs.ucr.edu/∼mueen/MK 9http://www.cs.ucr.edu/∼mueen/OnlineMotif 10http://www.freesound.org/people/JeffWojo/sounds/121250\n(linear frequency) Vamp SDK example plugin from Sonic Visualizer [53]. We used a Hann window of 8192 samples at 44.1 KHz with 75% overlap. 6) WIND: The wind speed (in m/s) registered in the buoy of Rincon del San Jose, TX, USA, between January 1, 2010 and April 11, 2014. The time series was retrieved from the Texas Coastal Ocean Observation Network website11. Segments of missing values were manually interpolated or removed. 7) POWER: The electric power consumption (in KW) of an individual household12. The data was retrieved from the UCI Machine Learning Repository [51]. We took the global active power, removed missing values, and downsampled the original time series by a factor of 5 using averaging and 50% overlap. 8) EOG: An electrooculogram tracking the eye movements of a sleeping patient [54]. We took the downsampled time series [48] from Mueen’s web page13. 9) RANDOMWALK: A random walk time series. This was artificially synthesized using zi+1 = zi + N(0, 1) for i = 2, . . . n and z1 = 0, where N(0, 1) is a real Gaussian random number generator with zero mean and unit variance.\nTo assess the statistical significance of the differences between alternative parameter settings, we employ a two stage approach. First, we consider all settings at the same time and perform the Friedman’s test [55], which is a non-parametric statistical test used to detect differences in treatments across multiple test attempts. We use as inputs the median values for all settings for 25 equally-spaced time steps. In the case some difference between settings is detected (i.e., we reject the null hypothesis that the settings’ performances come from the same distribution), we proceed to the second stage. In it, we perform all possible pairwise comparisons between settings using the Wilcoxon signed-rank test [55], another non-parametric statistical hypothesis test used for comparing matched samples. To counteract the problem of multiple comparisons and control the so-called family-wise error rate, we employ the HolmBonferroni correction [56]. In all statistical tests, we consider a significance level of 0.01."
    }, {
      "heading" : "V. RESULTS",
      "text" : ""
    }, {
      "heading" : "A. Configuration",
      "text" : "In pre-analysis, and according to common practice, we set κ = 100, φ = 4.1, and τ = 2000. We then experimented with 6 different static topologies θ [57]: global best, local best (two neighbors), Von Neumann, random (three neighbors), wheel, and binary tree. The results showed the qualitative equivalence of all topologies except, perhaps, global best and wheel (Fig. 4). In some data sets, these two turned out to yield slightly worse performances for short-time runs of the algorithm (small t), although for longer runs they gradually became equivalent to the rest. However, in general,\n11http://lighthouse.tamucc.edu/pq 12http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+\npower+consumption 13http://www.cs.ucr.edu/∼mueen/DAME\n8 10 1 10 2 10 3 10 4 0.0082 0.0142 0.0247 0.0430 0.0749 0.1304\nt [s]\nD (m\ni)\nGlobal best Local best Von Neumann Random Wheel Binary tree\nFig. 4. Effect of θ on the EEG time series. Equivalent results were observed with the other time series.\nno systematic statistically significant difference was detected between topologies. With this in mind, we chose the local best topology to further favor exploration and parallelism, and to be more consistent with our local neighborhood design principle of Sec. III-A.\nNext, we studied the effect of the number of particles κ and the stagnation threshold τ . To do so, we kept the previous configuration with the local best topology and subsequently evaluated κ = {20, 40, 80, 160, 320} and τ = {500, 1000, 2000, 4000, 8000}. Essentially, we observed almost no performance changes under these alternative settings (Figs. 5 and 6). We only found a statistically significant difference in the case of the CARCOUNT data set. Specifically, the performance with τ = 500 was found to be statistically significantly worse than τ ≥ 2000. Regarding κ, and after considering different n, w∆ and k, a partial tendency seemed to emerge: an increasing number of particles κ was slightly beneficial for increasing lengths n, increasing w∆, and increasing k. Unfortunately, we could not obtain strong empirical evidence nor formal proof for this statement. Nonetheless, in subsequent experiments, we decided to use a value for κ and τ that dynamically adapts SWARMMOTIF’s configuration to such predefined task parameters. We arbitrarily set τ proportional to κ, and κ proportional to n and in direct relation to w∆ and k (we refer to the provided code for the exact formulation).\nTo conclude our pre-analysis, we studied the influence of the constriction constant φ. Following common practice, we considered φ = {4.02, 4.05, 4.1, 4.2, 4.4, 4.8}. In this case, we saw that high values had a negative impact on performance (Fig. 7). In particular, values of φ ≥ 4.2 or φ ≥ 4.4, depending on the data set, statistically significantly increased the motif dissimilarities at a given t. Contrastingly, values 4 < φ < 4.2 yielded stable dissimilarities with no statistically significant variation (in some data sets, this range could be extended to 4 < φ ≤ 4.4). It is well-known that higher φ values favor exploitation rather than exploration [43]. Hence, it is not\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0102\n0.0168\n0.0276\n0.0452\n0.0742\n0.1219\nt [s]\nD (m\ni)\n20 40 80 160 320\nFig. 5. Effect of κ on the WIND time series. Equivalent results were observed with the other time series.\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0240\n0.0368\n0.0562\n0.0860\n0.1316\n0.2012\nt [s]\nD (m\ni)\n500 1000 2000 4000 8000\nFig. 6. Effect of τ on the FIELDRECORDING time series. Equivalent results were observed with the other time series.\nstrange to observe that low φ values are more appropriate for searching the large motif spaces we consider here. We finally chose φ = 4.05.\nOverall, the result of our pre-analysis suggests a high degree of robustness with respect to the possible configurations. The topology θ, the number of particles κ, the stagnation threshold τ , and the constriction constant φ have, in general, no significant influence on the obtained results. The only consistent exception is observed for values of φ ≥ 4.4, which are not the most common practice [34]. The global best and wheel topologies could also constitute a further exception. However, as we have shown, these become qualitatively equivalent to the rest as execution time t increases, yielding no statistically significant difference. We believe that the reported stability of SWARMMOTIF against the tested configurations and data sets justifies the use of our setting for finding motifs in diverse time series coming from further application domains.\n9 10 0 10 1 10 2 10 3 10 4 0.0102 0.0157 0.0243 0.0375 0.0579 0.0895\nt [s]\nD (m\ni)\n4.02 4.05 4.1 4.2 4.4 4.8\nFig. 7. Effect of φ on the INSECT time series. Equivalent results were observed with the other time series.\nB. Variants\nUsing the configuration resulting from the previous section, we subsequently assessed the performance of the variations considered in Sec. III-C. We started with the sociability variant, experimenting with social-only models, α = 1, cognitive-only models, α = 0, and intermediate configurations, α = {0.2, 0.33, 0.66, 0.8}. Apart from the fact that no clear tendency could be observed, none of the previous settings was able to consistently reach the performance achieved by the original variant (α = 1/2, Eq. 1) in all time series. That is, none of the previous settings could statistically significantly outperform α = 1/2 in the majority of the data sets.\nNext, we experimented with the stochastic and the velocity clamping variants. While the former did not improve our results, the latter led to a statistically significant improvement for some time series. Because of that, we decided to discard the use of a stochastic variant but to incorporate velocity clamping to our main algorithm. The former could be difficult to justify while the latter has empirical evidence behind it (Sec. III-C).\nFinally, we experimented with craziness and its probability ρ. The results showed a similar performance for 0 ≤ ρ < 0.001, a slightly better performance for 0.001 ≤ ρ ≤ 0.01, and an increasingly worse performance for ρ > 0.01 (Fig. 8). A statistically significant difference was found between ρ ≤ 0.01 and ρ > 0.1, being ρ > 0.1 a consistently worse setting. These results were expected, as the swarm performs a more random search with increasing ρ, being completely random in the limiting case of ρ = 1. The slightly better performance for 0.001 ≤ ρ ≤ 0.01 was not found to be statistically significant under our criteria. However, it was visually noticeable for some data sets. For instance, with the EEG data set, we see that curves 33 and 34 hit the dissimilarities of the true exact motif setM∗ (gray area) two or three times earlier than curves 30, 31, and 32 (Fig. 8). With these results, and seeing that ρ values between 0.001 and 0.01 never harmed the performance of the algorithm, we chose ρ = 0.002.\n10 1\n10 2\n10 3\n10 4\n0.0082\n0.0142\n0.0247\n0.0430\n0.0749\n0.1304\nt [s]\nD (m\ni)\n0 0.00001 0.0001 0.001 0.01 0.1\nFig. 8. Effect of ρ on the EEG time series. Equivalent results were observed with the other time series."
    }, {
      "heading" : "C. Final Performance",
      "text" : "After extending SWARMMOTIF with velocity clamping and craziness, we assess its performance on all considered time series using the default parameter combination resulting from the previous two sections. As can be seen, the obtained motif dissimilarities are far from the random sampling in all cases (Fig. 9; notice the logarithmic axes). In addition, we see that SWARMMOTIF is able to already obtain dissimilarities withinM∗ as soon as its execution begins. Specifically, motif dissimilarities inM start to overlap the ones inM∗ at t < 10 s for practically all time series. The only exceptions are EOG and RANDOMWALK, where M starts to overlap with M∗ at t < 100 s. We hypothesize that taking a smaller number of particles κ could make M overlap with M∗ earlier, but leave the formal assessment of this hypothesis for future work.\nFinally, as execution time t progresses, we see that SWARMMOTIF consistently retrieves lower dissimilarities, up to the point that M ' M∗ (Fig. 9 and Table II). Following the condition we specify in Sec. IV, this means that the distances in the motif set obtained by SWARMMOTIF are not statistically worse than the ones of the true exact motif set. With respect to MOEN’s execution time, this happens 1487 (DOWJONES), 184 (CARCOUNT), 50 (INSECT), 179 (EEG), 100 (FIELDRECORDING), 241 (WIND), 286 (POWER), 74 (EOG), and 287 (RANDOMWALK) times faster. This implies between one and three orders of magnitude speedups (more than that for DOWJONES). Overall, we believe this is an extremely competitive performance for an anytime motif discovery algorithm."
    }, {
      "heading" : "VI. CONCLUSION",
      "text" : "In this article, we propose an innovative standpoint to the task of time series motif discovery by formulating it as an anytime multimodal optimization problem. After a concise but comprehensive literature review, we reason out the new formulation and the development of an approach based on\n10\nevolutionary computation. We then highlight the several advantages of this new formulation, many of which relate to a high degree of flexibility of the solutions that come from it. To the best of our knowledge, such a degree of flexibility is unseen in previous works on time series motif discovery.\nWe next present SWARMMOTIF, an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. We show that SWARMMOTIF is extremely competitive when compared to the best approach we could find in the literature. It obtains motifs of comparable similarities, in considerably less time, and with minimum memory requirements. This is confirmed with 9 independent real-world time series of increasing length coming from a variety of domains. Besides, we find that the high majority of the possible implementation choices lead to non-significant performance changes in all considered time series. Thus, given this robustness, we can think about the proposed solution as being parameter-free from the user’s perspective. Overall, if we add the aforementioned, unprecedented degree of\nflexibility, SWARMMOTIF stands out as one of the most prominent choices for motif discovery in long time series streams. Since the used data and code are available online (Sec. I), the research presented here is fully reproducible, and SWARMMOTIF is freely available to researchers and practitioners.\nWe believe that the consideration of multimodal optimization algorithms is a relevant direction for future research in the field of time series analysis and mining. Not only with regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23]. With regard to the latter, we envision powerful approaches to variable-length local similarity calculations, in the vein of existing dynamic programming approaches [58], [59]. Finally, we believe that considering the search spaces and the time constraints derived from time series problems can be a challenge for the evolutionary computation community. We look forward to exploring all these topics in forthcoming works, together with\n11\nother multimodal optimization techniques that could be easily mapped to the problem of time series motif discovery."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "We would like to thank all the people who contributed the data sets used in this study and Abdullah Mueen for additionally sharing his code. We would also like to thank Xavier Anguera for useful discussions that motivated the present work. This research has been funded by 2009-SGR-1434 from Generalitat de Catalunya, JAEDOC069/2010 from Consejo Superior de Investigaciones Cientı́ficas (JS), TIN2012-38450C03-03 from the Spanish Government, and E.U. Social and FEDER funds (JS)."
    } ],
    "references" : [ {
      "title" : "Finding motifs in time series",
      "author" : [ "J. Lin", "E. Keogh", "S. Lonardi", "P. Patel" ],
      "venue" : "Proc. of the Workshop on Temporal Data Mining, 2002, pp. 53–56.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Time series motif discovery: dimensions and applications",
      "author" : [ "A. Mueen" ],
      "venue" : "WIREs Data Mining and Knowledge Discovery, vol. 4, no. 2, pp. 152– 159, 2014.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Enumeration of time series motifs of all lengths",
      "author" : [ "——" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2013, pp. 547–556.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Probabilistic discovery of time series motifs",
      "author" : [ "B. Chiu", "E. Keogh", "S. Lonardi" ],
      "venue" : "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2003, pp. 493–498.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Experiencing SAX: a novel symbolic representation of time series",
      "author" : [ "J. Lin", "E. Keogh", "L. Wei", "S. Lonardi" ],
      "venue" : "Data Mining and Knowledge Discovery, vol. 15, no. 2, pp. 107–144, 2007.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Finding motifs using random projections",
      "author" : [ "J. Buhler", "M. Tompa" ],
      "venue" : "Journal of Computational Biology, vol. 9, no. 2, pp. 225–242, 2002.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Multiresolution motif discovery in time series",
      "author" : [ "N. Castro", "P. Azevedo" ],
      "venue" : "Proc. of the SIAM Int. Conf. on Data Mining (SDM), 2010, pp. 665–676.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Approximate variable-length time series motif discovery using grammar inference",
      "author" : [ "Y. Li", "J. Lin" ],
      "venue" : "Proc. of the Int. Workshop on Multimedia Data Mining (MDM), 2010, p. 10.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The motif tracking algorithm",
      "author" : [ "W. Wilson", "P. Birkin", "U. Aickelin" ],
      "venue" : "International Journal of Automation and Computing, vol. 5, no. 1, pp. 32–44, 2008.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Efficient and accurate discovery of patterns in sequence data sets",
      "author" : [ "A. Floratou", "S. Tata", "J.M. Patel" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering, vol. 23, no. 8, pp. 1154–1168, 2011.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Using anytime algorithms in intelligent systems",
      "author" : [ "S. Zilberstein" ],
      "venue" : "AI Magazine, vol. 17, no. 3, pp. 73–83, 1996.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Discovery of time-series motif from multi-dimensional data based on MDL principle",
      "author" : [ "Y. Tanaka", "K. Iwamoto", "K. Uehara" ],
      "venue" : "Machine Learning, vol. 58, pp. 269–300, 2005.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Detecting time series motifs under uniform scaling",
      "author" : [ "D. Yankov", "E. Keogh", "J. Medina", "B. Chiu", "V. Zordan" ],
      "venue" : "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2007, pp. 844–853.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Discovering original motifs with different lengths from time series",
      "author" : [ "H. Tang", "S.S. Liao" ],
      "venue" : "Knowledge-Based Systems, vol. 21, pp. 666– 671, 2008.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Discovering patterns in realvalued time series",
      "author" : [ "J. Catalano", "T. Armstrong", "T. Oates" ],
      "venue" : "Knowledge Discovery in Databases: PKDD 2006, ser. Lecture Notes on Artificial Intelligence, J. Fürnkranz, T. Scheffer, and M. Spiliopoulou, Eds. Berlin, Germany: Springer, 2006, vol. 4213, pp. 462–469.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Constrained motif discovery in time series",
      "author" : [ "Y. Mohammad", "T. Nishida" ],
      "venue" : "New Generation Computing, vol. 27, no. 4, pp. 319–346, 2009.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Exact discovery of time series motifs",
      "author" : [ "A. Mueen", "E. Keogh", "Q. Zhu", "S. Cash", "B. Westover" ],
      "venue" : "Proc. of the SIAM Int. Conf. on Data Mining (SDM), 2009, pp. 473–484.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Discovery of variable length time series motif",
      "author" : [ "P. Nunthanid", "V. Niennattrakul", "C.A. Ratanamahatana" ],
      "venue" : "Proc. of the Int. Conf. on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), 2011, pp. 472–475.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Efficient proper length time series motif discovery",
      "author" : [ "S. Yingchareonthawornchai", "H. Sivaraks", "T. Rakthanmanon", "C.A. Ratanamahatana" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2013, pp. 1265–1270.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Exact discovery of length-range motifs",
      "author" : [ "Y. Mohammad", "T. Nishida" ],
      "venue" : "Intelligent Information and Database Systems, ser. Lecture Notes in Artificial Intelligence, N. T. Nguyen, B. Attachoo, B. Trawiski, and K. Somboonviwat, Eds. Cham, Switzerland: Springer Int. Publishing, 2014, vol. 8398, pp. 23–32.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Online discovery and maintenance of time series motifs",
      "author" : [ "A. Mueen", "E. Keogh" ],
      "venue" : "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2010, pp. 1089–1098.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Everything you know about dynamic time warping is wrong",
      "author" : [ "C.A. Ratanamahatana", "E. Keogh" ],
      "venue" : "ACM SIGKDD Workshop on Mining Temporal and Sequential Data, 2004, pp. 22–25.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "An empirical evaluation of similarity measures for time series classification",
      "author" : [ "J. Serrà", "J.L. Arcos" ],
      "venue" : "Knowledge-Based Systems, vol. 67, pp. 305–314, 2014.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Introduction to operations research, 9th ed",
      "author" : [ "F.S. Hillier", "G.J. Lieberman" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2010
    }, {
      "title" : "Metaheuristics in combinatorial optimization: overview and conceptual comparison",
      "author" : [ "C. Blum", "A. Roli" ],
      "venue" : "ACM Computing Surveys, vol. 35, no. 3, pp. 268–308, 2003.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Evolutionary optimization in uncertain environments: a survey",
      "author" : [ "Y. Jin", "J. Branke" ],
      "venue" : "IEEE Trans. on Evolutionary Computation, vol. 9, no. 3, pp. 303–317, 2005.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "A survey on metaheuristics for stochastic combinatorial optimization",
      "author" : [ "L. Bianchi", "M. Dorigo", "L.M. Gambardella", "W.J. Gutjahr" ],
      "venue" : "Natural Computing, vol. 8, no. 2, pp. 239–287, 2009.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Optimizing similarity search for arbitrary length time series queries",
      "author" : [ "T. Kahveci", "A.K. Singh" ],
      "venue" : "IEEE Trans. on Knowledge and Data Engineering, vol. 16, no. 4, pp. 418–433, 2004.",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Searching and mining trillions of time series subsequences under dynamic time warping",
      "author" : [ "T. Rakthanmanon", "B. Campana", "A. Mueen", "G.E.A.P.A. Batista", "B. Westover", "Q. Zhu", "J. Zakaria", "E. Keogh" ],
      "venue" : "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2012, pp. 262–270.",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Particle swarm optimization",
      "author" : [ "M. Clerc" ],
      "venue" : "London, UK: ISTE,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2006
    }, {
      "title" : "Particle swarm optimization",
      "author" : [ "R. Poli", "J. Kennedy", "T.M. Blackwell" ],
      "venue" : "Swarm Intelligence, vol. 1, no. 1, pp. 33–57, 2007.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "A review of particle swarm optimization. Part I: background and development",
      "author" : [ "A. Banks", "J. Vincent", "C. Anyakoha" ],
      "venue" : "Natural Computing, vol. 6, no. 4, pp. 467–484, 2007.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Particle swarm optimization and  12 intelligence: advances and applications",
      "author" : [ "K.E. Parsopoulos", "M.N. Vrahatis" ],
      "venue" : "Hershey, USA: IGI Global,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2010
    }, {
      "title" : "A review of particle swarm optimization methods used for multimodal optimization",
      "author" : [ "J. Barrera", "C. Coello Coello" ],
      "venue" : "Innovations in Swarm Intelligence, ser. Studies in Computational Intelligence, C. P. Lim, L. C. Jain, and S. Dehuri, Eds. Berlin, Germany: Springer, 2009, vol. 248, pp. 9–37.",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A convergence proof for the particle swarm optimizer",
      "author" : [ "F. van der Bergh", "A.P. Engelbrecht" ],
      "venue" : "Fundamenta Informaticae, vol. 105, no. 4, pp. 341–374, 2010.",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Visual exploration of frequent patterns in multivariate time series",
      "author" : [ "M.C. Hao", "M. Marwah", "H. Janetzko", "U. Dayal", "D.A. Keim", "D. Patnaik", "N. Ramakrishnan", "R.K. Sharma" ],
      "venue" : "Information Visualization, vol. 11, no. 1, pp. 71–83, 2014.",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Detecting subdimensional motifs: an efficient algorithm for generalized multivariate pattern discovery",
      "author" : [ "D. Minnen", "C. Isbell", "I. Essa", "T. Starner" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2007, pp. 601–606.",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Tracking and optimizing dynamic systems with particle swarms",
      "author" : [ "R.C. Eberhart", "Y. Shi" ],
      "venue" : "Proc. of the IEEE Congress on Evolutionary Computation (CEC), 2001, pp. 94–100.",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Niching without niching parameters: particle swarm optimization using a ring topology",
      "author" : [ "X. Li" ],
      "venue" : "IEEE Trans. on Evolutionary Computation, vol. 14, no. 1, pp. 150–169, 2010.",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A hybrid particle swarm with a time-adaptive topology for constrained optimization",
      "author" : [ "M.R. Bonyadi", "X. Li", "Z. Michalewicz" ],
      "venue" : "Swarm and Evolutionary Computation, vol. 18, pp. 22–37, 2014.",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Locating potentially disjoint feasible regions of a search space with a particle swarm optimizer",
      "author" : [ "M.R. Bonyadi", "Z. Michalewicz" ],
      "venue" : "Evolutionary Constrained Optimization. In press. Springer.",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "The particle swarm - explosion, stability, and convergence in a multidimensional complex space",
      "author" : [ "M. Clerc", "J. Kennedy" ],
      "venue" : "IEEE Trans. on Evolutionary Computation, vol. 6, no. 1, pp. 58–73, 2002.",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "The particle swarm: social adaptation of knowledge",
      "author" : [ "J. Kennedy" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Evolutionary Computation (CEC), 1997, pp. 303–308.",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Particle swarm optimization",
      "author" : [ "J. Kennedy", "R.C. Eberhart" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Neural Networks (ICNN), 1995, pp. 1942– 1948.",
      "citeRegEx" : "45",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Comparing inertia weights and constriction factors in particle swarm optimization",
      "author" : [ "R.C. Eberhart", "Y. Shi" ],
      "venue" : "Proc. of the IEEE Congress on Evolutionary Computation (CEC), 2000, pp. 84–88.",
      "citeRegEx" : "46",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Particle swarms in size and shape optimization",
      "author" : [ "P.C. Fourie", "A.A. Groenwold" ],
      "venue" : "Proc. of the Int. Workshop on Multidisciplinary Design Optimization, 2000, pp. 97–106.",
      "citeRegEx" : "47",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Finding time series motifs in disk-resident data",
      "author" : [ "A. Mueen", "E. Keogh", "N. Bigdely-Shamlo" ],
      "venue" : "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2009, pp. 367–376.",
      "citeRegEx" : "48",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Daily closing value of the Dow Jones average, 1885 to present",
      "author" : [ "S.H. Williamson" ],
      "venue" : "2012. [Online]. Available: http://www.measuringworth.com/ datasets/DJA/index.php",
      "citeRegEx" : "49",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Adaptive event detection with timevarying Poisson processes",
      "author" : [ "A. Ihler", "J. Hutchins", "P. Smyth" ],
      "venue" : "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2006, pp. 207–216.",
      "citeRegEx" : "50",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "The UCI machine learning repository",
      "author" : [ "K. Bache", "M. Lichman" ],
      "venue" : "2013. [Online]. Available: http://archive.ics.uci.edu/ml",
      "citeRegEx" : "51",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Freesound technical demo",
      "author" : [ "F. Font", "G. Roma", "X. Serra" ],
      "venue" : "Proc. of the ACM Multimedia Int. Conf. (ACM-MM), 2013, pp. 411–412.",
      "citeRegEx" : "52",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Sonic Visualiser: an open source application for viewing, analysing, and annotating music audio files",
      "author" : [ "C. Cannam", "C. Landone", "M.B. Sandler" ],
      "venue" : "Proc. of the ACM Multimedia Int. Conf. (ACM-MM), 2010, pp. 1467–1468.",
      "citeRegEx" : "53",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals",
      "author" : [ "A.L. Goldberger", "L.A.N. Amaral", "L. Glass", "J.M. Hausdorff", "P.C. Ivanov", "R.G. Mark", "J.E. Mietus", "G.B. Moody", "C.-K. Peng", "H.E. Stanley" ],
      "venue" : "Circulation, vol. 101, no. 23, pp. e215–e220, 2000.",
      "citeRegEx" : "54",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Nonparametric statistical methods, 2nd ed",
      "author" : [ "M. Hollander", "D.A. Wolfe" ],
      "venue" : null,
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 1999
    }, {
      "title" : "A simple sequentially rejective multiple test procedure",
      "author" : [ "S. Holm" ],
      "venue" : "Scandinavian Journal of Statistics, vol. 6, no. 2, pp. 65–70, 1979.",
      "citeRegEx" : "56",
      "shortCiteRegEx" : null,
      "year" : 1979
    }, {
      "title" : "Population topologies and their influence in particle swarm performance",
      "author" : [ "R. Mendes" ],
      "venue" : "Ph.D. dissertation, Escola de Engenharia, Universidade do Minho, Braga, Portugal, 2004.",
      "citeRegEx" : "57",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Identification of common molecular subsequences",
      "author" : [ "T.F. Smith", "M.S. Waterman" ],
      "venue" : "Journal of Molecular Biology, vol. 147, pp. 195–197, 1981.",
      "citeRegEx" : "58",
      "shortCiteRegEx" : null,
      "year" : 1981
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "These segment pairs are commonly called motifs [1], and their existence is unlikely to be due to chance alone.",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 1,
      "context" : "the time series [2].",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : ", references in [2], [3]).",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 2,
      "context" : ", references in [2], [3]).",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : "[1] and Chiu et al.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 5,
      "context" : "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 6,
      "context" : "For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al.",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 7,
      "context" : "For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al.",
      "startOffset" : 120,
      "endOffset" : 123
    }, {
      "referenceID" : 8,
      "context" : "[9] use concepts from immune memory to deal with different lengths, and Floratou et al.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] combine suffix trees with segment models to find motifs of any length.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "In addition, approximate algorithms are restricted to a specific dissimilarity measure between segments (the one implicit in their discretization step) and do not allow easy access to preliminary results, which is commonly known as anytime algorithms [11].",
      "startOffset" : 251,
      "endOffset" : 255
    }, {
      "referenceID" : 11,
      "context" : "Finally, to the best of our knowledge, only [12]–[14] consider the identification of motif pairs containing segments of different lengths.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 13,
      "context" : "Finally, to the best of our knowledge, only [12]–[14] consider the identification of motif pairs containing segments of different lengths.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 12,
      "context" : "This can be considered a relevant feature, as it produces better results in a number of different domains [13].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 14,
      "context" : "Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 15,
      "context" : "Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16].",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 16,
      "context" : "[17], the exact identification of time series motifs was thought to be intractable for even time series of moderate length.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "and many approximate ones [17].",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 17,
      "context" : "’s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]–[20].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 19,
      "context" : "’s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]–[20].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 16,
      "context" : "erative search for the optimal length using [17] and, from the",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 17,
      "context" : "reported numbers, also outperforms further approaches such as [18]–[20].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 19,
      "context" : "reported numbers, also outperforms further approaches such as [18]–[20].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 2,
      "context" : "This algorithm, called MOEN [3], is essentially parameter-free, and is believed to be one of the most efficient motif discovery algorithms available nowadays.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 2,
      "context" : "However, its complexity is still quadratic in the length of the time series [3], and hence its applicability to large-scale time series streams remains problematic.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 2,
      "context" : "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 16,
      "context" : "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "zb+wb−1], for wa, wb ∈ [wmin, wmax], a ∈ [1, n−wa+1], and b ∈ [1, n − wb + 1] where, in order to avoid repeated and trivial matches [1], a + wa < b.",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "1Notice that, following [3], this definition can be trivially extended to different degrees of overlap.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 20,
      "context" : "Example of a time series motif pair found in the WILDLIFE time series of [21] using SWARMMOTIF and normalized dynamic time warping as the dissimilarity measure: a = 248, wa = 244, b = 720, and wb = 235.",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 21,
      "context" : "Ratanamahatana & Keogh [22] list a number of intuitive normalization mechanisms for dynamic time warping that can easily be applied to other measures.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 22,
      "context" : "For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 21,
      "context" : "For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 23,
      "context" : "Magnitudes like this challenge the memory and speed of any optimization algorithm, specially if we have no clue to guide the search [24].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 22,
      "context" : "between time series [23], is what gives continuity to our search space.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 20,
      "context" : "Visualizations of the search space obtained with the WILDLIFE time series [21] and dynamic time warping as the dissimilarity measure: (A) fixing a = 110 and b = 602 but i, j = 200, .",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 24,
      "context" : "However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]–[27].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 26,
      "context" : "However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]–[27].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 10,
      "context" : "corresponds to the basic paradigm of anytime algorithms [11].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 18,
      "context" : "Anytime algorithms have recently been highlighted as “very beneficial for motif discovery in massive [time series] datasets” [19].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 1,
      "context" : "This is particularly true for more exploratory tasks, where one is typically interested in data understanding and visual inspection (see [2]), and can also hold for other tasks, as top-k motifs can be very similar among themselves.",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 27,
      "context" : "M∗, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 28,
      "context" : "M∗, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 24,
      "context" : "In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]–[27].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 26,
      "context" : "In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]–[27].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 29,
      "context" : "Among them, we choose PSO [30]–[34].",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 32,
      "context" : "Among them, we choose PSO [30]–[34].",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 33,
      "context" : "optimization problems [33] which has been applied to multimodal problems [35].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 26,
      "context" : "It is a metaheuristic [27], meaning that it cannot guarantee whether the found solution corresponds to a global optimum.",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 34,
      "context" : "versions of it have been proven to solve this issue [36].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 34,
      "context" : "Other versions guarantee the convergence to the global optimum, but only with the number of iterations approaching infinity [36].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 29,
      "context" : "(see [30]–[35] and references therein).",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 33,
      "context" : "(see [30]–[35] and references therein).",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 23,
      "context" : "2) We are able to achieve a certain efficiency, as optimization algorithms do not usually explore the full solution space and perform few fitness evaluations [24].",
      "startOffset" : 158,
      "endOffset" : 162
    }, {
      "referenceID" : 22,
      "context" : "Additionally, we can straightforwardly incorporate notions of ‘interestingness’, hubness, or complexity (see references in [23]).",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 21,
      "context" : "The dissimilarity function D can expressly handle segments of different lengths or we can simply upsample to the largest length (see [22]).",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 35,
      "context" : "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 36,
      "context" : "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 15,
      "context" : "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 1,
      "context" : "definition of motif to incorporate both notions [2].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 31,
      "context" : "The agentbased nature of PSO naturally yields to parallel implementations [32].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 1,
      "context" : "6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29].",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 28,
      "context" : "6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 30,
      "context" : "Our PSO approach to time series motif discovery is based on the combination of two well-known extensions to the canonical PSO [31].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 37,
      "context" : "On one hand, we employ multiple reinitializations of the swarm on stagnation [39].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 38,
      "context" : "On the other hand, we exploit the particles’ “local memories” with the intention of forming stable niches across different local minima [40].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 33,
      "context" : "The former emulates a parallel multi-swarm approach [35] without the need of having to define the number of swarms and their communication.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 33,
      "context" : "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 39,
      "context" : "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 40,
      "context" : "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 41,
      "context" : "Algorithm 1 starts by computing the velocity update constants (line 1) following Clerc’s constriction method [43], i.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 38,
      "context" : "Note that by considering the particles’ neighborhood personal bests pg we follow the aforementioned local neighborhood niching strategy [40].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 37,
      "context" : "aforementioned multiple reinitialization strategy [39].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 2,
      "context" : "[3]).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 42,
      "context" : "• Sociability: We study whether a “cognitive-only” model, a “social-only” one, or different weightings of the two yield to some improvements [44].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 0,
      "context" : "To do so, we just need to introduce a parameter α ∈ [0, 1] controlling the degree of ‘sociability’ of the particles, and implement lines 1–2 of Algorithm 3 instead of Eq.",
      "startOffset" : 52,
      "endOffset" : 58
    }, {
      "referenceID" : 37,
      "context" : "• Stochastic: We investigate the use of a random inertia weight [39].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 43,
      "context" : "• Velocity clamping: In addition to constriction, we study limiting the maximum velocity of the particles [45].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 44,
      "context" : "constriction factor and velocity clamping results in improved performance on certain problems [46].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 43,
      "context" : "• Craziness: We introduce so-called “craziness” or “perturbation” in the particles’ velocities, as initially suggested by Kennedy & Eberhart [45].",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 45,
      "context" : "In such variant, inspired by the sudden direction changes observed in flocking birds, the particles’ velocity is altered with a certain probability ρ, with the aim of favoring exploration by increasing directional diversity and discouraging premature convergence [47].",
      "startOffset" : 263,
      "endOffset" : 267
    }, {
      "referenceID" : 45,
      "context" : "We coincide with [47] in that, in some sense, this can be seen as a mutation operation.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "As a baseline, we use the top25 motifs found by MOEN [3], which we will denote byM∗.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 2,
      "context" : "Existing empirical evidence [3], [17] suggests that MOEN is",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 16,
      "context" : "Existing empirical evidence [3], [17] suggests that MOEN is",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 16,
      "context" : "Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task:",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 46,
      "context" : "Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task:",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 47,
      "context" : "1) DOWJONES: The daily closing values of the Dow Jones average in the USA from May 2, 1885 to April 22, 2014 [49].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 48,
      "context" : "2) CARCOUNT: The number of cars measured for the Glendale on ramp for the 101 North freeway in Los Angeles, CA, USA [50].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 49,
      "context" : "The measurement was carried out by the Freeway Performance Measurement System7 and the data was retrieved from the UCI Machine Learning Repository [51].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 16,
      "context" : "3) INSECT: The electrical penetration graph of a beet leafhopper (circulifer tenellus) [17].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 16,
      "context" : "single channel in a sleeping patient [17].",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 50,
      "context" : "5) FIELDRECORDING: The spectral centroid (in Hz) of a field recording retrieved from Freesound10 [52].",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 51,
      "context" : "Visualizer [53].",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 49,
      "context" : "The data was retrieved from the UCI Machine Learning Repository [51].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 52,
      "context" : "8) EOG: An electrooculogram tracking the eye movements of a sleeping patient [54].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 46,
      "context" : "We took the downsampled time series [48] from Mueen’s web page13.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 53,
      "context" : "First, we consider all settings at the same time and perform the Friedman’s test [55], which is a non-parametric statistical test used to detect differences in treatments across multiple test attempts.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 53,
      "context" : "In it, we perform all possible pairwise comparisons between settings using the Wilcoxon signed-rank test [55], another non-parametric statistical hypothesis test used for comparing matched samples.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 54,
      "context" : "To counteract the problem of multiple comparisons and control the so-called family-wise error rate, we employ the HolmBonferroni correction [56].",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 55,
      "context" : "We then experimented with 6 different static topologies θ [57]: global best, local best (two neighbors), Von Neumann, random (three neighbors), wheel, and binary tree.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 41,
      "context" : "It is well-known that higher φ values favor exploitation rather than exploration [43].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 32,
      "context" : "4, which are not the most common practice [34].",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 27,
      "context" : "regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 22,
      "context" : "regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 56,
      "context" : "With regard to the latter, we envision powerful approaches to variable-length local similarity calculations, in the vein of existing dynamic programming approaches [58], [59].",
      "startOffset" : 164,
      "endOffset" : 168
    } ],
    "year" : 2015,
    "abstractText" : "Efficiently finding similar segments or motifs in time series data is a fundamental task that, due to the ubiquity of these data, is present in a wide range of domains and situations. Because of this, countless solutions have been devised but, to date, none of them seems to be fully satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution coming from it: an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. By considering data from a variety of domains, we show that this solution is extremely competitive when compared to the state-of-the-art, obtaining comparable motifs in considerably less time using minimal memory. In addition, we show that it is robust to different implementation choices and see that it offers an unprecedented degree of flexibility with regard to the task. All these qualities make the presented solution stand out as one of the most prominent candidates for motif discovery in long time series streams. Besides, we believe the proposed standpoint can be exploited in further time series analysis and mining tasks, widening the scope of research and potentially yielding novel effective solutions.",
    "creator" : "LaTeX with hyperref package"
  }
}