{
  "name" : "1106.0671.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Romuald Debruyne" ],
    "emails" : [ "Romuald.Debruyne@emn.fr", "bessiere@lirmm.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Enforcing local consistencies is one of the main features of constraint reasoning. Which level of local consistency should be used when searching for solutions in a constraint network is a basic question. Arc consistency and partial forms of arc consistency have been widely studied, and have been known for sometime through the forward checking or the MAC search algorithms. Until recently, stronger forms of local consistency remained limited to those that change the structure of the constraint graph, and thus, could not be used in practice, especially on large networks. This paper focuses on the local consistencies that are stronger than arc consistency, without changing the structure of the network, i.e., only removing inconsistent values from the domains. In the last ve years, several such local consistencies have been proposed by us or by others. We make an overview of all of them, and highlight some relations between them. We compare them both theoretically and experimentally, considering their pruning e ciency and the time required to enforce them."
    }, {
      "heading" : "1. Introduction",
      "text" : "There are more and more applications in arti cial intelligence that use constraint networks (CNs) to solve combinatorial problems, ranging from design to diagnosis, resource allocation to car sequencing, natural language understanding to machine vision. Finding a solution in a constraint network involves looking for a set of value assignments, one for each variable, so that all the constraints are simultaneously satis ed (Meseguer, 1989; Tsang, 1993). This task is NP-hard and many exponential time algorithms have been proposed to solve this problem. These algorithms, which make a systematic exploration of the search space, all have backtracking as a basis. As long as the unassigned variables have values consistent with the partial instantiation, they extend it by assigning values to variables. Otherwise, a dead-end is reached and some previous assignments have to be changed before going on with the partial instantiation extension. The explicit constraints of the network together induce some implicit constraints. Since basic search algorithms do not record these implicit constraints, they waste time by repeatedly detecting the local inconsistencies caused by them. Filtering techniques are essential to reduce the size of the search space and so to improve the e ciency of search algorithms. They can be used during a preprocessing step to remove once and for all some local inconsistencies that otherwise would have been repeatedly found during search (Dechter & Meiri, 1994). They can also be maintained during search.\nc 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nDebruyne & Bessi ere\nSearch algorithms di er in the kind of local consistency they achieve after each choice of a value for a variable. Most of them enforce partial arc consistency, going from forward checking (FC,Golomb & Baumert, 1965; Haralick & Elliott, 1980), which only removes the values directly arc inconsistent with the last assignment, to really full look-ahead (RFL, Gaschnig, 1974), which achieves full arc consistency. Arc consistency (AC) and partial forms of arc consistency are widely used for two reasons. First, they have low space and time complexities, while path consistency and higher levels of k-consistency, which were for a long time the only other options, are prohibitive and can change the structure of the network. Moreover, until 1995, more pruningful local consistencies seemed uninteresting since experimental evaluations of search algorithms showed that the limited local consistency used by forward checking was the best choice (Nadel, 1988; Kumar, 1992; Bacchus & van Run, 1995). This conclusion is not surprising since the comparisons were made on very small and easy constraint networks. On such problems, the additional cost of pruning more values could not be outweighed by the search savings.\nHowever, the harder a constraint network is, the more useful ltering techniques are. More recent works (Bessi ere & R egin, 1996; Sabin & Freuder, 1994; Grant & Smith, 1996) testing search algorithms at the threshold (Cheeseman, Kanefsky, & Taylor, 1991), where most of the hard problems are expected to be, show that using more pruningful local consistencies can be worthwhile. Their conclusion is that maintaining arc consistency during search (MAC), namely achieving AC both after the choice of a value for a variable and after the refutation of such a choice, outperforms forward checking on hard problems. The good behavior of MAC is even more signi cant on large problems, especially when domains are large. It is conceivable that on very di cult instances, maintaining an even more pruningful local consistency may pay o . Obviously, such an algorithm would waste seconds on easy CNs but it would save many minutes (hours ?) on very hard problems, reducing the set of pathological CNs on which search is really prohibitive.\nIn this paper we study the local consistencies as preprocessing ltering techniques. This is a preliminary work before trying to determine which local consistency is the most advantageous to be maintained during search. In the last ve years, many new local consistencies have been proposed. In the remaining of this paper, we focus our attention on those that leave unchanged the structure of the network since they are the only able to be used on large CNs. In addition to an overview of these local consistencies that only remove inconsistent values, we both compare, theoretically and experimentally, their pruning e ciency and the time needed to enforce them."
    }, {
      "heading" : "2. De nitions and Notations",
      "text" : "A network of binary constraints P = (X ; D; C) is de ned by a set X = fi; j; : : :g of n variables , each taking value in its respective nite domain D\ni\n; D\nj\n; : : : elements of D, and a\nset C of e binary constraints. d is the size of the largest domain. A binary constraint C\nij\nis a subset of the Cartesian product D\ni\nD\nj\nthat denotes the compatible pairs of values\nfor i and j. We denote C\nij\n(a; b) = true to specify that ((i; a); (j; b)) 2 C\nij\n. We then say\nthat (j; b) is a support for (i; a) on C\nij\n. Checking whether a pair of values is allowed by\na constraint is called a constraint check . With each CN we associate a constraint graph in which nodes represent variables and arcs connect pairs of variables that are constrained\nDomain Filtering Consistencies\nexplicitly. c is the number of 3-cliques in the constraint graph and g is the maximum degree of a node in the constraint graph. The neighborhood of i is the set of variables adjacent to i in the constraint graph. A domain D 0 = fD 0\ni\n; D\n0 j ; : : :g is a sub-domain of D = fD i ; D j ; : : :g\nif 8i; D\n0 i\nD\ni\n. An instantiation I of a set of variables S is a set of value assignments\nfI\nj\ng\nj2S\n, one for each variable belonging to S, s.t. 8j 2 S; I\nj\n2 D\nj\n. An instantiation I of\nS satis es a constraint C\nij\nif fi; jg 6 S or C\nij\n(I\ni\n; I\nj\n) is true. An instantiation is consistent\nif it satis es all the constraints. A pair of values ((i; a); (j; b)) is path consistent if for all k 2 X s.t. j 6= k 6= i 6= j, this pair of values can be extended to a consistent instantiation of fi; j; kg. (j; b) is a path consistent support for (i; a) if (a; b) 2 C\nij\nand ((i; a); (j; b)) is\npath consistent. A solution of P = (X ; D; C) is a consistent instantiation of X . A value (i; a) is consistent if there is a solution I such that I\ni\n= a, and a CN is consistent if it has\nat least one solution. We denote by P j\nD\ni\n=fag\nthe CN obtained by restricting D\ni\nto fag in\nP . If LC is a local consistency, a CN P is not LC-consistent i LC does not hold on P . A CN P is LC-inconsistent i we cannot obtain a LC-consistent constraint network by deletion of some local inconsistencies in P . If a local consistency LC is used to detect the inconsistency of instantiations no longer than 1, we can say that a CN P = (X ; D; C) is LC-inconsistent i there is no sub-domain D 0 of D such that LC holds on (X ; D 0 ; C)."
    }, {
      "heading" : "3. The Local Consistencies Studied",
      "text" : "Filtering techniques can be used to detect the inconsistency of a CN, and under some assumptions, they can ensure a backtrack-free search (Freuder, 1982, 1985). However, their usual purpose is not to nd a solution in a constraint network. They remove some local inconsistencies and so delete some regions of the search space that do not contain any solution. The resulting CN is equivalent to the initial one since the set of solutions is unchanged, but if substantial reductions are made the search becomes easier. In this section we review the basis of arc consistency, k-consistency, restricted path consistency, and inverse consistencies. Furthermore, we extend the idea of restricted path consistency to k-restricted path consistency and Max-restricted path consistency. We propose a new class of local consistencies called singleton consistencies. We also show a property of path inverse consistency that can be used to have an optimal worst case time complexity in a path inverse consistency algorithm (Debruyne, 2000).\nArc consistency The most widely used local consistency is arc consistency. It is based on the notion of support. A value is viable as long as it has at least one compatible value in the domain of each neighboring variable. An AC algorithm has to remove the values that have no support on a constraint. As in most of the ltering techniques, the value deletions have to be propagated through the network since they can lead to the arc inconsistency of some values that were previously viable.\nk-consistency A consistent instantiation of length k-1 is k-consistent (i.e., (k-1, 1)- consistent in the formalism of Freuder, 1985) if it can be extended to any additional k th variable. The time and space complexities of enforcing k-consistency are polynomial with the exponent dependent on k. If k 3, the constraints have to be represented in extension to store the (k-1)-tuples deleted, and the structure of the network can be changed. This leads to huge space requirements and subsequently important cpu time costs. In practice,\nDebruyne & Bessi ere\nonly 2-consistency, which is arc consistency in binary CNs, can be used. Although path consistency (PC, namely 3-consistency) cannot be used on large CNs, our experiments will involve strong path consistency (namely enforcing both arc and path consistency) because PC has been widely studied.\nRestricted path consistency The aim of Berlandier when he proposed restricted path consistency (RPC, Berlandier, 1995) was to remove more inconsistent values than AC while avoiding the drawbacks of path consistency. Even the most e cient PC algorithms have to try to extend all the pairs of values (even those between two variables that are not neighbors) to any third variable. The basis of RPC is to avoid most of this prohibitive work. RPC performs only the most pruningful path consistency checks, namely those able to directly delete a value. In addition to AC, an RPC algorithm checks the path consistency of the pairs of values ((i; a); (j; b)) such that (j; b) is the only support for (i; a) in D\nj\n. If such\na pair is path inconsistent, its deletion would lead to the arc inconsistency of (i; a). Thus (i; a) can be removed. These few additional path consistency checks allow detecting more inconsistent values than AC without having to delete any pair of values, and so leaving unchanged the structure of the network.\nk-restricted path consistency We can extend the idea of RPC to a more pruningful local consistency. If RPC holds, the values that have only one support on a constraint are such that this support is path consistent. Checking the path consistency of more supports can remove even more values without falling into the traps of PC. k-restricted path consistency (k-RPC, Debruyne & Bessi ere, 1997a) looks for a path consistent support on a constraint for the values that have at most k supports on this constraint. RPC is 1-RPC and AC corresponds to 0-RPC. If k-RPC holds, to achieve (k+1)-RPC we only have to check the values that have exactly (k+1) supports on a constraint and to propagate their possible deletion. So, it is possible to achieve AC, RPC, 2-RPC and so on, each time reusing previous ltering e ort. This adaptive enforcement can be stopped as soon as each value has at least one path consistent support on each constraint, the constraint network being d-RPC where d is the size of the largest domain. Indeed, if after achieving k-RPC all the values have at most k supports on each constraint, k 0 -RPC holds for all k 0 > k.\nMax-restricted path consistency A constraint network is Max-restricted path consistent (Max-RPC, Debruyne & Bessi ere, 1997a) if all the values have at least one path consistent support on each constraint, whatever is the number of supports. From the pruning e ciency point of view, Max-RPC is an upper bound for k-RPC. Achieving Max-RPC involves deleting all the k-restricted path inconsistent values for all k. However, achieving Max-RPC can be less expensive than enforcing a high level of k-RPC. As opposed to MaxRPC, to achieve k-RPC we have to look for the values that have at most k supports on a constraint to know the values for which a path consistent support has to be found. This can be expensive if k is great, the algorithm having to look for k+1 supports for each value on each constraint. Unconditionally looking for a path consistent support avoids this costly extra work.\nk inverse consistency The aim of Freuder and Elfe when they proposed inverse consistency(Freuder & Elfe, 1996) was to achieve high order local consistencies with a good space complexity. A k-consistency algorithm removes the instantiation of length k-1 that cannot\nDomain Filtering Consistencies\nbe extended to any k\nth\nvariable. It requires O(n\nk 1\nd\nk 1\n) space to keep track of the deleted\ninstantiations. Space requirements are no longer a problem with k inverse consistency ((1, k-1)-consistency), which removes the values that cannot be extended to a consistent instantiation including any k-1 additional variables. Its linear space complexity would allow using it on large CNs. However, its worst case time complexity is polynomial with the exponent dependent on k, which restricts its use to small values of k.\nPath inverse consistency The rst level of k inverse consistency removing more values than AC is path inverse consistency (PIC, k = 3). By de nition, (i; a) is path inverse consistent if it can be extended to all the 3-tuples of variables containing i. However, as said in (Freuder & Elfe, 1996), not all the 3-tuples need to be checked to enforce PIC. Only one of the tuples (i; j; k) and (i; k; j) has to be checked. Moreover, if i is linked to neither j nor k, (i; a) can be deleted because of (i; j; k) only if all the values of j or k are path inverse inconsistent. In such a case, checking (i; j; k) is useless since PIC detects the inconsistency of the network when processing j or k.\nNeighborhood inverse consistency Since k inverse consistency is polynomial with the exponent dependent on k, checking the k inverse consistency of all the values is prohibitive if k is great. However, if the variables are not uniformly constrained, it would be worthwhile to adapt the level of k inverse consistency to the number of constraints involving them, focusing\nltering e ort on the most constrained variables (as it is done for adaptive consistency Dechter & Pearl, 1988). This is the basis of neighborhood inverse consistency (NIC, Freuder & Elfe, 1996), which removes the values that cannot be extended to a consistent instantiation including all the neighboring variables. We have to point out that the behavior of NIC is dependent on the structure of the constraint graph. If two variables i and j are not neighbors, we can add a universal constraint allowing all the pairs of values (a; b) 2 D\ni\nD\nj\nbetween i and j. The resulting CN is equivalent to the initial one since it has the same set of solutions. However, as opposed to the other lterings studied in this paper, NIC is a ected by this change since it can remove more values. Obviously, this process increases time complexity. On complete constraint networks, NIC tries to extend all the values to a whole solution, namely deleting all the globally inconsistent values (named variable completability in Freuder, 1991). This is a far more di cult task than looking for one solution. To be cost e ective, NIC has to be used only on sparse CNs, where the degree of the variables is small.\nSingleton consistencies If a value (i; a) is consistent, the constraint network obtained by restricting D\ni\nto the singleton fag is consistent. Singleton consistencies are a class of\nltering techniques based on this remark. To detect the inconsistency of a value (i; a), a singleton consistency ltering technique checks whether a given local consistency can detect the possible inconsistency of P j\nD\ni\n=fag\n. For example, singleton arc consistency (SAC, De-\nbruyne & Bessi ere, 1997b) deletes the values (i; a) such that P j\nD\ni\n=fag\nhas no arc consistent\nsub-domain.\n1\nSAC has been inspired by the strong path consistency algorithm proposed\nby McGregor(McGregor, 1979). A SAC algorithm is obtained by omitting the deletions\n1. Any AC algorithm can be used to know whether enforcing AC on P j\nD\ni\n=fag\nleads to a domain wipe out,\nbut a lazy approach (such as LAC7 Schiex, R egin, Gaspin, & Verfaillie, 1996) is su cient.\nDebruyne & Bessi ere\nDomain Filtering Consistencies\noptimal worst case time complexity.\nof pairs of values in that algorithm. Many other singleton consistencies can be considered\nsince any local consistency can be used to detect the possible inconsistency of the CNs P j\nD\ni\n=fag\nwith (i; a) 2 D. If a local consistency can be enforced in a polynomial time, the\ncorresponding singleton consistency also has a polynomial worst case time complexity.\nThe formal de nitions of the local consistencies studied in this paper are presented in Figure 1. Table 1 recalls the time and space complexities of the most e cient algorithms enforcing them. The worst case time complexity of SAC1, SRPC1, and NIC1 have not been proved to be optimal."
    }, {
      "heading" : "4. Relations between PIC, RPC and Max-RPC",
      "text" : "To highlight the relations between PIC, RPC and Max-RPC, let us show a property of path inverse consistency. As shown in (Debruyne, 2000), if we assume that the constraint network is arc consistent, enforcing PIC requires checking even less 3-tuples than those mentioned in (Freuder & Elfe, 1996). If (i; a) is arc consistent, it can be extended to any 3-tuple (i; j; k) such that there is no constraint between j and k. Indeed, (i; a) has a support (j; b) on C\nij\nand a support (k; c) on C\nik\n, and since j is not linked to k, ((i; a); (j; b); (k; c)) is consistent.\nFurthermore, (i; a) can be extended to (i; j; k) if there is no constraint between i and k (resp. between i and j). Indeed, (i; a) has a support b in D\nj\n(resp. c in D\nk\n) and this value\nbeing arc consistent too, it has a support c in D\nk\n(resp. b in D\nj\n). So, ((i; a); (j; b); (k; c))\nis consistent. Consequently, if the constraint network is arc consistent, the only 3-tuples that have to be checked to achieve PIC correspond to the 3-cliques of the constraint graph.\n2. However a O(n\n2\nd\n2\n) data structure is required for the constraint representation.\n3. See Section 2 for a de nition of n, d, e, c, and g.\nDebruyne & Bessi ere\nFurthermore, the de nition of PIC shows that any constraint network involving less than three variables is path inverse consistent, even though it is not arc consistent.\nProperty 1 A CN is path inverse consistent i\nit involves less than three variables, or it is arc consistent and for each value (i; a) in D, for any 3-clique fi; j; kg, (i; a) can be extended to a consistent instantiation of fi; j; kg.\nThis property allows us to see the relations between PIC, RPC and Max-RPC. If a\nvalue (i; a) has no support on a constraint C\nij\n, the three local consistencies delete this\narc inconsistent value (see Figure 2A). If (i; a) has only one support b in D\nj\n, PIC, RPC,\nand Max-RPC delete (i; a) because of C\nij\nif ((i; a); (j; b)) is path inconsistent (see Figure\n2B). The di erence between these three local consistencies appears if (i; a) has at least two supports on C\nij\n. In such a case, (i; a) is restricted path consistent w.r.t. C\nij\nbut PIC can\ndelete it if there is a 3-clique fi; j; kg such that all the supports of (i; a) in D\nj\nare path\ninconsistent because of k (see Figure 2C). So, PIC is more pruningful than RPC. But it\nDomain Filtering Consistencies\noften deletes only few additional values because the supports of a value are seldom all path inconsistent because of the same third variable. Max-RPC is far more pruningful since it deletes (i; a) because of C\nij\nif all its supports in D\nj\nare path inconsistent, even if they are\nnot path inconsistent because of the same third variable (see Figure 2D)."
    }, {
      "heading" : "5. Pruning E ciency",
      "text" : ""
    }, {
      "heading" : "5.1 Qualitative Study",
      "text" : "To compare the pruning e ciency of the local consistencies presented above, we use the transitive relation \\stronger\" introduced in (Debruyne & Bessi ere, 1997b). A local consistency LC is stronger than another local consistency LC 0 if in any CN in which LC holds, LC 0 holds too. Consequently, if LC is stronger than LC 0 , any algorithm achieving LC deletes at least all the values removed by an algorithm achieving LC 0 . For instance, since by de nition of restricted path consistency RPC is stronger than AC, an RPC algorithm removes at least all the arc inconsistent values. A local consistency LC is strictly stronger than another local consistency LC 0 if LC is stronger than LC 0 and there is at least one CN in which LC 0 holds and LC does not.\nTheorem 1 Restricted path consistency is strictly stronger than AC.\nProof By de nition of restricted path consistency, RPC is stronger than arc consistency. Figure 3a shows that there exists a constraint network on which AC holds and RPC does not. Therefore, RPC is strictly stronger than AC. 2\nTheorem 2 If k > k\n0\n0, k-RPC is strictly stronger than k\n0\n-RPC.\nProof The proof that k-RPC is stronger than k\n0\n-RPC if k > k\n0\n0 is trivial. Figure 3g\nshows that there exists a constraint network on which k\n0\n-RPC holds and k-RPC (k > k\n0\n0)\ndoes not. Therefore, k-RPC is strictly stronger than k\n0\n-RPC if k > k\n0\n0. 2\nTheorem 3 Max-RPC is strictly stronger than k-RPC, 8k 0.\nProof The proof that Max-RPC is stronger than k-RPC 8k 0 is trivial. Figure 3g shows that for any k 0 there exists a constraint network on which k-RPC holds and Max-RPC does not. Therefore, Max-RPC is strictly stronger than k-RPC 8k 0. 2\nTheorem 4 If jX j 3, path inverse consistency is strictly stronger than restricted path consistency.\nProof From property 1, PIC is stronger than AC if jX j 3. Now, consider a value (i; a) having only one support (j; b) on C\nij\n. If PIC holds, for any third variable k, (i; a) can be\nextended to a consistent instantiation I including fi; j; kg and since b is the only support of (i; a) in D\nj\n, I\nj\n= b. So ((i; a); (j; b)) is path consistent and (i; a) is restricted path consistent\nw.r.t. C\nij\n. Furthermore, Figure 3b shows that there exists a constraint network on which\nDebruyne & Bessi ere\nRPC holds and PIC does not. Therefore, path inverse consistency is strictly stronger than restricted path consistency if jX j 3. 2\nTheorem 5 If jX j 3, max-restricted path consistency is strictly stronger than path inverse consistency.\nProof Suppose there is a max-restricted path consistent CN P with a value (i; a) which is not path inverse consistent. Since the CN is max-restricted path consistent, it is also arc consistent by de nition of max-restricted path consistency. Thus, because of property 1 we know there exist two variables j and k such that fi; j; kg is a clique in the constraint graph and (i; a) cannot be extended to a consistent instantiation on fi; j; kg. As a result, none of the supports of (i; a) on C\nij\nis path consistent, which contradicts the assumption\nthat the CN P is max-restricted path consistent. Furthermore, Figure 3i shows that there exists a constraint network on which path inverse consistency hold and max-restricted path consistency does not. Therefore, if jX j 3, max-RPC is strictly stronger 2\nTheorem 6 Singleton arc consistency is strictly stronger than Max-RPC.\nProof Suppose that there exists a CN P with a singleton arc consistent value (i; a) that is not max-restricted path consistent. Let j 2 X be a variable such that (i; a) has no path consistent support in D\nj\n. For each support b of (i; a) in D\nj\n, there exists a variable k\nsuch that 6 9c 2 D\nk\nsuch that C\nik\n(a; c) ^ C\njk\n(b; c). Therefore, all the values of D\nj\nare arc\ninconsistent w.r.t. P j\nD\ni\n=fag\nand (i; a) is not singleton arc consistent. So, SAC is stronger\nthan Max-RPC. Figure 3e shows that there exists a constraint network on which Max-RPC holds and SAC does not. Therefore, SAC is strictly stronger than Max-RPC. 2\nTheorem 7 Neighborhood inverse consistency is strictly stronger than max-restricted path consistency.\nProof Let (i; a) be any value of a neighborhood inverse consistent CN P . There exists a consistent instantiation I including i and its neighborhood s.t. I\ni\n= a. For any C\nij\n2 C, I\nj\nis a path consistent support of (i; a). Indeed, let k be any third variable. If k is linked to i, ((i; a); (j; I\nj\n); (k; I\nk\n)) is a consistent instantiation since P is neighborhood inverse consistent.\nOtherwise, there are two cases: First, if k is not linked to j, ((i; a); (j; I\nj\n); (k; c)) is consistent\n8c 2 D\nk\n; Second, if 9C\njk\n2 C, there exists a consistent instantiation I\n0\nof j and its neigh-\nborhood s.t. I\n0 j = I j and ((i; a); (j; I 0 j ); (k; I 0\nk\n)) is consistent. So, (i; a) is max-restricted path\nconsistent. Furthermore, Figure 3d shows that there exists a constraint network on which Max-RPC holds and NIC does not. Therefore, NIC is strictly stronger than Max-RPC. 2\nTheorem 8 Strong path consistency is strictly stronger than singleton arc consistency.\nProof Consider a problem that is strong path consistent. Any pair of values can be extended to any third variable. Furthermore, since the problem is strong path consistent, it is also arc consistent and a sub-problem obtained by restricting a domain D\ni\nto a singleton\nDomain Filtering Consistencies\nf(i; a)g can be made arc consistent. The initial problem is therefore singleton arc consistent. Figure 3c shows that there exists a constraint network on which SAC holds and strong PC does not. Therefore, strong PC is strictly stronger than SAC. 2\nTheorem 9 Singleton restricted path consistency is strictly stronger than singleton arc consistency.\nProof Singleton restricted path consistency is stronger than singleton arc consistency since RPC is stronger than AC. Figure 3d shows that there exists a constraint network on which SAC holds and SRPC does not. Therefore, SRPC is strictly stronger than SAC. 2\nThe stronger relation does not induce a total ordering. Some local consistencies are\nincomparable.\nTheorem 10\n1. If jX j 3, path inverse consistency and k-restricted path consistency are incomparable.\n2. Neighborhood inverse consistency and singleton arc consistency are incomparable.\n3. Neighborhood inverse consistency and strong path consistency are incomparable.\n4. Neighborhood inverse consistency and singleton restricted path consistency are incom-\nparable.\nProof\n1. cf. Figure 3h and Figure 3j.\n2. cf. Figure 3d and Figure 3e.\n3. cf. Figure 3d and Figure 3e.\n4. cf. Figure 3e and Figure 3f.\nFigure 4 summarizes the relations between the local consistencies. There is an arrow\nfrom LC to LC\n0\ni LC is strictly stronger than LC\n0\n. A crossed line between two local\nconsistencies means that they are not comparable w.r.t. the \\stronger\" relation. When LC is not stronger than LC 0 (LC 0 is strictly stronger than LC, or LC and LC 0 are not comparable), a CN in which LC holds and LC 0 does not can be found in Figure 3. Obviously, the stronger relation is transitive. In Figure 4 we omit the transitivity arcs.\nDebruyne & Bessi ere\nDomain Filtering Consistencies"
    }, {
      "heading" : "5.2 Experimental Evaluation",
      "text" : "Figure 4 does not give any quantitative information. A local consistency LC can remove more values than another local consistency LC 0 on most of the CNs even though it is incomparable with LC because of some particular CNs. When they are comparable, it does not show if a local consistency is far more pruningful than another or if it performs only few additional value deletions. To have some quantitative information about the pruning e ciency of these local consistencies, we performed an experimental evaluation. The aim of this evaluation is to show how pruningful a local consistency is on random CNs, with a xed number of variables and values, when the number of constraints and the constraint tightness\nDebruyne & Bessi ere\nare changing. We used the random uniform CN generator of (Frost, Bessi ere, Dechter, & R egin, 1996) which produces instances according to the Model B (Prosser, 1996). It involves four parameters: n the number of variables, d the common size of the initial domains, p1 the proportion of constraints in the network (the density p1=1 corresponds to the complete graph) and p2 the proportion of forbidden pairs of values in a constraint (the tightness). The generated problems have 40 variables and 15 values in each domain. For each local consistency and each density p1, two particular values of the tightness have been determined. On the one hand, T\n0\n(p1) is the tightness such that the local consistency does not delete any\nvalue on 50% of the CNs generated with p1 for density. For values of tightness lower than T\n0\n(p1), the local consistency seldom deletes many values. On the other hand, T\nall\n(p1) is the\ntightness such that the local consistency nds the inconsistency of 50% of the CNs generated with density p1. On constraint networks with tighter constraints, the local consistency often removes all the values. For all the mentioned local consistencies, the values T\n0\n(p1)\nDomain Filtering Consistencies\nand T\nall\n(p1) for any density p1 are given in Figure 5 and Figure 6 respectively. We also\nshow these bounds for the variable completability ltering which removes all the globally inconsistent values, and thus is the strongest ltering we can have when we limit ltering to the domains. To determine the T\n0\nand T\nall\nbounds, 300 CNs have been generated for each\n(density, tightness) pair. This explains why the generated problems are relatively small.\nAs already proved theoretically, PIC is stronger than RPC. Their pruning e ciencies are closed. RPC deletes most of the path inverse inconsistent values and is halfway between AC and Max-RPC in terms of pruning e ciency. k-RPC with k > 1 is incomparable with PIC with regard to the stronger relation. However, Figure 5 and Figure 6 show that 2-RPC is more pruningful than PIC. SAC and strong PC have almost the same pruning e ciency. Their T\n0\nlimits merge and their T\nall\nlimits show a slight di erence. This con rms\nthe similitude between SAC and strong PC pointed out in Section 3. Although SRPC and strong PC are not comparable w.r.t. the stronger relation, SRPC removes is more pruningful than strong PC. As predicted in (van Beek, 1994), these polynomial lterings have more\nDebruyne & Bessi ere\ndi culties to delete inconsistent values on dense problems with loose constraints. On sparse CNs, the polynomial local consistencies studied are close to variable completability, whereas on very dense CNs, Figure 5 and Figure 6 show a large range of tightnesses between them and variable completability. NIC behaves very di erently since on complete constraint networks it corresponds to variable completability. So, on dense CNs, NIC is far more pruningful than the other local consistencies. On CNs generated with a density lower than .28 NIC is less pruningful than SRPC, strong PC and SAC. The more important the propagation through the network is, the closer T\n0\nand T\nall\nare. If a ltering (such as AC) uses a very\nlocal property to delete inconsistent values, there is a large set of CNs on which it removes some but not all the values. More pruningful local consistencies consider a more important part of the network to know whether a value is consistent or not. So, they seldom delete few values. On most of the CNs, they do not delete any value, or detect inconsistency: the propagation of the rst value deletions often leads to a domain wipe out."
    }, {
      "heading" : "6. Time E ciency",
      "text" : ""
    }, {
      "heading" : "6.1 Radio Link Frequency Assignment Problems",
      "text" : "An experimental evaluation has been done on the radio link frequency assignment problems described in (Cabon, de Givry, Lobjois, Schiex, & Warners, 1999), namely the instances of the CELAR 4 named Scen01 to Scen11, and the GRAPH instances generated using the GRAPH generator at Delft University named Graph01 to Graph14. In these problems we have to assign frequencies to a set of radio links de ned between pairs of sites in order to avoid interferences 5 . These problems have from 200 to 916 variables and there are 40 values in average in each domain. The constraints are binary and have a cost of violation speci ed\n4. We thanks the Centre d'Electronique de l'Armement (France). 5. See http://www-bia.inra.fr/T/schiex/Doc/CELARE.html for a more detailed presentation of these\nproblems.\nDomain Filtering Consistencies\nby a level from 0 to 4. The level 0 corresponds to hard constraints, and levels from 1 to 4 have a decreasing cost of violation. For each problem ScenXX (resp. GraphXX), we call ScenXX.3, ScenXX.2, ScenXX.1 and ScenXX.0 (resp. GraphXX.3, GraphXX.2, GraphXX.1 and GraphXX.0) the problems of satisfaction obtained by considering the problem ScenXX (resp. GraphXX) with only the constraints of level 0 to 3, 0 to 2, 0 to 1, and 0 respectively.\nIn this experimental evaluation, we consider both the cpu time performances and the percentage of values deleted by the local consistencies studied. The algorithms used are AC7 (Bessi ere, Freuder, & R egin, 1995), RPC2 (Debruyne & Bessi ere, 1997a), PIC2 (Debruyne, 2000), Max-RPC1 (Debruyne & Bessi ere, 1997a), the singleton arc consistency algorithm of (Debruyne & Bessi ere, 1997b) (SAC1) based on AC6, a SRPC algorithm based on RPC2 (SRPC1), and the NIC algorithm proposed in (Freuder & Elfe, 1996) (NIC1) using FCCBJ (Prosser, 1993) (as inFreuder & Elfe, 1996) with dom+deg dynamic variable ordering heuristic (minimal domain rst, in which ties are broken by choosing the variable with the highest degree in the constraint graph Frost & Dechter, 1995; Bessi ere & R egin, 1996). All these algorithms have been modi ed to stop as soon as a domain wipe out occurs. We do not show results on strong PC in this section because on these large problems it requires often more than our 2 hours time out limit. These algorithms have been tested on each ScenXX, Scen XX.X, GraphXX, and GraphXX.X problem using a Sun UltraSparc IIi 440 Mhz. For sake of clarity, we only show the results on some representative problems."
    }, {
      "heading" : "6.1.1 Results on problems on which all the studied local consistencies hold",
      "text" : "(cf. Table 2)\nIf all the local consistencies studied hold on a constraint network, all the corresponding\nltering algorithms are useless. They waste time to check whether the local consistencies hold without deleting any inconsistent value. On these problems, the stronger the local consistency is, the more important is the time wasted.\nWe can see the consequence of the exponential worst case time complexity of NIC1. On most of these problems, NIC1 requires a reasonable cpu time. But as we can see on the problem Scen11, a combinatorial explosion can lead to really prohibitive cpu time for NIC1."
    }, {
      "heading" : "6.1.2 Results on arc inconsistent problems (cf. Table 3)",
      "text" : "When arc consistency is su cient to detect the inconsistency of the problem, stronger local consistencies are not always more costly. On Figure 3 we can see that Max-RPC1 has often the best cpu time performances and on Graph06 for example, AC7 is one of the\nDebruyne & Bessi ere\nmost expensive local consistencies. When enforcing AC requires propagation to nd the arc inconsistency of the problem, a stronger local consistency can wipe out a domain more quickly than AC7.\nOn these constraint networks, all the algorithms used have very low cpu time require-\nments, except NIC1, which can be very expensive on some instances, such as Scen08."
    }, {
      "heading" : "6.1.3 Results on the other problems (cf. Table 4)",
      "text" : "On many of the RLFAP problems the local consistencies do not delete the same sets of inconsistent values. We can see an important di erence between the pruning e ciencies especially on the problems ScenXX.1 and GraphXX.1.\nObviously, on most of these problems, the more pruningful the local consistency is, the more important is the time required. We can see this on the problems Scen06.1 and Scen09.1 for example. However, AC7, RPC2, PIC2, and Max-RPC1 have cpu time performances in the same order of magnitude while SAC1, SRPC1, and NIC1 are often far more expensive.\nDomain Filtering Consistencies\nThis is especially obvious on Graph04 and Graph10. However, it is di cult to say which is the most interesting local consistency on these problems since even if SAC1, and SRPC1 are costly, we can see on Scen06.1 and Graph04 that they can be far more pruningful.\nThese problems highlight that NIC1 is not very stable. It sometimes shows good performances, but an exponential explosion can lead to a prohibitive cost on some instances. When NIC1 requires a reasonable time, its pruning e ciency is closer to the one of MaxRPC1 than to the one of SAC1. These results con rm that if the neighborhoods of the variables are not small, NIC1 can be really prohibitive.\nOn Graph06.1, PIC2 (and obviously the algorithms enforcing a stronger local consistency) nds the inconsistency of the problem whereas AC7, and RPC2 remove only a part of the inconsistent values. We can see a similar behavior on Graph12.1 where Max-RPC1 wipes out a domain whereas AC7, RPC2 and PIC2 do not nd the inconsistency of the problem. On these instances, Max-RPC1 is the best choice."
    }, {
      "heading" : "6.2 Randomly Generated Problems",
      "text" : "The random uniform CN generator of section 5.2 is used to compare the cpu time required to enforce the local consistencies. We have to point out that NIC has not been designed to be used on uniform CNs but to adapt ltering e ort to the degree of the variables in the constraint graph. So, NIC would have better performances on non-uniform CNs than those presented in this section. The generated problems have 200 variables and 30 values in each initial domain. Figure 8 shows the results on CNs with density of .02. These CNs are relatively sparse since the variables have four neighbors on average. Figure 9 presents performances at density .15 (the variables have 30 neighbors on average). Because of the set of parameters, there are no awed variables (MacIntyre, Prosser, Smith, & Walsh, 1998) in the generated problems. 6 In addition to the algorithms of the previous section, we use a strong path consistency algorithm based on PC8 (Chmeiss & J egou, 1996) and AC6. This algorithm stops as soon as a domain wipe out occurs or as soon as a constraint no longer allows any pair of values. In addition to the percentage of deleted values and cpu time performances, Figure 8 and Figure 9 show the cpu time to number of deleted values ratio for each tightness where the local consistency removes at least one value on average. For each tightness, 50 instances were generated. Figure 8 and Figure 9 show mean values obtained on a Pentium II-266 Mhz with 32 Mb of memory under Linux.\nAs observed in (Gent, MacIntyre, Prosser, Shaw, & Walsh, 1997) for arc consistency, the ltering algorithms tested have a complexity peak. For low values of the tightness, they easily prove that the values are locally consistent, and when constraints are very tight, they quickly wipe out a domain. Each local consistency has a phase transition where most of the hardest problems for an algorithm achieving this local consistency tend to occur."
    }, {
      "heading" : "6.3 Experiments on Sparse CNs",
      "text" : "Even on sparse CNs (see Figure 8), the cpu time results are so di erent between the algorithms (7h 48min for strong PC at its peak when AC7 requires at most .22 seconds on average) that a logarithmic scale has to be used. Strong PC is really prohibitive, even for\n6. In Section 5.2,the tightness reaching 1, there was obviously awed variables for some sets of parameters.\nDebruyne & Bessi ere\nlow values of tightness. SRPC and SAC have bad cpu time to number of deleted values ratios, except SAC on CNs having very tight constraints because the SAC algorithm used is based on AC6 which can be more e cient than AC7 on such problems. On these sparse CNs, NIC has often better cpu time performances than SAC but it does not remove more values than Max-RPC. Consequently, NIC has a bad cpu time to number of deleted values ratio. Unlike strong PC, SRPC, SAC, and NIC, the cpu time requirements of AC7, PIC2, RPC2 and Max-RPC are of the same order of magnitude. The cpu time to number of deleted values ratios of these four last lterings are also very close, with a little advantage for PIC2. Although PIC is stronger than RPC, PIC2 can be less expensive than RPC2 on sparse CNs. If there are few 3-cliques in the constraint graph, PIC2 does not require far more cpu time than AC7 whereas RPC2 is about two times as expensive as AC7 since it looks for two supports for each value on each constraint."
    }, {
      "heading" : "6.4 Experiments on more Dense CNs",
      "text" : "On more dense CNs (see Figure 9), the complexity peaks of AC7, RPC2, PIC2, and MaxRPC stay close to each other. PIC2 is less worthwhile since it deletes few additional values compared to RPC2 while its cpu time requirements are close to those of Max-RPC. MaxRPC has one of the best cpu time to number of deleted values ratios. As soon as RPC leads to a domain wipe out, the cpu time performances of SRPC and RPC2 merge. Indeed, the SRPC algorithm used enforces RPC2 before checking the restricted path consistency of the sub-problems P j\nD\ni\n=fag\nfor each (i; a) 2 D. If all the values of a domain are restricted\npath inconsistent, the RPC preprocessing nds the global inconsistency of the problem and the SRPC algorithm stops. SRPC is less expensive than strong PC although it is more pruningful. These two lterings remain the most expensive. NIC is the most pruningful local consistency on these CNs. Hence, on a large range of tightnesses, NIC has the best cpu time to number of deleted values ratio. However, on some instances, NIC cannot avoid the combinatorial explosion. Although NIC requires \\only\" fteen minutes on average at tightness .52, more than two hours are required on some instances. It is conceivable that instances on which NIC requires far more cpu time exist for this set of parameters. Obviously, the set of CNs on which NIC is prohibitive grows when the density increases. The results on SAC have a lower standard deviation. SAC never requires more than fty two minutes on the problems generated for these experiments."
    }, {
      "heading" : "6.5 Discussion",
      "text" : "What can we conclude from these results? Strong PC is by far the least interesting ltering technique. Compared to SAC, which removes most of the strong path inconsistent values, strong PC is really prohibitive. 7 Achieving SAC or SRPC is costly as long as these two local consistencies do not delete any value. Obviously, although SAC and SRPC are more expensive than Max-RPC on almost all the generated problems, we cannot say that it is better to use Max-RPC. Indeed, at density .15 for example, Max-RPC is useless for\n7. We can point out that when the path consistency of a constraint can be expressed without explicitly\nstoring the set of forbidden tuples, path consistency can be used (e.g., temporal networks Allen, 1983, constraint networks Smith, 1992).\nDomain Filtering Consistencies\nDebruyne & Bessi ere\nDomain Filtering Consistencies\ntightnesses lower than .63 since it does not delete any value, while for SRPC the limit is .57 of tightness. Furthermore, for singleton consistencies we can argue that the algorithm used to achieve them is not optimal. An algorithm reusing part of the ltering performed on P j\nD\ni\n=fag\nto process other sub-problems P j\nD\nj\n=fbg\n, ((i; a) and (j; b) belonging to D) would\nimprove cpu time performances. However, the cpu time to number of deleted values ratios of SAC and SRPC algorithms are often among the worst ones, especially on sparse CNs. SAC and SRPC are so expensive that it is hardly likely that enhancements of these algorithms could lead them to be the most worthwhile lterings. On sparse uniform CNs, NIC is not the best choice. Compared to Max-RPC, it does not delete enough values to o set the additional cpu time cost. Furthermore, NIC cannot be used on dense CNs since its cpu time requirements become greater than those of a search algorithm. So, NIC has to be used only on \\relatively\" dense CNs, as those of Figure 9 on which NIC is worthwhile on average (although on some instances a combinatorial explosion cannot be avoided). On very dense CNs, the worst case time complexity of Max-RPC and PIC2 is close to the one of the best path consistency algorithm (O(en+ ed 2 + cd 3 ) against O(n 3 d 3 )). However, the experiments underline that achieving Max-RPC and PIC2 is far less expensive in practice. Compared to RPC2 and Max-RPC, PIC2 is not a good solution in-between. The cpu time to number of deleted values ratios of RPC2 and Max-RPC are better than the one of PIC2 (except on very sparse CNs on which PIC2 can be less expensive than RPC2). Indeed, PIC2 deletes only few additional values compared to RPC2, while its cpu time performances are close to those of Max-RPC.\nCpu time performances are even more essential when the aim is to maintain a local consistency during search. Maintaining a local consistency during search requires to repeatedly propagate the choice of a value for a variable (namely the restriction of a domain to a singleton) or the refutation of a value. To be worthwhile, a local consistency has to require less time to detect that a branch of the search tree does not lead to a solution than a search algorithm to explore this branch. So, maintaining a local consistency during search can outperform MAC on hard problems only if this local consistency is more pruningful than AC while requiring only a little additional cpu time. With regard to this criterion, we can discard strong PC, SAC, SRPC, and NIC on dense CNs because they are too expensive. It is conceivable that we can nd instances on which maintaining these consistencies during search outperforms MAC, but the more expensive the maintained local consistency is, the more seldom the problems on which MAC is outperformed will be. On sparse CNs, NIC is not prohibitive, but it deletes only few additional values compared to Max-RPC and it has therefore a bad cpu time to number of deleted values ratio. Finally, The most promising local consistencies are RPC and Max-RPC. If we exclude arc consistency, RPC is the least expensive local consistency we studied. Furthermore, the RPC algorithms delete most of the path inverse inconsistent values. Although Max-RPC is far more pruningful than arc consistency, experiments show that in practice, Max-RPC has very good cpu time results. Therefore, it seems very likely that maintaining RPC or Max-RPC during search could outperform MAC on very hard problems.\nTo con rm these results, an algorithm called Quick that maintains an adaptation of Max-RPC has been compared to MAC. The results of these experiments (Debruyne, 1999) show that Quick has better cpu time performances than MAC on large and hard randomly generated CNs that are relatively sparse. More interestingly, Quick has a more impor-\nDebruyne & Bessi ere\ntant stability than MAC (the cpu time performances of Quick have a very low standard deviation). It would be very interesting to propose e cient algorithms that maintain the local consistencies studied in this paper and to compare these algorithms. Such a study would allow us to know whether during search, the more advantageous local consistencies remain RPC and Max-RPC as during a preprocessing step. First results on the e ect of maintaining SAC during search are given in (Prosser, Stergiou, & Walsh, 2000)."
    }, {
      "heading" : "7. Conclusion",
      "text" : "In this paper we extended the idea of restricted path consistency to k-RPC and MaxRPC, which are more pruningful local consistencies. We proposed a new class of local consistencies called singleton consistencies. We studied these new local consistencies and the other local consistencies that alike can be used on large CNs while removing more values than arc consistency. We showed some relations between them and we compared both theoretically and experimentally their pruning and time e ciencies. The most pruningful are neighborhood inverse consistency and singleton restricted path consistency. However, SRPC is expensive in time and the exponential worst case time complexity of NIC makes it unusable on dense CNs. If we are looking for a local consistency that would advantageously be maintained during search, RPC and Max RPC seem to be the most promising local consistencies. Indeed, they are relatively inexpensive and far more pruningful than arc consistency."
    }, {
      "heading" : "8. Acknowledgements",
      "text" : "We would like to thank Toby Walsh for his suggestions for improving the presentation of the gures in Section 5."
    } ],
    "references" : [ {
      "title" : "Maintaining Knowledge about Temporal Intervals",
      "author" : [ "J. Allen" ],
      "venue" : null,
      "citeRegEx" : "Allen,? \\Q1983\\E",
      "shortCiteRegEx" : "Allen",
      "year" : 1983
    }, {
      "title" : "Dynamic variable ordering in csps",
      "author" : [ "F. Bacchus", "P. van Run" ],
      "venue" : null,
      "citeRegEx" : "Bacchus and Run,? \\Q1995\\E",
      "shortCiteRegEx" : "Bacchus and Run",
      "year" : 1995
    }, {
      "title" : "Radio link frequency assignment",
      "author" : [ "C. Cabon", "S. de Givry", "L. Lobjois", "T. Schiex", "J. Warners" ],
      "venue" : "benchmarks. CONSTRAINTS,",
      "citeRegEx" : "Cabon et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Cabon et al\\.",
      "year" : 1999
    }, {
      "title" : "Where the really hard problems are",
      "author" : [ "P. Cheeseman", "B. Kanefsky", "W. Taylor" ],
      "venue" : "In Proceedings of IJCAI-91,",
      "citeRegEx" : "Cheeseman et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Cheeseman et al\\.",
      "year" : 1991
    }, {
      "title" : "Two new constraint propagation algorithms requiring small space complexity",
      "author" : [ "A. Chmeiss", "P. J egou" ],
      "venue" : "In Proceedings of IEEE ICTAI-96,",
      "citeRegEx" : "Chmeiss and egou,? \\Q1996\\E",
      "shortCiteRegEx" : "Chmeiss and egou",
      "year" : 1996
    }, {
      "title" : "A strong local consistency for constraint satisfaction",
      "author" : [ "R. Debruyne" ],
      "venue" : "In Proceedings of IEEE ICTAI-99, Chicago IL,",
      "citeRegEx" : "Debruyne,? \\Q1999\\E",
      "shortCiteRegEx" : "Debruyne",
      "year" : 1999
    }, {
      "title" : "A property of path inverse consistency leading to an optimal algorithm",
      "author" : [ "R. Debruyne" ],
      "venue" : "In Proceedings of ECAI-00, Berlin,",
      "citeRegEx" : "Debruyne,? \\Q2000\\E",
      "shortCiteRegEx" : "Debruyne",
      "year" : 2000
    }, {
      "title" : "From restricted path consistency to max-restricted path consistency",
      "author" : [ "R. Debruyne", "C. Bessi ere" ],
      "venue" : "In Proceedings of CP-97,",
      "citeRegEx" : "Debruyne and ere,? \\Q1997\\E",
      "shortCiteRegEx" : "Debruyne and ere",
      "year" : 1997
    }, {
      "title" : "Some practicable ltering techniques for the constraint satisfaction problem",
      "author" : [ "R. Debruyne", "C. Bessi ere" ],
      "venue" : "In Proceedings of IJCAI-97,",
      "citeRegEx" : "Debruyne and ere,? \\Q1997\\E",
      "shortCiteRegEx" : "Debruyne and ere",
      "year" : 1997
    }, {
      "title" : "Experimental evaluation of preprocessing algorithms for constraint satisfaction problems",
      "author" : [ "R. Dechter", "I. Meiri" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Dechter and Meiri,? \\Q1994\\E",
      "shortCiteRegEx" : "Dechter and Meiri",
      "year" : 1994
    }, {
      "title" : "Network-based heuristics for constraint-satisfaction problems",
      "author" : [ "R. Dechter", "J. Pearl" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Dechter and Pearl,? \\Q1988\\E",
      "shortCiteRegEx" : "Dechter and Pearl",
      "year" : 1988
    }, {
      "title" : "A su cient condition for backtrack-free search",
      "author" : [ "E. Freuder" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Freuder,? \\Q1982\\E",
      "shortCiteRegEx" : "Freuder",
      "year" : 1982
    }, {
      "title" : "A su cient condition for backtrack-bounded search",
      "author" : [ "E. Freuder" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Freuder,? \\Q1985\\E",
      "shortCiteRegEx" : "Freuder",
      "year" : 1985
    }, {
      "title" : "Completable representations of constraint satisfaction problems",
      "author" : [ "E. Freuder" ],
      "venue" : "In Proceedings of KR-91,",
      "citeRegEx" : "Freuder,? \\Q1991\\E",
      "shortCiteRegEx" : "Freuder",
      "year" : 1991
    }, {
      "title" : "Neighborhood inverse consistency preprocessing",
      "author" : [ "E. Freuder", "C. Elfe" ],
      "venue" : "In Proceedings of AAAI-96, Portland OR,",
      "citeRegEx" : "Freuder and Elfe,? \\Q1996\\E",
      "shortCiteRegEx" : "Freuder and Elfe",
      "year" : 1996
    }, {
      "title" : "Random uniform csp generators. In http://www.ics.uci.edu/~ frost/csp/generatotr.html",
      "author" : [ "D. Frost", "C. Bessi ere", "R. Dechter", "J. R egin" ],
      "venue" : null,
      "citeRegEx" : "Frost et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Frost et al\\.",
      "year" : 1996
    }, {
      "title" : "Look-ahead value ordering for constraint satisfaction problems",
      "author" : [ "D. Frost", "R. Dechter" ],
      "venue" : "In Proceedings of IJCAI-95,",
      "citeRegEx" : "Frost and Dechter,? \\Q1995\\E",
      "shortCiteRegEx" : "Frost and Dechter",
      "year" : 1995
    }, {
      "title" : "A constraint satisfaction method for inference making",
      "author" : [ "J. Gaschnig" ],
      "venue" : "In Proceedings of the 12th Annual Allerton Conf. Circuit System Theory, U.I.L., Urbana-Champaign IL,",
      "citeRegEx" : "Gaschnig,? \\Q1974\\E",
      "shortCiteRegEx" : "Gaschnig",
      "year" : 1974
    }, {
      "title" : "The phase transition behaviour of maintaining arc consis",
      "author" : [ "S. 516{524. Grant", "B. Smith" ],
      "venue" : null,
      "citeRegEx" : "Grant and Smith,? \\Q1996\\E",
      "shortCiteRegEx" : "Grant and Smith",
      "year" : 1996
    }, {
      "title" : "Increasing tree search e ciency for constraint satisfaction",
      "author" : [ "R. Haralick", "G. Elliott" ],
      "venue" : null,
      "citeRegEx" : "Haralick and Elliott,? \\Q1980\\E",
      "shortCiteRegEx" : "Haralick and Elliott",
      "year" : 1980
    }, {
      "title" : "Random constraint satisfaction",
      "author" : [ "E. MacIntyre", "P. Prosser", "B. Smith", "T. Walsh" ],
      "venue" : null,
      "citeRegEx" : "MacIntyre et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "MacIntyre et al\\.",
      "year" : 1998
    }, {
      "title" : "Hybrid algorithms for the constraint satisfaction problem",
      "author" : [ "P. 287{342. Prosser" ],
      "venue" : null,
      "citeRegEx" : "Prosser,? \\Q1993\\E",
      "shortCiteRegEx" : "Prosser",
      "year" : 1993
    }, {
      "title" : "Contradicting conventional wisdom in constraint satisfac",
      "author" : [ "D. Sabin", "E. Freuder" ],
      "venue" : "CP-00, Singapore,",
      "citeRegEx" : "Sabin and Freuder,? \\Q1994\\E",
      "shortCiteRegEx" : "Sabin and Freuder",
      "year" : 1994
    }, {
      "title" : "Lazy arc consistency",
      "author" : [ "Amsterdam", "T. Netherlands. Schiex", "J. R egin", "C. Gaspin", "G. Verfaillie" ],
      "venue" : null,
      "citeRegEx" : "Amsterdam et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Amsterdam et al\\.",
      "year" : 1996
    }, {
      "title" : "Path consistency revisited",
      "author" : [ "M. Singh" ],
      "venue" : "Portland OR,",
      "citeRegEx" : "Singh,? \\Q1995\\E",
      "shortCiteRegEx" : "Singh",
      "year" : 1995
    }, {
      "title" : "How to Solve the Zebra Problem, or Path Consistency the Easy Way",
      "author" : [ "B.D.C. Smith" ],
      "venue" : null,
      "citeRegEx" : "Smith,? \\Q1992\\E",
      "shortCiteRegEx" : "Smith",
      "year" : 1992
    }, {
      "title" : "Foundations of Constraint Satisfaction",
      "author" : [ "E. Tsang" ],
      "venue" : "Proceedings of ECAI-92,",
      "citeRegEx" : "Tsang,? \\Q1993\\E",
      "shortCiteRegEx" : "Tsang",
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "Finding a solution in a constraint network involves looking for a set of value assignments, one for each variable, so that all the constraints are simultaneously satis ed (Meseguer, 1989; Tsang, 1993).",
      "startOffset" : 171,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "We also show a property of path inverse consistency that can be used to have an optimal worst case time complexity in a path inverse consistency algorithm (Debruyne, 2000).",
      "startOffset" : 155,
      "endOffset" : 171
    }, {
      "referenceID" : 24,
      "context" : "PC5 (Singh, 1995) O(n 3 d 3 ) ( ) O(n 3 d 2 ) PC8 (Chmeiss & J egou, 1996) O(n 3 d 4 ) O(n 2 d) 2",
      "startOffset" : 4,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : "PIC2 (Debruyne, 2000) O(en+ ed 2 + cd 3 ) ( ) O(ed+ cd)",
      "startOffset" : 5,
      "endOffset" : 21
    }, {
      "referenceID" : 6,
      "context" : "As shown in (Debruyne, 2000), if we assume that the constraint network is arc consistent, enforcing PIC requires checking even less 3-tuples than those mentioned in (Freuder & Elfe, 1996).",
      "startOffset" : 12,
      "endOffset" : 28
    }, {
      "referenceID" : 6,
      "context" : "The algorithms used are AC7 (Bessi ere, Freuder, & R egin, 1995), RPC2 (Debruyne & Bessi ere, 1997a), PIC2 (Debruyne, 2000), Max-RPC1 (Debruyne & Bessi ere, 1997a), the singleton arc consistency algorithm of (Debruyne & Bessi ere, 1997b) (SAC1) based on AC6, a SRPC algorithm based on RPC2 (SRPC1), and the NIC algorithm proposed in (Freuder & Elfe, 1996) (NIC1) using FCCBJ (Prosser, 1993) (as inFreuder & Elfe, 1996) with dom+deg dynamic variable ordering heuristic (minimal domain rst, in which ties are broken by choosing the variable with the highest degree in the constraint graph Frost & Dechter, 1995; Bessi ere & R egin, 1996).",
      "startOffset" : 107,
      "endOffset" : 123
    }, {
      "referenceID" : 21,
      "context" : "The algorithms used are AC7 (Bessi ere, Freuder, & R egin, 1995), RPC2 (Debruyne & Bessi ere, 1997a), PIC2 (Debruyne, 2000), Max-RPC1 (Debruyne & Bessi ere, 1997a), the singleton arc consistency algorithm of (Debruyne & Bessi ere, 1997b) (SAC1) based on AC6, a SRPC algorithm based on RPC2 (SRPC1), and the NIC algorithm proposed in (Freuder & Elfe, 1996) (NIC1) using FCCBJ (Prosser, 1993) (as inFreuder & Elfe, 1996) with dom+deg dynamic variable ordering heuristic (minimal domain rst, in which ties are broken by choosing the variable with the highest degree in the constraint graph Frost & Dechter, 1995; Bessi ere & R egin, 1996).",
      "startOffset" : 375,
      "endOffset" : 390
    }, {
      "referenceID" : 5,
      "context" : "The results of these experiments (Debruyne, 1999) show that Quick has better cpu time performances than MAC on large and hard randomly generated CNs that are relatively sparse.",
      "startOffset" : 33,
      "endOffset" : 49
    } ],
    "year" : 2017,
    "abstractText" : "Enforcing local consistencies is one of the main features of constraint reasoning. Which level of local consistency should be used when searching for solutions in a constraint network is a basic question. Arc consistency and partial forms of arc consistency have been widely studied, and have been known for sometime through the forward checking or the MAC search algorithms. Until recently, stronger forms of local consistency remained limited to those that change the structure of the constraint graph, and thus, could not be used in practice, especially on large networks. This paper focuses on the local consistencies that are stronger than arc consistency, without changing the structure of the network, i.e., only removing inconsistent values from the domains. In the last ve years, several such local consistencies have been proposed by us or by others. We make an overview of all of them, and highlight some relations between them. We compare them both theoretically and experimentally, considering their pruning e ciency and the time required to enforce them.",
    "creator" : "dvipsk 5.66a Copyright 1986-97 Radical Eye Software (www.radicaleye.com)"
  }
}