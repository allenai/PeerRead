{
  "name" : "1612.00542.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks",
    "authors" : [ "Daniel Lévy" ],
    "emails" : [ "danilevy@cs.stanford.edu", "ajain@cs.stanford.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "According to the International Agency for Research on Cancer, breast cancer accounts for 22.9% of invasive cancers and 13.7% of cancer-related deaths in women worldwide [5]. In the U.S., 1 in 8 women is expected to develop invasive breast cancer over the course of her lifetime [7]. Routine mammography is standard for preventive care and detection of breast cancer before biopsy. However, it is still a manual process, prone to human error due to high variability in mass appearance [2] and low signal-to-noise ratio, and thus can cause unnecessary biopsies or worse, missed malignant masses. Furthermore, efficacy is often highly correlated with radiologist expertise and workload [10].\nConvolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17]. For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability. In this work, we successfully train end-to-end CNN architectures to directly classify breast masses as benign or malignant. We obtain state-of-the-art results using a combination of transfer learning, careful pre-processing and data augmentation. We analyze the effects of these modelling choices and furthermore show how we can provide interpretability to the model’s predictions."
    }, {
      "heading" : "2 Related Work",
      "text" : "While medical images differs significantly from natural images, traditional feature engineering techniques from computer vision such as scale-invariant feature transform (SIFT) and histogram of oriented gradients (HOG) have seen use and success when applied to medical images. More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].\nIn the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests. Multiple works tackle the problem of breast lesion classification, but typically adopt a multi-stage approach. [24] extracts hand-engineered semantic (such as calcification) and textual features, and [6] classifies a full mammogram by extracting features from each view of the breast\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 2.\n00 54\n2v 1\n[ cs\n.C V\n] 2\nD ec\n2 01\nand combining them to output a prediction. [1] performs extensive pre-processing using domain knowledge before training a CNN. To the best of our knowledge, ours is the first work to directly classify pre-detected breast masses using CNN architectures."
    }, {
      "heading" : "3 Dataset",
      "text" : "In our experiments, we use the Digital Database for Screening Mammography (DDSM) [4], a collaboratively maintained public dataset at the University of South Florida. It comprises approximately 2500 studies each containing both mediolateral oblique (MLO) and craniocaudal (CC) views of each breast. Each image is grayscale and accompanied by a mask specifying the region of the pre-segmented mass if present. Examples of benign and malignant masses are shown in Fig. 1.\nWe consider only mammograms which contain masses, resulting in 1820 images from 997 patients. We split these randomly by patient into training, validation and testing sets (80%, 10% and 10% of the full dataset), constraining the validation and test sets to be balanced."
    }, {
      "heading" : "4 Methods",
      "text" : "We train three different CNN architectures for breast mass classification, and analyze the effect of a number of model choices. We describe these below."
    }, {
      "heading" : "4.1 CNN architectures",
      "text" : "We evaluate three network architectures: a shallow CNN (the baseline model), an AlexNet [16] and a GoogLeNet [22]. For both the AlexNet and GoogLeNet, we use the same base architecture as the original works but replace the last fully-connected (FC) layer to output 2 classes. We also remove the two auxiliary classifiers from the GoogLeNet which we found impaired our training in practice.\nThe baseline model’s architecture is inspired by the early layers of AlexNet [16]. We additionally use batch normalization [13]. The network takes a 224 × 224 × 3 image as input. It consists of 3 convolutional blocks composed of 3× 3 Convolutions - Batch Norm - ReLU - Max Pooling, with respectively 32, 32 and 64 filters each, followed by 3 FC layers of size 128, 64 and 2. The final layer is a soft-max layer for binary classification. We use ReLU activation functions, Xavier [12] weight initialization, and the Adam [15] update rule with a base learning rate of 10−3 and batch size 64."
    }, {
      "heading" : "4.2 Aspects of model analysis",
      "text" : "Transfer learning We analyze the effect of initializing networks with pre-training on the ImageNet dataset [19], and then fine-tuning on mammography images. For the AlexNet model, we initialize the convolutional layers with pre-trained weights and a smaller learning rate multiplier of 0.1, and randomly initialize the 3 FC layers. For the GoogLeNet, we use the same weight initialization scheme. We use a learning rate multiplier of 0.1 for the layers before the Inception_5a module, 1 for the Inception_5a and Inception_5b modules, and 10 for the last FC layer for more aggressive learning.\nWe train the AlexNet with Adam, base learning rate 10−3, and dropout rate 0.5. We train the GoogLeNet with Vanilla SGD, base learning rate 10−2, and dropout rate 0.2.\nMass context The area surrounding a mass provides useful context for diagnosis. We explore two approaches for providing the network with context. In the first, our input to the network is the region including 50 pixels of fixed padding around the mass, providing a context size independent of mass dimensions (referred to as Small Context). In the second approach we use proportional padding by extracting a region two times the size of the mass bounding box (referred to as Large Context).\nData Augmentation We study the impact of data augmentation to alleviate to the relatively small size of our training set, which is characteristic of many medical image datasets. We use rotation, cropping, and mirroring transformations to increase the effective size of our dataset (referred to as Aug). For each training image, we perform 5 random rotations and sample 5 random crops per rotation offline, effectively increasing training set size by a factor of 25. We also perform random mirroring at train time. These augmentations are justified since masses have no inherent orientation and their diagnosis is invariant to these transformations."
    }, {
      "heading" : "5 Results",
      "text" : "We first present empirical analysis of our model design using the AlexNet base architecture, then show quantitative results of our best models. Finally we use techniques for visualizing saliency maps to provide interpretability of the model. All experiments are implemented with Caffe [14], and the analysis and results are presented on the validation and test sets, respectively."
    }, {
      "heading" : "5.1 Empirical analysis",
      "text" : "Effectiveness of transfer learning CNN-based image representations learned on large-scale annotated datasets have proven to to be a useful form of pre-training that can be effectively transferred to other computer vision tasks with limited training data [18]. More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23]. In Table 1, we strongly confirm this claim by demonstrating that a fine-tuned AlexNet significantly outperforms our baseline model.\nInfluence of context To understand the influence of context around masses, we fine-tune an AlexNet on two different datasets - one with fixed padding and the other with proportional padding. The results in Table 2 show that proportional padding contains greater signal for classification, and we consequently use this for the remaining experiments.\nInfluence of data augmentation Limited amounts of training data is a common bottleneck in machine learning applications to medical problems. We evaluate the utility of data augmentation schemes to increase the effective amount of training data and reduce overfitting. The training loss curves in Fig. 2 show that our data augmentation technique described in Sec. 4.2 successfully regularises the network and helps remedy the scarcity of data."
    }, {
      "heading" : "5.2 Performance",
      "text" : "Our final results using the model choices described in Sec. 5.1 and all base architectures are presented in Table 3. The GoogLeNet outperforms the other models by a fair margin. It is also more suited for fine-tuning and less prone to overfitting due to its relatively small number of parameters, approximately 5 million compared to 100 million for AlexNet.\nAn important metric for diagnostic applications is maximizing recall, since the cost of a false negative (patient remaining undiagnosed) is much higer than a false positive (an additional biopsy). Our best model achieves 0.934 recall at 0.924 precision, outperforming human performance in a study that\nshows radiologist recall between 0.745 and 0.923 [10]. This result is very promising for real-life use of such models in clinical practice."
    }, {
      "heading" : "5.3 Interpretability",
      "text" : "Deep learning models often lack interpretability and as such are hard to adopt for practical use in medical settings. [21] describe a methodology to visualize saliency maps which show the regions of an image the network is sensitive to when making predictions. This is performed by computing the gradient of the image with respect to the unnormalized class scores. Regions with larger gradient indicate higher contribution to the prediction (brighter in Fig. 3). Both the AlexNet and GoogLeNet learn to attend to the edges of the mass, which is a high-signal criterion for diagnosis, while also paying attention to context."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this work, we propose an end-to-end deep learning model to classify pre-detected breast masses from mammograms. We show how careful pre-processing, data augmentation and transfer learning can overcome the data bottleneck common to medical computer vision tasks, and additionally provide a method to give more interpretability to network predictions.\nOur approach obtains state-of-the-art results, outperforming trained radiologists, and the interpretability enables more comfortable adoption in real-world settings. Future work includes exploring other architectures, and integration of attention mechanisms which are more difficult to train but could provide even more concrete interpretability."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Justin Johnson for continuous feedback and guidance throughout this project as well as Serena Yeung for insightful comments on the draft. The authors also ackowledge the support of AWS Educate program for generously providing free instances with GPUs."
    } ],
    "references" : [ {
      "title" : "Representation learning for mammography mass lesion classification with convolutional neural networks",
      "author" : [ "J. Arevalo", "F.A. González", "R. Ramos-Pollán", "J.L. Oliveira", "M.A.G. Lopez" ],
      "venue" : "Computer methods and programs in biomedicine, 127:248–257",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Digital mammographic computer aided diagnosis (cad) using adaptive level set segmentation",
      "author" : [ "J.E. Ball", "L.M. Bruce" ],
      "venue" : "2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 4973–4978. IEEE",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Chest pathology detection using deep learning with non-medical training",
      "author" : [ "Y. Bar", "I. Diamant", "L. Wolf", "S. Lieberman", "E. Konen", "H. Greenspan" ],
      "venue" : "2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI), pages 294–297. IEEE",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The digital database for screening mammography",
      "author" : [ "K. Bowyer", "D. Kopans", "W. Kegelmeyer", "R. Moore", "M. Sallam", "K. Chang", "K. Woods" ],
      "venue" : "Third international workshop on digital mammography, volume 58, page 27",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "et al",
      "author" : [ "P. Boyle", "B. Levin" ],
      "venue" : "World cancer report 2008. IARC Press, International Agency for Research on Cancer",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Unregistered multiview mammogram analysis with pre-trained deep learning models",
      "author" : [ "G. Carneiro", "J. Nascimento", "A.P. Bradley" ],
      "venue" : "International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 652–660. Springer International Publishing",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Breast cancer statistics",
      "author" : [ "C. DeSantis", "J. Ma", "L. Bryan", "A. Jemal" ],
      "venue" : "2013. CA: a cancer journal for clinicians, 64(1):52–62",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Automated mass detection in mammograms using cascaded deep learning and random forests",
      "author" : [ "N. Dhungel", "G. Carneiro", "A.P. Bradley" ],
      "venue" : "Digital Image Computing: Techniques and Applications (DICTA), 2015 International Conference on, pages 1–8. IEEE",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Deep learning and structured prediction for the segmentation of mass in mammograms",
      "author" : [ "N. Dhungel", "G. Carneiro", "A.P. Bradley" ],
      "venue" : "International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 605–612. Springer International Publishing",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "et al",
      "author" : [ "J.G. Elmore", "S.L. Jackson", "L. Abraham", "D.L. Miglioretti", "P.A. Carney", "B.M. Geller", "B.C. Yankaskas", "K. Kerlikowske", "T. Onega", "R.D. Rosenberg" ],
      "venue" : "Variability in interpretive performance at screening mammography and radiologists’ characteristics associated with accuracy 1. Radiology, 253(3):641–651",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Rich feature hierarchies for accurate object detection and semantic segmentation",
      "author" : [ "R. Girshick", "J. Donahue", "T. Darrell", "J. Malik" ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 580–587",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Understanding the difficulty of training deep feedforward neural networks",
      "author" : [ "X. Glorot", "Y. Bengio" ],
      "venue" : "Aistats, volume 9, pages 249–256",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "S. Ioffe", "C. Szegedy" ],
      "venue" : "arXiv preprint arXiv:1502.03167",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Caffe: Convolutional architecture for fast feature embedding",
      "author" : [ "Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell" ],
      "venue" : "Proceedings of the 22nd ACM international conference on Multimedia, pages 675–678. ACM",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D. Kingma", "J. Ba" ],
      "venue" : "arXiv preprint arXiv:1412.6980",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "ImageNet Classification with Deep Convolutional Neural Networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : "NIPS",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Fully convolutional networks for semantic segmentation",
      "author" : [ "J. Long", "E. Shelhamer", "T. Darrell" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3431–3440",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning and transferring mid-level image representations using convolutional neural networks",
      "author" : [ "M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic" ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1717–1724",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "et al",
      "author" : [ "O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein" ],
      "venue" : "Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211–252",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Deep convolutional neural networks for computer-aided detection: Cnn architectures",
      "author" : [ "H.-C. Shin", "H.R. Roth", "M. Gao", "L. Lu", "Z. Xu", "I. Nogues", "J. Yao", "D. Mollura", "R.M. Summers" ],
      "venue" : "dataset characteristics and transfer learning. IEEE transactions on medical imaging, 35(5): 1285–1298",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Deep inside convolutional networks: Visualising image classification models and saliency maps",
      "author" : [ "K. Simonyan", "A. Vedaldi", "A. Zisserman" ],
      "venue" : "arXiv preprint arXiv:1312.6034",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Going deeper with convolutions",
      "author" : [ "C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1–9",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans",
      "author" : [ "B. van Ginneken", "A.A. Setio", "C. Jacobs", "F. Ciompi" ],
      "venue" : "In 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2015
    }, {
      "title" : "Discrimination of breast cancer with microcalcifications on mammography by deep learning",
      "author" : [ "J. Wang", "X. Yang", "H. Cai", "W. Tan", "C. Jin", "L. Li" ],
      "venue" : "Scientific reports, 6:27327",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "7% of cancer-related deaths in women worldwide [5].",
      "startOffset" : 47,
      "endOffset" : 50
    }, {
      "referenceID" : 6,
      "context" : ", 1 in 8 women is expected to develop invasive breast cancer over the course of her lifetime [7].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 1,
      "context" : "However, it is still a manual process, prone to human error due to high variability in mass appearance [2] and low signal-to-noise ratio, and thus can cause unnecessary biopsies or worse, missed malignant masses.",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 9,
      "context" : "Furthermore, efficacy is often highly correlated with radiologist expertise and workload [10].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 15,
      "context" : "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 10,
      "context" : "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 16,
      "context" : "Convolutional Neural Networks (CNN) have achieved impressive results on computer visions tasks spanning classification [16], object detection [11], and segmentation [17].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 0,
      "context" : "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 5,
      "context" : "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 7,
      "context" : "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 23,
      "context" : "For breast mass diagnosis, deep learning techniques have been explored [1, 6, 8, 9, 24], but never in a fully end-to-end manner (directly classifying from pixel space) because of the scarcity of available data and lack of interpretability.",
      "startOffset" : 71,
      "endOffset" : 87
    }, {
      "referenceID" : 2,
      "context" : "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].",
      "startOffset" : 174,
      "endOffset" : 181
    }, {
      "referenceID" : 22,
      "context" : "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].",
      "startOffset" : 174,
      "endOffset" : 181
    }, {
      "referenceID" : 19,
      "context" : "More recently, deep learning-based approaches using CNNs have begun to achieve impressive performance on medical tasks such as chest pathology identification in X-Ray and CT [3, 23], and thoraco-abdominal lymph node detection and interstitial lung disease classification [20].",
      "startOffset" : 271,
      "endOffset" : 275
    }, {
      "referenceID" : 7,
      "context" : "In the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 8,
      "context" : "In the context of mammography, [8, 9] detect breast masses using a combination of R-CNN and random forests.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 23,
      "context" : "[24] extracts hand-engineered semantic (such as calcification) and textual features, and [6] classifies a full mammogram by extracting features from each view of the breast",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 5,
      "context" : "[24] extracts hand-engineered semantic (such as calcification) and textual features, and [6] classifies a full mammogram by extracting features from each view of the breast",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 0,
      "context" : "[1] performs extensive pre-processing using domain knowledge before training a CNN.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "In our experiments, we use the Digital Database for Screening Mammography (DDSM) [4], a collaboratively maintained public dataset at the University of South Florida.",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "We evaluate three network architectures: a shallow CNN (the baseline model), an AlexNet [16] and a GoogLeNet [22].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 21,
      "context" : "We evaluate three network architectures: a shallow CNN (the baseline model), an AlexNet [16] and a GoogLeNet [22].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : "The baseline model’s architecture is inspired by the early layers of AlexNet [16].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 12,
      "context" : "We additionally use batch normalization [13].",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 11,
      "context" : "We use ReLU activation functions, Xavier [12] weight initialization, and the Adam [15] update rule with a base learning rate of 10−3 and batch size 64.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 14,
      "context" : "We use ReLU activation functions, Xavier [12] weight initialization, and the Adam [15] update rule with a base learning rate of 10−3 and batch size 64.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 18,
      "context" : "2 Aspects of model analysis Transfer learning We analyze the effect of initializing networks with pre-training on the ImageNet dataset [19], and then fine-tuning on mammography images.",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 13,
      "context" : "All experiments are implemented with Caffe [14], and the analysis and results are presented on the validation and test sets, respectively.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 17,
      "context" : "Effectiveness of transfer learning CNN-based image representations learned on large-scale annotated datasets have proven to to be a useful form of pre-training that can be effectively transferred to other computer vision tasks with limited training data [18].",
      "startOffset" : 254,
      "endOffset" : 258
    }, {
      "referenceID" : 2,
      "context" : "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].",
      "startOffset" : 122,
      "endOffset" : 133
    }, {
      "referenceID" : 19,
      "context" : "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].",
      "startOffset" : 122,
      "endOffset" : 133
    }, {
      "referenceID" : 22,
      "context" : "More recently, low-level features learned from natural images have shown to be effective for medical image classification [3, 20, 23].",
      "startOffset" : 122,
      "endOffset" : 133
    }, {
      "referenceID" : 9,
      "context" : "923 [10].",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 20,
      "context" : "[21] describe a methodology to visualize saliency maps which show the regions of an image the network is sensitive to when making predictions.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2016,
    "abstractText" : "Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model.",
    "creator" : "LaTeX with hyperref package"
  }
}