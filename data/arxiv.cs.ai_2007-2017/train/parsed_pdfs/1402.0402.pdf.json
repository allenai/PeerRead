{
  "name" : "1402.0402.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Customizable Contraction Hierarchies∗",
    "authors" : [ "Julian Dibbelt", "Ben Strasser" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Computing optimal routes in road networks has many applications such as navigation, logistics, traffic simulation or web-based route planning. Road networks are commonly formalized as weighted graphs and the optimal route is formalized as the shortest path in this graph. Unfortunately, road graphs tend to be huge in practice with vertex counts in the tens of millions, rendering Dijkstra’s algorithm [18] impracticable for interactive use: It incurs running times in the order of seconds even for a single path query. For practical performance on large road networks, preprocessing techniques that augment the network with auxiliary data in a (possibly expensive) offline phase have proven useful. See [4] for an overview. Many techniques work by adding extra edges called shortcuts to the graph that allow query algorithms to bypass large regions of the graph efficiently. While variants of the optimal shortcut selection problem have been proven to be NP-hard [7], determining good shortcuts is feasible in practice even on large road graphs. Among the most successful speedup techniques using this building block are Contraction Hierarchies (CH) by [20, 21]. At its core the technique consists of a systematic way of adding shortcuts by iteratively contracting vertices along a given order. Even though ordering heuristics exist that work well in practice [21], the problem of computing an optimal ordering is NP-hard in general [5]. Worst-case bounds have been proven in [1] in terms of a weight-dependent graph measure called highway dimension and [30] have shown that many of these bounds are tight on many graph classes.\nA central restriction of CHs as proposed by [21] is that their preprocessing is metric-dependent, that is edge weights, also called metric, need to be known. Substantial changes to the metric, e. g., due to user preferences or traffic congestion, may require expensive recomputation. For this reason, a Customizable Route Planning (CRP) approach was proposed in [12], extending the multi-level-overlay MLD techniques of [36, 26]. It works in three phases: In a first, expensive phase, auxiliary data is computed that solely exploits the topological structure of the network, disregarding its metric. In a second, much less expensive phase, this auxiliary data is customized to a specific metric, enabling fast queries in the third phase. In this work we extend CH to support such a three-phase approach.\nGame Scenario Most existing CH papers focus solely on road graphs, with [37] being a notable exception, but there are many other applications with differently structured graphs in which fast shortest path computations are important. One of such applications is games. Think of a real-time strategy game where units quickly have to navigate across a large map with many choke points. The basic topology of the map is fixed, however, when buildings are constructed or destroyed, fields are rendered impassable or freed up. Furthermore, every player has his own knowledge of the map. Many games include a feature\n∗Partial support by DFG grant WA654/16-2 and EU grant 288094 (eCOMPASS) and Google Focused Research Award.\nar X\niv :1\n40 2.\n04 02\nv5 [\ncs .D\nS] 2\n1 A\nug 2\n01 5\ncalled fog of war : Initially only the fields around the player’s starting location are revealed. As his units explore the map, new fields are revealed. Since a unit must not route around a building that the player has not yet seen, every player needs his own metric. Furthermore, units such as hovercrafts may traverse water and land, while other units are bound to land. This results in vastly different, evolving metrics for different unit types per player, making metric-dependent preprocessing difficult to apply. Contrary to road graphs one-way streets tend to be extremely rare, and thus being able to exploit the symmetry of the underlying graph is a useful feature.\nMetric-Independent Orders for CHs One of the central building blocks of this paper is the use of metric-independent nested dissection orders (ND-orders) [22] for CH precomputation instead of the metric-dependent order of [21]. This approach was proposed by [6], and a preliminary case study can be found in [42]. A similar idea was followed by [16], where the authors employ partial CHs to engineer subroutines of their customization phase. They also refer to preliminary experiments on full CH but did not publish results. Similar ideas have also appeared in [31]: They consider graphs of low treewidth (see below) and leverage this property to compute CH-like structures, without explicitly using the term CH. Related techniques by [40, 11] work directly on the tree decomposition. Interestingly, our experiments show that even large road networks have relatively low treewidth: Real-world road networks with vertex counts in the 107 have treewidth in the 102.\nTree-Decompositions, Sparse Matrices and Minimum Fill-In Customizable speedup techniques for shortest path queries are a very recent development but the idea to order vertices along nested dissection orders is significantly older. To the best of our knowledge the idea first appeared in 1973 in [22] and was refined in [29]. They use nested dissection orders to reorder the columns and rows of sparse matrices to assure that Gaussian elimination preserves as many zeros as possible. From the matrix they derive a graph and show that vertex contraction in this graph corresponds to Gaussian variable elimination. Inserting an extra edge in the graph destroys a zero in the matrix. The additional edges are called the fill-in. The minimum fill-in problem asks for a vertex order that results in a minimum number of extra arcs. In CH terminology these extra edges are called shortcuts. The super graph constructed by adding the additional edges is a chordal graph. The treewidth of a graph G can be defined using chordal super graphs: For every super graph consider the number of vertices in the maximum clique minus one. The treewidth of a graph G is the minimum of this number over all chordal super graphs of G. This establishes a relation between sparse matrices and treewidth and in consequence with CHs. We refer to [9] and [8] for an introduction to the broad field of treewidth and tree decompositions.\nMinimizing the number of extra edges, i. e., minimizing the fill-in, is NP-hard [41] but fixed parameter tractable in the number of extra edges [27]. Note, however, that from the CH point of view, optimizing the number of extra edges, i. e., the number of shortcuts, is not the sole optimization criterion. Consider for example a path graph as depicted in Figure 1: Optimizing the CH search space and the number of shortcuts are competing criteria. A tree relevant in the theory of treewidth is the elimination tree. [6] have shown that the maximum search space size in terms of vertices corresponds to the height of this elimination tree. Unfortunately, minimizing the elimination tree height is also NP-hard [32]. For planar graphs, it has been shown that the number of additional edges is in O(n log n) [24]. However, this does not imply a O(log n) search space bound in terms of vertices as search spaces can share vertices.\nDirected and Undirected Graphs Real-world road networks contain one-way streets and highways. Such networks are thus usually modeled as directed graphs. Our algorithms fully support direction of traffic— however, we introduce it at a different stage of the toolchain than most related techniques, which should not be confused with only supporting undirected networks. Our first preprocessing phase works exclusively on\nthe underlying undirected and unweighted graph, obtained by dropping all edge directions and edge weights. Direction of traffic as well as traversal weights are only introduced in the second (customization) phase, where every edge can have two weights: an upward and a downward weight. If an edge corresponds to an one-way street, then one of these weights is set to ∞. Note that this setup is a strength of our algorithm: Throughout large parts of the toolchain we are not confronted with additional complexity\ninduced by directed edges. This contrasts with many other techniques, where considering edge direction induces changes in nearly every step of the algorithm.\nOur Contribution The main contribution of our work is to show that Customizable Contraction Hierarchies (CCH) solely based on the ND-principle are feasible and practical. Compared to CRP [12] we achieve a similar preprocessing–query tradeoff, albeit with slightly better query performance at slightly slower customization speed and we need somewhat more space. Interestingly, for less well-behaved metrics such as travel distance, we achieve query times below the original metric-dependent CH of [21]. Besides this main result, we show that given a fixed contraction order, a metric-independent CH can be constructed in time essentially linear in the size of the Contraction Hierarchy with working memory consumption linear in the input graph. Our specialized algorithm has better theoretic worst-case running time and performs significantly better empirically than the dynamic adjacency arrays used in [21]. Another contribution of our work are perfect witness searches. We show that for a fixed metric-independent vertex order it is possible to construct CHs with a provably minimum number of arcs in a few seconds on continental road graphs. Our construction algorithm has a running time performance completely independent of the weights used. We further show that an order based on nested dissection gives a constant factor approximation of the maximum and average search space sizes in terms of the number of arcs and vertices for metric-independent CHs on a class of graphs with very regular recursive vertex separators. Experimentally, we show that road graphs have such a recursive separator structure.\nOutline Section 2 sets necessary notation. Section 3 discusses metric-dependent orders as used by [21], highlighting specifics of our implementation. Next, we discuss metric-independent orders in Section 4. In Section 5, we describe how to efficiently construct the arcs of the CH. The next Section 6 discusses how to efficiently enumerate triangles in the CH — an operation needed throughout the customization process detailed in Section 7. In Section 7 we further describe the details of the perfect witness search. Finally, Section 8 concludes the algorithm description by introducing the algorithms used in the query phase to compute shortest path distances and compute the corresponding paths in the input graph. We then present an extensive experimental study that thoroughly evaluates the proposed algorithm. We finish with the conclusion, and with directions for future work."
    }, {
      "heading" : "2 Basics",
      "text" : "We denote by G = (V,E) an undirected n-vertex graph where V is the set of vertices and E the set of edges. Furthermore, G = (V,A) denotes a directed graph, where A is the set of arcs. A graph is simple if it has no loops or multi-edges. Graphs in this paper are simple unless noted otherwise, e. g., in parts of Section 5. Furthermore, we assume that input graphs are strongly connected. We denote by N(v) the neighborhood of vertex v ∈ G, i. e., the set of vertices adjacent to v; for directed graphs the neighborhood ignores arc direction. A vertex separator is a vertex subset S ⊆ V whose removal separates G into two disconnected subgraphs induced by the vertex sets A and B. The sets S, A and B are disjoint and their union forms V . Note that the subgraphs induced by A and B are not necessarily connected and may be empty. A separator S is balanced if |A| , |B| ≤ 2n/3.\nA vertex order π : {1 . . . n} → V is a bijection. Its inverse π−1 assigns each vertex a rank. Every undirected graph can be transformed into a upward directed graph with respect to a vertex order π, i. e., every edge {π(i), π(j)} with i < j is replaced by an arc (π(i), π(j)). Note that all upward directed graphs are acyclic. We denote by Nu(v) the upward neighborhood of v, i. e., the neighbors of v with a higher rank than v, and by Nd(v) the downward neighborhood of v, i. e., the vertices with a lower rank than v. We denote by du(v) = |Nu(v)| the upward degree and by dd(v) = |Nd(v)| the downward degree of a vertex.\nUndirected edge weights are denoted using w : E → R>0. With respect to a vertex order π we define an upward weight wu : E → R>0 and a downward weight wd : E → R>0. For directed graphs, one-way streets are modeled by setting wu or wd to ∞.\nA path P is a sequence of adjacent vertices and incident edges. Its hop-length is the number of edges in P . Its weight-length with respect to w is the sum over all edges’ weights. Unless noted otherwise, length always refers to weight-length in this paper. A shortest st-path is a path of minimum length between vertices s and t. The minimum length in G between two vertices is denoted by distG(s, t). We set distG(s, t) = ∞ if no path exists. An up-down path P with respect to π is a path that can be split into an upward path Pu and a downward path Pd. The vertices in the upward path Pu must occur by\nincreasing rank π−1 and the vertices in the downward path Pd must occur by decreasing rank π −1. The upward and downward paths meet at the vertex with the maximum rank on the path. We refer to this vertex as the meeting vertex.\nThe vertices of every acyclic directed graph (DAG) can be partitioned into levels ` : V → N such that for every arc (x, y) it holds that `(x) < `(y). We only consider levels such that each vertex has the lowest possible level. Note that such levels can be computed in linear time given a directed acyclic graph.\nThe unweighted vertex contraction of v in G consists of removing v and all incident edges and inserting edges between all neighbors N(v) if not already present. The inserted edges are referred to as shortcuts and the other edges are original edges. Given an order π the core graph Gπ,i is obtained by contracting all vertices π(1) . . . π(i − 1) in order of their rank. We call the original graph G augmented by the set of shortcuts a contraction hierarchy G∗π = ⋃ iGπ,i. Furthermore, we denote by G ∧ π the corresponding upward directed graph.\nGiven a fixed weight w, one can exploit that in many applications it is sufficient to only preserve all shortest path distances [21]. Weighted vertex contraction of a vertex v in the graph G is defined as the operation of removing v and inserting (a minimum number of shortcuts) among the neighbors of v to obtain a graph G′ such that distG(x, y) = distG′(x, y) for all vertices x 6= v and y 6= v. To compute G′, one iterates over all pairs of neighbors x, y of v increasing by distG(x, y). For each pair one checks whether a xy-path of length distG(x, y) exists in G\\{v}, i. e., one checks whether removing v destroys the xy-shortest path. This check is called witness search [21] and the xy-path is called witness, if it exists. If a witness is found, the considered vertex pair is skipped and no shortcut added. Otherwise, if an edge {x, y} already exists, its weight is decreased to distG(x, y), or a new shortcut edge with that weight is added to G. This new shortcut edge is considered in witness searches for subsequent neighbor pairs as part of G. If shortest paths are not unique, it is important to iterate over the pairs increasing by distG(x, y), because otherwise more edges than strictly necessary can be inserted: Shorter shortcuts can make longer shortcuts superfluous. However, if we insert the shorter shortcut after the longer ones, the witness search will not consider them. See Figure 2 for an example. Note that the witness searches are expensive and therefore the witness search is usually aborted after a certain number of steps [21]. If no witness was found until, we assume that none exists and add a shortcut. This does not affect the correctness of the technique but might result in slightly more shortcuts than necessary. To distinguish, perfect witness search is without such an one-sided error.\nFor an order π and a weight w the weighted core graph Gw,π,i is obtained by contracting all vertices π(1) . . . π(i−1). The original graph G augmented by the set of weighted shortcuts is called a weighted contraction hierarchy G∗w,π. The corresponding upward directed graph is denoted by G∧w,π.\nThe search space SS(v) of a vertex v is the subgraph of G∧π (respectively G∧w,π) reachable from v. For every vertex pair s and t, it has been shown that a shortest up-down path must exist. This up-down path can be found by running a bidirectional search from s restricted to SS(s) and from t restricted to SS(t) [21]. A graph is chordal if for every cycle of at least four vertices there exists a pair of vertices that are non-adjacent in the cycle but are connected by an edge. An alternative characterization is that a vertex order π exists such that for every i the neighbors of π(i) in Gπ,i, i. e., the core graph before the contraction of π(i), form a clique [19]. Such an order is called a perfect elimination order. Another way to formulate this characterization in CH terminology is as follows: A graph is chordal if and only if a contraction order exists such that the CH construction without witness search does not insert any shortcuts. A chordal super graph can be obtained by adding the CH shortcuts.\nThe elimination tree TG,π is a tree directed towards its root π(n). The parent of vertex π(i) is its upward neighbor v ∈ Nu(π(i)) of minimal rank π−1(v). Note that this definition already yields a straightforward algorithm for constructing the elimination tree. As shown in [6], the set of vertices on the path from v to π(n) is the set of vertices in SS(v). Computing a contraction hierarchy without witness search of graph G consists of computing a chordal super graph G∗π with perfect elimination order π. The height of the elimination tree corresponds to the maximum number of vertices in the search space. Note that the elimination tree is only defined for undirected unweighted graphs."
    }, {
      "heading" : "3 Metric-Dependent Orders",
      "text" : "Most publications on applications and extensions of Contraction Hierarchies use greedy orders in the spirit of [21], but details of vertex order computation and witness search vary. For reproducibility, we describe our precise approach in this section, extending on the general description of metric-dependent CH preprocessing given in Section 2. Our witness search aborts once it finds some path shorter than the shortcut—or when both forward and backward search each have settled at most p vertices. For most experiments we choose p = 50. The only exception is the distance metric on road graphs, where we set p = 1500. We found that a higher value of p increases the time per witness-search but leads to sparser cores. For the distance metric we needed a high value because otherwise our cores get too dense. This effect did not occur for the other weights considered in the experiments. Our weighting heuristic is similar to the one of [2]. We denote by L(x) a value that approximates the level of vertex x. Initially all L(x) are 0. If x is contracted, then for every incident edge {x, y} we perform `(y)← max{`(y), `(x) + 1}. We further store for every arc a a hop length h(a). This is the number of arcs that the shortcut represents if fully unpacked. Denote by D(x) the set of arcs removed if x is contracted and by A(x) the set of arcs that are inserted. Note that A(x) is not necessarily a full clique because of the witness search and because some edges may already exist. We greedily contract a vertex x that minimizes its importance I(x) defined by\nI(x) = L(x) + |A(x)| |D(x)| + ∑ a∈A(x) h(a)∑ a∈D(x) h(a) .\nWe maintain a priority queue that contains all vertices weighted by I. Initially all vertices are inserted with their exact importance. As long as the queue is not empty, we remove a vertex x with minimum importance I(x) and contract it. This modifies the importance of other vertices. However, our weighting function is chosen such that only the importance of adjacent vertices is influenced, if the witness search was perfect. We therefore only update the importance values of all vertices y in the queue that are adjacent to x. In practice, with a limited witness search, we sometimes choose a vertex x with a sightly suboptimal I(x). However, preliminary experiments have shown that this effect can be safely ignored. Hence, for the experiments presented in Section 9, we do not use lazy updates or periodic queue rebuilding as proposed in [21]."
    }, {
      "heading" : "4 Metric-Independent Order",
      "text" : "The metric-dependent orders presented in the previous section lead to very good results on road graphs with travel time metric. However, the results for the distance metric are not as good and the orders are completely impracticable to compute Contraction Hierarchies without witness search as our experiments in Section 9 show. To support metric-independence, we therefore use nested dissection orders as suggested in [6] or ND-orders for short. An order π for G is computed recursively by determining a balanced separator S of minimum cardinality that splits G into two parts induced by the vertex sets A and B. The vertices of S are assigned to π(n − |S|) . . . π(n) in an arbitrary order. Orders πA and πB are computed recursively and assigned to π(1) . . . π(|A|) and π(|A| + 1) . . . π(|A| + |B|), respectively. The base case of the recursion is reached when the subgraphs are empty. Computing ND-orders requires good graph bisectors, which in theory is NP -hard. However, recent years have seen heuristics that solve the problem very well even for continental road graphs [34, 15, 14]. This justifies assuming in our particular context that an efficient bisection oracle exists. We experimentally examine the performance of nested dissection orders computed by NDMetis [28] and KaHIP [34] in Section 9. After having obtained the nested dissection order we reorder the in-memory vertex IDs of the input graph accordingly, i. e., the contraction order of the reordered graph is the identity function. This improves cache locality and we have seen a resulting acceleration of a factor 2 to 3 in query times. In the remainder of this section we prepare and provide a theoretical approximation result.\nFor α ∈ (0, 1), let Kα, be a class of graphs that is closed under subgraph construction and admits balanced separators S of cardinality O(nα).\nLemma 1. For every G ∈ Kα a ND-order results in O(nα) vertices in the maximum search space.\nThe proof of this lemma is a straightforward argument using a geometric series as described in [6]. As a direct consequence, the average number of vertices is also in O(nα) and the number of arcs in O(n2α).\nLemma 2. For every connected graph G with minimum balanced separator S and every order π, the chordal super graph G∗π contains a clique of |S| vertices. Furthermore, there are at least n/3 vertices such that this clique is a subgraph of their search space in G∧π .\nThis lemma is a minor adaptation and extension of [29], who only prove that such a clique exists but not that it lies within enough search spaces. We provide the full proof for self-containedness.\nProof. Consider the subgraph Gi of G ∗ π induced by the vertices π(1) . . . π(i). Do not confuse with the core graph Gπ,i. Choose the smallest i, such that a connected component A exists in Gi such that |A| ≥ n/3. As G is connected, such an A must exist. We distinguish two cases:\n1. |A| ≤ 2n/3: Consider the set of vertices S′ adjacent to A in G∗π but not in A. Let B be the set of all remaining vertices. S′ is by definition a separator. It is balanced because |A| ≤ 2n/3 and |B| = n− |A|︸︷︷︸\n≥n/3 − |S′|︸︷︷︸ ≥0 ≤ 2n/3. As S is minimum, we have that |S′| ≥ |S|. For every pair of vertices\nu ∈ S′ and v ∈ S′ there exists a path through A as A is connected. The vertices u and v are not in Gi as otherwise they could be added to A. The ranks of u and v are thus strictly larger than i. On the other hand, the ranks of the vertices in A are at most i as they are part of Gi. The vertices u and v thus have the highest ranks on the path. They are therefore contracted last and therefore an edge {u, v} in G∗ must exist. S′ is therefore a clique. Furthermore, from every u ∈ A to every v ∈ S′ there exists a path such that v has the highest rank. Hence, v is in the search space of u, i. e., there are at least|A| ≥ n/3 vertices whose search space contains the full S′-clique.\n2. |A| > 2n/3: As i is minimum, we know that π(i) ∈ A and that removing it disconnects A into connected subgraphs C1 . . . Ck. We know that |Cj | < n/3 for all j because i is minimum. We further know that |A| = 1 + ∑ |Cj | > 2n/3. We can therefore select a subset of components Ck\nsuch that the number of their vertices is at most 2n/3 but at least n/3. Denote by A′ their union. Note that A′ does not contain π(i). Consider the vertices S′ adjacent to A′ in G∗π. The set S ′ contains π(i). Using an argument similar to Case 1, one can show that |S′| ≥ |S|. But since A′ is not connected, we cannot directly use the same argument to show that S′ forms a clique in G∗. Observe that A′ ∪ {π(i)} is connected and thus the argument can be applied to S′\\{π(i)} showing that it forms a clique. This clique can be enlarged by adding π(i) as for every v ∈ S′\\{π(i)} a path through one of the components Ck exists where v and π(i) have the highest ranks and thus an edge {v, π(i)} must exist. The vertex set S′ therefore forms a clique of at least the required size. It remains to show that enough vertices exist whose search space contains the S′ clique. As π(i) has the lowest rank in the S′ clique, the whole clique is contained within the search space of π(i). It is thus sufficient to show that π(i) is contained in enough search spaces. As π(i) is adjacent to each component Ck, a path from each vertex v ∈ A′ to π(i) exists such that π(i) has maximum rank showing that S′ is contained in the search space of v. This completes the proof as |A′| ≥ n/3.\nTheorem 1. Let G be a graph from Kα with a minimum balanced separator with Θ(n α) vertices. Then a ND-order gives an O(1)-approximation of the average and maximum search spaces of an optimal metricindependent contraction hierarchy in terms of vertices and arcs.\nProof. The key observation of this proof is that the top level separator solely dominates the performance. Denote by πnd the ND-order and by πopt an optimal order. First, we show a lower bound on the performance of πopt. We then demonstrate that πnd achieves this lower bound showing that πnd is an O(1)-approximation.\nAs the minimum balanced separator has cardinality Θ(nα), we know by Lemma 2 that a clique with Θ(nα) vertices exists in G∗πopt . As this clique is in the search space of at least one vertex with respect to πopt, we know that the maximum number of vertices in the search space is at least Ω(n\nα). Further, as this clique contains Θ(n2α) arcs we also have a lower bound of Ω(n2α) on the maximum number of arcs in a search space. From these bounds for the worst case search space, we cannot directly derive bounds for the average search space. Fortunately, Lemma 2 does not only tell us that this clique exists but that it must also be inside the search space of at least n/3 vertices. For the remaining 2n/3 vertices we use a very pessimistic lower bound: We assume that their search space is empty. The resulting lower bound for the average number of vertices is 2/3 · Ω(0) + 1/3 · Ω(nα) = Ω(nα) and the lower bound for the average number of arcs is 2/3 · Ω(0) + 1/3 · Ω(n2α) = Ω(n2α).\nWe required that G ∈ Kα, i. e., that recursive O(nα) balanced separators exists. This allows us to apply Lemma 1. We therefore know that the number of vertices in the maximum search space of G∧πnd is in O(nα). In the worst-case this search space contains O(n2α) arcs. As the average case can never be better than the worst case, these upper bounds directly translate to upper bounds for the average search space.\nAs the given upper and lower bounds match, we can conclude that πnd is a O(1)-approximation in terms of average and maximum search space in terms of vertices and arcs."
    }, {
      "heading" : "5 Constructing the Contraction Hierarchy",
      "text" : "In this section, we describe how to efficiently compute the hierarchy G∧π for a given graph G and order π. Weighted contraction hierarchies are commonly constructed using a dynamic adjacency array representation of the core graph. Our experiments show that this approach also works for the unweighted case, however, requiring more computational and memory resources because of the higher growth in shortcuts. It has been proposed [42] to use hash-tables on top of the dynamic graph structure to improve speed but at the cost of significantly increased memory consumption. In this section, we show that the contraction hierarchy construction can be done significantly faster on unweighted and undirected graphs. Note that in our toolchain, graph weights and arc directions are accounted for during the customization phase.\nDenote by n the number of vertices in G (and G∧π ), by m the number of edges in G, by m̂ the number of arcs in G∧π , and by α(n) the inverse A(n, n) Ackermann function. For simplicity we assume that G is connected. Our approach enumerates all arcs of G∧π in O(m̂ α(n)) running time and has a memory consumption in O(m). To store the arcs of G∧π , additional space in O(m̂) is needed. The approach is heavily based upon the method of the quotient graph [23]. To the best of our knowledge it has not yet been applied in the context of route planning and there exists no complexity analysis for the specific variant employed by us. Therefore we discuss both the approach and present a running time analysis in the remainder of the section.\nRecall that to compute the contraction hierarchy G∧π from a given input graph G and order π, one iteratively contracts each vertex, adding shortcuts between its neighbors. Let G′ = Gπ,i be the core graph in iteration i. We do not store G′ explicitly but employ a special data structure called contraction graph for efficient contraction and neighborhood enumeration. The contraction graph H contains both yet uncontracted core vertices as well as an independent set of virtually contracted super vertices, see Figure 3 for an illustration. These super vertices enable us to avoid the overhead of dynamically adding shortcuts to G′. For each vertex in H we store a marker bit indicating whether it is a super vertex. Note that G′ can be obtained by contracting all super vertices in H."
    }, {
      "heading" : "5.1 Contracting Vertices",
      "text" : "A vertex x in G′ is contracted by turning it into a super vertex. However, creating new super vertices can violate the independent set property. We restore it by merging neighboring super vertices: Denote by y a super vertex that is a neighbor of x. We rewire all edges incident to y to be incident to x and remove y from H. To support efficiently merging vertices in H, we store a linked list of neighbors for each vertex. When merging two vertices we link these lists together. Unfortunately, combining these lists is not enough as the former neighbors z of y still have y in their list of neighbors. We therefore further maintain a union-find data structure: Initially all vertices are within their own set. When merging x and y, the sets of x and y are united. We chose x as representative as y was deleted.1 When z enumerates\n1Or alternatively, we can let the union-find data structure choose the new representative. We then denote by x the new representative and by y the other vertex. In this variant, it is possible that the new x is the old y, which can be confusing.\nits neighbors, it finds a reference to y. It can then use the union-find data structure to determine that the representative of y’s set is x. The reference in z’s list is thus interpreted as pointing to x.\nIt is possible that merging vertices can create multi-edges and loops. For example, consider that the neighborhood list of y contains x. After merging, the united list of x will therefore contain a reference to x. Similarly it will contain a reference to y, which after looking up the representative is actually x. Two loops are thus created at x per merge. Furthermore, consider a vertex z that is a neighbor of both y and x. In this case the neighborhood list of x will contain two references to z. These multi-edges and loops need to be removed. We do this lazily and remove them in the neighborhood enumeration instead of removing them in the merge operation."
    }, {
      "heading" : "5.2 Enumerating Neighbors",
      "text" : "Suppose that we want to enumerate the neighbors of a vertex x in H. Note that x’s neighborhood in H differs from its neighborhood in G′. The neighborhood of x in H can contain super vertices, as super vertices are only contracted in G′. We maintain a boolean marker that indicates which neighbors have already been enumerated. Initially no marker is set. We iterate over x’s neighborhood list. For each reference we lookup the representative v. If v was already marked or is x, we remove the reference from the list. If v was not marked and is not x, we mark it and report it as a neighbor. After the enumeration we reset all markers by enumerating the neighbors again.\nHowever, during the execution of our algorithm, we are not interested in the neighborhood of x in H, but we want the neighborhood of x in G′, i. e., the algorithm should not list super vertices. Our algorithm conceptually first enumerates the neighborhood of x and then contracts x. We actually do this in reversed order. We first contract x. After the contraction x is a super vertex. Because of the independent set property, we know that x has no super vertex neighbors in H. We can thus enumerate x’s neighbors in H and exploit that in this particular situation the neighborhoods of x in G′ and H coincide."
    }, {
      "heading" : "5.3 Performance Analysis",
      "text" : "As there are no memory allocations, it is clear that the working space memory consumption is in O(m). Proving a running time in O(m̂α(n)) is less clear. Denote by d(x) the degree of x just before x is contracted. d(x) coincides with the upward degree of x in G∧π and thus ∑ d(x) = m̂. We first prove that we can account for the neighborhood cleanup operations outside of the actual algorithm. This allows us to assume that they are free within the main analysis. We then show that contracting a vertex x and enumerating its neighbors is in O(d(x)α(n)). Processing all vertices has thus a running time in O(m̂α(n)).\nThe neighborhood list of x can contain duplicated references and thus its length can be larger than the number of neighbors of x. Further, for each entry in the list, we need to perform a union find lookup. The costs of a neighborhood enumeration can thus be larger than O(d(x)α(n)). Fortunately, the first neighborhood enumeration compactifies the neighborhood list and thus every subsequent enumeration runs in O(d(x)α(n)). Removing a reference has a cost in O(α(n)). Our algorithm never adds references. Initially there are Θ(m) references. The total costs for removing references over the whole algorithm are thus in O(mα(n)). As our graph is assumed to be connected, we have that m ∈ O(m′) and therefore O(mα(n)) ⊆ O(m̂α(n)). We can therefore assume that removing references is free within the algorithm. As removing a reference is free, we can assume that even the first enumeration of the neighbors of x is within O(d(x)α(n)). Merging two vertices consists of redirecting a constant number of references within a linked list. The merge operation is thus in O(1).\nOur algorithm starts by enumerating all neighbors of x to determine all neighboring super vertices in O(d(x)α(n)) time. There are at most d(x) neighboring super vertices and therefore the costs of merging all super vertices into x is in O(d(x)). We subsequently enumerate all neighbors a second time to output the arcs of G∧π . The costs of this second enumeration is also within O(d(x)α(n)). The whole algorithm thus runs in O(m̂α(n)) time as ∑ d(x) = m̂, which completes the proof.\nFor this reason, we describe the simpler variant, where x is always chosen as representative and thus x always refers to the same vertex."
    }, {
      "heading" : "5.4 Adjacency Array",
      "text" : "While the described algorithm is efficient in theory, linked lists cause too many cache misses in practice. We therefore implemented a hybrid of a linked list and an adjacency array, which has the same worst case performance, but is more cache-friendly in practice. An element in the linked list does not only hold a single reference, but a small set of references organized as small arrays called blocks. The neighbors of every original vertex form a single block. The initial linked neighborhood list are therefore composed of a single block. We merge two vertices by linking their blocks together. If all references are deleted from a block, we remove it from the list.\n6 Enumerating Triangles\nA triangle {x, y, z} is a set of 3 adjacent vertices. A triangle can be an upper, intermediate or lower triangle with respect to an arc (x, y), as illustrated in Figure 4. A triangle {x, y, z} is a lower triangle of (y, z) if x has the lowest rank among the three vertices. Similarly {x, y, z} is a upper triangle of (x, y) if z has the highest rank and {x, y, z} is a intermediate triangle of (x, z) if y’s rank is between the ranks of x and z. The triangles of an edge (a, b) can be characterized using the upward Nu and downward Nd neighborhoods of a and b. There is a lower triangle {a, b, c} of an arc (a, b) if and only if c ∈ Nd(a)∩Nd(b). Similarly, there is an intermediate triangle {a, b, c} of an arc (a, b) with π−1(a) < π−1(b) if and only if c ∈ Nu(a)∩Nd(b) and an upper triangle {a, b, c} of an arc (a, b) if and only if c ∈ Nu(a) ∩Nu(b). The triangles of an arc can thus be enumerated by intersecting the neighborhoods of the arc’s endpoints.\nEfficiently enumerating all lower triangles of an arc is an important base operation of the customization (Section 7) and path unpacking algorithms (Section 8). It can be implemented using adjacency arrays or accelerated using extra preprocessing. Note that in addition to the vertices of a triangle we are interested in the IDs of the participating arcs as we need these to access the metric of an arc.\nBasic Triangle Enumeration Triangles can be efficiently enumerated by exploiting their characterization using neighborhood intersections. We construct an upward and a downward adjacency array for G∧π , where incident arcs are ordered by their head respectively tail vertex ID. The lower triangles of an arc (x, y) can be enumerated by simultaneously scanning the downward neighborhoods of x and y to determine their intersection. Intermediate and upper triangles are enumerated analogously using the upward adjacency arrays. For later access to the metric of an arc, we also store each arc’s ID in the adjacency arrays. This approach requires space proportional to the number of arcs in G∧π .\nTriangle Preprocessing Instead of merging the neighborhoods on demand to find all lower triangles, we propose to create a triangle adjacency array structure that maps the arc ID of (x, y) to the pair of arc ids of (z, x) and (z, y) for every lower triangle {x, y, z} of (x, y). This requires space proportional to the number of triangles t in G∧π , but allows for a very fast access. Analogous structures allow us to efficiently enumerate all upper triangles and all intermediate triangles.\nHybrid Approach For less well-behaved graphs the number of triangles t can significantly outgrow the number of arcs in G∧π . In the worst case G is the complete graph and the number of triangles t is in Θ(n3) whereas the number of arcs is in Θ(n2). It can therefore be prohibitive to store a list of all triangles. We therefore propose a hybrid approach. We only precompute the triangles for the arcs (u, v) where the level of u is below a certain threshold. The threshold is a tuning parameter that trades space for time.\nComparison with CRP Triangle preprocessing has similarities with micro and macro code in CRP [16]. In the following, we compare the space consumption of these two approaches against our lower triangles preprocessing scheme. However, note that at this stage we do not yet consider travel direction on arcs. Hence, let t be the number of undirected triangles and m be the number of arcs in G∧π ; further let t\n′ be the number of directed triangles and m′ be the number of arcs used in [16]. If every street is a one-way street, then m′ = m and t′ = t; otherwise, without one-way streets, m′ = 2m and t′ = 2t.\nMicro code stores an array of triples of pointers to the arc weights of the three arcs in a directed triangle, i. e., it stores the equivalent of 3t′ arc IDs. Computing the exact space consumption of macro code is more difficult. However, it is easy to obtain a lower bound: Macro code must store for every triangle at least the pointer to the arc weight of the upper arc. This yields a space consumption equivalent to at least t′ arc IDs. In comparison, our approach stores for each triangle the arc IDs of the two lower arcs. Additionally, the index array of the triangle adjacency array, which maps each arc to the set of its lower triangles, maintains m + 1 entries. Each entry has a size equivalent to an arc ID. Our total memory consumption is thus 2t+m+ 1 arc IDs.\nHence, our approach always requires less space than micro code. It has similar space consumption as macro code if one-way streets are rare, otherwise it needs at most twice as much data. However, the main advantage of our approach over macro code is that it allows for random access, which is crucial in the algorithms presented in the following sections."
    }, {
      "heading" : "7 Customization",
      "text" : "Up to now we only considered the metric-independent first preprocessing phase. In this section, we describe the second metric-dependent preprocessing phase, known as customization. That is, we show how to efficiently extend the weights of the input graph to a corresponding metric with weights for all arcs in G∧π . We consider three different distances between the vertices: We refer to distI(s, t) as the shortest st-path distance in the input graph G. With distUD(s, t) we denote the shortest st-path distance in G ∧ π when only considering up-down paths. Finally, let distA(s, t) be the shortest st-path distance in G ∗ π, i. e., when allowing arbitrary not-necessarily up-down paths in G∧π . For correctness of the CH query algorithms (cf. Section 8) it is necessary that between any pair of vertices s and t a shortest up-down st-path in G∧π exists with the same distance as the shortest st-path in the input graph G. In other words, distI(s, t) = distA(s, t) = distUD(s, t) must hold for all vertices s and t. We say that a metric that fulfills distI(s, t) = distA(s, t) respects the input weights. If additionally distA(s, t) = distUD(s, t) holds, we call the metric customized. Note that customized metrics are not necessarily unique. However, there is a special customized metric, called perfect metric mP , where for every arc (x, y) in G∧π the weight of this arc mP (x, y) is equal to the shortest path distance distI(x, y). We optionally use the perfect metric to perform perfect witness search.\nConstructing a respecting metric is trivial: Assign to all arcs of G∧π that already exist in G their input weight and to all other arcs +∞. Computing a customized metric is less trivial. We therefore describe in Section 7.1 the basic customization algorithm that computes a customized metric mC given a respecting one. Afterwards, we describe the perfect customization algorithm that computes the perfect metric mP given a customized one (such as for example mC). Finally, we show how to employ the perfect metric to perform a perfect witness search."
    }, {
      "heading" : "7.1 Basic Customization",
      "text" : "A central notion of the basic customization algorithm is the lower triangle inequality, which is defined as following: A metric mC fulfills it if for all lower triangles {x, y, z} of each arc (x, y) of G∧π , it holds that mC(x, y) ≤ mC(x, z) +mC(z, y). We show that every respecting metric that also fulfills this inequality is customized. Our algorithm exploits this by transforming the given respecting metric in a coordinated way that maintains the respecting property and assures that the lower triangle inequality holds. The resulting metric is thus customized. We first describe the algorithm and prove that the resulting metric is respecting and fulfills the inequality. We then prove that this is sufficient for the resulting metric to be customized.\nOur algorithm iterates over all arcs (x, y) ∈ G∧π ordered increasingly by the rank of x in a bottom-up fashion. For each arc (x, y), it enumerates all lower triangles {x, y, z} and checks whether the path x → z → y is shorter than the path x → y. If this is the case, then it decreases mC(x, y) so that both paths are equally long. Formally, it performs for every arc (x, y) the operation mC(x, y) ← min{mC(x, y),mC(x, z) + mC(z, y)}. Note, that this operation never assigns values that do not correspond to a path length and therefore mC remains respecting. By induction over the vertex levels, we can show that after the algorithm is finished, the lower triangle inequality holds for every arc, i. e., for every arc (x, y) and lower triangle {x, y, z} the inequality mC(x, y) ≤ mC(x, z)+mC(z, y) holds. The key observation is that by construction the rank of z must be strictly smaller than the ranks of x and y. The final weights of mC(x, z) and mC(z, y) have therefore already been computed when considering (x, y).\nIn other words, when the algorithm considers the arc (x, y), the weights mC(x, z) and mC(z, y) are guaranteed to remain unchanged until termination.\nTheorem 2. Every respecting metric that additionally fulfills the lower triangle inequality is customized.\nProof. We need to show that between any pair of vertices s and t a shortest up-down st-path exists. As we assumed for simplicity that G is connected, there always exists a shortest not-necessarily up-down path from s to t. Either this is an up-down path, or a subpath x → z → y with π−1(x) > π−1(z) and π−1(y) > π−1(z) must exist. As z is contracted before x and y, an edge {x, y} must exist. Because of the lower triangle inequality, we further know that m(x, y) ≤ m(x, z) + m(z, y) and thus replacing x→ z → y by x→ y does not make the path longer. Either the path is now an up-down path or we can apply the argument iteratively. As the path has only a finite number of vertices, this is guaranteed to eventually yield the up-down path required by the theorem and thus this completes the proof.\n7.2 Perfect Customization\nGiven a customized metric mC , we want to compute the perfect metric mP . We first copy all values of mC into mP . Our algorithm then iterates over all arcs (x, y) decreasing by the rank of x in a top-down fashion. For every arc it enumerates all intermediate and upper triangles {x, y, z} and checks whether the path over z is shorter and adjusts the value of mP (x, y) accordingly, i. e., it performs mP (x, y) ← min{mP (x, y),mP (x, z) +mP (z, y)}. After all arcs have been processed mP is the perfect metric, as is shown in the following theorem.\nTheorem 3. After the perfect customization, mP (x, y) corresponds to the shortest xy-path distance for every arc (x, y), i. e., mP is the perfect metric.\nProof. We have to show that after the algorithm has finished processing a vertex x, all of its outgoing arcs in G∧π are weighted by the shortest path distance. We prove this by induction over the level of the processed vertices. The top-most vertex is the only vertex in the top level. It does not have any upward arcs and thus the algorithm does not have anything to do. This forms the base case of the induction. In the inductive step, we assume that all vertices with a strictly higher level have already been processed. As consequence, we know that the upward neighbors of x form a clique weighted by shortest path distances. Denote these neighbors by yi. The situation is depicted in Figure 5. The weights of the yi encode a complete shortest path distance table between the upward neighbors of x.\nPick some arbitrary arc (x, yj). We show the correctness of our algorithm by proving that either mC(x, yj) is already the shortest path distance or a neighbor yk ∈ Nu(x) must exist such that x → yk → yj is a shortest up-down path. For the rest of this paragraph assume the existence of yk, we prove its existence in the next paragraph. If mC(x, yj) is already the shortest xyj-path distance, then enumerating triangles will not change mC(x, yj) and is thus correct. If mC(x, yj) is not the shortest xyj-path distance, then enumerating all intermediate and upper triangles of (x, yj) is guaranteed to find the x → yk → yj path and thus the algorithm is correct. The upper triangles correspond to paths with `(yk) > `(yj) while the intermediate triangles to paths with `(yk) < `(yj).\nIt remains to show that the x → yk → yj shortest up-down path actually exists. As the metric is customized at every moment during the perfect customization, we know that a shortest up-down xyj-path K exists. As K is an up-down path, we can conclude that the second vertex of K must be an upward neighbor of x. We denote this neighbor by yk . K thus has the following structure: x→ yk → . . .→ yj . As yk has a higher rank than x, mP (yk, yj) is guaranteed to be the shortest ykyj-path distance, and therefore we can replace the yk → . . . → yj subpath of K by yk → yj and we have proven that the required x→ yk → yj shortest up-down path exists, which completes the proof."
    }, {
      "heading" : "7.3 Perfect Witness Search",
      "text" : "Using the perfect customization algorithm, we can efficiently compute the weighted CH with a minimum number of arcs with respect to the same contraction order. We present two variants of our algorithm. The first variant consists of removing all arcs (x, y) whose weight after the basic customization mC(x, y) does not correspond to the shortest xy-path distance mP (x, y). This variant is simple and always correct, but it does not remove as many arcs as possible, if a pair of vertices a and b exists in the input graph such that there are multiple shortest ab-paths. The second variant2 also removes these additional arcs. An arc (x, y) is removed if and only if an upper or intermediate triangle {x, y, z} exists such that the shortest path from x over z to y is no longer than the shortest xy-path. However, before we can proof the correctness of the second variant, we need to introduce some technical machinery, which will also be needed in the correctness proof of the stalling query algorithm. We define the “height” of a notnecessarily up-down path in G∗π. We show that with respect to every customized metric, for every path that is not up-down, an up-down path must exist that is strictly higher and is no longer."
    }, {
      "heading" : "7.3.1 Variant for Graphs with Unique Shortest Paths",
      "text" : "The first algorithm variant consists of removing all arcs (x, y) from the CH for whichmP (x, y) 6= mC(x, y). It is optimal if shortest path are unique in the input graph, i. e., between every pair of vertices a and b there is only one shortest ab-path. This simple algorithm is correct as the following theorem shows.\nTheorem 4. If the input graph has unique shortest paths between all pairs of vertices, then we can remove an arc (x, y) from the CH if and only if mP (x, y) 6= mC(x, y).\nProof. We need to show that after removing all arcs, there still exists a shortest up-down path between every pair of vertices s and t. We know that before removing any arc a shortest up-down st-path K exists. We show that no arc of K is removed and thus K also exists after removing all arcs. Every subpath of K must be a shortest path as K is a shortest path. Every arc of K is a subpath. However, we only remove arcs such that mP (x, y) 6= mC(x, y), i. e., which are not shortest paths.\nTo show that no further arcs can be removed we need to show that if mP (x, y) = mC(x, y), then the path x → y is the only shortest up-down path. Denote the x → y path by Q. Suppose that another shortest up-down path R existed. R must be different than Q, i. e., a vertex z must exist that lies on R but not on Q. As z must be reachable from x, we know that z is higher than x. Unpacking the path Q in the input graph yields a path where x and y are the highest ranked vertices and thus this unpacked path cannot contain z. Unpacking R yields a path that contains z and is therefore different. Both paths are shortest paths from x to y in the input graph. This contradicts the assumption that shortest paths are unique. We have thus proven that, if the input graph has unique shortest paths, we can remove an arc (x, y) if and only if mP (x, y) 6= mC(x, y).\n7.3.2 Variant for General Graphs rank\nUsing the first variant of our algorithm, even when shortest paths are not unique in the original graph is not wrong. However, it is possible that some arcs are not removed that could be removed. Our second algorithm variant does not have this weakness. It removes all arcs (x, y) for which an intermediate or upper triangle {x, y, z} exists such that mP (x, y) = mP (x, z) + mP (z, y). These arcs can efficiently be identified while running the perfect customization algorithm. An arc (x, y) is marked for removal if an upper or intermediate triangle {x, y, z} with mC(x, y) ≥ mC(x, z) +mC(z, y) is encountered. However, before we can proof the correctness of the second variant, we need to introduce some technical machinery.\nWe want to order paths by “height”. To achieve this, we first define for each path K in G∗π its rank\n2Note that the second algorithm variant exploits that we defined weights as being non-zero. If zero weights are allowed, it may remove too many arcs. A workaround consists of replacing all zero weights with a very small but non-zero weight.\nsequence. We order paths by comparing the rank sequences lexicographically. Denote by vi the vertices in K. For each edge {vi, vi+1} in K the rank sequence contains min{r(vi), r(vi+1)}. The numbers in the rank sequences are order decreasingly. Two paths have the same height if one rank sequence is a prefix of the other. Otherwise we compare the rank sequences lexicographically. This ordering is illustrated in Figure 6. We proof the following technical lemma:\nLemma 3. Let mC be some customized metric. For every st-path K that is no up-down path, an up-down st-path Q exists, such that Q is strictly higher K and Q is no longer than K with respect to mC .\nProof. Denote by vi the vertices on the path K. As K is no up-down path, there must exist a vertex vi on K that has lower ranks than its neighbors vi−1 and vi+1. vi−1 and vi+1 are different vertices because they are part of a shortest path and zero weights are not allowed. Further, as vi is contracted before its neighbors, there must be a edge between vi−1 and vi+1. As the metric is customized, mC(vi−1, vi+1) ≤ mC(vi−1, vi)+mC(vi, vi+1) must hold. We can thus remove vi from K and replace it with the (vi−1, vi+1) are without making the path longer. Denote this new path by R. R is higher than K as we replaced r(vi) in the rank sequence by min{r(vi−1), r(vi+1)}, which must be larger. Either, R is an up-down path or we apply the argument iteratively. In each iteration the path looses a vertex and therefore we can guarantee that eventually we obtain an up-down path that is higher than K and no longer. This is the desired up-down path Q that is no longer than K and strictly higher.\nNote that, this lemma does not exploit any property that is inherent to CHs with a metric-independent contraction ordering and is thus applicable to every CH.\nGiven this technical lemma, we can prove the correctness of the second variant of our algorithm.\nTheorem 5. We can remove an arc (x, y) if and only if an upper or intermediate triangle {x, y, z} exists with mP (x, y) = mP (x, z) +mP (z, y).\nProof. We need to show that for every pair of vertices s and t a shortest up-down st-path exists, that uses no removed arc. We show that a highest shortest up-down st-path has this property. As the metric is customized, we know that a shortest up-down st-path K exists before removing any arcs. If K does not contain an arc (x, y) for which an upper or intermediate triangle {x, y, z} exists with mP (x, y) = mP (x, z) +mP (z, y), then there is nothing to show. Otherwise, we modify K by inserting z between x and y. This does not modify the length of K, but we can no longer guarantee that K is an up-down path. If {x, y, z} was an intermediate triangle, then K is still an up-down path. However, it is strictly higher, as we added r(z) into the rank sequence, which is guaranteed to be larger than r(x). If {x, y, z} was an upper triangle, then K is still no up-down path anymore. Fortunately, using Lemma 3 we can transform K into an up-down path, that is no longer and strictly higher. In both case, the new K is an up-down path or we apply the argument iteratively. As K gets strictly higher in each iteration and the number of up-down paths is finite, we know that we will eventually obtain a shortest up-down st-path where no arc can be removed.\nFurther, we need to show that if no such triangle exists, then an arc cannot be removed, i. e., we need to show that the only shortest up-down path from x to y is the path consisting only of the (x, y) arc. Assume that no such triangle and a further up-down path Q existed. Q must contain a vertex beside x and y and all vertices in Q must have the rank of x or higher. Consider the vertex z that comes directly after x in Q. As x is contracted before z and y, an arc between z and y must exist. Therefore, a triangle {x, y, z} must exist that is an intermediate triangle, if z has a lower rank than y and is an upper triangle, if z has a higher rank than y. However, we assumed that no such triangle can exist. We have thus proven that we can remove an arc (x, y) if and only if an upper or intermediate triangle {x, y, z} exists with mP (x, y) = mP (x, z) +mP (z, y)."
    }, {
      "heading" : "7.4 Parallelization",
      "text" : "The basic customization can be parallelized by processing the arcs (x, y) that depart within a level in parallel. Between levels, we need to synchronize all threads using a barrier. As all threads only write to the arc they are currently assigned to and only read from arcs processed in a strictly lower level, we can thus guarantee that no read/write conflict occurs. Hence, no locks or atomic operations are needed.\nOn most modern processors, the perfect customization can be parallelized analogously to the basic customization algorithm. However, seeing why this is correct is non-obvious because the exact order in which the threads are executed influences intermediate results. Fortunately, the end result is always the same and independent of the execution order. Our algorithm works as following: We iterate over\nall arcs departing within a level in parallel and synchronize all threads between levels. For every arc (x, y) we enumerate all upper and intermediate triangles and update mP (x, y) accordingly. Consider the situation from Figure 5. Suppose that thread A processes the arc (x, yA) at the same time as thread B processes the arc (x, yB). Further, suppose that thread A updates mP (x, yA) at the same moment as thread B enumerates the {x, yB , yA} triangle. In this situation it is unclear what value thread B will see. However, our algorithm is correct as long it is guaranteed that thread B will either see the old value or the new value.\nIn the proof of Theorem 3, we have shown, that for every vertex x and arc (x, yi) either the arc (x, yi) already has the shortest path distance or an upper or intermediate triangle {x, yi, yj} exists, such that x → yj → yi is a shortest path. No matter in which order the threads process the arcs, they do not modify shortest path weights. This implies that the shortest path x → yj → yi is thus retained, regardless of the execution order. This shortest path is not modified and is guaranteed to exist before any arcs outgoing from the current level are processed. Every thread is thus guaranteed to see it. However, other weights can be modified. Fortunately, this is not a problem as long as we can guarantee that no thread sees a value that is below the corresponding shortest path distance. Therefore, if we can guarantee that thread B either sees the old value or the new value, as is the case on x86 processors, then the algorithm is correct. If thread B can see some mangled combination of the old value’s bits and new value’s bits, then we need to use locks or make sure that all outgoing arcs of x are processed by the same thread."
    }, {
      "heading" : "7.5 Directed Graphs",
      "text" : "Up to now we have focused on customizing undirected graphs. If the input graph G is directed, our toolchain works as follows: Based on the undirected unweighted graph induced by G we compute a vertex ordering π (Section 4), build the upward directed Contraction Hierarchy G∧π (Section 5), and optionally perform triangle preprocessing (Section 6). For customization, however, we consider two weights per arc in G∧π , one for each direction of travel. One-way streets are modeled by setting the weight corresponding to the forbidden traversal direction to ∞. With respect to π we define an upward metric mu and a downward metric md on G ∧ π . For each arc (x, y) ∈ G in the directed input graph with input weight w(x, y), we set mu(x, y) = w(x, y) if π −1(x) < π−1(y), i. e., if x is ordered before y; otherwise, we set md(x, y) = w(x, y). All other values of mu and md are set to ∞. In other words, each arc (x, y) ∈ G∧π of the Contraction Hierarchy has upward weight mu(x, y) = w(x, y) if (x, y) ∈ G, downward weight md(x, y) = w(y, x) if (y, x) ∈ G, and ∞ otherwise.\nThe basic customization considers both metrics mu and md simultaneously. For every lower triangle {x, y, z} of (x, y) it sets mu(x, y) ← min{mu(x, y),md(x, z) + mu(z, y)} and md(x, y) ← min{md(x, y), mu(x, z)+md(z, y)}. The perfect customization can be adapted analogously. For every intermediate triangle {x, y, z} of (x, y) the perfect customization sets mu(x, y)← min{mu(x, y),mu(x, z)+mu(z, y)} and md(x, y)← min{md(x, y),md(x, z) +md(z, y)}. Similarly for every upper triangle {x, y, z} of (x, y) the perfect customization sets mu(x, y)← min{mu(x, y),mu(x, z)+md(z, y)} and md(x, y)← min{md(x, y), md(x, z) + mu(z, y)}. The perfect witness search might need to remove an arc only in one direction. It therefore produces, just as in the original CHs, two search graphs: an upward search graph and a downward search graph. The forward search in the query phase is limited to the upward search graph and the backward search to the downward search graph, just as in the original CHs. The arc (x, y) is removed from the upward search graph if and only if an intermediate triangle {x, y, z} with mu(x, y) = mu(x, z) +mu(z, y) exists or an upper triangle {x, y, z} with mu(x, y) = mu(x, z) +md(z, y) exists. Analogously, the arc (x, y) is removed from the downward search graph if and only if an intermediate triangle {x, y, z} with md(x, y) = md(x, z) + md(z, y) exists or an upper triangle {x, y, z} with md(x, y) = md(x, z) +mu(z, y) exists."
    }, {
      "heading" : "7.6 Single Instruction Multiple Data",
      "text" : "The weights attached to each arc in the CH can be replaced by an interleaved set of k weights by storing for every arc a vector of k elements. Vectors allows us to customize all k metrics in one go, amortizing triangle enumeration time and they allow us to use single instruction multiple data (SIMD) operations. Further, as we use essentially two metrics to handle directed graphs, we can store both of them in a 2- dimensional vector. This allows us to handle both directions in a single processor instruction. Similarly, if we have k directed input weights we can store them in a 2k-dimensional vectors.\nThe processor needs to support component-wise minimum and saturated addition, i. e., a+b = intmax\nmust hold in the case of an overflow. In the case of directed graphs it additionally needs to support efficiently swapping neighboring vector components. A current SSE-enabled processor supports all the necessary operations for 16-bit integer components. For 32-bit integer saturated addition is missing. There are two possibilities to work around this limitation: The first is to emulate saturated-add using a combination of regular addition, comparison and blend/if-then-else instruction. The second consists of using 31-bit weights and use 231− 1 as value for ∞ instead of 232− 1. The algorithm only computes the saturated addition of two weights followed by taking the minimum of the result and some other weight, i. e., if computing min(a + b, c) for all weights a, b and c is unproblematic, then the algorithms works correctly. We know that a and b are at most 231− 1 and thus their sum is at most 232− 2 which fits into a 32-bit integer. In the next step we know that c is at most 231 − 1 and thus the resulting minimum is also at most 231 − 1."
    }, {
      "heading" : "7.7 Partial Updates",
      "text" : "Until now we have only considered computing metrics from scratch. However, in many scenarios this is overkill, as we know that only a few edge weights of the input graph were changed. It is unnecessary to redo all computations in this case. The ideas employed by our algorithm are somewhat similar to those presented in [21], but our situation differs as we know that we do not have to insert or remove arcs. Denote by U = {((xi, yi), wnewi )} the set of arcs whose weights should be updated, where (xi, yi) is the arc ID and wnewi the new weight. Note that modifying the weight of one arc can trigger further changes. However, these new changes have to be at higher levels. We therefore organize U as a priority queue ordered by the level of xi. We iteratively remove arcs from the queue and apply the change. If new changes are triggered we insert these into the queue. The algorithm terminates once the queue is empty.\nDenote by (x, y) the arc that was removed from the queue and by wnew its new weight and by wold its old weight. We first have to check whether wnew can be bypassed using a lower triangle. For this reason, we iterate over all lower triangles {x, y, z} of (x, y) and perform wnew ← min{wnew,m(z, x) + m(z, y)}. Furthermore, if {x, y} is an edge in the input graph G, we might have overwritten its weight with a shortcut weight, which after the update might not be shorter anymore. Hence, we additionally test that wnew is not larger than the input weight. If after both checks wnew = m(x, y) holds, then no change is necessary and no further changes are triggered. If wold and wnew differ we iterate over all upper triangles {x, y, z} of (x, y) and test whether m(x, z) + wold = m(y, z) holds and if so the weight of the arc (y, z) must be set to m(x, z) +wnew. We add this change to the queue. Analogously we iterate over all intermediate triangles {x, y, z} of (x, y) and queue up a change to (z, y) if m(x, z) + wold = m(z, y) holds.\nHow many subsequent changes a single change triggers heavily depends on the metric and can significantly vary. Slightly changing the weight of a dirt road has near to no impact whereas changing a heavily used highway segment will trigger many changes. In the game setting such largely varying running times are undesirable as they lead to lag-peaks. We propose to maintain a queue into which all changes are inserted. Every round a fixed amount of time is spent processing elements from this queue. If time runs out before the queue is emptied the remaining arcs are processed in the next round. This way costs are amortized resulting in a constant workload per turn. The downside is that as long the queue is not empty some distance queries will use outdated data. How much time is spent each turn updating the metric determines how long an update needs to be propagated along the whole graph."
    }, {
      "heading" : "8 Distance Query",
      "text" : "In this section, we describe how to compute distance queries3, i. e., a shortest up-down path in G∧π between two vertices s and t given a customized metric and how to unpack into a shortest path edge sequence in G."
    }, {
      "heading" : "8.1 Basic",
      "text" : "The basic query runs two instances of Dijkstra’s algorithm on G∧π from s and from t. If G is undirected, then both searches use the same metric. Otherwise if G is directed the search from s uses the upward metric mu and the search from t the downward metric md. In either case in contrast to [21] they operate\n3We refer to the minimum sum over all weights over all st-paths as the distance between s and t. The term “distance query” does not imply that we only consider shortest paths according to geographical distance.\non the same upward search graph G∧π . Once the radius of one of the two searches is larger than the shortest path found so far, we stop the search because we know that no shorter path can exist. We alternate between processing vertices in the forward search and processing vertices in the backward search."
    }, {
      "heading" : "8.2 Stalling",
      "text" : "We implemented a basic version of an optimization presented in [21, 33] called stall-on-demand. The optimization exploits that the shortest strictly upward sv-path in G∧π can be longer than the shortest sv-path in G∗π, which can go up and down arbitrarily. The search from s only finds upward paths and if we observe that an up-down path exists that is not longer, then we can prune the upward search. Denote by x the vertex removed from the queue. We iterate over all outgoing arcs (x, y) and test whether d(x) ≥ m(x, y) + d(y) holds. If it holds for some arc we prune x by not relaxing its outgoing arcs.\nIf d(x) > m(x, y) + d(y) holds, then pruning is correct because all subpaths of shortest up-down paths must be shortest paths and the upward path ending at x is not shortest path as a shorter up-down path through y exists. We can also prune when d(x) ≥ m(x, y) + d(y), but a different argument is needed. To the best of our knowledge, correctness has so far not been proven for the d(x) = m(x, y) + d(y) case. Notice that we do not exploit any special properties of metric independent\norders and thus our prove works for every CH.\nTheorem 6. The upward search can be pruned when d(x) ≥ m(x, y) + d(y) holds.\nProof. We show that for every pair of vertices s and t an unprunable, shortest, up-down st-path exists. Our proof relies on Lemma 3 which orders paths by height and states that st-path that are no up-down paths can be transformed into up-down paths that are no longer and strictly higher. We know that some shortest st-path K exists. If K is not pruned, then there is nothing to show. If K is pruned, then there exists a vertex x on K at which the search is pruned. Without loose of generality we assume that x lies on the upward part of K. Further there must exist a vertex y and a path Q from s to x going through y such that Q is no longer than the sx-prefix of K. Consider the path R obtained by concatenating Q with the xt-suffix of K. R is by construction not longer than K. If x is the highest vertex on K then R is an up-down path and R is strictly higher. Otherwise, R is no up-down path, but using Lemma 3 R can be transformed into an up-down path that is strictly higher and no longer. In both cases, R is no longer and strictly higher. Either, R is unprunable or we apply the argument iteratively. As there are only finitely many up-down paths and each iteration increases the height of R, we eventually end up at an unprunable, shortest, up-down st-path, which concludes the proof."
    }, {
      "heading" : "8.3 Elimination Tree",
      "text" : "We precompute for every vertex its parent’s vertex ID in the elimination tree in a preprocessing step. This allows us to efficiently enumerate all vertices in SS(s) and SS(t) at query time. The vertices are enumerated increasing by rank.\nWe store two tentative distance arrays df (v) and db(v). Initially these are all set to ∞. In a first step we compute the lowest common ancestor (LCA) x of s and t in the elimination tree. We do this by simultaneously enumerating all ancestors of s and t by increasing rank until a common ancestor is found. In a second step we iterate over all vertices y on the tree-path from s to x and relax all forward arcs of such y. In a third step we do the same for all vertices y from t to x in the backward search. In a final fourth step we iterate over all vertices y from x to the root r and relax all forward and backward arcs. Further in the fourth step we also determine the vertex z that minimizes df (z)+db(z). A shortest up-down\npath must exist that goes through z. Knowing z is necessary to determine the shortest path distance and to compute the sequence of arcs that compose the shortest path. In a fifth cleanup step we iterate over all vertices from s and t to the root r to reset all df and db to ∞. This fifth step avoids having to spend O(n) running time to initialize all tentative distances to ∞ for each query. Consider the situation depicted in Figure 7. In the first step the algorithm determines x. In the second step it relaxes all dotted arcs and the tree arcs departing in the lightgray area. In the third step all dashed arcs and the tree arcs departing in the middlegray area and in the fourth step the solid arcs and the remaining tree arcs follow.\nThe elimination tree query can be combined with the perfect witness search. Before pruning any arc, we compute the elimination tree. We then prune the arcs. It is now possible that a vertex has an ancestor in the tree that is not in its pruned search space. However, we can still guarantee that every vertex in the pruned search space is an ancestor and this is enough to prove the query correctness. To avoid relaxing the outgoing arcs of an ancestor outside of the search space, we prune vertices whose tentative distance df (x) respectively db(x) is ∞.\nContrary to the approaches based upon Dijkstra’s algorithm the elimination tree query approach does not need a priority queue. This leads to significantly less work per processed vertex. Unfortunately the query must always process all vertices in the search space. Luckily, our experiments show that for random queries with s and t sampled uniformly at random the query time ends up being lower for the elimination tree query. If s and t are close in the original graph, i. e., not sampled uniformly at random, then the Dijkstra-based approaches win."
    }, {
      "heading" : "8.4 Path Unpacking",
      "text" : "All shortest path queries presented only compute shortest up-down paths. This is enough to determine the distance of a shortest path in the original graph. However, if the sequence of edges that form a shortest path should be computed, then the up-down path must be unpacked. The original CH of [21] unpacks an up-down path by storing for every arc (x, y) the vertex z of the lower triangle {x, y, z} that caused the weight at m(x, y). This information depends on the metric and we want to avoid storing additional metric-dependent information. We therefore resort to a different strategy: Denote by p1 . . . pk the up-down path found by the query. As long as a lower triangle {pi, pi+1, x} of an arc (pi, pi+1) exists with m(pi, pi+1) = m(x, pi) + m(x, pi+1), our algorithm inserts the vertex x between pi and pi+1 into the path."
    }, {
      "heading" : "9 Experiments",
      "text" : "In this section we present our careful and extensive experimental evaluation of the algorithms introduced and described before.\nCompiler and Machine We implemented our algorithms in C++, using g++ 4.7.1 with -O3 for compilation. The customization and query experiments were run on a dual-CPU 8-core Intel Xeon E52670 processor, which is based on the Sandy Bridge architecture, clocked at 2.6 GHz, with 64 GiB of DDR3-1600 RAM, 20 MiB of L3 and 256 KiB of L2 cache. The order computation experiments reported in Table 2 were run on a single core of an Intel Core i7-2600K CPU processor.\nInstances We evaluate three large instances of practical relevance in detail. In Section 10 we provide summarized experiments on further instances. The sizes of our main test instances are reported in Table 1: The DIMACS-Europe graph4 was provided by PTV5 for the DIMACS challenge [17]. The vertex positions are depicted in Figure 8. It is the standard benchmarking instance used by road routing papers over the past few years. Note that besides roads it also contains a few ferries to connect Great Britain and some other islands with the continent. The Europe graph analyzed here is its largest strongly connected component, which is a common method to remove bogus vertices. The numbers in Table 1 are the numbers after computing the strongly connected component. The graph is directed, and we consider two different weights. The first weight is the travel time and the second weight is the straight line distance between two vertices on a perfect Earth sphere. Note that in\nthe input data highways are often modeled using only a small number of vertices compared to the streets going through the cities. This differs from other data sources, such as OpenStreetMap6 that have a high number of vertices on highways to model road bends. As demonstrated in Section 10.1, degree-2 vertices do not hamper the performance of CHs. The Karlsruhe graph is a subgraph of the PTV graph for a larger region around Karlsruhe. We consider the largest connected component of the graph induced by all vertices with a latitude between 48.3° and 49.2°, and a longitude between 8° and 9°. The TheFrozenSea graph is based on the largest Star Craft map presented in [38]. The map is composed of square tiles having at most eight neighbors and distinguishes between walkable and non-walkable tiles. These are not distributed uniformly, but rather form differently-sized pockets of freely walkable space alternating with choke points of very limited walkable space. The corresponding graph contains for every walkable tile a vertex and for every pair of adjacent walkable tiles an edge. Diagonal edges are weighted by √ 2, while horizontal and vertical edges have weight 1. The graph is symmetric, i. e., for each forward arc there is a backward arc, and contains large grid subgraphs. For comparability with other works we report in Table 1 the time needed by Dijkstra’s algorithm. The variant of Dijkstra’s algorithm used to compute the baseline running times did not reorder the vertices in-memory, used a 4-ary heap, was unidirectional, used the stopping criterion.\n9.1 Orders\nWe analyze three different vertex orders: 1) The greedy metric-dependent order is an order in the spirit of [21]. We refer to it as “MetDep” in the tables. 2) The Metis 5.0.1 graph partitioning package contains a tool called ndmetis to create ND-orders. 3) KaHIP 0.61 provides just graph partitioning tools. We therefore implemented a very basic nested dissection based program on top of it. We aimed at computing the best order possible. Doing this fast is not the focus of this work. For every graph we iteratively compute bisections with different random seeds using the “strong” configuration until for 10 consecutive runs no better cut is found. We recursively bisect the graph until the parts are too small for KaHIP to handle and assign the order arbitrarily in these small parts. We set the imbalance for KaHIP to 20%. Note that our program is solely tuned for quality completely disregarding running time. It is certainly\npossible to trade much speed for a negligible or even no decrease in quality. We therefore report the running times as upper bounds, as no attempt was made to optimize them. Please do not cite our reported running times to claim that KaHIP is slow. This is no valid conclusion.\nTable 2 reports the times needed to compute the orders. Interestingly, Metis outperforms even the metric-dependent greedy vertex ordering strategy. Figure 9 shows the sizes of the computed separators.\n4Visit http://i11www.iti.kit.edu/resources/roadgraphs.php for details on how to acquire this graph. 5http://www.ptvgroup.com 6http://www.openstreetmap.org\nAs expected, KaHIP results in better quality. The road graphs seem to have separators following a Θ( 3 √ n)-law. On Karlsruhe the separator sizes steadily decrease from the top level to the bottom level, making Theorem 1 directly applicable under the assumption that no significantly better separators exist. The KaHIP separators on the Europe graph have a different structure on the top level. The separators first increase before they get smaller. This is because of the special structure of the European continent. For example the cut separating Great Britain and Spain from France is far smaller than one would expect for a graph of that size. In the next step KaHIP cuts Great Britain from Spain which results in one of the extremely thin cuts observed in the plot. Interestingly Metis is not able to find these cuts that exploit the continental topology. The game map has a structure that differs from road graphs as the plots have two peaks. This effect results from the large grid subgraphs. The grids have Θ( √ n) separators, whereas at the higher levels the choke points results in separators that approximately follow a Θ( 3 √ n)-law. At some point the bisector has cut all choke points and has to start cutting through the grids. The second peak is at the point where this switch happens.\n9.2 CH Construction\nTable 3 compares the performance of our specialized Contraction Graph data structure, described in Section 5, to the dynamic adjacency structure, as used in [21] to compute undirected and unweighted CHs. We do not report numbers for the hash-based approach of [42] as it is fully dominated. Our data structure dramatically improves performance. However to be fair, our approach cannot immediately be extended to directed or weighted graphs. Fortunately, this is no problem as we can introduced weights and directions during the customization phase."
    }, {
      "heading" : "9.3 CH Size",
      "text" : "In Table 4 we report the resulting CH sizes for various approaches. Computing a CH on Europe without witness search with the metric-dependent order is infeasible even using the Contraction Graph data structure. This is even true if we only want to count the number of arcs: We aborted calculations after several days. We can however say with certainty that there are at least 1.3 × 1012 arcs in the CH and the maximum upward vertex degree is at least 1.4× 106. As the original graph has only 4.2× 107 arcs, it is safe to assume that using this order it is impossible to achieve a speedup compared to Dijkstra’s algorithm on the input graph. However, on the Karlsruhe graph we can actually compute the CH without witness search and perform a perfect witness search. The numbers show that the heuristic witness search employed by [21] is nearly optimal. Furthermore, the numbers clearly show that using metric-dependent orders in a metric-independent setting, i. e., without witness search, results in unpractical CH sizes. However, they also show that a metric-dependent order exploiting the weight structure dominates NDorders. In Figure 10 we plot the number of arcs in the search space vs the number of vertices. The plots show that the KaHIP order significantly outperforms the Metis order on the road graphs whereas the situation is a lot less clear on the game map where the plots suggest nearly a tie. KaHIP only slightly outperforms Metis, when using a perfect customization. Table 5 examines the elimination tree. Note that the height of the elimination tree corresponds7 to the number of vertices in the (undirected) search space. As the ratio between the maximum and the average height is only about 2, we know that no special vertex exists that has a search space significantly differing from the numbers shown in Table 5. The elimination tree has a relatively small height compared to the number of vertices in G.\nThe treewidth of a graph is a measure widely used in theoretical computer science and thus interesting on its own. The notion of treewidth is deeply coupled with the notion of chordal super graphs and vertex separators. See [10] for details. The authors show in their Theorem 6 that the maximum upward degree du(v) over all vertices v in G ∧ π is an upper bound to the treewidth of a graph G. This theorem yields a straightforward algorithm that gives us the upper bounds presented in Table 5.\n7The numbers in Table 4 and Table 5 deviate a little because the search spaces in the former table are sampled while in the latter we compute precise values.\nInterestingly these numbers correlate with our other findings: The difference between the bounds on the road graphs reflect that the KaHIP orders are better than Metis orders. On the game map there is nearly no difference between Metis and KaHIP, which is in accordance with all other performance indicators. The fact that the treewidth grows with the graph size reflects that the running times are not independent of the graph size. These numbers strongly suggest that road graphs are not part of a graph class of constant treewidth. However, fortunately, the treewidth grows sub-linearly. Our findings from Figure 9 suggest that assuming a O( 3 √ n) treewidth for road graphs of n vertices might come close to reality. In Table 6 we evaluate the witness search performances for different metrics. It turns out that the distance metric is the most difficult one of the tested metrics. That the distance metric is more difficult than the travel time metric is well known. However it surprised us, that uniform and random metrics are easier than the distance metric. We suppose that the random metric contains a few very long arcs that are nearly never used. These could just as well be removed from the graph resulting in a thinner graph with nearly the same shortest path structure. The CH of a thinner graph with a similar shortest path structure naturally has a smaller size. To explain why the uniform metric behaves more similar to the travel time metric than to the distance metric we have to realize that highways do not have many degree 2 vertices in the input graph. Note that for different data sources this assumption might not hold. Highways are therefore also preferred by the uniform metric. We expect an instance with more degree-2 vertices on highways to behave differently. Interestingly the heuristic witness search is perfect for a uniform metric. We expect this effect to disappear on larger graphs.\nRecall that a CH is a DAG, and in DAGs each vertex can be assigned a level. If a vertex can be placed in several levels we put it in the lowest level. Figure 11 illustrates the amount of vertices and arcs in each level of a CH. The many highly ranked extremely thin levels are a result of the top level separator clique: Inside a clique every vertex must be on its own level. A few big separators therefore significantly increase the level count."
    }, {
      "heading" : "9.4 Triangle Enumeration",
      "text" : "We first evaluate the running time of the adjacency-array-based triangle enumeration algorithm. Figure 12 clearly shows that most time is spent enumerating the triangles of the lower levels. This justifies our suggestion to only precompute the triangles for the lower levels as these are the levels were the optimization is most effective. However, precomputing more levels does not hurt if enough memory is available. We propose to determine the threshold level up to which triangles are precomputed based on the size of the available unoccupied memory. On modern server machines such as our benchmarking machine there is enough memory to precompute all levels. The memory consumption is summarized in Table 7. However, note that precomputing all triangles is prohibitive in the game scenario as less available memory should be expected."
    }, {
      "heading" : "9.5 Customization",
      "text" : "In Table 8 we report the times needed to compute a customized metric using the basic customization algorithm. A first observation is that on the road graphs the KaHIP order leads to a faster customization whereas on the game map Metis dominates. Using all optimizations presented we customize Europe in below one second. When amortized8, we even achieve 415 ms which is only slightly above the nonamortized 347 ms reported in [16] for CRP. Note that their experiments were run on a different machine with a faster clock but 2× 6 instead of 2× 8 cores, while using a turn-aware data structure, making an exact comparison difficult.\nPrevious works have tried to accelerate the preprocessing phase of the original two-phase CH to the point that it can be used in a similar scenario as our technique. A fast preprocessing phase can be\n8We refer to a server scenario of multiple active users that require simultaneous customization, e. g., due to traffic updates.\nviewed as form of customization phase. In [21] a sequential preprocessing time of 451 s was reported. This compares best to our 9.5 s sequential customization time. Note that the machine on which the 451 s were measured is slower than our machine. However, the gap in performance is large enough to conclude that we achieve a significant speedup. Furthermore, [2] report a CH preprocessing time of 2 min when parallelized on 12 cores. This compares best against our 415 ms parallelized amortized customization time. While the machine used in [2] is slightly older and slower than our machine and the number of cores differs (12 vs. 16), again, the performance gap is large enough to safely conclude that a significant speedup is present. Besides the differences in running time, both CH preprocessing experiments were only performed for travel time weights. To the best of our knowledge, nobody has been able to reproduce such running times for less well-behaved weights, such as travel distance. For example, in [21] the fastest CH preprocessing time reported for distance metric is 2,853 s. This contrasts with CCH, for which we can prove that the customization and elimination tree query running times are completely independent of the weights used.\nUnfortunately, the optimizations illustrated in Table 8 are pretty far from what is possible with the hardware normally available in a game scenario. Regular PCs do not have 16 cores and one cannot clutter up the whole RAM with several GB of precomputed triangles. We therefore ran additionally experiments with different parameters and report the results in Table 9. The experiments show that it is possible to fully customize TheFrozenSea in an amortized9 time of 1.06s without precomputing triangles or using multiple cores. However a whole second is still too slow to be usable, as graphics, network and game logic also require resources. We therefore evaluated the time needed by partial updates as\n9We refer to a multiplayer scenario, where, e. g., fog of war requires player-specific simultaneous customization.\ndescribed in Section 7.7. We report our results in Table 10. The median, average and maximum running times significantly differ. There are a few arcs that trigger a lot of subsequent changes whereas for most arcs a weight change has nearly no effect. The explanation is that highway arcs and choke point arcs are part of many shortest paths and thus updating such an arc triggers significantly more changes.\nFinally, we report the running times of the perfect customization algorithm in Table 11. The required running time is about 3 times the running time needed by the basic customization. Recall that the basic customization in essence enumerates all lower triangles, i. e., it visits every triangle once, while the perfect customization also enumerates all intermediate and upper triangles, i. e., it visits every triangle three times."
    }, {
      "heading" : "9.6 Query Performance",
      "text" : "We experimentally evaluated the running times of the query algorithms. For this we ran 106 shortest path distance queries with the source and target vertices picked uniformly at random. The presented times are averaged running times on a single core without SSE.\nIn Table 12 and 13 we compare the query running times. The “MetDep+w” variant use a metricdependent order and a non-perfect witness search in the spirit of [21]. The details are described in Section 3. The “Metis-w” and “KaHIP-w” variants use a metric-independent order computed by Metis or KaHIP. Only a basic customization was performed, i. e., no witness search was performed. The “Metis+w” and “KaHIP+w” variants use the same metric-independent order but a perfect customization followed by a perfect witness search was performed. We evaluate three query variants. The “Basic” variant uses a bidirectional variant of Dijkstra’s algorithm with stopping criterion. The “Stalling” variant additionally uses the stall-on-demand optimization as described in Section 8.2. Finally, we also evaluate the elimination tree query and refer to it as “Tree”. This query requires the existence of an elimination tree of low depth and is therefore not available for metric-dependent orders. We ran our experiments on all three of our main benchmark instances. Experiments on additional instances are available in Section 10. For both road graphs, we evaluate the travel-time and distance variants. We report the average running time needed to perform a distance query, i. e., we do not unpack the paths. We further\nreport the average number of “visited” vertices in the forward search. For the “basic” and “stalling” queries, these are the vertices removed from the queue. For the “tree” query, we regard every ancestor as “visited”. The numbers for the backward search are analogous and therefore not reported. We also report the average number of arcs relaxed in forward search of each query variant. Finally, we also report the average number of vertices stalled and the average number of arcs that need to be tested in the stalling test. Note that, a stalled vertex is not counted as “visited”.\nAn important detail necessary to reproduce these results consists of reordering the vertex IDs according to the contraction order. Preliminary experiments showed that this reordering results in better cache behavior and a speed-up of about 2 to 3 because much query time is spent on the topmost clique and this order assures that these vertices appear adjacent in memory.\nAs already observed by the original CH authors, we confirm that the stall-on-demand heuristic improves running times by a factor of 2–5 compared to the basic algorithm for “greedy+w”. Interestingly, this is not the case with any variant using a metric-independent order. This can be explained by the density of the search spaces. While, the number of vertices in the search spaces are comparable between metric-independent orders and metric-dependent order, the number of arcs are not comparable and thus metric-independent search spaces are denser. As consequence, we need to test significantly more arcs in the stalling-test, which makes the test more expensive and therefore the additional time spent in the test does not make up for the time economized in the actual search. We thus conclude that stall-on-demand is not useful, when using metric-independent orders.\nVery interesting is the comparison between the elimination tree query and the basic query. The elimination tree query always explores the whole search space. In contrast to the basic query, it does not have a stopping criterion. However, the elimination tree query does not require a priority queue. It performs thus less work per vertex and arc than the basic query. Our experiments show, that the basic query always explores large parts of the search space regardless of the stopping criterion. The elimination tree query therefore does not visit significantly more. A consequence of this effect is that the time spent in the priority queue outweighs the additional time necessary to explore the remainder of the search space. The elimination tree query is therefore always the fastest among the three query types when using metric-independent orders. Combining a perfect witness search with the elimination tree query results in the fastest queries for metric-independent orders. However, the perfect witness search results in three times higher customization times. Whether, it is superior therefore depends on the specific application and the specific trade-off between customization and query running time needed.\nThe orders computed by KaHIP are nearly always significantly better than those produced by Metis. However, significantly more running time must be invested in the preprocessing phase to obtain these better order. It therefore depends on the situation which order is better. If the running time of the preprocessing phase is relevant, then Metis seems to strike a very good balance between all criteria. However, if the graph topology is fixed, as we expect it to be, then the flexibility gained by using Metis is not worth the price. Interestingly, on the game map KaHIP and Metis seem to be very close in terms of search space size. The difference is only apparent when using the perfect customization. For a setup with basic customization, the two orders should are nearly indistinguishable.\nThe metric-dependent orders with travel-time outperform the metric-independent orders. However, it is very interesting how close the query times actually are. On the Europe graph, the basic query visits about the same number of vertices, regardless of whether a metric-dependent or the KaHIP order is used. The real difference lies in the number of arcs that need to be relaxed. This number is significantly higher with metric-independent orders. However, the effect this has on the actual running times is comparatively slim. Using KaHIP without perfect witness search results in an elimination tree query that is only about 4 times slower than using the stalling query combined with metric-dependent orders. If a perfect witness search is used then, the gap is below a factor of 2. Further, the metric-dependent orders only win because of the stall-on-demand optimization. The KaHIP order combined with perfect customization outperforms the basic query combined with metric-dependent orders.\nIt is well-known that metric-dependent CHs work significantly better with the travel-time metric than with other less well behaved metrics such as the geographic distance. For such metrics, the KaHIP order outperforms the metric-dependent orders. For example the basic query with perfect customization visits less vertices and less arcs. This is very surprising, especially considering, that the metric-dependent orders that we computed are better than those reported in [21], i. e., the gap with respect to the original implementation is even larger. However, combining the stalling query with metric-dependent orders yields the smallest number of visited vertices and relaxed arcs. Unfortunately, combining the stalling query with metric-independent orders does not yield the same benefit and even makes the query running times worse. Fortunately, the metric-independent orders can be combined with the elimination tree\nquery. As result, the fastest variant is the combination of KaHIP order, perfect witness search, and elimination tree query, which is over a factor of two faster than stalling with the metric-dependent order. Interestingly, the later is even beaten when no perfect witness search is performed, but with a significantly lower margin.\nA huge advantage of metric-independent orders compared to metric-dependent orders is that the resulting CH performs equally well regardless of the weights of the input graph. The combination of metric-independent order, elimination tree query and basic customization results in setup, where the order in which the vertices are visited and the order in which the arcs are relaxed during the query execution does not even depend on the weights of the input graph. It is thus impossible to construct a metric, where this setup performs badly. This contrasts with the CH of [21], whose performances varies significantly depending on the input metric.\nIn Table 14, we give a more in-depth experimental analysis of the elimination tree query algorithm without perfect witness search. We break the running times down into the time needed to compute the least common ancestor (LCA), the time needed to reset the tentative distances and the time needed to relax all arcs. We further report the total distance query time, which is in essence the sum of the former three. We additionally report the time needed to unpack the full path. Our experiments show that the arc-relaxation phase clearly dominates the running times. It is therefore not useful to further optimize the LCA computation or to accelerate tentative distance resetting using, e. g., timestamps. We only report path unpacking performance without precomputed lower triangles. Using them would result in a further speedup with a similar speed-memory trade-off as already discussed for customization."
    }, {
      "heading" : "9.7 Comparison with Related Work",
      "text" : "We conclude our experimental analysis on the DIMACS Europe road network with a final comparison of related techniques, as shown in Table 15. For Contraction Hierarchies (CH), we report results based on implementations by [21, 13] and ourselves, covering different trade-offs in terms of preprocessing versus query speed. More precisely, we observe that our own CH implementation (used for detailed analysis and comparison in Section 9.1–9.6) has slightly slower queries on travel time metric but factor of 2.1 faster queries on distance metric, at the cost of higher preprocessing time. Recall from Section 3 that we employ a different vertex priority function and no lazy updates. For Customizable Route Planning (CRP), we report results from [13, 12].\nTraditional, metric-dependent CH offers the fastest query time (91 µs, on our machine), but it incurs substantial metric-dependent preprocessing costs, even when parallelized (109 s, 12 cores). Furthermore, CH performance is very sensible regarding metrics used: For distance metric, preprocessing time increases\nby factor of 3.2–11.5 and query time by factor of 4.9–12.8. In contrast to traditional CH, Customizable Contraction Hierarchies (CCH) by design achieve a performance trade-off with much lower metric-dependent preprocessing costs, similar to CRP. Accounting for differences in hardware, CCH basic customization time is about a factor of 2–3 slower than CRP customization, but still well below a second. On the other hand, CCH query performance is factor of 2–4 faster than CRP, both in terms of search space as well as query time (even when accounting for differences due to turn-aware implementation and hardware used). Most interestingly, on travel distance, CCH outperforms even the best CH result in terms of query performance. Overall, CCH is more robust wrt. to the metric than CRP: By design, CCH customization processes the same sequence of lower triangles for any metric, while the CCH elimination-tree query (given a fixed source and target) processes the same sequence of vertices and arcs for any metric.\nThe CRP implementation of [13] uses SSE to achieve its customization time of 0.37 s. In a server scenario where customization is run for many users concurrently (e. g., to customize traffic updates for all active users), we propose to amortize triangle enumeration time by using SSE to customize metrics for four users at once (cf. “Metric Pairs” in Table 8). With this amortized customization (CCH+a, 0.42 s), we can almost close the gap to CRP customization performance.\nFor even better CCH query performance, we may employ perfect customization and witness search (CCH+w). It increases customization time by factor of 3.2 (enumerating all lower, intermediate and upper triangles), but enables a CCH query variant that, while still visiting all vertices in the elimination tree, needs to consider far fewer arcs (cf. Table 13). Thereby, CCH+w further improves CCH query performance by factor of 1.9 for distance metric and factor of 2.6 for time metric. With 161 µs for travel time, CCH+w query times are almost as fast as the best CH result of 91 µs."
    }, {
      "heading" : "10 Further Instances",
      "text" : "10.1 OpenStreetMap-based Road Graphs\nOpenStreetMap (OSM) is a very popular collaborative effort to create a map of the world. From this huge data source very large road graphs can be extracted, that are very detailed depending on the exact region considered. Using the data provided by GeoFabrik10 and the tools provided by OSRM11, we extracted a road graph of Europe and report its size in Table 16. The exact graph is available in DIMACS format on our website12. The geographic region corresponding to the graph is depicted in Figure 13. Note that compared to the DIMACS Europe, our OSM Europe graph also contains Eastern Europe and Turkey. The graph’s east border ends at the east border of Turkey and then goes upward cutting through Russia. On the other hand, the DIMACS Europe graph stops at the German-Polish border.\nAt first glance the DIMACS Europe graph looks drastically smaller, at least in terms of vertex count. However, this is very misleading. A peculiarity of OSM is that the road graphs have a huge number of degree-2 vertices. These vertices are used to encode the curvature of a road. This information is needed to correctly represent a road graph on a map but not necessarily for routing. However, most other data sources, including the one on which the DIMACS graph is based, encode this information as arc attributes and thus have fewer degree-2 vertices. Accelerating shortest path computations on graphs with a huge number of vertices of degree 1 or 2 is signif-\nicantly easier relative to the graph size. One reason is that Dijkstra’s algorithm cannot exploit the abundance of low-degree vertices. Dijkstra’s algorithm with stopping criterion needs on average 27 s for a st-query with s and t picked uniformly at random on the OSM-Europe graph. This contrasts\n10http://download.geofabrik.de/ 11http://project-osrm.org/ 12http://i11www.iti.kit.edu/resources/roadgraphs.php\nwith the DIMACS Europe graph, where only 1.6 s are needed. A slower baseline obviously leads to larger speedups. Table 16 shows that the difference between the two Europe graphs in terms of vertex count is significantly smaller, when discarding degree 1 and degree-2 vertices. In fact, relative to their geographical region’s area, the two graphs seem to be approximately comparable in size.\nWe computed contraction orders for OSMEurope. The sizes of the resulting CHs are reported in Table 17. These sizes can be compared with the “undirected” numbers of Table 4. We did not perform experiments with a perfect witness search. Metis ordered the vertices within 29 minutes, whereas the KaHIP-based ordering algorithm needed slightly less than 3 weeks. However, as already discussed in detail, we did not optimize the later for speed and therefore one must not conclude from this experiment that KaHIP is slow. The CHs for OSM-based graphs are significantly larger. The DIMACS-Europe CH only contains 70M arcs for Metis whereas the OSM-Europe CH contains 400M arcs for Metis. However, this is due to the huge amount of low-degree vertices in the input. On the DIMACS graph the size increase compared to the number of input arcs is 70 M/42 M = 1.67 whereas for the OSM-based graph the size increase is only 400 M/348 M = 1.15. This effect can be explained by considering what happens when contracting a graph consisting of a single path. In the input graph every vertex, except the endpoints, has 2 outgoing arcs, one in each direction. As long as the endpoints are contracted last, every vertex, except the endpoints, in the resulting CH search graph also have degree 2. There is thus no size increase. As the OSM-based graph has many degree-2 vertices, this effect dominates and explains the comparatively small size increase. The search space sizes are nearly identically. For example the KaHIP search space contains 117K arcs for the DIMACS Europe graph, whereas it contains 119K arcs for the OSM Europe graph. This effect is explained by the fact, that both data sources correspond to almost the same geographical region. The mountains and rivers are thus in the same locations and the number of roads through these geographic obstacles are the same in both graphs, i. e., both graphs have very similar recursive separators. The small size increase is explained by the fact that the OSM-based graph also includes Eastern Europe. The customization times are reported in Table 18. As the OSMbased graph has more arcs, the customization times are higher on that graph. On the DIMACS Europe graph 0.61s are needed whereas 1.7s are needed on OSM Europe for the KaHIP order and 16 threads,\nwhich is a surprisingly small gap considering the differences in input sizes. Eliminating the degree-2 vertices from the input should further narrow this gap. As the search space sizes are very similar, it is not surprising that the query running times reported in Table 19 are nearly identical."
    }, {
      "heading" : "10.2 Further DIMACS-Instances",
      "text" : "During the DIMACS challenge on shortest path [17] several benchmark instances were made available. Among them is the Europe instance used throughout our in-depth experiments in previous chapters.\nBesides this instance, also a set of graphs representing the road network of the USA was published. In Table 20 we report experiments for these additional DIMACS road graphs. Other than the DIMACSEurope instance, these USA instances originate from the U.S. Census Bureau. Note that the USA instances have some known data quality issues: The graphs are generally undirected (no one-way streets) and highways are sometimes not connected at state borders. The DIMACS-Europe comes from another data source and does not have these limitations. This is the reason why we focus on the Europe instance in the main part of our evaluation.\nHowever, as the graphs are undirected we can evaluate the impact of using a single undirected metric has on customization running times compared to using two directed metrics (as used on DIMACS Europe). Experiments using a single metric are marked with “Uni” in the table, whereas the experiments with two metrics are marked with “Bi”. The query running times are very similar. This is not surprising as the number of relaxed arcs does not depend on whether one or two weights are used. For larger graphs there is a slightly larger difference in running times. We believe that this is a cache effect. As the “Bi” variant has twice as many weights, less arcs fit into the L3 cache. For the smaller graphs this effect does not occur because the higher CH levels occupy less memory than the cache’s size and thus doubling the memory consumption is non-problematic.\nThe difference in customization times between the two variants is larger. The number of enumerated triangles is the same, but twice as many instructions are executed per triangle. We would thus expect a factor of 2 difference in the customization running times. However, this factor is only observed on the largest instance. On all smaller instances, the gap is significantly smaller. Again, this is most likely the result of cache effects."
    }, {
      "heading" : "10.3 Further Game Instances",
      "text" : "Besides our main game benchmark instance TheFrozenSea, the benchmark data set of [38] contains a large variety of different game maps. To demonstrate that our technique also works on other game maps we ran our experiments on a selection of different graphs from the set. “16room 005” is a synthetic map with many rooms in grid shape that are connected through small doors. “AcrosstheCape” is another Star Craft map that is sometimes used as benchmark instance. “blastedlands” originates from WarCraft 3 and is the largest map in that set in terms of vertices. “maze512-4-3” is a synthetic map that consists\nof a random maze with corridors that are 4 fields wide. “ost100d” is the largest map from the Dragon Age Origins map set. “random512-35-8” and “random512-40-8” are synthetic maps that contain random obstacles. The difference between them is the amount of space covered by obstacles. The website13 from which the data originates includes pictures depicting each instance.\nAll experiments were run using a single undirected metric with 32bits per weight. The customization running times are non-amortized. We did not perform experiments with a perfect witness search.\nAll additional game-based instances have fewer vertices than TheFrozenSea. Further, the CH query is the slowest on TheFrozenSea with 316 µs. Interestingly, a full customization is slower on AcrosstheCape than on TheFrozenSea by about a factor of 2. This is most likely due to slight differences in the structures of the maps. However, we believe that it is safe to conclude from the experiments that our technique works across a wide range of maps."
    }, {
      "heading" : "11 Conclusions",
      "text" : "We have extended Contraction Hierarchies (CH) to a three-phase customization approach and demonstrated in an extensive experimental evaluation that our Customizable Contraction Hierarchies approach is practicable and efficient not only on real world road graphs but also on game maps. We have proposed new algorithms that improve on the state-of-the-art for nearly all stages of the toolchain: Using our contraction graph data structure, a metric-independent CH can be constructed faster than with the established approach based on dynamic arrays. We have shown that the customization phase is essentially a triangle enumeration algorithm. We have provided two variants of the customization: The basic variant yields faster customization running times, while perfect customization and witness search computes CHs with a provable minimum number of shortcuts within seconds given a metric-independent vertex order. We proposed an elimination-tree based query that unlike previous approaches is not based on Dijkstra’s algorithm and thus does not use a priority queue. This results in significantly lower overhead per visited arc, enabling faster queries. Finally, our extensive experimental analysis shed some light onto the inner workings of Contraction Hierarchies."
    }, {
      "heading" : "11.1 Future Work",
      "text" : "Good separators are the foundation of Customizable Contraction Hierarchies: Finding better separators directly improves both customization as well as query performance. For our purposes, the time required to compute good separators was of no primary concern (we do it once per graph). Hence, our nested dissection implementation based on KaHIP [34] was not optimized for speed but rather to demonstrate that good separators exist.\nFor some applications this may be too slow. However, since we performed the experiments reported in this paper, significant improvements have been made in this domain: The works of [39] lay the\n13http://www.movingai.com/benchmarks/\nfoundations of a well-implemented KaHIP-based algorithm. [35] introduce a new and surprisingly simple road graph bisection algorithm called Inertial Flow. FlowCutter [25], available as preprint, computes the best metric-independent contraction orders we have observed so far, much faster than the nested dissection implementation presented in this work. This results in decreased query and customization times and reduced memory consumption for Customizable Contraction Hierarchies.\nOur experiments suggest, that even metric-dependent Contraction Hierarchies implicitly exploit the existence of small graph cuts. However, this does not seem to be the only exploited feature as metricindependent orders behave differently when it comes to details: For example, the stall-on-demand optimization only works with metric-dependent orders, for both travel time as well as distance metric, but not for the metric-independent orders. Further investigations into this effect might yield additional valuable insights. A good starting point could be the theoretical works of [3].\nFurther investigation into algorithms explicitly exploiting treewidth [11, 31] seems promising. Also, determining the precise treewidth of road networks could prove useful.\nIn practice, route planning services consider several additional real-world constraints beyond the scope of this paper. These include, e. g., turn costs and restrictions, historic traffic data for rush hours, and range constraints due to limited electric vehicle batteries. For turns, we assume that Customizable Contraction Hierarchies is well applicable as the size of graph cuts cannot grow arbitrarily when turnexpanding the road graph. We are interested in further in-depth experimental analysis of aforementioned scenarios.\nAcknowledgment: We would like to thank Ignaz Rutter and Tim Zeitz for very inspiring conversations."
    } ],
    "references" : [ {
      "title" : "Highway dimension and provably efficient shortest path",
      "author" : [ "Ittai Abraham", "Daniel Delling", "Amos Fiat", "Andrew V. Goldberg", "Renato F. Werneck" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Hierarchical hub labelings for shortest paths",
      "author" : [ "Ittai Abraham", "Daniel Delling", "Andrew V. Goldberg", "Renato F. Werneck" ],
      "venue" : "In Proceedings of the 20th Annual European Symposium on Algorithms (ESA’12),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Highway dimension, shortest paths, and provably efficient algorithms",
      "author" : [ "Ittai Abraham", "Amos Fiat", "Andrew V. Goldberg", "Renato F. Werneck" ],
      "venue" : "In Proceedings of the 21st Annual ACM–SIAM Symposium on Discrete Algorithms",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "Route planning in transportation networks",
      "author" : [ "Hannah Bast", "Daniel Delling", "Andrew V. Goldberg", "Matthias Müller–Hannemann", "Thomas Pajor", "Peter Sanders", "Dorothea Wagner", "Renato F. Werneck" ],
      "venue" : "Technical Report abs/1504.05140, ArXiv e-prints,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "Preprocessing speed-up techniques is hard",
      "author" : [ "Reinhard Bauer", "Tobias Columbus", "Bastian Katz", "Marcus Krug", "Dorothea Wagner" ],
      "venue" : "In Proceedings of the 7th Conference on Algorithms and Complexity (CIAC’10),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "Search-space size in contraction hierarchies",
      "author" : [ "Reinhard Bauer", "Tobias Columbus", "Ignaz Rutter", "Dorothea Wagner" ],
      "venue" : "In Proceedings of the 40th International Colloquium on Automata, Languages, and Programming (ICALP’13),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "The shortcut problem – complexity and algorithms",
      "author" : [ "Reinhard Bauer", "Gianlorenzo D’Angelo", "Daniel Delling", "Andrea Schumm", "Dorothea Wagner" ],
      "venue" : "Journal of Graph Algorithms and Applications,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "A tourist guide through treewidth",
      "author" : [ "Hans L. Bodlaender" ],
      "venue" : "j-acta-cybernet,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1993
    }, {
      "title" : "Treewidth: Structure and algorithms",
      "author" : [ "Hans L. Bodlaender" ],
      "venue" : "Proceedings of the 14th International Colloquium on Structural Information and Communication Complexity,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Treewidth computations i. upper bounds",
      "author" : [ "Hans L. Bodlaender", "Arie M.C.A. Koster" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Shortest paths in digraphs of small treewidth",
      "author" : [ "Soma Chaudhuri", "Christos Zaroliagis" ],
      "venue" : "i: Sequential algorithms. Algorithmica,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2000
    }, {
      "title" : "Customizable route planning",
      "author" : [ "Daniel Delling", "Andrew V. Goldberg", "Thomas Pajor", "Renato F. Werneck" ],
      "venue" : "In Proceedings of the 10th International Symposium on Experimental Algorithms (SEA’11),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    }, {
      "title" : "Customizable route planning in road networks",
      "author" : [ "Daniel Delling", "Andrew V. Goldberg", "Thomas Pajor", "Renato F. Werneck" ],
      "venue" : "Transportation Science,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Graph partitioning with natural cuts",
      "author" : [ "Daniel Delling", "Andrew V. Goldberg", "Ilya Razenshteyn", "Renato F. Werneck" ],
      "venue" : "In 25th International Parallel and Distributed Processing Symposium",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2011
    }, {
      "title" : "Exact combinatorial branch-and-bound for graph bisection",
      "author" : [ "Daniel Delling", "Andrew V. Goldberg", "Ilya Razenshteyn", "Renato F. Werneck" ],
      "venue" : "In Proceedings of the 14th Meeting on Algorithm Engineering and Experiments",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Faster customization of road networks",
      "author" : [ "Daniel Delling", "Renato F. Werneck" ],
      "venue" : "In Proceedings of the 12th International Symposium on Experimental Algorithms (SEA’13),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "The Shortest Path Problem: Ninth DIMACS Implementation Challenge, volume",
      "author" : [ "Camil Demetrescu", "Andrew V. Goldberg", "David S. Johnson", "editors" ],
      "venue" : "DIMACS Book. American Mathematical Society,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "A note on two problems in connexion with graphs",
      "author" : [ "Edsger W. Dijkstra" ],
      "venue" : "Numerische Mathematik,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1959
    }, {
      "title" : "Incidence matrices and interval graphs",
      "author" : [ "Delbert R. Fulkerson", "O.A. Gross" ],
      "venue" : "Pacific Journal of Mathematics,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1965
    }, {
      "title" : "Contraction hierarchies: Faster and simpler hierarchical routing in road networks",
      "author" : [ "Robert Geisberger", "Peter Sanders", "Dominik Schultes", "Daniel Delling" ],
      "venue" : "In Proceedings of the 7th Workshop on Experimental Algorithms (WEA’08),",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Exact routing in large road networks using contraction hierarchies",
      "author" : [ "Robert Geisberger", "Peter Sanders", "Dominik Schultes", "Christian Vetter" ],
      "venue" : "Transportation Science,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Nested dissection of a regular finite element mesh",
      "author" : [ "Alan George" ],
      "venue" : "SIAM Journal on Numerical Analysis,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1973
    }, {
      "title" : "A quotient graph model for symmetric factorization",
      "author" : [ "Alan George", "Joseph W. Liu" ],
      "venue" : "In Sparse Matrix Proceedings",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1978
    }, {
      "title" : "The analysis of a nested dissection algorithm",
      "author" : [ "John R. Gilbert", "Robert Tarjan" ],
      "venue" : "Numerische Mathematik,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1986
    }, {
      "title" : "Graph bisection with pareto-optimization",
      "author" : [ "Michael Hamann", "Ben Strasser" ],
      "venue" : "Technical report,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2015
    }, {
      "title" : "Engineering multilevel overlay graphs for shortest-path queries",
      "author" : [ "Martin Holzer", "Frank Schulz", "Dorothea Wagner" ],
      "venue" : "ACM Journal of Experimental Algorithmics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2008
    }, {
      "title" : "Tractability of parameterized completion problems on chordal, strongly chordal, and proper interval graphs",
      "author" : [ "Haim Kaplan", "Ron Shamir", "Robert Tarjan" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1999
    }, {
      "title" : "A fast and high quality multilevel scheme for partitioning irregular graphs",
      "author" : [ "George Karypis", "Vipin Kumar" ],
      "venue" : "SIAM Journal on Scientific Computing,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1999
    }, {
      "title" : "Generalized nested dissection",
      "author" : [ "Richard J. Lipton", "Donald J. Rose", "Robert Tarjan" ],
      "venue" : "SIAM Journal on Numerical Analysis,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1979
    }, {
      "title" : "On optimal preprocessing for contraction hierarchies",
      "author" : [ "Nikola Milosavljević" ],
      "venue" : "In Proceedings of the 5th ACM SIGSPATIAL International Workshop on Computational Transportation Science,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2012
    }, {
      "title" : "Computing all-pairs shortest paths by leveraging low treewidth",
      "author" : [ "Léon Planken", "Mathijs de Weerdt", "Roman van Krogt" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2012
    }, {
      "title" : "The complexity of optimal elimination trees",
      "author" : [ "Alex Pothen" ],
      "venue" : "Technical report, Pennsylvania State University,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1988
    }, {
      "title" : "Engineering highway hierarchies",
      "author" : [ "Peter Sanders", "Dominik Schultes" ],
      "venue" : "ACM Journal of Experimental Algorithmics,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2012
    }, {
      "title" : "Think locally, act globally: Highly balanced graph partitioning",
      "author" : [ "Peter Sanders", "Christian Schulz" ],
      "venue" : "In Proceedings of the 12th International Symposium on Experimental Algorithms (SEA’13),",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2013
    }, {
      "title" : "On balanced separators in road networks",
      "author" : [ "Aaron Schild", "Christian Sommer" ],
      "venue" : "In Proceedings of the 14th International Symposium on Experimental Algorithms (SEA’15),",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2015
    }, {
      "title" : "Dijkstra’s algorithm on-line: An empirical case study from public railroad transport",
      "author" : [ "Frank Schulz", "Dorothea Wagner", "Karsten Weihe" ],
      "venue" : "ACM Journal of Experimental Algorithmics,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2000
    }, {
      "title" : "Contraction hierarchies on grid graphs",
      "author" : [ "Sabine Storandt" ],
      "venue" : "In Proceedings of the 36rd Annual German Conference on Advances in Artificial Intelligence, Lecture Notes in Computer Science. Springer,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2013
    }, {
      "title" : "Benchmarks for grid-based pathfinding",
      "author" : [ "Nathan Sturtevant" ],
      "venue" : "Transactions on Computational Intelligence and AI in Games,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2012
    }, {
      "title" : "Finding small node separators",
      "author" : [ "Michael Wegner" ],
      "venue" : "Bachelor thesis, Karlsruhe Institute of Technology,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2014
    }, {
      "title" : "Tedi: efficient shortest path query answering on graphs",
      "author" : [ "Fang Wei" ],
      "venue" : "In Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data (SIGMOD’10). ACM Press,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2010
    }, {
      "title" : "Computing the minimum fill-in is np-complete",
      "author" : [ "Mihalis Yannakakis" ],
      "venue" : "SIAM Journal on Algebraic and Discrete Methods,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 1981
    }, {
      "title" : "Weak contraction hierarchies work",
      "author" : [ "Tim Zeitz" ],
      "venue" : "Bachelor thesis, Karlsruhe Institute of Technology,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "Unfortunately, road graphs tend to be huge in practice with vertex counts in the tens of millions, rendering Dijkstra’s algorithm [18] impracticable for interactive use: It incurs running times in the order of seconds even for a single path query.",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 3,
      "context" : "See [4] for an overview.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "While variants of the optimal shortcut selection problem have been proven to be NP-hard [7], determining good shortcuts is feasible in practice even on large road graphs.",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 19,
      "context" : "Among the most successful speedup techniques using this building block are Contraction Hierarchies (CH) by [20, 21].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 20,
      "context" : "Among the most successful speedup techniques using this building block are Contraction Hierarchies (CH) by [20, 21].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 20,
      "context" : "Even though ordering heuristics exist that work well in practice [21], the problem of computing an optimal ordering is NP-hard in general [5].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 4,
      "context" : "Even though ordering heuristics exist that work well in practice [21], the problem of computing an optimal ordering is NP-hard in general [5].",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "Worst-case bounds have been proven in [1] in terms of a weight-dependent graph measure called highway dimension and [30] have shown that many of these bounds are tight on many graph classes.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 29,
      "context" : "Worst-case bounds have been proven in [1] in terms of a weight-dependent graph measure called highway dimension and [30] have shown that many of these bounds are tight on many graph classes.",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 20,
      "context" : "A central restriction of CHs as proposed by [21] is that their preprocessing is metric-dependent, that is edge weights, also called metric, need to be known.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 11,
      "context" : "For this reason, a Customizable Route Planning (CRP) approach was proposed in [12], extending the multi-level-overlay MLD techniques of [36, 26].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 35,
      "context" : "For this reason, a Customizable Route Planning (CRP) approach was proposed in [12], extending the multi-level-overlay MLD techniques of [36, 26].",
      "startOffset" : 136,
      "endOffset" : 144
    }, {
      "referenceID" : 25,
      "context" : "For this reason, a Customizable Route Planning (CRP) approach was proposed in [12], extending the multi-level-overlay MLD techniques of [36, 26].",
      "startOffset" : 136,
      "endOffset" : 144
    }, {
      "referenceID" : 36,
      "context" : "Game Scenario Most existing CH papers focus solely on road graphs, with [37] being a notable exception, but there are many other applications with differently structured graphs in which fast shortest path computations are important.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 21,
      "context" : "Metric-Independent Orders for CHs One of the central building blocks of this paper is the use of metric-independent nested dissection orders (ND-orders) [22] for CH precomputation instead of the metric-dependent order of [21].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 20,
      "context" : "Metric-Independent Orders for CHs One of the central building blocks of this paper is the use of metric-independent nested dissection orders (ND-orders) [22] for CH precomputation instead of the metric-dependent order of [21].",
      "startOffset" : 221,
      "endOffset" : 225
    }, {
      "referenceID" : 5,
      "context" : "This approach was proposed by [6], and a preliminary case study can be found in [42].",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 41,
      "context" : "This approach was proposed by [6], and a preliminary case study can be found in [42].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "A similar idea was followed by [16], where the authors employ partial CHs to engineer subroutines of their customization phase.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 30,
      "context" : "Similar ideas have also appeared in [31]: They consider graphs of low treewidth (see below) and leverage this property to compute CH-like structures, without explicitly using the term CH.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 39,
      "context" : "Related techniques by [40, 11] work directly on the tree decomposition.",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 10,
      "context" : "Related techniques by [40, 11] work directly on the tree decomposition.",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 21,
      "context" : "To the best of our knowledge the idea first appeared in 1973 in [22] and was refined in [29].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 28,
      "context" : "To the best of our knowledge the idea first appeared in 1973 in [22] and was refined in [29].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "We refer to [9] and [8] for an introduction to the broad field of treewidth and tree decompositions.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 7,
      "context" : "We refer to [9] and [8] for an introduction to the broad field of treewidth and tree decompositions.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 40,
      "context" : ", minimizing the fill-in, is NP-hard [41] but fixed parameter tractable in the number of extra edges [27].",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 26,
      "context" : ", minimizing the fill-in, is NP-hard [41] but fixed parameter tractable in the number of extra edges [27].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 5,
      "context" : "[6] have shown that the maximum search space size in terms of vertices corresponds to the height of this elimination tree.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 31,
      "context" : "Unfortunately, minimizing the elimination tree height is also NP-hard [32].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 23,
      "context" : "For planar graphs, it has been shown that the number of additional edges is in O(n log n) [24].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 11,
      "context" : "Compared to CRP [12] we achieve a similar preprocessing–query tradeoff, albeit with slightly better query performance at slightly slower customization speed and we need somewhat more space.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 20,
      "context" : "Interestingly, for less well-behaved metrics such as travel distance, we achieve query times below the original metric-dependent CH of [21].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 20,
      "context" : "Our specialized algorithm has better theoretic worst-case running time and performs significantly better empirically than the dynamic adjacency arrays used in [21].",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 20,
      "context" : "Section 3 discusses metric-dependent orders as used by [21], highlighting specifics of our implementation.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 20,
      "context" : "Given a fixed weight w, one can exploit that in many applications it is sufficient to only preserve all shortest path distances [21].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 20,
      "context" : "This check is called witness search [21] and the xy-path is called witness, if it exists.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 20,
      "context" : "Note that the witness searches are expensive and therefore the witness search is usually aborted after a certain number of steps [21].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 20,
      "context" : "This up-down path can be found by running a bidirectional search from s restricted to SS(s) and from t restricted to SS(t) [21].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 18,
      "context" : ", the core graph before the contraction of π(i), form a clique [19].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 5,
      "context" : "As shown in [6], the set of vertices on the path from v to π(n) is the set of vertices in SS(v).",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 20,
      "context" : "3 Metric-Dependent Orders Most publications on applications and extensions of Contraction Hierarchies use greedy orders in the spirit of [21], but details of vertex order computation and witness search vary.",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "Our weighting heuristic is similar to the one of [2].",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 20,
      "context" : "Hence, for the experiments presented in Section 9, we do not use lazy updates or periodic queue rebuilding as proposed in [21].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 5,
      "context" : "To support metric-independence, we therefore use nested dissection orders as suggested in [6] or ND-orders for short.",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 33,
      "context" : "However, recent years have seen heuristics that solve the problem very well even for continental road graphs [34, 15, 14].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 14,
      "context" : "However, recent years have seen heuristics that solve the problem very well even for continental road graphs [34, 15, 14].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 13,
      "context" : "However, recent years have seen heuristics that solve the problem very well even for continental road graphs [34, 15, 14].",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 27,
      "context" : "We experimentally examine the performance of nested dissection orders computed by NDMetis [28] and KaHIP [34] in Section 9.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 33,
      "context" : "We experimentally examine the performance of nested dissection orders computed by NDMetis [28] and KaHIP [34] in Section 9.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 5,
      "context" : "The proof of this lemma is a straightforward argument using a geometric series as described in [6].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 28,
      "context" : "This lemma is a minor adaptation and extension of [29], who only prove that such a clique exists but not that it lies within enough search spaces.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 41,
      "context" : "It has been proposed [42] to use hash-tables on top of the dynamic graph structure to improve speed but at the cost of significantly increased memory consumption.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 22,
      "context" : "The approach is heavily based upon the method of the quotient graph [23].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 15,
      "context" : "Comparison with CRP Triangle preprocessing has similarities with micro and macro code in CRP [16].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 15,
      "context" : "Hence, let t be the number of undirected triangles and m be the number of arcs in Gπ ; further let t ′ be the number of directed triangles and m′ be the number of arcs used in [16].",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 2,
      "context" : "Figure 6: The rank sequence of the solid red path is [3, 2, 1].",
      "startOffset" : 53,
      "endOffset" : 62
    }, {
      "referenceID" : 1,
      "context" : "Figure 6: The rank sequence of the solid red path is [3, 2, 1].",
      "startOffset" : 53,
      "endOffset" : 62
    }, {
      "referenceID" : 0,
      "context" : "Figure 6: The rank sequence of the solid red path is [3, 2, 1].",
      "startOffset" : 53,
      "endOffset" : 62
    }, {
      "referenceID" : 2,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 2,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 1,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 108,
      "endOffset" : 117
    }, {
      "referenceID" : 1,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 108,
      "endOffset" : 117
    }, {
      "referenceID" : 0,
      "context" : "The rank sequence of the blue dashed path is [3, 3, 2, 1] and the rank sequence of the green dotted path is [4, 2, 1].",
      "startOffset" : 108,
      "endOffset" : 117
    }, {
      "referenceID" : 20,
      "context" : "The ideas employed by our algorithm are somewhat similar to those presented in [21], but our situation differs as we know that we do not have to insert or remove arcs.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "In either case in contrast to [21] they operate 3We refer to the minimum sum over all weights over all st-paths as the distance between s and t.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 20,
      "context" : "2 Stalling We implemented a basic version of an optimization presented in [21, 33] called stall-on-demand.",
      "startOffset" : 74,
      "endOffset" : 82
    }, {
      "referenceID" : 32,
      "context" : "2 Stalling We implemented a basic version of an optimization presented in [21, 33] called stall-on-demand.",
      "startOffset" : 74,
      "endOffset" : 82
    }, {
      "referenceID" : 20,
      "context" : "The original CH of [21] unpacks an up-down path by storing for every arc (x, y) the vertex z of the lower triangle {x, y, z} that caused the weight at m(x, y).",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "The sizes of our main test instances are reported in Table 1: The DIMACS-Europe graph was provided by PTV for the DIMACS challenge [17].",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 37,
      "context" : "The TheFrozenSea graph is based on the largest Star Craft map presented in [38].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "We analyze three different vertex orders: 1) The greedy metric-dependent order is an order in the spirit of [21].",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 20,
      "context" : "Table 3 compares the performance of our specialized Contraction Graph data structure, described in Section 5, to the dynamic adjacency structure, as used in [21] to compute undirected and unweighted CHs.",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 41,
      "context" : "We do not report numbers for the hash-based approach of [42] as it is fully dominated.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 20,
      "context" : "The numbers show that the heuristic witness search employed by [21] is nearly optimal.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "See [10] for details.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 15,
      "context" : "When amortized, we even achieve 415 ms which is only slightly above the nonamortized 347 ms reported in [16] for CRP.",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 20,
      "context" : "In [21] a sequential preprocessing time of 451 s was reported.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 1,
      "context" : "Furthermore, [2] report a CH preprocessing time of 2 min when parallelized on 12 cores.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 1,
      "context" : "While the machine used in [2] is slightly older and slower than our machine and the number of cores differs (12 vs.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 20,
      "context" : "For example, in [21] the fastest CH preprocessing time reported for distance metric is 2,853 s.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "In each run we change the upward and the downward weight of a single random arc in G to random values in [0, 10].",
      "startOffset" : 105,
      "endOffset" : 112
    }, {
      "referenceID" : 20,
      "context" : "The “MetDep+w” variant use a metricdependent order and a non-perfect witness search in the spirit of [21].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 20,
      "context" : "This is very surprising, especially considering, that the metric-dependent orders that we computed are better than those reported in [21], i.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 20,
      "context" : "This contrasts with the CH of [21], whose performances varies significantly depending on the input metric.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 20,
      "context" : "For Contraction Hierarchies (CH), we report results based on implementations by [21, 13] and ourselves, covering different trade-offs in terms of preprocessing versus query speed.",
      "startOffset" : 80,
      "endOffset" : 88
    }, {
      "referenceID" : 12,
      "context" : "For Contraction Hierarchies (CH), we report results based on implementations by [21, 13] and ourselves, covering different trade-offs in terms of preprocessing versus query speed.",
      "startOffset" : 80,
      "endOffset" : 88
    }, {
      "referenceID" : 12,
      "context" : "For Customizable Route Planning (CRP), we report results from [13, 12].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : "For Customizable Route Planning (CRP), we report results from [13, 12].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 20,
      "context" : "Queries Turn- Time [s] Search Space Time [μs] Algorithm Implementation Machine Metric aware (# Threads) [# Vertices] (# Threads) CH [21] Opt 270 Time ◦ 1 809 (1) 356 152 (1) CH [21] Opt 270 Dist ◦ 5 723 (1) 1 582 1 940 (1) CH [21] E5-2670 Time ◦ 1 075.",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 20,
      "context" : "Queries Turn- Time [s] Search Space Time [μs] Algorithm Implementation Machine Metric aware (# Threads) [# Vertices] (# Threads) CH [21] Opt 270 Time ◦ 1 809 (1) 356 152 (1) CH [21] Opt 270 Dist ◦ 5 723 (1) 1 582 1 940 (1) CH [21] E5-2670 Time ◦ 1 075.",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 20,
      "context" : "Queries Turn- Time [s] Search Space Time [μs] Algorithm Implementation Machine Metric aware (# Threads) [# Vertices] (# Threads) CH [21] Opt 270 Time ◦ 1 809 (1) 356 152 (1) CH [21] Opt 270 Dist ◦ 5 723 (1) 1 582 1 940 (1) CH [21] E5-2670 Time ◦ 1 075.",
      "startOffset" : 226,
      "endOffset" : 230
    }, {
      "referenceID" : 20,
      "context" : "88 (1) 353 91 (1) CH [21] E5-2670 Dist ◦ 3 547.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 12,
      "context" : "32 (1) 1422 540 (1) CH [13] X5680 Time ◦ 109 (12) 280 110 (1) CH [13] X5680 Dist ◦ 726 (12) 858 870 (1) CRP [13] X5680 Time • 0.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 12,
      "context" : "32 (1) 1422 540 (1) CH [13] X5680 Time ◦ 109 (12) 280 110 (1) CH [13] X5680 Dist ◦ 726 (12) 858 870 (1) CRP [13] X5680 Time • 0.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 12,
      "context" : "32 (1) 1422 540 (1) CH [13] X5680 Time ◦ 109 (12) 280 110 (1) CH [13] X5680 Dist ◦ 726 (12) 858 870 (1) CRP [13] X5680 Time • 0.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 12,
      "context" : "37 (12) 2 766 1 650 (1) CRP [13] X5680 Dist • 0.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "37 (12) 2 942 1 910 (1) CRP [12] i7 920 Time ◦ 4.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "7 (4) 3 828 720 (2) CRP [12] i7 920 Dist ◦ 4.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 12,
      "context" : "We further report average query search space, including stalled vertices for CH (which might not be included in the CH figures taken from [13]).",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 20,
      "context" : "Since the CH performance in [21] was evaluated on a ten year old machine (AMD Opteron 270), we obtained the source code and re-ran experiments on our hardware (Intel Xeon E5-2670) for better comparability.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 12,
      "context" : "Also note that the latest CRP implementation by [13], evaluated on an Intel Xeon X5680, is turn-aware (•), i.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 11,
      "context" : ", it uses turn tables (set to zero in the reported experiments); We therefore additionally take results from [12] obtained on an Intel Core-i7 920, which uses a turn-unaware implementation but parallelizes queries.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 12,
      "context" : "The CRP implementation of [13] uses SSE to achieve its customization time of 0.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 16,
      "context" : "2 Further DIMACS-Instances During the DIMACS challenge on shortest path [17] several benchmark instances were made available.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 37,
      "context" : "3 Further Game Instances Besides our main game benchmark instance TheFrozenSea, the benchmark data set of [38] contains a large variety of different game maps.",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "Hence, our nested dissection implementation based on KaHIP [34] was not optimized for speed but rather to demonstrate that good separators exist.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 38,
      "context" : "However, since we performed the experiments reported in this paper, significant improvements have been made in this domain: The works of [39] lay the 13http://www.",
      "startOffset" : 137,
      "endOffset" : 141
    } ],
    "year" : 2015,
    "abstractText" : "We consider the problem of quickly computing shortest paths in weighted graphs. Often, this is achieved in two phases: 1) derive auxiliary data in an expensive preprocessing phase, 2) use this auxiliary data to speedup the query phase. By adding a fast weight-customization phase, we extend Contraction Hierarchies to support a three-phase workflow: The expensive preprocessing is split into a phase exploiting solely the unweighted topology of the graph, as well as a lightweight phase that adapts the auxiliary data to a specific weight. We achieve this by basing our Customizable Contraction Hierarchies on nested dissection orders. We provide an in-depth experimental analysis on large road and game maps that shows that Customizable Contraction Hierarchies are a very practicable solution in scenarios where edge weights often change.",
    "creator" : "LaTeX with hyperref package"
  }
}