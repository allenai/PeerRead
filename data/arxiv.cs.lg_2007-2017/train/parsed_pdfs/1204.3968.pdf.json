{
  "name" : "1204.3968.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "sermanet@cs.nyu.edu", "soumith@cs.nyu.edu", "yann@cs.nyu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n20 4.\n39 68\nv1 [\ncs .C\nV ]\n1 8\nA pr\n2 01"
    }, {
      "heading" : "1. Introduction",
      "text" : "Character recognition in documents can be considered a solved task for computer vision, whether handwritten or typed. It is however a harder problem in the context of complex natural scenes like photographs where the best current methods lag behind human performance, mainly due to non-contrasting backgrounds, low resolution, de-focused and motion-blurred images and large illumination differences (Figure 1).\n[8] recently introduced a new digit classification dataset of house numbers extracted from street level images. It is similar in format to the popular MNIST dataset[7] (10 digits, 32x32 inputs), but an order of magnitude bigger (600,000 labeled digits), contains color information and various natural backgrounds.\nPrevious approaches in classifying characters and digits from natural images used multiple hand-crafted features [3] and template-matching [14]. In contrast, ConvNets learn features all the way from pixels to the classifier. [8] demonstrated the superiority of learned features over hand-designed ones. Such superiority\nwas also previously shown among others in a traffic sign classification challenge [13] where two independent teams obtained the best performance against various other approaches using ConvNets [11, 2]. [8] also show superior results with unsupervised learning, we however only report results with fully-supervised training. We obtain a 4.25 points improvement in accuracy (with 94.85% accuracy) over the previous state-of-theart of 90.6%. We use the traditional ConvNet architecture augmented with different pooling methods and with multi-stage features [11]. This work was implemented with the EBLearn 1 C++ open-source framework [10].\n1http://eblearn.sf.net"
    }, {
      "heading" : "2 Architecture",
      "text" : "The ConvNet architecture is composed of repeatedly stacked feature stages. Each stage contains a convolution module, followed by a pooling/subsampling module and a normalization module. While traditional pooling modules in ConvNet are either average or max poolings, we use an Lp pooling here. The normalization module is subtractive only as opposed to subtractive and divisive, i.e. the mean value of each neighborhood is subtracted to the output of each stage (but not divided by the standard deviation as it decreases performance with this dataset). Finally, multi-stage features are also used as opposed to single-stage features."
    }, {
      "heading" : "2.1 Lp-Pooling",
      "text" : "Lp pooling is a biologically inspired pooling layer modelled on complex cells [12, 5] who’s operation can be summarized in equation (1), where G is a Gaussian kernel, I is the input feature map and O is the output feature map. It can be imagined as giving an increased weight to stronger features and suppressing weaker features. Two special cases of Lp pooling are notable. P = 1 corresponds to a simple Gaussian averaging, whereas P = ∞ corresponds to max-pooling (i.e only the strongest signal is activated). Lp-pooling has been used previously in [6, 15] and a theoretical analysis of this method is described in [1].\nO = ( ∑∑ I(i, j)P ×G(i, j))1/P (1)\nFigure 2 demonstrates a simple example of L2pooling."
    }, {
      "heading" : "2.2 Multi-Stage Features",
      "text" : "Multi-Stage features (MS) are obtained by branching out outputs of all stages into the classifier (Figure 3). They provide richer representations compared to Single-Stage features (SS) by adding complementary information such as local textures and fine details lost by higher levels. MS features have consistently improved performance in other work [4, 11, 9] and in this work as well (Figure 4). However we observe minimal gains on this dataset compared to other types of\nobjects such as pedestrians and traffic signs (Table 1). The likely explanation for this observation is that gains are correlated to the amount of texture and multi-scale characteristics of the objects of interest."
    }, {
      "heading" : "3. Experiments",
      "text" : ""
    }, {
      "heading" : "3.1. Data Preparation",
      "text" : "The SVHN classification dataset [8] contains 32x32 images with 3 color channels. The dataset is divided into three subsets: train set, extra set and test set. The extra set is a large set of easy samples and train set is a smaller set of more difficult samples. Since we are given no information about how the sampling of these images was done, we assume a random order to construct our validation set. We compose our validation set with 2/3 from training samples (400 per class) and 1/3 from extra samples (200 per class), yielding a total of 6000 samples. This distribution allows to measure success on easy samples but puts more emphasis on difficult ones.\nSamples are pre-processed with a local contrast normalization (with a 7x7 kernel) on the Y channel of the YUV space followed by a global contrast normalization over each channel. No sample distortions were used to improve invariance."
    }, {
      "heading" : "3.2 Architecture Details",
      "text" : "The ConvNet has 2 stages of feature extraction and a two-layer non-linear classifier. The first convolution layer produces 16 features with 5x5 convolution filters while the second convolution layer outputs 512 features with 7x7 filters. The output to the classifier also includes inputs from the first layer, which provides local features/motifs to reinforce the global features. The classifier is a 2-layer non-linear classifier with 20 hidden units. Hyper-parameters such as learning rate, reg-\nularization constant and learning rate decay were tuned on the validation set. We use stochastic gradient descent as our optimization method and shuffle our dataset after each training iteration.\nFor the pooling layers, we compare Lp-pooling for the value p = 1, 2, 4, 8, 12, 16, 32,∞ on the validation set and use the best performing pooling on the final testing. The performance of different pooling methods on the validation set can be seen in Figure 5. Insights from [1] tell us that the optimal value of p varies for different input spaces and there is no single globally optimal value for p. For our validation data, we observe that p = 2, 4, 12 give the best performance (5.62%, 5.64% and 5.61% respectively). Max-pooling, which corresponds to p = ∞ yielded a validation error rate of 7.57%."
    }, {
      "heading" : "4 Results & Future Work",
      "text" : "Our experiments demonstrate a clear advantage of Lp pooling with 1 < p < ∞ on this dataset in validation (Figure 5) and test (Average pooling is 3.58 points inferior to L2 pooling in Table 2). With L4 pooling, we obtain a state-of-the-art performance on the test set with an accuracy of 94.85% compared to the previous best of 90.6% (Table 2). We also show that using multi-stage features gives only a slight increase in performance, compared to the performance increase seen in other vision applications.\nAdditionally, it is important to note that our approach is trained fully supervised only, whereas the best previous methods are unsupervised learning methods (kmeans, auto-encoders). We shall, in the future, run experiments with unsupervised learning, to compare the accuracy improvement that can be attributed to supervision. Figure 6 shows the validation samples with highest energy. Many of these seem to exhibit large scale variations, future work could address this problem by introducing artificial scale deformations during training."
    } ],
    "references" : [ {
      "title" : "A theoretical analysis of feature pooling in vision algorithms",
      "author" : [ "Y. Boureau", "J. Ponce", "Y. LeCun" ],
      "venue" : "In Proc. International Conference on Machine learning,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "A committee of neural networks for traffic sign classification",
      "author" : [ "D.C. Ciresan", "U. Meier", "J. Masci", "J. Schmidhuber" ],
      "venue" : "In International Joint Conference on Neural Networks,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Character recognition in natural images",
      "author" : [ "T.E. de Campos", "B.R. Babu", "M. Varma" ],
      "venue" : "In Proceedings of the International Conference on Computer Vision Theory and Applications,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Human tracking using convolutional neural networks",
      "author" : [ "J. Fan", "W. Xu", "Y. Wu", "Y. Gong" ],
      "venue" : "Neural Networks, IEEE Transactions on,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Complex cell pooling and the statistics of natural images",
      "author" : [ "A. Hyvrinen", "U. Kster" ],
      "venue" : "In Computation in Neural Systems,,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2005
    }, {
      "title" : "Learning invariant features through topographic filter maps",
      "author" : [ "K. Kavukcuoglu", "M. Ranzato", "R. Fergus", "Y. Le- Cun" ],
      "venue" : "In Proc. International Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "Reading digits in natural images with unsupervised feature learning",
      "author" : [ "Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng" ],
      "venue" : "In NIPS Workshop on Deep Learning and Unsupervised Feature Learning,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "Traffic signs and pedestrians vision with multi-scale convolutional networks",
      "author" : [ "P. Sermanet", "K. Kavukcuoglu", "Y. LeCun" ],
      "venue" : "In Snowbird Machine Learning Workshop,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Eblearn: Open-source energy-based learning in c++",
      "author" : [ "P. Sermanet", "K. Kavukcuoglu", "Y. LeCun" ],
      "venue" : "In Proc. International Conference on Tools with Artificial Intelligence",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Traffic sign recognition with multi-scale convolutional networks",
      "author" : [ "P. Sermanet", "Y. LeCun" ],
      "venue" : "In Proceedings of International Joint Conference on Neural Networks,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "A model of neuronal responses in visual area",
      "author" : [ "E.P. Simoncelli", "D.J. Heeger" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1997
    }, {
      "title" : "The German Traffic Sign Recognition Benchmark: A multi-class classification competition",
      "author" : [ "J. Stallkamp", "M. Schlipsing", "J. Salmen", "C. Igel" ],
      "venue" : "In IEEE International Joint Conference on Neural Networks,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Digit classification on signboards for telephone number recognition",
      "author" : [ "T. Yamaguchi", "Y. Nakano", "M. Maruyama", "H. Miyao", "T. Hananoi" ],
      "venue" : "In ICDAR,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "Linear spatial pyramid matching using sparse coding for image classification",
      "author" : [ "J. Yang", "K. Yu", "Y. Gong", "T. Huang" ],
      "venue" : "In in IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "[8] recently introduced a new digit classification dataset of house numbers extracted from street level images.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "Previous approaches in classifying characters and digits from natural images used multiple hand-crafted features [3] and template-matching [14].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 12,
      "context" : "Previous approaches in classifying characters and digits from natural images used multiple hand-crafted features [3] and template-matching [14].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 6,
      "context" : "[8] demonstrated the superiority of learned features over hand-designed ones.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "was also previously shown among others in a traffic sign classification challenge [13] where two independent teams obtained the best performance against various other approaches using ConvNets [11, 2].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 9,
      "context" : "was also previously shown among others in a traffic sign classification challenge [13] where two independent teams obtained the best performance against various other approaches using ConvNets [11, 2].",
      "startOffset" : 193,
      "endOffset" : 200
    }, {
      "referenceID" : 1,
      "context" : "was also previously shown among others in a traffic sign classification challenge [13] where two independent teams obtained the best performance against various other approaches using ConvNets [11, 2].",
      "startOffset" : 193,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "[8] also show superior results with unsupervised learning, we however only report results with fully-supervised training.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "We use the traditional ConvNet architecture augmented with different pooling methods and with multi-stage features [11].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 8,
      "context" : "This work was implemented with the EBLearn 1 C++ open-source framework [10].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 10,
      "context" : "Lp pooling is a biologically inspired pooling layer modelled on complex cells [12, 5] who’s operation can be summarized in equation (1), where G is a Gaussian kernel, I is the input feature map and O is the output feature map.",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 4,
      "context" : "Lp pooling is a biologically inspired pooling layer modelled on complex cells [12, 5] who’s operation can be summarized in equation (1), where G is a Gaussian kernel, I is the input feature map and O is the output feature map.",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 5,
      "context" : "Lp-pooling has been used previously in [6, 15] and a theoretical analysis of this method is described in [1].",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 13,
      "context" : "Lp-pooling has been used previously in [6, 15] and a theoretical analysis of this method is described in [1].",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 0,
      "context" : "Lp-pooling has been used previously in [6, 15] and a theoretical analysis of this method is described in [1].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : "MS features have consistently improved performance in other work [4, 11, 9] and in this work as well (Figure 4).",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 9,
      "context" : "MS features have consistently improved performance in other work [4, 11, 9] and in this work as well (Figure 4).",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : "MS features have consistently improved performance in other work [4, 11, 9] and in this work as well (Figure 4).",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 6,
      "context" : "The SVHN classification dataset [8] contains 32x32 images with 3 color channels.",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 7,
      "context" : "Pedestrians detection (INRIA) [9] 14.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "Traffic Signs classification (GTSRB) [11] 1.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "Insights from [1] tell us that the optimal value of p varies for different input spaces and there is no single globally optimal value for p.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 6,
      "context" : "Performance reported by [8] with the additional Supervised ConvNet with state-of-the-art accuracy of 94.",
      "startOffset" : 24,
      "endOffset" : 27
    } ],
    "year" : 2012,
    "abstractText" : "We classify digits of real-world house numbers using convolutional neural networks (ConvNets). ConvNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are handdesigned, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multistage features and by using Lp pooling and establish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2% error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at eblearn.sf.net.",
    "creator" : "gnuplot 4.4 patchlevel 4"
  }
}