{
  "name" : "1401.4605.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Consistency Techniques for Flow-Based Projection-Safe Global Cost Functions in Weighted Constraint Satisfaction",
    "authors" : [ "J.H.M. Lee", "K.L. Leung" ],
    "emails" : [ "JLEE@CSE.CUHK.EDU.HK", "KLLEUNG@CSE.CUHK.EDU.HK" ],
    "sections" : [ {
      "heading" : null,
      "text" : "solutions with the minimum cost. Weighted constraint satisfaction is a framework for modeling such problems, which consists of a set of cost functions to measure the degree of violation or preferences of different combinations of variable assignments. Typical solution methods for weighted constraint satisfaction problems (WCSPs) are based on branch-and-bound search, which are made practical through the use of powerful consistency techniques such as AC*, FDAC*, EDAC* to deduce hidden cost information and value pruning during search. These techniques, however, are designed to be efficient only on binary and ternary cost functions which are represented in table form. In tackling many real-life problems, high arity (or global) cost functions are required. We investigate efficient representation scheme and algorithms to bring the benefits of the consistency techniques to also high arity cost functions, which are often derived from hard global constraints from classical constraint satisfaction.\nThe literature suggests some global cost functions can be represented as flow networks, and the minimum cost flow algorithm can be used to compute the minimum costs of such networks in polynomial time. We show that naive adoption of this flow-based algorithmic method for global cost functions can result in a stronger form of ∅-inverse consistency. We further show how the method can be modified to handle cost projections and extensions to maintain generalized versions of AC* and FDAC* for cost functions with more than two variables. Similar generalization for the stronger EDAC* is less straightforward. We reveal the oscillation problem when enforcing EDAC* on cost functions sharing more than one variable. To avoid oscillation, we propose a weak version of EDAC* and generalize it to weak EDGAC* for non-binary cost functions. Using various benchmarks involving the soft variants of hard global constraints ALLDIFFERENT, GCC, SAME, and REGULAR, empirical results demonstrate that our proposal gives improvements of up to an order of magnitude when compared with the traditional constraint optimization approach, both in terms of time and pruning."
    }, {
      "heading" : "1. Introduction",
      "text" : "Constraint satisfaction problems (CSPs) occur in all walks of industrial applications and computer science, such as scheduling, bin packing, transport routing, type checking, diagram layout, just to name a few. Constraints in CSPs are functions returning true or false. These constraints are hard in the sense that they must be satisfied. In over-constrained and optimization scenarios, hard constraints have to be relaxed or softened. The weighted constraint satisfaction framework adopt soft constraints as cost functions returning a non-negative integer with an upper bound ⊤. Solution techniques for solving weighted constraint satisfaction problems (WCSPs) are made practi-\nc©2012 AI Access Foundation. All rights reserved.\ncal by enforcing various consistency notions during branch-and-bound search, such as NC*, AC*, FDAC* (Larrosa & Schiex, 2004, 2003) and EDAC* (de Givry, Heras, Zytnicki, & Larrosa, 2005). These enforcement techniques, however, are designed to be efficient only on binary and ternary cost functions which are represented in table form. On the other hand, many real-life problems can be modelled naturally by global cost functions of high arities. We investigate efficient representation scheme and algorithms to bring the benefits of the existing consistency techniques for binary and ternary cost functions to also high arity cost functions, which are often derived from hard global constraints from classical constraint satisfaction.\nIn existing WCSP solvers, these high arity cost functions are delayed until they become binary or ternary during search. The size of the tables is also a concern. The lack of efficient handling of high arity global cost functions in WCSP systems greatly restricts the applicability of WCSP techniques to more complex real-life problems. To overcome the difficulty, we incorporate van Hoeve, Pesant, and Rousseau’s (2006) flow-based algorithmic method into WCSPs, which amounts to representing global cost functions as flow networks and computing the minimum costs of such networks using the minimum cost flow algorithm. We show that a naive incorporation of global cost functions into WCSPs would result in a strong form of the ∅-inverse consistency (Zytnicki, Gaspin, & Schiex, 2009), which is still relatively weak in terms of lower bound estimation and pruning. The question is then whether we can achieve stronger consistencies such as GAC* and FDGAC*, the generalized versions of AC* and FDAC* respectively, for non-binary cost functions efficiently. Consistency algorithms for (G)AC* and FD(G)AC* involve three main operations: (a) computing the minimum cost of the cost functions when a variable x is fixed with value v, (b) projecting the minimum cost of a cost function to the unary cost functions for x at value v, and (c) extending unary costs to the related high arity cost functions. These operations allow cost movements among cost functions and shifting of costs to increase the global lower bound of the problem, which implies more opportunities for domain value prunings. Part (a) is readily handled using the minimum cost flow (MCF) algorithm as proposed in van Hoeve et al.’s method. However, parts (b) and (c) modify the cost functions, which can possibly destroy the required flow-based structure of the cost functions required by van Hoeve et al.’s method. To overcome the difficulty, we propose and give sufficient conditions for the flow-based projection-safety property. If a global cost function is flowbased projection-safe, the flow-based property of the cost function is guaranteed to be retained no matter how many times parts (b) and (c) are performed. Thus, the MCF algorithm can be applied throughout the enforcements of GAC* and FDGAC* to increase search efficiency.\nA natural next step is to generalize also the stronger consistency EDAC* (de Givry et al., 2005) to EDGAC*, but this turns out to be non-trivial. We identify and analyze an inherent limitation of EDAC* similar to the case of Full AC* (de Givry et al., 2005). ED(G)AC* enforcement will go into oscillation if two cost functions share more than one variable, which is common when a problem involves high arity cost functions. Sanchez, de Givry, and Schiex (2008) did not mention the oscillation problem but their method for enforcing EDAC* for the special case of ternary cost functions would avoid the oscillation problem. In this paper, we give a weak form of EDAC*, which can be generalized to weak EDGAC* for cost functions of any arity. Most importantly, weak EDAC* is reduced to EDAC* when no two cost functions share more than one variable. Weak EDGAC* is stronger than FDGAC* and GAC*, but weaker than VAC (Cooper, de Givry, Sanchez, Schiex, Zytnicki, & Werner, 2010). We also give an efficient algorithm to enforce weak EDGAC*.\nBased on the theoretical results, we prove that some of the soft variants of ALLDIFFERENT, GCC, SAME, and REGULAR constraints are flow-based projection-safe, and give polynomial time\nalgorithms to enforce GAC*, FDGAC* and also weak EDGAC* on these cost functions. Experiments are carried out on different benchmarks featuring the proposed global cost functions. Empirical results coincide with the theoretical prediction on the relative strengths of the various consistency notions and the complexities of the enforcement algorithms. Our experimental results also confirm that stronger consistencies such as GAC*, FDGAC* and weak EDGAC* are worthwhile and essential in making global cost functions in WCSP practical. In addition, the reified approach (Petit, Régin, & Bessière, 2000) and strong ∅IC are too weak in estimating useful lower bounds and pruning the search space in branch-and-bound search.\nThe rest of the paper is organized as follows. Section 2 gives the necessary definitions and background, while Section 3 gives related work. Generalized versions of existing consistency techniques for global cost functions are presented and compared in Section 4. Enforcement algorithms for these consistencies are exponential in general. We introduce the notion of flow-based projectionsafety, and describe polynomial time consistency enforcement algorithms for global cost functions enjoying the flow-based projection-safety property. In Section 5, we prove that the softened form of some common hard global constraints are flow-based projection-safe and give experimental results demonstrating the feasibility and efficiency of our proposal both in terms of runtime and search space pruning. Section 6 summarizes our contributions and shed light on possible directions for future research."
    }, {
      "heading" : "2. Background",
      "text" : "We give the preliminaries on weighted constraint satisfaction problems, global cost functions and network flows."
    }, {
      "heading" : "2.1 Weighted Constraint Satisfaction",
      "text" : "A weighted constraint satisfaction problem (WCSP) is a special case of valued constraint satisfaction (Schiex, Fargier, & Verfaillie, 1995) with a cost structure ([0, . . . ,⊤],⊕,≤). The structure contains a set of integers from 0 to ⊤ ordered by the standard ordering ≤. Addition ⊕ is defined by a ⊕ b = min(⊤, a + b), and subtraction ⊖ is defined only for a ≥ b, a ⊖ b = a− b if a 6= ⊤ and ⊤⊖ a = ⊤ for any a. Formally,\nDefinition 1 (Schiex et al., 1995) A WCSP is a tuple (X ,D, C,⊤), where:\n• X is a set of variables {x1, x2, . . . , xn} ordered by their indices;\n• D is a set of domains D(xi) for xi ∈ X , only one value of which can be assigned to xi;\n• C is a set of cost functions WS with different scope S = {xs1 , . . . , xsn} ⊆ X that maps a tuple ℓ ∈ L(S), where L(S) = D(xs1)× . . . D(xsn), to [0, . . . ,⊤].\nAn assignment of a set of variables S ⊆ X , written as {xs1 7→ vs1 , . . . , xsn 7→ vsn}, is to assign each variable xsi ∈ S to a value vsi ∈ D(xsi). When the context is clear and assuming an ordering by the variable indices, we abuse notations by considering an assignment also a tuple ℓ = (vs1 , . . . , vsn) ∈ L(S), where L(S) = D(xs1) × D(xs2) × . . . D(xsn). The notation ℓ[xsi ] denotes the value vsi assigned to xsi ∈ S, and ℓ[S\n′] denotes the tuple formed by projecting ℓ onto S′ ⊆ S.\nWithout loss of generality, we assume C = {W∅} ∪ {Wi | xi ∈ X} ∪ C+. W∅ is a constant nullary cost function. Wi is a unary cost function associated with each xi ∈ X . C+ is a set of cost\nfunctions WS with scope S containing two or more variables. If W∅ and {Wi} are not defined, we assume Wi(v) = 0 for all v ∈ D(xi) and W∅ = 0. To simplify the notation, we denote Ws1,s2,...,sn for the cost function on variables {xs1 , xs2 , . . . , xsn} if the context is clear.\nDefinition 2 Given a WCSP (X ,D, C,⊤). The cost of a tuple ℓ ∈ L(X ) is defined as cost(ℓ) = W∅ ⊕ ⊕\nxi∈X Wi(ℓ[xi]) ⊕\n⊕\nWS∈C+ WS(ℓ[S]). A tuple ℓ ∈ L(X ) is feasible if cost(ℓ) < ⊤, and\nis a solution of a WCSP if cost(ℓ) is minimum among all tuples in L(X ).\nWCSPs are usually solved with basic branch-and-bound search augmented with consistency techniques which prune infeasible values from variable domains and push costs into W∅ while preserving the equivalence of the problems, i.e. the cost of each tuple ℓ ∈ L(X ) is unchanged. Different consistency notions have been defined such as NC*, AC*, FDAC* (Larrosa & Schiex, 2004, 2003), and EDAC* (de Givry et al., 2005).\nDefinition 3 A variable xi is node consistent (NC*) if each value v ∈ D(xi) satisfies Wi(v) ⊕ W∅ < ⊤ and there exists a value v′ ∈ D(xi) such that Wi(v′) = 0. A WCSP is NC* iff all variables are NC*.\nProcedure enforceNC*() in Algorithm 1 enforces NC*, where unaryProject() moves unary costs towards W∅ while keeping the solution unchanged, and pruneVal() removes infeasible values. The variables Q, R, and S are global propagation queues used for further consistency enforcements explained in later sections. They are initially empty if not specified.\nProcedure enforceNC*() foreach xi ∈ X do unaryProject (xi);1 pruneVal ();2\nProcedure unaryProject(xi) α := min{Wi(v) | v ∈ D(xi)};3 W∅ := W∅ ⊕ α;4 foreach v ∈ D(xi) do Wi(v) := Wi(v) ⊖ α;5\nProcedure pruneVal() foreach xi ∈ X do6 flag := false;7 foreach v ∈ D(xi) s.t. Wi(v)⊕W∅ = ⊤ do8\nD(xi) := D(xi) \\ {v};9 flag := true;10\nif flag then11 // For further consistency enforcement. Assume initially empty if not specified Q := Q ∪ {xi};12 S := S ∪ {xi};13 R := R ∪ {xi};14\nAlgorithm 1: Enforce NC*\nBased on NC*, AC* and FDAC* have been developed for binary (Larrosa & Schiex, 2004, 2003) and ternary cost functions (Sanchez et al., 2008). Enforcing these consistency notions requires two equivalence preserving transformations besides NC* enforcement, namely projection and extension (Cooper & Schiex, 2004).\nA projection, written as Project(WS,Wi,v,α), transforms (WS ,Wi) to (W ′S ,W ′ i ) with respect to a value v ∈ D(xi) and a cost α, where α ≤ min{WS(ℓ) | ℓ[xi] = v ∧ ℓ ∈ L(S)}, such that:\n• W ′i (u) =\n{\nWi(u)⊕ α if u = v, Wi(u) otherwise.\n• W ′S(ℓ) =\n{\nWS(ℓ)⊖ α if ℓ[xi] = v, WS(ℓ) otherwise.\nAn extension, written as Extend(WS,Wi,v,α), transforms (WS ,Wi) to (W ′′S ,W ′′ i ) with\nrespect to a value v ∈ D(xi) and a cost α, where α ≤ Wi(v), such that:\n• W ′′i (u) =\n{\nWi(u)⊖ α if u = v, Wi(u) otherwise.\n• W ′′S (ℓ) =\n{\nWS(ℓ)⊕ α if ℓ[xi] = v, WS(ℓ) otherwise."
    }, {
      "heading" : "2.2 Global Constraints and Global Cost Functions",
      "text" : "A global constraint is a constraint with special semantics. They are usually with high arity, and thus cannot be propagated efficiently with standard consistency algorithms. With their special semantics, special propagation algorithms can be designed to achieve efficiency.\nA global cost function is the soft variant of a hard global constraint. The cost of each tuple indicates how much the tuple violates the corresponding global constraint. One global constraint can give rise to different global cost functions using different violation measures. A global cost function returns 0 if the tuple satisfies the corresponding global constraint. The notation SOFT GCµ denotes the global cost function derived from a global constraint GC using a violation measure µ. For instance, the ALLDIFFERENT constraint has two soft variants.\nDefinition 4 (Petit, Régin, & Bessière, 2001) The cost function SOFT ALLDIFFERENTvar returns the minimum number of variable assignments that needed to be changed so that the tuple contains only distinct values; while SOFT ALLDIFFERENTdec returns the number of pairs of variables having the same assigned value."
    }, {
      "heading" : "2.3 Flow Theory",
      "text" : "Definition 5 A flow network G = (V,E,w, c, d) is a connected directed graph (V,E), in which each edge e ∈ E has a weight we, a capacity ce, and a demand de ≤ ce.\nAn (s, t)-flow f from a source s ∈ V to a sink t ∈ V of a value α in G is defined as a mapping from E to real numbers such that:\n• ∑ (s,u)∈E f(s,u) = ∑ (u,t)∈E f(u,t) = α;\n• ∑ (u,v)∈E f(u,v) = ∑ (v,u)∈E f(v,u) ∀ v ∈ V \\ {s, t};\n• de ≤ fe ≤ ce ∀ e ∈ E.\nFor simplicity, we call an (s, t)-flow as a flow if s and t have been specified.\nDefinition 6 The cost of a flow f is defined as cost(f) = ∑\ne∈E wefe. A minimum cost flow problem of a value α is to find the flow whose value is α and cost is minimum.\nIf α is not given, it is assumed to be the maximum value among all flows. To solve minimum cost flow problems, various approaches have been developed. Two of those are the successive shortest path and cycle-cancelling algorithms (Lawler, 1976). Both algorithms focus on the computation in the residual network of the corresponding flow network.\nDefinition 7 Given a flow f in the network G = (V,E,w, c, d). The residual network Gres = (V,Eres, wres, cres, dres) is defined as:\n• Eres = {(u, v) ∈ e | f(u,v) < c(u,v)} ∪ {(v, u) ∈ e | f(u,v) > d(u,v)};\n• wres(u,v) =\n{\nw(u,v) ,if f(u,v) < c(u,v) −w(u,v) ,if f(v,u) > d(v,u)\n• cres(u,v) =\n{\nc(u,v) − f(u,v) ,if f(u,v) < c(u,v) f(u,v) − d(u,v) ,if f(v,u) > d(v,u)\n• drese = 0, for all e ∈ E;\nThe successive shortest path algorithm successively increases flow values of the edges along the shortest paths between s and t in the residual network until the value of flow reaches α or no more paths can be found. The cycle-cancelling algorithm reduces the cost of the given flow to minimum by removing negative cycles in the induced residual network.\nIn consistency enforcement with flow, we usually deal with the following problem: consider a (s, t)-flow f in a network G = (V,E,w, c, d) with minimum cost, and an edge ē ∈ E. The problem is to determine whether increasing (or decreasing) fē by one unit keeps the flow value unchanged, and compute the minimal cost of the new resultant flow if possible. Again, such a problem can be solved using the residual network Gres (Régin, 2002; van Hoeve et al., 2006): we compute the shortest path P from v′ to u′ in Gres, where ē = (u′, v′) ∈ E. If P exists, the value of the flow is unchanged if fē is increased by one unit. The new minimum cost can be computed by the following theorem.\nTheorem 1 (Régin, 2002; van Hoeve et al., 2006) Suppose f ′ is the resultant flow by increasing fē by one unit. Then the minimum value of cost(f ′) is cost(f) + wresē + ∑ e∈P w res e .\nTheorem 1 reduces the problem into finding a shortest path from v′ to u′, which can be made incremental for consistency enforcement. If we want to reduce a unit flow from an edge, we can apply similar methods to those used in Theorem 1."
    }, {
      "heading" : "3. Related Work",
      "text" : "Global cost functions can be handled using constraint optimization, which focuses on efficient computation of min{WS(ℓ) | ℓ ∈ L(S)} and enforcing GAC on their hard constraint forms WS(ℓ) ≤ zS , where zS is the variable storing costs (Petit et al., 2001). Van Hoeve et al. (2006)\ndevelop a framework for global cost functions representable by flow networks, whose computation is polynomial in the size of networks. Beldiceanu (2000) and Beldiceanu, Carlsson and Petit (2004) further develop a representation scheme for global cost functions using a graph-based approach and an automaton approach. Under their framework, the computation of all global cost functions can be reduced to only considering a fixed set of global cost functions, e.g. the SOFT REGULAR functions.\nOn the other hand, to efficiently remove more search space during WCSPs solving, various consistency notions have been developed. Examples are NC* (Larrosa & Schiex, 2004), BAC∅ (Zytnicki et al., 2009), AC* (Larrosa & Schiex, 2004), FDAC* (Larrosa & Schiex, 2003), and EDAC* (de Givry et al., 2005). Stronger consistency notions, namely OSAC and VAC (Cooper et al., 2010), are also defined, but enforcement requires a relaxation of the cost valuation structure V (⊤) to rational numbers, and current implementations are efficient only on binary WCSPs. For ternary cost functions, AC, FDAC and EDAC are introduced (Sanchez et al., 2008). Cooper (2005) incorporates the concept of k-consistency into WCSPs to form complete k-consistency. However, the time and space complexities increase exponentially as the problem size increases, making complete k-consistency impractical to enforce for general WCSPs."
    }, {
      "heading" : "4. Consistency Notions for Global Cost Functions",
      "text" : "In this section, we discuss four consistency notions for high-arity cost functions: (1) strong ∅- inverse consistency (strong ∅IC), (2) generalized arc consistency (GAC*), (3) full directional generalized arc consistency(FDGAC*), and (4) generalized EDAC*. These consistency notions require exponential time to enforce in general, but flow-based global cost functions (van Hoeve et al., 2006) enjoy polynomial time enforcement."
    }, {
      "heading" : "4.1 Strong ∅-Inverse Consistency",
      "text" : "Strong ∅-inverse consistency is based on ∅-inverse consistency (∅IC) (Zytnicki et al., 2009).\nDefinition 8 (Zytnicki et al., 2009) Given a WCSP P = (X ,D, C,⊤). A cost function WS ∈ C is ∅-inverse consistent (∅IC) if there exists a tuple ℓ ∈ L(S) such that WS(ℓ) = 0. A WCSP is ∅IC iff all cost functions are ∅IC.\nThe procedure enforce∅IC() in Algorithm 2 enforces ∅IC. Each cost function WS is made ∅IC by lines 3 to 6, which move costs from WS to W∅ by simple arithmetic operations.\nFunction enforce∅IC() flag := false;1 foreach WS ∈ C do2 α := min{WS(ℓ) | ℓ ∈ L(S)};3 W∅ := W∅ ⊕ α;4 foreach ℓ ∈ L(S) do WS(ℓ) := WS(ℓ)⊖ α;5 if α > 0 then flag := true;6\nreturn flag;7\nAlgorithm 2: Enforcing ∅IC on a WCSP\nThe time complexity of enforce∅IC() in Algorithm 2 depends on the time complexities of lines 3 and 5. Line 3 computes the minimum cost and line 5 modifies the cost of each tuple\nto maintain equivalence. In general, these two operations are exponential in the arity of the cost function. However, the first operation can be reduced to polynomial time for a global cost function. One such example is flow-based global cost functions (van Hoeve et al., 2006).\nDefinition 9 (van Hoeve et al., 2006) A global cost function WS is flow-based if WS can be represented as a flow network G = (V,E,w, c, d) such that\nmin{cost(f) | f is the max. {s, t}-flow of G} = min{WS(ℓ) | ℓ ∈ L(S)},\nwhere s ∈ V is the fixed source and t ∈ V is the fixed destination.\nFor examples, the cost function SOFT ALLDIFFERENTdec (S) returns the number of pairs of variables in S that share the same value, and is shown to be flow-based (van Hoeve et al., 2006). An example of its corresponding flow network, where S = {x1, x2, x3, x4}, is shown in Figure 1. All edges have a capacity of 1. The numbers on the edges represent the weight of the edges. If an edge has no number, the edge has zero weight. The thick lines show the flow corresponding to the tuple ℓ = (a, c, b, b) having a cost of 1.\nWith flow-based cost functions, the first operation (computing the minimum cost) can be reduced to time polynomial to the network size for those constraints. The second operation can be reduced to constant time using the ∆S data structure suggested by Zytnicki et al. (2009). Instead of deducting the projected value α from each tuple in WS , we simply store the projected value in ∆S . When we want to know the actual value of WS , we compute WS ⊖∆S .\nEnforcing ∅IC only increases W∅ but does not help reduce domain size. Consider the WCSP in Figure 2. It is ∅IC, but the value c ∈ D(x1) cannot be a part of any feasible tuple. All tuples associated with the assignment {x1 7→ c} must have a cost of at least 4: 1 from W∅, 2 from W1, and 1 from W1,2. To allow domain reduction, extra conditions are added to ∅IC to form strong ∅IC.\nDefinition 10 Given a WCSP P = (X ,D, C,⊤). Consider a non-unary cost function WS ∈ C+ and a variable xi ∈ S. A tuple ℓ ∈ L(S) is the ∅-support of a value v ∈ D(xi) with respect to WS iff ℓ[xi] = v and W∅ ⊕Wi(v)⊕WS(ℓ) < ⊤. The cost function WS is strong ∅IC iff it is ∅IC, and each value in each variable in S has a ∅-support with respect to WS . A WCSP is strong ∅IC if it is ∅IC and all non-unary cost functions are strong ∅IC.\nFor instance, the WCSP in Figure 2 is not strong ∅IC. The value c ∈ D(x1) does not have a ∅- support, since W∅ ⊕W1(c)⊕min{W1,2(ℓ) | ℓ[x1] = c ∧ ℓ ∈ L({x1, x2})} = ⊤ = 4. Removal of c ∈ D(x1) makes it so.\nStrong ∅IC collapses to GAC in classical CSPs when WCSPs collapse to CSPs. Although its definition is similar to BAC∅ (Zytnicki et al., 2009), their strengths are incomparable. BAC∅ gathers cost information from all cost functions on the boundary values, while we only consider the information from one non-unary cost function for all individual values.\nThe procedure enforceS∅IC() in Algorithm 3 enforces strong ∅IC, based on the W-AC*3() Algorithm (Larrosa & Schiex, 2004). The algorithm maintains a propagation queue Q of variables. Cost functions involving variables in Q are potentially not strong ∅IC. At each iteration, an arbitrary variable xj is removed from Q by the function pop() in constant time. The algorithm enforces strong ∅IC for the cost functions involving xj from lines 4 to 6. The existence of ∅-support is enforced by find∅Support(). If domain reduction occurs (find∅Support() returns true), or W∅ increases (enforce∅IC() returns true), variables are pushed onto Q at lines 6 and 7 respectively, indicating that ∅IC are potentially broken. If the algorithm terminates, i.e. Q = ∅, no variables are pushed into Q at line 6, or Q is not set to X at line 7. It implies all variables are strong ∅IC and the WCSP is ∅IC. Thus the WCSP is strong ∅IC after execution.\nProcedure enforceS∅IC() Q := X ;1 while Q 6= ∅ do2 xj := pop (Q);3 foreach WS ∈ C+ s.t. xj ∈ S do4 foreach xi ∈ S \\ {xj} do5 if find∅Support (WS , xi) then Q := Q ∪ {xi};6\nif enforce∅IC () then Q := X ;7\nFunction find∅Support(WS, xi) flag := false;8 foreach v ∈ D(xi) do9\nα := min{WS(ℓ) | ℓ[xi] = v};10 if W∅ ⊕Wi(v)⊕ α = ⊤ then11 D(xi) := D(xi) \\ {v};12 flag := true;13\nreturn flag;14\nAlgorithm 3: Enforcing strong ∅IC of a WCSP\nThe procedure enforceS∅IC() is correct and must terminate. Its complexity can be analyzed by abstracting the worst-case time complexities of find∅Support() and enforce∅IC() as\nfstrong and f∅IC respectively. Using an augment similar to the proof of Larrosa and Schiex’s (2004) Theorems 12 and 21, the complexity can be stated as follows.\nTheorem 2 The procedure enforceS∅IC() a time complexity of O(r2edfstrong+ndf∅IC), where r is the maximum arity of all cost functions, d is maximum domain size, e = |C+| and n = |X |.\nProof: The while loop at line 2 iterates at most O(nd) times. In each iteration, line 6 executes at most O(r · |N(j)|) times, where N(j) is the set of soft constraints restricting xj . Since line 7 executes at most O(nd) times, the overall time complexity is O(rdfstrong · ∑n j=1 |N(j)|+ ndf∅IC) = O(r2edfstrong+ndf∅IC). O( ∑n\nj=1 |N(j)|) = O(re) holds since each cost function counts at most r times in\n∑n j=1 |N(j)|. Thus, it must terminate.\nCorollary 1 The procedure enforceS∅IC() must terminate. The resultant WCSP is strong ∅IC, and equivalent to the original WCSP.\nIn general, due to enforce∅IC() and find∅Support(), enforcing strong ∅IC is exponential in r. As discussed before, enforce∅IC() can be reduced to polynomial time for flow-based global cost functions. Similarly, find∅Support() can be executed efficiently and incrementally for flow-based global cost functions since line 10 can be computed in polynomial time using minimum cost flow.\nAnother property we are interested in is confluence. A consistency Ψ is confluent if enforcing Ψ always transforms a problem P into a unique problem P ′ which is Ψ. AC* is not confluent (Larrosa & Schiex, 2004). With different variable and/or cost function orderings, AC* enforcement can lead to different equivalent WCSPs with different values of W∅. BAC∅ is confluent (Zytnicki et al., 2009). Following the proofs of Propositions 3.3 and 4.3 by Zytnicki et al., it can be shown that strong ∅IC is also confluent.\nTheorem 3 (Confluence) Given a WCSP P = (X ,D, C,⊤), there exists a unique WCSP P ′ = (X ,D′, C′,⊤) which is strong ∅IC and equivalent to P .\nThe above concludes the theoretical analysis of strong ∅IC. In the following, we compare the strength of strong ∅IC with the classical consistency notions used in constraint optimization. Following Petit et al. (2000), we define the reified form of a WCSP as follows:\nDefinition 11 (Petit et al., 2000) Given a WCSP P = (X ,D, C,⊤). The reified form, reified(P ), of P is a constraint optimization problem (COP) (X h,Dh, Ch, obj), where:\n• X h = X ∪ Z , where Z = {zS | WS ∈ C \\ {W∅}} are the cost variables.\n• Dh(xi) = D(xi) for xi ∈ X , and Dh(zS) = {0, . . . ,⊤ − W∅ − 1} for each zS ∈ Z . If ⊤−W∅ < 1, Dh(zS) = ∅.\n• Ch contains the reified constraints Ch S∪{zS} , which are the hard constraints associated with\neach WS ∈ C \\ {W∅} defined as WS(ℓ) ≤ zS for each tuple ℓ ∈ L(S). Ch also contains ChZ defined as W∅ ⊕ ⊕\nzS∈Z zS < ⊤.\n• The objective is to minimize obj, where obj = W∅ ⊕ ⊕\nzS∈Z zS .\nFinding the optimal solution of reified(P ) is equivalent to solving P . However, enforcing GAC on reified(P ) cannot remove more values than enforcing strong ∅IC of P . It is because strong ∅IC of P implies GAC of reified(P ) but not vice versa.\nIn general, we define the strength comparison as follows.\nDefinition 12 Given a problem P representable by two models φ(P ) and ψ(P ). A consistency Φ on φ(P ) is strictly stronger than another consistency Ψ on ψ(P ), written as Φ on φ(P ) > Ψ on ψ(P ), or Φ > Ψ if φ(P ) = ψ(P ), iff ψ(P ) is Ψ whenever φ(P ) is Φ, but not vice versa.\nZytnicki et al. (2009) also define consistency strength comparison in terms of unsatisfiability detection, which is subsumed by our new definition. If Φ on φ(P ) implies Ψ on ψ(P ), and enforcing Ψ on ψ(P ) detects unsatisfiability, enforcing Φ on φ(P ) can detect unsatisfiability as well.\nGiven a WCSP P = (X ,D, C,⊤). We show strong ∅IC on P is stronger than GAC on reified(P ) by the following theorem.\nTheorem 4 Strong ∅IC on P > GAC on reified(P ).\nProof: Figure 2 has given an example that a WCSP whose reified COP is GAC may not be strong ∅IC. We have to show that strong ∅IC on P implies GAC on reified(P ).\nFirst, ChZ is GAC. If |C| ≤ 1, the constraint is obviously GAC. If |C| > 1, for each vSi ∈ D(zSi), to satisfy the constraint, we just let other cost variables take the value 0, i.e. supports for each vSi ∈ D(zSi) exist.\nBesides, Ch S∪{zS} is GAC. By the definition of ∅IC, there exists a tuple ℓ′ ∈ L(S) such that WS(ℓ ′) = 0. The tuple ℓ′ can form the support of vS ∈ D(zS) with respect to ChS∪{zS}. Besides, the ∅-support ℓ∅ of v ∈ D(xi), together with vS = WS(ℓ∅), forms a support for v ∈ D(xi). For a detailed comparison between strong ∅IC of WCSPs and GAC of the reified approach, readers can refer to the work of Leung (2009). When the cost functions are binary, strong ∅IC cannot be stronger than AC*. In the next section, we show this fact by proving GAC*, a generalized version of AC*, to be stronger than strong ∅IC."
    }, {
      "heading" : "4.2 Generalized Arc Consistency",
      "text" : "Definition 13 (Cooper & Schiex, 2004) Given a WCSP P = (X ,D, C,⊤). Consider a cost function WS ∈ C\n+ and a variable xi ∈ S. A tuple ℓ ∈ L(S) is a simple support of v ∈ D(xi) with respect to WS with xi ∈ S iff ℓ[xi] = v and WS(ℓ) = 0. A variable xi ∈ S is star generalized arc consistent (GAC*) with respect to WS iff xi is NC*, and each value vi ∈ D(xi) has a simple support ℓ with respect to WS . A WCSP is GAC* iff all variables are GAC* with respect to all related non-unary cost functions.\nThe definition is designed with practical considerations, and is slightly weaker than Definition 4.2 in the work of Cooper et al. (2010), which also requires WS(ℓ) = ⊤ if W∅ ⊕ ⊕\nxi∈S Wi(ℓ[xi]) ⊕\nWS(ℓ) = ⊤. GAC* collapses to AC* for binary cost functions (Larrosa & Schiex, 2004) and AC for ternary cost functions (Sanchez et al., 2008). GAC* is stronger than strong ∅IC, as a WCSP which is GAC* is also strong ∅IC, but not vice versa. We state without proof as follows.\nTheorem 5 GAC* > strong ∅IC.\nThe procedure enforceGAC*() in Algorithm 4 enforces GAC* for a WCSP (X ,D, C,⊤), based on the W-AC*3() Algorithm (Larrosa & Schiex, 2004). The propagation queue Q stores a set of variables xj . If xj ∈ Q, all variables involved in the same cost functions as xj are potentially not GAC*. Initially, all variables are in Q. A variable xj is pushed into Q only after values are removed from D(xj). At each iteration, an arbitrary variable xj is removed from the queue by the function pop() at line 4. The function findSupport() at line 7 enforces GAC* of xi with respect to WS by finding the simple supports. The infeasible values are removed by the function pruneVal() at line 10. If a value is removed from D(xi), the simple supports of other related variables may be destroyed. Thus, xi is pushed back to Q again by the procedure pruneVal(). If GAC*() terminates, all values in each variable domain must have a simple support. The WCSP is now GAC*.\nProcedure enforceGAC*() Q := X ;1 GAC* ();2\nProcedure GAC*() while Q 6= ∅ do3 xj := pop (Q);4 foreach WS ∈ C+ s.t. xj ∈ S do5 foreach xi ∈ S \\ {xj} do6 if findSupport (WS , xi) then7\n// For further consistency enforcement. Assume initially empty if not specified\nS := S ∪ {xi};8 R := R ∪ {xi};9\npruneVal ();10\nFunction findSupport(WS, xi) flag := false;11 foreach v ∈ D(xi) do12 α := min{WS(ℓ) | ℓ[xi] = v};13 if Wi(v) = 0 ∧ α > 0 then flag := true;14 Wi(v) := Wi(v)⊕ α;15 foreach ℓ ∈ L(S) s.t. ℓ[xi] = a do WS(ℓ) := WS(ℓ)⊖ α;16\nunaryProject (xi);17 return flag;18\nAlgorithm 4: Enforcing GAC* for a WCSP\nThe procedure enforceGAC*() in Algorithm 4 is correct and must terminate. The proof is similar to that of Theorem 2. By replacing fstrong by fGAC (the worst-case time complexities of findSupport()) and f∅IC by O(nd) (the complexity of pruneVal()), the complexity of Algorithm 4 can be stated as follows.\nTheorem 6 The procedure enforceGAC*() has a time complexity of O(r2edfGAC+n2d2), where n, d, e, and r are as defined in Theorem 2.\nCorollary 2 The procedure enforceGAC*() must terminate. The resultant WCSP is GAC*, and equivalent to the original WCSP.\nIn general, the procedure enforceGAC*() is exponential in the maximum arity of the cost function due to findSupport(). The function findSupport() consists of two operations: (1) finding the minimum cost of the tuple associated with {xi 7→ v} at line 13, and (2) performing projection at lines 15 and 16. The time complexity of the first operation is polynomial for a flowbased global cost function WS . The method introduced by van Hoeve et al. (2006) can be applied to the first operation as discussed in Section 4.1. However, the second operation modifies WS to W ′S , which requires changing the costs of an exponential number of tuples. Cooper and Schiex (2004) use a similar technique as the one by Zytnicki et al. (2009) (similar to the technique described in Section 4.1) to make the modification constant time. However, the resulting W ′S may not be flowbased, affecting the time complexity of the subsequent procedure calls. To resolve the issue, we introduce flow-based projection-safety. If WS is flow-based projection-safe, the flow property can be maintained throughout enforcement.\nDefinition 14 Given a property T . A global cost function WS is T projection-safe iff WS satisfies the property T , and for all W ′S derived from WS by a series of projections and extensions, W ′ S also satisfies T .\nIn other words, a T projection-safe cost function WS still satisfies T after any numbers of projections or extensions. This facilitates the use of T to derive efficient consistency enforcement algorithms. In the following, we consider a special form of T projection-safety, when T is the flow-based property.\nIn the following, we first define FB, and show that FB is the sufficient condition of flow-based projection-safety.\nDefinition 15 A global cost function satisfies FB if:\n1. WS is flow-based, with the corresponding network G = (V,E,w, c, d) with a fixed source s ∈ V and a fixed destination t ∈ V ;\n2. there exists a subjective function mapping each maximum flow f in G to each tuple ℓf ∈ L(S), and;\n3. there exists an injection mapping from an assignment {xi 7→ v} to a subset of edges Ē ⊆ E such that for all maximum flow f and the corresponding tuple ℓf , ∑\ne∈Ē fe = 1 whenever ℓf [xi] = v, and ∑ e∈Ē fe = 0 whenever ℓf [xi] 6= v\nLemma 1 Given WS satisfying FB. Suppose W ′S is obtained from Project(WS,Wi,v,α) or Extend(WS,Wi,v,α). Then W ′S also satisfies FB.\nProof: We only prove the part for projection, since the proof for extension is similar. We first show that W ′S is flow-based (condition 1). Assume G = (V,E,w, c, d) is the corresponding flow network of WS . After the projection, G can be modified to G′ = (V,E,w′, c, d), where w′(e) = w(e) − α if e ∈ Ē is an edge corresponding to {xi 7→ v} and w′(e) = w(e) otherwise. The resulting G′ is\nthe corresponding flow network of W ′S , since for the maximum flow f in G with minimum cost:\n∑\ne∈E\nw′efe = ∑\ne∈E\nwefe − α ∑\ne∈Ē\nfe\n= min{WS(ℓ) | ℓ ∈ L(S)} − α ∑\ne∈Ē\nfe\n= min{W ′S(ℓ) | ℓ ∈ L(S)}.\nMoreover, since the topology of G′ = (V,E,w′, c, d) is the same as that of G = (V,E,w, c, d), W ′S also satisfies conditions 2 and 3.\nTheorem 7 If a global cost function WS satisfies FB, then WS is flow-based projection-safe.\nProof: Initially, if no projection and extension is performed, directly from Definition 15, WS is flow-based. Assume W ′S is the cost function formed from WS after a series of projections and/or extensions. By Lemma 1, W ′S still satisfies FB and thus flow-based. Result follows.\nAs shown by Theorem 7, if a global cost function is flow-based projection-safe, it is always flow-based after projections and/or extensions. Besides, by checking the conditions in Definition 15, we can determine whether a global cost function is flow-based projection-safe.\nNote that the computation in the proof is performed under the standard integer set instead of V (⊤) for practical considerations. Further investigation is required if the computation can be restricted on V (⊤).\nBy using Theorem 7, we can apply the results by van Hoeve et al. (2006) to compute the value min{WS(ℓ) | ℓ[xi] = v ∧ ℓ ∈ L(S)} in polynomial time throughout GAC* enforcement. Besides, the proof gives an efficient algorithm to perform projection in polynomial time by simply modifying the weights of the corresponding edges.\nAgain, we use SOFT ALLDIFFERENTdec as an example. Van Hoeve et al. (2006) have shown that SOFT ALLDIFFERENTdec (S) satisfies conditions 1 and 2 in Definition 15. Besides, from the network structure shown in Figure 1, by taking Ē = {(xi, v)} for each assignment {xi 7→ v}, condition 3 can be satisfied. Thus, SOFT ALLDIFFERENTdec is flow-based projection-safe.\nConsider the flow network of the SOFT ALLDIFFERENTdec in Figure 1. Suppose we perform Project(SOFT ALLDIFFERENTdec(S),W1,a,1). The network is modified to the one in Figure 3, the weight of the edge (x1, a) in which is decreased from 0 to −1. The flow has a cost of 0, which is the cost of the tuple (a, c, b, b) after projection.\nIf a global cost function is flow-based projection-safe, findSupport() has a time complexity depending on the time complexity of computing the minimum cost flow and the shortest path from any two nodes in the network. The result is stated by the following theorem.\nTheorem 8 Given the time complexities of computing the minimum cost flow and the shortest path are K and SP respectively. If WS is flow-based projection-safe, findSupport() has a time complexity of O(K+ εd · SP), where d = max{|D(xi)| | xi ∈ S} and ε is the maximum size of Ē.\nProof: By Theorem 1, after finding a first flow by O(K), the minimum cost at line 13 can be found by augmenting the existing flow, which only requires O(SP). Line 15 can be done in constant time, while line 16 can be done as follows: (a) decrease the weights of all edges corresponding to xi 7→ v by α, and (b) augment the current flow to the one with new minimum cost by changing the flow values of the edges whose weights have been modified in the first step. The first step requires O(ε), while the second step requires O(ε · SP). At most ε edges are required to change their flow values to maintain minimality of the flow cost. Since unaryProject() requires O(d), the overall time is O(K + d(SP + ε · SP) + d) = O(K + εd · SP).\nThe time complexity for finding a shortest path in a graph SP varies by applying different algorithms. In general, SP = O(|V ||E|), as negative weights are introduced in the graph. However, it can be reduced by applying a potential value on each vertices, as in Johnson’s (1977) algorithm. For example, in Figure 3, we can increase the potential value of vertices a and t by 1, and the weight of the edges (b, t) and (c, t) by 1. This increases the cost of all paths from s to t by 1, and makes the weights of all edges non-negative. Dijkstra’s (1959) algorithm can thus be applied, reducing the time complexity to O(|E| + |V |log(|V |)).\nAlthough GAC* can be enforced in polynomial time for flow-based projection-safe global cost functions, the findSupport() function still requires runtime much higher than that for binary or ternary table cost functions in general. To optimize the performance of the solver, we can delay the consistency enforcement of global cost functions until all binary or ternary table cost functions are processed at line 5.\nFDAC* for binary cost functions (Larrosa & Schiex, 2003) suggests that a stronger consistency can be deduced by using the extension operator. We will discuss the generalized version of FDAC* for non-binary cost functions in the next section."
    }, {
      "heading" : "4.3 Full Directional Generalized Arc Consistency",
      "text" : "Definition 16 Given a WCSP P = (X ,D, C,⊤). Consider a cost function WS ∈ C+ and a variable xi ∈ S. A tuple ℓ is the full support of the value v ∈ D(xi) with respect to WS and a subset of variables U ⊆ S \\ {xi} iff ℓ[xi] = v and WS(ℓ) ⊕ ⊕\nxj∈U Wj(ℓ[xj ]) = 0. A variable xi is\ndirectional star generalized arc consistent (DGAC*) with respect to WS if it is NC* and each value v ∈ D(xi) has a full support with respect to {xu | xu ∈ S ∧u > i}. A WCSP is full directional star generalized arc consistent (FDGAC*) if it is GAC* and each variable is DGAC* with respect to all related non-unary cost functions.\nFDGAC* collapses to GAC when WCSPs collapse to CSPs. Moreover, FDGAC* collapses to FDAC* (Larrosa & Schiex, 2003) when the arity of the cost functions is two. However, FDGAC* is incomparable to FDAC for ternary cost functions (Sanchez et al., 2008). FDAC requires full supports with not only zero unary but also zero binary costs for the next variable in S only, while we only require all variables with full supports of zero unary costs.\nBy definition, FDGAC* is stronger than GAC* and also strong ∅IC.\nTheorem 9 FDGAC* > GAC* > strong ∅IC.\nThe procedure enforceFDGAC*() enforces FDGAC* for a WCSP, based on the FDAC*() Algorithm (Larrosa & Schiex, 2003). The propagation queues Q and R store a set of variables. If xj ∈ Q, all variables involved in the same cost functions as xj are potentially not GAC*; if xj ∈ R, the variables xi involved in the same cost functions as xj are potentially not DGAC*. When values are removed from the domain of variable xj , xj is pushed onto Q and R; when unary costs of the values in D(xj) are increased, xj is pushed to R. At each iteration, GAC* is maintained by the procedure GAC*(). DGAC* is then enforced by DGAC*(). Enforcing DGAC* follows the ordering from the largest index to the smallest index such that the full supports of values in the domains of variables with smaller indices are not destroyed by DGAC*-enforcement on those with larger indices. The variable with the largest index in R is removed from R by the function popMax(). By implementing R as a heap, popMax() requires only constant time. DGAC* enforcement is performed at line 10 by findFullSupport(). In the last step, NC* is re-enforced by pruneVal(). The iteration continues until all propagation queues are empty, which implies all values in each variable domain has a simple and full support, and all variables are NC*. The resultant WCSP is FDGAC*.\nProcedure enforceFDGAC*() R := Q := X ;1 while R 6= ∅ ∨Q 6= ∅ do2 GAC* ();3 DGAC* ();4 pruneVal ();5\nProcedure DGAC*() while R 6= ∅ do6 xu := popMax (R);7 foreach WS ∈ C+ s.t. xu ∈ S do8\nfor i = n DownTo 1 s.t. xi ∈ S \\ {xu} do9 if findFullSupport (WS , xi, S ∩ {xj | j > i}) then R := R ∪ {xi};101 S := S ∪ {xi} ; // For further consistency enforcement.12\nFunction findFullSupport(WS, xi, U ) foreach xj ∈ U do13 foreach vj ∈ D(xj) do14 foreach ℓ ∈ L(S) s.t. ℓ[xj ] = vj do WS(ℓ) := WS(ℓ)⊕Wj(vj);15 Wj(vj) := 0;16\nflag := findSupport (WS , xi);17 foreach xj ∈ U do findSupport (WS , xj );18 unaryProject (xi);19 return flag;20\nAlgorithm 5: Enforcing FDGAC* on a WCSP\nThe procedure enforceFDGAC*() in Algorithm 5 is correct and must terminate, the proof of which is similar to those of Theorems 3 and 4 by Larrosa and Schiex (2003). The worst-case time complexity of enforceFDGAC*() can be stated in terms of that of findFullSupport() (fDGAC) and findSupport() (fGAC) as follows.\nTheorem 10 The procedure enforceFDGAC*() has a time complexity of O(r2ed(nfDGAC + fGAC) + n 2d2), where n, d, e, and r are as defined in Theorem 2.\nProof: First we analyze the time complexity of enforcing DGAC*. Consider the procedure DGAC*() at line 6. The while-loop iterates at most O(n) times. Since no value is removed in the while-loop, once xi is processed at line 10, where i > j, it is not pushed back to R at line 11. Thus, line 10 executes at most O(r\n∑n j=0 |N(j)|) = O(r 2e) times, where N(j) is the set of cost functions restricting xj . Therefore, the time complexity of DGAC*() is O(r2efDGAC). Since DGAC*() executes at most O(nd) times throughout the global enforcement iteration. Thus the time spent on enforcing DGAC* is O(nr2edfDGAC)\nAlthough GAC*() is called O(nd) times, it does nothing if no values are removed from variable domains. Thus we count the number of times calling findSupport(). Since the variables are pushed into Q only when a value is removed, findSupport() only executes at most O(nd) times throughout the global enforcement iteration. Similar arguments apply to pruneVal() at line 10 inside GAC*() defined in Algorithm 4. With the proof similar to Theorem 6, the time spent on enforcing GAC* is O(r2edfGAC + n2d2).\nThe pruneVal at line 5 executes O(nd) times, and each time it requires a time complexity of O(nd). Therefore, the overall time complexity is O(r2ed(nfDGAC + fGAC) + n2d2).\nCorollary 3 The procedure enforceFDGAC*() must terminate. The resultant WCSP is FDGAC* and equivalent to the original WCSP.\nAgain, the complexity is exponential in the maximum arity due to the function findSupport() and findFullSupport(). In the following, we focus the discussion on findFullSupport(). The first part (lines 15 and 16) performs extensions to push all the unary costs back to WS . By the time we execute line 17, all unary costs Wj , where xj ∈ U , are 0, and enforcing GAC* for xi achieves the second requirement of DGAC* (each v ∈ D(xi) has a full support). Line 18 re-instates GAC* for all variables xj ∈ U . Note that success in line 17 guarantees that Wj(vj) = 0 for some value vj appearing in a tuple ℓ which makes WS(ℓ) = 0.\nAgain, flow-based projection-safety helps reduce the time complexity of findFullSupport() throughout the enforcement. The proof of Theorem 7 gives a polynomial time algorithm to perform extension and maintain efficient computation of min{WS(ℓ) | ℓ ∈ L(S)}. Flow-based projectionsafety can be guaranteed by Theorem 7, which requires checking conditions 1, 2, and 3 in the definition of flow-based projection-safety. The complexity result follows from Theorems 2 and 8.\nTheorem 11 If WS is a flow-based projection-safe global cost function, findFullSupport() has a time complexity of O(K + εrd · SP), where r, ε, d, K and SP are as defined in Theorems 2 and 8.\nProof: Similarly to Theorem 8, lines 13 to 16 can be performed as follows: (a) for each xj ∈ U and each value vj ∈ D(xj), increase the weights of all edges corresponding to {xj 7→ vj} by Wj(vj), and then reduce Wj(vj) to 0, and (b) find a flow with the new minimum cost in the new\nflow network. The first step can be done in O(εrd), as the size of U is bounded by the arity of the cost function r. The second step can be done in O(K), which also acts as preprocessing for findSupport() at lines 17 and 18. By Theorem 8, lines 17 and 18 can be done in O(rεd · SP). Thus, the overall complexity is O(r · εd+K+ rεd · SP) = O(K + εrd · SP).\nSimilarly to GAC*, the DGAC* enforcement for global cost functions can be delayed until all binary and ternary table cost functions are processed."
    }, {
      "heading" : "4.4 Generalizing Existential Directional Arc Consistency",
      "text" : "EDAC* (de Givry et al., 2005) can be generalized to EDGAC* using the full support definition as in FDGAC*. However, we find that naively generalizing EDAC* is not always enforceable, due to the limitation of EDAC*. In the following, we explain and provide a solution to this limitation."
    }, {
      "heading" : "4.4.1 AN INHERENT LIMITATION OF EDAC*",
      "text" : "Definition 17 (de Givry et al., 2005) Consider a binary WCSP P = (X ,D, C,⊤). A variable xi ∈ X is existential arc consistent (EAC*) if it is NC* and there exists a value v ∈ D(xi) with zero unary cost such that it has full supports with respect to all binary cost functions Wi,j on {xi, xj} and {xj}. P is existential directional arc consistent (EDAC*) if it is FDAC* and all variables are EAC* .\nEnforcing EAC* on a variable xi requires two main operations: (1) compute\nα = min a∈D(xi)\n{Wi(a)⊕ ⊕\nWi,j∈C\nmin b∈D(xj) {Wi,j(a, b)⊕Wj(b)}},\nwhich determines whether enforcing full supports breaks the NC* requirement, and (2) if α > 0, enforce full supports with respect to all cost functions Wi,j ∈ C by invoking findFullSupport (xi, Wi,j , {xj}), implying that NC* is no longer satisfied and hence W∅ can be increased by enforcing NC*. EDAC* enforcement will oscillate if constraints share more than one variable. The situation is similar to Example 3 by de Givry et al. (2005). We demonstrate by the example in Figure 4(a), which shows a WCSP with two cost functions W 11,2 and W 2 1,2. It is FDAC* but not EDAC*. If x2 takes the value a, W 11,2(v, a) ⊕ W1(v) ≥ 1 for all values v ∈ D(x1); if x2 takes the value b, W 21,2(v, b) ⊕ C1(v) ≥ 1 for all values v ∈ D(x1). Thus, by enforcing full supports of each value in D(x2) with respect to all cost functions and {x1}, NC* is broken and W∅ can be increased. To increase W∅, we enforce full supports: the cost of 1 in W1(a) is extended to W 11,2, resulting in Figure 4(b). No costs in W1 can be extended to W 21,2. Performing projection from W 1 1,2 to W2 results in Figure 4(c). The WCSP is now EAC* but not FDAC*. Enforcing FDAC* converts the problem state back to Figure 4(a).\nThe problem is caused by the first step, which does not tell how the unary costs are separated for extension to increase W∅. Although an increment is predicted, the unary cost in W1(a) has a choice of moving itself to W 11,2 or W 2 1,2. During computation, no information is obtained on how the unary costs are moved. As shown, a wrong movement breaks DAC* without incrementing W∅, resulting in oscillation.\nThis problem does not occur in existing solvers which handle only up to ternary cost functions. The solvers allow only one binary cost functions for every pair of variables. If there are indeed two cost functions for the same two variables, the cost functions can be merged into one, where the\ncost of a tuple in the merged function is the sum of the costs of the same tuple in the two original functions. However, if we allow high arity global cost functions, sharing of more than one variable would be common and necessary in many scenarios. A straightforward generalization of EDAC* for non-binary cost functions would inherit the same oscillation problem. In the case of ternary cost functions, Sanchez et al. (2008) cleverly avoid the oscillation problem by re-defining full supports to include not just unary but also binary cost functions. During EDAC enforcement, unary costs are distributed through extension to binary cost functions. However, the method is only designed for ternary cost functions. In the following, we define a weak version of EDAC*, which is based on the notion of cost-providing partitions."
    }, {
      "heading" : "4.4.2 COST-PROVIDING PARTITIONS AND WEAK EDGAC*",
      "text" : "Definition 18 A cost-providing partition Bxi for variable xi ∈ X is a set of sets {Bxi,WS | xi ∈ S} such that:\n• |Bxi | is the number of constraints which scope includes xi; • Bxi,WS ⊆ S; • Bxi,WSj ∩Bxi,WSk = ∅ for any two different constraints WSk ,WSj ∈ C +, and; • ⋃\nBxi,WS∈Bxi Bxi,WS = (\n⋃\nWS∈C+∧xi∈S S) \\ {xi}.\nEssentially, Bxi forms a partition of the set containing all variables constrained by xi. If xj ∈ Bxi,WS , the unary costs in Wj can only be extended to WS when enforcing EAC* for xi. This avoids the problem of determining how the unary costs of xj are distributed when there exists more than one constraint on {xi, xj}.\nBased on the cost-providing partitions, we define weak EDAC*.\nDefinition 19 Consider a binary WCSP P = (X ,D, C,⊤) and cost-providing partitions {Bxi | xi ∈ X}. A weak fully supported value v ∈ D(xi) of a variable xi ∈ X is a value with zero unary cost and for each variable xj and a binary cost function Wmi,j , there exists a value b ∈ D(xj) such that Wmi,j(v, b) = 0 if Bxi,Wmi,j = {}, and W m i,j(v, b)⊕Wj(b) = 0 if Bxi,Wmi,j = {xj}. A variable xi is weak existential arc consistent (weak EAC*) if it is NC* and there exists at least one weak fully supported value in its domain. P is weak existential directional arc consistent (weak EDAC*) if it is FDAC* and each variable is weak EAC*.\nWeak EDAC* collapses to AC when WCSPs collapse to CSPs for any cost-providing partition. Moreover, weak EDAC* is reduced to EDAC* (de Givry et al., 2005) when the binary cost functions share at most one variable.\nWe further generalize weak EDAC* to weak EDGAC* for n-ary cost functions.\nDefinition 20 Given a WCSP P = (X ,D, C,⊤) and cost-providing partitions {Bxi | xi ∈ X}. A weak fully supported value v ∈ D(xi) of a variable xi is a value with zero unary cost and full supports with respect to all cost functions WS ∈ C+ with xi ∈ S and Bxi,WS . A variable xi is weak existential generalized arc consistent (weak EGAC*) if it is NC* and there exists at least one weak fully supported value in its domain. P is weak existential directional generalized arc consistent (weak EDGAC*) if it is FDGAC* and each variable is weak EGAC*.\nWeak EDAC* and weak EDGAC* can be achieved using for any cost-providing partitions. Weak EDGAC* is reduced to GAC when WCSPs collapse to CSPs.\nCompared with other consistency notions, weak EDGAC* is strictly stronger than FDGAC* and other consistency notions we have described. It can be deduced directly from the definition.\nTheorem 12 For any cost-providing partitions, weak EDGAC* > FDGAC* > GAC* > strong ∅IC\nVAC is stronger than weak EDGAC*, as stated in the theorem below.\nTheorem 13 VAC are strictly stronger than weak EDGAC* with any cost-providing partition.\nProof: A WCSP which is VAC must be weak EDGAC* for any cost-providing partition. Otherwise, there must exist a sequence of projections and extensions to increase W∅, which violates Theorem 7.3 by Cooper et al. (2010). On another hand, Cooper et al. (2010) give an example which is EDAC* but not VAC. Results follow. However, weak EDGAC* is incomparable to complete k-consistency (Cooper, 2005), where k > 2, for any cost-providing partition. It is because EDAC* is already incomparable to complete kconsistency (Sanchez et al., 2008).\nTo compute the cost-providing partition Bxi of a variable xi, we could apply Algorithm 6, which is a greedy approach to partition the set Y containing all variables related to xi defined in line 1, hoping to gathering more costs by gathering more variables at one cost function, increasing the chance of removing more infeasible values and raising W∅.\nProcedure findCostProvidingPartition(xi) Y = ( ⋃\nWS∈C+∧xi∈S S) \\ {xi};1 Sort C+ in decreasing order of |S|;2 foreach WS ∈ C+ s.t. xi ∈ S do3 Bxi,WS = Y ∩ S;4 Y = Y \\ S;5\nAlgorithm 6: Finding Bxi\nThe procedure enforceWeakEDGAC*() in Algorithm 7 enforces weak EDGAC* of a WCSP. The cost-providing partitions are first computed in line 1. The procedure makes use of four propagation queues P, Q, R and S. If xi ∈ P, the variable xi is potentially not weak EGAC* due to\nProcedure enforceWeakEDGAC*() foreach xi ∈ X do findCostProvidingPartition (xi);1 R := Q := S := X ;2 while S 6= ∅ ∨R 6= ∅ ∨Q 6= ∅ do3\nP := S ∪ ⋃\nxi∈S,WS∈C+ (S \\ {xi});4 weakEGAC* ();5 S := ∅;6 DGAC* ();7 GAC* ();8 pruneVal ();9\nProcedure weakEGAC*() while P 6= ∅ do10 xi := pop(P);11 if findExistentialSupport (xi) then12 R := R ∪ {xi};13 P := P ∪ {xj | xi, xj ∈ WS ,WS ∈ C +};14\nFunction findExistentialSupport(xi) flag := false;15 α := mina∈D(xi){Wi(a)⊕ ⊕ xi∈S,WS∈C+ minℓ[xi]=a{WS(ℓ)⊕ ⊕ xj∈Bxi,WS Wj(ℓ[xj ])}};16 if α > 0 then17 flag := true;18 foreach WS ∈ C+ s.t. xi ∈ S do findFullSupport (WS , xi, Bxi,WS );19 return flag;20\nAlgorithm 7: Enforcing weak EDGAC*\na change in unary costs or a removal of values in some variables. If xj ∈ R, the variables xi involved in the same cost functions as xj are potentially not DGAC*. If xj ∈ Q, all variables in the same cost functions as xj are potentially not GAC*. The propagation queue S helps build P efficiently. The procedure weakEGAC*() enforces weak EGAC* on each variable by the procedure findExistentialSupport() in line 12. If findExistentialSupport() returns true, a projection has been performed for some cost functions. The weak fully supported values of other variables may be destroyed. Thus, the variables constrained by xi are pushed back onto P for revision in line 14. DGAC* and GAC* are enforced by the procedures DGAC*() and GAC*(). A change in unary cost requires re-examining DGAC* and weak EGAC*, which is done by pushing the variables into the corresponding queues in lines 13 and 14, and lines 11 and 12 in Algorithm 5. In the last step, NC* is enforced by pruneVal(). Again, if a value in D(xi) is removed, GAC*, DGAC* or weak EGAC* may be destroyed, and xi is pushed into the corresponding queues for re-examination by pruneVal() in Algorithm 1. If all propagation queues are empty, all variables are GAC*, DGAC*, and weak EGAC*, i.e. the WCSP is weak EDGAC*.\nThe algorithm is correct and must terminate. We analyze the time complexity by abstracting the worst-case time complexities of findSupport(), findFullSupport() and\nfindExistentialSupport() as fGAC , fDGAC , and fEGAC respectively. The overall time complexity is stated as follows.\nTheorem 14 The procedure enforceWeakEDGAC*() requires O((nd+⊤)(fEGAC+r2efDGAC+ nd) + r2edfGAC), where n, d, e, and r are defined in Theorem 2.\nProof: As line 1 requires only O(nr), we only analyze the overall time complexity spent by each sub-procedure and compute the overall time complexity.\nA variable is pushed into S if a value is removed or weak EGAC* is violated. The former happens O(nd) times, while the latter occurs O(⊤) times (each time weak EGAC* is violated, W∅ will be increased). Since P is built on S, findExistentialSupport() is executed at most O(nd+⊤) times throughout the global enforcement. Thus, the time complexity spent on enforcing weak EGAC* is O((nd+⊤)fEGAC).\nA variable is pushed into R if either a value is removed, or unary costs are moved by GAC* or weak EGAC* enforcement. Thus, DGAC*() is called O(nd + ⊤) times. Each time DGAC*() is called, by Theorem 10, it requires O(r2efDGAC) for DGAC* enforcement. Thus, the time complexity of enforcing DGAC* is O((nd+⊤)r2efDGAC).\nA variable is pushed into Q only if a value is removed. Thus, findSupport() inside the procedure GAC*() is called at most O(nd) times throughout the global enforcement. Using the proof similar to Theorem 6, the overall time spent on enforcing GAC* is O(r2edfGAC + n2d2).\nThe main while-loop in line 3 terminates when all propagation queues are empty. Thus, the main while-loop iterates O(nd+ ⊤) times. The time complexity for re-enforcing NC* by pruneVal() at line 9 is O((nd+⊤)nd).\nBy summing up all time complexity results, the overall time complexity is O((nd+⊤)(fEGAC+ r2efDGAC + nd) + r 2edfGAC).\nCorollary 4 The procedure enforceWeakEDGAC*() must terminate. The resultant WCSP is weak EDGAC*, and equivalent to the original WCSP.\nThe procedure enforceWeakEDGAC*() is again exponential due to findSupport(), findFullSupport() and findExistentialSupport(). In the following, we focus on the last procedure. It first checks whether a weak fully supported value exists by computing α, which determines whether NC* still holds if we perform findFullSupport() from line 19. If α equals 0, a weak fully supported value exists and nothing should be done; otherwise, this value can be made weak fully supported by the for-loop at line 19. The time complexity depends on two operations: (1) computing the value of α in line 16, and; (2) finding full supports by the line 19. These two operations are exponential in |S| in general. However, if all global cost functions are flow-based projection-safe, the time complexity of the above operations can be reduced to polynomial time.\nIn the next section, we put theory into practice. We demonstrate our framework with different benchmarks and compare the results with the current approach."
    }, {
      "heading" : "5. Towards a Library of Efficient Global Cost Functions",
      "text" : "In the previous section, we only show SOFT ALLDIFFERENTdec is flow-based projection-safe. In the following, we further show that a range of common global cost functions are also flow-based projection-safe. We give experimental results on various benchmarks with different consistency notions and different global cost functions."
    }, {
      "heading" : "5.1 A List of Flow-Based Projection-Safe Global Cost Functions",
      "text" : "In this section, we show that a number of common global cost functions are flow-based projectionsafe. They include the soft variants of ALL DIFFERENT, GCC, SAME, and REGULAR constraints."
    }, {
      "heading" : "5.1.1 THE SOFT VARIANTS OF ALLDIFFERENT",
      "text" : "The ALLDIFFERENT() constraint restricts variables to take distinct values (Laurière, 1978). There are two possible soft variants, namely SOFT ALLDIFFERENTdec () and ALLDIFFERENTvar (). The former returns the number of pairs of variables that share the same value, while the latter returns the least number of variables that must be changed so that all variables take distinct values. The cost function SOFT ALLDIFFERENTdec () is shown to be flow-based projection-safe in Section 4.2. In fact, this also implies that another cost function SOFT ALLDIFFERENTvar () is flow-based projection-safe. The SOFT ALLDIFFERENTvar () function also corresponds to a flow network with structure similar to that of SOFT ALLDIFFERENTdec () but different in weights on the edges connecting to t (van Hoeve et al., 2006). We state the results as follows.\nTheorem 15 The cost functions SOFT ALLDIFFERENTvar (S) and SOFT ALLDIFFERENTdec (S) are flow-based projection-safe."
    }, {
      "heading" : "5.1.2 THE SOFT VARIANTS OF GCC",
      "text" : "Given a set of values Σ = ⋃\nxi∈S D(xi) and functions lb and ub that maps from Σ to non-negative\nintegers. Each value v ∈ Σ is associated with a upper bound ubv and a lower bound lbv. The GCC(S, ub, lb) constraint is satisfied by a tuple ℓ ∈ L(S) if the number of occurrences of a value v ∈ Σ in ℓ (denoted by #(ℓ, v)) is at most ubv times and at least lbv times (Régin, 1996). There are two soft variants of GCC constraints, namely SOFT GCCvar() and SOFT GCCval() (van Hoeve et al., 2006).\nDefinition 21 (van Hoeve et al., 2006) Define two functions s(ℓ, v) and e(ℓ, v): s(ℓ, v) returns lbv −#(ℓ, v) if #(ℓ, v) ≤ lbv, and 0 otherwise; e(ℓ, v) returns #(ℓ, v)−ubv if #(ℓ, v) ≥ ubv, and 0 otherwise.\nThe global cost functions SOFT GCCvar(S) returns max{ ∑ v∈Σ s(ℓ, v), ∑\nv∈Σ e(ℓ, v)}, provided that ∑\nv∈Σ lbv ≤ |S| ≤ ∑ v∈Σ ubv; while SOFT GCC val(S) returns ∑ v∈Σ(s(ℓ, v)+ e(ℓ, v)).\nVan Hoeve et al. (2006) show that both SOFT GCCvar and SOFT GCCdec are flow-based, and the flow networks have structures similar to the SOFT ALLDIFFERENT cost functions. With a proof similar to Theorem 15, we can show the following theorem.\nTheorem 16 The cost functions SOFT GCCvar(S) and SOFT GCCval(S) are flow-based projectionsafe."
    }, {
      "heading" : "5.1.3 THE SOFT VARIANTS OF SAME",
      "text" : "Given two sets of variables S1 and S2 with |S1| = |S2| and S1 ∩ S2 = ∅. The SAME(S1,S2) constraint is satisfied by the tuple ℓ ∈ L(S1 ∪ S2) if ℓ[S1] is a permutation of ℓ[S2] (Beldiceanu, Katriel, & Thiel, 2004). The hard SAME() constraint can be softened to the global cost function SOFT SAMEvar () (van Hoeve et al., 2006):\nDefinition 22 (van Hoeve et al., 2006) Given that the union operation ∪ is the multi-set union, and ϕ1∆ϕ2 returns the symmetric difference between two multi-sets ϕ1 and ϕ2, i.e.ϕ1∆ϕ2 = (ϕ1 \\ ϕ2) ∪ (ϕ2 \\ ϕ1).\nThe global cost function SOFT SAMEvar (S1, S2) returns |( ⋃\nxi∈S1 {ℓ[xi]})∆(\n⋃\nyi∈S2 {ℓ[yi]})|/2.\nTheorem 17 The cost function SOFT SAMEvar (S1, S2) is flow-based projection-safe.\nProof: Van Hoeve et al. (2006) have shown that SOFT SAMEvar satisfies conditions 1 and 2 in Definition 15. For instance, consider S1 = {x1, x2, x3} and S2 = {x4, x5, x6} with D(x1) = {a}, D(x2) = {a, b}, D(x3) = {b}, D(x4) = {a, b} ,and D(x5) = D(x6) = {a}. The flow network corresponding to SOFT SAMEvar (S1, S2) is shown in Fig. 5. Solid edges have zero weight and unit capacity. Dotted edges have unit weight and a capacity of 3. The thick edges show the (s, t)-flow corresponding to the tuple ℓ = (a, b, b, b, a, a).\nMoreover, from the network structure, by taking Ē = {(xi, v)} for xi ∈ S1 and v ∈ D(xi), and Ē = {(v, yi)} for yi ∈ S2 and v ∈ D(yi), the cost function satisfies condition 3. Thus, it is flow-based projection-safe."
    }, {
      "heading" : "5.1.4 THE SOFT VARIANTS OF REGULAR",
      "text" : "The REGULAR constraint are defined based on regular languages. A regular language L(M) can be represented by a finite state automaton M = (Q,Σ, δ, q0, F ). Q is the set of states. Σ is a set of characters. The symbol q0 ∈ Q denotes the initial state and F ⊆ Q is the set of final states. The transition function δ is defined as δ : Q×Σ 7→ Q. An automaton can be represented graphically as shown in Figure 6, where the final states are denoted by double circles.\nGiven D(xi) ⊆ Σ for each xi ∈ S. The REGULAR(S, M ) constraint accepts the tuple ℓ ∈ L(S) if the corresponding string belongs to a regular language L(M) represented by a finite state automaton M = (Q,Σ, δ, q0, F ) (Pesant, 2004).\nTwo soft variants are defined for the REGULAR constraint, namely SOFT REGULARvar () and SOFT REGULARedit() (van Hoeve et al., 2006):\nDefinition 23 (van Hoeve et al., 2006) Define τℓ to be the string formed from the tuple ℓ ∈ L(S). The cost functions SOFT REGULARvar (S) returns min{H(τℓ, τ) | τ ∈ L(M)}, where H(τ1, τ2) returns the number of positions at which two strings τ1 and τ2 differ; while SOFT REGULARedit(S) returns min{E(τℓ, τ) | τ ∈ L(M)}, where E(τ1, τ2) returns the minimum number of insertions, deletions and substitutions to transform τ1 to τ2 .\nTheorem 18 The cost functions SOFT REGULARvar (S) and SOFT REGULARedit(S) are flow-based projection-safe.\nProof: Van Hoeve et al. (2006) show that conditions 1 and 2 are satisfied. For example, consider the automaton M shown in Figure 6 and S = {x1, x2, x3} with D(x1) = {a} and D(x2) = D(x3) = {a, b}. The flow networks corresponding to the SOFT REGULARvar (S) and SOFT REGULARedit(S) functions are shown in Figure 7(a) and 7(b) respectively. The solid edges have zero weight and the dotted edges have unit weight. The thick edges show the flow corresponding to the tuple (a, b, a).\nThe graphs are constructed as follows (van Hoeve et al., 2006): the vertices are separated into n + 1 layers, where n = |X |, and each layer contains |Q| nodes. The source s is connected to q0,0 at the first layer, and the sink t is connected by {qn+1,i | qi ∈ F} at the last layer. Between the ith and (i + 1)th layers, an zero weighted edge representing v ∈ D(xi) connects qi,h at the ith layer and qi+1,k at the (i+ 1)th layer if δ(qk, v) = qh. For SOFT REGULARvar (S), a set of unit-weighted edges Esub is added to the graph, where Esub = {(qi,k, qi+1,h)u | xi ∈ X ∧ u ∈ D(xi) ∧ ∃v 6= u s.t. δ(qk, v) = qh}. For SOFT REGULARedit(S), a set of unit-weighted edges Eedit is added to the graph, where Eedit = Esub ∪ {(qi,k, qi,h) | xi ∈ X ∧ ∃v s.t. δ(qk, v) = qh} ∪ {(qi,k, qi,k)u | xi ∈ X ∧ u ∈ D(xi)}.\nMoreover, each assignment {xi 7→ v} maps to a set of edges Ē labelled as v at the layer xi in the networks. For example, {x1 7→ a} maps to the edges labeled as a at the layer x1 shown in Fig. 7(a). Thus, the SOFT REGULAR cost functions satisfy condition 3 and are flow-based projection-safe.\nFor the SOFT REGULAR cost functions, instead of the general flow computation algorithms, the dynamic programming approach can be applied to compute the minimum cost (van Hoeve et al., 2006; Demassey, Pesant, & Rousseau, 2006)."
    }, {
      "heading" : "5.2 Experimental Results",
      "text" : "In this section, a series of experiments with different benchmarks is conducted to demonstrate the efficiency and practicality of different consistencies with different global cost functions. We implemented the strong ∅IC, GAC*, FDGAC* and weak EDGAC* enforcement algorithms for these global cost functions in ToulBar2 version 0.51. We compare their performance using five benchmarks of different natures. In case of the reified COP models, the instances are solved using ILOG Solver 6.0.\nAll benchmarks are crisp in nature, and are softened as follows. For each variable xi introduced, a random unary cost from 0 to 9 is assigned to each value in D(xi). Soft variants of global constraints are implemented as proposed. The target of all benchmarks is to find the optimal value within 1 hour.\n1. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro\nIn the experiments, variables are assigned in lexicographical order. Value assignment starts with the value with minimum unary cost. The test was conducted on a Sun Blade 2500 (2 × 1.6GHz USIIIi) machine with 2GB memory. The average runtime and number of nodes of five instances are measured for each value of n with no initial upper bound. Entries are marked with a “*” if the average runtime exceeds the limit of 1 hour. The best results are marked using the ‘†’ symbol."
    }, {
      "heading" : "5.2.1 BENCHMARKS BASED ON SOFT ALLDIFFERENT",
      "text" : "The ALLDIFFERENT() constraint has various applications. In the following, we focus on two: the all-interval series and the Latin Square problem.\nALL INTERVAL SERIES\nThe all-interval series problem (prob007 in CSPLib) is modelled as a WCSP by two sets of variables {si} and {di} with domains {0, . . . n− 1} to denote the elements and the adjacent difference respectively. Random unary costs ranging from 0 to 9 is placed on each variable. We apply two soft ALLDIFFERENT cost functions on {si} and {di} respectively, with a set of hard arithmetic constraints di = |si − si+1| for each i = 1, . . . , n− 1.\nThe experiment is divided into two parts. We first compare results on enforcing different consistencies using global cost functions derived from ALLDIFFERENT() . Then we compare the result on using different approaches on modelling SOFT ALLDIFFERENTdec () functions.\nThe result of the first experiment is shown in Table 1, which agrees with the theoretical strength of the consistency notions as shown by the number of nodes. FDGAC* and GAC* always outperforms strong ∅IC and the reified modelling, but FDGAC* requires more time than GAC*. One explanation for this phenomenon is the problem structure. When xi and xi+1 are assigned, di is\nautomatically assigned due to the hard constraint di = |xi − xi+1|. Thus, enforcing FDGAC* on the variables {di} on every search node is not worthwhile.\nThe second experiment is based on the following fact. The SOFT ALLDIFFERENTdec (S) is flowbased projection-safe. It can be modelled as a flow network for consistency enforcement efficiently. Another way to model the global cost functions is to apply the decomposition directly. The cost returned by SOFT ALLDIFFERENTdec (S) is equal to the sum of the costs returned by a set of soft binary cost functions {Wi,j | i > j ∧ xi, xj ∈ S}, where Wi,j(a, b) returns 0 if a 6= b and 1 otherwise. Thus, binary consistency notions, such as AC* and FDAC* can be applied directly.\nWe compare the performance on solving the all interval series problem with different modelling methods on SOFT ALLDIFFERENTdec (). The results are shown in Table 2. Under the same level of consistency, global cost functions remove an order of magnitude 10 to 100 times more nodes than the binary decomposition. However, the time required for binary cost functions is much smaller than global cost functions for AC* and FDAC*. This is because enforcing consistency notions on binary cost functions is faster than global cost functions, and the removal of nodes is not great enough to compensate the extra time for consistency enforcement of global cost functions. The runtime of weak EDGAC*, however, is the fastest among all (2 times over the EDAC* counterpart) since it is able to utilize global information to prune drastically more search space than any of the binary decomposition approaches.\nLATIN SQUARES\nThe Latin Square problem (prob003 in CSPLib) of order n is to fill an initially empty n × n table using numbers from {0, . . . , n − 1} such that each number occurs once in every row and every column. We model and relax the problem as a WCSP by a set of variables {xij} denoting the value placed in the cell at the ith row and the jth column with random unary costs. These costs are essentially restrictions/preferences on the value to be taken by each cell. Thus, our formulation can model different variants of the Latin Square problem, including the Latin Square Completion problem. One SOFT ALLDIFFERENT() cost function is posted on the variables at each row and each\ncolumn, denoting that same elements on the same rows and columns are allowed but with violation costs so that the resultant cost is optimal. The result is shown in Table 3, which is similar to Table 1. Besides, the runtime also agrees with the theoretical strength of the consistency notions.\nThe SOFT ALLDIFFERENTdec () cost functions can also be decomposed into binary disequality cost functions. We also perform experiments to compare the binary decomposition approach and our global cost function approach. The result is shown in Table 4. The result confirms that enforcing stronger consistency on global cost functions is efficient in terms of the number of nodes explored and also as the problem size grows large."
    }, {
      "heading" : "5.2.2 BENCHMARKS BASED ON SOFT GCC",
      "text" : "The GCC() constraint has various applications. In the following, we focus on the Latin Square problem and round robin tournament problem.\nLATIN SQUARES\nWe first focus on the Latin Square problem, which is described in Section 5.2.1. We use the same soft version but we replace SOFT ALLDIFFERENT by either SOFT GCCvar() or SOFT GCCval() cost functions which measure the violation differently. The results are shown in Table 5, which shows a similar result as Table 3. Weak EDGAC* always performs the best in terms of time and reduction in search space.\nROUND ROBIN TOURNAMENT\nThe round robin problem problem (prob026 in CSPLib) of order n is to schedule a tournament of n teams over n−1 weeks. Each week is divided into n/2 periods, and each period is divided into two slots. A tournament must satisfy the following three constraints: (1) every team plays at least once a week, (2) every team plays at most twice in the same period over the tournament, and (3) every team plays every other team. Van Hentenryck, Michel, Perron, and Régin (1999) give a CSP model only based on GCC constraints: a triple of variables (sij , tij,mij) represents the match played on the ith week at the jth period. The assignment {sij 7→ a, tij 7→ b,mij 7→ ab} represents team a is played against the team b. Ternary constraints link sij , tij and mij together such that sij takes the value a\nand tij takes the value b iff mij takes the value ab or ba. The first and the second requirements are represented by the GCC constraints on {sij , tij | i = w} for each wth week and {sij, tij | j = p} for each pth period. The third requirement is represented by a GCC constraint on {mij}.\nThe problem can be generalized by three parameters (N,P,M): scheduling a tournament of N teams over M weeks, with each week divided into P periods. Besides placing random unary costs, we also replace the GCC constraints by the soft variants. We try different combinations of N , P , and M . The results are shown in Table 6, which agrees with the theoretical strength of each consistency. It also shows that although enforcing stronger consistency is more expensive, it helps to reduce search space more. Thus, stronger consistency helps to solve larger instances."
    }, {
      "heading" : "5.2.3 BENCHMARKS BASED ON SOFT SAME",
      "text" : "The SAME() constraint can be used to model the following two problems: (1) fair scheduling, and (2) people-mission scheduling.\nFAIR SCHEDULING\nThe problem is suggested in the Global Constraint Catalog2. The goal is to schedule n persons into s shifts over d days such that the schedule is fair, i.e. each person should be assigned to the same number of the ith shift. For example, the schedule in Figure 8(a) is not fair. The person p1 is assigned to the AM shift two times but p2 is assigned to the AM shift once only. Figure 8(b) shows a schedule that is fair to everyone: both p1 and p2 are assigned to the AM shift and Overnight shift once, and the PM shift twice.\nWe model and soften the problem by a set of variables {xij}, which denote the shift assigned to the ith person on the jth day with random unary costs. The SOFT SAMEvar ({xp1j}, {xp2j}) cost functions are placed between each pair of persons p1 and p2, allowing violation for the fairness of the schedule to obtain minimum cost. We fix s = 4 and d = 5 and vary n. The results are shown in Table 7. Similarly to Table 5, weak EDGAC* produces the smallest number of nodes. However,\n2. http://www.emn.fr/x-info/sdemasse/gccat/\nweak EDGAC* requires more time to solve than FDGAC*. We look into the execution and discover that FDGAC* is so strong that the first lower bound computed is already very close, if not identical, to the objective value of the optimal solution. Therefore, enforcing weak EDGAC* gives only little improvement on reducing the search space.\nPEOPLE-MISSION SCHEDULING\nThis problem extends the doctor-nurse rostering problem described by Beldiceanu, Katriel and Thiel (2004). Given three groups of n persons, m missions must be assigned to a team containing exactly one person in each group. We are also given a set of constraints restricting the combination of each team in one mission. The problem is to schedule those people into teams for missions such that no restriction is violated. We model the problem by {xij} denoting the mission assigned to the ith person in the jth group with random unary costs. The combination restriction is softened as ternary cost functions. Two global cost functions SOFT SAMEvar ({xi1}, {xi2}) and SOFT SAMEvar ({xi2}, {xi3}) are posted to ensure each team exactly contains one person from each group. We fix m = 6 and vary n. The results are shown in Table 8. Similarly to Table 7, weak EDGAC* produces the smallest number of nodes, but requires more time than FDGAC*."
    }, {
      "heading" : "5.2.4 BENCHMARKS BASED ON SOFT REGULAR",
      "text" : "The REGULAR() constraint has many applications. In the following, we focus on two: (1) the nurse rostering problem, and; (2) the STRETCH() constraint modelling.\nNURSE ROSTERING PROBLEM\nThe nurse rostering problem (Cheng, Lee, & Wu, 1997) is to schedule a group of n nurses into four shifts, PM shift, AM shift, Overnight, and Day-Off, over a period with most requirements satisfied.\nIn the experiment, the nurses are scheduled over four days such that (1) each nurse must have at most three AM shifts, at least two PM shifts, at least one Overnight, and at least one day-off; (2) each AM shift must have two nurses, each PM shift and each Overnight must have one nurse, and; (3) AMshifts are preferred to be packed together, and the same preference is also posted on Day-Offs. We model this problem by a set of variables {xij} to denote the shift assigned to the ith nurse on the jth day with random unary costs. Restrictions (1) and (2) are modeled by SOFT GCCval cost functions, and (3) is modeled by either SOFT REGULARvar or SOFT REGULARedit cost functions. All restrictions are allowed to be violated. The results are shown in Table 9. When SOFT REGULARedit() is used, FDGAC* wins in term of runtime. However, if SOFT REGULARvar () is used, weak EDGAC* again requires the least time and the least number of nodes to solve.\nMODELLING THE STRETCH() CONSTRAINT\nAnother application of the REGULAR() constraint is to model constraints that describe patterns. One example is the STRETCH() constraint.\nDefinition 24 (Pesant, 2001) Given a value v and a tuple ℓ ∈ L(S). A v-stretch is the maximal subsequence of identical values v in ℓ. The STRETCH(S, ub, lb) constraint is satisfied by ℓ if the length of the v-stretch in ℓ is at most ubv and at least lbv.\nFor simplicity, we omit the case when the STRETCH() constraint is circular. However, it can be handled by variable duplication (Pesant, 2004).\nThe STRETCH() constraint can be described by an automaton and thus modelled using the REGULAR() constraint (Pesant, 2004). The SOFT REGULARvar () and SOFT REGULARedit() cost functions can be directly applied to define two soft variants of the STRETCH() constraint, namely SOFT STRETCHvar () and SOFT STRETCHedit(). They are flow-based projection-safe by inheriting the same property from SOFT REGULARvar () and SOFT REGULARedit() respectively.\nTo demonstrate the idea, we conduct experiments using the following sliding problem. The sliding problem of order n consists a set of variables {x1, . . . , xn} with domains D(xi) = {a, b} and random unary costs. Each subsequence {xi, . . . , xn−5+i}, where 1 ≤ i ≤ 5, is required to contain a-stretches of length 2 and b-stretches of length 2 or 3. This restriction can be enforced through STRETCH constraints. We allow violations by modeling the constraints using either the SOFT REGULARvar or SOFT REGULARedit cost functions. The results are shown in Table 10. Weak EDGAC* needs more time than FDGAC* when the instances are small, but weak EDGAC* pays off for large instances. This experiment also shows that the STRETCH constraint, an important constraint for modeling patterns, can be efficiently propagated in the WCSP framework."
    }, {
      "heading" : "5.2.5 DISCUSSIONS",
      "text" : "A control comparison should have been conducted to examine the efficiency of ToulBar2 on the global cost functions encoded explicitly as tables as well. This cannot be done in a meaningful manner since the tables will be prohibitively large. Consider a simple cost function on 10 variables,\neach with a domain size of 10. The table already requires storage in the order of 1010 integers or tens of gigabytes.\nBased on our experiments, two conclusions can be made. First, the experiments show that the reified approach and strong ∅IC are too weak both in terms of search space pruning and runtime reduction as compared to GAC*, FDGAC*, and weak EDGAC*. Second, the stronger consistency notions, weak EDGAC*, FDGAC* and GAC*, are worthwhile although they are more expensive to enforce. As shown from the experiments, GAC* reduces the number of search nodes at least 3 times more than the reified approach and 1.5 times more than strong ∅IC. GAC* has runtime at least 4 times less than the reified approach and 1.5 times less strong ∅IC. Weak EDGAC* and FDGAC* can reduce the search space by a much greater extent. Such additional pruning can usually compensate for the extra effort. Although Table 7 and Table 8 have shown cases where weak EDGAC* results in slower runtime, FDGAC* only wins by a small margin. In general, weak EDGAC* is still worthwhile to enforce. Table 10 further confirms that a stronger consistency is more desirable as the problem becomes large."
    }, {
      "heading" : "6. Conclusion and Remarks",
      "text" : "In this section, we summarize our contributions and shed light on possible future directions of research.\nOur contributions are five-fold. First, we introduce strong ∅IC based on ∅IC (Zytnicki et al., 2009) and give an algorithm to enforce strong ∅IC. Besides, we prove that strong ∅IC is confluent. We also show that enforcing strong ∅IC on a WCSP is stronger than GAC in the reified approach. Second, we give an algorithm to enforce GAC* for a WCSP, but enforcement is exponential. For efficient enforcement, we introduce flow-based projection-safety, which preserves the basic structure of global cost functions. We give sufficient conditions for a global cost function to be flow-based projection-safe. We also show as a part of the proof how projection and extension can be done so that the flow property is preserved. Third, we generalize FDAC* (Larrosa & Schiex, 2003) to FDGAC* and give an enforcement algorithm. Again, flow-based projection-safety helps FDGAC* enforcement. Fourth, we attempt to generalize EDAC* using similar methods, but find it to be nontrivial. We discover and give an example of a limitation of EDAC*. When cost functions share more than one variable, oscillation similar to the one demonstrated in Full AC* (de Givry et al., 2005) will occur. To solve this problem, we introduce cost-providing partitions, which restrict the distribution of costs when enforcing EDAC*. Based on cost-providing partitions, we define weak EDGAC*, which can be enforced in polynomial time for flow-based projection-safe global cost functions. Last but not least, we show that soft versions of ALLDIFFERENT(), GCC(), SAME() and REGULAR() are flow-based projection-safe. We also prove the practicality of our framework with empirical results on various benchmarks involving these global cost functions. The empirical results agree with the theoretical strength of the consistencies in terms of search tree pruning. The results also show that stronger consistency notions like weak EDGAC* and FDGAC* are more worthwhile to enforce, especially when solving large problems.\nThree directions of future work are possible. The first one is to investigate if other even stronger consistency notions, such as VAC (Cooper et al., 2010), can also benefit from projection-safety to make their enforcement practical for global cost functions. Second, the current sufficient conditions for flow-based projection-safety might still be overly restrictive. For example, the global cost function SOFT SEQUENCE (Maher, Narodytska, Quimper, & Walsh, 2008) does not satisfy the three\nconditions. It is interesting to find out other possible definition of flow-based projection-safety, which allow efficient projection and extension operations. Third, we only consider the minimum cost flow computation for finding the minimum cost in a global cost function. It is interesting to check if other approaches, such as mathematical programming, can be used to achieve the same results."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Work described in this paper was generously supported by grants CUHK413808 and CUHK413710 from the Research Grants Council of Hong Kong SAR."
    } ],
    "references" : [ {
      "title" : "Global Constraints as Graph Properties on a Structured Network of Elementary Constraints of the Same Type",
      "author" : [ "N. Beldiceanu" ],
      "venue" : "Proceedings of CP’00, pp. 52–67.",
      "citeRegEx" : "Beldiceanu,? 2000",
      "shortCiteRegEx" : "Beldiceanu",
      "year" : 2000
    }, {
      "title" : "Deriving Filtering Algorithms from Constraint Checkers",
      "author" : [ "N. Beldiceanu", "M. Carlsson", "T. Petit" ],
      "venue" : "In Proceedings of CP’04,",
      "citeRegEx" : "Beldiceanu et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Beldiceanu et al\\.",
      "year" : 2004
    }, {
      "title" : "Filtering Algorithms for the Same Constraints",
      "author" : [ "N. Beldiceanu", "I. Katriel", "S. Thiel" ],
      "venue" : "In Proceedings of CPAIOR’04,",
      "citeRegEx" : "Beldiceanu et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Beldiceanu et al\\.",
      "year" : 2004
    }, {
      "title" : "A Nurse Rostering System Using Constraint Programming and Redundant Modeling",
      "author" : [ "B. Cheng", "J.H.M. Lee", "J. Wu" ],
      "venue" : "IEEE Transactions on Information Technology in Biomedicine,",
      "citeRegEx" : "Cheng et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 1997
    }, {
      "title" : "Soft Arc Consistency Revisited",
      "author" : [ "M. Cooper", "S. de Givry", "M. Sanchez", "T. Schiex", "M. Zytnicki", "T. Werner" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Cooper et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Cooper et al\\.",
      "year" : 2010
    }, {
      "title" : "Arc Consistency for Soft Constraints",
      "author" : [ "M. Cooper", "T. Schiex" ],
      "venue" : "Artifical Intelligence,",
      "citeRegEx" : "Cooper and Schiex,? \\Q2004\\E",
      "shortCiteRegEx" : "Cooper and Schiex",
      "year" : 2004
    }, {
      "title" : "High-Order Consistency in Valued Constraint Satisfaction",
      "author" : [ "M.C. Cooper" ],
      "venue" : "Constraints, 10(3), 283–305.",
      "citeRegEx" : "Cooper,? 2005",
      "shortCiteRegEx" : "Cooper",
      "year" : 2005
    }, {
      "title" : "Existential Arc Consistency: Getting Closer to Full Arc Consistency in Weighted CSPs",
      "author" : [ "S. de Givry", "F. Heras", "M. Zytnicki", "J. Larrosa" ],
      "venue" : "In Proceedings of IJCAI’05,",
      "citeRegEx" : "Givry et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Givry et al\\.",
      "year" : 2005
    }, {
      "title" : "A Cost-Regular Based Hybrid Column",
      "author" : [ "S. Demassey", "G. Pesant", "Rousseau", "L.-M" ],
      "venue" : "Generation Approach. Constraints,",
      "citeRegEx" : "Demassey et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Demassey et al\\.",
      "year" : 2006
    }, {
      "title" : "A Note on Two Problems in Connexion with Graphs",
      "author" : [ "E.W. Dijkstra" ],
      "venue" : "Numerische Mathematik, 1, 269–271.",
      "citeRegEx" : "Dijkstra,? 1959",
      "shortCiteRegEx" : "Dijkstra",
      "year" : 1959
    }, {
      "title" : "Efficient Algorithms for Shortest Paths in Sparse Networks",
      "author" : [ "D. Johnson" ],
      "venue" : "Journal of the ACM, 24(1), 1–13.",
      "citeRegEx" : "Johnson,? 1977",
      "shortCiteRegEx" : "Johnson",
      "year" : 1977
    }, {
      "title" : "In the Quest of the Best Form of Local Consistency for Weighted CSP",
      "author" : [ "J. Larrosa", "T. Schiex" ],
      "venue" : "In Proceedings of IJCAI’03,",
      "citeRegEx" : "Larrosa and Schiex,? \\Q2003\\E",
      "shortCiteRegEx" : "Larrosa and Schiex",
      "year" : 2003
    }, {
      "title" : "Solving Weighted CSP by Maintaining Arc Consistency",
      "author" : [ "J. Larrosa", "T. Schiex" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Larrosa and Schiex,? \\Q2004\\E",
      "shortCiteRegEx" : "Larrosa and Schiex",
      "year" : 2004
    }, {
      "title" : "A Language and a Program for Stating and Solving Combinatorial Problems",
      "author" : [ "Laurière", "J.-L." ],
      "venue" : "Artificial Intelligence, 10, 29–127.",
      "citeRegEx" : "Laurière and J..L.,? 1978",
      "shortCiteRegEx" : "Laurière and J..L.",
      "year" : 1978
    }, {
      "title" : "Combinatorial Optimization: Networks and Matroids",
      "author" : [ "E. Lawler" ],
      "venue" : "Holt, Rinehart and Winston.",
      "citeRegEx" : "Lawler,? 1976",
      "shortCiteRegEx" : "Lawler",
      "year" : 1976
    }, {
      "title" : "Soft Global Constraints in Constraint Optimization and Weighted Constraint Satisfaction",
      "author" : [ "K.L. Leung" ],
      "venue" : "Master’s thesis, The Chinese University of Hong Kong.",
      "citeRegEx" : "Leung,? 2009",
      "shortCiteRegEx" : "Leung",
      "year" : 2009
    }, {
      "title" : "Flow-Based Propagators for the SEQUENCE and Related Global Constraints",
      "author" : [ "M. Maher", "N. Narodytska", "Quimper", "C.-G", "T. Walsh" ],
      "venue" : "In Proceedings of CP’08,",
      "citeRegEx" : "Maher et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Maher et al\\.",
      "year" : 2008
    }, {
      "title" : "A Filtering Algorithm for the Stretch Constraint",
      "author" : [ "G. Pesant" ],
      "venue" : "Proceedings of CP’01, pp. 183–195.",
      "citeRegEx" : "Pesant,? 2001",
      "shortCiteRegEx" : "Pesant",
      "year" : 2001
    }, {
      "title" : "A Regular Language Membership Constraint for Finite Sequences of Variables",
      "author" : [ "G. Pesant" ],
      "venue" : "Proceedings of CP’04, pp. 482–495.",
      "citeRegEx" : "Pesant,? 2004",
      "shortCiteRegEx" : "Pesant",
      "year" : 2004
    }, {
      "title" : "Meta-constraints on Violations for Over Constrained Problems",
      "author" : [ "T. Petit", "Régin", "J.-C", "C. Bessière" ],
      "venue" : "In Proceedings of ICTAI’00,",
      "citeRegEx" : "Petit et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Petit et al\\.",
      "year" : 2000
    }, {
      "title" : "Specific Filtering Algorithm for Over-Constrained Problems",
      "author" : [ "T. Petit", "Régin", "J.-C", "C. Bessière" ],
      "venue" : "In Proceedings of CP’01,",
      "citeRegEx" : "Petit et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Petit et al\\.",
      "year" : 2001
    }, {
      "title" : "Generalized Arc Consistency for Global Cardinality Constraints",
      "author" : [ "Régin", "J.-C." ],
      "venue" : "Proceedings of AAAI’96, pp. 209–215.",
      "citeRegEx" : "Régin and J..C.,? 1996",
      "shortCiteRegEx" : "Régin and J..C.",
      "year" : 1996
    }, {
      "title" : "Cost-Based Arc Consistency for Global Cardinality Constraints",
      "author" : [ "Régin", "J.-C." ],
      "venue" : "Constraints, 7, 387–405.",
      "citeRegEx" : "Régin and J..C.,? 2002",
      "shortCiteRegEx" : "Régin and J..C.",
      "year" : 2002
    }, {
      "title" : "Mendelian Error Detection in Complex Pedigrees using Weighted Constraint Satisfaction",
      "author" : [ "M. Sanchez", "S. de Givry", "T. Schiex" ],
      "venue" : "Techniques. Constraints,",
      "citeRegEx" : "Sanchez et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sanchez et al\\.",
      "year" : 2008
    }, {
      "title" : "Valued Constraint Satisfaction Problems: Hard and Easy Problems",
      "author" : [ "T. Schiex", "H. Fargier", "G. Verfaillie" ],
      "venue" : "In Proceedings of IJCAI’95,",
      "citeRegEx" : "Schiex et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Schiex et al\\.",
      "year" : 1995
    }, {
      "title" : "Constraint Programming in OPL",
      "author" : [ "P. Van Hentenryck", "L. Michel", "L. Perron", "Régin", "J.-C" ],
      "venue" : "In Proceedings of the International Conference on the Principles and Practice of Declarative Programming,",
      "citeRegEx" : "Hentenryck et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Hentenryck et al\\.",
      "year" : 1999
    }, {
      "title" : "On Global Warming: Flow-based Soft Global Constraints",
      "author" : [ "van Hoeve", "W.-J", "G. Pesant", "Rousseau", "L.-M" ],
      "venue" : "J. Heuristics,",
      "citeRegEx" : "Hoeve et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoeve et al\\.",
      "year" : 2006
    }, {
      "title" : "Bounds Arc Consistency for Weighted CSPs",
      "author" : [ "M. Zytnicki", "C. Gaspin", "T. Schiex" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Zytnicki et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Zytnicki et al\\.",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "To overcome the difficulty, we incorporate van Hoeve, Pesant, and Rousseau’s (2006) flow-based algorithmic method into WCSPs, which amounts to representing global cost functions as flow networks and computing the minimum costs of such networks using the minimum cost flow algorithm.",
      "startOffset" : 54,
      "endOffset" : 84
    }, {
      "referenceID" : 6,
      "context" : "A natural next step is to generalize also the stronger consistency EDAC* (de Givry et al., 2005) to EDGAC*, but this turns out to be non-trivial. We identify and analyze an inherent limitation of EDAC* similar to the case of Full AC* (de Givry et al., 2005). ED(G)AC* enforcement will go into oscillation if two cost functions share more than one variable, which is common when a problem involves high arity cost functions. Sanchez, de Givry, and Schiex (2008) did not mention the oscillation problem but their method for enforcing EDAC* for the special case of ternary cost functions would avoid the oscillation problem.",
      "startOffset" : 77,
      "endOffset" : 461
    }, {
      "referenceID" : 24,
      "context" : "Formally, Definition 1 (Schiex et al., 1995) A WCSP is a tuple (X ,D, C,⊤), where: • X is a set of variables {x1, x2, .",
      "startOffset" : 23,
      "endOffset" : 44
    }, {
      "referenceID" : 23,
      "context" : "Based on NC*, AC* and FDAC* have been developed for binary (Larrosa & Schiex, 2004, 2003) and ternary cost functions (Sanchez et al., 2008).",
      "startOffset" : 117,
      "endOffset" : 139
    }, {
      "referenceID" : 14,
      "context" : "Two of those are the successive shortest path and cycle-cancelling algorithms (Lawler, 1976).",
      "startOffset" : 78,
      "endOffset" : 92
    }, {
      "referenceID" : 20,
      "context" : "Related Work Global cost functions can be handled using constraint optimization, which focuses on efficient computation of min{WS(l) | l ∈ L(S)} and enforcing GAC on their hard constraint forms WS(l) ≤ zS , where zS is the variable storing costs (Petit et al., 2001).",
      "startOffset" : 246,
      "endOffset" : 266
    }, {
      "referenceID" : 19,
      "context" : "Related Work Global cost functions can be handled using constraint optimization, which focuses on efficient computation of min{WS(l) | l ∈ L(S)} and enforcing GAC on their hard constraint forms WS(l) ≤ zS , where zS is the variable storing costs (Petit et al., 2001). Van Hoeve et al. (2006)",
      "startOffset" : 247,
      "endOffset" : 292
    }, {
      "referenceID" : 27,
      "context" : "Examples are NC* (Larrosa & Schiex, 2004), BAC (Zytnicki et al., 2009), AC* (Larrosa & Schiex, 2004), FDAC* (Larrosa & Schiex, 2003), and EDAC* (de Givry et al.",
      "startOffset" : 47,
      "endOffset" : 70
    }, {
      "referenceID" : 4,
      "context" : "Stronger consistency notions, namely OSAC and VAC (Cooper et al., 2010), are also defined, but enforcement requires a relaxation of the cost valuation structure V (⊤) to rational numbers, and current implementations are efficient only on binary WCSPs.",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 23,
      "context" : "For ternary cost functions, AC, FDAC and EDAC are introduced (Sanchez et al., 2008).",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 0,
      "context" : "Beldiceanu (2000) and Beldiceanu, Carlsson and Petit (2004) further develop a representation scheme for global cost functions using a graph-based approach and an automaton approach.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "Beldiceanu (2000) and Beldiceanu, Carlsson and Petit (2004) further develop a representation scheme for global cost functions using a graph-based approach and an automaton approach.",
      "startOffset" : 0,
      "endOffset" : 60
    }, {
      "referenceID" : 0,
      "context" : "Beldiceanu (2000) and Beldiceanu, Carlsson and Petit (2004) further develop a representation scheme for global cost functions using a graph-based approach and an automaton approach. Under their framework, the computation of all global cost functions can be reduced to only considering a fixed set of global cost functions, e.g. the SOFT REGULAR functions. On the other hand, to efficiently remove more search space during WCSPs solving, various consistency notions have been developed. Examples are NC* (Larrosa & Schiex, 2004), BAC (Zytnicki et al., 2009), AC* (Larrosa & Schiex, 2004), FDAC* (Larrosa & Schiex, 2003), and EDAC* (de Givry et al., 2005). Stronger consistency notions, namely OSAC and VAC (Cooper et al., 2010), are also defined, but enforcement requires a relaxation of the cost valuation structure V (⊤) to rational numbers, and current implementations are efficient only on binary WCSPs. For ternary cost functions, AC, FDAC and EDAC are introduced (Sanchez et al., 2008). Cooper (2005) incorporates the concept of k-consistency into WCSPs to form complete k-consistency.",
      "startOffset" : 0,
      "endOffset" : 1006
    }, {
      "referenceID" : 27,
      "context" : "1 Strong ∅-Inverse Consistency Strong ∅-inverse consistency is based on ∅-inverse consistency (∅IC) (Zytnicki et al., 2009).",
      "startOffset" : 100,
      "endOffset" : 123
    }, {
      "referenceID" : 27,
      "context" : "Definition 8 (Zytnicki et al., 2009) Given a WCSP P = (X ,D, C,⊤).",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 27,
      "context" : "The second operation can be reduced to constant time using the ∆S data structure suggested by Zytnicki et al. (2009). Instead of deducting the projected value α from each tuple in WS , we simply store the projected value in ∆S .",
      "startOffset" : 94,
      "endOffset" : 117
    }, {
      "referenceID" : 27,
      "context" : "Although its definition is similar to BAC (Zytnicki et al., 2009), their strengths are incomparable.",
      "startOffset" : 42,
      "endOffset" : 65
    }, {
      "referenceID" : 11,
      "context" : "Using an augment similar to the proof of Larrosa and Schiex’s (2004) Theorems 12 and 21, the complexity can be stated as follows.",
      "startOffset" : 41,
      "endOffset" : 69
    }, {
      "referenceID" : 27,
      "context" : "BAC is confluent (Zytnicki et al., 2009).",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 19,
      "context" : "Following Petit et al. (2000), we define the reified form of a WCSP as follows:",
      "startOffset" : 10,
      "endOffset" : 30
    }, {
      "referenceID" : 19,
      "context" : "Definition 11 (Petit et al., 2000) Given a WCSP P = (X ,D, C,⊤).",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "For a detailed comparison between strong ∅IC of WCSPs and GAC of the reified approach, readers can refer to the work of Leung (2009). When the cost functions are binary, strong ∅IC cannot be stronger than AC*.",
      "startOffset" : 120,
      "endOffset" : 133
    }, {
      "referenceID" : 4,
      "context" : "2 in the work of Cooper et al. (2010), which also requires WS(l) = ⊤ if W∅ ⊕ ⊕",
      "startOffset" : 17,
      "endOffset" : 38
    }, {
      "referenceID" : 23,
      "context" : "GAC* collapses to AC* for binary cost functions (Larrosa & Schiex, 2004) and AC for ternary cost functions (Sanchez et al., 2008).",
      "startOffset" : 107,
      "endOffset" : 129
    }, {
      "referenceID" : 24,
      "context" : "The method introduced by van Hoeve et al. (2006) can be applied to the first operation as discussed in Section 4.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 5,
      "context" : "Cooper and Schiex (2004) use a similar technique as the one by Zytnicki et al.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 5,
      "context" : "Cooper and Schiex (2004) use a similar technique as the one by Zytnicki et al. (2009) (similar to the technique described in Section 4.",
      "startOffset" : 0,
      "endOffset" : 86
    }, {
      "referenceID" : 26,
      "context" : "By using Theorem 7, we can apply the results by van Hoeve et al. (2006) to compute the value min{WS(l) | l[xi] = v ∧ l ∈ L(S)} in polynomial time throughout GAC* enforcement.",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 26,
      "context" : "By using Theorem 7, we can apply the results by van Hoeve et al. (2006) to compute the value min{WS(l) | l[xi] = v ∧ l ∈ L(S)} in polynomial time throughout GAC* enforcement. Besides, the proof gives an efficient algorithm to perform projection in polynomial time by simply modifying the weights of the corresponding edges. Again, we use SOFT ALLDIFFERENT as an example. Van Hoeve et al. (2006) have shown that SOFT ALLDIFFERENT (S) satisfies conditions 1 and 2 in Definition 15.",
      "startOffset" : 52,
      "endOffset" : 395
    }, {
      "referenceID" : 9,
      "context" : "However, it can be reduced by applying a potential value on each vertices, as in Johnson’s (1977) algorithm.",
      "startOffset" : 81,
      "endOffset" : 98
    }, {
      "referenceID" : 9,
      "context" : "Dijkstra’s (1959) algorithm can thus be applied, reducing the time complexity to O(|E| + |V |log(|V |)).",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 23,
      "context" : "However, FDGAC* is incomparable to FDAC for ternary cost functions (Sanchez et al., 2008).",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 11,
      "context" : "The procedure enforceFDGAC*() in Algorithm 5 is correct and must terminate, the proof of which is similar to those of Theorems 3 and 4 by Larrosa and Schiex (2003). The worst-case time complexity of enforceFDGAC*() can be stated in terms of that of findFullSupport() (fDGAC) and findSupport() (fGAC) as follows.",
      "startOffset" : 138,
      "endOffset" : 164
    }, {
      "referenceID" : 7,
      "context" : "The situation is similar to Example 3 by de Givry et al. (2005). We demonstrate by the example in Figure 4(a), which shows a WCSP with two cost functions W 1 1,2 and W 2 1,2.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 23,
      "context" : "In the case of ternary cost functions, Sanchez et al. (2008) cleverly avoid the oscillation problem by re-defining full supports to include not just unary but also binary cost functions.",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 6,
      "context" : "However, weak EDGAC* is incomparable to complete k-consistency (Cooper, 2005), where k > 2, for any cost-providing partition.",
      "startOffset" : 63,
      "endOffset" : 77
    }, {
      "referenceID" : 23,
      "context" : "It is because EDAC* is already incomparable to complete kconsistency (Sanchez et al., 2008).",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 4,
      "context" : "3 by Cooper et al. (2010). On another hand, Cooper et al.",
      "startOffset" : 5,
      "endOffset" : 26
    }, {
      "referenceID" : 4,
      "context" : "3 by Cooper et al. (2010). On another hand, Cooper et al. (2010) give an example which is EDAC* but not VAC.",
      "startOffset" : 5,
      "endOffset" : 65
    }, {
      "referenceID" : 26,
      "context" : "Van Hoeve et al. (2006) show that both SOFT GCC and SOFT GCC are flow-based, and the flow networks have structures similar to the SOFT ALLDIFFERENT cost functions.",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 26,
      "context" : "Proof: Van Hoeve et al. (2006) have shown that SOFT SAME satisfies conditions 1 and 2 in Definition 15.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 18,
      "context" : "The REGULAR(S, M ) constraint accepts the tuple l ∈ L(S) if the corresponding string belongs to a regular language L(M) represented by a finite state automaton M = (Q,Σ, δ, q0, F ) (Pesant, 2004).",
      "startOffset" : 181,
      "endOffset" : 195
    }, {
      "referenceID" : 24,
      "context" : "Proof: Van Hoeve et al. (2006) show that conditions 1 and 2 are satisfied.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "PEOPLE-MISSION SCHEDULING This problem extends the doctor-nurse rostering problem described by Beldiceanu, Katriel and Thiel (2004). Given three groups of n persons, m missions must be assigned to a team containing exactly one person in each group.",
      "startOffset" : 95,
      "endOffset" : 132
    }, {
      "referenceID" : 17,
      "context" : "Definition 24 (Pesant, 2001) Given a value v and a tuple l ∈ L(S).",
      "startOffset" : 14,
      "endOffset" : 28
    }, {
      "referenceID" : 18,
      "context" : "However, it can be handled by variable duplication (Pesant, 2004).",
      "startOffset" : 51,
      "endOffset" : 65
    }, {
      "referenceID" : 18,
      "context" : "The STRETCH() constraint can be described by an automaton and thus modelled using the REGULAR() constraint (Pesant, 2004).",
      "startOffset" : 107,
      "endOffset" : 121
    }, {
      "referenceID" : 27,
      "context" : "First, we introduce strong ∅IC based on ∅IC (Zytnicki et al., 2009) and give an algorithm to enforce strong ∅IC.",
      "startOffset" : 44,
      "endOffset" : 67
    }, {
      "referenceID" : 4,
      "context" : "The first one is to investigate if other even stronger consistency notions, such as VAC (Cooper et al., 2010), can also benefit from projection-safety to make their enforcement practical for global cost functions.",
      "startOffset" : 88,
      "endOffset" : 109
    } ],
    "year" : 2012,
    "abstractText" : "Many combinatorial problems deal with preferences and violations, the goal of which is to find solutions with the minimum cost. Weighted constraint satisfaction is a framework for modeling such problems, which consists of a set of cost functions to measure the degree of violation or preferences of different combinations of variable assignments. Typical solution methods for weighted constraint satisfaction problems (WCSPs) are based on branch-and-bound search, which are made practical through the use of powerful consistency techniques such as AC*, FDAC*, EDAC* to deduce hidden cost information and value pruning during search. These techniques, however, are designed to be efficient only on binary and ternary cost functions which are represented in table form. In tackling many real-life problems, high arity (or global) cost functions are required. We investigate efficient representation scheme and algorithms to bring the benefits of the consistency techniques to also high arity cost functions, which are often derived from hard global constraints from classical constraint satisfaction. The literature suggests some global cost functions can be represented as flow networks, and the minimum cost flow algorithm can be used to compute the minimum costs of such networks in polynomial time. We show that naive adoption of this flow-based algorithmic method for global cost functions can result in a stronger form of ∅-inverse consistency. We further show how the method can be modified to handle cost projections and extensions to maintain generalized versions of AC* and FDAC* for cost functions with more than two variables. Similar generalization for the stronger EDAC* is less straightforward. We reveal the oscillation problem when enforcing EDAC* on cost functions sharing more than one variable. To avoid oscillation, we propose a weak version of EDAC* and generalize it to weak EDGAC* for non-binary cost functions. Using various benchmarks involving the soft variants of hard global constraints ALLDIFFERENT, GCC, SAME, and REGULAR, empirical results demonstrate that our proposal gives improvements of up to an order of magnitude when compared with the traditional constraint optimization approach, both in terms of time and pruning.",
    "creator" : "dvips(k) 5.98 Copyright 2009 Radical Eye Software"
  }
}