{
  "name" : "1609.00331.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Verifier Theory from Axioms to Unverifiability of Mathematical Proofs, Software and AI",
    "authors" : [ "Roman V. Yampolskiy" ],
    "emails" : [ "roman.yampolskiy@lousiville.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Despite significant developments in Proof Theory, surprisingly little attention has been devoted to the concept of proof verifier. In particular, mathematical community may be interested in studying different types of proof verifiers (people, programs, oracles, communities, superintelligences, etc.) as mathematical objects, their properties, their powers and limitations (particularly in human mathematicians), minimum and maximum complexity, as well as selfverification and self-reference issues in verifiers. We propose an initial classification system for verifiers and provide some rudimentary analysis of solved and open problems in this important domain. Our main contribution is a formal introduction of the notion of unverifiability, for which the paper could serve as a general citation in domains of theorem proving, software and AI verification.\nKeywords: Verifier Theory, Proof Theory, Observer, Verified Verifier, Verifiability."
    }, {
      "heading" : "1. On Observers and Verifiers",
      "text" : "The concept of an ‘observer’ shows up in contexts as diverse as physics (particularly quantum), biophysics, neuroscience, cognitive science, artificial intelligence, philosophy of consciousness, relativity, and cosmology [1], but what is an equivalent idea in mathematics? We believe it is the notion of the proof ‘verifier’. Consequently, majority of open questions recently raised [1] by the Foundational Questions Institute related to the physics of the observer, could be asked about proof verifiers. In particular, mathematical community may be interested in studying different types of proof verifiers (people, programs, oracles, communities, superintelligences, etc.) as mathematical objects, ways they can be formalized, their power and limitations (particularly in human mathematicians), minimum and maximum complexity, as well as self-verification and self-reference in verifiers.\nThe proof theory has been developed to study proofs as formal mathematical objects consisting of axioms from which, by rules of inference, one can arrive at theorems [2]. However, the indispensable concept of the verifier has been conspicuously absent from the discussion, particularly with regards to its formalization and practical manifestation. A verifier in the context of mathematics is an agent capable of checking a given proof, step-by-step, starting with axioms to make sure that all intermediate deductions are indeed warranted and that the final conclusion follows and consequently that the claimed theorem is indeed true. In this work we present an overview of different types of verifiers currently relied on by the mathematical community as well as a few novel types of verifiers which we suggest be added to the repertoire of\nmathematicians at least as theoretical tools of Verifier Theory. Our general analysis should be equality applicable to different types of proofs (induction, contradiction, exhaustion, enumeration, refinement, nonconstructive, probabilistic, holographic, experiment, picture, etc.) and computer software."
    }, {
      "heading" : "2. Historical Perspective",
      "text" : "The field of mathematics progresses by proving theorems, which in turn serve as building blocks for future proofs of yet more interesting and useful theorems. To avoid introduction of costly errors in the form of incorrect theorems, proofs typically undergo an examination process usually as a part of a peer-review of claimed proofs. Traditionally human mathematicians have been employed as proof verifiers, but unfortunately history is full of examples of undetected errors and important omissions even in the most widely examined proofs [3-7]. It has been estimated that at least a third of all mathematical publications contain errors [8]. To avoid errors and make the job of human verifiers as easy as possible “… a single step in a deduction has been required … [t]o be simple enough, broadly speaking, to be apprehended as correct by a human being in a single intellectual act. No doubt this custom originated in the desire that each single step of a deduction should be indubitable, even though the deduction as a whole may consist of a long chain of such steps” [9].\nDespite such stringent requirements, it has long been realized that a single human verifier is not reliable enough to ascertain validity of a proof with a sufficient degree of accuracy. In fact, it is know that humans are subjects to 100s of well-known “bugs” 1 , and probably many more unknown ones. To reduce the number of potential mistakes and to increase our confidence in a validity of a proof a number of independent human mathematicians should examine an important mathematical claim. As Calude puts it “A theorem is a statement which could be checked individually by a mathematician and confirmed also individually by at least two or three other mathematicians, each of them working independently. But already we can observe the weakness of the criterion: how many mathematicians are to check individually and independently the status of [a conjecture] to give it a status of a theorem” [4].\nClearly the greater the number of independent verifiers the higher is our confidence in the validity of a theorem, we can say that “a theorem is validated if it has been accepted by a general agreement of the mathematical community” [4]. Krantz agrees and says: “… it is the mathematics profession, taken as a whole, that decides what is correct and valid, and also what is useful and is interesting and has value” [10]. Wittgenstein expresses similar views, as quoted in [11]: “… who validates the ‘mathematical knowledge’? … the acceptability ultimately comes from the collective opinion of the social group of people practising mathematics”. So for many practitioners of mathematics proof verification is a social and democratic process in which “[a]fter enough internalization, enough transformation, enough generalization, enough use, and enough connection, the mathematical community eventually decides that the central concepts in the original theorem, now perhaps greatly changed, have an ultimate stability. If the various proofs feel right and the results are examined from enough angles, then the truth of the theorem is eventually considered to be established” [12].\n1 https://en.wikipedia.org/wiki/List_of_cognitive_biases\nWhile mathematical community as a whole constitutes a powerful proof verifier, a desire for ever greater accuracy has lead researchers to develop mechanized verification systems capable of handling formal proofs of great length. The prototype for such verifiers has its roots in formal systems [13] proposed by David Hillbert and which “… contain an algorithm that mechanically checks the validity of all proofs that can be formulated in the system. The formal system consists of an alphabet of symbols in which all statements can be written; a grammar that specifies how the symbols are to be combined; a set of axioms, or principles accepted without proof; and rules of inference for deriving theorems from the axioms” [14]. However there is a tradeoff when one switches from using human verifiers to utilizing automated ones, namely: “People are usually not very good in checking formal correctness of proofs, but they are quite good at detecting potential weaknesses or flaws in proofs” [15]. “… ‘Artificial’ mathematicians are far less ingenious and subtle than human mathematics, but they surpass their human counterparts by being infinitely more patient and diligent” [4]. In other words while automated verifiers are excellent at spotting incorrect deductions they are much worse than humans at seeing the “big picture” outlined in the proof.\nAdditionally, to maintain a consistent standard of verification for all excepted theorems a significant effort would need to be applied to reexamination of already accepted proofs. “… to do so would certainly entail going back and rewriting from scratch all old mathematical papers whose results we depend on. It is also quite hard to come up with good technical choices for formal definitions that will be valid in the variety of ways that mathematicians want to use them and that will anticipate future extensions of mathematics. … [M]uch of our time would be spent with international standards commissions to establish uniform definitions and resolve huge controversies” [15].\nSuch criticism of automated verifiers is not new and has been expressed in the past particularly from human centric point of view: “No matter how precise the rules (logical and physical) are, we need human consciousness to apply the rules and to understand them and their consequences. Mathematics is a human activity” [4]. Additionally, while “[m]echanical proof-checkers have indeed been developed, though their use is currently limited by the need for the proof to be written in precisely the right logical formalism [16]”.\nDespite such criticism there is also a lot of hope in terms of what the automated verification can offer mathematics. “… mathematical knowledge is far too vast to be understood by one person, moreover, it has been estimated that the total amount of published mathematics doubles every ten to fifteen years… Perhaps computers can also help us to navigate, abstract and, hence, understand … proofs. Realising this dream of: computer access to a world repository of mathematical knowledge; visualising and understanding this knowledge; reusing and combining it to discover new knowledge…” [17]."
    }, {
      "heading" : "3. Classification of Verifiers",
      "text" : "It is likely that a very deep and fundamental connection exists between the concept of observer in physics and a verifier in mathematics/science. Both must be instantiated in the physical world as either hardware or software to perform its function, but other than that, we currently have a very limited understanding of types and properties associated with such agents. As the first step, we propose a simple classification system for verifiers, sorting them with respect to domain of\napplication, type of implementation and meta-properties. With respect to domain, we see verifiers as necessary for checking mathematical proofs, scientific theories, software correctness, intelligent behavior safety and consistency and properties of algorithms. Some examples:\n Software Verifier – via Curry-Harvard Correspondence [18], proof verification and program verification are equivalent and software verification is a special case of theorem verification\nrestricted to computational logic [19]. A compiler or interpreter can be seen as a program syntax verifier.\n AI-Verifier – is a particular type of Software Verifier capable of verifying behavior of intelligent systems in novel environments unknown at the time of design [20],[21].\nYampolskiy presents verification of self-improving software [22, 23] as a particular challenge to the AI community: “Ideally every generation of self-improving system should be able to produce a verifiable proof of its safety for external examination [24].” Consequently, research linking functional specification to physical states is of great interest. “This type of theory would allow use of formal tools to anticipate and control behaviors of systems that approximate rational agents, alternate designs such as satisficing agents, and systems that cannot be easily described in the standard agent formalism (powerful prediction systems, theorem-provers, limited-purpose science or engineering systems, etc.). It may also be that such a theory could allow rigorously demonstrating that systems are constrained from taking certain kinds of actions or performing certain kinds of reasoning [20].”\n Scientific Theory Verifier – examines output of computer simulations of scientific theories. A scientific theory cannot be considered fully accepted until it can be expressed as an\nalgorithm and simulated on a computer. It should produce observations consistent with measurements obtained in the real world, perhaps adjusting for relativity of time between simulation and real world. In other words, an unsimulatable hypothesis should be considered significantly weaker than a simulatable one. It is possible that the theory can’t be simulated due to limits in our current computational capacity, hardware design or capability of programmers and that it will become simulatable in the future, but until such time it should have a tentative status. A scientific theory verifier could be seen as a formalized equivalent of a peer-reviewer in science.\n NP-Complete Solution Verifier – is an algorithm which can quickly (in polynomial time) check a certificate (aka witness) representing a solution which can be used to determine if a\ncomputation produces a “yes” or “no” answer. In fact, one of the definitions of NPCompleteness states that a problem is in that class if there exists a verifier for the problem. NP-Completeness Verifier would check a reduction of a novel problem to an already known problem in the NP class to determine if it is of equal or lesser complexity. Analogously we can postulate an AI-Completeness Verifier – capable of checking if a problem is reducible to an instance of Turing Test [25-27].\nWith respect to type, verifiers could be people (or groups of people), software, hypothetical agents such as oracles, or artificially (super)intelligent entities. For example:\n Human Mathematician – historically the default verifier for most mathematical proofs. Individual mathematicians have been recruited to examine mathematical reasoning since the\ninception of the field. Recent developments in computer-generated proofs appear to be beyond capacity of human verifiers due to the size of such proofs.\n Mathematical Community – a collective of mathematicians as a whole used to examine and evaluate proof claims while at the same time removing any outlier opinions of individual\nmathematicians. It is well known that wisdom of crowds can outperform individual experts [28, 29].\n Mechanical Verifier (Automated Proof Checker) – Automated software and hardware verifiers such as computer programs have been developed to assist in verification of formal\nproofs [30]. “The proof checker verifies that each inference step in the proof is a valid instance of one of the axioms and inference rules specified as part of the safety policy [31].” They are believed to be more accurate than human mathematicians and are capable of verifying much longer proofs, which may not be surveyable [32-35] or too complex (not comprehensible [36]) for human mathematicians.\n Hybrid Verifier – a combination of other types of verifiers, most typically human mathematician assisted by a mechanical verifier.\n Oracle Verifier – a verifier with access to an Oracle Turing Machine. Particular types would include Halting Verifier (a hypothetical verifier not subject to the halting problem), Gödel\nVerifier (not subject to incompleteness limits) and undecidable proof verifier. All such verification would be done in a single computational step.\n (Super)Intelligent Verifier – verifier capable of checking all decidable proofs, particularly those constructed by superintelligent AI.\nSome verifiers also have non-trivial mathematical properties, which include: ability to selfverify, probabilistic proof checking, relative correctness, designated nature, meta verification capacity, honest or dishonest behavior and axiomatic acceptance. For example:\n Axiomatically Correct Verifier – a type of authority based verifier, which decides truth of a theorem without a need to disclose its process. A verifier who’s correctness is accepted\nwithout justification like an axiom by the math community.\n Designated Verifier – For some proofs of knowledge it is important that only the verifier nominated by the confirmer can get any conviction of the correctness of the proof [37].\n Honest (Trusted) verifier – “… does not try to extract any secret from the prover by deviating from the proof protocol. … Untrusted-verifier does not need to assume that the\nverifier is honest” [38].\n Probabilistic Verifier – a verifier, which by examining ever-greater number of parts of a proof arrives at a probabilistic measure of theorem’s correctness. Such verifiers could be a\npart of Zero Knowledge based protocols.\n Relative Verifier – a verifier with respect to which a particular theorem has been shown to be correct.\n Gradual Verifier – a verifier which determines a percentage of statements that are already guaranteed to be safe [39].\n Meta-Verifier – a hypothetical verifier capable of checking correctness of all other verifiers.\n Self-Verifier – an agent which is capable of verifying its own accuracy [40]. A frequently suggested approach to avoid an infinite regress of verifiers, a self-verifying verifier could\ncontain an error causing it to erroneously claim its own correctness [41] and is also subject to limitations imposed by Godel’s Incompleteness theorem [42] and other similar selfreferential constraints [21]."
    }, {
      "heading" : "4. Unverifiability",
      "text" : "Unverifiability, an idea frequently discussed in philosophy [43-45], has been implicitly present in mathematics since the inception of the field. In this section, we survey literature, which deals with the limits of proof verifiability caused by infinite regress of verifiers, and provide analysis of the concept of unverifiability. We believe that such explicit discussion will be useful to researchers interested in being able to cite this important idea, which so far has been delegated to the status of mathematical folklore [46] and only alluded to in literature, despite being a more general result than incompleteness [42, 47].\nUnverifiability could be defined as a fundamental limitation on verification of mathematical proofs, computer software or behavior of intelligent agents. It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47], undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55]. Many paths can leads us to arrive at the concept of unverifiability, but as this paper is on Verifier Theory we concentrate specifically on the infinite regress of verifiers.\nFor example, Calude et al. state: “… what if the “agent” human or computer checking a proof for correctness makes a mistake (agents are fallible)? Obviously, another agent has to check that the agent doing the checking did not make any mistakes. Some other agent will need to check that agent and so on. Eventually one runs out of agents who could check the proof and, in principle, they could all have made a mistake!” [56]. And later, Calude and Muller emphasize: “…one cannot prove the correctness of the formal prover itself …” [57]. Similarly, MacKenzie observes: “Indeed, if one was to apply the formal, mechanical notion of proof entirely stringently, might not the software of the automated theorem prover itself have to be verified formally? … The formal, mechanized notion of proof thus prompted a modern day version of Juvenal’s ancient question, quis custodiet ipsos custodes, who will guard the guards themselves?” [58]. Others have expressed similar sentiments [11].\nOur trust in a formal proof is only as strong as our trust in the verifier used to check the proof and as the verifier itself needs to be verified, and so on ad infinitum, we are never given a 100% guarantee of correctness, only asymptotically increasing probability of correctness. Worse yet, at the end of the chain of verifiers there is typically a single human, whose internal mechanism is simply not verifiable with our current technology and possibly not verifiable in principal. Additionally, problems other than infinite regress of verifiers may significantly reduce our ability to verify proofs. Such obstacles include: splicing and skipping [59], hidden lemmas [60], exponential size proofs [61] (with recent publication of a 200 terabyte computer proof [62] being only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].\nAfter the advent of probabilistic proofs by Michael Rabin [67], “[s]ome have argued that there is no essential difference between such probabilistic proofs and the deterministic proofs of standard mathematical practice. Both are convincing arguments. Both are to be believed with a certain probability of error. In fact, many deterministic proofs, it is claimed, have a higher probability of error. [68]” “… the authenticity of a mathematical proof is not absolute, but only probabilistic.\n… Proofs cannot be too long, else their probabilities go down and they baffle the checking process. To put it in another way: all really deep theorems are false (or at best unproved or unprovable). All true theorems are trivial. [3]” “A derivation of a theorem or a verification of a proof has only probabilistic validity. It makes no difference whether the instrument of derivation or verification is man or a machine. The probabilities may vary, but are roughly of the same order of magnitude…[3].” All proofs have a certain level of “proofness” [69], which can be made arbitrarily deep via expending necessary verification resources, but “… in no domain of mathematics is the notion of provability a perfect substitute for the notion of truth [70].” To conclude, we reiterate Don Knuth’s famous warning: “Beware of bugs in the above code: I have only proved it correct, not tried it.”"
    }, {
      "heading" : "5. Unverifiability of Software",
      "text" : "Unverifiability has important consequences not just for mathematicians and philosophers of knowledge, but also, more recently it has become an important issue in software and hardware verification, which can be seen as special cases of proof verification [18, 19]. Just like a large portion of published mathematical proofs, software is known to contain massive amounts of bugs [71], perhaps as many as 50 per thousand lines of code 2 , but maybe as few as 2.3 [72]. Similarly, just like with mathematical proofs the issue of infinite regress of verifiers is making software only probabilistically verifiable. For example, Fetzer writes: “There are no special difficulties so long as [higher-level machines’] intended interpretations are abstract machines. When their intended interpretations are target machines, then we encounter the problem of determining the reliability of the verifying programs themselves (“How do we verify the verifiers?”), which invites a regress of relative verifications of relative verifications.” [73].\nThis notion of unverifiability of software has been a part of the field since its early days. Smith writes: “For fundamental reasons - reasons that anyone can understand - there are inherent limitations to what can be proven about computers and computer programs. … Just because a program is \"proven correct\" …, you cannot be sure that it will do what you intend. [74]” Rodd agrees and says: “Indeed, although it is now almost trite to say it, since the comprehensive testing of software is impossible, only very vague estimates of any program's reliability seem ever to be possible. [75]” At the same time, most software is released without any attempt to formally verify it in the first place."
    }, {
      "heading" : "5.1 Artificial Intelligence Unverifiability",
      "text" : "Particular type of software, known as Artificial Intelligence (AI) (and even more so superintelligence, differs from other software by its ability to learn new behaviors, adjust its performance and act autonomously in novel situations. Given potential impact from intelligent software, it is not surprising that ability to verify future intelligent behavior is one of the grand challenges of modern AI research [24, 76, 77].\nIt has been observed that science frequently discovers so called “conjugate (complimentary) pairs\", “…a couple of requirements, each of them being satisfied only at the expense of the other … . Famous prototypes of conjugate pairs are (position, momentum) discovered by W. Heisenberg in quantum mechanics and (consistency, completeness) discovered by K. Gödel in\n2 http://www.theengineer.co.uk/issues/may-2013-online/verification-system-aims-to-guarantee-software-function/\nlogic. But similar warnings come from other directions. According to Einstein …, “in so far as the propositions of mathematics are certain, they do not refer to reality, and in so far as they refer to reality, they are not certain\", hence (certainty, reality) is a conjugate pair. [56]” Similarly, in proofs we are “[t]aking rigour as something that can be acquired only at the expense of meaning and conversely, taking meaning as something that can be obtained only at the expense of rigour … [56]”. With respect to intelligent agents, we can propose an additional conjugate pair - (capability, control). The more generally intelligent and capable an entity is the less likely it is to be predictable, controllable or verifiable.\nIt is becoming obvious, that just like we can only have probabilistic confidence in correctness of mathematical proofs and software implementations, our ability to verify intelligent agents is at best limited. As Gerwin Klein puts it: “… if you really want to build a system that can have truly unexpected behaviour, then by definition you cannot verify that it is safe, because you just don’t know what it will do.” 3 Muehlhauser writes: “The same reasoning applies to [Artificial General Intelligence] AGI ‘friendliness.’ Even if we discover (apparent) solutions to known open problems in Friendly AI research, this does not mean that we can ever build an AGI that is ‘provably friendly’ in the strongest sense, because … we can never be 100% certain that there are no errors in our formal reasoning. … Thus, the approaches sometimes called ‘provable security,’ ‘provable safety,’ and ‘provable friendliness’ should not be misunderstood as offering 100% guarantees of security, safety, and friendliness.” 4 Jilk, writing on limits to verification and validation in AI points out that “language of certainty” is unwarranted in reference to agentic behavior [78]. He also sates: “ … there cannot be a general automated procedure for verifying that an agent absolutely conforms to any determinate set of rules of action.”\nThese results are not surprising, AI cannot be verified because it itself can serve as a verifier which we already showed cannot be verified because of infinite regress problem and general unverifiability. By spending increasing (computational) resources, the best we can hope for is an increased statistical probability that our mathematical proofs, software/AI is error free, but we should never forget that a 100% accurate verification is not possible, even in theory, and act accordingly. Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84]."
    }, {
      "heading" : "6. Conclusions and Future Work",
      "text" : "Our early stage work suggests “verifier” be investigated as a new mathematical object of interest for future study and predicts significant benefit from our improved understanding of the topic. For example, an artificially intelligent verifier could be used to re-check all previously published mathematical proofs, greatly increasing correctness of all proofs, which depend on prior work. Problems such as infinite regress of verifiers may be unsolvable but methods such as probabilistic verification should be capable of giving us as much assurance as we are willing to pay for. Any progress in the proposed “verifier theory” will have additional benefits beyond its contribution to mathematics by making it possible to design safer advanced Artificial Intelligence, a topic that is predicted to become one of the greatest problems in science in the upcoming decades [85, 86]. Verifier is a hidden component of any proof; we can improve our capacity to verify by explicitly describing the required verification agent.\n3 https://intelligence.org/2014/02/11/gerwin-klein-on-formal-methods 4 https://intelligence.org/2013/10/03/proofs/\nIt would be valuable to learn what types of physical or informational systems can act as verifiers and what are their essential properties? How selection of the type of the verifier influences mathematics as a field and specifically what categories of theorems we can or can’t prove with respect to different verifiers. Are there still undiscovered types of mathematical verifiers? Does a group of verifiers have greater power than the sum of its component modules? How can verifiers perform best while operating with limited computational resources? What is the formal relationship between the set of all verifiers and the set of all observers? Can a verifier be hacked and can the attack be contained in the proof it is examining? Can all these questions be reduced to a broader question on the nature of different possible types of intelligences [87]?"
    }, {
      "heading" : "Acknowledgements",
      "text" : "The author is grateful to Kenneth Regan, Edward Frenkel and Sebastien Zany for valuable advice on the topic. Author is particularly thankful to Yana Feygin for proofreading a draft of this work. Finally, I would like to emphasize that the “proof” presented in this paper is itself subject to unverifiability and as such is certainly not guaranteed to be correct, but probably is."
    } ],
    "references" : [ {
      "title" : "Physics of the Observer - an international request for proposals for reserach and outreach projects. 2015: http://www.braude.ac.il/files/research_development/2016Request-for-Proposals_FQXi.pdf",
      "author" : [ "M. Tegmark", "A. Aguirre" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2016
    }, {
      "title" : "An introduction to proof theory",
      "author" : [ "S.R. Buss" ],
      "venue" : "Handbook of proof theory,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1998
    }, {
      "title" : "Fidelity in mathematical discourse: Is one and one really two",
      "author" : [ "P.J. Davis" ],
      "venue" : "American Mathematical Monthly,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1972
    }, {
      "title" : "Passages of Proof, in University of Auckland",
      "author" : [ "C.S. Calude", "E. Calude", "S. Marcus" ],
      "venue" : "Massey University. Romanian Academy",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2002
    }, {
      "title" : "The four-color theorem and mathematical proof",
      "author" : [ "M. Detlefsen", "M. Luker" ],
      "venue" : "The Journal of Philosophy,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1980
    }, {
      "title" : "Bounding the impact of AGI",
      "author" : [ "A. Kornai" ],
      "venue" : "Journal of Experimental & Theoretical Artificial Intelligence,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2014
    }, {
      "title" : "How to write a proof",
      "author" : [ "L. Lamport" ],
      "venue" : "The American mathematical monthly,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1995
    }, {
      "title" : "The Automation of Proof: A Historical and Sociological Exploration",
      "author" : [ "D. Mackenzie" ],
      "venue" : "IEEE Annals of the History of Computing,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1995
    }, {
      "title" : "The Proof is in the Pudding",
      "author" : [ "S.G. Krantz" ],
      "venue" : "A Look at the Changing Nature of Mathematical Proof",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2007
    }, {
      "title" : "Mathematical proofs at a crossroad?, in Theory Is Forever",
      "author" : [ "C.S. Calude", "S. Marcus" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "Social Processes and Proofs of Theorems and Programs",
      "author" : [ "R.A.D. Millo", "R.J. Lipton", "A.J. Perlis" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1979
    }, {
      "title" : "A ‘Theory’mechanism for a proof-verifier based on first-order set theory, in Computational Logic: Logic Programming and Beyond",
      "author" : [ "E.G. Omodeo", "J.T. Schwartz" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2002
    }, {
      "title" : "Randomness and Mathematical Proof",
      "author" : [ "G.J. Chaitin" ],
      "venue" : "Scientific American, May 1975",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1975
    }, {
      "title" : "On Proof and Progress in Mathematics",
      "author" : [ "W.P. Thurston" ],
      "venue" : "Bulletin of the American Mathematical Society,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1994
    }, {
      "title" : "Slaying the Kraken: The Sociohistory of a Mathematical Proof",
      "author" : [ "D. MacKenzie" ],
      "venue" : "Social Studies of Science, February 1999",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1999
    }, {
      "title" : "OMDoc: An Open Markup Format for Mathematical Documents",
      "author" : [ "M. Kohlhase" ],
      "venue" : "Lecture Notes in Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "A mechanized program verifier, in Verified Software: Theories, Tools, Experiments",
      "author" : [ "J.S. Moore" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2008
    }, {
      "title" : "Research Priorities for Robust and Benecial Artificial Intelligence, in Future of Life  Institute",
      "author" : [ "S Russell" ],
      "venue" : "http://futureoflife.org/static/data/documents/research_priorities.pdf",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Tiling agents for self-modifying AI, and the Löbian obstacle",
      "author" : [ "E. Yudkowsky", "M. Herreshoff" ],
      "venue" : "MIRI Technical Report",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "On the Limits of Recursively Self-Improving AGI",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "The Eighth Conference on Artificial General Intelligence. July 22-25,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Analysis of Types of Self-Improving Software",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "The Eighth Conference on Artificial General Intelligence. July 22-25,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2015
    }, {
      "title" : "Artificial intelligence safety engineering: Why machine ethics is a wrong approach, in Philosophy and Theory of Artificial Intelligence",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2013
    }, {
      "title" : "Turing Test as a Defining Feature of AI-Completeness, in Artificial Intelligence, Evolutionary Computation and Metaheuristics - In the footsteps of Alan Turing",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    }, {
      "title" : "AI-Complete, AI-Hard, or AI-Easy – Classification of Problems in AI, in The 23rd Midwest Artificial Intelligence and Cognitive Science Conference",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "April 21-22,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2012
    }, {
      "title" : "AI-Complete CAPTCHAs as Zero Knowledge Proofs of Access to an Artificially Intelligent System",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "ISRN Artificial Intelligence,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2011
    }, {
      "title" : "Wisdom of Artificial Crowds—A Metaheuristic Algorithm for Optimization",
      "author" : [ "R.V. Yampolskiy", "L. Ashby", "L. Hassan" ],
      "venue" : "Journal of Intelligent Learning Systems and Applications,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2012
    }, {
      "title" : "The seventeen provers of the world: Foreword",
      "author" : [ "F. Wiedijk" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2006
    }, {
      "title" : "Safe, untrusted agents using proof-carrying code, in Mobile Agents and Security",
      "author" : [ "G.C. Necula", "P. Lee" ],
      "venue" : null,
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1998
    }, {
      "title" : "A mathematical proof must be surveyable. What Wittgenstein meant by this and what it implies",
      "author" : [ "F. Mülhölzer" ],
      "venue" : "Grazer Philosophische Studien,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2005
    }, {
      "title" : "The surveyability of long proofs",
      "author" : [ "E. Coleman" ],
      "venue" : "Foundations of Science,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2009
    }, {
      "title" : "Computers, proofs and mathematicians: A philosophical investigation of the fourcolor proof",
      "author" : [ "T. Tymoczko" ],
      "venue" : "Mathematics magazine,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1980
    }, {
      "title" : "Efficiency Theory: a Unifying Theory for Information, Computation and Intelligence",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "Journal of Discrete Mathematical Sciences & Cryptography,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2013
    }, {
      "title" : "Designated verifier proofs and their applications. in Advances in Cryptology—EUROCRYPT’96",
      "author" : [ "M. Jakobsson", "K. Sako", "R. Impagliazzo" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1996
    }, {
      "title" : "Efficient proof of bid validity with untrusted verifier in homomorphic e-auction",
      "author" : [ "K. Peng" ],
      "venue" : "IET Information Security,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2013
    }, {
      "title" : "The Gradual Verifier. in NASA Formal Methods",
      "author" : [ "S Arlt" ],
      "venue" : null,
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2014
    }, {
      "title" : "Promskii, Towards the verified verifier. Theory and practice",
      "author" : [ "D.A. Kondrat'ev", "A.V" ],
      "venue" : "Modelirovanie i Analiz Informatsionnykh Sistem [Modeling and Analysis of Information Systems],",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2014
    }, {
      "title" : "Foundational proof-carrying code, in 16th Annual",
      "author" : [ "A.W. Appel" ],
      "venue" : "IEEE Symposium on Logic in Computer Science",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2001
    }, {
      "title" : "On undecidable propositions of formal mathematical systems. 1934: Institute for Advanced Study Princeton, NJ",
      "author" : [ "K. Gödel", "S.C. Kleene", "J.B. Rosser" ],
      "venue" : null,
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 1934
    }, {
      "title" : "The principle of verifiability",
      "author" : [ "M. Black" ],
      "venue" : "Analysis, 1934",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 1934
    }, {
      "title" : "The Unverifiability of Unverifiability",
      "author" : [ "R.C. Hoy" ],
      "venue" : "Philosophy and Phenomenological Research,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 1973
    }, {
      "title" : "The nature of mathematical proof",
      "author" : [ "R.L. Wilder" ],
      "venue" : "The American Mathematical Monthly,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 1944
    }, {
      "title" : "Proving as a computable procedure",
      "author" : [ "C.S. Calude", "S. Rudeanu" ],
      "venue" : "Fundamenta Informaticae,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2005
    }, {
      "title" : "Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik",
      "author" : [ "W. Heisenberg" ],
      "venue" : "Zeitschrift für Physik, 1927",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 1927
    }, {
      "title" : "Stay, From Heisenberg to Gödel via Chaitin",
      "author" : [ "C.S. Calude", "M.A" ],
      "venue" : "International Journal of Theoretical Physics,",
      "citeRegEx" : "49",
      "shortCiteRegEx" : "49",
      "year" : 2007
    }, {
      "title" : "Incompleteness, complexity, randomness and beyond",
      "author" : [ "C.S. Calude" ],
      "venue" : "Minds and Machines,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2002
    }, {
      "title" : "On Computable Numbers, with an Application to the Entscheidungsproblem",
      "author" : [ "A.M. Turing" ],
      "venue" : "Proceedings of the London Mathematical Society, 1936",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 1936
    }, {
      "title" : "Undefinability of truth. The problem of priority: Tarski vs Gödel",
      "author" : [ "R. Murawski" ],
      "venue" : "History and Philosophy of Logic,",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 1998
    }, {
      "title" : "The unprovability of consistency: an essay in modal logic",
      "author" : [ "G. Boolos" ],
      "venue" : null,
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 2009
    }, {
      "title" : "Computing a glimpse of randomness",
      "author" : [ "C.S. Calude", "M.J. Dinneen", "C.-K. Shu" ],
      "venue" : "Experimental Mathematics,",
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 2002
    }, {
      "title" : "Relativity: The special and the general theory",
      "author" : [ "A. Einstein" ],
      "venue" : null,
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 2015
    }, {
      "title" : "Formal proof: reconciling correctness and understanding, in Intelligent Computer Mathematics",
      "author" : [ "C.S. Calude", "C. Müller" ],
      "venue" : null,
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 2009
    }, {
      "title" : "Mechanizing proof: computing, risk, and trust",
      "author" : [ "D. MacKenzie" ],
      "venue" : null,
      "citeRegEx" : "58",
      "shortCiteRegEx" : "58",
      "year" : 2004
    }, {
      "title" : "Proofs and refutations (III)",
      "author" : [ "I. Lakatos" ],
      "venue" : "The British Journal for the Philosophy of Science,",
      "citeRegEx" : "60",
      "shortCiteRegEx" : "60",
      "year" : 1963
    }, {
      "title" : "The intractability of resolution",
      "author" : [ "A. Haken" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "61",
      "shortCiteRegEx" : "61",
      "year" : 1985
    }, {
      "title" : "Solving and Verifying the boolean Pythagorean Triples problem via Cube-and-Conquer",
      "author" : [ "M.J. Heule", "O. Kullmann", "V.W. Marek" ],
      "venue" : "arXiv preprint arXiv:1605.00723,",
      "citeRegEx" : "62",
      "shortCiteRegEx" : "62",
      "year" : 2016
    }, {
      "title" : "The biggest mystery in mathematics: Shinichi Mochizuki and the impenetrable",
      "author" : [ "D. Castelvecchi" ],
      "venue" : null,
      "citeRegEx" : "63",
      "shortCiteRegEx" : "63",
      "year" : 2015
    }, {
      "title" : "Is quantum computing inherently evil",
      "author" : [ "M. Wolf", "F. Grodzinsky", "K. Miller" ],
      "venue" : "CEPE 2011: Crossing Boundaries:",
      "citeRegEx" : "64",
      "shortCiteRegEx" : "64",
      "year" : 2011
    }, {
      "title" : "Ultimate cognition à la Gödel",
      "author" : [ "J. Schmidhuber" ],
      "venue" : "Cognitive Computation,",
      "citeRegEx" : "65",
      "shortCiteRegEx" : "65",
      "year" : 2009
    }, {
      "title" : "Classes of recursively enumerable sets and their decision problems",
      "author" : [ "H.G. Rice" ],
      "venue" : "Transactions of the American Mathematical Society,",
      "citeRegEx" : "66",
      "shortCiteRegEx" : "66",
      "year" : 1953
    }, {
      "title" : "Probabilistic algorithms, in Research Division",
      "author" : [ "M. Rabin" ],
      "venue" : "Thomas J. Watson IBM Research Center",
      "citeRegEx" : "67",
      "shortCiteRegEx" : "67",
      "year" : 1976
    }, {
      "title" : "Rigor and proof in mathematics: A historical perspective",
      "author" : [ "I. Kleiner" ],
      "venue" : "Mathematics Magazine,",
      "citeRegEx" : "68",
      "shortCiteRegEx" : "68",
      "year" : 1991
    }, {
      "title" : "How convincing is a proof",
      "author" : [ "Y.I. Manin" ],
      "venue" : "Math. Intelligencer,",
      "citeRegEx" : "69",
      "shortCiteRegEx" : "69",
      "year" : 1979
    }, {
      "title" : "Economics of software verification",
      "author" : [ "G.J. Holzmann" ],
      "venue" : "Proceedings of the 2001 ACM SIGPLANSIGSOFT workshop on Program analysis for software tools and engineering",
      "citeRegEx" : "71",
      "shortCiteRegEx" : "71",
      "year" : 2001
    }, {
      "title" : "Software verification and validation: an overview",
      "author" : [ "D.R. Wallace", "R.U. Fujii" ],
      "venue" : "IEEE Software,",
      "citeRegEx" : "72",
      "shortCiteRegEx" : "72",
      "year" : 1989
    }, {
      "title" : "Program verification: the very idea",
      "author" : [ "J.H. Fetzer" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "73",
      "shortCiteRegEx" : "73",
      "year" : 1988
    }, {
      "title" : "The limits of correctness",
      "author" : [ "B.C. Smith" ],
      "venue" : "ACM SIGCAS Computers and Society,",
      "citeRegEx" : "74",
      "shortCiteRegEx" : "74",
      "year" : 1985
    }, {
      "title" : "Safe AI—is this possible",
      "author" : [ "M. Rodd" ],
      "venue" : "Engineering Applications of Artificial Intelligence,",
      "citeRegEx" : "75",
      "shortCiteRegEx" : "75",
      "year" : 1995
    }, {
      "title" : "Verification and validation and artificial intelligence",
      "author" : [ "T. Menzies", "C. Pecheur" ],
      "venue" : "Advances in computers,",
      "citeRegEx" : "77",
      "shortCiteRegEx" : "77",
      "year" : 2005
    }, {
      "title" : "Limits to Verification and Validation of Agentic Behavior",
      "author" : [ "D.J. Jilk" ],
      "venue" : "arXiv preprint arXiv:1604.06963,",
      "citeRegEx" : "78",
      "shortCiteRegEx" : "78",
      "year" : 2016
    }, {
      "title" : "Unethical Research: How to Create a Malevolent Artificial Intelligence",
      "author" : [ "F. Pistono", "R.V. Yampolskiy" ],
      "venue" : "arXiv preprint arXiv:1605.02817,",
      "citeRegEx" : "79",
      "shortCiteRegEx" : "79",
      "year" : 2016
    }, {
      "title" : "Taxonomy of Pathways to Dangerous Artificial Intelligence",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "Workshops at the Thirtieth AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "80",
      "shortCiteRegEx" : "80",
      "year" : 2016
    }, {
      "title" : "Utility function security in artificially intelligent agents",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "Journal of Experimental & Theoretical Artificial Intelligence,",
      "citeRegEx" : "81",
      "shortCiteRegEx" : "81",
      "year" : 2014
    }, {
      "title" : "Responses to catastrophic AGI risk: a survey",
      "author" : [ "K. Sotala", "R.V. Yampolskiy" ],
      "venue" : "Physica Scripta,",
      "citeRegEx" : "82",
      "shortCiteRegEx" : "82",
      "year" : 2014
    }, {
      "title" : "Safety engineering for artificial general intelligence",
      "author" : [ "R. Yampolskiy", "J. Fox" ],
      "venue" : "Topoi,",
      "citeRegEx" : "83",
      "shortCiteRegEx" : "83",
      "year" : 2013
    }, {
      "title" : "What to Do with the Singularity Paradox",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : "Philosophy and Theory of Artificial Intelligence",
      "citeRegEx" : "84",
      "shortCiteRegEx" : "84",
      "year" : 2013
    }, {
      "title" : "Responses to Catastrophic AGI risk: A Survey",
      "author" : [ "K. Sotala", "R.V. Yampolskiy" ],
      "venue" : "Physica Scripta, January",
      "citeRegEx" : "85",
      "shortCiteRegEx" : "85",
      "year" : 2015
    }, {
      "title" : "Artificial Superintelligence: a Futuristic Approach. 2015: Chapman and Hall/CRC",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : null,
      "citeRegEx" : "86",
      "shortCiteRegEx" : "86",
      "year" : 2015
    }, {
      "title" : "The Space of Possible Mind Designs, in Artificial General Intelligence",
      "author" : [ "R.V. Yampolskiy" ],
      "venue" : null,
      "citeRegEx" : "87",
      "shortCiteRegEx" : "87",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "On Observers and Verifiers The concept of an ‘observer’ shows up in contexts as diverse as physics (particularly quantum), biophysics, neuroscience, cognitive science, artificial intelligence, philosophy of consciousness, relativity, and cosmology [1], but what is an equivalent idea in mathematics? We believe it is the notion of the proof ‘verifier’.",
      "startOffset" : 248,
      "endOffset" : 251
    }, {
      "referenceID" : 0,
      "context" : "Consequently, majority of open questions recently raised [1] by the Foundational Questions Institute related to the physics of the observer, could be asked about proof verifiers.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 1,
      "context" : "of axioms from which, by rules of inference, one can arrive at theorems [2].",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 2,
      "context" : "Traditionally human mathematicians have been employed as proof verifiers, but unfortunately history is full of examples of undetected errors and important omissions even in the most widely examined proofs [3-7].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 3,
      "context" : "Traditionally human mathematicians have been employed as proof verifiers, but unfortunately history is full of examples of undetected errors and important omissions even in the most widely examined proofs [3-7].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 4,
      "context" : "Traditionally human mathematicians have been employed as proof verifiers, but unfortunately history is full of examples of undetected errors and important omissions even in the most widely examined proofs [3-7].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 5,
      "context" : "Traditionally human mathematicians have been employed as proof verifiers, but unfortunately history is full of examples of undetected errors and important omissions even in the most widely examined proofs [3-7].",
      "startOffset" : 205,
      "endOffset" : 210
    }, {
      "referenceID" : 6,
      "context" : "It has been estimated that at least a third of all mathematical publications contain errors [8].",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "No doubt this custom originated in the desire that each single step of a deduction should be indubitable, even though the deduction as a whole may consist of a long chain of such steps” [9].",
      "startOffset" : 186,
      "endOffset" : 189
    }, {
      "referenceID" : 3,
      "context" : "But already we can observe the weakness of the criterion: how many mathematicians are to check individually and independently the status of [a conjecture] to give it a status of a theorem” [4].",
      "startOffset" : 189,
      "endOffset" : 192
    }, {
      "referenceID" : 3,
      "context" : "Clearly the greater the number of independent verifiers the higher is our confidence in the validity of a theorem, we can say that “a theorem is validated if it has been accepted by a general agreement of the mathematical community” [4].",
      "startOffset" : 233,
      "endOffset" : 236
    }, {
      "referenceID" : 8,
      "context" : "it is the mathematics profession, taken as a whole, that decides what is correct and valid, and also what is useful and is interesting and has value” [10].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 9,
      "context" : "Wittgenstein expresses similar views, as quoted in [11]: “.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 10,
      "context" : "If the various proofs feel right and the results are examined from enough angles, then the truth of the theorem is eventually considered to be established” [12].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 11,
      "context" : "The prototype for such verifiers has its roots in formal systems [13] proposed by David Hillbert and which “.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 12,
      "context" : "The formal system consists of an alphabet of symbols in which all statements can be written; a grammar that specifies how the symbols are to be combined; a set of axioms, or principles accepted without proof; and rules of inference for deriving theorems from the axioms” [14].",
      "startOffset" : 271,
      "endOffset" : 275
    }, {
      "referenceID" : 13,
      "context" : "However there is a tradeoff when one switches from using human verifiers to utilizing automated ones, namely: “People are usually not very good in checking formal correctness of proofs, but they are quite good at detecting potential weaknesses or flaws in proofs” [15].",
      "startOffset" : 264,
      "endOffset" : 268
    }, {
      "referenceID" : 3,
      "context" : "‘Artificial’ mathematicians are far less ingenious and subtle than human mathematics, but they surpass their human counterparts by being infinitely more patient and diligent” [4].",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 13,
      "context" : "[M]uch of our time would be spent with international standards commissions to establish uniform definitions and resolve huge controversies” [15].",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 3,
      "context" : "Mathematics is a human activity” [4].",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 14,
      "context" : "Additionally, while “[m]echanical proof-checkers have indeed been developed, though their use is currently limited by the need for the proof to be written in precisely the right logical formalism [16]”.",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 15,
      "context" : "” [17].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 16,
      "context" : " Software Verifier – via Curry-Harvard Correspondence [18], proof verification and program verification are equivalent and software verification is a special case of theorem verification restricted to computational logic [19].",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 17,
      "context" : " AI-Verifier – is a particular type of Software Verifier capable of verifying behavior of intelligent systems in novel environments unknown at the time of design [20],[21].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 18,
      "context" : " AI-Verifier – is a particular type of Software Verifier capable of verifying behavior of intelligent systems in novel environments unknown at the time of design [20],[21].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 19,
      "context" : "Yampolskiy presents verification of self-improving software [22, 23] as a particular challenge to the AI community: “Ideally every generation of self-improving system should be able to produce a verifiable proof of its safety for external examination [24].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 20,
      "context" : "Yampolskiy presents verification of self-improving software [22, 23] as a particular challenge to the AI community: “Ideally every generation of self-improving system should be able to produce a verifiable proof of its safety for external examination [24].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 21,
      "context" : "Yampolskiy presents verification of self-improving software [22, 23] as a particular challenge to the AI community: “Ideally every generation of self-improving system should be able to produce a verifiable proof of its safety for external examination [24].",
      "startOffset" : 251,
      "endOffset" : 255
    }, {
      "referenceID" : 17,
      "context" : "It may also be that such a theory could allow rigorously demonstrating that systems are constrained from taking certain kinds of actions or performing certain kinds of reasoning [20].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 22,
      "context" : "to an instance of Turing Test [25-27].",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 23,
      "context" : "to an instance of Turing Test [25-27].",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 24,
      "context" : "to an instance of Turing Test [25-27].",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 25,
      "context" : "It is well known that wisdom of crowds can outperform individual experts [28, 29].",
      "startOffset" : 73,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : " Mechanical Verifier (Automated Proof Checker) – Automated software and hardware verifiers such as computer programs have been developed to assist in verification of formal proofs [30].",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 27,
      "context" : "“The proof checker verifies that each inference step in the proof is a valid instance of one of the axioms and inference rules specified as part of the safety policy [31].",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 28,
      "context" : "” They are believed to be more accurate than human mathematicians and are capable of verifying much longer proofs, which may not be surveyable [32-35] or too complex (not comprehensible [36]) for human mathematicians.",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 29,
      "context" : "” They are believed to be more accurate than human mathematicians and are capable of verifying much longer proofs, which may not be surveyable [32-35] or too complex (not comprehensible [36]) for human mathematicians.",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 30,
      "context" : "” They are believed to be more accurate than human mathematicians and are capable of verifying much longer proofs, which may not be surveyable [32-35] or too complex (not comprehensible [36]) for human mathematicians.",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 31,
      "context" : "” They are believed to be more accurate than human mathematicians and are capable of verifying much longer proofs, which may not be surveyable [32-35] or too complex (not comprehensible [36]) for human mathematicians.",
      "startOffset" : 186,
      "endOffset" : 190
    }, {
      "referenceID" : 32,
      "context" : " Designated Verifier – For some proofs of knowledge it is important that only the verifier nominated by the confirmer can get any conviction of the correctness of the proof [37].",
      "startOffset" : 174,
      "endOffset" : 178
    }, {
      "referenceID" : 33,
      "context" : "Untrusted-verifier does not need to assume that the verifier is honest” [38].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 34,
      "context" : " Gradual Verifier – a verifier which determines a percentage of statements that are already guaranteed to be safe [39].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 35,
      "context" : " Self-Verifier – an agent which is capable of verifying its own accuracy [40].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 36,
      "context" : "A frequently suggested approach to avoid an infinite regress of verifiers, a self-verifying verifier could contain an error causing it to erroneously claim its own correctness [41] and is also subject to limitations imposed by Godel’s Incompleteness theorem [42] and other similar self-",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 37,
      "context" : "A frequently suggested approach to avoid an infinite regress of verifiers, a self-verifying verifier could contain an error causing it to erroneously claim its own correctness [41] and is also subject to limitations imposed by Godel’s Incompleteness theorem [42] and other similar self-",
      "startOffset" : 258,
      "endOffset" : 262
    }, {
      "referenceID" : 18,
      "context" : "referential constraints [21].",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 38,
      "context" : "Unverifiability, an idea frequently discussed in philosophy [43-45], has been implicitly present in mathematics since the inception of the field.",
      "startOffset" : 60,
      "endOffset" : 67
    }, {
      "referenceID" : 39,
      "context" : "Unverifiability, an idea frequently discussed in philosophy [43-45], has been implicitly present in mathematics since the inception of the field.",
      "startOffset" : 60,
      "endOffset" : 67
    }, {
      "referenceID" : 40,
      "context" : "We believe that such explicit discussion will be useful to researchers interested in being able to cite this important idea, which so far has been delegated to the status of mathematical folklore [46] and only alluded to in literature, despite being a more general result than incompleteness [42, 47].",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 37,
      "context" : "We believe that such explicit discussion will be useful to researchers interested in being able to cite this important idea, which so far has been delegated to the status of mathematical folklore [46] and only alluded to in literature, despite being a more general result than incompleteness [42, 47].",
      "startOffset" : 292,
      "endOffset" : 300
    }, {
      "referenceID" : 41,
      "context" : "We believe that such explicit discussion will be useful to researchers interested in being able to cite this important idea, which so far has been delegated to the status of mathematical folklore [46] and only alluded to in literature, despite being a more general result than incompleteness [42, 47].",
      "startOffset" : 292,
      "endOffset" : 300
    }, {
      "referenceID" : 42,
      "context" : "It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47],",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 43,
      "context" : "It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47],",
      "startOffset" : 192,
      "endOffset" : 200
    }, {
      "referenceID" : 44,
      "context" : "It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47],",
      "startOffset" : 192,
      "endOffset" : 200
    }, {
      "referenceID" : 37,
      "context" : "It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47],",
      "startOffset" : 218,
      "endOffset" : 226
    }, {
      "referenceID" : 41,
      "context" : "It is an ultimate limit to our ability to know certain information and is similar to other major “impossibilities” to acquiring knowledge in our universe such as: uncertainty [48] (randomness [49, 50]), incompleteness [42, 47],",
      "startOffset" : 218,
      "endOffset" : 226
    }, {
      "referenceID" : 45,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 46,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 47,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 12,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 48,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 49,
      "context" : "undecidability [51], undefinability [52], unprovability [53], incompressibility [14], noncomputability [54], relativity [55].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 50,
      "context" : "” [57].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 51,
      "context" : "The formal, mechanized notion of proof thus prompted a modern day version of Juvenal’s ancient question, quis custodiet ipsos custodes, who will guard the guards themselves?” [58].",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 9,
      "context" : "Others have expressed similar sentiments [11].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 52,
      "context" : "Such obstacles include: splicing and skipping [59], hidden lemmas [60], exponential size proofs [61] (with recent publication of a 200 terabyte computer proof [62] being",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 53,
      "context" : "Such obstacles include: splicing and skipping [59], hidden lemmas [60], exponential size proofs [61] (with recent publication of a 200 terabyte computer proof [62] being",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 54,
      "context" : "Such obstacles include: splicing and skipping [59], hidden lemmas [60], exponential size proofs [61] (with recent publication of a 200 terabyte computer proof [62] being",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 55,
      "context" : "only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 56,
      "context" : "only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].",
      "startOffset" : 104,
      "endOffset" : 112
    }, {
      "referenceID" : 57,
      "context" : "only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].",
      "startOffset" : 104,
      "endOffset" : 112
    }, {
      "referenceID" : 58,
      "context" : "only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 37,
      "context" : "only a current record which is unlikely to stand for long), impenetrable proofs [63], hardware failures [64, 65], Rice’s theorem [66], and Gödel’s Incompleteness theorem [42].",
      "startOffset" : 170,
      "endOffset" : 174
    }, {
      "referenceID" : 59,
      "context" : "After the advent of probabilistic proofs by Michael Rabin [67], “[s]ome have argued that there is no essential difference between such probabilistic proofs and the deterministic proofs of standard mathematical practice.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 60,
      "context" : "[68]” “.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "[3]” “A derivation of a theorem or a verification of a proof has only probabilistic validity.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 61,
      "context" : "” All proofs have a certain level of “proofness” [69], which can be made arbitrarily deep via expending necessary verification resources, but “.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 16,
      "context" : "knowledge, but also, more recently it has become an important issue in software and hardware verification, which can be seen as special cases of proof verification [18, 19].",
      "startOffset" : 164,
      "endOffset" : 172
    }, {
      "referenceID" : 62,
      "context" : "Just like a large portion of published mathematical proofs, software is known to contain massive amounts of bugs [71], perhaps as many as 50 per thousand lines of code 2 , but maybe as few as 2.",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 63,
      "context" : "3 [72].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 64,
      "context" : "” [73].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 65,
      "context" : "[74]” Rodd agrees and says: “Indeed, although it is now almost trite to say it, since the comprehensive testing of software is impossible, only very vague estimates of any program's reliability seem ever to be possible.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 66,
      "context" : "[75]” At the same time, most software is released without any attempt to formally verify it in the first place.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "challenges of modern AI research [24, 76, 77].",
      "startOffset" : 33,
      "endOffset" : 45
    }, {
      "referenceID" : 67,
      "context" : "challenges of modern AI research [24, 76, 77].",
      "startOffset" : 33,
      "endOffset" : 45
    }, {
      "referenceID" : 68,
      "context" : "” 4 Jilk, writing on limits to verification and validation in AI points out that “language of certainty” is unwarranted in reference to agentic behavior [78].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 69,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 70,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 71,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 72,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 73,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 74,
      "context" : "Artificial Intelligence, and even more so artificial Superintelligence, is unverifiable and so potentially unsafe [79-84].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 75,
      "context" : "Any progress in the proposed “verifier theory” will have additional benefits beyond its contribution to mathematics by making it possible to design safer advanced Artificial Intelligence, a topic that is predicted to become one of the greatest problems in science in the upcoming decades [85, 86].",
      "startOffset" : 288,
      "endOffset" : 296
    }, {
      "referenceID" : 76,
      "context" : "Any progress in the proposed “verifier theory” will have additional benefits beyond its contribution to mathematics by making it possible to design safer advanced Artificial Intelligence, a topic that is predicted to become one of the greatest problems in science in the upcoming decades [85, 86].",
      "startOffset" : 288,
      "endOffset" : 296
    }, {
      "referenceID" : 77,
      "context" : "Are there still undiscovered types of mathematical verifiers? Does a group of verifiers have greater power than the sum of its component modules? How can verifiers perform best while operating with limited computational resources? What is the formal relationship between the set of all verifiers and the set of all observers? Can a verifier be hacked and can the attack be contained in the proof it is examining? Can all these questions be reduced to a broader question on the nature of different possible types of intelligences [87]?",
      "startOffset" : 529,
      "endOffset" : 533
    } ],
    "year" : 2016,
    "abstractText" : "Despite significant developments in Proof Theory, surprisingly little attention has been devoted to the concept of proof verifier. In particular, mathematical community may be interested in studying different types of proof verifiers (people, programs, oracles, communities, superintelligences, etc.) as mathematical objects, their properties, their powers and limitations (particularly in human mathematicians), minimum and maximum complexity, as well as selfverification and self-reference issues in verifiers. We propose an initial classification system for verifiers and provide some rudimentary analysis of solved and open problems in this important domain. Our main contribution is a formal introduction of the notion of unverifiability, for which the paper could serve as a general citation in domains of theorem proving, software and AI verification.",
    "creator" : "Microsoft® Word 2010"
  }
}