{
  "name" : "1212.2036.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Query-focused Multi-document Summarization: Combining a Novel Topic Model with Graph-based Semi-supervised Learning",
    "authors" : [ "Jiwei Li", "Sujian Li" ],
    "emails" : [ "jl3226@cornell.edu", "lisujian@pku.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "quality. Inspired by previous researches, we propose a two-layer (i.e. sentence layer and topic layer) graph-based semi-supervised learning approach. At the same time, we propose a novel topic model which makes full use of the dependence between sentences and words. Experimental results on DUC and TAC data sets demonstrate the effectiveness of our proposed approach."
    }, {
      "heading" : "1 Introduction",
      "text" : "Query-focused multi-document summarization can facilitate users to grasp the main idea of the documents according to the users‟ concern and has drawn much attention in recent years. In queryfocused summarization, one query is proposed\nbefore documents and it is usually a question or an imperative sentence for inquiring some aspects 1 about a certain event. Then according to the given query, each sentence in the related document collection is assigned a score representing its importance and higher ranked sentences are picked into summary.\nAmong the existing approaches for queryfocused summarization, graph-based semisupervised learning is a convenient and effective\nway to impose the query‟s influence on sentence ranking (Zhou, et al., 2003; Zhou, et al., 2004;\n1 It is noted that the words “topic” “aspect” and “theme” in this paper express the same meaning.\nWan, et al., 2007). Generally, all sentences including the query are modeled as nodes and\nrelationship between sentences as directed or undirected edges. With the assumption that the query is the most important of all nodes, the query is initially labeled and the query relevance score is recursively propagated to the unlabeled sentences. The problem of such semi-supervised learning methods is that sentences are ranked without considering the higher-level information beyond the sentence level and the sentences expressing the\nmain topic or theme cannot be treated with priority (Wan and Yang, 2008).\nIn this paper, inspired by the graph-based semisupervised strategy and the topic based model, we propose a two-layer (i.e. sentence layer and topic layer) graph-based semi-supervised learning approach for query-focused multi-document summarization. Previous studies usually saw one topic as a cluster of sentences which can be\nobtained by the traditional clustering techniques such as k-means clustering (Zha, 2002). In such cases, the semantically similar sentences are likely to be clustered into different topics, if they share few words in common. It is obvious that there exists a widening gap between the “clustered” topics and the “real” topics. To solve this problem, various topic modeling techniques have been explored, and Latent Dirichlet Allocation (LDA)\nmodel and its variants have recently shown their advantages in topic modeling (Blei, et al., 2003; Titov and McDonld, 2008; Li et al., 2010), due to their clear and rigorous probabilistic interpretation of topics.\nBase on LDA, we propose a novel topic model DS-LDA which strengthens the modeling of both the sentence level and word level. Based on the observation that neighboring sentences or words usually share the same topic, in DS-LDA, we put\nforward that the topic assignment of each sentence is influenced by its neighboring sentences, and the topic assignment of each word is influenced by\nboth its neighboring words and the sentence containing the word. Then DS-LDA can naturally model the relations between topics and sentences, and further these relations are helpful to the construction of the two-layer graph. The\nexperiments on DUC and TAC data sets also demonstrate that our topic modeling technique can improve the summarization performance under the framework of two-layer graph-based semisupervised learning.\nTo sum up, the main contributions of this paper are twofold. First, we propose a two-layer graph based semi-supervised learning approach for query focused summarization. Second, a novel topic\nmodeling technique is developed to naturally model the relations between sentences and topics.\nThe rest of this paper is organized as follows: Section 2 reviews the related work on queryfocused summarization and topic modeling techniques. Section 3 describes our two-layer graph-based semi-supervised learning approach, which converts the ranking of sentences and topics to an optimization problem. Section 4 presents our topic model which serves for the construction of\nthe two-layer graph and the semi-supervised learning. Section 5 provides the experimental results and finally Section 6 concludes this paper."
    }, {
      "heading" : "2 Related works",
      "text" : "In recent years, graph-based summarization approaches have attracted much attention for both generic and query-focused summarizations (Zhou\net al., 2003; Zhou et al., 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008). Commonly used graph-based ranking are mainly inspired by the link analysis approaches like PageRank (Page et al., 1998) and HITS (Kleinberg 1999), which have achieved much success in Web page ranking. LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to query-\nfocused summarization by formulating query‟s effect on links of sentences (Wei et al., 2008). Wan et al. (2007) first proposed to treat query-focused summarization as a semi-supervised learning task, in which the query is deemed as a labeled node, and the sentences as unlabeled nodes. Then the importance scores of the query and the sentences are tuned by applying the manifold learning algorithm proposed by Zhou et al. (2003) or the\nharmonic approach proposed by Zhu et al. (2003). The difference between manifold algorithm and harmonic approach is whether the given labeling of the labeled nodes is clamped.\nTo our knowledge, most semi-supervised\nlearning methods rank sentences without considering the higher level information beyond the sentence-level information and do not treat the sentences expressing the main topic of one event with priority. It is worthy of noting that many researches on generic summarization have introduced the topic level and effectively improved the summarization performance (Wan and Yang, 2008; Hardy et al., 2002; Harabagiu and Lacatusu,\n2005). Most of these previous researches saw one topic as a cluster of sentences and use the traditional clustering techniques (e.g. K-means or agglomerate clustering) to acquire topics (Wan and Yang, 2008; Hardy et al., 2002). The problem of such „clustered‟ topics is that the semantically same sentences with different expressions are usually divided into different topics. Recently the generative probabilistic models such as LDA (Latent Dirichlet Allocation) and its variants have\nbeen proposed with the goal of reducing dimensionality and acquiring semantic topics (Blei et al., 2003; Li et al., 2010; Titov and McDonald, 2008; Gruber et al., 2007). In these LDA based models, each hidden topic is seen as distribution over a given vocabulary and each document as distribution over topics. Obviously, LDA based models can offer clear and rigorous probabilistic interpretation of topics that the traditional\nclustering techniques cannot offer. However, most current LDA based models still suffers from the problem of conditional independence assumption on the sentence and word levels. To overcome the conditional independence limitation, we develop a novel topic model DS-LDA to strengthen the processing of both the sentence and word levels and put more emphasis on depicting the relations between sentences and topics."
    }, {
      "heading" : "3 Two-Layer Graph-Based Semisupervised Learning",
      "text" : "As stated in Section 1, the introduction of higher level information (i.e. topics) has been proven to be helpful to guiding the sentence ranking for generic summarization. Here, we newly add one layer of topics as shown in Fig. 1. As can be seen,\nthe upper layer is composed of topic nodes and the lower layer is just the traditional graph composed of sentences nodes. In the two-layer graph, the gray node represents the labeled query and the other nodes denote the unlabeled topics and sentences.\nFormally, given a document set, let ( , , , , )s t tt ss stG V V E E E be the two-layer undirected graph to denote the relationship between sentences and topics, where\nsV is the set of sentence nodes,\nand tV is the set of topic nodes. ssE and ttE respectively correspond to the relations between sentences and relations between topics, and stE contains the edges each of which connects one sentence with one topic.\nTo determine the weights of the edges in ssE , we use the traditional cosine similarity matrix. Suppose the sentence set is S={\uD835\uDC600,\uD835\uDC601,\uD835\uDC602,…,\uD835\uDC60\uD835\uDC5B} where \uD835\uDC600 is the query and \uD835\uDC601,\uD835\uDC602,…,\uD835\uDC60n are sentences in the document set. Each item in S is represented by a weighted term vector under the VSM (vector space model) scheme. The weight of a term is calculated using the inverse sentence frequency (ISF) with the intuition that the terms contained in a few sentences should be more important than those appearing in many sentences. Then the cosine similarity of two sentences si and sj can be calculated. Based on this, we get a row-normalized\nprobability matrix U ( cos ( , )\ncos ( , ) j\nji\nij\nij\nine s s U\nine s s   ). The\nweighing of the edges in ttE and stE involves the identification of topics and is detailed in Section 4. Now we suppose relations between topics (i.e. the\nweights of edges in ttE ) are formalized by a row-\nnormalized topic similarity matrix K KP  where K is the topic number, and the relations from sentences to topics (i.e. the weights of edges in stE ) are represented by a topic assignment probability\nmatrix ( 1)n KW   which is further row-normalized as ( 1)n KW   or column-normalized as ( 1)n KW    where n+1 is the number of sentences including the query.\nAlgorithm 1: TwolayerSemisupervisedLearning Input: The sentence set {\uD835\uDC600,\uD835\uDC601,\uD835\uDC602,…\uD835\uDC60\uD835\uDC5B} and the topic set {t1,t2,…t\uD835\uDC5B}, \uD835\uDC600 is the query Output: The score vector f and g BEGIN\nUnder the semi-supervised framework, the query node in the graph is deemed as having a high score (e.g. labeled as 1). Given the weighted graph, our task is to assign a score to each sentence and each topic, unlabeled initially. Two real valued scoring functions: :f S R and :g T R are\ndesigned with the following assumptions: (1) The given query has the highest score; (2) Closely related nodes (sentences and topics) tend to have similar scores. This motivates the following optimization problem:\n     \n   \n2 2\n, ,\n0 , 1 ,\n2 2\n, , 0 0\n0 ,1\nΩ , 2 2\nˆ( ) ( ) 2\ni j i j i j i j\ni j n i j K\ni j i j i j j i\ni n j K\na a\nb\nf g U f f P g g\nW f g W g f f y\n   \n   \n   \n    \n \n\n(1)\nwhere a and b denote the relative influence of the score difference from homogeneous nodes and heterogeneous nodes, and we have a+b=1. It is obvious to show\n,( , ) argmin ( )f gf g f  can satisfy\nthe two assumptions above. That is, the score of the labeled query (f0) should keep the value of y0 (e.g. 1). And on the unlabeled sentences and topics, we get the following equations:\n( ) 2\nb f aUf W W g\n\n   (2)\nˆ( ) 2\nT Tbg aPg W W f   (3)\nEquation (2) and (3) also illustrate the following characteristics which conform to our intuition: (1) A sentence would be important if it is heavily connected with many important sentences and a topic would be important if it is closely related to many important topics. (2) A sentence would be important if it is expressing an important topic, and in turn a topic would be important if it is referred by an important sentence. Then, the algorithm of ranking is designed as in Fig. 2."
    }, {
      "heading" : "4 Topic Modeling",
      "text" : "In this section, we begin with two basic methods of modeling documents, LDA and a simply revised LDA with sentence level added (named IS-LDA). Then we clarify why and how we propose our new topic model, named DS-LDA.\n4.1 LDA and IS-LDA\nThe hierarchical Bayesian LDA models the probability of a document collection on hidden topics as in Fig. 3(a). Let K be the number of topics; V be the vocabulary size; M be the number of documents. The topic distribution of each\ndocument 1{ }\nk K\nm m k   is drawn from a prior\nDirichlet distribution Dir(α), and each word ,m nw is\nsampled from a topic-word distribution 1{ }\nk k V\nw w  \nspecified by a random drawn of the word-topic assignment from the topic-document distribution m . In order to infer the topic distribution of each sentence, two methods can be used. One method named LDA(D) gets the topic distribution of each sentence by using the word-topic and topicdocument distribution.\n,( ) ( | ) ( | ) i i i\nk k\nm s i k k m w\nw w\np z k p w t p t m        (4)\nwhere ,m sz denotes the topic assignment of the s\nth\nsentence in document m and iw denotes each word in the sentence. The other method named LDA(S) deems each sentence as one document, and then\ndirectly makes use of m to compute the topic distribution of each sentence. The defect of LDA is that it cannot naturally model document level and sentence level simultaneously. To solve this problem, we implement one topic model named IS-LDA as in Fig. 3(b), based on the assumption made by Gruber et al. (2007) that words in the same sentence belong to one same topic. In IS-LDA, the topic assignments of sentences are independent and the topic assignment of each word is determined only by its sentence. Here we directly infer the probability of assigning topic k to sentence s of document m with the following formula.\n, ,\n, ,\n, ,\n( ) ( )( ) ( ) ,( ) ( )\n( ) ( )\n( ) ( ) , ( )\n( | , )\n( )( )\n( ) ( )\nm s n\nm s n\nm s m s\nk wm w m sk k\nm k w Sk m s w\np z k z\nA NC E V\nC K E V N A\n \n \n  \n\n\n \n \n      \n      \n,\n(5)\nwhere ( )\nm\nkC is the number of sentences assigned to\ntopic k in document m and ( ) mC  is the number of sentences in document m. ( ) ( )kE  is the total number\nof words assigned to topic k and ,m sN is the\nnumber of words in the current sentence. , ,\n( ) ( )m s n k wA is\nthe number of times that the word , ,m s nw is assigned\nto topic k and ( ), w m sN denotes the number of word w\nappearing in the current sentence."
    }, {
      "heading" : "4.2 DS-LDA",
      "text" : "4.2.1 Model Overview\nWe can see that IS-LDA still cannot precisely describe the generation process of one document collection. Firstly, it is observed that, though most words in one sentence are assigned the topic as the sentence is assigned, there still exists the possibility that some words may be assigned other topics, especially when the length of one sentence is long. Secondly, we find that the topic\nassignments of sentences and words are not independent: neighboring sentences (or words) are likely to talk about the same topic, and the longer the distance of two sentences (words) are, the less the influence between their topic assignments. Based on our observation, we propose our topic model DS-LDA, meaning the topic assignments of sentences and words are dependent.\nThe DS-LDA model is illustrated in Fig. 4. We suppose that the mth document has Nm sentences and the sth sentence in document m has Nm,s words. α and γ are fixed parameters of symmetric Dirichlet priors for the M document-topic\nmultinomials represented by a M K matrix θ and\nthe K topic-word multinomials represented by a K×V matrix Φ. To describe the relations between topic assignment of sentences and topic assignment of their owned words, we introduce the asymmetric Dirichlet priors\n1 1 2 1 1( ... , , ... ) k     \n( 2 1, ( ) k k k i i k      ) which denotes the hyperparameter for the K topic-topic multinomials represented by a K×K matrix Ψ. That is, Ψ is used to control the topic distribution of each word when the topic assignment of the current sentence is given. 2( ) k k  denotes the probability prior of assigning a word to topic k given that the current sentence is assigned topic k, and\n1 denotes the\nprobability prior of assigning one word to a different topic from the topic of the current sentence. 2 is usually larger than 1 and we use  to represent their ratio ( 2 1/  ).\nLet , ,m s nw be the observed variable representing the nth word in the sth sentence of document m,\n,m sz the hidden variable indicating the topic one\nsentence is assigned to, and , ,m s nz the hidden\nvariable denoting the topic one word belongs to.\nFirst of all, we draw a topic distribution ~ ( )m Dir  for document m. According to m and the topic assignment of the neighboring sentences, we sample a topic for sentence s in document m. Finally, each word in the current sentence is assigned to a topic. Fig. 5 describes the process of generating the whole document collection."
    }, {
      "heading" : "4.2.2 Inference",
      "text" : "We use Gibbs sampling to perform model inference (Griffiths and Steyvers, 2004). Due to the space limit, we will just show the sampling formula without derivation. First, given the assignment of all other hidden variables, to sample a value for\n,m sz , we use the following formula:\n,\n, , 2 [1, ] { }\n( )\n( ) ( ) 1 2\n( )\n( ) ( ) , 1 2\n( ) ( ) ( ) , 1 2\n( ) ( ) 1\n( , )1 ( | , , , , ) ( exp( ))\n| 1|\n( ( 1) )\n( ( 1) )\n( (1 ( , )) ( , ))\n( (1 ( , ))\nm\nm j\nm s m s\nj N sm\nm k k\nm\nk m s\ni i k m s\ni k\nc k z p z k z\nN s j\nC E K\nC K E N K\nE N k i k i\nE k i\n  \n  \n  \n   \n \n\n \n\n\n\n  \n \n       \n      \n       \n    \nwz w\n[1, ] 2 ( , ))i K k i   \n(6)\nwhere c is a parameter tuning the influence from neighboring sentences. The longer the distance from one sentence to the current sentence, the less the influence of that sentence on the current\nsentence. The meaning of ( )\nm kC and ( ) mC  is the same\nas that in Formula (5). ( ) ( )kE  is the total number of words of the sentences which are assigned to topic k and\n,m sN is the number of words in the current\nsentence. ( ) ( ) i kE is the number of times any word is assigned topic i given that the sentence containing the word is assigned topic k. ( ) , i m sN is the number of words that are assigned topic i in the current\nsentence. All the counts above except ,m sN and\n( )\n,\ni\nm sN exclude the current sentence.\nNext, we sample , ,m s nz for each word in current\nsentence.\n, ,\n,\n,\n,\n, , , , 1 2\n( )\n( ), ,\n2 ( ) [1, ] { }, ( )\n( ) ( ) 2 , 1 ,\n( ) ( ) 1 2\n( | , , , , , )\n( , )1 exp( )\n| 1|\n( , ) (1 ( , ))\n( 1)\nm s n\nm s\nm s\nm s\nm s n m s n\nk\nwm s t\nk t N nm s\nk z m s m s\nz\np z k z\nAd k z\nN A Vn t\nE z k z k\nE K\n   \n\n\n   \n \n\n  \n\n\n  \n \n    \n  \n\nsz ,w\n(7)\nwhere d is a parameter to tune the influence from neighboring words,\n, ,\n( ) ( )m s n k wA is the number of times\nthat word , ,m s nw is assigned topic k and ( ) ( ) kA  is the total number of times any word is assigned to topic k. In these counts, the current word is excluded.\nWith the Gibbs sampler, we can also get the following estimation:\n( )\n( ) ( )\n( ) ( )\n( ) ( ) ( ') ( ) 2 1\n' ( )\n( ) 1 2\n, ,\n( , ') (1 ( , '))\n( 1)\nm k\nk wm k k wm k\nk\nkk k\nk\nC A\nC K A V\nE k k k k\nE K\n   \n \n    \n \n \n\n   \n \n     \n  \n(8)\n4.2.3 DS-LDA Based Summarization\nAccording to Formula (6), we can get the topic assignment probability of each sentence which serves for the computation of the matrix W, and then the matrices W and W \nare obtained through row-normalization and column-normalization respectively. To reflect the relations between the topics, we compute the cosine similarity between topics ti and tj as:\n2 2 cos ( , )\n| | | | ( ) ( )\ni j\nw w i j w\ni j i j\ni j w w\nw w\nt t ine t t\nt t\n \n \n \n  \n\n  (9)\nThe topic similarity matrix is further rownormalized and we get the matrix P.\nNow, using our semi-supervised algorithm as in Fig. 2, we can compute the importance scores for both topics and sentences. Finally, we adopt a sentence selection strategy which is similar to Maximum Marginal Relevance (MMR) (Goldstein et al., 1999). That is, we opt for the highly ranked sentences with less similarity with the selected summary sentences. Let Y denote the set which contains the already selected summary sentences and sm denote the highest ranked sentence of the remaining sentences. We can compute the semantic similarity between sm and Y as:\n1\n2 2\n1 1\n1 [ ]\n| | cos_ ( , )\n1 ( ) [ ]\n| |\ni\ni\nK j i\nk k\nk S Y\nj K K\nj i\nk k\nk k S Y\nW W Y\nsem s Y\nW W Y\n \n  \n\n\n\n \n  \n(10)\nwhere jkW means the k th dimension of the vector jW and |Y| represents the number of sentences in Y. Only the sentence with cos_ ( , )jsem s Y below the\nthreshold Thsem can be selected into the summary set. Thsem is set an experience value 0.25."
    }, {
      "heading" : "5 Experiments",
      "text" : "Our experiment data is composed of DUC (2005 - 2007) and TAC (2008-2009) data 2 . Table 1\nillustrates the number of document collection, averaged number of documents per collection,\n2 http://www.nist.gov/\naveraged number of sentences per collection, and averaged number of words per sentence for each year‟s data. For DUC collection, the length of one system-generated summary is limited to 250 words. For TAC, we use their docset-A3 data sets which\nAs for evaluation metrics, we use ROUGE (Recall-Oriented Understudy for Gisting Evaluation) (Lin, 2004) measures, including ROUGE-1, ROUGE-2, and ROUGE-SU4 4 and\ntheir corresponding 95% confidential intervals, to evaluate the performance of the system-generated summaries."
    }, {
      "heading" : "5.1 Determination of Topic Number",
      "text" : "How to set the topic number for one topic model is the main consideration. Let n be the total number of the sentences for each collection, and one simple\nrule of thumb sets the topic number to n . Here we assume that there exists a linear relation\nbetween the optimum topic number and n . For each document collection in the training set, we extract one summary using our DS-LDA based semi-supervised ranking method with the topic number changing from 1 to 50. The value with which the summary gets the highest ROUGE-2 score is assumed as the optimum topic number of the corresponding document collection. Fig. 6(a) shows the relation between the optimum topic number and the squared root of sentence number. From this figure, we get the fitting curve with the algebra formula as:\n1.11 5.05K n     \n(11)\nwhere    is the ceiling function which maps a real number to the smallest following integer. Next, we test the DS-LDA model with the\ndetermination formula of topic number on DUC\n3In TAC, the summarization for docset-A can be seen the query-focused summarization task referred in this paper. 4Jackknife scoring for ROUGE is used in order to compare with the human summaries.\n2006 and TAC 2008 data sets. For comparison, we\nalso set the topic number respectively as n , 10,\n20, 30 and 40, with which the summaries on two years‟ data sets are generated and ranked by ROUGE-1, ROUGE-2 and ROUGE-SU4 scores as in Fig. 6(b)(c)(d). On the whole, our determination formula of topic number can reach a better performance than the other settings. We can also see that the next best option of setting topic\nnumber is n . It is concluded that the topic\nnumber for each collection should be set with the consideration of the sentence number. In addition, Table 1 displays that the average sentence numbers\nper collection are respectively 705 and 246 on DUC 2006 and TAC 2008 data. Putting the average sentence numbers in Eq. (11), we can get 25 and 13, which can also explain the phenomena in Fig. 6: on DUC 2006 data the performance when topic numbers are assigned the values of 20 and 30 obviously outperform the performance when 10 and 40 are the topic numbers, while a better performance is achieved when topic number are assigned as 10 or 20 on TAC 2008."
    }, {
      "heading" : "5.2 Parameter Tuning in DS-LDA",
      "text" : "In the experiments, the hyperparameters α, 1 and γ in DS-LDA are respectively set 1, 0.1 and 0.5. Now, we still need to tune four parameters: the parameter a in Eq. (1) denoting the relative influence from homogeneous nodes, and sentence influence parameter c in Eq. (6), word influence parameter d in Eq. (7), and the ratio  (between the two hyperparameters\n2 1 and   ). Here, we apply a\ngreedy strategy to search the optimum values of the three parameters. That is, we tune each parameter\nand get its optimum value when the other three parameters are fixed.\nFirstly, a is set as 0.5, and both c and d are set to 1.0. Reviewing Eq.(7), we can see that, the topic assignment of a word is independent from its sentence when  is set as 1. However, if  is set a large value, the word topic is mainly decided by the topic of the sentence. Here, we experiment  from 1 to 81 with interval of 10. Through observation, we find that the ROUGE scores drops sharply when  approaches 20. This indicates that the optimum value of  may be in the range between 1 and 20. Thus, we assign  to the values ranging from 1 to 20 with interval of 1. Fig. 7 presents the ROUGE-2 and ROUGE-SU4 evaluation results. We find that the summarization algorithm reaches a peak performance around  =12 and drops afterwards.\nNext, we set  as 12 and tune c. From Eq. (7), we can see that, the topic assignment of one sentence is mainly determined by its neighboring sentences when c is set a large value (if c is large enough, all sentences in the same document would be assigned to the same topic), whereas the influence from other sentences is not considered at all when c is set 0. The performance using different values of c ranging from 0 to 10 with interval of 1 is evaluated. Similar to tuning  , we conduct a fine-tuning of c in the range from 0.0 to 2.0 with interval of 0.1. The performance gets better as c increases from 0 to 1.8, and then declines gently until c arrives at 3.0. Afterwards, the curve becomes smooth and means that sentences in the document are assigned to one same topic. The determination of d is almost the same as that of c and the ROUGE scores seem to reach a peak when the value of d approaches to 1.2. Finally, a is tuned in the range from 0.0 to 1.0 with interval of 0.1 and reach its peak performance around the value of 0.7. This means that the parameter b is equal to 0.3 since a+b=1 and homogeneous nodes have more influence than heterogeneous nodes on the sentence ranking. Due to space limit, the figures illustrating the tuning process of a, c and d are not given. In the following experiments, the parameters a,  , c and d are set to 0.7, 12, 1.8 and 1.2 respectively in DSLDA ."
    }, {
      "heading" : "5.3 Comparison with Other Approaches",
      "text" : "Now, we aim to compare the performance of various topic modeling techniques. Except the hierarchical Bayesian topic models LDA(D), LDA(S) and IS-LDA introduced above, clustering is also seen as a topic modeling technique. Thus, we present other three baselines: K-means clustering, agglomerative clustering, divisive clustering, and use clusters as topics for the construction of the two-layer graph. Divisive clustering and agglomerative clustering are hierarchical clustering algorithms which do not require the specification of cluster number. For Kmeans clustering algorithm, the cluster number is specified respectively as the squared root of the\nsentence number (named Kmeans( n ) method), and the value computed by Formula (11). Then on both DUC 2006 and TAC 2008 data, the two-layer graph-based semi-supervised learning algorithm is combined with each topic model for sentence ranking, and the summaries are evaluated in ROUGE scores as presented in Table 2 and 3. Methods ROUGE-1 ROUGE-2 ROUGE-SU4\nDS-LDA 0.4317 (0.4205-0.4429) 0.1019 (0.0930-0.1107) 0.1596 (0.1531-0.1661) IS-LDA 0.4176\n(0.4083-0.4269) 0.0947 (0.0886-0.1008) 0.1482 (0.1445-0.1519)\nLDA(D) 0.3985\n(0.3907-0.4063)\n0.0856\n(0.0803-0.0909)\n0.1401\n(0.1366-0.1435)\nLDA(S) 0.4047\n(0.3961-0.4133)\n0.0887\n(0.0849-0.0925)\n0.1432\n(0.1394-0.1470)\nDivisive 0.3977 (0.3873-0.4080) 0.0817 (0.0779-0.0858) 0.1310 (0.1273-0.1347)\nAgglomera tive 0.3964 (0.3857-0.4071) 0.0832 (0.0803-0.0863) 0.1346 (0.1297-0.1396) Kmeans(K) 0.4027\n(0.3941-0.4113) 0.0829 (0.0786-0.0873) 0,1387 (0.1343-0.1431)\nKmeans( ) 0.4020\n(0.3954-0.4087)\n0.0818\n(0.0780-0.0857)\n0.1381\n(0.1335-0.1427)\nManifold 0.3969 (0.3792-0.4146) 0.0801(0.0769- 0.0834) 0.1370(0.1327- 0.1413)\nTable 2. Comparison of topic models on DUC2006\nMethods ROUGE-1 ROUGE-2 ROUGE-SU4 DS-LDA 0.3882\n(0.3761-0.4003) 0.1093 (0.1021-0.1166) 0.1414 (0.1372-0.1456)\nIS-LDA 0.3770 (0.3620-0.3929) 0.1001 (0.0920-0.1082) 0.1329 (0.1267-0.1391) LDA(D) 0.3717\n(0.3610-0.3824) 0.0980 (0.0934-0.1028) 0.1296 (0.1209-0.1384)\nLDA(S) 0.3687\n(0.3612-0.3762)\n0.0966\n(0.0901-0.1031)\n0.1293\n(0.1231-0.1355)\nDivisive 0.3648\n(0.3566-0.3730)\n0.0951\n(0.0898-0.1004)\n0.1268\n(0.1176-0.1360)\nAgglomera tive 0.3624 (0.3550-0.3699) 0.0910 (0.0833-0.0988) 0.1251 (0.1126-0.1376) Kmeans(K) 0.3643\n(0.3589-0.3697) 0.0986 (0.0797-0.1076) 0.1264 (0.1218-0.1210)\nKmeans( ) 0.3621 (0.3506-0.3736) 0.0931 (0.0868-0.0994) 0.1283 (0.1206-0.1360)\nManifold 0.3597\n(0.3499-0.3695)\n0.0879\n(0.0809-0.0950)\n0.1251\n(0.1173-0.1329)\nTable 3. Comparison of topic models on TAC2008\nThe results are in accord with our expectation. Overall, the hierarchical Bayesian topic models perform better than the clustering algorithms, and this is why the hierarchical Bayesian models are widely used recently. Among all the hierarchical Bayesian models, DS-LDA is much better than the other models and the IS-LDA model is better than the LDA models. From the tables, we can see that the relative improvement of DS-LDA over LDA(D) in ROUGE-1, ROUGE-2 and ROUGE-SU4 scores reaches 8.3%, 19.0% and 13.9% respectively on DUC 2006, and 4.4%, 11.5% and 9.1% respectively on TAC 2008. This verifies that DSLDA can appropriately model the documents by adding the conditional dependence of sentences and words.\nTo have a global picture of evaluation, we also compare our approach (denoted as OUR) with the top five participating systems (with respect to ROUGE-2) in DUC and TAC. These five systems are represented by their system IDs respectively. Table 4 demonstrates that our approach obviously outperforms the state-of-the-art summarization techniques.\nROUGE-2 ROUGE-SU4\nDUC 2006\nOUR 0.1049(0.0960-0.1137) 0.1596(0.1531-0.1661)\nS24 0.0956(0.0914-0.0998) 0.1553(0.1513-0.1591) S15 0.0910(0.0867-0.0948) 0.1473(0.1437-0.1507) S12 0.0899(0.0858-0.0939) 0.1476(0.1436-0.1514)\nS8 0.0895(0.0854-0.0934) 0.1461(0.1425-0.1494)\nS23 0.0879(0.0837-0.0920) 0.1449(0.1410-0.1485)\nTAC 2008\nOUR 0.1073(0.1001-0.1146) 0.1394(0.1352-0.1436)\nS43 0.1040(0.0995-0.1094) 0.1365(0.1325-0.1408) S13 0.0990(0.0946-0.1039) 0.1359(0.1289-0.1366) S14 0.0978(0.0931-0.1026) 0.1358(0.1287-0.1370)\nS2 0.0962(0.0917-0.1009) 0.1344(0.1304-0.1387)\nS65 0.0956(0.0910-0.1002) 0.1315(0.1278-0.1354)"
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "In this paper, one two-layer graph-based semisupervised learning approach combined with topic modeling technique is explored for the queryfocused multi-document summarization. To model the topic level in the two-layer graph, we propose a novel topic modeling technique named DS-LDA which can efficiently and naturally model the whole document collection and represent the relations between sentences and topics. Experiments on DUC and TAC data sets have proven that the addition of appropriate topic information can promote the summarization performance. In our future work, we plan to further explore the topic modeling techniques for the influence of the hyperparameters."
    } ],
    "references" : [ {
      "title" : "Latent dirichlet allocation",
      "author" : [ "David Blei", "Andrew Ng", "Micheal Jordan." ],
      "venue" : "The Journal of Machine Learning Research, page: 993-1022.",
      "citeRegEx" : "Blei et al\\.,? 2003",
      "shortCiteRegEx" : "Blei et al\\.",
      "year" : 2003
    }, {
      "title" : "Lexrank: graph-based lexical centrality as salience in text summarization",
      "author" : [ "Gune Erkan", "Dragomir Radev." ],
      "venue" : "J. Artif. Intell. Res. (JAIR), page 457-479.",
      "citeRegEx" : "Erkan and Radev.,? 2004",
      "shortCiteRegEx" : "Erkan and Radev.",
      "year" : 2004
    }, {
      "title" : "Hidden topic markov models",
      "author" : [ "Amit Gruber", "Michal Rosen-zvi", "Yair" ],
      "venue" : "In Artificial Intelligence and Statistics (AISTATS)",
      "citeRegEx" : "Gruber et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Gruber et al\\.",
      "year" : 2007
    }, {
      "title" : "Exploring content models for multi-document summarization",
      "author" : [ "Aria Haghighi", "Lucy Vanderwende." ],
      "venue" : "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Haghighi and Vanderwende.,? 2009",
      "shortCiteRegEx" : "Haghighi and Vanderwende.",
      "year" : 2009
    }, {
      "title" : "Cross-document summarization by concept classification",
      "author" : [ "Hilda Hardy", "Nobuyuki Shimizu", "Tomek Strzakowski", "Liu Ting", "Xinyang Zhang", "Bowden Wize." ],
      "venue" : "Proceedings of the 25th annual international ACM SIGIR conference on Research",
      "citeRegEx" : "Hardy et al\\.,? 2002",
      "shortCiteRegEx" : "Hardy et al\\.",
      "year" : 2002
    }, {
      "title" : "Authoritative Sources in a Hyperlinked Environment",
      "author" : [ "Jon M. Kleinberg." ],
      "venue" : "Journal of the ACM, page 604-632.",
      "citeRegEx" : "Kleinberg.,? 1999",
      "shortCiteRegEx" : "Kleinberg.",
      "year" : 1999
    }, {
      "title" : "Generating templates of entity summaries with an entity-aspect model and pattern mining",
      "author" : [ "Peng Li", "Jing Jiang", "Yingli Wang." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics page:640-649",
      "citeRegEx" : "Li et al\\.,? 2010",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2010
    }, {
      "title" : "Rouge: A package for automatic evaluation of summaries",
      "author" : [ "Chen-Yew Lin." ],
      "venue" : "Text Summarization Branches Out: Proceedings of the ACL-04 Workshop Page:71-84",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Using random walks for question-focused sentence retrieval",
      "author" : [ "Jahna Otterbacher", "Gunes Erkan", "Dragomir Radev." ],
      "venue" : "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, page 915-",
      "citeRegEx" : "Otterbacher et al\\.,? 2005",
      "shortCiteRegEx" : "Otterbacher et al\\.",
      "year" : 2005
    }, {
      "title" : "Developing learning strategies for topic-based summarization",
      "author" : [ "You Ouyang", "Sujian. Li", "Wenjie. Li" ],
      "venue" : "In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,",
      "citeRegEx" : "Ouyang et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Ouyang et al\\.",
      "year" : 2007
    }, {
      "title" : "Multi-document Summarization using cluster-based link analysis",
      "author" : [ "Xiaojun Wan", "Jianwu Yang." ],
      "venue" : "Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, page: 299-306.",
      "citeRegEx" : "Wan and Yang.,? 2008",
      "shortCiteRegEx" : "Wan and Yang.",
      "year" : 2008
    }, {
      "title" : "Manifold-ranking based topic-focused multidocument summarization",
      "author" : [ "Xiaojun Wan", "Jianwu Yang", "Jianguo Xiao." ],
      "venue" : "Proceedings of International Joint Conference on Artificial Intelligence, page 2903-2908.",
      "citeRegEx" : "Wan et al\\.,? 2007",
      "shortCiteRegEx" : "Wan et al\\.",
      "year" : 2007
    }, {
      "title" : "Query-sensitive mutual reinforcement chain and its application in query-oriented multi-document summarization",
      "author" : [ "Furu Wei", "Wenjie Li", "Qin Lu", "Yanxiang He." ],
      "venue" : "Proceedings of the 31st annual international ACM SIGIR conference on Research",
      "citeRegEx" : "Wei et al\\.,? 2008",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2008
    }, {
      "title" : "Generic summarization and keyphrase extraction using mutual reinforcement principle and sentence clustering",
      "author" : [ "Hongyuan Zha." ],
      "venue" : "Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information",
      "citeRegEx" : "Zha.,? 2002",
      "shortCiteRegEx" : "Zha.",
      "year" : 2002
    }, {
      "title" : "Ranking on Data Manifolds",
      "author" : [ "Dengzhong Zhou", "Jason Weston", "Arthur Gretton", "Olivier Bousquet", "Bernhard Schölkopf." ],
      "venue" : "Proceedings of the Conference on Advances in Neural Information Processing Systems, page 169-176.",
      "citeRegEx" : "Zhou et al\\.,? 2003",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2003
    }, {
      "title" : "Learning with Local and Global Consistency",
      "author" : [ "Dengyou Zhou", "Olivier Bousquet", "Thomas Navin", "JasonWeston." ],
      "venue" : "Advances in neural information processing systems, page 321-328.",
      "citeRegEx" : "Zhou et al\\.,? 2004",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2004
    }, {
      "title" : "Semisupervised Learning using Gaussian Fields and Harmonic Functions",
      "author" : [ "X. Zhu", "Z. Ghahramani", "J. Lafferty." ],
      "venue" : "ICML, 03’, 2003, page. 912919.",
      "citeRegEx" : "Zhu et al\\.,? 2003",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "The problem of such semi-supervised learning methods is that sentences are ranked without considering the higher-level information beyond the sentence level and the sentences expressing the main topic or theme cannot be treated with priority (Wan and Yang, 2008).",
      "startOffset" : 242,
      "endOffset" : 262
    }, {
      "referenceID" : 13,
      "context" : "Previous studies usually saw one topic as a cluster of sentences which can be obtained by the traditional clustering techniques such as k-means clustering (Zha, 2002).",
      "startOffset" : 155,
      "endOffset" : 166
    }, {
      "referenceID" : 6,
      "context" : "To solve this problem, various topic modeling techniques have been explored, and Latent Dirichlet Allocation (LDA) model and its variants have recently shown their advantages in topic modeling (Blei, et al., 2003; Titov and McDonld, 2008; Li et al., 2010), due to their clear and rigorous probabilistic interpretation of topics.",
      "startOffset" : 193,
      "endOffset" : 255
    }, {
      "referenceID" : 14,
      "context" : "In recent years, graph-based summarization approaches have attracted much attention for both generic and query-focused summarizations (Zhou et al., 2003; Zhou et al., 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008).",
      "startOffset" : 134,
      "endOffset" : 233
    }, {
      "referenceID" : 15,
      "context" : "In recent years, graph-based summarization approaches have attracted much attention for both generic and query-focused summarizations (Zhou et al., 2003; Zhou et al., 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008).",
      "startOffset" : 134,
      "endOffset" : 233
    }, {
      "referenceID" : 1,
      "context" : "In recent years, graph-based summarization approaches have attracted much attention for both generic and query-focused summarizations (Zhou et al., 2003; Zhou et al., 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008).",
      "startOffset" : 134,
      "endOffset" : 233
    }, {
      "referenceID" : 12,
      "context" : "In recent years, graph-based summarization approaches have attracted much attention for both generic and query-focused summarizations (Zhou et al., 2003; Zhou et al., 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008).",
      "startOffset" : 134,
      "endOffset" : 233
    }, {
      "referenceID" : 1,
      "context" : "LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to queryfocused summarization by formulating query‟s effect on links of sentences (Wei et al.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : "LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to queryfocused summarization by formulating query‟s effect on links of sentences (Wei et al., 2008).",
      "startOffset" : 201,
      "endOffset" : 219
    }, {
      "referenceID" : 10,
      "context" : "It is worthy of noting that many researches on generic summarization have introduced the topic level and effectively improved the summarization performance (Wan and Yang, 2008; Hardy et al., 2002; Harabagiu and Lacatusu, 2005).",
      "startOffset" : 156,
      "endOffset" : 226
    }, {
      "referenceID" : 4,
      "context" : "It is worthy of noting that many researches on generic summarization have introduced the topic level and effectively improved the summarization performance (Wan and Yang, 2008; Hardy et al., 2002; Harabagiu and Lacatusu, 2005).",
      "startOffset" : 156,
      "endOffset" : 226
    }, {
      "referenceID" : 10,
      "context" : "K-means or agglomerate clustering) to acquire topics (Wan and Yang, 2008; Hardy et al., 2002).",
      "startOffset" : 53,
      "endOffset" : 93
    }, {
      "referenceID" : 4,
      "context" : "K-means or agglomerate clustering) to acquire topics (Wan and Yang, 2008; Hardy et al., 2002).",
      "startOffset" : 53,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "Recently the generative probabilistic models such as LDA (Latent Dirichlet Allocation) and its variants have been proposed with the goal of reducing dimensionality and acquiring semantic topics (Blei et al., 2003; Li et al., 2010; Titov and McDonald, 2008; Gruber et al., 2007).",
      "startOffset" : 194,
      "endOffset" : 277
    }, {
      "referenceID" : 6,
      "context" : "Recently the generative probabilistic models such as LDA (Latent Dirichlet Allocation) and its variants have been proposed with the goal of reducing dimensionality and acquiring semantic topics (Blei et al., 2003; Li et al., 2010; Titov and McDonald, 2008; Gruber et al., 2007).",
      "startOffset" : 194,
      "endOffset" : 277
    }, {
      "referenceID" : 2,
      "context" : "Recently the generative probabilistic models such as LDA (Latent Dirichlet Allocation) and its variants have been proposed with the goal of reducing dimensionality and acquiring semantic topics (Blei et al., 2003; Li et al., 2010; Titov and McDonald, 2008; Gruber et al., 2007).",
      "startOffset" : 194,
      "endOffset" : 277
    }, {
      "referenceID" : 0,
      "context" : ", 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008). Commonly used graph-based ranking are mainly inspired by the link analysis approaches like PageRank (Page et al., 1998) and HITS (Kleinberg 1999), which have achieved much success in Web page ranking. LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to queryfocused summarization by formulating query‟s effect on links of sentences (Wei et al., 2008). Wan et al. (2007) first proposed to treat query-focused summarization as a semi-supervised learning task, in which the query is deemed as a labeled node, and the sentences as unlabeled nodes.",
      "startOffset" : 8,
      "endOffset" : 510
    }, {
      "referenceID" : 0,
      "context" : ", 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008). Commonly used graph-based ranking are mainly inspired by the link analysis approaches like PageRank (Page et al., 1998) and HITS (Kleinberg 1999), which have achieved much success in Web page ranking. LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to queryfocused summarization by formulating query‟s effect on links of sentences (Wei et al., 2008). Wan et al. (2007) first proposed to treat query-focused summarization as a semi-supervised learning task, in which the query is deemed as a labeled node, and the sentences as unlabeled nodes. Then the importance scores of the query and the sentences are tuned by applying the manifold learning algorithm proposed by Zhou et al. (2003) or the harmonic approach proposed by Zhu et al.",
      "startOffset" : 8,
      "endOffset" : 827
    }, {
      "referenceID" : 0,
      "context" : ", 2004; Erkan and Radev, 2004; Wan and Yang, 2007; Wei et al., 2008). Commonly used graph-based ranking are mainly inspired by the link analysis approaches like PageRank (Page et al., 1998) and HITS (Kleinberg 1999), which have achieved much success in Web page ranking. LexRank (Erkan and Radev, 2004) is a typical PageRank-like algorithm for generic summarization and further is extended to queryfocused summarization by formulating query‟s effect on links of sentences (Wei et al., 2008). Wan et al. (2007) first proposed to treat query-focused summarization as a semi-supervised learning task, in which the query is deemed as a labeled node, and the sentences as unlabeled nodes. Then the importance scores of the query and the sentences are tuned by applying the manifold learning algorithm proposed by Zhou et al. (2003) or the harmonic approach proposed by Zhu et al. (2003). The difference between manifold algorithm and harmonic approach is whether the given labeling of the labeled nodes is clamped.",
      "startOffset" : 8,
      "endOffset" : 882
    }, {
      "referenceID" : 2,
      "context" : "3(b), based on the assumption made by Gruber et al. (2007) that words in the same sentence belong to one same topic.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "As for evaluation metrics, we use ROUGE (Recall-Oriented Understudy for Gisting Evaluation) (Lin, 2004) measures, including ROUGE-1, ROUGE-2, and ROUGE-SU4 4 and their corresponding 95% confidential intervals, to evaluate the performance of the system-generated summaries.",
      "startOffset" : 92,
      "endOffset" : 103
    } ],
    "year" : 2012,
    "abstractText" : "Graph-based semi-supervised learning has proven to be an effective approach for query-focused multi-document summarization. The problem of previous semi-supervised learning is that sentences are ranked without considering the higher level information beyond sentence level. Researches on general summarization illustrated that the addition of topic level can effectively improve the summary quality. Inspired by previous researches, we propose a two-layer (i.e. sentence layer and topic layer) graph-based semi-supervised learning approach. At the same time, we propose a novel topic model which makes full use of the dependence between sentences and words. Experimental results on DUC and TAC data sets demonstrate the effectiveness of our proposed approach.",
    "creator" : "Microsoft Office Word 2007"
  }
}