{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2016", "title": "Matching Networks for One Shot Learning", "abstract": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.", "histories": [["v1", "Mon, 13 Jun 2016 19:34:22 GMT  (2522kb,D)", "http://arxiv.org/abs/1606.04080v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["oriol vinyals", "charles blundell", "tim lillicrap", "koray kavukcuoglu", "daan wierstra"], "accepted": true, "id": "1606.04080"}
