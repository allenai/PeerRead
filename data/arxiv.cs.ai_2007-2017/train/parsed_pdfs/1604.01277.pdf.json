{
  "name" : "1604.01277.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Landmark-Based Plan Recognition",
    "authors" : [ "Ramon Fraga Pereira", "Felipe Meneguzzi" ],
    "emails" : [ "ramon.pereira@acad.pucrs.br", "felipe.meneguzzi@pucrs.br" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "As more computer systems require reasoning about what agents (both human and artificial) other than themselves are doing, the ability to accurately and efficiently recognize goals and plans from agent behavior becomes increasingly important. Plan recognition is the task of recognizing goals and plans based on often incomplete observations that include actions executed by agents and properties of agent behavior in an environment [18]. Accurate plan recognition is important to monitor and anticipate agent behavior, such as in crime detection and prevention, monitoring activities, and elderlycare. Most plan recognition approaches [7, 1] employ plan libraries (i.e, a library with all plans for achieving a set of goals) to represent agent behavior, resulting in approaches to recognize plans that are analogous to language parsing. Recent work [16, 15, 13, 5] use planning domain definitions (domain theories) to represent potential agent behavior, bringing plan recognition closer to planning algorithms. These approaches allow techniques used in planning algorithms to be employed for recognizing goals and plans.\nIn this paper, we develop a plan recognition approach that relies on planning landmarks [14, 9] to filter candidate goals and plans from the observations. Landmarks are properties (or actions) that every plan must satisfy (or execute) at some point in every plan execution to achieve a goal. Whereas in planning algorithms these landmarks are used to focus search, in our approach, they allow plan recognition algorithms to rule out candidate goals whose landmarks are missing from observations. Thus, based on planning landmarks, we develop an algorithm to filter candidate goals by estimating how many landmarks required by every goal in the set of candidate goals have been\n1 This document is a full paper of a work published (as short paper) in the 22nd European Conference on Artificial Intelligence (ECAI), 2016. 2 Pontifical Catholic University of Rio Grande do Sul (PUCRS), Brazil. Contact: ramon.pereira@acad.pucrs.br and felipe.meneguzzi@pucrs.br\nachieved within the observed actions. Since computing a subset of landmarks for a set of goals can be done very quickly, our approach can provide substantial runtime gains. In this way, we use this filtering algorithm in two settings. First, we build a landmark-based plan recognition heuristic that analyzes the amount of achieved landmarks to estimate the percentage of completion of each filtered candidate goal. Second, we show that the filter we develop can also be applied to other planning-based plan recognition approaches, such as the approach from Ramı́rez and Geffner [16].\nWe evaluate empirically our plan recognition approach against the current state-of-the-art [16] by using openly available datasets for plan recognition developed by Ramı́rez and Geffner in [16, 15], and which have been used to evaluate recent approaches to plan recognition [5]. This dataset provides several domains and problems in which it is not trivial to recognize the intended goal from a set of candidate goals and observations. Using this dataset, we show that our approach has at least three advantages over existing approaches. First, by relaxing the filter using a small threshold our landmarkbased plan recognition approach is more accurate than the current state-of-the-art [16]. Second, our approach also provides substantially faster recognition time on its own and when used to improve existing plan recognition approaches. Finally, we show that our filtering algorithm provides substantial improvements in recognition time when used to improve existing plan recognition approaches.\nThis paper is organized as follows. Section 2 provides background on planning and plan recognition. In Section 3, we describe how we extract useful information from planning domain definition. Sections 4, 5, and 6 develop the key parts of our approach for plan recognition. We empirically evaluate our approach in Section 7, which shows the results of the experiments. In Section 8, we survey related work and compare the state of the art with our approach. Finally, in Section 9, we conclude this paper by discussing limitations, advantages and future directions of our approach."
    }, {
      "heading" : "2 Background",
      "text" : "In this section, we provide essential background on planning terminology, and how we define plan recognition problems over planning domain definitions."
    }, {
      "heading" : "2.1 Planning",
      "text" : "Planning is the problem of finding a sequence of actions (i.e, plan) that achieves a particular goal from an initial state. In this work, we adopt the terminology from Ghallab et al. [8] to represent planning domains and problems. First, we define a state in the environment by the following Definition 1.\nDefinition 1 (Predicates and State). A predicate is denoted by an n-ary predicate symbol p applied to a sequence of zero or more terms\nar X\niv :1\n60 4.\n01 27\n7v 3\n[ cs\n.A I]\n7 F\neb 2\n01 7\n(τ1, τ2, ..., τn) – terms are either constants or variables. A state is a finite set of grounded predicates (facts) that represent logical values according to some interpretation. Facts are divided into two types: positive and negated facts, as well as constants for truth (>) and falsehood (⊥).\nDefinition 2 (Operator). An operator a is represented by a triple 〈name(a), pre(a), eff(a)〉: name(a) represents the description or signature of a; pre(a) describes the preconditions of a, a set of predicates that must exist in the current state for a to be executed; eff(a) represents the effects of a. These effects are divided into eff(a)+ (i.e, an add-list of positive predicates) and eff(a)− (i.e, a delete-list of negated predicates).\nA plain domain contains operator definitions, which represents the environment dynamics that guide an agent’s search for plans to achieve its goals. Operator definitions are used in the construction of a planning domain, which represents the environment dynamics that guide an agent’s search for plans to achieve its goals. An agent can modify the current state by executing actions according to Definition 3.\nDefinition 3 (Action). An action is a ground operator instantiated over its free variables. Thus, if all operator free variables are substituted by objects when instantiating an operator, we have an action.\nDefinition 4 (Planning Domain). A planning domain definition Ξ is represented by a pair 〈Σ,A〉, which specifies the knowledge of the domain, and consists of a finite set of facts Σ and a finite set of actions A.\nA planning instance, comprises both a planning domain and the elements of a planning problem, describing the initial state of the environment and the goal which an agent wishes to achieve as formalized in Definition 5.\nDefinition 5 (Planning Instance). A planning instance Π is represented by a triple 〈Ξ, I, G〉, in which Ξ = 〈Σ,A〉 is the domain definition; I ⊆ Σ is the initial state specification, which is defined by specifying the value for all facts in the initial state; and G ⊆ Σ is the goal state specification, which represents a desired state to be reached.\nClassical planning representations often separate the definition of I and G as part of a planning problem (to be used together with a domain Ξ). Finally, a plan is the solution to a planning problem, as formalized in Definition 6.\nDefinition 6 (Plan). A plan π for a plan instance Π = 〈Ξ, I, G〉 is a sequence of actions 〈a1, a2, ..., an〉 that modifies the initial state I into one in which the goal state G holds by the successive execution of actions in a plan π. A plan π∗ with length |π∗| is optimal if there exists no other plan π′ for Π such that π′ < π∗."
    }, {
      "heading" : "2.2 Plan Recognition",
      "text" : "Plan recognition is the task of recognizing how agents achieve their goals by observing their interactions in an environment [18]. In plan recognition, such observed interactions are defined as available evidence that can be used to recognize plans. Most plan recognition approaches require knowledge of an agent’s possible plans for representing its typical behavior, in other words, this knowledge provides the recipes (i.e, know-how) for achieving goals. These recipes are\noften called plan libraries and are used as input for many plan recognition approaches [7, 1]. However, in this work we use as input a planning domain definition, more specifically, we use the STRIPS [6] fragment of PDDL [12]. We follow Ramı́rez and Geffner [16, 15] to formally define a plan recognition problem over a planning domain definition as follows.\nDefinition 7 (Plan Recognition Problem). A plan recognition problem is a quadruple TPR = 〈Ξ, I,G, O〉, in which Ξ = 〈Σ, A〉 is the domain definition, and consists of a finite set of facts Σ and a finite set of actionsA; I represents the initial state; G is the set of possible goals of a hidden goal G, such that G ∈ G; and O = 〈o1, o2, ..., on〉 is an observation sequence of a plan execution with each observation oi ∈ O being an action in the finite set of actions A from the domain definition Ξ. This observation sequence can be full or partial, which means that for a full observation sequence we observe all actions during the execution of an agent plan, and for a partial observation sequence, only a sub-sequence of actions of the execution of an agent plan is observed. The solution for this problem is to find a hidden goal G in the set of possible goals G that the observation sequence of a plan execution achieves."
    }, {
      "heading" : "3 Extracting Recognition Information from Planning Definition",
      "text" : "In this section, we describe the process through which we extract useful information for plan recognition from a planning domain. First, we describe landmark extraction algorithms from the literature, and how we use these algorithms to our approach. Second, we show how we classify facts into partitions from planning action descriptions."
    }, {
      "heading" : "3.1 Extracting Landmarks",
      "text" : "In the planning literature, landmarks [9] are defined as necessary features that must be true at some point in every valid plan to achieve a particular goal. Landmarks are often partially ordered according to the sequence in which they must be achieved. Hoffman et al. [9] define landmarks as follows.\nDefinition 8 (Landmark). Given a planning instance Π = 〈Ξ, I, G〉, a formula L is a landmark in Π iff L is true at some point along all valid plans that achieve G from I. In other words, a landmark is a type of formula (e.g, conjunctive formula or disjunctive formula) over a set of facts that must be satisfied at some point along all valid plan executions.\nFor plan recognition problems, landmarks allow us to infer whether a sequence of observations cannot possibly lead to a certain goal. In order to extract the landmarks of a planning problem, we use two landmark extraction algorithms from the literature: 1) Hoffman et al. [9] to extract conjunctive landmarks; and 2) Porteous and Cresswell [14] to extract conjunctive and disjunctive landmarks. To represent landmarks and their ordering, these algorithms use a tree in which nodes represent landmarks and edges represent necessary prerequisites between landmarks. Each node in the tree represents a conjunction of facts that must be true simultaneously at some point during plan execution, and the root node is a landmark representing the goal state. These algorithms use a Relaxed Planning Graph (RPG) [3], which is a leveled graph that ignores the delete-list effects of all actions, and this way, there are no mutex relations in this graph. Once the RPG is built, the algorithm extracts landmark candidates by back-chaining from the RPG level in which all facts of the goal state\nG are possible, and, for each fact g in G, checks which facts must be true until the first level of the RPG. For example, if fact B is a landmark and all actions that achieve B share A as precondition, then A is a landmark candidate. To confirm that a landmark candidate is indeed a landmark, the algorithm builds a new RPG structure by removing actions that achieve this landmark candidate and checks the solvability over this modified problem3, and, if the modified problem is unsolvable, then the landmark candidate is a necessary landmark. This means that the actions that achieve the landmark candidate are necessary to solve the original planning problem.\nHoffman et al. [9] proves that the process of generating exactly all landmarks and deciding about their ordering is PSPACE-complete, which is exactly the same complexity of deciding plan existence [4]. Nevertheless, most landmark extraction algorithms extract only a subset of landmarks for a given planning instance in order to extract landmarks efficiently. In this way, we can monitor landmarks during plan execution to determine which goals a plan is going to achieve and discard candidate goals if some landmarks are not achievable or do not appear as precondition or effect of actions in the observations."
    }, {
      "heading" : "3.2 Fact Partitioning",
      "text" : "Pattison and Long [13] classify facts into mutually exclusive partitions in order to infer whether certain observations are likely to be goals for goal recognition. Their classification relies on the fact that, in some planning domains, predicates may provide additional information that can be extracted by analyzing preconditions and effects in operator definition. We use this classification to infer if certain observations are consistent with a particular goal, and if not, we can eliminate a candidate goal. We formally define fact partitions in what follows.\nDefinition 9 (Strictly Activating). A fact f is strictly activating if f ∈ I and ∀a ∈ A, such that f /∈ eff(a)+ ∪ eff(a)−. Furthermore, ∃a ∈ A, such that f ∈ pre(a).\nDefinition 10 (Unstable Activating). A fact f is unstable activating if f ∈ I and ∀a ∈ A, f /∈ eff(a)+ and ∃a ∈ A, f ∈ pre(a) and ∃a ∈ A, f ∈ eff(a)−.\nDefinition 11 (Strictly Terminal). A fact f is strictly terminal if ∃a ∈ A, such that f ∈ eff(a)+ and ∀a ∈ A, f /∈ pre(a) and f /∈ eff(a)−.\nA Strictly Activating fact (Definition 9) appears as a precondition, and does not appear as add or delete effect in an operator definition. This means that unless defined in the initial state, this fact can never be added or deleted by an operator. An Unstable Activating fact (Definition 10) appears as both a precondition and a delete effect in two operator definitions, so once deleted, this fact cannot be re-achieved. The deletion of an unstable activating fact may prevent a plan execution to achieve a goal. A Strictly Terminal fact (Definition 11) does not appear as a precondition of any operator definition, and once added, cannot be deleted. For some planning domains, this kind of fact is the most likely to be in the set of goal facts, because once added in the current state, it cannot be deleted, and remains true until the final state.\nThe fact partitions that we can extract depend on the planning domain definition. For example, from the BLOCKS-WORLD4 domain,\n3 Deciding the solvability of a relaxed planning problem using an RPG structure can be done in polynomial time [2]. 4 BLOCKS-WORLD is a classical planning domain where a set of stackable blocks must be re-assembled on a table [8].\nit is not possible to extract any fact partitions. However, it is possible to extract fact partitions from the EASY-IPC-GRID5 domain, such as Strictly Activating and Unstable Activating facts. Here, we use fact partitions to obtain additional information on fact landmarks. For example, consider an Unstable Activating fact landmark Lua, so that if Lua is deleted from the current state, then it cannot be re-achieved. We can trivially determine that goals for which this fact is a landmark are unreachable, because there is no available action that achieves Lua again."
    }, {
      "heading" : "4 Filtering Candidate Goals from Landmarks in Observations",
      "text" : "Key to our approach to plan recognition is the ability to filter candidate goals based on the evidence of fact landmarks and partitioned facts in preconditions and effects of observed actions in a plan execution. We now present a filtering process that analyzes fact landmarks in preconditions and effects of observed actions, and selects goals, from a set of candidate goals, that have achieved most of their associated landmarks.\nThis filtering process is detailed in function FILTERCANDIDATEGOALS of Algorithm 1, which takes as input a plan recognition problem TPR, which is composed of a planning domain definition Ξ, an initial state I, a set of candidate goals G, a set of observed actions O, and a filtering threshold θ. Our algorithm iterates over the set of candidate goals G, and, for each goal G in G, it extracts and classifies fact landmarks and partitions for G from the initial state I (Lines 4 and 5). We then check whether the observed actions O contain fact landmarks or partitioned facts in either their preconditions or effects. At this point, if any Strictly Activating facts for the candidate goal G are not in initial state I, then the candidate goal G is no longer achievable and we discard it (Line 6). Subsequently, we check for Unstable Activating and Strictly Terminal facts of goal G in the preconditions and effects of the observed actions O, and if we find any, we discard the candidate goal G (Line 11). If we observe no facts from partitions as evidence from the actions in O, we move on to checking landmarks of G within the actions in O. If we observe any landmarks in the preconditions and positive effects of the observed actions (Line 15), we compute the percentage of achieved landmarks for goal G. As we deal with partial observations in a plan execution some executed actions may be missing from the observation, thus whenever we identify a fact landmark, we also infer that its predecessors have been achieved. For example, let us consider that the set of fact landmarks to achieve a goal from a state is represented by the following ordered facts: (at A)≺ (at B)≺ (at C) ≺ (at D), and we observe just one action during a plan execution, and this observed action contains the (at C) fact landmark as an effect. Based on this action from a partial observation, we can infer that the predecessors of (at C) have been achieved before the observation, and thus, we also include them as achieved landmarks. Given the number of achieved fact landmarks of G, we estimate the percentage of fact landmarks that the observed actions O have achieved according to the ratio between the amount of achieved fact landmarks and the total amount of landmarks (Line 21). Finally, after analyzing all candidate goals in G, we return the goals with the highest percentage of achieved landmarks within our filtering threshold θ (Line 23). Note that, if threshold θ = 0, the filter returns only the goals with maximum completion, given the observations. The threshold gives\n5 EASY-IPC-GRID domain consists of an agent that moves in a grid using keys to open locked locations.\nAlgorithm 1 Filter candidate goals. Input: Ξ = 〈Σ, A〉 planning domain, I initial state, G set of candidate goals, O observations, and θ threshold. Output: A set of filtered candidate goals ΛG with the highest percentage of achieved landmarks.\n1: function FILTERCANDIDATEGOALS(Ξ, I,G, O, θ) 2: ΛG := 〈〉 . Map goals to % of landmarks achieved . 3: for each goal G in G do 4: LG := EXTRACTLANDMARKS(Ξ, I, G) 5: 〈Fsa, Fua, Fst〉 := PARTITIONFACTS(Lg) . Fsa: Strictly Activating, Fua: Unstable Activating, Fst: Strictly Terminal. 6: if Fsa ∩ I = ∅ then 7: continue . Goal G is no longer possible. 8: end if 9: ALG := 〈 〉 . Achieved landmarks for G. 10: for each observed action o in O do 11: if (Fua ∪ Fst) ⊆ (pre(o) ∪ eff(o)+ ∪ eff(o)−) then 12: discardG = true 13: break 14: else 15: L := select all fact landmarks l in LG such that l ∈ pre(o) ∪ eff (o)+ 16: ALG := ALG ∪ L 17: end if 18: end for 19: if discardG then break . Avoid computing achieved\nlandmarks for G. 20: end if 21: ΛG := ΛG ∪ 〈G, ( |ALG| |LG| ) 〉 . Percentage of achieved\nlandmarks for G. 22: end for 23: return all G s.t 〈G, v〉 ∈ ΛG and v ≥ (maxvi 〈G′, vi〉 ∈ ΛG)− θ 24: end function\nus flexibility when dealing with incomplete observations and suboptimal plans, which, when θ = 0, may cause some potential goals to be filtered out before we get additional observations.\nAs an example of how the algorithm filters a set of candidate goals, consider the BLOCKS-WORLD example shown in Figure 1, which represents an initial configuration of stackable blocks, as well as set of candidate goals. The candidate goals consist of the following stackable words: BED, DEB, EAR, and RED. Now consider that the following actions have been observed in the plan execution: (stack E D) and (pick-up S). After filtering the set of candidate goals, we have the following filtered goals for θ = 0: BED and RED. Function FILTERCANDIDATEGOALS returns these goals because the observed action (stack E D) has in its preconditions the fact landmarks (and(clear D)(holding E)), and its effects contain (on E D). Consequently, from these landmarks, it is possible to infer the evidence for another fact landmark, that is: (and(on E A)(clear E)(handempty)). This fact landmark is inferred because it must be true before (clear D) and (holding E). The observed action (pick-up S) does not provide any evidence for filtering the set of candidate goals. Thus, the estimated percentage of achieved fact landmarks of the filtered candidate goals BED and RED is 75%. Both of these goals have 8 fact landmarks, and based on the evidence in the observed actions, we infer 6 fact landmarks have been reached, including fact landmarks in the initial state,\nsuch as: (clear B), (ontable D), and (and(on B C)(clear B)(handempty)) for BED; and (clear R), (ontable D), and (and(clear R)(ontable R)(handempty)) for RED. Regarding goals EAR and DEB, the observations allow us to conclude that, respectively, 3 and 2 out of 7 and 9 fact landmarks were reached. Figures 2 and 3 show the ordered fact landmarks for the filtered candidate goals BED and RED. Boxes in dark gray show achieved fact landmarks for these goals while boxes in light gray show inferred fact landmarks."
    }, {
      "heading" : "5 Heuristic Plan Recognition using Landmarks",
      "text" : "We now develop a landmark-based heuristic method that estimates the goal completion of every goal in the set of filtered goals by analyzing the number of achieved landmarks for each goal provided by the filtering process. We can now heuristically estimate the goal completion of every goal in the set of filtered goals using the computed landmarks. Each candidate goal is composed of sub-goals: atomic facts that are part of a conjunction of facts. This estimate represents the percentage of sub-goals (atomic facts that are part of a conjunction of facts) in a goal that have been accomplished based on the evidence of achieved fact landmarks in observations.\nOur heuristic method estimates the percentage of completion towards a goal by using the set of achieved fact landmarks provided by the filtering process (Algorithm 1, Line 15). We aggregate the percentage of completion of each sub-goal into an overall percentage of completion for all facts in a candidate goal. This heuristic, denoted as hprl, is computed by the formula below, where ALg is the number of achieved landmarks from observations of every sub-goal g of the candidate goal G, and Lg represents the number of necessary landmarks to achieve every sub-goal g of G:\nhprl(G) =\n(∑ g∈G |ALg | |Lg |\n| G |\n) (1)\nThus, heuristic hprl(G) estimates the completion of a goal G by calculating the ratio between the sum of the percentage of completion for every sub-goal g ∈ G, i.e, ∑ g∈G |ALg| |Lg| , and the number of subgoals in G. To exemplify how heuristic hprl estimates goal completion, recall the BLOCKS-WORLD example from Figure 1. For the BED goal its sub-goals (shown at the top of Figure 2) are: (clear B), (on B E), (on E D), and (ontable D). Based on the observed actions (stack E D) and (pick-up S), we conclude that sub-goals (clear B) and (ontable D) have already been achieved because they are in the initial state, and the observed actions do not delete any of those facts. Although fact (clear B) in the initial state does not correspond to the final configuration of goal BED, we account for this fact in the heuristic calculation, since we consider all observed evidence. At this point, our heuristic computes that 50% of goal BED\nhas been accomplished. However, for this goal, there is even more information to be considered in order to calculate the percentage of the BED goal completion. The observed actions have achieved fact landmarks that correspond to the sub-goal (on E D), such as preconditions and effects of the observed action (stack E D), which are: (and(clear D)(holding E)), and (on E D). Therefore, we infer that fact landmark (and(on E A)(clear E)(handempty)) has been achieved, because it must be true before fact landmark (and(clear D)(holding E)). For the sub-goal (on B E), the initial state provides the evidence of the following fact landmark: (and(on B C)(clear B)(handempty)). The observed action (pick-up S) does not provide any evidence for the goal BED. Thus, heuristic hprl estimates that from the evidence of landmarks in the observed actions, the percentage of completion for the goal BED is 83.3%, as follows: (clear B) = 1\n1 + (on B E) = 1 3 + (on E D)\n= 3 3 + (ontable D) = 1 1 . Note that, by varying the threshold θ in the filter of Algorithm 1, we increase the number of candidate goals for which we must compute the heuristic. However, since the heuristic is linear on the number of predicates in a goal, increasing the number of candidate goals has virtually no impact in computational complexity."
    }, {
      "heading" : "6 Landmark-based Plan Recognition",
      "text" : "We now bring together the techniques from Sections 4 and 5 into our landmark-based plan recognition approach that uses the presented filter and heuristic for recognizing goals and plans. Our plan recognition approach is detailed in Algorithm 2. This algorithm takes as input a plan recognition problem TPR, and works in two stages. In the first stage, this algorithm filters candidate goals using the filter (Algorithm 1), which returns the candidate goals with the highest percentage of achieved landmarks within a given threshold θ. In the second stage, from the filtered candidates, this algorithm uses our landmarkbased heuristic (Equation 1) to return the recognized goal(s) by estimating the percentage of completion using the set of achieved fact landmarks provided by the filter.\nAlgorithm 2 Recognize goals and plans using the filtering method and the landmark-based heuristic. Input: Ξ = 〈Σ, A〉 planning domain, I initial state, G set of candidate goals, O observations, and θ threshold. Output: Recognized goal(s).\n1: function RECOGNIZE(Ξ, I,G, O, θ) 2: ΛG := 〈〉 . Map goals to % of landmarks achieved. 3: ΛG := FILTERCANDIDATEGOALS(Ξ, I,G, O, θ) 4: return arg max\nG∈ΛG hprl(G)\n5: end function"
    }, {
      "heading" : "7 Experiments and Evaluation",
      "text" : "In this section, we describe the experiments and evaluation we carried out on our landmark-based plan recognition approach against state-of-the-art techniques. For experiments, we use six domains from datasets provided by Ramı́rez and Geffner [16, 15], comprising hundreds of problems6. We summarize these domains as follows.\n• BLOCKS-WORLD domain consists of a set of blocks, a table, and a robot hand. Blocks can be stacked on top of other blocks or on the table. A block that has nothing on it is clear. The robot hand can hold one block or be empty. The goal is to find a sequence of actions that achieves a final configuration of blocks; • CAMPUS domain consists of finding what activity is being performed by a student from his observations on campus environment; • EASY-IPC-GRID domain consists of an agent that moves in a grid from connected cells to others by transporting keys in order to open locked locations; • INTRUSION-DETECTION represents a domain where a hacker tries to access, vandalize, steal information, or perform a combination of these attacks on a set of servers; • KITCHEN is a domain that consists of home-activities, in which the goals can be preparing dinner, breakfast, among others; and • LOGISTICS is a domain which models cities, and each city contains locations. These locations are airports. For transporting packages between locations, there are trucks and airplanes. Trucks can drive between cities. Airplanes can fly between airports. The goal is to get and transport packages from locations to other locations.\nThese domains contain hundreds of plan recognition problems, i.e, a domain description as well as an initial state, a set of candidate goals G, a hidden goal G in G, and an observation sequence O. An observation sequence contains actions that represent an optimal plan or sub-optimal plan that achieves a hidden goal G, and this observation sequence can be full or partial. A full observation sequence represents the whole plan for a hidden goal G, i.e, 100% of the actions having been observed. A partial observation sequence represents a plan for a hidden goal G with 10%, 30%, 50%, or 70% of its actions having been observed. Our experiments use two metrics, the accuracy of the recognition and the speed to recognize a goal. We compare our approach to two other approaches: the approach of Ramı́rez and Geffner [16], more specifically, we use their faster and most accurate approach; as well as a combination of their approach and our filter.\nFor evaluation, we use the accuracy metric (true positive rate), which represents how well a hidden goal is recognized from a set 6 https://goo.gl/gLF6wB"
    }, {
      "heading" : "82.2% / 85.5% / 97.7% / 100.0%",
      "text" : ""
    }, {
      "heading" : "86.6% / 93.3% / 97.7% / 100.0%",
      "text" : ""
    }, {
      "heading" : "94.4% / 97.7% / 97.7% / 100.0%",
      "text" : ""
    }, {
      "heading" : "95.5% / 98.8% / 98.8% / 100.0%",
      "text" : "0\n20\n40\n60\n80\n100\n0 20 40 60 80 100\nT ru\ne P\no s it iv\ne R\na te\nFalse Positive Rate\nBlocks-World\nFigure 4: ROC curve for the BLOCKS-WORLD domain. 0\n20\n40\n60\n80\n100\nT ru\ne P\no s it iv\ne R\na te\nof possible goals for a given plan recognition problem; as well as recognition time (in seconds), which represents how long it takes for a hidden goal to be recognized given a plan recognition problem. In the BLOCKS-WORLD domain, the accuracy metric measures how well these approaches recognize, from observations, the word that is being assembled. Regarding CAMPUS domain, we aim to accurate how well these approaches recognize the activity is being performed by an observed student. For the EASY-IPC-GRID domain, how accurate these approaches recognize the cell where keys are being to transported by the observed agent. With regard to INTRUSION-DETECTION domain, how accurate these approaches recognize the type of attack and servers that are being hacked observations. In the KITCHEN domain, we aim to accurate how well these approaches recognize the meal is being prepared. For LOGISTICS domain, how accurate these approaches recognize the location where the packages are being transported from observations. Besides the accuracy metric, we use the Receiver Operating Characteristic (ROC), which is called ROC curve. ROC curve shows graphically the performance of a binary classifier system by evaluating true positive rate\nagainst the false positive rate at various threshold settings (in this paper we evaluate plan recognition approaches). More specifically, we use the ROC curve to compare not only true positive predictions (i.e, accuracy), but also to compare the false positive ratio of the experimented plan recognition approaches.\nTable 1 compares the results for the three plan recognition approaches, showing the total number of plan recognition problems used under each domain name. For each domain we show the number of candidate goals |G| and varying percentages of the plan that is actually observed, as well as the average number of observed actions per problem |O|. Note that, for partial observations, random observed actions are removed (up to the set percentage), but the order is maintained. |L| denotes the average number of fact landmarks extracted for each domain. For each approach, we compute the time to recognize the hidden goal (seconds), given the observations, and the accuracy with which the approaches correctly infer the goal. For our landmark-based plan recognition approach, we show the accuracy under different filtering thresholds (0%, 10%, 20% and 30%). If threshold θ = 0, our approach does not give any flexibility for filter-\nFigure 7: ROC curve for the INTRUSION-DETECTION domain.\n0\n20\n40\n60\n80\n100\n0 20 40 60 80 100\nT ru\ne P\no s it iv\ne R\na te\nFalse Positive Rate\nKitchen\nFigure 8: ROC curve for the KITCHEN domain. 0\n20\n40\n60\n80\n100\n0 20 40 60 80 100\nT ru\ne P\no s it iv\ne R\na te\nFalse Positive Rate\nLogistics\nRandom Access θ = 0% (Obs 10%) θ = 0% (Obs 30%) θ = 0% (Obs 50%) θ = 0% (Obs 70%)\nθ = 0% (Obs 100%) θ = 10% (Obs 10%) θ = 10% (Obs 30%) θ = 10% (Obs 50%) θ = 10% (Obs 70%)\nθ = 10% (Obs 100%) θ = 20% (Obs 10%) θ = 20% (Obs 30%) θ = 20% (Obs 50%) θ = 20% (Obs 70%) θ = 20% (Obs 100%) θ = 30% (Obs 10%) θ = 30% (Obs 30%) θ = 30% (Obs 50%) θ = 30% (Obs 70%) θ = 30% (Obs 100%) R&G (Obs 10%) R&G (Obs 30%) R&G (Obs 50%) R&G (Obs 70%)\nR&G (Obs 100%)\nFigure 9: ROC curve for the LOGISTICS domain.\ning candidate goals, returning only the goals with the highest percentage of achieved landmarks. Each row of this table shows the observability (% Obs) and averages of the number of candidate goals |G|, the number of observed actions |O|, recognition time, and accuracy. From this table, it is possible to see that our landmark-based plan recognition approach is both faster and more accurate than Ramı́rez and Geffner [16], and, when we combine their algorithm with our filter, the resulting approach gets a substantial speedup. Importantly, as we increase the threshold, our plan recognition approach quickly surpasses the state of the art in all domains tested. We note that when measuring time to recognition using our filter we also include the time to compute landmarks, so that landmark computation is performed online (i.e, during the process of plan recognition). Thus, even if this computation has a complex upper bound, in our experience, computing landmarks (especially conjunctive ones) is very fast.\nTable 1 shows that both our landmark-based plan recognition approach and Ramı́rez and Geffner’s [16] yield near perfect accuracy for recognizing goals and plans for all planning domains. However, by using the ROC curve we highlight the trade-off between true positive results and false positive results for these plan recognition approaches. Figures 4-9 show the ROC curve for the six planning\ndomains we use. In the ROC curve, the diagonal line in (Random Access) represents a random guess to recognize a goal from observations. This diagonal line divides the ROC space, in which points above the diagonal represent good classification results (better than random), whereas points below the line represent poor results (worse than random). The best possible (perfect) prediction for recognizing goals must be a point in the upper left corner (i.e, coordinate x = 0 and y = 100) in the ROC space. Thus, the closer a plan recognition approach (point) gets to the upper left corner, the better it is for recognizing goals and plans. Blue, green, red, and yellow points with five different symbols represent our plan recognition approach varying the use of the threshold (0%, 10%, 20% and 30%). These five different symbols represent the percentage of observability (10%, 30%, 50%, 70% and 100%) with regard to the observed plan. Black points represent Ramı́rez and Geffner’s [16] approach (R&G). According to the ROC curve in Figures 5, 7, 8, and 9 we see that all variation (using different thresholds) of our plan landmark-based recognition approach yield good (sometimes perfect) predictions for recognizing goals and plans, in contrast to R&G, which is near-perfect in these four domains. Figure 4 shows that the results for the BLOCKSWORLD are quite scattered in the ROC curve, so recognizing goals and plans in this domain is difficult. Nevertheless, it possible to see\nthat our plan recognition is not only competitive (using the thresholds between 10% and 20%) with R&G with superior accuracy, but also at least 8.75 orders of magnitude faster than R&G. Finally, Figure 6 shows that in the EASY-IPC-GRID domain our approach is very competitive with R&G, again with consistently higher accuracy, but also is near perfect for false positives, surpassing R&G by using different thresholds."
    }, {
      "heading" : "8 Related Work",
      "text" : "Ramı́rez and Geffner [16] propose planning approaches for plan recognition, and instead of using plan-libraries, they model the problem as a planning domain theory with respect to a known set of goals. Their work uses a heuristic, an optimal and modified sub-optimal planner to determine the distance to every goal in a set of goals after an observation. Follow-up work [15] proposes a probabilistic plan recognition approach using off-the-shelf planners. These approaches yield high accuracy in most domains, however, this accuracy is lower than in our threshold-based approaches, and their time to recognition ranges from twice slower to up to an order of magnitude slower. Pattison and Long [13] propose IGRAPH (AUTOmatic Goal Recognition with A Planning Heuristic), a probabilistic heuristic-based goal recognition over planning domains. IGRAPH uses heuristic estimation and domain analysis to determine which goals an agent is pursuing. Although we adapt their fact partitions, their problem definition is formally different than ours, preventing direct comparison. In [11], Keren et al. present an alternate view regarding the goal and plan recognition problem. This work uses planning techniques to assist in the design of goal and plan recognition problems. Most recently, E.Martı́n et al. [5] propose a planning-based plan recognition approach that propagates cost and interaction information in a plan graph, and uses this information to estimate goal probabilities over the set of candidate goals. Although our landmark-based plan recognition approach has no probabilistic interpretation, the accuracy of our approach seems to be higher in the same domains."
    }, {
      "heading" : "9 Conclusion",
      "text" : "We have developed an approach for plan recognition that relies on planning landmarks and a new heuristic based on these landmarks. Landmarks provide key information about what cannot be avoided to achieve a goal, and we show that landmarks can be used efficiently for very accurate plan recognition. We have shown empirically that our approach yields not only superior accuracy results but also substantially faster recognition times for all domains used in evaluating against the state of the art [16] at varying observation completeness levels.\nOur experiments show that in at least one domain, disjunctive landmarks have a positive effect on accuracy with minimal effect on recognition time, whereas in some domains, these landmarks are either not present or yield almost no gain in accuracy at substantial loss of speed. Knowledge of the domains leads us to believe that disjunctive landmarks are most useful in domains in which we assume that observed plans are just sub-optimal, such as the KITCHEN domain. Conversely, disjunctive landmarks slow down recognition in domains in which there are multiple mutually exclusive plans towards the same goal, such as the EASY-IPC-GRID domain in which the agent moves in a grid.\nWe intend to explore multiple avenues for future work. First, we aim to evaluate other planning techniques, such as heuristics and symmetries in classical planning [17]. Second, we intend to explore\nother landmark extraction algorithms to obtain additional information from planning domains, such as temporal landmarks [10]. Third, we aim to model a probability interpretation to the observed landmarks and compare the probability results (and probabilistic accuracy) to the recent work of E.-Martı́n et al. [5]. Finally, for domains with goals with intersecting landmarks, we can use measures of information gain to weigh observations to help break ties when multiple goals are left after the filter. Given the computational complexity of landmark extraction in the general case, we aim to theoretically analyze the tradeoff between landmark completeness and runtime efficiency."
    } ],
    "references" : [ {
      "title" : "Fast and Complete Symbolic Plan Recognition",
      "author" : [ "Dorit Avrahami-Zilberbrand", "Gal A. Kaminka" ],
      "venue" : "IJCAI",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Fast Planning Through Planning Graph Analysis",
      "author" : [ "Avrim L. Blum", "Merrick L. Furst" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1997
    }, {
      "title" : "A Tutorial on Planning Graph Based Reachability Heuristics",
      "author" : [ "Daniel Bryce", "Subbarao Kambhampati" ],
      "venue" : "AI Magazine,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "The Computational Complexity of Propositional STRIPS Planning",
      "author" : [ "Tom Bylander" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1994
    }, {
      "title" : "A Fast Goal Recognition Technique Based on Interaction Estimates",
      "author" : [ "Yolanda E.-Martı́n", "Marı́a D.R.-Moreno", "David E. Smith" ],
      "venue" : "IJCAI",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "STRIPS: A new approach to the application of theorem proving to problem solving",
      "author" : [ "Richard E Fikes", "Nils J Nilsson" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1971
    }, {
      "title" : "Partial Observability and Probabilistic Plan/Goal Recognition",
      "author" : [ "Christopher W. Geib", "Robert P. Goldman" ],
      "venue" : "Proceedings of the 2005 International Workshop on Modeling Others from Observations (MOO-",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2005
    }, {
      "title" : "Ordered Landmarks in Planning",
      "author" : [ "Jörg Hoffmann", "Julie Porteous", "Laura Sebastia" ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "Temporal landmarks: What must happen, and when",
      "author" : [ "Erez Karpas", "David Wang", "Brian C. Williams", "Patrik Haslum" ],
      "venue" : "ICAPS",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "Goal recognition design",
      "author" : [ "Sarah Keren", "Avigdor Gal", "Erez Karpas" ],
      "venue" : "Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Extending Landmarks Analysis to Reason about Resources and Repetition",
      "author" : [ "J. Porteous", "S. Cresswell" ],
      "venue" : "Proceedings of the 21st Workshop of the UK Planning and Scheduling Special Interest Group (PLANSIG",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2002
    }, {
      "title" : "Probabilistic Plan Recognition Using Off-the-Shelf Classical Planners",
      "author" : [ "Miquel Ramı́rez", "Hector Geffner" ],
      "venue" : "AAAI",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Plan Recognition as Planning.",
      "author" : [ "Miquel Ramı́rez", "Hector Geffner" ],
      "venue" : "IJCAI 2009.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2009
    }, {
      "title" : "Heuristics and Symmetries in Classical Planning",
      "author" : [ "Alexander Shleyfman", "Michael Katz", "Malte Helmert", "Silvan Sievers", "Martin Wehrle" ],
      "venue" : "AAAI",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Most plan recognition approaches [7, 1] employ plan libraries (i.",
      "startOffset" : 33,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "Most plan recognition approaches [7, 1] employ plan libraries (i.",
      "startOffset" : 33,
      "endOffset" : 39
    }, {
      "referenceID" : 12,
      "context" : "Recent work [16, 15, 13, 5] use planning domain definitions (domain theories) to represent potential agent behavior, bringing plan recognition closer to planning algorithms.",
      "startOffset" : 12,
      "endOffset" : 27
    }, {
      "referenceID" : 11,
      "context" : "Recent work [16, 15, 13, 5] use planning domain definitions (domain theories) to represent potential agent behavior, bringing plan recognition closer to planning algorithms.",
      "startOffset" : 12,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : "Recent work [16, 15, 13, 5] use planning domain definitions (domain theories) to represent potential agent behavior, bringing plan recognition closer to planning algorithms.",
      "startOffset" : 12,
      "endOffset" : 27
    }, {
      "referenceID" : 10,
      "context" : "In this paper, we develop a plan recognition approach that relies on planning landmarks [14, 9] to filter candidate goals and plans from the observations.",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "In this paper, we develop a plan recognition approach that relies on planning landmarks [14, 9] to filter candidate goals and plans from the observations.",
      "startOffset" : 88,
      "endOffset" : 95
    }, {
      "referenceID" : 12,
      "context" : "Second, we show that the filter we develop can also be applied to other planning-based plan recognition approaches, such as the approach from Ramı́rez and Geffner [16].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 12,
      "context" : "We evaluate empirically our plan recognition approach against the current state-of-the-art [16] by using openly available datasets for plan recognition developed by Ramı́rez and Geffner in [16, 15], and which have been used to evaluate recent approaches to plan recognition [5].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 12,
      "context" : "We evaluate empirically our plan recognition approach against the current state-of-the-art [16] by using openly available datasets for plan recognition developed by Ramı́rez and Geffner in [16, 15], and which have been used to evaluate recent approaches to plan recognition [5].",
      "startOffset" : 189,
      "endOffset" : 197
    }, {
      "referenceID" : 11,
      "context" : "We evaluate empirically our plan recognition approach against the current state-of-the-art [16] by using openly available datasets for plan recognition developed by Ramı́rez and Geffner in [16, 15], and which have been used to evaluate recent approaches to plan recognition [5].",
      "startOffset" : 189,
      "endOffset" : 197
    }, {
      "referenceID" : 4,
      "context" : "We evaluate empirically our plan recognition approach against the current state-of-the-art [16] by using openly available datasets for plan recognition developed by Ramı́rez and Geffner in [16, 15], and which have been used to evaluate recent approaches to plan recognition [5].",
      "startOffset" : 274,
      "endOffset" : 277
    }, {
      "referenceID" : 12,
      "context" : "First, by relaxing the filter using a small threshold our landmarkbased plan recognition approach is more accurate than the current state-of-the-art [16].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 6,
      "context" : "These recipes are often called plan libraries and are used as input for many plan recognition approaches [7, 1].",
      "startOffset" : 105,
      "endOffset" : 111
    }, {
      "referenceID" : 0,
      "context" : "These recipes are often called plan libraries and are used as input for many plan recognition approaches [7, 1].",
      "startOffset" : 105,
      "endOffset" : 111
    }, {
      "referenceID" : 5,
      "context" : "However, in this work we use as input a planning domain definition, more specifically, we use the STRIPS [6] fragment of PDDL [12].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "We follow Ramı́rez and Geffner [16, 15] to formally define a plan recognition problem over a planning domain definition as follows.",
      "startOffset" : 31,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "We follow Ramı́rez and Geffner [16, 15] to formally define a plan recognition problem over a planning domain definition as follows.",
      "startOffset" : 31,
      "endOffset" : 39
    }, {
      "referenceID" : 7,
      "context" : "In the planning literature, landmarks [9] are defined as necessary features that must be true at some point in every valid plan to achieve a particular goal.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 7,
      "context" : "[9] define landmarks as follows.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9] to extract conjunctive landmarks; and 2) Porteous and Cresswell [14] to extract conjunctive and disjunctive landmarks.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "[9] to extract conjunctive landmarks; and 2) Porteous and Cresswell [14] to extract conjunctive and disjunctive landmarks.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 2,
      "context" : "These algorithms use a Relaxed Planning Graph (RPG) [3], which is a leveled graph that ignores the delete-list effects of all actions, and this way, there are no mutex relations in this graph.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "[9] proves that the process of generating exactly all landmarks and deciding about their ordering is PSPACE-complete, which is exactly the same complexity of deciding plan existence [4].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[9] proves that the process of generating exactly all landmarks and deciding about their ordering is PSPACE-complete, which is exactly the same complexity of deciding plan existence [4].",
      "startOffset" : 182,
      "endOffset" : 185
    }, {
      "referenceID" : 1,
      "context" : "3 Deciding the solvability of a relaxed planning problem using an RPG structure can be done in polynomial time [2].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 12,
      "context" : "For experiments, we use six domains from datasets provided by Ramı́rez and Geffner [16, 15], comprising hundreds of problems.",
      "startOffset" : 83,
      "endOffset" : 91
    }, {
      "referenceID" : 11,
      "context" : "For experiments, we use six domains from datasets provided by Ramı́rez and Geffner [16, 15], comprising hundreds of problems.",
      "startOffset" : 83,
      "endOffset" : 91
    }, {
      "referenceID" : 12,
      "context" : "We compare our approach to two other approaches: the approach of Ramı́rez and Geffner [16], more specifically, we use their faster and most accurate approach; as well as a combination of their approach and our filter.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 12,
      "context" : "Table 1: Comparison and experimental results of our landmark-based approach against Ramirez and Geffner [16] approach.",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "From this table, it is possible to see that our landmark-based plan recognition approach is both faster and more accurate than Ramı́rez and Geffner [16], and, when we combine their algorithm with our filter, the resulting approach gets a substantial speedup.",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 12,
      "context" : "Table 1 shows that both our landmark-based plan recognition approach and Ramı́rez and Geffner’s [16] yield near perfect accuracy for recognizing goals and plans for all planning domains.",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 12,
      "context" : "Black points represent Ramı́rez and Geffner’s [16] approach (R&G).",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 12,
      "context" : "Ramı́rez and Geffner [16] propose planning approaches for plan recognition, and instead of using plan-libraries, they model the problem as a planning domain theory with respect to a known set of goals.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 11,
      "context" : "Follow-up work [15] proposes a probabilistic plan recognition approach using off-the-shelf planners.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 9,
      "context" : "In [11], Keren et al.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "[5] propose a planning-based plan recognition approach that propagates cost and interaction information in a plan graph, and uses this information to estimate goal probabilities over the set of candidate goals.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 12,
      "context" : "We have shown empirically that our approach yields not only superior accuracy results but also substantially faster recognition times for all domains used in evaluating against the state of the art [16] at varying observation completeness levels.",
      "startOffset" : 198,
      "endOffset" : 202
    }, {
      "referenceID" : 13,
      "context" : "First, we aim to evaluate other planning techniques, such as heuristics and symmetries in classical planning [17].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 8,
      "context" : "Second, we intend to explore other landmark extraction algorithms to obtain additional information from planning domains, such as temporal landmarks [10].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 4,
      "context" : "[5].",
      "startOffset" : 0,
      "endOffset" : 3
    } ],
    "year" : 2017,
    "abstractText" : "Recognition of goals and plans using incomplete evidence from action execution can be done efficiently by using planning techniques. In many applications it is important to recognize goals and plans not only accurately, but also quickly. In this paper, we develop a heuristic approach for recognizing plans based on planning techniques that rely on ordering constraints to filter candidate goals from observations. These ordering constraints are called landmarks in the planning literature, which are facts or actions that cannot be avoided to achieve a goal. We show the applicability of planning landmarks in two settings: first, we use it directly to develop a heuristic-based plan recognition approach; second, we refine an existing planning-based plan recognition approach by pre-filtering its candidate goals. Our empirical evaluation shows that our approach is not only substantially more accurate than the state-of-the-art in all available datasets, it is also an order of magnitude faster.",
    "creator" : "LaTeX with hyperref package"
  }
}