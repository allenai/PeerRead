{
  "name" : "1709.00917.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Using Optimal Ratio Mask as Training Target for Supervised Speech Separation",
    "authors" : [ "Shasha Xia", "Hao Li", "Xueliang Zhang" ],
    "emails" : [ "cszxl@imu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "APSIPA ASC 2017\nlearning algorithms to learn a mapping from an input noisy signal to an output target. With the fast development of deep learning, supervised separation has become the most important direction in speech separation area in recent years. For the supervised algorithm, training target has a significant impact on the performance. Ideal ratio mask is a commonly used training target, which can improve the speech intelligibility and quality of the separated speech. However, it does not take into account the correlation between noise and clean speech. In this paper, we use the optimal ratio mask as the training target of the deep neural network (DNN) for speech separation. The experiments are carried out under various noise environments and signal to noise ratio (SNR) conditions. The results show that the optimal ratio mask outperforms other training targets in general.\nI. INTRODUCTION\nSpeech separation aims to extract the target speech signal from a noisy mixture and it is meaningful for many applications such as robust automatic speech recognition (ASR) and hearing aids design. Monaural speech separation is the most common case and also very challenging, because only one channel signal could be used. In this study, we focus on monaural speech separation. This problem has been studied for many years. The early methods, e.g. spectral subtraction [1], have stationary assumptions on background noise, which limit their application. Computational auditory scene analysis (CASA) [2] stimulates human auditory mechanism and employs an Ideal binary mask (IBM) [3] as the computational goal. The IBM indicates the target speech on a time-frequency (T-F) representation, where “1” and “0” indicates a T-F unit dominated by target speech and noise respectively. With this concept, it is natural to formulate the speech separation as a binary classification problem which can be solved by supervised learning algorithms.\nFor the supervised speech separation, three key factors are mainly concerned, i.e. learning machines, features and training targets. Several learning machines have been investigated in the literature, e.g. Gaussian mixture model (GMM) [4], support vector machine (SVM) [5] and Deep Neural Networks (DNN) [6]. Typically, DNN-based speech separation has achieved a\ngreat success, because its strong learning capacity enables effective modeling of nonlinear interactions between speech and the acoustic environments as well as dynamic structure of speech. Discriminative features are also important. In [7-8], extensive features are studied in noisy and reverberant conditions.\nFor the training target, we should keep in mind that the ideal target can obtain good separation results, and its estimation shouldn’t be hard by current learning machines. The IBM and Ideal Ratio Mask (IRM) [9] are commonly used targets. Separating with the IBM usually introduces residual musical noise and speech quality cannot be improved. IRM can be thought of as smooth form of IBM, which improves both speech quality and intelligibility. Recent works show that phase information is also important for speech separation. Based on these researches, complex Ideal Ratio Mask (cIRM) [10] and Phase Sensitive Mask (PSM) [11] were proposed. The cIRM is computed on complex domain. Although the cIRM can perfectly recover the target speech, it increases the difficulty of estimation. The PSM introduces the phase information and operates on real domain.\nRecently, Optimal Ratio Mask (ORM) is proposed in [12], which can be viewed as an improved version of the IRM. The ORM considers the correlation between the target speech and noise in real environment. Theoretical analysis shows that the ORM can improve the SNR over the IRM. However, is the ORM a good training target for supervised speech separation algorithm? This key question, as we mentioned earlier, is not answered.\nThis paper aims to investigate the performance of ORM when applied in DNN-based monaural speech separation. The rest of this paper is organized as follows: next Section describes the framework and procedure of DNN-based monaural speech separation system. In Section III, we describe the calculations of five training targets adopted for comparison. The results are shown in Section IV. We conclude the paper in the last Section."
    }, {
      "heading" : "II. DNN-BASED MONAURAL SPEECH SEPARATION",
      "text" : "The framework of the DNN-based monaural speech separation used in this study is same as in [9]. We use a set of complementary features consisting of amplitude modulation spectrogram (AMS), relative spectral transform and perceptual linear prediction (RASTA-PLP) and Mel-frequency cepstral coefficients (MFCC). The feature set used here is similar to the one in [9]. Since useful information is carried across time frames, a symmetric 5-frame context window is used to splice adjacent frames into a single feature vector.\nThe DNN is composed of three hidden layers, each layer has 1024 rectified linear hidden units (ReLU) [13]. The back propagation with dropout regularization (dropout rate 0.2) [14] is used for network training. Adaptive gradient descent [15]\nAPSIPA ASC 2017\ncoupled with a momentum term as the optimization technique. Momentum rate is 0.5 during first 5 epochs and 0.9 during the rest epochs. The goal of network training is to output an ideal estimation of training target. We use the mean squared error (MSE) as cost function. The number of output units is correspond to the dimensionality of the training target. The sigmoid activation function is applied when target is in the range of [0, 1], otherwise linear activation function is applied. The general architecture is shown in Fig. 1."
    }, {
      "heading" : "III. THE OPTIMAL RATIO MASK",
      "text" : "The definition for the ORM is derived by minimizing the mean square error (MSE) of clean speech and estimated target speech [12].\n\uD835\uDEFE(\uD835\uDC61, \uD835\uDC53) = |\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|2 + ℛ(\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)\uD835\uDC41∗(\uD835\uDC61, \uD835\uDC53))\n|\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|2 + |\uD835\uDC41(\uD835\uDC61, \uD835\uDC53)|2 + 2ℛ(\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)\uD835\uDC41∗(\uD835\uDC61, \uD835\uDC53))\n(1)\nwhere, \uD835\uDC46(\uD835\uDC61, \uD835\uDC53) and \uD835\uDC41(\uD835\uDC61, \uD835\uDC53) are the spectrum of speech and noise at frame \uD835\uDC61 and frequency \uD835\uDC53 . ℛ(°) denotes the real component of spectrum and ‘*’ denotes the conjugate operation.\nIt can be seen that ORM is very similar to IRM, except for the coherent part ℛ(\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)\uD835\uDC41∗(\uD835\uDC61, \uD835\uDC53)), which is assumed to be 0 in IRM. In fact, this assumption is too strong. Figure 2 shows the spectral coherence between the speech and the noise in a noisy speech. We can see that the speech and the noise are highly correlated. The ORM is proven to get better performance for speech separation in [12].\nThe ORM varies in the range of (−∞, +∞) that is not easy to estimate. So, we restrict the value of the ORM with a hyperbolic tangent as in [9]\nORM(\uD835\uDC61, \uD835\uDC53) = \uD835\uDC3E 1 − \uD835\uDC52−\uD835\uDC50\uD835\uDEFE(\uD835\uDC61,\uD835\uDC53)\n1 + \uD835\uDC52−\uD835\uDC50\uD835\uDEFE(\uD835\uDC61,\uD835\uDC53)\n(2)\nwhere, c = 0.1 is steepness and \uD835\uDC3E=10 restricts the range of the ORM to (−10, +10) . \uD835\uDEFE(\uD835\uDC61, \uD835\uDC53) is the original ORM defined in eq. (1).\nIV. VARIOUS TRAINING TARGETS\nIn this section, we will introduce several mask targets. The separation system employing mask target is called mask-based speech separation.\nA. Ideal binary mask (IBM)\nThe IBM the simplest mask which is defined as following.\nIBM(\uD835\uDC61, \uD835\uDC53) = { 1,\n0,\n\uD835\uDC56\uD835\uDC53 |\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|2 − |\uD835\uDC41(\uD835\uDC61, \uD835\uDC53)|2 > \uD835\uDF03\n\uD835\uDC5C\uD835\uDC61ℎ\uD835\uDC52\uD835\uDC5F\uD835\uDC64\uD835\uDC56\uD835\uDC60\uD835\uDC52\n(3)\nwhere \uD835\uDF03 is the local threshold in T-F units, and it is set to zero.\nB. Ideal ratio mask (IRM)\nFrom eq. (3), we can see that the IBM makes a hard decision according to the energy of speech and noise in T-F unit. IRM can be viewed as a soft decision, which is defined as,\nIRM(\uD835\uDC61, \uD835\uDC53) = ( |\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|2\n|\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|2 + |\uD835\uDC41(\uD835\uDC61, \uD835\uDC53)|2 )\n\uD835\uDEFD\n(4)\nwhere \uD835\uDEFD is a tunable parameter, which is usually set to 0.5.\nC. Complex Ideal ratio mask (cIRM)\nThe IBM and the IRM are constructed on the magnitude of the speech and the noise. Recent research showed that the phase information is also important for speech separation [16]. The cIRM includes the phase in its construction, which can be viewed as the IRM in the complex domain.\nGiven the spectrum Y of mixture, the spectrum S of speech\nsignal can be generated as follows, S(\uD835\uDC61, \uD835\uDC53) = \uD835\uDC40(\uD835\uDC61, \uD835\uDC53) ∗ \uD835\uDC4C(\uD835\uDC61, \uD835\uDC53) (5) where ‘*’ is complex multiplication. \uD835\uDC40(\uD835\uDC61, \uD835\uDC53) is the complex mask which can be expressed as follows,\nM = \uD835\uDC4C\uD835\uDC5F\uD835\uDC46\uD835\uDC5F + \uD835\uDC4C\uD835\uDC56\uD835\uDC46\uD835\uDC56\n\uD835\uDC4C\uD835\uDC5F 2 + \uD835\uDC4C\uD835\uDC56\n2 + \uD835\uDC56 \uD835\uDC4C\uD835\uDC5F\uD835\uDC46\uD835\uDC56 − \uD835\uDC4C\uD835\uDC5F\n\uD835\uDC4C\uD835\uDC5F 2 + \uD835\uDC4C\uD835\uDC56 2\n(6)\nwhere \uD835\uDC4C\uD835\uDC5F , \uD835\uDC4C\uD835\uDC56 , \uD835\uDC46\uD835\uDC5F and \uD835\uDC46\uD835\uDC56 stand for the real and imaginary components of \uD835\uDC4C and \uD835\uDC46, respectively.\nD. Phase sensitive mask (PSM)\nThe PSM directly uses a phase sensitive target function,\nwhich involves both amplitude and phase information.\nPSM(\uD835\uDC61, \uD835\uDC53) = |\uD835\uDC46(\uD835\uDC61, \uD835\uDC53)|\n|\uD835\uDC4C(\uD835\uDC61, \uD835\uDC53)| cos \uD835\uDF03\n(7)\nwhere \uD835\uDF03 = \uD835\uDF03\uD835\uDC46 + \uD835\uDF03\uD835\uDC4C is the phase. PSM is restricted in real domain.\nAPSIPA ASC 2017"
    }, {
      "heading" : "V. EXPERIMENTAL RESULTS",
      "text" : ""
    }, {
      "heading" : "A. Dateset",
      "text" : "We use 600 randomly chosen utterances from the IEEE female corpus as our training utterances. The rest of 120 utterances are used as the test set. Four noises from the NOISEX dataset [17] are used as our training and test noises, including a speech-shaped noise (SSN), a babble noise (babble), a factory noise (factory) and a destroyer engine room noise (engine). Except SNN, all other 3 noises are non-stationary. All noises are around 4 minutes long. To create the training set, we use random 10 slices from the first 2 minutes of each noise to mix with each utterance from the training utterances at -3, 0 and 3dB. Thus, we have 72000 (600 utterances×10 slices×4 noises×3 SNR). The test mixtures are constructed by mixing random cuts from the last 2 minutes of each noise with the test utterances at -3, 0 and 3 dB. Cutting from different parts of the noises ensures that noise segments used in training and testing phase are different."
    }, {
      "heading" : "B. Evaluation Criteria",
      "text" : "We use the Short-Time Objective Intelligibility (STOI) score [18] to measure the objective intelligibility. STOI denotes a correlation of short-time temporal envelopes between clean and separated speech, and has been proved to be highly correlated to human speech intelligibility score. The value of STOI is in the range of [0, 1]. We also evaluate objective speech quality using the Perceptual Evaluation of Speech\nQuality (PESQ) score [19]. Same as the STOI, the PESQ is calculated by comparing the separated speech with the corresponding clean speech. The STOI score ranges from 0 to 1, and PESQ score ranges from -0.5 to 4.5."
    }, {
      "heading" : "C. Results",
      "text" : "The separating results of the five training targets is given in table 1, 2, 3, which are respectively under the condition of - 3dB, 0dB, 3dB SNR mixture. Bold face indicates the target that performed best within a noise type. IBM and IRM are two most widely used training targets. Table 1~3 show that IBM improves speech intelligibility but not speech quality. This may due to the binary property of IBM, and musical noise is produced during the separation. Compared to IBM, IRM improves both speech intelligibility and speech quality significantly, especially the speech quality.\ncIRM, PSM and ORM are training targets proposed recent years whose value various in a large range. cIRM performs best theoretically, the result shows it outperforms IRM on improvement of speech quality, whereas its improvement of speech intelligibility is close to IRM. cIRM and PSM both concerned about phase information, cIRM operates on complex domain while PSM on real domain. Table 1~3 show that PSM improves speech intelligibility by 1%~2% and 12%~22% compared to cIRM and unprocessed mixture, outperforms other training targets. PSM improves speech quality by 0.07~0.19 compared to cIRM. This maybe because that\nAPSIPA ASC 2017\nstructure of the imagine component of cIRM is not obvious and difficult to estimate, which lead to its poor actual performance.\nTable I, II and III show that the improvement on speech intelligibility of ORM and PSM are close, while ORM outperforms PSM on speech quality. We can see from Table I that improvement of ORM is 1% lower than PSM while better than other training targets. For the speech quality, on SSN, Engine and Factory noise, ORM performs best, which improves 0.81~1.07 compared to unprocessed mixture and 0.05~0.07 compared to PSM. In Table II, performance of ORM is close to PSM on speech intelligibility. ORM outperforms other training targets on speech quality. In Table III, on engine noise PSM is little bit better than ORM, while on other noise their performance are close as to speech intelligibility ORM outperforms other training targets. In general, ORM outperforms other training targets. ORM concerns about the correlation between clean speech and noise while PSM concerns about the phase information. ORM performs better than PSM may due to that the correlation between clean speech and noise have greater impact on speech separation than phase information, the estimated target signal is closer to clean speech. Fig 5 shows STFT spectrogram of mixture on Babble noise at 3dB and target speech separated with IBM, IRM, cIRM, ORM, PSM as the training targets."
    }, {
      "heading" : "VI. CONCLUSIONS",
      "text" : "Monaural speech separation is always a challenging task in the area of speech recognition. Supervised speech separation integrates deep neural network technology which emerged as a new trend in recent years, impressive improvements are achieved under low SNR mixture and non-stationary noise condition. The IBM and IRM are the most popular training targets. However, IBM improves speech intelligibility but not speech quality. IRM improves both speech intelligibility and speech quality under the assumption that clean speech is independent with noise. Recent research prove that phase information is important for speech separation, cIRM and PSM were proposed. cIRM performs well theoretically, while the structure of its imagine component is not obvious, difficult to estimate. PSM improves speech intelligibility and speech quality significantly, outperform other training targets.\nIn this paper, we adapt ORM as training target, which concerns about the correlation between clean speech and noise, the result shows that ORM performs better than other training targets in general. This maybe because that there is relation between clean speech and noise in real environment and have greater impact on speech separation than phase information. Based on this, we think the analyses of the relation between clean speech and noise and how to describe and estimate it is going to be a new direction in the area of training target research."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "This research was supported in part by a China National\nNature Science Foundation grant (No. 61365006),"
    } ],
    "references" : [ {
      "title" : "Suppression of acoustic noise in speech using spectral subtraction,",
      "author" : [ "S. Boll" ],
      "venue" : "IEEE Trans. on acoust., speech, and signal process.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1979
    }, {
      "title" : "On Ideal Binary Mask as the Computational Goal of Auditory Scene Analysis",
      "author" : [ "D.L Wang" ],
      "venue" : "P. Divenyi (Ed.), Speech Separation by Humans and Machines, Kluwer Academic, Norwell MA, 2005:181-197, 2005.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "An algorithm that improves speech intelligibility in noise for normal-hearing listeners",
      "author" : [ "G. Kim", "Y. Lu", "Y. Hu", "P.C. Loizou" ],
      "venue" : "J. Acoust. Soc. Amer., vol. 126, pp. 1486–1494, 2009.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A classification based approach to speech segregation",
      "author" : [ "K. Han", "D.L. Wang" ],
      "venue" : "Journal of the Acoust. Society of Amer., vol. 132, pp. 3475- 3483, 2012.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Cocktail party processing via structured prediction",
      "author" : [ "Y. Wang", "D.L. Wang" ],
      "venue" : "Proceedings of NIPS-12, pp. 224-232, 2012.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A feature study for classificationbased speech separation at low signal-to-noise ratios",
      "author" : [ "J. Chen", "Y. Wang", "D.L. Wang" ],
      "venue" : "IEEE/ACM Trans. on Audio, Speech, and Lang. Process., vol. 22, pp. 1993-2002, 2014.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Features for masking-based monaural speech separation in reverberant conditions",
      "author" : [ "M. Delfarah", "D.L. Wang" ],
      "venue" : "IEEE/ACM Trans. on Audio, Speech, and Lang. Process., vol. 25, pp. 1085-1094, 2017.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2017
    }, {
      "title" : "On training targets for supervised speech separation",
      "author" : [ "Y. Wang", "A. Narayanan", "D.L. Wang" ],
      "venue" : "IEEE/ACM Trans. on Audio, Speech, and Lang. Process., vol. 22, pp. 1849-1858, 2014.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1849
    }, {
      "title" : "Complex ratio masking for monaural speech separation",
      "author" : [ "D.S. Williamson", "Y. Wang", "D.L. Wang" ],
      "venue" : "IEEE/ACM Trans. on Audio, Speech, and Lang. Process, vol. 24, pp. 483-492, 2016.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks",
      "author" : [ "H. Erdogan", "J.R. Hershey", "S. Watanabe" ],
      "venue" : "ICASSP, pp. 708-712, 2015.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "The optimal ratio time-frequency mask for speech separation in terms of the signal-to-noise ratio",
      "author" : [ "S. Liang S", "W. Liu", "W. Jiang" ],
      "venue" : "Journal of the Acoust. Society of Amer., vol. 134, pp.452-458, 2013.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "V. Nair", "G. Hinton" ],
      "venue" : "Proc. ICML 2010 pp. 807-814.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "N. Srivastava", "G. Hinton", "A. Krizhevsky" ],
      "venue" : "The Journal of Machine Learn. Resear., vol. 15, pp. 1929-1958, 2014.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1929
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : "The Journal of Machine Learning Research, vol. 12, pp. 2121-2159, 2011.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "The importance of phase in speech enhancement",
      "author" : [ "K. Paliwal", "K. Wójcicki", "B. Shannon" ],
      "venue" : "Speech Commun., vol. 53, pp. 465-494, 2011.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems",
      "author" : [ "A. Varga", "H. Steeneken" ],
      "venue" : "Speech Commun., vol. 12, pp. 247–251, 1993.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "An algorithm for intelligibility prediction of time-frequency weighted noisy speech",
      "author" : [ "C. Taal", "R. Hendriks", "R. Heusdens", "J. Jensen" ],
      "venue" : "IEEE Trans. Audio, Speech, Lang. Process., vol. 19, pp. 2125–2136, 2011.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs",
      "author" : [ "A. Rix", "J. Beerends", "M. Hollier", "A. Hekstra" ],
      "venue" : "Proc. ICASSP, pp. 749–752, 2001.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "spectral subtraction [1], have stationary assumptions on background noise, which limit their application.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "Computational auditory scene analysis (CASA) [2] stimulates human auditory mechanism and employs an Ideal binary mask (IBM) [3] as the computational goal.",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "Gaussian mixture model (GMM) [4], support vector machine (SVM) [5] and Deep Neural Networks (DNN) [6].",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 3,
      "context" : "Gaussian mixture model (GMM) [4], support vector machine (SVM) [5] and Deep Neural Networks (DNN) [6].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 4,
      "context" : "Gaussian mixture model (GMM) [4], support vector machine (SVM) [5] and Deep Neural Networks (DNN) [6].",
      "startOffset" : 98,
      "endOffset" : 101
    }, {
      "referenceID" : 5,
      "context" : "In [7-8], extensive features are studied in noisy and reverberant conditions.",
      "startOffset" : 3,
      "endOffset" : 8
    }, {
      "referenceID" : 6,
      "context" : "In [7-8], extensive features are studied in noisy and reverberant conditions.",
      "startOffset" : 3,
      "endOffset" : 8
    }, {
      "referenceID" : 7,
      "context" : "The IBM and Ideal Ratio Mask (IRM) [9] are commonly used targets.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "Based on these researches, complex Ideal Ratio Mask (cIRM) [10] and Phase Sensitive Mask (PSM) [11] were proposed.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 9,
      "context" : "Based on these researches, complex Ideal Ratio Mask (cIRM) [10] and Phase Sensitive Mask (PSM) [11] were proposed.",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 10,
      "context" : "Recently, Optimal Ratio Mask (ORM) is proposed in [12], which can be viewed as an improved version of the IRM.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 7,
      "context" : "The framework of the DNN-based monaural speech separation used in this study is same as in [9].",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 7,
      "context" : "The feature set used here is similar to the one in [9].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 11,
      "context" : "The DNN is composed of three hidden layers, each layer has 1024 rectified linear hidden units (ReLU) [13].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 12,
      "context" : "2) [14] is used for network training.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 13,
      "context" : "Adaptive gradient descent [15]",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "The sigmoid activation function is applied when target is in the range of [0, 1], otherwise linear activation function is applied.",
      "startOffset" : 74,
      "endOffset" : 80
    }, {
      "referenceID" : 10,
      "context" : "The definition for the ORM is derived by minimizing the mean square error (MSE) of clean speech and estimated target speech [12].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 10,
      "context" : "The ORM is proven to get better performance for speech separation in [12].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 7,
      "context" : "So, we restrict the value of the ORM with a hyperbolic tangent as in [9]",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 14,
      "context" : "Recent research showed that the phase information is also important for speech separation [16].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 15,
      "context" : "Four noises from the NOISEX dataset [17] are used as our training and test noises, including a speech-shaped noise (SSN), a babble noise (babble), a factory noise (factory) and a destroyer engine room noise (engine).",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 16,
      "context" : "We use the Short-Time Objective Intelligibility (STOI) score [18] to measure the objective intelligibility.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "The value of STOI is in the range of [0, 1].",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "We also evaluate objective speech quality using the Perceptual Evaluation of Speech Quality (PESQ) score [19].",
      "startOffset" : 105,
      "endOffset" : 109
    } ],
    "year" : 2017,
    "abstractText" : "Supervised speech separation uses supervised learning algorithms to learn a mapping from an input noisy signal to an output target. With the fast development of deep learning, supervised separation has become the most important direction in speech separation area in recent years. For the supervised algorithm, training target has a significant impact on the performance. Ideal ratio mask is a commonly used training target, which can improve the speech intelligibility and quality of the separated speech. However, it does not take into account the correlation between noise and clean speech. In this paper, we use the optimal ratio mask as the training target of the deep neural network (DNN) for speech separation. The experiments are carried out under various noise environments and signal to noise ratio (SNR) conditions. The results show that the optimal ratio mask outperforms other training targets in general.",
    "creator" : "Microsoft® Word 2013"
  }
}