{
  "name" : "1605.01677.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Copeland Dueling Bandit Problem: Regret Lower Bound, Optimal Algorithm, and Computationally Efficient Algorithm",
    "authors" : [ "Junpei Komiyama", "Junya Honda", "Hiroshi Nakagawa" ],
    "emails" : [ "JUNPEI@KOMIYAMA.INFO", "HONDA@STAT.T.U-TOKYO.AC.JP", "NAKAGAWA@DL.ITC.U-TOKYO.AC.JP" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "A multi-armed bandit problem is a crystallized instance of a sequential decision-making problem in an uncertain environment, and it can model many real-world scenarios. This problem involves conceptual entities called arms. At each round, the forecaster draws one of the K arms and receives a corresponding reward feedback. The aim of the forecaster is to maximize the cumulative reward over rounds, which is achieved by running an algorithm that balances the exploration (acquisition of information) and the exploitation (utilization of information). In evaluating the performance of a bandit algorithm, a metric called regret, which mea-\nsures how much the algorithm explores, is widely used.\nWhile it is desirable to obtain rewards as direct feedback from an arm, in a number of practical cases such direct feedback is not available. In this paper, we consider a version of the standard stochastic bandit problem called the K-armed dueling bandit problem (Yue et al., 2009), in which the forecaster receives relative feedback, which specifies which of the two arms is preferred. Although the original motivation of the dueling bandit problem arose in the field of information retrieval, learning under relative feedback is universal to many fields, such as recommender systems (Gemmis et al., 2009), graphical design (Brochu et al., 2010), and natural language processing (Zaidan & Callison-Burch, 2011), which involve explicit or implicit feedback provided by humans.\nIn the standard bandit problem, the best arm is naturally defined as the one with the largest expected reward. However, if the feedback is restricted to the results of pairwise comparisons, there are several possible ways to define the best arm. Following the literature on the dueling bandit problem, we call the best arm the winner. When there exists an arm that beats (i.e., preferred in expectation) all the other arms, it is natural to define it as the winner; this notion is called a Condorcet winner. Unfortunately, the Condorcet winner does not always exist. Still, we can define an extended notion of the Condorcet winner that always exists as follows. Let the Copeland winners be the arms that beat the greatest number of other arms. In this paper, we study the difficulty of finding the Copeland winners from pairwise feedback."
    }, {
      "heading" : "1.1. Related work",
      "text" : "Early algorithms for solving the dueling bandit problem, such as Interleaved Filter (Yue et al., 2012) and Beat the Mean Bandit (Yue & Joachims, 2011), require the arms to\nar X\niv :1\n60 5.\n01 67\n7v 2\n[ st\nat .M\nL ]\n2 4\nM ay\nbe totally ordered.\nUrvoy et al. (2013) considered a large class of sequential learning problems that includes the dueling bandit problem and introduced the notion of Condorcet, Copeland, and Borda dueling bandit problems. Several algorithms, such as Relative Upper Confidence Bound (RUCB) (Zoghi et al., 2014), and Relative Minimum Empirical Divergence (RMED) (Komiyama et al., 2015a), have since been proposed that effectively solve the Condorcet dueling bandit problem. The assumption on the Condorcet winner partly relaxes the assumption of the total order because it admits circular preferences that involve non-winners.\nHowever, as the Condorcet winner does not always exist, the result of running one of these algorithms is unpredictable if it is applied to an instance without a Condorcet winner. Consequently, the practical applicability of Condorcet dueling bandit algorithms is limited. Some papers have discussed the problem of preference elicitation without a Condorcet winner (Jamieson et al., 2015; Zoghi et al., 2015a) and have motivated studies of more general dueling bandit problems. Unlike the Condorcet winner, the Borda and Copeland winners always exist. Note that there are also other notions of winners, such as the von Neumann winner (Dudı́k et al., 2015) or Random walk winner (Altman & Tennenholtz, 2008) together with their corresponding dueling bandit problems. Among them, we will consider the Copeland dueling bandit problem. Unlike the Borda or Random Walk winners, the Copeland winners are compatible with the Condorcet winner; if the Condorcet winner exists, it is also the Copeland winner. An algorithm for finding the Copeland winner (i) covers the application range of the Condorcet winner and (ii) can find arms that beat other arms the most, even if the Condorcet winner does not exist.\nAnother line of study is on the partial monitoring problem (Bartók et al., 2014). The partial monitoring is general enough to cover the multi-armed bandit. Some classes of dueling bandit problems, such as utility-based ones (Gajane & Urvoy, 2015), can also be formalized as a partial monitoring. However, it is unknown as to whether the Copeland dueling bandit problem can be effectively represented as a partial monitoring or not. Moreover, existing algorithms for partial monitoring, such as Bayes-update Partial Monitoring (BPM) (Vanchinathan et al., 2014) or Partial Monitoring Deterministic Minimum Empirical Divergence (PMDMED) (Komiyama et al., 2015b), are not very scalable to the number of actions.\nExisting results on the Copeland dueling bandit problem: The difficulty of the dueling bandit problem lies in that there are O(K2) pairs. There are some algorithms, such as Sensitivity Analysis of VAriables for Generic Exploration (SAVAGE) (Urvoy et al., 2013), Preference-based Racing (PBR) (Busa-Fekete et al., 2013), and Rank Elicita-\ntion (RankEI) (Busa-Fekete et al., 2014), that can deal with general classes of problems that entail solving Copeland dueling bandit problems. The price to pay for such generality is performance: all three algorithms have O(K2 log T ) regret because they naively compare all pairs O(log T ) times.\nThe recently proposed Copeland Confidence Bound (CCB) (Zoghi et al., 2015a) exploits the structure of the Copeland dueling bandit problem and is relatively efficient. It has an asymptotic regret of O(K(C+L1+1)∆2 log T ) (Theorem 3 in Zoghi et al. 2015a), where C is the number of Copeland winners, L1 is the number of arms that beats the Copeland winner, and ∆ is related to how hard it is to determine whether each arm i beats arm j or not. In this paper, we further push our understanding of the dueling bandit problem by deriving an asymptotically optimal regret bound. The optimal bound states that (i) the dependency on C can be completely removed; (ii) the dependency on L1 is necessary for some cases but unnecessary for typical cases explained later, and (iii) the dependency on ∆ can be relaxed by introducing a divergence-based bound. In an information retrieval example, the optimal bound improves the one of the CCB by several orders of magnitude (Table 1).\nContributions: The main contributions of this paper are summarized in the following four aspects: First, we derive an asymptotic regret lower bound (Section 3). The lower bound is based on the minimum amount of exploration for identifying a Copeland winner. Second, we propose the Copeland Winners Relative Minimum Empirical Divergence (CW-RMED) algorithm. CW-RMED is the first algorithm whose performance asymptotically matches the regret lower bound (Section 4.1). Unfortunately, a naive implementation of CW-RMED is computationally prohibitive. Third, we propose Efficient Copeland Winners RMED (ECW-RMED), another algorithm that addresses the above computational issue (Section 4.2). An efficient way to implement it is proposed. Moreover, we show that the regret of ECW-RMED is very close to optimal. Finally, we implemented ECW-RMED and compared its performance with those of existing algorithms (Section 5). ECW-\nRMED significantly outperformed the state-of-the-art algorithms on many datasets. In a ranker evaluation example, its regret was smaller than one third of those of the others."
    }, {
      "heading" : "2. Problem Setup",
      "text" : "TheK-armed dueling bandit problem involvesK arms that are indexed as [K] := {1, 2, . . . ,K}. Let M ∈ RK×K be a preference matrix whose ij entry µi,j corresponds to the probability that arm i is preferred to arm j. At each round t = 1, 2, . . . , T , the forecaster draws a pair of arms p(t) = (l(t),m(t)) ∈ [K]2 and, receives relative feedback X̂l(t),m(t)(t) ∼ Bernoulli(µl(t),m(t)) that indicates which of (l(t),m(t)) is preferred. We say arm i beats arm j if µi,j > 1/2. By definition, µi,j = 1 − µj,i holds for any i, j ∈ [K] and µi,i = 1/2. Throughout this paper, we assume µi,j 6= 1/2 for i 6= j. Let Pi 6=j := {(i, j) : i, j ∈ [K], i > j} and Pall := {(i, j) : i, j ∈ [K], i ≥ j}. A comparison of pair (i, j) is identified with that of pair (j, i).\nLet Ni,j(t) be the number of comparisons of pair (i, j) and µ̂i,j(t) be the empirical estimate of µi,j at round t. For j 6= i, let Ni>j(t) be the number of times i is preferred over j. Accordingly, µ̂i,j(t) = Ni>j(t)/Ni,j(t), where we set 0/0 = 1/2 here.\nLet the superiors of arm i be Si := {j : j ∈ [K], µi,j < 1/2}, that is, the set of arms that beat arm i. Let Li := |Si| and C = |{i ∈ [K] : Li = minj Lj}|. Without loss of generality, we can assume L1 = L2 = · · · = LC ≤ · · · ≤ LK . Of course, algorithms should not exploit this ordering. Arms [C] are called Copeland winners. Note that the Copeland winners always exist, but are not necessarily unique. Let the inferiors of arm i be Ii := {j : j ∈ [K], µi,j > 1/2}. Assuming that µi,j 6= 1/2 for i 6= j, each arm j is either a superior or an inferior of arm i. When L1 = 0, the Copeland winner is unique and also called a Condorcet winner.\nWe define the regret per round1 is ri,j := (Li + Lj − 2L1)/(2(K − 1)) ≤ 1 when the pair (i, j) is compared and the regret as R(T ) := ∑ t∈[T ] rl(t),m(t). The regret increases at each round unless both l(t) and m(t) are Copeland winners. This definition is reasonable because we have defined the goodness of an arm by the number of arms that i beats (Copeland number) and are interested in drawing the best arms. The choice of l(t) = m(t) is possible, but yields no useful information since, by definition, µi,i = 1/2 for any arm i.\nNote that, we can also consider other definitions of regret; the analysis in this paper is relied on the facts that regret per round ri,j is (i) finite, (ii) determined by the Copeland\n1The constant factor of this definition is different from the one defined in Zoghi et al. (2015a). Our result can be compared with that of Zoghi et al. (2015a) simply by multiplying a constant.\nnumbers, (iii) and equal to zero if i and j are Copeland winners. For example, we can consider a regret such that ri,j = 0 if i, j ∈ [C] and 1 otherwise, and easily modify our result in accordance with that definition."
    }, {
      "heading" : "3. Regret Lower Bound",
      "text" : "In this section, we derive an asymptotic regret lower bound when T → ∞. In the context of the standard multi-armed bandit problem, Lai & Robbins (1985) derived the regret lower bound of strongly consistent algorithms; intuitively, a strongly consistent algorithm is “uniformly good” in the sense that it works well with any set of model parameters. We extend this result to the Copeland dueling bandit problem.\nWe first define notions that are important in characterizing the regret lower bound: the subsets of the power set of the superiors and the inferiors with a fixed size. Let Smi := {S ∈ 2Si : |S| = m}, Imi := {I ∈ 2Ii : |I| = m}, and S\\j,mi := {S ∈ 2Si\\{j} : |S| = m}. Moreover, let MCop be a set of all preference matrices of size K × K. A Copeland dueling bandit algorithm is strongly consistent if it satisfies E[R(T )] = o(T a) for any a > 0 given any preference matrix M ∈ MCop. Essentially, a strongly consistent algorithm needs to find one of the Copeland winners with a high confidence level. To make sure that arm i∗ is a Copeland winner, we need to simultaneously find (i) an upper-bound Li∗ of a Copeland winner i∗ and (ii) a lower-bound Lj of the other arms. The minimum amount of exploration in Copeland dueling bandit is characterized in this way. The following lemma formalizes the aforementioned statement.\nLemma 1. (Lower bound on the number of draws) Let dKL(p, q) := p log p/q+(1−p) log (1− p)/(1− q) be the Kullback-Leibler (KL) divergence between two Bernoulli distributions with parameters p, q. For any strongly consistent algorithm, the following inequality holds for at least one i1 ∈ [C]:\n∀i2 6=i1 ∀l ∈ {max{0, L1 − 1}, . . . , L2}\n∀I ∈ Il+1−Li1i1 ∀S ∈ S \\i1,max{0,Li2−l−1{i2∈I}} i2∑\n(i,j)∈PIS\ndKL(µi,j , 1/2)E [Ni,j(T )] ≥ (1− o(1)) log T,\n(1)\nwhere\nPIS = PIS(i1, i2, l, I, S) := {(i1, j) : j ∈ I} ∪ {(i2, j) : j ∈ S}.\nIntuitively, Lemma 1 can be interpreted as follows: for each round t, consistency requires an algorithm to identify one of the Copeland winners i1 with confidence level\n1/t. For some i2, l, I, and S, if the preferences among the pairs in PIS(i1, i2, l, I, S) are inverted, then arm i2 6= i1 has Li2 ≤ l and Li1 ≥ l + 1, which implies that i1 is not a Copeland winner. We need to limit all such risks for all possible i2, l, I, S. Each risk is calculated in accordance with the large deviation principle (Cover & Thomas, 2006) as∼ exp (− ∑ PIS dKL(µi,j , 1/2)Ni,j(t)), and the algorithm must continue comparing pairs in PIS until ∑ PIS dKL(µi,j , 1/2)Ni,j(t) ∼ log t in order to lower the risk to exp (− log t) = 1/t for each PIS .\nThe proof of Lemma 1 is in Appendix E. Note that all proofs are in Supplementary Material. The technique used in the proof extends the one of Lai & Robbins (1985) for the standard bandit problem in two aspects: (i) in the standard bandit problem, each arm is associated with a single distribution, whereas in the Copeland dueling bandit problem each arm is related to K − 1 distributions (i.e., comparison with other arms). Therefore, not all of the pairs are required to be drawn, and we need a sophisticated analysis to determine the set of conditions that consistency requires. Moreover, (ii) the Copeland winner is not necessarily unique; there can be several ties with the maximum Copeland number. We show that consistency requires an algorithm to find at least one of the Copeland winners, but it does not need to find all of them.\nNext, we derive the asymptotic regret lower bound, which is the minimum amount of regret such that inequality (1) is satisfied. Let {νi,j} be a K ×K preference matrix, and let the superiors and the inferiors under the preference matrix {νi,j} be Ŝi = Ŝi({νi,j}) := {j ∈ [K] : νi,j < 1/2} and Îi = Îi({νi,j}) := {j ∈ [K] : νi,j > 1/2}. Moreover, let the number of the superiors be L̂i = L̂i(νi,j) := |Ŝi(νi,j)|, and the a-th smallest element among {L̂i}i∈[K] be L̂(a) = L̂(a)({νi,j}); let the Copeland winner be Ĉcop = Ĉcop({νi,j}) := {i : L̂i = L̂(1)({νi,j})} ⊂ [K]. Ŝmi ({νi,j}), Îmi ({νi,j}), and Ŝ \\j,m i ({νi,j}) are defined in the same way. For i1 ∈ Ĉcop, let\nRi1({νi,j}):= { {qi,j}i>j∈ [0, 1/dKL(νi,j , 1/2)]K(K−1)/2 :\n∀i2 6=i1 ∀l ∈ {max{0, L̂(1) − 1}, . . . , L̂(2)}\n∀I ∈ Î(l+1−L̂ (1)) i1 ∀S ∈ Ŝ\\i1,max{0,L̂i2−l−1{i2∈I}}i2∑\n(i,j)∈PIS\nqi,jdKL(νi,j , 1/2) ≥ 1 } . (2)\nNote that Ri1({νi,j}) is non-empty because it includes a trivial solution qi,j = 1/dKL(νi,j , 1/2) for each (i, j) ∈ Pi 6=j . Moreover, let r̂i,j({νi,j}) := (L̂i + L̂j −\n2L̂(1))/(2(K − 1)) be the regret per draw with {νi,j} and\nC∗i1({νi,j}) := inf{qi,j}i>j∈Ri1 ({νi,j}) ∑\n(i,j)∈Pi6=j\nr̂i,jqi,j ,\nand let the (possibly non-unique) set of optimal solutions be\nR∗i1({νi,j}) := { {qi,j}i>j ∈ Ri1({νi,j}) :∑ (i,j)∈Pi6=j r̂i,jqi,j = C ∗ i1({νi,j}) } .\nThe value C∗i1({µi,j}) log T is the possible minimum regret for exploration to make sure that the arm i1 is in [C]. Using Lemma 1 yields the following regret lower bound.\nTheorem 2. The regret of a strongly consistent algorithm is lower bounded as:\nE[R(T )] ≥ min i1∈[C] C∗i1({µi,j}) log T − o(log T ).\nThe proof of Theorem 2 is in Appendix E."
    }, {
      "heading" : "3.1. Comparison with the Consistency in Condorcet dueling bandits",
      "text" : "A dueling bandit algorithm is strongly consistent in the sense of Condorcet if it has subpolynomial regret for any M ∈ MCond, whereMCond is the set of preference matrices in which the Condorcet winner (i.e., the Copeland winner i1 of Li1 = 0) exists (Komiyama et al., 2015a). Although the definitions of the regret in the two dueling bandit problems are slightly different, they are the same in that drawing pairs that include non-Copeland winners increases regret, and thus a subpolynomial regret in the sense of the Condorcet dueling bandit problem is consistent with the one of the Copeland dueling bandit problem. Therefore, a strongly consistent Copeland dueling bandit algorithm is also strongly consistent in the sense of the Condorcet dueling bandit problem sinceMCop ⊃ MCond. The converse is not necessarily true: when we run a Condorcet dueling bandit algorithm with a preference matrix without a Condorcet winner, it can fail to identify a Copeland winner.\nAn example in which the two consistencies make a difference is in Table 2. RMED2FH (Komiyama et al., 2015a), an optimal algorithm for solving the Condorcet dueling bandit problem, may not be consistent in the sense of Copeland; RMED2FH draws pairs (2, 3), (2, 4), and (3, 4) to prove that each of 2, 3, and 4 is beaten by another arm, which implies that these arms are non-Condorcet. However, in the sense of Copeland, an algorithm must make sure that the superior of arm 1 is smaller than those of the other arms, and thus, it needs to compare arm 1 with the others for sufficiently many times."
    }, {
      "heading" : "4. Algorithms",
      "text" : "In this section, we first introduce the CW-RMED algorithm, which is inspired by the DMED algorithm (Honda & Takemura, 2010) for solving the multi-armed bandit problem. We then derive an asymptotically optimal regret bound for CW-RMED. However, to the best of our knowledge, it is not known whether an optimization in the subroutine can be efficiently computed or not. To address this issue, we devise another algorithm called ECW-RMED, which is computationally efficient and has a regret bound that is close to optimal."
    }, {
      "heading" : "4.1. CW-RMED",
      "text" : "Algorithm 1 is CW-RMED. At the beginning of each round t = 1, 2, . . . , T , if there exists a pair (i, j) ∈ Pi 6=j that is not drawn O( √ log t) times or µ̂i,j(t) is very close to 1/2, it immediately draws that pair. Otherwise, it enters the loop that sequentially draws each pair in LC . After drawing each pair, it checks whether the current observation is sufficient or not. If the observation is enough to identify some î∗(t) as a Copeland winner, it exploits by adding (̂i∗(t), î∗(t)) into LNC , the candidates of the pairs that will be drawn in the next loop. Otherwise, it draws the pairs with the number of observations below the minimum requirement for identifying î∗(t) as a winner with high confidence. Note that it considers a pair of the same arm (i, i) and pair of different arms (i, j), i 6= j, separately. Since a comparison with itself yields no information, drawing (i, i) is purely for exploitation.\nThe following theorem, whose proof is in Appendix H, states that the regret of CW-RMED is asymptotically optimal when we view the parameters of the preference matrix {µi,j} as constants. Therefore, it performs as well as any other strongly consistent algorithm for sufficiently large T . Theorem 3. Assume that arg mini1∈[C] C ∗ i1\n({µi,j}) and R∗i1({µi,j}) for each i1 ∈ [C] are unique. For any α > 0, β > 0, the regret of CW-RMED is bounded as:\nE[R(T )] ≤ min i1∈[C] C∗i1({µi,j}) log T + o(log T ) ."
    }, {
      "heading" : "4.1.1. COMPUTATION OF AN OPTIMAL SOLUTION",
      "text" : "Here, we discuss the computational aspects of CWRMED. Checking (3) is relatively easy since we can sort"
    }, {
      "heading" : "1 0.5 0.6 0.6 0.6",
      "text" : ""
    }, {
      "heading" : "2 0.4 0.5 0.9 0.1",
      "text" : ""
    }, {
      "heading" : "3 0.4 0.1 0.5 0.9",
      "text" : "Algorithm 1 CW-RMED and ECW-RMED Algorithms 1: Input: K arms, α > 0, β > 0. 2: LC , LR ← Pi 6=j , LN ← ∅. 3: while t ≤ T do 4: Draw all pairs such that (i, j) ∈ Pi 6=j if Ni,j(t) <\nα √\nlog t or |µ̂i,j(t)− 1/2| < β/ log log t. t← t+ 1 for each draw.\n5: for p(t) = (l(t),m(t)) ∈ LC in an arbitrarily fixed order do 6: Draw arm pair p(t). 7: LNC ← ∅. 8: if\n{Ni,j(t)/ log t}i6=j ∈ Rî∗(t)({µ̂i,j(t)}) (3)\nfor some î∗(t) ∈ Ĉcop(µ̂i,j(t)) then 9: Put (̂i∗(t), î∗(t)) into LNC .\n10: else 11: Compute some\nî∗(t) =\n{ arg mini1∈Ĉcop C ∗ i1\n({µ̂i,j(t)}) (CW) arg mini1∈Ĉcop C E∗ i1 ({µ̂i,j(t)}) (ECW)\n{q∗i,j} ∈\n{ R∗ î∗(t) (µ̂i,j(t)) (CW)\nRE∗ î∗(t) (µ̂i,j(t)) (ECW) (ties are broken arbitrarily) and put all pairs (i, j) ∈ Pi 6=j such that q∗i,j > Ni,j(t)/ log t into LNC .\n12: Put (̂i∗(t), î∗(t)) into LNC . 13: end if 14: LR ← LR \\ {p(t)}. 15: LN ← LN ∪ (i, j) (without a duplicate) for any (i, j) ∈ LNC ∩ (Pi 6=j \\ LR). 16: t← t+ 1. 17: end for 18: LC , LR ← LN , LN ← ∅. 19: end while\n{qi,jdKL(νi,j , 1/2)} for each (i1, j) ∈ Ii1 or (i2, j) ∈ Si2 , and the constraint that matters is the top-c smallest of them for each size-c subset.\nThe difficult part is the computation of {q∗i,j} ∈ R∗i1({µ̂i,j(t)}) for each i1, which can be formulated as a linear programming (LP). In the case of this paper the number of constraints of the LP is exponential in K and a naive use of an LP solver is sometimes very slow. It is well known that even if there are exponentially many constraints an LP can be solved by using the ellipsoid method (Khachiyan, 1980) in a polynomial time if there exists a polynomial-time oracle that (i) checks whether a point {qij} is feasible or not and (ii) returns a hyperplane such that {qij} and the feasible region are separated if {qij} is infeasible. Such an oracle is easily constructed based on the\nsorting described above, and thus {q∗i,j} ∈ R∗i1({µ̂i,j(t)}) can be computed in a polynomial time. Although the ellipsoid method is practically very slow, a practical combinatorial algorithm is often derived later for many problems that are solvable by the ellipsoid method (see, e.g., Korte & Vygen 2007, Chapters 1–4 and 12). Thus the authors think that R∗i1({µ̂i,j(t)}) can be computed practically. Still, in this paper, we consider a suboptimal solution because it runs not only in polynomial time but also in time almost the same as that of sorting, as described in Section 4.2."
    }, {
      "heading" : "4.2. ECW-RMED",
      "text" : "In this section, we propose ECW-RMED (Algorithm 1). The difference between CW-RMED (Section 4.1) and ECW-RMED is the amount of exploration. For a candidate of Copeland winners i1, it tries to make sure that neither Li1 ≥ mini Li + 1 nor Li2 ≤ mini Li − 1 for any i2 6= i1 occurs, which implies that i1 is a Copeland winner. Namely, for i1 ∈ Ĉcop, let\nREi1({νi,j}):= { {qi,j}i>j∈ [0, 1/dKL(νi,j , 1/2)]K(K−1)/2 :\n∀j ∈ Îi1 qi1,j = 1/dKL(νi1,j , 1/2), (4)\n∀i2 6=i1∀S ∈ Ŝ \\i1,L̂i2−L̂i1+1 i2∑\nj∈S qj,i2dKL(νj,i2 , 1/2) ≥ 1\n} . (5)\nNote that the red lines are the differences from Ri1(·). Moreover, let\nCE∗i1 ({νi,j}) := inf{qi,j}∈Ri1 ({νi,j}) ∑\n(i,j)∈Pi6=j\nr̂i,jqi,j ,\nand let the (possibly non-unique) set of optimal solutions be\nRE∗i1 ({νi,j}) := { {qi,j} ∈ REi1({νi,j}) :∑\n(i,j)∈Pi6=j\nr̂i,jqi,j = C ∗ i1({νi,j})\n} .\nThe following theorem, whose proof is in Appendix H, bounds the regret of ECW-RMED.\nTheorem 4. Assume that arg mini1∈[C] C E∗ i ({µi,j}) and RE∗i1 ({µi,j}) for each i1 ∈ [C] are unique. For any α > 0, β > 0, the regret of ECW-RMED is bounded as:\nE[R(T )] ≤ min i1∈[C] CE∗i1 ({µi,j}) log T + o(log T ) .\nA quantitative discussion on the regret bounds of CW/ECW-RMED is found in Appendix C."
    }, {
      "heading" : "4.2.1. EFFICIENT COMPUTATION OF ECW-RMED",
      "text" : "In this section, we show an efficient method of finding {qi,j}i>j ∈ RE∗i1 ({µ̂i,j(t)}) for i1 ∈ Ĉcop({µ̂i,j(t)}). Since the inequality (5) is disjoint for each i2 6= i1, solving it for each i2 suffices. Let S := Ŝi2 \\ {i1}, k := |S| − (L̂i2 − L̂i1 + 1). Moreover, let cj := r̂j,i2({µ̂i,j(t)})/dKL(µ̂j,i2(t), 1/2) ≥ 0 and ej := qj,i2dKL(µ̂j,i2(t), 1/2) ≥ 0. Accordingly, the regret minimization under (5) is reduced to the following linear optimization problem:\nminimize ∑ j∈S cjej\nsubject to ∀S⊂S:|S|=|S|−k ∑ j∈S ej ≥ 1. (6)\nHere, cj ≥ 0 can be considered as a cost, and (6) is a cost minimization problem. In the following discussion we assume |S| > k > 0; otherwise the optimization problem is trivial. The following theorem, whose proof is in Appendix F, states that an optimal solution of the problem is computed efficiently.\nTheorem 5. Let σ1, σ2, . . . , σ|S| ∈ S be a permutation of S such that cσ1 ≤ cσ2 ≤ · · · ≤ cσ|S| . There exists h > k such that at least one optimal solution {e∗j} of (6) satisfies\ne∗σ1 = e ∗ σ2 = · · · = e ∗ σh = 1/(h− k), e∗σh+1 = e ∗ σh+2 = . . . e∗σ|S| = 0. (7)\nSince we only have |S| − k ≤ K candidates of h in (7), an optimal solution can be found by checking each of them."
    }, {
      "heading" : "4.3. Relation between CW-RMED and ECW-RMED",
      "text" : "The following theorem, whose proof is in Appendix G, relates the optimal regret bound and the one of ECW-RMED.\nTheorem 6. (Optimality of ECW-RMED) The following inequality always holds:\nCE∗i1 ({µi,j}) ≥ C ∗ i1({µi,j}). (8)\nMoreover, if C ≥ 2, the following equality holds:\nCE∗i1 ({µi,j}) = C ∗ i1({µi,j}). (9)\nInequality (8) states that the leading logarithmic constant of the bound on CW-RMED is always as good as that of ECW-RMED, which is natural since CW-RMED is asymptotically optimal as stated in Theorem 4. Still, (9) states that ECW-RMED has exactly the same constant when the Copeland winners are not unique."
    }, {
      "heading" : "4.4. Comparison of ECW-RMED and CCB",
      "text" : "In this section, we qualitatively discuss the improvement on the regret bound given by ECW-RMED.\nLet ∆ := min(i,j)∈Pi6=j |µi,j − 1/2|. Theorem 3 in Zoghi et al. (2015a) showed that CCB has an asymptotic regret bound2 of\nO\n( K(C + L1 + 1)\n∆2 log T\n) . (10)\nOn the other hand,RE∗i1 ({µi,j}) includes\nqi,j/dKL(µi,j , 1/2)\n=  1 if i = i1, j ∈ Ii1 , 1/(Li2 − L1 + 1) if i = i2, j ∈ Si2 \\ {i1}, 0 otherwise,\nwhich implies that ECW-RMED has a leading constant of\nmin i1∈[C]\nCE∗i1 ({µi,j}) ≤\n1\ndKL(1/2 + ∆, 1/2) ∑ i2 6=i1 ( 1 + Li2 Li2 − L1 + 1 ) . (11)\n2Here, we use a ∆ that is a little bit looser than the one in the original bound of Zoghi et al. (2015a) for the sake of discussion. In Table 1, we used the value of the original regret bound of CCB.\nThis bound is expressed in terms of the KL divergence instead of ∆2 ≤ dKL(1/2 + ∆, 1/2)/2. Furthermore, taking the maximum of (11) over {Li2}i2 6=i1 with facts\n∀i2 6= i1, L1 ≤ Li2 ≤ K, ∑ i2 6=i1 Li2 ≤ K2 2 ,\nwe see that\nmin i1\nCE∗i1 ({µi,j}) ≤ K\ndKL(1/2 + ∆, 1/2)\n( L1 + 3\n2 + L21 K\n) .\n(12)\nTherefore the regret of ECW-RMED can be bounded independent of C whereas (10) contains a O(CK) term. Furthermore, the bound (12) is tight only in the case that Li2 is close to L1 for O(K) arms i2, which infrequently occurs in practice since Li2 ≈ K/2 on average. In fact, if L1 = o(K) and there exists ρ ∈ (0, 1/2) such that Li2 ≤ ρK for at most o(K) arms i2 then we can bound (11) in the same way as (12) by\nmin i1\nCE∗i1 ({µi,j}) ≤ 2K + o(K)\ndKL(1/2 + ∆, 1/2) ,\nwhich is independent of L1.\nThe only drawback of our analysis is the assumption on the uniqueness of the optimal solution, which is not very\nstringent. In our experiment, ECW-RMED performed well even when the optimal solution was not unique (MultiSol in Section 5)."
    }, {
      "heading" : "4.5. On hyperparameters α and β",
      "text" : "CW/ECW-RMED have two hyperparameters α and β. The hyperparameter α is necessary in both theoretical and practical point of views. It urges the draw of each pair for o(log t) times to assure the quality of the estimator µ̂i,j(t). On the other hand, we conjecture that the parameter β is a theoretical artifact. Technically, the hyperparameter β is required for bounding the regret when the quality of the estimation is low (i.e., inequality (32) in Appendix). A very small or zero β is practically sufficient: One can confirm that, setting β = 0 yields almost the same results as shown in Section 5."
    }, {
      "heading" : "5. Numerical Experiment",
      "text" : "To evaluate the empirical performance of the proposed algorithms, we conducted computer simulations with the following datasets (preference matrices).\nMSLR: We tested submatrices of a 136 × 136 preference matrix from Zoghi et al. (2015b), which is derived from the Microsoft Learning to Rank (MSLR) dataset (Microsoft Research, 2010; Qin et al., 2010) that consists of relevance information between queries and documents with more than 30K queries. Zoghi et al. (2015b) created a finite set of rankers, each of which corresponds to a ranking feature in the base dataset. The value µi,j is the probability that the ranker i beats ranker j based on the informational click model (Hofmann et al., 2013). We randomly chose subsets of rankers in our experiments and made sub preference matrices. We excluded cases with extremely small gaps such that |µi,j − 1/2| < 0.005 for K = 16 or |µi,j − 1/2| < 0.0005 for K = 64. Furthermore, we selected the submatrices in which the Condorcet winner exists (Figure 1(a)) and the Condorcet winner does not exist (Figures 1(b) and 1(c)).\nSushi: This dataset is based on the sushi preference dataset (Kamishima, 2003) that contains the preferences of 5, 000 Japanese users as regards to 100 types of sushi. We extracted 16 types of sushi and converted them into a preference matrix with µi,j corresponding to the ratio of users who prefer sushi i over j, which is shown in Table 3(a) in Appendix.\nGap is the preference matrix of Table 3(b) in Appendix. This matrix is a corner case in which (arg mini1 C E∗ i1 ({µi,j}))/(arg mini1 C ∗ i∗({µi,j})) > 100.\nMultiSol is the preference matrix of Table 3(c) in Appendix. This matrix is an example in which the optimality condition in Theorem 4 is violated.\nNote that MLSR (Condorcet) and Sushi each have a Condorcet winner, whereas the others do not. The results with smaller preference matrices are shown in Appendix B.\nAlgorithms: We compared the following algorithms: Random is a uniformly random sampling among pairs. Copeland SAVAGE with δ = 1/T is the algorithm that is general enough to solve the Copeland dueling bandit problems and have O(K2 log T ) regret bounds. We did not include PBR and RankEI because the two algorithms are reported to be consistently outperformed by other algorithms (Zoghi et al., 2015a). RUCB (Zoghi et al., 2014) with α = 0.51 and RMED1 (Komiyama et al., 2015a) are algorithms for solving Condorcet dueling bandit problems. These algorithms are not designed to find all instances of Copeland dueling bandit problems. The values of the hyperparameters of RMED1 are the same as in Komiyama et al. (2015a). CCB (Zoghi et al., 2015a) with α = 0.51 and our ECW-RMED with α = 3.0 and β = 0.01 are algorithms designed for the Copeland dueling bandit problems.\nResults: Figure 1 plots the regrets of the algorithms. SAVAGE did not perform well for in any of the experiments. RMED1 performed best in MSLR (Condorcet). However, in datasets such as MSLR (non-Condorcet) and MultiSol where the Condorcet winner does not exist, it suffered a large regret. RUCB did not perform better than RMED1 and showed a similar tendency. These observations support the hypothesis that these algorithms are not capable of finding a Copeland winner. CCB performed similarly to RUCB in many datasets and outperformed RUCB for the datasets without a Condorcet winner. ECW-RMED significantly outperformed CCB and in all datasets, including Gap in which the uniqueness assumption of Theorem 4 is violated. In particular, in MSLR non-Condorcet dataset with K = 16, the regret of ECW-RMED was more than three times smaller than that of CCB. The slope of ECWRMED in many of the datasets is close to ECWB when T is large, which is consistent with our analysis."
    }, {
      "heading" : "6. Conclusion",
      "text" : "We studied the stochastic dueling bandit problem. The hardness of the problem of recommending Copeland winners was uncovered by deriving a lower bound of the regret. CW-RMED, an asymptotically optimal algorithm, was proposed. Moreover, ECW-RMED, a close-to-optimal algorithm, was proposed and an efficient computation method of it is given. ECW-RMED significantly outperformed the state-of-the-art algorithms in an experiment."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported in part by JSPS KAKENHI Grant Number 15J09850 and 16H00881."
    }, {
      "heading" : "A. Preference Matrices in the Experiment",
      "text" : "The following table shows the preference matrices that are used in the numerical experiment in Section 5."
    }, {
      "heading" : "B. Additional Experiment",
      "text" : "We conducted additional simulations with the following datasets.\nArXiv is a preference matrix based on the six retrieval functions in the full-text search engine of ArXiv.org (Yue & Joachims, 2011) shown in Table 3(d), where an order among arms exists. Although the fact µ4,6 = 1/2 violates our assumption, the Copeland winner is arguably arm 1.\nCyclic is the preference matrix of Table 2.\nMSLR Fixed are the two matrices of size 5× 5 provided by Zoghi et al. (2015a) shown in Table 3(e) and 3(f). One matrix has a Condorcet winner, whereas the other does not. We include these matrices to compare our results with their ones.\nThe results of the simulations are shown in Figure 2."
    }, {
      "heading" : "C. Comparison of Regret Bounds",
      "text" : "In this section, we clarify differences among the regret bounds of CW-RMED, ECW-RMED and CCB by calculating them in the cyclic preference matrix (Table 2). In the cyclic preference matrix, we have C = 1, L1 = 0, and\n∆ = min(i,j)∈Pi6=j |µi,j − 1/2| = 0.1. Table 4 shows the regret bounds of the three algorithms. These bounds are calculated as follows. First, the regret bound of CW-RMED (inequality (2)) states that the risk of arm 1 being a non-Copeland winner is smaller than log T : It requires N1,2(T ), N1,3(T ), N1,4(T ) ≥ (log T )/(2dKL(0.6, 0.5)) and N2,3(T ), N3,4(T ), N4,2(T ) ≥ (log T )/(2dKL(0.9, 0.5)). Second, the regret bound of ECW-RMED (inequality (5)) requires that (i) the arm 1 beats all other arms in I1 and (ii) the other arms loses at least L1 times: It requires N1,2(T ), N1,3(T ), N1,4(T ) ≥ (log T )/dKL(0.6, 0.5). Finally, the regret bound of CCB ((R(T )/ log T ) = 2K(C+L1+1)∆2 = 1600) is much larger because it corresponds to the exploration for checking that (i) arm 1 wins against all other arms (CK pairs) and (ii) the other arms loses at least L1 + 1 times ((L1 + 1)K pairs). Moreover, (iii) it may compare all pairs that are required to confirm (i)–(ii) for 2 log T/∆2 times."
    }, {
      "heading" : "D. Facts",
      "text" : "The following facts are frequently used in this paper. Fact 7 is a concentration inequality that bounds the tail probability on the empirical means. Fact 8 is used to bound the KL divergence from below. Fact 9 is later used in the proof of Lemma\n11.\nFact 7. (The Chernoff bound) Let X1, . . . , Xn be i.i.d. binary random variables. Let X̂ = 1n ∑n i=1Xi and µ = E[X̂]. Then, for any > 0,\nP(X̂ ≥ µ+ ) ≤ exp (−dKL(µ+ , µ)n)\nand P(X̂ ≤ µ− ) ≤ exp (−dKL(µ− , µ)n).\nFact 8. (The Pinsker’s inequality) For p, q ∈ (0, 1), the KL divergence between two Bernoulli distributions is bounded as:\ndKL(p, q) ≥ 2(p− q)2.\nFact 9. (Lemma 13 of Honda & Takemura 2010) For any µ and µ2 satisfying 0 < µ2 < µ < 1. Let C1(µ, µ2) = (µ− µ2)2/(2µ(1− µ2)). Then, for any µ3 ≤ µ2,\ndKL(µ3, µ)− dKL(µ3, µ2) ≥ C1(µ, µ2) > 0."
    }, {
      "heading" : "E. Proofs on the Regret Lower Bound",
      "text" : "In this section, we prove Lemma 1 and Theorem 2. In proofs, we frequently denote A,B instead of A ∩ B for two events A and B.\nProof of Lemma 1. Let δ > 0 be arbitrary. For i1 ∈ [C], i2 6= i1, l ∈ {max{0, L1 − 1}, . . . , L2}, I ∈ I l+1−Li1 i1 , S ∈ S\\i1,max{0,Li2−l−1{i1∈I}}i2 , let\neSumi1,i2,l,I,S(T ) := ∑\n(i,j)∈PIS\ndKL(µi,j , 1/2)Ni,j(T )\nand\nEi1,i2,l,I,S(T ) := {eSumi1,i2,l,I,S(T ) ≤ (1− δ) log T} A(T ) := ∩i1 ∪i2 ∪l ∪I ∪S Ei1,i2,l,I,S(T ).\nIn the following we prove lim T→∞ P[A(T )] = 0,\nwhich implies Lemma 1. Let N sumi (T ) := ∑ j∈[K] Ni,j(T )\nand\nBi(T ) := { N sumi (T ) = max\ni′∈[K] N sumi′ (T )\n} .\nNote that ∪i∈[K]Bi(T ) always occurs. Since Bi1(T ) implies N sumi1 (T ) ≥ T/K = Ω(T ), consistency requires P[Bi(T )] = o(1) for each i /∈ [C] and thus\nP[∪i∈[C]Bi(T )] = 1− o(1). (13)\nLet 1 > 0 be sufficiently small. Consider a modified preference matrix M ′i1,i2,l,I,S := {µ′i,j} = {µ′i,j(i1, i2, l, I, S)} such that, for each pair (i, j) in PIS , if µi,j > 1/2 then µ′i,j < 1/2 otherwise (i.e., if µi,j < 1/2) µ′i,j > 1/2 such that\ndKL(µi,j , µ ′ i,j) = dKL(µi,j , 1/2)(1 + 1). (14)\nSuch a µ′i,j for each pair (i, j) uniquely exists for sufficiently small 1. For each pair (i, j) that are not involved in PIS , we set µ′i,j = µi,j . Let E′ = E′i1,i2,l,I,S , P′ = P′i1,i2,l,I,S be the expectation and probability of the algorithm with respect to the modified preference matrix M ′i1,i2,l,I,S . Let L ′ i = {j ∈ [K] : j 6= i, µ′i,j < 1/2} be the number of arms that beat i in the modified game. In the modified game, arm i1 is not a Copeland winner because L′i1 = l + 1 and L ′ i2\n= l. Let X̂mi,j ∈ {0, 1} be the result of m-th draw of the pair (i, j),\nK̂Li,j(ni,j) = ni,j∑ m=1 log ( X̂mi,jµi,j + (1− X̂mi,j)(1− µi,j) X̂mi,jµ ′ i,j + (1− X̂mi,j)(1− µ′i,j) ) ,\nand K̂L({ni,j}(i,j)∈PIS ) = ∑ (i,j)∈PIS K̂Li,j(ni,j). Let 2 > 0 and\nDi1,i2,l,I,S(T ) := { K̂L({ni,j}(i,j)∈PIS ) < (1− 2) log T } .\nFor any i1, i2, l, I, S,\nP[Ei1,i2,l,I,S(T ) ∩ Dci1,i2,l,I,S(T )]\n≤ P[eSumi1,i2,l,I,S(T ) ≤ (1− δ) log T, K̂L({ni,j}) > (1− 2) log T ] = P[ ∑\n(i,j)∈PIS\ndKL(µi,j , µ ′ i,j)Ni,j(T ) ≤ (1− δ)(1 + 1) log T, K̂L({ni,j}) > (1− 2) log T ]\n≤ P [ max\n{ni,j}(i,j)∈PIS∈N |PIS |, ∑ (i,j)∈PIS dKL(µi,j ,µ′i,j)ni,j≤(1−δ)(1+ 1) log T K̂L({ni,j}) > (1− 2) log T\n] .\nNote that, max\n1≤n≤N K̂Li,j(n)\nis the maximum sum of positive-mean random variables, and thus converges to its average. Namely,\nlim N→∞ max 1≤n≤N\nK̂Li,j(n)/N = dKL(µi,j , µ ′ i,j) a.s.\nand thus\nlim sup T→∞\nmax{ni,j}(i,j)∈PIS∈N |PIS |, ∑ (i,j)∈PIS dKL(µi,j ,µ′i,j)ni,j≤(1−δ)(1+ 1) log T K̂L({ni,j})\nlog T\n≤ (1− δ)(1 + 1) a.s.\nTake 1 = 1(δ) and 2 = 2(δ) such that (1− δ)(1 + 1) < (1− 2), and as a result\nlim T→∞\nP [ max\n{ni,j}(i,j)∈PIS∈N |PIS |, ∑ (i,j)∈PIS dKL(µi,j ,µ′i,j)ni,j≤(1−δ)(1+ 1) log T K̂L({ni,j}) > (1− 2) log T\n] = 0,\nwhich leads to P[Ei1,i2,l,I,S(T ) ∩ Dci1,i2,l,I,S(T )] = o(1) (15)\nas a function of T .\nNote that the consistency requires P′i1,i2,l,I,S{Bi1(T )} = o(T a−1)\nfor any a > 0. Take a < 2. For any i1, i2, l, I, S,\nP[Bi1(T ) ∩ Di1,i2,l,I,S(T )] = ∑\nT= ∑K i=1 ∑K j<i ni,j\n∫ {Ni,j(T )=ni,j} 1{Bi1(T ) ∩ Di1,i2,l,I,S(T )}eK̂L({ni,j}(i,j)∈PIS )dP′i1,i2,l,I,S\n≤ T 1− 2P′i1,i2,l,I,S [Bi1(T )] ≤ o(T a− 2) = o(1). (16)\nWe finally obtain\nP[A(T )] = P [ ∩i1∈[C] ∪i2 ∪l ∪I ∪S Ei1,i2,l,I,S(T ) ] ≤ P [ ∩i1∈[C] ∪i2 ∪l ∪I ∪S {Ei1,i2,l,I,S(T ) ∩ D c i1,i2,l,I,S(T )}\n] + P [ ∩i1∈[C] ∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T )\n] = o(1) + P [ ∩i1∈[C] ∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T ) ] (by union bound of (15) over i1, i2, l, I, S).\nRemember that ∪i∈[C]Bi(T ) occurs with probability 1− o(1) (inequality (13)). By using{ ∩i1∈[C] ∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T ) } ∩ ⋃ i∈[C] Bi(T )\n⊂ ∪i1∈[C] {Bi(T ) ∩ (∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T ))} ,\nwe have\nP [ ∩i1∈[C] ∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T ) ] = P [ ∪i1∈[C] {Bi(T ) ∩ (∪i2 ∪l ∪I ∪S Di1,i2,l,I,S(T ))} ] + o(1) (by (13))\n= o(1) (by union bound of (16) over i1, i2, l, I, S).\nIn summary, P[A(T )] = o(1) and thus the proof is completed.\nProof of Theorem 2. Assume that there exists δ > 0 and a sequence T1 < T2 < T3 < · · · such that for all s\nE[R(Ts)] < (1− δ) min i1∈[C] C∗i1({µi,j}) log Ts ,\nthat is, there exists PIS(s) such that\n∑ (i,j)∈PIS(s) E[Ni,j(Ts)] (1− δ) log Ts ri,j < min i1∈[C] C∗i1({µi,j}) .\nLet i∗ ∈ [C] be arbitrary and S be the closure of the space of preference matrices in which i1 is not the Copeland winner, that is, S = cl({{νi,j}i>j : i1 /∈ Ĉcop({νi,j})}). From the definition of C∗i1 , there exists {νi,j(s)} ∈ S such that∑\n(i,j)∈PIS(s)\nE[Ni,j(Ts)] (1− δ) log Ts dKL(µi,j , νi,j(s)) < 1 .\nSince S is compact, there exists a subsequence s0 < s1 < · · · such that limu→∞{νi,j(su)} = {ν′i,j} for some {ν′i,j} ∈ S. Therefore from the lower semicontinuity of the divergence we obtain\n1 ≥ lim inf u→∞ ∑ (i,j)∈PIS(su) E[Ni,j(Tsu)] (1− δ) log Tsu dKL(µi,j , νi,j(su))\n≥ lim inf u→∞ ∑ (i,j)∈PIS(su) E[Ni,j(Tsu)] (1− δ) log Tsu dKL(µi,j , ν ′ i,j) ,\nwhich contradicts Lemma 1."
    }, {
      "heading" : "F. Proof on an Efficient Computation of ECW-RMED",
      "text" : "Proof of Theorem 5. First, we show that there exists a optimal solution of (6) such that\ne′σ1 ≥ e ′ σ2 ≥ · · · ≥ e ′ σ|S|\n(17)\nfor the following reason; let {e′′j } be an arbitrary optimal solution. If there exists a pair i < j such that e′′σi > e ′′ σj , swapping the values of e′′σi for e ′′ σj does not increase the objective value since cσi ≤ cσj , and recursively applying this swap operation yields another optimal solution {e′j} such that (17) holds. The constraint in (6) for {e′j} satisfying (17) is equivalent to∑ o∈k+1,...,|S| e′σo ≥ 1. (18) Let the number of gaps be D := ∑|S|−1 i=1 1{e′σi > e ′ σi+1 , e ′ σi+1 > 0}. In the following, we show that if D > 0 there exists another optimal solution with a smaller value ofD. LetD > 0 and i < |S| be the smallest index such that e′σi > e ′ σi+1 > 0. (i) if i ≤ k, replacing e′σ1 , . . . , e ′ σi with e ′ σi+1 does not increase the objective since each cσi is non-negative. This operation yields another optimal solution that satisfies (17) and (18) with a smaller value of D, which is illustrated in Figure 3(a). (ii) If i > k and D ≥ 2, let S = ∑|S| j=i+1 e ′ σj . Then,\ne′′σj =  e′σi (if (j − i)e ′ σi ≥ S) e′σi(j − i)− S (if (j − i+ 1)e ′ σi ≥ S > (j − i)e ′ σi )\n0 (otherwise)\nhas equal or smaller value of the objective since cσj is non-decreasing in j. Therefore, {e′′j } is an optimal solution withD ≤ 1 such that (17) and (18) hold, which is illustrated in Figure 3(b). (iii) If i > k and D = 1, then ∑i j=1 cσj = (i− k)cσi+1 always hold. Otherwise, for sufficiently small δ > 0 either of (iii-a) increasing e′σ1 , . . . , e ′ σi by δ and decreasing σi+1 by (i − k)δ or (iii-b) decreasing e′σ1 , . . . , e ′ σi by δ and increasing σi+1 by (i − k)δ must decrease the objective, which\ncontradicts the assumption that {e′j} is optimal. Therefore, ∑i j=1 cσj = (i− k)cσi+1 . Then,\ne′′σj =\n{ e′σi + e ′ σi+1/(i− k) (if j ≤ i)\n0 (otherwise)\nhas the same value of the objective function, and it satisfies (17) and (18). Therefore, {e′′j } is an optimal solution with D = 0, which is illustrated in Figure 3(c). In summary, if D > 0, one can apply one of the operations (i)–(iii) that yields a modified optimal solution with a smaller value of D. Applying these operations yields the desired solution {e∗j} with D = 0, which is illustrated in Figure 3(d)."
    }, {
      "heading" : "G. Proof of Theorem 6",
      "text" : "Proof of Theorem 6. First, one can check that (5) for each i2 6= i1 is equivalent to the constraints of (2) for l = L1 − 1. Second, Equation (4) implies that the constraints of (2) for all i2 6= i1, l ≥ L1. Combining these two facts, we conclude that {qi,j} ∈ REi1({µi,j}) implies {qi,j} ∈ Ri1({µi,j}), and thus (8) is proven.\nMoreover, to derive (9), it suffices to show Ri1({µi,j}) = REi1({µi,j}) for any preference matrix {µi,j} in which two or more Copeland winners exists. In that case, L1 = L2, and l in (2) runs for {L1 − 1, L1}. One can check that (4) is equivalent to the constraints of (2) for l = L1. Since (5) for each i2 6= i1 is equivalent to the constraints of (2) for l = L1 − 1, the constraints ofRi1({µi,j}) andREi1({µi,j}) are equivalent."
    }, {
      "heading" : "H. Proofs of Theorems 3 and 4",
      "text" : "In this section, we provide full proofs of Theorems 3 and 4. We define the following events that are important in bounding regret. Let\nXi,j(t) := { {Ni,j(t) < α √ log t} ∪ {|µ̂i,j(t)− 1/2| < β/ log log t} } and X ′i,j(t) be the event that Xi,j(t) and pair (i, j) is drawn. Let Yi,j(t) be the event that pair (i, j) is added into LN . Note that ∩(i′,j′)∈Pi6=jX ci′,j′(t) implies the algorithm reaches Line 5 in Algorithm 1, and Yi,j(t) implies ∩(i′,j′)∈Pi6=jX ci′,j′(t). Moreover, let\nZδ(t) = ∩(i,j)∈Pi6=j{|µ̂i,j(t)− µi,j | < δ}.\nIn the following, we first show some lemmas, and then bounds the regret. The proofs of the lemmas are in the following sections of this appendix.\nLemma 10. (Case that arms are immediately drawn) For CW/ECW-RMED, the following inequality holds:\nT∑ t=1 P[X ′i,j(t)] ≤ o(log T ).\nLemma 11. (Case that Copeland winner is not properly estimated) For CW/ECW-RMED, for any i2 ∈ [K] \\ [C] the following inequality holds:\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t), î∗(t) = i2  = O(1). (19) Lemma 12. (The continuity of the optimal solution) Let the algorithm be CW-RMED. For (i, j) ∈ Pi 6=j , let R∗i,j be the ij-th component of the unique element of R∗i∗({µi,j}) such that i∗ = arg mini1∈[C] C ∗ i1\n({µi,j}). There exists (δ) such that → 0 as δ → +0, and for any (i, j) ∈ Pi 6=j ,\nT∑ t=1 1[Yi,j(t),Zδ(t)] ≤ (1 + (δ))R∗i,j log T + 1.\nLet the algorithm be ECW-RMED. We can define RE∗i,j in the same way and\nT∑ t=1 1[Yi,j(t),Zδ(t)] ≤ (1 + (δ))RE∗i,j log T + 1.\nLemma 13. (The regret when the solution quality is low) For CW/ECW-RMED, the following inequality holds:\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t),Yi,j(t),Zcδ (t)  = o(log T ). Note that the regret per round satisfies ri,j ≤ 1. For each pair (i, j) to be drawn, it either (i) satisfies Xi,j(t) (only for pair i 6= j), (ii) was put into LN in the previous loop, or (iii) is in the first loop of LC (only for pair i 6= j). By using this, the regret is bounded as R(T ) = ∑\n(i,j)∈Pall\nri,j T∑ t=1 1[p(t) = (i, j)]\n≤ ∑\n(i,j)∈Pi6=j\nT∑ t=1 1[X ′i,j(t)] + ∑\n(i,j)∈Pall\nri,j T∑ t=1 1[∩(i′,j′)∈Pi6=jX c i′,j′(t),Yi,j(t)] + ∑ (i,j)∈Pi6=j 1\n≤ ∑\n(i,j)∈Pi6=j\nT∑ t=1 1[X ′i,j(t)] + ∑ (i,i):i∈[K]\\[C] T∑ t=1 1[∩(i′,j′)∈Pi6=jX c i′,j′(t),Yi,i(t)] + ∑ (i,j)∈Pi6=j ri,j T∑ t=1 1[Yi,j(t),Zδ(t)]\n+ ∑\n(i,j)∈Pi6=j\nT∑ t=1 (1[∩(i′,j′)∈Pi6=jX c i′,j′(t),Yi,j(t),Zcδ (t)]) +K2 (20)\nIn the following, we bound each term in (20) in expectation. First,∑ (i,j)∈Pi6=j T∑ t=1 P[X ′i,j(t)] = o(log T ) (21)\nfollows from Lemma 10. Second,∑ (i,i):i∈[K]\\[C] T∑ t=1 P[∩(i′,j′)∈Pi6=jX c i′,j′(t),Yi,i(t)]\n≤ ∑\n(i,i):i∈[K]\\[C] T∑ t=1 P[∩(i′,j′)∈Pi6=jX c i′,j′(t), î ∗(t) = i] (by the fact that Yi,i(t) implies î∗(t) = i)\n= O(1) (by the union bound of Lemma 11 over [K] \\ [C]). (22)\nThird, let the algorithm be CW-RMED. From Lemma 12,∑ (i,j)∈Pi6=j ri,j T∑ t=1 1[Yi,j(t),Zδ(t)] ≤ (1 + (δ)) ∑ (i,j)∈Pi6=j ri,j ( R∗i,j log T + 1 ) ≤ (1 + (δ))(min\ni1 C∗i1({µi,j}) log T +K 2 (23)\nThe same arguments yields the following bound for ECW-RMED:∑ (i,j)∈Pi6=j ri,j T∑ t=1 1[Yi,j(t),Zδ(t)] ≤ (1 + (δ))(min i1 CE∗i1 ({µi,j}) log T +K 2.\nFinally, ∑ (i,j)∈Pi6=j T∑ t=1 P  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t),Yi,j(t),Zcδ (t)  = o(log T ) (24) follows from Lemma 13.\nCombining (20), (21), (22), (23), (24) completes the proof."
    }, {
      "heading" : "I. Proof of Lemma 10",
      "text" : "Proof of Lemma 10. We have,\nT∑ t=1 P[X ′i,j(t)] = T∑ n=1 P [ T⋃ t=n { Ni,j(t) < α √ log t ∪ |µ̂i,j(t)− 1/2| < β/ log log t,Ni,j(t) = n }]\n≤ α √ log T + T∑ n=1 P [ T⋃ t=n { |µ̂i,j(t)− 1/2| < β/ log log t,Ni,j(t) ≥ α √ log T ,Ni,j(t) = n }] . (25)\nLet F (T ) = log log (α √ log T ). By using\n|µ̂i,j(t)− 1/2| ≥ |µi,j − 1/2| − |µ̂i,j(t)− µi,j |\nwe have\nT∑ n=1 P [ T⋃ t=n { |µ̂i,j(t)− 1/2| < β/ log log t,Ni,j(t) ≥ α √ log T ,Ni,j(t) = n }]\n≤ T∑ n=1 P[|µ̂ni,j − µi,j | > β/F (T )] + T∑ n=1 P[|µi,j − 1/2| < (2β)/(log log n)]\n≤ T∑ n=1 P[|µ̂ni,j − µi,j | > β/F (T )] + ee 2β/|µi,j−1/2|\n≤ 2 ∞∑ n=1 e−2n(β/F (T )) 2 + ee β/(2|µi,j−1/2|) (by Chernoff bound and Pinsker’s inequality)\n≤ O\n( F (T ) 2\nβ2\n) + ee β/(2|µi,j−1/2|) = o(log T ). (26)\nCombining (25) and (26) completes the proof."
    }, {
      "heading" : "J. Proof of Lemma 11",
      "text" : "Proof of Lemma 11. Note that we can assume µ̂i,j(t) 6= 1/2 from X ci,j(t). Let i1 ∈ [C] be arbitrary. Event {̂i∗(t) = i2} implies that, there exists a set of pairs PIS such that l ∈ {max{0, L1 − 1}, . . . , Li2}, I ∈ I l+1−L1 i1 , S ∈ S\\i1,max{0,Li2−l−1{i1∈I}}i2 and PIS = {(i1, j) : j ∈ I} ∪ {(i2, j) : j ∈ S} and the signs of µ̂i,j(t) − 1/2 and µi,j − 1/2 are different. In other words,\n{̂i∗(t) = i2} ⊂ {̂i∗(t) = i2} ∩ { ∪l ∪I ∪S ∩(i,j)∈PIS {(µ̂i,j(t)− 1/2)(µi,j − 1/2) < 0} } .\nIn the following we are going to show\nT∑ t=1 P [ ∩(i′,j′)∈Pi6=jX c i′,j′(t), î ∗(t) = i2,∩(i,j)∈PIS{(µ̂i,j(t)− 1/2)(µi,j − 1/2) < 0} ] = O(1) (27)\nfor each l, I, S. Note thatlog t ≥ ∑ (i,j)∈PIS Ni,j(t)dKL(µ̂i,j(t), 1/2),∩(i′,j′)∈Pi6=jX c i′,j′(t), î ∗(t) = i2  implies that {Ni,j(t)/ log t} /∈ Ri2({µ̂i,j(t)}) and at least one of the pairs in PIS is immediately put into LNC to satisfy the constraints. Therefore, one of the arms in PIS is drawn within K2 rounds of {t : ∩(i′,j′)∈Pi6=jX ci′,j′(t)}. By using this\nfact, we have∑ t 1 [ ∩(i′,j′)∈Pi6=jX c i′,j′(t), î ∗(t) = i2,∩(i,j)∈PIS{(µi,j − 1/2)(µ̂i,j(t)− 1/2) < 0, Ni,j(t) = ni,j} ]\n≤ exp  ∑ (i,j)∈PIS ni,jdKL(µ̂i,j(t), 1/2) +K2. Let µ̂ni,j be the empirical estimate of µi,j with n draws. Letting Pi,j(xi,j) = P[(µi,j − 1/2)(µ̂ ni,j i,j − 1/2) ≤ 0, dKL(µ̂ ni,j i,j , 1/2) ≥ xi,j ], we have\nE ∑ t 1  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t), î∗(t) = i2, ⋂ (i,j)∈PIS {(µi,j − 1/2)(µ̂ ni,j i,j − 1/2) < 0, Ni,j(t) = ni,j}  ≤ ∫ {xi,j}∈[0,log 2]|PIS | exp  ∑\n(i,j)∈PIS\nni,jxi,j\n+K2  ∏\n(i,j)∈PIS\nd(−Pi,j(xi,j))\n= K2 ∏\n(i,j)∈PIS\nPi,j(0) + ∏\n(i,j)∈PIS\n∫ xi,j∈[0,log 2] eni,jxi,jd(−Pi,j(xi,j))\n= K2 ∏\n(i,j)∈PIS\nPi,j(0) + ∏\n(i,j)∈PIS\n( [−eni,jxi,jPi,j(xi,j)]log 20 + ∫ xi,j∈[0,log 2] ni,je ni,jxi,jPi,j(xi,j)dxi,j ) (integration by parts)\n≤ (1 +K2) ∏\n(i,j)∈PIS\nPi,j(0) + ∏\n(i,j)∈PIS\n∫ xi,j∈[0,log 2] ni,je ni,jxi,je−ni,j(xi,j+C1(µi,j ,1/2))dxi,j\n(by Chernoff bound and Fact 9, where C1(µ, µ2) = (µ− µ2)2/(2µ(1− µ2))) ≤ (1 +K2) ∏\n(i,j)∈PIS\ne−ni,jdKL(1/2,µi,j) + ∏\n(i,j)∈PIS\n∫ xi,j∈[0,log 2] ni,je −ni,jC1(µi,j ,1/2)dxi,j\n= (1 +K2) ∏\n(i,j)∈PIS\ne−ni,jdKL(1/2,µi,j) + ∏\n(i,j)∈PIS\n(log 2)ni,je −ni,jC1(µi,j ,1/2). (28)\nBy summing (28) over {ni,j},\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t), ⋂ (i,j)∈PIS {(µi,j − 1/2)(µ̂ ni,j i,j − 1/2) < 0}  ≤ ∑ · · ·\n∑ {ni,j}∈N|PIS | (1 +K2) ∏ (i,j)∈PIS e−ni,jdKL(1/2,µi,j) + ∏ (i,j)∈PIS (log 2)ni,je −ni,jC1(µi,j ,1/2)  ≤ (1 +K2)\n∏ (i,j)∈PIS\n1\nedKL(1/2,µi,j) − 1 + (log 2)|PIS | ∏ (i,j)∈PIS\neC1(µi,j ,1/2)\n(eC1(µi,j ,1/2) − 1)2 ,\n= O(1) where we used the fact that ∑∞ n=1 e −nx = 1/(ex + 1) and ∑∞ n=1 ne\n−nx = ex/(ex + 1)2. In summary, we showed (27). Taking a union bound over l, I, S yields (19)."
    }, {
      "heading" : "K. Proof of Lemma 12",
      "text" : "Following Hogan (1973), we define the continuity of a point-to-set map Ω : X → 2Y between metric spaces X and Y as follows: (i) Ω is open at x0 ∈ X if {xk}, xk → x0, and y0 ∈ Ω(x0) imply the existence of an integer m and a sequence\n{yk} such that yk ∈ Ω(xk) for k ≥ m and yk → y0. (ii) Ω is closed at x0 if {xk} ∈ X , xk → x0, yk → y0 imply that y0 ∈ Ω(x0). Moreover, (iii) Ω is continuous at x0 if it is closed and open at x0.\nLet a set of relaxed feasible solutions be\nR+1i1 ({νi,j}) := { {qi,j}i>j ∈ [0, 1/dKL(νi,j , 1/2)+1]K(K−1)/2 : ∀i2 6=i1 ∀l ∈ {max{0, L̂(1) − 1}, . . . , L̂(2)}\n∀I ∈ Î(l+1−L̂ (1)) i1 ∀S ∈ Ŝ\\i1,max{0,L̂i2−l−1{i2∈I}}i2 ∑ (i,j)∈PIS qi,jdKL(νi,j , 1/2) ≥ 1\n} .\nNote that the red term is the difference from Ri1(·). This set of relaxed feasible solutions is introduced for the sake of inequality (29) that appears later. The optimal coefficient C+1,∗i1 ({νi,j}) and the set of the optimal solutionsR +1,∗ i1\n({νi,j}) are defined in accordance withR+1i1 ({νi,j}), that is,\nC+1,∗i1 ({νi,j}) := inf{qi,j}i>j∈R+1i1 ({νi,j}) ∑ (i,j)∈Pi6=j r̂i,jqi,j ,\nand\nR+1,∗i1 ({νi,j}) := { {qi,j}i>j ∈ R+1i1 ({νi,j}) : ∑ (i,j)∈Pi6=j r̂i,jqi,j = C +1,∗ i1 ({νi,j}) } .\nLet the norms on {νi,j} and {qi,j} be |{νi,j}| = ∑ i,j |νi,j | and |{qi,j}| = ∑ i,j |qi,j |, respectively. In the following, we show the following lemma:\nLemma 14. (The continuity of the solution function) The point-to-set map R+1,∗i1 ({νi,j}) : MCop → 2 [0,∞)K(K−1) is continuous at {νi,j} = {µi,j}.\nThe continuity and the uniqueness of the optimal solution function R+1,∗i1 ({µi,j}) implies that all solutions of R+1,∗i1 ({νi,j}) approach R +1,∗ i1\n({µi,j}) (= R∗i1({µi,j}), unique) when {νi,j} is sufficiently close to {µi,j}. To prove Lemma 14, we first restate the following three Lemmas of Hogan (1973):\nLemma 15. (Theorem 10 of Hogan 1973) Let g be a set of real-valued functions on X × Y , and P (x) := {y ∈ Y : g(x, y) ≤ 0} be a map of feasible solutions. If each component of g is continuous on x0 × Y , then P is closed at x0. Lemma 16. (Theorem 12 of Hogan 1973) If Y is convex and normed, if each component of g is continuous on x0×P (x0) and convex in y for each fixed x ∈ X , and if there exists a y0 such that g(x0, y0) < 0, then P is open at x0. Lemma 17. (Corollary 8.1 of Hogan 1973) Let Ω : X → 2Y be a point-to-set map and M(x) := {y ∈ Ω(x) : supy′∈Ω(x) f(x, y\n′) = f(x, y)} be an optimal solution function of some real-valued function f on X × Y . Suppose Ω is continuous at x0, f is continuous on x0 × Ω(x0), M is non-empty and uniformly compact near x0, and M(x0) is unique. Then, M is continuous at x0.\nProof of Lemma 14. We first show the continuity of the feasible solution function R+1i ({νi,j}) at {νi,j} = {µi,j}. The continuity of each component of g as a function of {νi,j}, {qi,j} follows from the continuity of the KL divergence, and thus, applying Lemma 15 for P = R+1i1 , x0 = {µi,j} and g({νi,j}, {qi,j}) = {1− ∑ (i,j)∈PIS qi,jdKL(νi,j , 1/2)}i2,l,I,S yields the closedness ofR+1i1 at {µi,j}. Moreover, by (i) continuity of each component of g, (ii) linearity of each component of g as a function of {qi,j} for each {νi,j}, and (iii) the fact that {q′i,j} := {(1/dKL(νi,j , 1/2)) + 1}K(K−1) satisfies∑\n(i,j)∈PIS\nq′i,jdKL(νi,j , 1/2) > 1, (29)\napplying Lemma 16 to the same P, x0, g and y0 = {(1/dKL(νi,j , 1/2)) + 1} yields the openness of R+1i1 at {µi,j}. The continuity ofR+1i1 follows from its closedness and the openness.\nFinally, by using the continuity ofR+1i1 and C +1,∗ i , and uniform compactness and uniqueness ofR +1,∗ i1\nat {µi,j}, applying Lemma 17 to M = R+1,∗i1 , Ω = R +1 i1 , and f = C∗i1 yields the continuity ofR +1,∗ i1 at {µi,j}.\nProof of Lemma 12. By using the continuity ofR+1,∗i1 ({νi,j}) (Lemma 14),R ∗ i1 ({νi,j}) ⊂ R+1,∗i1 ({νi,j}), and the uniqueness of arg mini1∈[C] C ∗ i1 ({µi,j}) andR∗i1({µi,j}), there exists (δ) such that → 0 as δ → +0 and\nT∑ t=1 1[Yi,j(t),Zδ(t)] ≤ T∑ n=1 1 [ T⋃ t=1 {Yi,j(t),Zδ(t), Ni,j(t) = n} ]\n≤ T∑ n=1 1 [ T⋃ t=1 { n/ log t ≤ (1 + (δ))R∗i,j }] ≤ (1 + (δ))R∗i,j log T + 1.\nThe same arguments also applies to ECW-RMED."
    }, {
      "heading" : "L. Proof of Lemma 13",
      "text" : "Proof of Lemma 13. We have\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j X ci′,j′(t),Yi,j(t),Zcδ (t)  ≤\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j { X ci′,j′(t), Ni′,j′(t) ≥ (log log T )1/3 } ,Yi,j(t),Zcδ (t)  +\n∑ (i′,j′)∈Pi6=j T∑ t=1 P[Ni′,j′(t) ≤ (log log T )1/3, Ni′,j′(t) ≥ α √ log t]. (30)\nHere, ∑ (i′,j′)∈Pi6=j T∑ t=1 P[Ni′,j′(t) ≤ (log log T )1/3, Ni′,j′(t) ≥ α √ log t] ≤ K2eα −2(log log T )2/3 = o(log T ). (31)\nMoreover,\nT∑ t=1 P  ⋂ (i′,j′)∈Pi6=j { X ci′,j′(t), Ni′,j′(t) ≥ (log log T )1/3 } ,Yi,j(t),Zcδ (t)  ≤\nT∑ n=1 P  T⋃ t=n |µ̂i,j(t)− 1/2| ≥ β/ log log t,Yi,j(t),Zcδ (t), ⋂ (i′,j′)∈Pi6=j Ni′,j′(t) ≥ (log log T )1/3, Ni,j(t) = n  \n≤ log T ((log log T/β)2/2)∑\nn=1\nP  T⋃ t=1 Zcδ (t), ⋂ (i′,j′)∈Pi6=j Ni′,j′(t) ≥ (log log T )1/3, Ni,j(t) = n  \n(byRi1({νi,j}),REi1({νi,j}) ⊂ [0, 1/dKL(νi,j , 1/2)] K(K−1)/2 and Pinsker’s inequality)\n≤ e−Ω((log log T ) 1/3)O((log T )(log log T )2) = o(log T ), (32)\nwhere we used the fact that\nP  T⋃ t=1 Zcδ (t), ⋂ (i′,j′)∈Pi6=j Ni′,j′(t) ≥ (log log T )1/3   ≤ ∑ (i′,j′)∈Pi6=j T∑ n=(log log T )1/3 P[|µ̂ni,j − µi,j | > δ]\n≤ ∑\n(i′,j′)∈Pi6=j T∑ n=(log log T )1/3 2e−2nδ = e−Ω((log log T ) 1/3).\nCombining (30), (31), and (32) completes the proof."
    } ],
    "references" : [ {
      "title" : "Axiomatic foundations for ranking systems",
      "author" : [ "Altman", "Alon", "Tennenholtz", "Moshe" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Altman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Altman et al\\.",
      "year" : 2008
    }, {
      "title" : "Partial monitoring - classification, regret bounds, and algorithms",
      "author" : [ "Bartók", "Gábor", "Foster", "Dean P", "Pál", "Dávid", "Rakhlin", "Alexander", "Szepesvári", "Csaba" ],
      "venue" : "Math. Oper. Res.,",
      "citeRegEx" : "Bartók et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bartók et al\\.",
      "year" : 2014
    }, {
      "title" : "A bayesian interactive optimization approach to procedural animation design",
      "author" : [ "Brochu", "Eric", "Tyson", "de Freitas", "Nando" ],
      "venue" : "In Proceedings of the 2010 Eurographics/ACM SIGGRAPH Symposium on Computer Animation,",
      "citeRegEx" : "Brochu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Brochu et al\\.",
      "year" : 2010
    }, {
      "title" : "Top-k selection based on adaptive sampling of noisy preferences",
      "author" : [ "Busa-Fekete", "Róbert", "Szörényi", "Balázs", "Cheng", "Weiwei", "Weng", "Paul", "Hüllermeier", "Eyke" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Busa.Fekete et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Busa.Fekete et al\\.",
      "year" : 2013
    }, {
      "title" : "PAC rank elicitation through adaptive sampling of stochastic pairwise preferences",
      "author" : [ "Busa-Fekete", "Róbert", "Szörényi", "Balázs", "Hüllermeier", "Eyke" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Busa.Fekete et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Busa.Fekete et al\\.",
      "year" : 2014
    }, {
      "title" : "Elements of information theory (2",
      "author" : [ "Cover", "Thomas M", "Thomas", "Joy A" ],
      "venue" : "ed.). Wiley,",
      "citeRegEx" : "Cover et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Cover et al\\.",
      "year" : 2006
    }, {
      "title" : "Contextual dueling bandits",
      "author" : [ "Dudı́k", "Miroslav", "Hofmann", "Katja", "Schapire", "Robert E", "Slivkins", "Aleksandrs", "Zoghi", "Masrour" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Dudı́k et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dudı́k et al\\.",
      "year" : 2015
    }, {
      "title" : "Utility-based dueling bandits as a partial monitoring",
      "author" : [ "Gajane", "Pratik", "Urvoy", "Tanguy" ],
      "venue" : "game. CoRR,",
      "citeRegEx" : "Gajane et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gajane et al\\.",
      "year" : 2015
    }, {
      "title" : "Preference learning in recommender systems",
      "author" : [ "Gemmis", "Marco De", "Iaquinta", "Leo", "Lops", "Pasquale", "Musto", "Cataldo", "Narducci", "Fedelucio", "Semeraro", "Giovanni" ],
      "venue" : "In In Preference Learning (PL-09) ECML/PKDD-09 Workshop,",
      "citeRegEx" : "Gemmis et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gemmis et al\\.",
      "year" : 2009
    }, {
      "title" : "Fidelity, soundness, and efficiency of interleaved comparison methods",
      "author" : [ "Hofmann", "Katja", "Whiteson", "Shimon", "de Rijke", "Maarten" ],
      "venue" : "Transactions on Information Systems,",
      "citeRegEx" : "Hofmann et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Hofmann et al\\.",
      "year" : 2013
    }, {
      "title" : "Point-to-set maps in mathematical programming",
      "author" : [ "Hogan", "William W" ],
      "venue" : "SIAM Review,",
      "citeRegEx" : "Hogan and W.,? \\Q1973\\E",
      "shortCiteRegEx" : "Hogan and W.",
      "year" : 1973
    }, {
      "title" : "An Asymptotically Optimal Bandit Algorithm for Bounded Support Models",
      "author" : [ "Honda", "Junya", "Takemura", "Akimichi" ],
      "venue" : "In COLT, pp",
      "citeRegEx" : "Honda et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Honda et al\\.",
      "year" : 2010
    }, {
      "title" : "Nantonac collaborative filtering: recommendation based on order responses",
      "author" : [ "Kamishima", "Toshihiro" ],
      "venue" : "In KDD, pp",
      "citeRegEx" : "Kamishima and Toshihiro.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kamishima and Toshihiro.",
      "year" : 2003
    }, {
      "title" : "Polynomial algorithms in linear programming",
      "author" : [ "L.G. Khachiyan" ],
      "venue" : "USSR Computational Mathematics and Mathematical Physics,",
      "citeRegEx" : "Khachiyan,? \\Q1980\\E",
      "shortCiteRegEx" : "Khachiyan",
      "year" : 1980
    }, {
      "title" : "Regret lower bound and optimal algorithm in dueling bandit problem",
      "author" : [ "Komiyama", "Junpei", "Honda", "Junya", "Kashima", "Hisashi", "Nakagawa", "Hiroshi" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Komiyama et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Komiyama et al\\.",
      "year" : 2015
    }, {
      "title" : "Regret lower bound and optimal algorithm in finite stochastic partial monitoring",
      "author" : [ "Komiyama", "Junpei", "Honda", "Junya", "Nakagawa", "Hiroshi" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Komiyama et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Komiyama et al\\.",
      "year" : 2015
    }, {
      "title" : "Combinatorial Optimization: Theory and Algorithms",
      "author" : [ "Korte", "Bernhard", "Vygen", "Jens" ],
      "venue" : "4th edition,",
      "citeRegEx" : "Korte et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Korte et al\\.",
      "year" : 2007
    }, {
      "title" : "Asymptotically efficient adaptive allocation rules",
      "author" : [ "Lai", "Tze Leung", "Robbins", "Herbert" ],
      "venue" : "Advances in Applied Mathematics,",
      "citeRegEx" : "Lai et al\\.,? \\Q1985\\E",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 1985
    }, {
      "title" : "LETOR: A benchmark collection for research on learning to rank for information",
      "author" : [ "Qin", "Tao", "Liu", "Tie-Yan", "Xu", "Jun", "Li", "Hang" ],
      "venue" : "retrieval. Inf. Retr.,",
      "citeRegEx" : "Qin et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Qin et al\\.",
      "year" : 2010
    }, {
      "title" : "Generic exploration and k-armed voting bandits",
      "author" : [ "Urvoy", "Tanguy", "Clérot", "Fabrice", "Feraud", "Raphaël", "Naamane", "Sami" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Urvoy et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Urvoy et al\\.",
      "year" : 2013
    }, {
      "title" : "Efficient partial monitoring with prior information",
      "author" : [ "Vanchinathan", "Hastagiri P", "Bartók", "Gábor", "Krause", "Andreas" ],
      "venue" : "In NIPS, pp",
      "citeRegEx" : "Vanchinathan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vanchinathan et al\\.",
      "year" : 2014
    }, {
      "title" : "Beat the mean bandit",
      "author" : [ "Yue", "Yisong", "Joachims", "Thorsten" ],
      "venue" : "In ICML, pp",
      "citeRegEx" : "Yue et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2011
    }, {
      "title" : "The k-armed dueling bandits problem",
      "author" : [ "Yue", "Yisong", "Broder", "Josef", "Kleinberg", "Robert", "Joachims", "Thorsten" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Yue et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2009
    }, {
      "title" : "The k-armed dueling bandits problem",
      "author" : [ "Yue", "Yisong", "Broder", "Josef", "Kleinberg", "Robert", "Joachims", "Thorsten" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "Yue et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2012
    }, {
      "title" : "Crowdsourcing translation: Professional quality from non-professionals",
      "author" : [ "Zaidan", "Omar", "Callison-Burch", "Chris" ],
      "venue" : "Proceedings of the Conference,",
      "citeRegEx" : "Zaidan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Zaidan et al\\.",
      "year" : 2011
    }, {
      "title" : "Relative upper confidence bound for the k-armed dueling bandit problem",
      "author" : [ "Zoghi", "Masrour", "Whiteson", "Shimon", "Munos", "Rémi", "de Rijke", "Maarten" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Zoghi et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zoghi et al\\.",
      "year" : 2014
    }, {
      "title" : "Mergerucb: A method for large-scale online ranker evaluation",
      "author" : [ "Zoghi", "Masrour", "Whiteson", "Shimon", "de Rijke", "Maarten" ],
      "venue" : "In WSDM, pp",
      "citeRegEx" : "Zoghi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zoghi et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 22,
      "context" : "In this paper, we consider a version of the standard stochastic bandit problem called the K-armed dueling bandit problem (Yue et al., 2009), in which the forecaster receives relative feedback, which specifies which of the two arms is preferred.",
      "startOffset" : 121,
      "endOffset" : 139
    }, {
      "referenceID" : 8,
      "context" : "Although the original motivation of the dueling bandit problem arose in the field of information retrieval, learning under relative feedback is universal to many fields, such as recommender systems (Gemmis et al., 2009), graphical design (Brochu et al.",
      "startOffset" : 198,
      "endOffset" : 219
    }, {
      "referenceID" : 2,
      "context" : ", 2009), graphical design (Brochu et al., 2010), and natural language processing (Zaidan & Callison-Burch, 2011), which involve explicit or implicit feedback provided by humans.",
      "startOffset" : 26,
      "endOffset" : 47
    }, {
      "referenceID" : 23,
      "context" : "Related work Early algorithms for solving the dueling bandit problem, such as Interleaved Filter (Yue et al., 2012) and Beat the Mean Bandit (Yue & Joachims, 2011), require the arms to ar X iv :1 60 5.",
      "startOffset" : 97,
      "endOffset" : 115
    }, {
      "referenceID" : 25,
      "context" : "Several algorithms, such as Relative Upper Confidence Bound (RUCB) (Zoghi et al., 2014), and Relative Minimum Empirical Divergence (RMED) (Komiyama et al.",
      "startOffset" : 67,
      "endOffset" : 87
    }, {
      "referenceID" : 6,
      "context" : "Note that there are also other notions of winners, such as the von Neumann winner (Dudı́k et al., 2015) or Random walk winner (Altman & Tennenholtz, 2008) together with their corresponding dueling bandit problems.",
      "startOffset" : 82,
      "endOffset" : 103
    }, {
      "referenceID" : 1,
      "context" : "Another line of study is on the partial monitoring problem (Bartók et al., 2014).",
      "startOffset" : 59,
      "endOffset" : 80
    }, {
      "referenceID" : 20,
      "context" : "Moreover, existing algorithms for partial monitoring, such as Bayes-update Partial Monitoring (BPM) (Vanchinathan et al., 2014) or Partial Monitoring Deterministic Minimum Empirical Divergence (PMDMED) (Komiyama et al.",
      "startOffset" : 100,
      "endOffset" : 127
    }, {
      "referenceID" : 19,
      "context" : "There are some algorithms, such as Sensitivity Analysis of VAriables for Generic Exploration (SAVAGE) (Urvoy et al., 2013), Preference-based Racing (PBR) (Busa-Fekete et al.",
      "startOffset" : 102,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : ", 2013), Preference-based Racing (PBR) (Busa-Fekete et al., 2013), and Rank Elicitation (RankEI) (Busa-Fekete et al.",
      "startOffset" : 39,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : ", 2013), and Rank Elicitation (RankEI) (Busa-Fekete et al., 2014), that can deal with general classes of problems that entail solving Copeland dueling bandit problems.",
      "startOffset" : 39,
      "endOffset" : 65
    }, {
      "referenceID" : 13,
      "context" : "Urvoy et al. (2013) considered a large class of sequential learning problems that includes the dueling bandit problem and introduced the notion of Condorcet, Copeland, and Borda dueling bandit problems.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 25,
      "context" : "Note that, we can also consider other definitions of regret; the analysis in this paper is relied on the facts that regret per round ri,j is (i) finite, (ii) determined by the Copeland The constant factor of this definition is different from the one defined in Zoghi et al. (2015a). Our result can be compared with that of Zoghi et al.",
      "startOffset" : 261,
      "endOffset" : 282
    }, {
      "referenceID" : 25,
      "context" : "Note that, we can also consider other definitions of regret; the analysis in this paper is relied on the facts that regret per round ri,j is (i) finite, (ii) determined by the Copeland The constant factor of this definition is different from the one defined in Zoghi et al. (2015a). Our result can be compared with that of Zoghi et al. (2015a) simply by multiplying a constant.",
      "startOffset" : 261,
      "endOffset" : 344
    }, {
      "referenceID" : 13,
      "context" : "It is well known that even if there are exponentially many constraints an LP can be solved by using the ellipsoid method (Khachiyan, 1980) in a polynomial time if there exists a polynomial-time oracle that (i) checks whether a point {qij} is feasible or not and (ii) returns a hyperplane such that {qij} and the feasible region are separated if {qij} is infeasible.",
      "startOffset" : 121,
      "endOffset" : 138
    }, {
      "referenceID" : 25,
      "context" : "Theorem 3 in Zoghi et al. (2015a) showed that CCB has an asymptotic regret bound2 of",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 25,
      "context" : "Here, we use a ∆ that is a little bit looser than the one in the original bound of Zoghi et al. (2015a) for the sake of discussion.",
      "startOffset" : 83,
      "endOffset" : 104
    }, {
      "referenceID" : 18,
      "context" : "(2015b), which is derived from the Microsoft Learning to Rank (MSLR) dataset (Microsoft Research, 2010; Qin et al., 2010) that consists of relevance information between queries and documents with more than 30K queries.",
      "startOffset" : 77,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "The value μi,j is the probability that the ranker i beats ranker j based on the informational click model (Hofmann et al., 2013).",
      "startOffset" : 106,
      "endOffset" : 128
    }, {
      "referenceID" : 25,
      "context" : "RUCB (Zoghi et al., 2014) with α = 0.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "MSLR: We tested submatrices of a 136 × 136 preference matrix from Zoghi et al. (2015b), which is derived from the Microsoft Learning to Rank (MSLR) dataset (Microsoft Research, 2010; Qin et al.",
      "startOffset" : 66,
      "endOffset" : 87
    }, {
      "referenceID" : 15,
      "context" : "(2015b), which is derived from the Microsoft Learning to Rank (MSLR) dataset (Microsoft Research, 2010; Qin et al., 2010) that consists of relevance information between queries and documents with more than 30K queries. Zoghi et al. (2015b) created a finite set of rankers, each of which corresponds to a ranking feature in the base dataset.",
      "startOffset" : 104,
      "endOffset" : 240
    }, {
      "referenceID" : 9,
      "context" : "The value μi,j is the probability that the ranker i beats ranker j based on the informational click model (Hofmann et al., 2013). We randomly chose subsets of rankers in our experiments and made sub preference matrices. We excluded cases with extremely small gaps such that |μi,j − 1/2| < 0.005 for K = 16 or |μi,j − 1/2| < 0.0005 for K = 64. Furthermore, we selected the submatrices in which the Condorcet winner exists (Figure 1(a)) and the Condorcet winner does not exist (Figures 1(b) and 1(c)). Sushi: This dataset is based on the sushi preference dataset (Kamishima, 2003) that contains the preferences of 5, 000 Japanese users as regards to 100 types of sushi. We extracted 16 types of sushi and converted them into a preference matrix with μi,j corresponding to the ratio of users who prefer sushi i over j, which is shown in Table 3(a) in Appendix. Gap is the preference matrix of Table 3(b) in Appendix. This matrix is a corner case in which (arg mini1 C E∗ i1 ({μi,j}))/(arg mini1 C ∗ i∗({μi,j})) > 100. MultiSol is the preference matrix of Table 3(c) in Appendix. This matrix is an example in which the optimality condition in Theorem 4 is violated. Note that MLSR (Condorcet) and Sushi each have a Condorcet winner, whereas the others do not. The results with smaller preference matrices are shown in Appendix B. Algorithms: We compared the following algorithms: Random is a uniformly random sampling among pairs. Copeland SAVAGE with δ = 1/T is the algorithm that is general enough to solve the Copeland dueling bandit problems and have O(K log T ) regret bounds. We did not include PBR and RankEI because the two algorithms are reported to be consistently outperformed by other algorithms (Zoghi et al., 2015a). RUCB (Zoghi et al., 2014) with α = 0.51 and RMED1 (Komiyama et al., 2015a) are algorithms for solving Condorcet dueling bandit problems. These algorithms are not designed to find all instances of Copeland dueling bandit problems. The values of the hyperparameters of RMED1 are the same as in Komiyama et al. (2015a). CCB (Zoghi et al.",
      "startOffset" : 107,
      "endOffset" : 2043
    }, {
      "referenceID" : 25,
      "context" : "MSLR Fixed are the two matrices of size 5× 5 provided by Zoghi et al. (2015a) shown in Table 3(e) and 3(f).",
      "startOffset" : 57,
      "endOffset" : 78
    } ],
    "year" : 2016,
    "abstractText" : "We study theK-armed dueling bandit problem, a variation of the standard stochastic bandit problem where the feedback is limited to relative comparisons of a pair of arms. The hardness of recommending Copeland winners, the arms that beat the greatest number of other arms, is characterized by deriving an asymptotic regret bound. We propose Copeland Winners Relative Minimum Empirical Divergence (CW-RMED) and derive an asymptotically optimal regret bound for it. However, it is not known whether the algorithm can be efficiently computed or not. To address this issue, we devise an efficient version (ECW-RMED) and derive its asymptotic regret bound. Experimental comparisons of dueling bandit algorithms show that ECW-RMED significantly outperforms existing ones.",
    "creator" : "LaTeX with hyperref package"
  }
}