{
  "name" : "1702.04849.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Theoretical and Practical Advances on Smoothing for Extensive-Form Games",
    "authors" : [ "Christian Kroer", "Kevin Waugh" ],
    "emails" : [ "ckroer@cs.cmu.edu", "kevin.waugh@gmail.com", "fkilinc@andrew.cmu.edu", "sandholm@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice."
    }, {
      "heading" : "1 Introduction",
      "text" : "Extensive-form games (EFGs) are a broad class of games; they model sequential interaction, imperfect information, and outcome uncertainty. Nash equilibria prescribe a particular notion of rational behavior in such games. In the specific case of two-player zero-sum EFGs with perfect recall, an exact Nash equilibrium can be computed in polynomial time using a Linear Program (LP) whose\n∗Supported by a Facebook Fellowship, the NSF under grants IIS-1617590, IIS-1320620, and IIS-1546752, and the ARO under awards W911NF-16-1-0061 and W911NF-17-1-0082. †Supported by NSF grant CMMI 1454548. ‡Supported by the NSF under grants IIS-1617590, IIS-1320620, and IIS-1546752, and the ARO under awards W911NF-16-1-0061 and W911NF-17-1-0082.\nar X\niv :1\n70 2.\n04 84\n9v 2\n[ cs\n.G T\nsize is linear in the size of the game tree [von Stengel, 1996]. However, in practice the LP approach has two major drawbacks limiting its applicability. First, the LP may be prohibitively large and may not fit in memory. Second, even when it does, the iterations of interior-point methods or the simplex algorithm are prohibitively expensive [Sandholm, 2010]. Practical methods for EFG solving tackle this issue through two complementary approaches: Abstraction and iterative game solvers with low memory requirements [Sandholm, 2010]. In this paper we focus on the second approach. Iterative game solvers mainly fall in two categories: (i) counterfactual-regret-based methods [Zinkevich et al., 2007, Lanctot et al., 2009] achieving a convergence rate on the order of O( 1\n2 ), and (ii)\nfirst-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O(1 ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective.\nNash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs.\nHoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O(1 ) convergence.\nIn this paper we construct a new weighting scheme for such entropy-based DGFs. This weighting scheme leads to new and improved bounds on the strong convexity parameter associated with general treeplex domains. In particular, our new bounds are first-of-their kind as they have no dependence on the branching operation of the treeplex. Informally, our strong convexity result allows us to improve the convergence rate of FOMs by a factor of Ω(bdd) (where b is the average branching factor for a player and d is the depth of the EFG) compared to the prior state-of-the-art results from Kroer et al. [2015]. Our bounds parallel the simplex case for matrix games where the entropy function achieves a logarithmic dependence on the dimension of the simplex domain.\nFinally, we complement our theoretical results with numerical experiments to investigate the speed up of FOMs with convergence rate O(1 ) and compare the performance of these algorithms with the premier regret-based methods CFR and CFR+ [Tammelin et al., 2015]. CFR+ is the fastest prior algorithm for computing Nash equilibria in EFGs when the entire tree can be traversed (rather than sampled). Bowling et al. [2015] used it to essentially solve the game limit Texas hold’em.\nCFR+ is also the algorithm used to accurately solve endgames in the Libratus agent, which showed superhuman performance against a team of top Heads-Up No-Limit Texas hold’em poker\nspecialist professional players in the Brains vs AI event 1. A slight variation2 of CFR+ was used in the DeepStack agent Moravč́ık et al. [2017], which beat a group of professional players. Our experiments show that FOMs are substantially faster than both CFR algorithms when using a practically tuned variant of our DGF. We also test the impact of stronger bounds on the strong convexity parameter: we instantiate EGT with the parameters developed in this paper, and compare the performance to the parameters developed by Kroer et al. [2015]. These experiments illustrate that the tighter parameters developed here lead to better practical convergence rate.\nThe rest of the paper is organized as follows. Section 2 discusses related research. We present the general class of problems that we address—bilinear saddle-point problems—and describe how they relate to EFGs in Section 3. Then Section 4 describes our optimization framework. Section 5 introduces treeplexes, the class of convex polytopes that define our domains of the optimization problems. Our focus is on dilated entropy-based DGFs; we introduce these in Section 6 and present our main results—bounds on the associated strong convexity parameter and treeplex diameter. In Section 7 we demonstrate the use of our results on instantiating EGT. We compare our approach with the current state-of-art in EFG solving and discuss the extent of theoretical improvements achievable via our approach in Section 7.1. Section 8 presents numerical experiments testing the effect of various parameters on the performance of our approach as well as comparing the performance of our approach to CFR and CFR+. We close with a summary of our results and a few compelling further research directions in Section 9."
    }, {
      "heading" : "2 Related work",
      "text" : "Nash equilibrium computation has received extensive attention in the literature [Littman and Stone, 2003, Lipton et al., 2003, Gilpin and Sandholm, 2007, Zinkevich et al., 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games.\nKoller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold’em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 · 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010].\nThe most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1\n2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015]\nshowed, with some caveats, an interpretation of CFR as a FOM with O( 1 2\n) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O(1 ) FOMs for ease of exposition.\nHoda et al. [2010] initially proposed DGFs for EFGs leading to O(1 ) convergence rate when used with EGT. Kroer et al. [2015] improved these result for the dilated entropy function. Gilpin\n1Confirmed through author communication 2This variation was chosen for implementation reasons, though, and has inferior practical iteration complexity.\net al. [2012] give an algorithm with convergence rate O(ln(1 )). Their bound has a dependence on a certain condition number of the payoff matrix, which is difficult to estimate; and as a result they show a bound of O(1 ) which is independent of the condition number. Detailed comparisons to all three algorithms discussed here are given in Section 7.1.\nFinally, Bosansky et al. [2014] develop an iterative double-oracle algorithm for exact equilibrium computation. This algorithm only scales for games where it can identify an equilibrium of small support, and thus suffers from the same performance issues as the general LP approach.\nIn addition to equilibrium-finding algorithms, another central topic in large-scale game solving has been automated abstraction [Sandholm, 2010, 2015]. Initially, this was used mostly for information abstraction [Gilpin and Sandholm, 2007, Shi and Littman, 2002, Zinkevich et al., 2007]. Lately, action abstraction approaches have gained considerable interest [Hawkin et al., 2011, 2012, Brown and Sandholm, 2014, Kroer and Sandholm, 2014, 2016]. Sequential game abstraction approaches with solution quality bounds have also emerged for stochastic [Sandholm and Singh, 2012] and extensive-form [Lanctot et al., 2012, Kroer and Sandholm, 2014, 2016] games more recently."
    }, {
      "heading" : "3 Problem setup",
      "text" : "Computing a Nash equilibrium in a two-player zero-sum EFG with perfect recall can be formulated as a Bilinear Saddle Point Problem (BSPP):\nmin x∈X max y∈Y 〈x,Ay〉 = max y∈Y min x∈X 〈x,Ay〉. (1)\nThis is known as the sequence-form formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the nonnegative strategy vectors for players 1 and 2 and the sets X ,Y are convex polyhedral reformulations of the sequential strategy space of these players. Here X ,Y are defined by the constraints Ex = e, Fy = f , where each row of E,F encodes part of the sequential nature of the strategy vectors, the right hand-side vectors e, f are |I1| , |I2|-dimensional vectors, and Ii is the information sets for player i. For a complete treatment of this formulation, see von Stengel [1996].\nOur theoretical developments mainly exploit the treeplex domain structure and are independent of other structural assumptions resulting from EFGs. Therefore, we describe our results for general BSPPs. We follow the presentation and notation of Juditsky and Nemirovski [2011a,b] for BSPPs. For notation and presentation of treeplex structure, we follow Kroer et al. [2015]."
    }, {
      "heading" : "3.1 Basic notation",
      "text" : "We let 〈x, y〉 denote the standard inner product of vectors x, y. Given a vector x ∈ Rn, we let ‖x‖p denote its `p norm given by ‖x‖p := ( ∑n i=1 |xi|p)\n1/p for p ∈ [1,∞) and ‖x‖∞ := maxi∈[n] |xi| for p = ∞. Throughout this paper, we use Matlab notation to denote vector and matrices, i.e., [x; y] denotes the concatenation of two column vectors x, y. For a given set Q, we let ri (Q) denote its relative interior. Given n ∈ N, we denote the simplex ∆n := {x ∈ Rn+ : ∑n i=1 xi = 1}."
    }, {
      "heading" : "4 Optimization setup",
      "text" : "In its most general form a BSPP is defined as\nOpt := max y∈Y min x∈X\nφ(x, y), (S)\nwhere X ,Y are nonempty convex compact sets in Euclidean spaces Ex,Ey and φ(x, y) = υ + 〈a1, x〉+ 〈a2, y〉+ 〈y,Ax〉. We let Z := X × Y; so φ(x, y) : Z → R. In the context of EFG solving, φ(x, y) is simply the inner product given in (1).\nThe BSPP (S) gives rise to two convex optimization problems that are dual to each other:\nOpt(P ) = minx∈X [φ(x) := maxy∈Y φ(x, y)] (P ), Opt(D) = maxy∈Y [φ(y) := minx∈X φ(x, y)] (D),\nwith Opt(P ) = Opt(D) = Opt. It is well known that the solutions to (S) — the saddle points of φ on X × Y — are exactly the pairs z = [x; y] comprised of optimal solutions to the problems (P ) and (D). We quantify the accuracy of a candidate solution z = [x; y] with the saddle point residual\nsad(z) := φ(x)− φ(y) = [ φ(x)−Opt(P ) ]︸ ︷︷ ︸ ≥0 + [ Opt(D)− φ(y) ]︸ ︷︷ ︸ ≥0 .\nIn the context of EFG, sad(z) measures the proximity to being an -Nash equilibrium."
    }, {
      "heading" : "4.1 General framework for FOMs",
      "text" : "Most FOMs capable of solving BSPP (S) are quite flexible in terms of adjusting to the geometry of the problem characterized by the domains X ,Y of the BSPP (S). The following components are standard in forming the setup for such FOMs (we present components for X , analogous components are used for Y):\n• Vector norm: ‖ · ‖X on the Euclidean space E where the domain X of (S) lives, along with its dual norm ‖ζ‖∗X = max‖x‖X≤1 〈ζ, x〉.\n• Matrix norm: ‖A‖ = maxy {‖Ay‖∗X : ‖y‖Y = 1} based on the vector norms ‖ · ‖X , ‖ · ‖Y .\n• Distance-Generating Function (DGF): A function ωX (x) : X → R, which is convex and continuous on X , and admits a continuous selection of subgradients ω′X (x) on the set X ◦ := {x ∈ X : ∂ωX (x) 6= ∅} (here ∂ωX (x) is a subdifferential of ωX taken at x), and is strongly convex with modulus ϕX w.r.t. the norm ‖ · ‖X :\n∀x′, x′′ ∈ X ◦ : 〈ω′X (x′)− ω′X (x′′), x′ − x′′〉 ≥ ϕX ‖x′ − x′′‖2X . (2)\n• Bregman distance: V (u‖x) := ωX (u)− ωX (x)− 〈ω′X (x), u− x〉 for all x ∈ X ◦ and u ∈ X .\n• Prox-mapping : Given a prox center x ∈ X ◦,\nProxx(ξ) := argmin u∈X\n{〈ξ, u〉+ V (u‖x)} : E→ X ◦.\nFor properly chosen stepsizes, the prox-mapping becomes a contraction. This is critical in the convergence analysis of FOMs. Furthermore, when the DGF is taken as the squared `2 norm, the prox mapping becomes the usual projection operation of the vector x− ξ onto X .\n• ω-center : xω := argmin x∈X ωX (x) ∈ X ◦ of X .\n• Set width: Ωx := max x∈X V (x‖xω) ≤ max x∈X ωX (x)−min x∈X ωX (x).\nThe distance-generating functions ωX , ωY can be used to create smoothed approximations to φ, φ as follows [Nesterov, 2005b]:\nφµ2(x) = maxy∈Y {φ(x, y)− µ2ωY(y)} , (3)\nφ µ1 (y) = min x∈X {φ(x, y) + µ1ωX (x)} , (4)\nwhere µ1, µ2 > 0 are smoothness parameters denoting the amount of smoothing applied. Let yµ2(x) and xµ1(y) refer to the y and x values attaining the optima in (3) and (4). These can be thought of as smoothed best responses. Nesterov [2005b] shows that the gradients of the functions φµ2(x) and φ\nµ1 (y) exist and are Lipschitz continuous. The gradient operators and Lipschitz constants are\ngiven as follows\n∇φµ2(x) = a1 +Ayµ2(x) and ∇φµ1(y) = a2 +A >xµ1(y),\nL1 ( φµ2 ) = ‖A‖2\nϕYµ2 and L2\n( φ µ1 ) = ‖A‖2\nϕXµ1 .\nBased on this setup, we formally state the Excessive Gap Technique (EGT) of Nesterov [2005a] in Algorithm 1.\nALGORITHM 1: EGT input : ω-center zω, DGF weights µ1, µ2,\nand > 0 output: zt(= [xt; yt]) x0 = Proxxω ( µ−11 ∇φµ2(xω) ) ; y0 = yµ2(xω); t = 0; z1 := zω; while sad(z\nt) > do τt = 2 t+3 ; if t is even then\n(µt+11 , x t+1, yt+1) =\nStep(µt1, µ t 2, x t, yt, τ) else\n(µt+12 , y t+1, xt+1) =\nStep(µt2, µ t 1, y t, xt, τ) end t = t+ 1;\nend\nALGORITHM 2: Step\ninput : µ1, µ2, x, y, τ output: µ+1 , x+, y+ x̂ = (1− τ)x+ τxµ1(y); y+ = (1− τ) y + τyµ2(x̂); x̃ = Proxxµ1 (y) ( τ (1−τ)µ1∇φµ2(x̂) ) ; x+ = (1− τ)x+ τ x̃; µ+1 = (1− τ)µ1;\nThe EGT algorithm alternates between taking steps focused on X and Y. Algorithm 2 shows a single step focused on X . Steps focused on y are completely analogous. Algorithm 1 shows how the alternating steps and stepsizes are computed, as well as how initial points are selected.\nSuppose the initial values µ1, µ2 in the EGT algorithm satisfy µ1 = ϕX\nL1(φµ2 ) . Then, at every\niteration t ≥ 1 of the EGT algorithm, the corresponding solution zt = [xt; yt] satisfies xt ∈ X , yt ∈ Y, and\nφ(xt)− φ(yt) = sad(zt) ≤ 4‖A‖ T + 1 √ ΩXΩY ϕXϕY .\nConsequently, [Nesterov, 2005a] proves that the EGT algorithm has a convergence rate of O(1 )."
    }, {
      "heading" : "5 Treeplexes",
      "text" : "Hoda et al. [2010] introduce the treeplex, a class of convex polytopes that encompass the sequenceform description of strategy spaces in perfect-recall EFGs.\nDefinition 1. Treeplexes are defined recursively:\n1. Basic sets: The standard simplex ∆m is a treeplex.\n2. Cartesian product: If Q1, . . . , Qk are treeplexes, then Q1 × · · · ×Qk is a treeplex.\n3. Branching: Given a treeplex P ⊆ [0, 1]p, a collection of treeplexes Q = {Q1, . . . , Qk} where Qj ⊆ [0, 1]nj , and l = {l1, . . . , lk} ⊆ {1, . . . , p}, the set defined by\nP l Q := { (u, q1, . . . , qk) ∈ Rp+ ∑ j nj : u ∈ P, q1 ∈ ul1 ·Q1, . . . , qk ∈ ulk ·Qk } is a treeplex. In this setup, we say ulj is the branching variable for the treeplex Qj .\nA treeplex is a tree of simplexes where children are connected to their parents through the branching operation. In the branching operation, the child simplex domain is scaled by the value of the parent branching variable. Understanding the treeplex structure is crucial because the proofs of our main results rely on induction over these structures. For EFGs, the simplexes correspond to the information sets of a single player and the whole treeplex represents that player’s strategy space. The branching operation has a sequential interpretation: The vector u represents the decision variables at certain stages, while the vectors qj represent the decision variables at the k potential following stages, depending on external outcomes. Here k ≤ p since some variables in u may not have subsequent decisions. For treeplexes, von Stengel [1996] has suggested a polyhedral representation of the form Eu = e where the matrix E has its entries from {−1, 0, 1} and the vector e has its entries in {0, 1}.\nFor a treeplex Q, we denote by SQ the index set of the set of simplexes contained in Q (in an EFG SQ is the set of information sets belonging to the player). For each j ∈ SQ, the treeplex rooted at the j-th simplex ∆j is referred to as Qj . Given vector q ∈ Q and simplex ∆j , we let Ij denote the set of indices of q that correspond to the variables in ∆j and define qj to be the sub vector of q corresponding to the variables in Ij . For each simplex ∆j and branch i ∈ Ij , the set Dij represents the set of indices of simplexes reached immediately after ∆j by taking branch i (in an EFG Dij is the set of potential next-step information sets for the player). Given a vector q ∈ Q, simplex ∆j , and index i ∈ Ij , each child simplex ∆k for every k ∈ Dij is scaled by qi. Conversely, for a given simplex ∆j , we let pj denote the index in q of the parent branching variable qpj that ∆ j is scaled by. We use the convention that qpj = 1 if Q is such that no branching operation precedes ∆j . For each j ∈ SQ, dj is the maximum depth of the treeplex rooted at ∆j , that is, the maximum number of simplexes reachable through a series of branching operations at ∆j . Then dQ gives the depth of Q. We use bjQ to identify the number of branching operations preceding the j-th simplex in Q. We will say that a simplex j such that bjQ = 0 is a root simplex. Figure 1 illustrates an example treeplex Q. Q is constructed from nine two-to-three-dimensional simplexes ∆1, . . . ,∆9. At level 1, we have two root simplexes, ∆1,∆2, obtained by a Cartesian product (denoted by ×). We have maximum depths d1 = 2, d2 = 1 beneath them. Since there are no preceding branching operations, the parent variables for these simplexes ∆1 and ∆2 are qp1 = qp2 = 1. For ∆\n1, the corresponding set of indices in the vector q is I1 = {1, 2}, while for ∆2 we have I2 = {3, 4, 5}. At level 2, we have the simplexes ∆3, . . . ,∆7. The parent variable of\n∆3 is qp3 = q1; therefore, ∆ 3 is scaled by the parent variable qp3 . Similarly, each of the simplexes ∆3, . . . ,∆7 is scaled by their parent variables qpj that the branching operation was performed on. So on for ∆8 and ∆9 as well. The number of branching operations required to reach simplexes ∆1,∆3 and ∆8 is b1Q = 0, b 3 Q = 1 and b 8 Q = 2, respectively.\nNote that we allow more than two-way branches; hence our formulation follows that of Kroer et al. [2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al. [2010], it is possible to model sequence-form games by treeplexes that use only two-way branches. Yet, this can cause a large increase in the depth of the treeplex, thus leading to significant degradation in the strong convexity parameter. Because we handle multi-way branches directly in our framework, our approach is more effective in taking into account the structure of the sequence-form game and thereby resulting in better bounds on the associated strong convexity parameters and thus overall convergence rates.\nOur analysis requires a measure of the size of a treeplex Q. Thus, we define MQ := maxq∈Q ‖q‖1. In the context of EFGs, suppose Q encodes player 1’s strategy space; then MQ is the maximum number of information sets with nonzero probability of being reached when player 1 has to follow a pure strategy while the other player may follow a mixed strategy. We also let\nMQ,r := max q∈Q ∑ j∈SQ:bjQ≤r ‖qj‖1. (5)\nIntuitively, MQ,r gives the maximum value of the `1 norm of any vector q ∈ Q after removing the variables corresponding to simplexes that are not within r branching operations of the root of Q.\nExample 1. In order to illustrate MQ and compare it to the size of |SQ|, let us now consider an example of an EFG and its corresponding treeplexes. Consider a game where two players take turns choosing among k actions, and each player chooses actions d times before leaf nodes are reached. In the treeplex Q of Player 1, each time Player 1 chooses among k actions constitutes a size k branching operation, and every time Player 2 chooses among k actions constitutes a size k Cartesian product operation. The total dimensionality of the treeplex, |SQ|, is k2d, while the value of MQ is k d (since only Cartesian products blow up). Thus, MQ is square root of the size of |SQ|."
    }, {
      "heading" : "6 Dilated entropy functions with bounded strong convexity",
      "text" : "In this section we introduce DGFs for domains with treeplex structures and establish their strong convexity parameters with respect to a given norm (see (2)).\nThe basic building block in our construction is the entropy DGF given by ωe(z) = ∑n\ni=1 zi log(zi), for the simplex ∆n. It is well-known that ωe(·) is strongly convex with modulus 1 with respect to the `1 norm on ∆n (see Juditsky and Nemirovski [2011a]). We will show that a suitable modification of this function achieves a desirable strong convexity parameter for the treeplex domain.\nThe treeplex structure is naturally related to the dilation operation [Hiriart-Urruty and Lemaréchal, 2001] defined as follows: Given a compact set K ⊆ Rd and a function f : K → R, we first define\nK̄ := { (t, z) ∈ Rd+1 : t ∈ [0, 1] , z ∈ t ·K } .\nDefinition 2. Given a function f(z), the dilation operation is the function f̄ : K̄ → R given by\nf̄(z, t) = { t · f(z/t) if t > 0 0 if t = 0 .\nThe dilation operation preserves convexity, and thus we define the following convex function by dilating the entropy function over the simplexes of a treeplex:\nDefinition 3. Given a treeplex Q and weights βj > 0 for each j ∈ SQ, we define the dilated entropy function as\nω(q) = ∑ j∈SQ βj ∑ i∈Ij qi log qi qpj for any q ∈ Q,\nwhere we follow the treeplex notation and pj is the index of the branching variable preceding ∆ j , with the convention that qpj = 1 if ∆ j has no branching operation preceding it.\nRemark 1. Note that the dilated entropy function ω(·) defined above is twice differentiable in the relative interior of treeplex Q and admits a continuous gradient selection. Moreover, for weights βj that scale appropriately with depth dj, we will demonstrate that it is strongly convex w.r.t. the `1 norm. Thus, the dilated entropy function is compatible with the `1 norm, as required by the BSPP setup.\nWe would also like the prox-mapping associated with our DGF to be efficiently computable. Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes. Since the entropy prox function can be computed in closed form on a simplex, the dilated entropy function can be computed by a single treeplex traversal involving closed-form expressions on each simplex.\nDefinition 3 above leads to a subset of the DGFs considered by Hoda et al. [2010]. Our main theoretical result shows that by a careful selection of the weights βj , we can significantly improve the strong convexity bounds associated with the dilated entropy function. We will consider weights that satisfy the following recurrence:\nαj = 1 + max i∈Ij ∑ k∈Dij αkβk βk − αk , ∀j ∈ SQ, βj > αj , ∀i ∈ Ij and ∀j ∈ SQ s.t. bjQ > 0, βj = αj , ∀i ∈ Ij and ∀j ∈ SQ s.t. bjQ = 0.\n(6)\nIntuitively, αj represents the negative terms that the weight βj has to cancel out: the constant 1 represents the negative term resulting from the squared norm in the strong convexity requirement; the summation term represents the amount of negative terms accumulated from the induction on simplexes descending from simplex j. The qualifications on βj ensure that βj is set such that it at least cancels out the negative terms; the difference βj − αj controls the amount of negative value the parent simplex has to make up. This is why we set βj = αj when b j Q = 0. As part of the proof of Lemma 2 we will see why we require a strict inequality βj > αj for non-root simplexes. Based on recurrence (6), our main results establish strong convexity of our dilated entropy DGF w.r.t. the `2 and `1 norms:\nTheorem 1. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1 with respect to the `2 norm.\nTheorem 2. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1MQ with respect to the `1 norm.\nWe give the proofs of Theorems 1 and 2 in Section 6.2. Based on Theorem 2, we get the following corollary:\nCorollary 1. For a treeplex Q, the dilated entropy function with weights βj = 2+ ∑dj r=1 2 r(MQj ,r−1) for all j ∈ SQ is strongly convex with modulus 1MQ w.r.t. the `1 norm.\nCorollary 1 follows easily from Theorem 2 and a recursive interpretation of the weights, which is presented as Fact 2 in the next section. In particular, a specific choice of weights in Fact 2 immediately satisfies the recurrence (6) and leads to Corollary 1.\nTo our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights βj = 2\ndjMQj they show strong convexity modulus 1 |SQ| w.r.t. the `1\nnorm. Corollary 1 improves the prior bounds by exchanging a factor of |SQ| with a factor of MQ. Note that |SQ| is tied to the branching factor associated with branching operations in the treeplex Q whereas MQ is not. Thus, our result removes the dependence of the strong convexity parameter on the branching factor and hence significantly improves upon Kroer et al. [2015].\nIn Theorem 3 we use our strong convexity result to establish a polytope diameter that has only a logarithmic dependence on the branching factor. As a consequence, the associated dilated entropy DGF when used in FOMs such as MP and EGT for solving EFGs leads to the same improvement in their convergence rate."
    }, {
      "heading" : "6.1 Preliminary results for the proofs of our main results",
      "text" : "We start with some simple facts and a few technical lemmas that are used in our proofs.\nFact 1. Given a treeplex Q, we have, respectively, for all i ∈ Ij , j ∈ SQ and all d = 1, . . . , dQ, q ∈ Q:\n(a) MQj ≥ 1 + ∑ l∈Dij MQl , (b) MQ ≥ ∑ j∈SQ:dj=d qpjMQj .\nProof. The first inequality was established in Kroer et al. [2015, Lemma 5.7]. The second follows by using MQ = ∑ j qi for some q, and inductively replacing terms belonging to simplexes j at the bottom with MQj . The result follows because branching operations cancel out by summing to 1.\nOur next observation follows from Fact 1(a) and is advantageous in suggesting a practically useful choice of the weights βj that can be used for Theorem 2 to arrive at Corollary 1.\nFact 2. Let Q be a treeplex and βj = 2 + ∑dj r=1 2 r(MQj ,r − 1) for all j ∈ SQ as in Corollary 1.\nThen Fact 1(a) implies βj ≥ 2 + ∑\nk∈Dij 2βk, ∀i ∈ Ij and ∀j ∈ SQ.\nConsequently, by selecting βj = 2αj , and αj = 1 + ∑dj r=1 2 r−1(MQj ,r − 1) for all i ∈ Ij and for all j ∈ SQ such that bjQ > 0, we immediately satisfy the conditions of the recurrence in (6). Given a twice differentiable function f , we let ∇2f(z) denote its Hessian at z. Our analysis is based on the following sufficient condition for strong convexity of a twice differentiable function:\nFact 3. A twice-differentiable function f is strongly convex with modulus ϕ with respect to a norm ‖ · ‖ on nonempty convex set C ⊂ Rn if h>∇2f(z)h ≥ ϕ‖h‖2, ∀h ∈ Rn, z ∈ C◦.\nFor simplexes ∆j at depth 1, there is no preceding branching operation; so the variables hpj , qpj do not exist. We circumvent this with the convention hpj = 0, qpj = 1 for such j ∈ SQ.\nIn our proofs we will use the following expression for h>∇2ω(q)h. Lemma 1. Given a treeplex Q and a dilated entropy function ω(·) with weights βj > 0, we have\nh>∇2ω(q)h = ∑ j∈SQ βj ∑ i∈Ij ( h2i qi − 2hihpj qpj ) + h2pj qpj  ∀q ∈ ri (Q) and ∀h ∈ Rn. (7) We provide the proof of Lemma 1 in the appendix. It simply follows from taking the second-\norder partial derivatives and rearranging terms."
    }, {
      "heading" : "6.2 Proofs of our main theorems",
      "text" : "The majority of the work for our strong-convexity results is performed by the following lemma, from which our strong convexity results follow easily.\nLemma 2. For any treeplex Q, the dilated entropy function with weights satisfying recurrence (6) satisfies the following inequality:\nh>∇2ω(q)h ≥ ∑ j∈SQ ∑ i∈Ij h2i qi ∀q ∈ ri (Q) and ∀h ∈ Rn. (8)\nProof. We will first show the following inductive hypothesis over the set of non-root simplexes ŜQ = { j ∈ SQ : bjQ > 0 } for any depth d ≥ 0:\n∑ j∈ŜQ:dj≤d βj ∑ i∈Ij ( h2i qi − 2hihpj qpj ) + h2pj qpj − ∑ j∈ŜQ:dj≤d ∑ i∈Ij h2i qi ≥ − ∑ j∈ŜQ:dj=d βjαj βj − αj h2pj qpj\nWe begin with the inductive step, as the base case will follow from the same logic. Consider a treeplex Q of depth d > 0. By applying the inductive hypothesis we have\n∑ j∈ŜQ:dj≤d βj ∑ i∈Ij ( h2i qi − 2hihpj qpj ) + h2pj qpj − ∑ j∈ŜQ:dj≤d ∑ i∈Ij h2i qi\n≥ ∑\nj∈ŜQ:dj=d\nβj ∑ i∈Ij ( h2i qi − 2hihpj qpj ) + h2pj qpj − ∑ j∈ŜQ:dj=d ∑ i∈Ij h2i qi − ∑ j∈ŜQ:dj=d−1 βjαj βj − αj h2pj qpj\n(9)\nNow we can rearrange terms: The sum over j ∈ ŜQ such that dj = d−1 is equivalent to a sum over the immediate descendant information sets k ∈ Dij inside the square brackets, and we can move the sum over i ∈ Ij outside the square brackets by using the fact that ∑ i∈Ij qi qpj = 1 and splitting the term h2pj qpj into separate terms multiplied by qiqpj , this gives\n(9) = ∑\nj∈ŜQ:dj=d\n∑ i∈Ij\n βj − 1− ∑\nk∈Dij\nβkαk βk − αk  h2i qi − ( 2βjhihpj qpj ) + qiβjh 2 pj q2pj  ≥\n∑ j∈ŜQ:dj=d ∑ i∈Ij\n[ (βj − αj) h2i qi − ( 2βjhihpj qpj ) + qiβjh 2 pj q2pj ] , (10)\nwhere the last inequality follows from the definition of αj .\nFor indices j ∈ SQ such that bjQ > 0 and i ∈ Ij , the relations in (6) imply βj > αj , and so the expression inside the square brackets in (10) is a convex function of hi. Taking its derivative w.r.t. hi and setting it to zero gives hi = βj\nβj−αj qi qpj hpj . Thus, we arrive at\n(10) ≥ ∑\nj∈ŜQ:dj=d\n∑ i∈Ij\n[ β2j\nβj − αj qih\n2 pj\nq2pj − β2j βj − αj 2qih 2 pj q2pj + qiβjh 2 pj q2pj\n]\n= ∑\nj∈ŜQ:dj=d\nh2pj qpj [( −β2j βj − αj + βj )∑i∈Ij qi qpj ] = − ∑ j∈ŜQ:dj=d βjαj βj − αj h2pj qpj .\nHence, the induction step is complete. For the base case d = 0 we do not need the inductive assumption: Because Dij = ∅, αj = 1, and we get (10) by definition; we can then apply the same convexity argument. This proves our inductive hypothesis.\nThen using Lemma 1, we now have\nh>∇2ω(q)h− ∑ j∈SQ ∑ i∈Ij h2i qi = ∑ j∈SQ βj ∑ i∈Ij ( h2i qi − 2hihpj qpj ) + h2pj qpj − ∑ j∈SQ ∑ i∈Ij h2i qi\n≥ ∑\nj∈SQ:bjQ=0\n∑ i∈Ij βj h2i qi − ∑ k∈Dij βkαk βk − αk h2i qi − h 2 i qi  ≥ 0. The first inequality follows from the fact that hpj = 0 for all j ∈ SQ such that b j Q = 0, and for all j ∈ SQ such that bjQ > 0, we used our induction. The last inequality follows from (6) and qi, h2i ≥ 0. This then proves (8).\nWe are now ready to prove our two main theorems, which we restate before proving them.\nTheorem 1. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1 with respect to the `2 norm.\nProof. Since qi ≤ 1, Lemma 2 implies h>∇2ω(q)h ≥ ∑ j∈SQ ∑ i∈Ij h 2 i = ‖h‖22 for all q ∈ ri (Q) and for all h ∈ Rn. Because the dilated entropy function ω(q) is twice differentiable on ri (Q), from Fact 3, we conclude that ω(·) is strongly convex w.r.t. the `2 norm on Q with modulus 1.\nThis analysis is tight: By choosing a vector q ∈ {0, 1}|Q| such that ‖q‖1 = MQ, and setting hi =\nβj βj−αj qi qpj hpj for all indices i such that qi = 1 and hi = 0 otherwise, every inequality in the\nproof of Lemma 2 becomes an equality.\nTheorem 2. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1MQ with respect to the `1 norm.\nProof. To show strong convexity with modulus 1 w.r.t. the `1 norm, we lower bound the right-hand side of (8) in Lemma 2:\n∑ j∈SQ ∑ i∈Ij h2i qi ≥ 1 MQ ( ∑ j∈SQ ∑ i∈Ij qi ) ∑ j∈SQ ∑ i∈Ij h2i qi ≥ 1 MQ ( ∑ j∈SQ ∑ i∈Ij |hi|√ qi √ qi )2 = 1 MQ ‖h‖21,\nwhere the first inequality follows from the fact that MQ is an upper bound on ‖q‖1 for any q ∈ Q, and the second inequality follows from the Cauchy-Schwarz inequality.\nHence, we deduce h>∇2ω(q)h ≥ 1MQ ‖h‖ 2 1 holds for all q ∈ ri (Q) and for all h ∈ Rn. Because the dilated entropy function ω(q) is twice differentiable on ri (Q), from Fact 3, we conclude that ω(·) is strongly convex w.r.t. the `1 norm on Q with modulus ϕ = 1MQ ."
    }, {
      "heading" : "6.3 Treeplex width",
      "text" : "The convergence rates of FOMs such as MP and EGT algorithms depend on the diameter-to-strong convexity parameter ratio Ωϕ , as described in Section 4.1. In order to establish full results on the convergence rates of these FOMs, we now bound this ratio using Corollary 1 scaled by MQ. Theorem 3. For a treeplex Q, the dilated entropy function with simplex weights βj = MQ(2 +∑dj r=1 2 r(MQj ,r − 1)) for each j ∈ SQ results in Ωϕ ≤ M 2 Q2 dQ+2 logm where m is the dimension of the largest simplex ∆j for j ∈ SQ in the treeplex structure."
    }, {
      "heading" : "7 EGT for extensive-form game solving",
      "text" : "We now describe how to instantiate EGT for solving two-player zero-sum EFGs of the form (1) with treeplex domains. Below we state the customization of all the definitions from Section 4 for our problem.\nLet m be the size of the largest simplex in either of the treeplexes X ,Y. Because X and Y are treeplexes, it is immediately apparent that they are closed, convex, and bounded. We use the `1 norm on both of the embedding spaces Ex,Ey. As our DGFs for X ,Y are compatible with the `1 norm, we use the dilated entropy DGF scaled with weights given in Theorem 3. Then Theorem 3 gives our bound on ΩXϕX and ΩY ϕY . Because the dual norm of the `1 norm is the `∞ norm, the matrix norm is given by: ‖A‖ = maxy∈Y {‖Ay‖∗1 : ‖y‖1 = 1} = maxi,j |Ai,j |.\nRemark 2. Note that ‖A‖ is not at the scale of the maximum payoff difference in the original game. The values in A are scaled by the probability of the observed nature outcomes on the path of each sequence. Thus, ‖A‖ is exponentially smaller (in the number of observed nature steps on the path to the maximizing sequence) than the maximum payoff difference in the original EFG.\nTheorem 3 immediately leads to the following convergence rate result for FOMs equipped with dilated entropy DGFs to solve EFGs (and more generally BSPPs over treeplex domains).\nTheorem 4. Consider a BSPP over treeplex domains X ,Y. Then EGT algorithm equipped with the dilated entropy DGF with weights βj = 2+ ∑dj r=1 2\nr(MXj ,r−1) for all j ∈ SX and the corresponding setup for Y will return an -accurate solution to the BSPP in at most the following number of iterations:\nmaxi,j |Ai,j | √ M2X 2 dX+2M2Y2 dY+2 logm\n.\nThis rate in Theorem 4, to our knowledge, establishes the state-of-the-art for FOMs with O(1 ) convergence rate for EFGs."
    }, {
      "heading" : "7.1 Improvements in extensive-form game convergence rate",
      "text" : "The ratio Ωϕ of set diameter over the strong convexity parameter is important for FOMs that rely on a prox function, such as EGT and MP. Compared to the rate obtained by [Kroer et al., 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al., 2015] by a factor of Ω(dX · adX + dY · adY ).\nAs mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen. 2) At each depth d, a Cartesian product operation of size k is applied. 3) Each element in a Cartesian product is an instance of the base treeplex with a size b branching operation leading to depth d − 1 uniform treeplexes constructed in the same way. Given bounds Ωb, ϕb for the base treeplex, the bound of Hoda et al. [2010] for a uniform treeplex with d uniform treeplex levels (note that the total depth of the constructed treeplex is d · dQb , where dQb is the depth of the base treeplex Qb) is\nΩ ϕ ≤ O ( b2d−2k2d+2d2M2Qb Ωb ϕb ) .\nThen when the base treeplex is a simplex of dimension m, their bound for the dilated entropy on a uniform treeplex Q becomes\nΩ ϕ ≤ O\n( |SQ|2 d2Q logm ) .\nEven for the special case of a uniform treeplex with a base simplex, comparing Theorem 3 to their bound, we see that our general bound improves the associated constants by exchanging O(|SQ|2 d2Q) with O(M2Q2\ndQ). Since MQ does not depend on the branching operation in the treeplex, whereas |SQ| does, these are also the first bounds to remove an exponential dependence on the branching operation (we have only a logarithmic dependence). In Example 1 we showed that there exist games where MQ = √ |SQ|, and in general MQ is much smaller than |SQ|. Consequently, our results establish the best known convergence results for all FOMs based on dilated entropy DGF such as EGT, MP, and stochastic variants of BSPP algorithms.\nCFR, CFR+, and EGT all need to keep track of a constant number of current and/or average iterates, so the memory usage of all three algorithms is of the same order; when gradients are computed using an iterative approach as opposed to storing matrices or matrix decompositions, each algorithm requires a constant times the number of sequences in the sequence-form representation. Therefore, we compare mainly the number of iterations required by each algorithm. Since the theoretical properties of CFR and CFR+ are comparable, we compare to CFR, with all statements being valid for CFR+ as well.\nCFR has a O( 1 2\n) convergence rate; but its dependence on the number of information sets is only linear (and sometimes sublinear [Lanctot et al., 2009]). Since our results have a quadratic dependence on M2Q, CFR sometimes has a better dependence on game constants and can be more attractive for obtaining low-quality solutions quickly for games with many information sets. MCCFR and CFR+ have a similar convergence rate [Lanctot et al., 2009], though MCCFR has cheaper iterations.\nGilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln(1 )); but this form of their bound has a dependence on a certain condition number of the A matrix. Specifically, their iteration bound for sequential games is O( ‖A‖2,2·ln(‖A‖2,2/ )· √ D\nδ(A) ), where δ(A) is the condition number\nof A, ‖A‖2,2 = supx 6=0 ‖Ax‖2 ‖x‖2 is the Euclidean matrix norm, and D = maxx,x̄∈X ,y,ȳ∈Y ‖(x, y) − (x̄, ȳ)‖22. Unfortunately, the condition number δ(A) is only shown to be finite for these games. Without any such unknown quantities based on condition numbers, Gilpin et al. [2012] establish a convergence rate of O( ‖A‖2,2·D\n). This algorithm, despite having the same dependence on as ours in its convergence rate, i.e., O(1 ), suffers from worse constants. In particular, there exist matrices such\nthat ‖A‖2,2 = √ ‖A‖1,∞‖A‖∞,1, where ‖A‖1,∞ and ‖A‖∞,1 correspond to the maximum absolute column and row sums, respectively. Then together with the value of D, this leads to a cubic dependence on the dimension of Q. For games where the players have roughly equal-size strategy spaces, this is equivalent to a constant of O(M4Q) as opposed to our constant of O(M 2 Q)."
    }, {
      "heading" : "8 Numerical experiments",
      "text" : "We carry out numerical experiments to investigate the practical performance of EGT on EFGs when instantiated with our DGF.\nWe test these algorithms on a scaled up variant of the poker game Leduc holdem [Southey et al., 2005], a benchmark problem in the imperfect-information game-solving community. In our version, the deck consists of k pairs of cards 1 . . . k, for a total deck size of 2k. Each player initially pays one chip to the pot, and is dealt a single private card. After a round of betting, a community card is dealt face up. After a subsequent round of betting, if neither player has folded, both players reveal their private cards. If either player pairs their card with the community card they win the pot. Otherwise, the player with the highest private card wins. In the event both players have the same private card, they draw and split the pot.\nFirst, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set βj relative to αj . Experimentally, we found that the best way to instantiate the recurrence is to use βj = αj for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights). Figure 2 shows the result of running EGT with the old and the new weights. For both the old and the new weights, we found that the scalars MQ and |SQ| applied to each DGF in order to achieve strong convexity modulus 1 according to Corollary 1 and Theorem 5.4 of Kroer et al. [2015], respectively, are too conservative. Instead, we show the results after tuning these parameters for the corresponding algorithms to yield the best results for each weight scheme. Anecdotally, we found that the old weights are more sensitive and more difficult to tune. The performance also seems more jittery; this is evident even in the strongest parameter we found (especially noticeable on 10, 16, and 30-card Leduc in Figure 2).\nWe compare the performance of EGT to that of CFR and CFR+ algorithms on a scaled up variant of the poker game Leduc hold’em [Southey et al., 2005], a benchmark problem in the\nimperfect-information game-solving community. In our version, the deck consists of k pairs of cards 1 . . . k, for a total deck size of 2k. Setting k = 3 yields the standard Leduc game. Each player initially pays one chip to the pot, and is dealt a single private card. After a round of betting, a community card is dealt face up. After a subsequent round of betting, if neither player has folded, both players reveal their private cards. If either player pairs their card with the community card, they win the pot. Otherwise, the player with the highest private card wins. In the event both players have the same private card, they draw and split the pot.\nThe results are shown in Figure 3. Each graph is a loglog plot that shows the results for a particular instance of Leduc with 6, 10, 16 and 30 card decks, respectively. For each graph, we show the performance of all three algorithms, with the x-axis showing the number of tree traversals, and the y-axis showing the sum of regrets over the two players. We note that tree-travels is a good proxy for overall computational effort because the majority of the time in FOMs is spent on gradient computations, which in our case directly translates into tree-traversals. We find that EGT instantiated with our DGF significantly outperforms both CFR and CFR+ across all four variants of Leduc. This is the case across all iterations; EGT finds a stronger initial point in x0, y0 (see Algorithm 1), and maintains a stronger convergence rate across all iterations.\nThe performance we get from EGT relative to CFR and CFR+ is surprising due to what the conventional wisdom in the field has been. In Kroer et al. [2015] it was found that, while EGT has better convergence rate, CFR (which performs worse than CFR+) had better initial performance, and it was only after a certain number of iterations that EGT took over. Furthermore, the switch point where EGT is preferable was found to shift outward on the x-axis as the Leduc game size was increased. This sentiment has been mirrored by Brown and Sandholm [2016]. In contrast to this, we find that our DGF along with proper initialization leads to EGT performing better than\nnot only CFR, but also CFR+, at every point on the x-axis. Furthermore, scaling up the game size does not seem to adversely affect this relationship.\nWhile the experiments in Figure 3 are very interesting from the perspective of which algorithm to use for large-scale EFG-solving in practice going forward, there are some caveats to keep in mind. First, we only considered number of tree traversals in our performance calculations. However, CFR algorithms have the ability to avoid parts of the tree traversal. For games where accelerated bestresponse calculation [Johanson et al., 2011] can be applied, e.g., poker-like games, this is unlikely to have a big effect. But, for some other games, this aspect can be important, though note that Brown et al. [2017] showed experimentally that pruning can be used in EGT as well. Second, to get superior performance from EGT, we had to hand-tune initialization parameters relating to our DGF, whereas CFR+ requires no tuning. Development of an algorithmic scheme for choosing this tuning parameter in EGT can make it significantly easier to apply the tuned variant of EGT in practice. Third, on another practical aspect, CFR+ is a conceptually very simple algorithm, and thus also easy to implement. In contrast to this, EGT and our DGF requires a safe-guarded numerical implementation because the prox operator associated with our DGF requires taking exponentials."
    }, {
      "heading" : "9 Conclusions",
      "text" : "We have investigated FOMs for computing Nash equilibria in two-player zero-sum perfect-recall EFGs. On the theoretical side, we analyzed the strong convexity properties of the dilated entropy DGF over treeplexes. By introducing specific weights that are tied to the structure of the treeplex, we improved prior results on treeplex diameter from O(|SQ|MQd2d logm) to O(M2Q2dQ+2 logm), thereby removing all but a logarithmic dependence on branching associated with the branching operator in the treeplex definition. These results lead to significant improvements in the convergence rates of many FOMs that can be equipped with dilated entropy DGFs and used for EFG solving including but not limited to EGT, MP, and Stochastic MP.\nWe numerically investigated the performance of EGT and compared it to the practical state-ofthe-art algorithms CFR and CFR+. Our experiments showed that EGT with the dilated entropy DGF, when tuned with a proper scaling, has better practical, as well as theoretical, convergence rate than CFR+, the current state-of-the-art algorithm in practice. While our scaling parameter for the DGF did not require extensive tuning, we believe a more principled way of setting it is worthy of further future investigation.\nTheorems 1 and 2 establish bounds for a general class of weights βj satisfying the recurrence (6). Then in Corollary 1, we have selected a particular weighting scheme for βj satisfying (6) and performed our numerical tests. There may be other interesting choices of βj satisfying the recurrence (6). Thus, finding a way to optimally choose among the set of weights satisfying (6) to minimize the polytope diameter for specific games is appealing.\nOn a separate note, in practice CFR is often paired with an abstraction technique [Sandholm, 2010] such as those mentioned in Section 2. This is despite the lack of any theoretical justification. Effective ways to pair FOMs such as MP and EGT with practical abstraction techniques [Brown et al., 2015] or abstraction techniques that achieve solution-quality guarantees [Lanctot et al., 2012, Kroer and Sandholm, 2014, 2016] are also worth further consideration."
    }, {
      "heading" : "A Omitted proofs",
      "text" : "A.1 Proof of Lemma 1\nProof. Consider q ∈ ri (Q) and any h ∈ Rn. For each j ∈ SQ and i ∈ Ij , the second-order partial derivates of ω(·) w.r.t. qi are:\n∇2q2i ω(q) = βj qi + ∑ k∈Dij ∑ l∈Ik βkql q2i = βj qi + ∑ k∈Dij βk qi , (11)\nwhere the last equality holds because k ∈ Dij and thus ∑ l∈Ik ql = ‖q k‖1 = qpk = qi. Also, for each j ∈ SQ, i ∈ Ij , k ∈ Dij , and l ∈ Ik, the second-order partial derivates w.r.t. qi, ql are given by:\n∇2qi,qlω(q) = ∇ 2 ql,qi ω(q) = −βk qi . (12)\nThen equations (11) and (12) together imply\nh>∇2ω(q)h = ∑ j∈SQ ∑ i∈Ij h2i βj qi + ∑ k∈Dij βk qi − ∑ k∈Dij ∑ l∈Ik hihl 2βk qi  . (13) Given j ∈ SQ and i ∈ Ij , we have pk = i for each k ∈ Dij and for any k ∈ Dij , there exists some other j′ ∈ SQ corresponding to k in the outermost summation. Then we can rearrange the following terms:∑\nj∈SQ ∑ i∈Ij h2i ∑ k∈Dij βk qi = ∑ j∈SQ βj h2pj qpj and ∑ j∈SQ ∑ i∈Ij ∑ k∈Dij ∑ l∈Ik hihl 2βk qi = ∑ j∈SQ ∑ i∈Ij βj 2hihpj qpj .\nUsing these two equalities in (13) leads to (7) and proves the lemma.\nA.2 Proof of Theorem 3\nProof. For our choice of scaled weights βj , Corollary 1 implies that the resulting dilated entropy function is strongly convex with modulus ϕ = 1. Hence, we only need to bound Ω.\nAny vector q ∈ Q satisfying qi ∈ {0, 1} for all i maximizes ω(q) and results in maxq∈Q ω(q) = 0. For the minimum value, consider any q ∈ ri (Q). Applying the well-known lower bound of − logm for the negative entropy function on an m-dimensional simplex, we have\nω(q) = ∑ j∈SQ βjqpj ∑ i∈Ij qi qpj log qi qpj ≥ − ∑ j∈SQ βjqpj logm = − dQ∑ d=0 ∑ j∈SQ:dj=d βjqpj logm\n= − dQ∑ d=1 ∑ j∈SQ:dj=d βjqpj logm− ∑ j∈SQ:dj=0 βjqpj logm = −MQ logm dQ∑ d=1 ∑ j∈SQ:dj=d qpj ( 2 + d∑ r=1 2r(MQj ,r − 1) ) −MQ ∑ j∈SQ:dj=0 2qpj logm ≥ −MQ logm dQ∑ d=1 ∑ j∈SQ:dj=d qpjMQj d∑ r=1 2r − 2MQ logm ∑ j∈SQ:dj=0 qpj , (14)\nwhere the last inequality follows because for each j ∈ SQ with dj = 0, the definition of MQ implies ∑ j∈SQ:dj=0 qpj ≤MQ, and for each j ∈ SQ with dj = d ≥ 1, we have 2+ ∑d r=1 2\nr(MQj ,r−1) ≤∑d r=1 2 rMQj ,r ≤ ∑d r=1 2 rMQj sinceMQj,r ≤MQj . Also, from Fact 1(b), we have ∑ j∈SQ:dj=d qpjMQj ≤ MQ. Then we arrive at\n(14) ≥ −M2Q logm ( 2 + dQ∑ d=1 d∑ r=1 2r ) = −M2Q logm ( 2 + dQ∑ d=1 (2d+1 − 2) )\n= −M2Q logm ( 2 + dQ∑ d=1 2d+1 − 2dQ ) ≥ −M2Q(logm)2dQ+2,\nwhere the last inequality follows because for dQ = 0 we have 2 dQ+2 = 4 > 2 and for dQ ≥ 1 we have 2dQ ≥ 2. This lower bound on the minimum value, i.e., minq∈Q ω(q) ≥ −M2Q(logm)2dQ+2, coupled with maxq∈Q ω(q) ≤ 0, establishes the theorem."
    } ],
    "references" : [ {
      "title" : "An exact doubleoracle algorithm for zero-sum extensive-form games with imperfect information",
      "author" : [ "Branislav Bosansky", "Christopher Kiekintveld", "Viliam Lisy", "Michal Pechoucek" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Bosansky et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bosansky et al\\.",
      "year" : 2014
    }, {
      "title" : "Heads-up limit hold’em poker is solved",
      "author" : [ "Michael Bowling", "Neil Burch", "Michael Johanson", "Oskari Tammelin" ],
      "venue" : "Science,",
      "citeRegEx" : "Bowling et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bowling et al\\.",
      "year" : 2015
    }, {
      "title" : "Regret transfer and parameter optimization",
      "author" : [ "Noam Brown", "Tuomas Sandholm" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Brown and Sandholm.,? \\Q2014\\E",
      "shortCiteRegEx" : "Brown and Sandholm.",
      "year" : 2014
    }, {
      "title" : "Strategy-based warm starting for regret minimization in games",
      "author" : [ "Noam Brown", "Tuomas Sandholm" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Brown and Sandholm.,? \\Q2016\\E",
      "shortCiteRegEx" : "Brown and Sandholm.",
      "year" : 2016
    }, {
      "title" : "Hierarchical abstraction, distributed equilibrium computation, and post-processing, with application to a champion no-limit Texas Hold’em agent",
      "author" : [ "Noam Brown", "Sam Ganzfried", "Tuomas Sandholm" ],
      "venue" : "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),",
      "citeRegEx" : "Brown et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2015
    }, {
      "title" : "Dynamic thresholding and pruning for regret minimization",
      "author" : [ "Noam Brown", "Christian Kroer", "Tuomas Sandholm" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Brown et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2017
    }, {
      "title" : "The complexity of computing a nash equilibrium",
      "author" : [ "Constantinos Daskalakis", "Paul W Goldberg", "Christos H Papadimitriou" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "Daskalakis et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Daskalakis et al\\.",
      "year" : 2009
    }, {
      "title" : "Near-optimal no-regret algorithms for zero-sum games",
      "author" : [ "Constantinos Daskalakis", "Alan Deckelbaum", "Anthony Kim" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Daskalakis et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Daskalakis et al\\.",
      "year" : 2015
    }, {
      "title" : "Lossless abstraction of imperfect information games",
      "author" : [ "Andrew Gilpin", "Tuomas Sandholm" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Gilpin and Sandholm.,? \\Q2007\\E",
      "shortCiteRegEx" : "Gilpin and Sandholm.",
      "year" : 2007
    }, {
      "title" : "First-order algorithm with O(ln(1/ )) convergence for -equilibrium in two-person zero-sum games",
      "author" : [ "Andrew Gilpin", "Javier Peña", "Tuomas Sandholm" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Gilpin et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gilpin et al\\.",
      "year" : 2012
    }, {
      "title" : "Automated action abstraction of imperfect information extensive-form games",
      "author" : [ "John Hawkin", "Robert Holte", "Duane Szafron" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Hawkin et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Hawkin et al\\.",
      "year" : 2011
    }, {
      "title" : "Using sliding windows to generate action abstractions in extensive-form games",
      "author" : [ "John Hawkin", "Robert Holte", "Duane Szafron" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Hawkin et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hawkin et al\\.",
      "year" : 2012
    }, {
      "title" : "Fundamentals of convex analysis",
      "author" : [ "Jean-Baptiste Hiriart-Urruty", "Claude Lemaréchal" ],
      "venue" : null,
      "citeRegEx" : "Hiriart.Urruty and Lemaréchal.,? \\Q2001\\E",
      "shortCiteRegEx" : "Hiriart.Urruty and Lemaréchal.",
      "year" : 2001
    }, {
      "title" : "Smoothing techniques for computing Nash equilibria of sequential games",
      "author" : [ "Samid Hoda", "Andrew Gilpin", "Javier Peña", "Tuomas Sandholm" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "Hoda et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Hoda et al\\.",
      "year" : 2010
    }, {
      "title" : "Polynomial-time computation of exact correlated equilibrium in compact games",
      "author" : [ "Albert Jiang", "Kevin Leyton-Brown" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (EC),",
      "citeRegEx" : "Jiang and Leyton.Brown.,? \\Q2011\\E",
      "shortCiteRegEx" : "Jiang and Leyton.Brown.",
      "year" : 2011
    }, {
      "title" : "Accelerating best response calculation in large extensive games",
      "author" : [ "Michael Johanson", "Kevin Waugh", "Michael Bowling", "Martin Zinkevich" ],
      "venue" : "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "Johanson et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Johanson et al\\.",
      "year" : 2011
    }, {
      "title" : "First order methods for nonsmooth convex large-scale optimization, i: general purpose methods",
      "author" : [ "Anatoli Juditsky", "Arkadi Nemirovski" ],
      "venue" : "Optimization for Machine Learning,",
      "citeRegEx" : "Juditsky and Nemirovski.,? \\Q2011\\E",
      "shortCiteRegEx" : "Juditsky and Nemirovski.",
      "year" : 2011
    }, {
      "title" : "First order methods for nonsmooth convex large-scale optimization, ii: utilizing problems structure",
      "author" : [ "Anatoli Juditsky", "Arkadi Nemirovski" ],
      "venue" : "Optimization for Machine Learning,",
      "citeRegEx" : "Juditsky and Nemirovski.,? \\Q2011\\E",
      "shortCiteRegEx" : "Juditsky and Nemirovski.",
      "year" : 2011
    }, {
      "title" : "Efficient computation of equilibria for extensive two-person games",
      "author" : [ "Daphne Koller", "Nimrod Megiddo", "Bernhard von Stengel" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Koller et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Koller et al\\.",
      "year" : 1996
    }, {
      "title" : "Extensive-form game abstraction with bounds",
      "author" : [ "Christian Kroer", "Tuomas Sandholm" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "Kroer and Sandholm.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kroer and Sandholm.",
      "year" : 2014
    }, {
      "title" : "Imperfect-recall abstractions with bounds in games",
      "author" : [ "Christian Kroer", "Tuomas Sandholm" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation",
      "citeRegEx" : "Kroer and Sandholm.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kroer and Sandholm.",
      "year" : 2016
    }, {
      "title" : "Faster first-order methods for extensive-form game solving",
      "author" : [ "Christian Kroer", "Kevin Waugh", "Fatma Kılınç-Karzan", "Tuomas Sandholm" ],
      "venue" : "In Proceedings of the ACM Conference on Economics and Computation (EC),",
      "citeRegEx" : "Kroer et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kroer et al\\.",
      "year" : 2015
    }, {
      "title" : "Monte Carlo sampling for regret minimization in extensive games",
      "author" : [ "Marc Lanctot", "Kevin Waugh", "Martin Zinkevich", "Michael Bowling" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Lanctot et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Lanctot et al\\.",
      "year" : 2009
    }, {
      "title" : "No-regret learning in extensive-form games with imperfect recall",
      "author" : [ "Marc Lanctot", "Richard Gibson", "Neil Burch", "Martin Zinkevich", "Michael Bowling" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "Lanctot et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lanctot et al\\.",
      "year" : 2012
    }, {
      "title" : "Playing large games using simple strategies",
      "author" : [ "Richard Lipton", "Evangelos Markakis", "Aranyak Mehta" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "Lipton et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lipton et al\\.",
      "year" : 2003
    }, {
      "title" : "A polynomial-time Nash equilibrium algorithm for repeated games",
      "author" : [ "Michael Littman", "Peter Stone" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "Littman and Stone.,? \\Q2003\\E",
      "shortCiteRegEx" : "Littman and Stone.",
      "year" : 2003
    }, {
      "title" : "Deepstack: Expert-level artificial intelligence in no-limit poker",
      "author" : [ "Matej Moravč́ık", "Martin Schmid", "Neil Burch", "Viliam Lisỳ", "Dustin Morrill", "Nolan Bard", "Trevor Davis", "Kevin Waugh", "Michael Johanson", "Michael Bowling" ],
      "venue" : "arXiv preprint arXiv:1701.01724,",
      "citeRegEx" : "Moravč́ık et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Moravč́ık et al\\.",
      "year" : 2017
    }, {
      "title" : "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
      "author" : [ "Arkadi Nemirovski" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "Nemirovski.,? \\Q2004\\E",
      "shortCiteRegEx" : "Nemirovski.",
      "year" : 2004
    }, {
      "title" : "Excessive gap technique in nonsmooth convex minimization",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "SIAM Journal of Optimization,",
      "citeRegEx" : "Nesterov.,? \\Q2005\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 2005
    }, {
      "title" : "Smooth minimization of non-smooth functions",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov.,? \\Q2005\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 2005
    }, {
      "title" : "Reduction of a game with complete memory to a matrix game",
      "author" : [ "I. Romanovskii" ],
      "venue" : "Soviet Mathematics,",
      "citeRegEx" : "Romanovskii.,? \\Q1962\\E",
      "shortCiteRegEx" : "Romanovskii.",
      "year" : 1962
    }, {
      "title" : "The state of solving large incomplete-information games, and application to poker",
      "author" : [ "Tuomas Sandholm" ],
      "venue" : "AI Magazine,",
      "citeRegEx" : "Sandholm.,? \\Q2010\\E",
      "shortCiteRegEx" : "Sandholm.",
      "year" : 2010
    }, {
      "title" : "Abstraction for solving large incomplete-information games",
      "author" : [ "Tuomas Sandholm" ],
      "venue" : "In AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Sandholm.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sandholm.",
      "year" : 2015
    }, {
      "title" : "Lossy stochastic game abstraction with bounds",
      "author" : [ "Tuomas Sandholm", "Satinder Singh" ],
      "venue" : "In Proceedings of the ACM Conference on Electronic Commerce (EC),",
      "citeRegEx" : "Sandholm and Singh.,? \\Q2012\\E",
      "shortCiteRegEx" : "Sandholm and Singh.",
      "year" : 2012
    }, {
      "title" : "Abstraction methods for game theoretic poker",
      "author" : [ "Jiefu Shi", "Michael Littman" ],
      "venue" : "In CG ’00: Revised Papers from the Second International Conference on Computers and Games,",
      "citeRegEx" : "Shi and Littman.,? \\Q2002\\E",
      "shortCiteRegEx" : "Shi and Littman.",
      "year" : 2002
    }, {
      "title" : "bluff: Opponent modelling in poker",
      "author" : [ "Finnegan Southey", "Michael Bowling", "Bryce Larson", "Carmelo Piccione", "Neil Burch", "Darse Billings", "Chris Rayner. Bayes" ],
      "venue" : "In Proceedings of the 21st Annual Conference on Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "Southey et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Southey et al\\.",
      "year" : 2005
    }, {
      "title" : "Solving heads-up limit Texas hold’em",
      "author" : [ "Oskari Tammelin", "Neil Burch", "Michael Johanson", "Michael Bowling" ],
      "venue" : "In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "Tammelin et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Tammelin et al\\.",
      "year" : 2015
    }, {
      "title" : "Efficient computation of behavior strategies",
      "author" : [ "Bernhard von Stengel" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Stengel.,? \\Q1996\\E",
      "shortCiteRegEx" : "Stengel.",
      "year" : 1996
    }, {
      "title" : "A unified view of large-scale zero-sum equilibrium computation",
      "author" : [ "Kevin Waugh", "Drew Bagnell" ],
      "venue" : "In Computer Poker and Imperfect Information Workshop at the AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Waugh and Bagnell.,? \\Q2015\\E",
      "shortCiteRegEx" : "Waugh and Bagnell.",
      "year" : 2015
    }, {
      "title" : "Regret minimization in games with incomplete information",
      "author" : [ "Martin Zinkevich", "Michael Bowling", "Michael Johanson", "Carmelo Piccione" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Zinkevich et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Zinkevich et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 31,
      "context" : "Second, even when it does, the iterations of interior-point methods or the simplex algorithm are prohibitively expensive [Sandholm, 2010].",
      "startOffset" : 121,
      "endOffset" : 137
    }, {
      "referenceID" : 31,
      "context" : "Practical methods for EFG solving tackle this issue through two complementary approaches: Abstraction and iterative game solvers with low memory requirements [Sandholm, 2010].",
      "startOffset" : 158,
      "endOffset" : 174
    }, {
      "referenceID" : 27,
      "context" : "The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains.",
      "startOffset" : 59,
      "endOffset" : 77
    }, {
      "referenceID" : 36,
      "context" : "Finally, we complement our theoretical results with numerical experiments to investigate the speed up of FOMs with convergence rate O( ) and compare the performance of these algorithms with the premier regret-based methods CFR and CFR+ [Tammelin et al., 2015].",
      "startOffset" : 236,
      "endOffset" : 259
    }, {
      "referenceID" : 12,
      "context" : ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG.",
      "startOffset" : 100,
      "endOffset" : 1210
    }, {
      "referenceID" : 12,
      "context" : ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al.",
      "startOffset" : 100,
      "endOffset" : 1577
    }, {
      "referenceID" : 12,
      "context" : ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al.",
      "startOffset" : 100,
      "endOffset" : 1782
    }, {
      "referenceID" : 12,
      "context" : ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence.",
      "startOffset" : 100,
      "endOffset" : 1821
    }, {
      "referenceID" : 12,
      "context" : ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes—a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence. In this paper we construct a new weighting scheme for such entropy-based DGFs. This weighting scheme leads to new and improved bounds on the strong convexity parameter associated with general treeplex domains. In particular, our new bounds are first-of-their kind as they have no dependence on the branching operation of the treeplex. Informally, our strong convexity result allows us to improve the convergence rate of FOMs by a factor of Ω(bdd) (where b is the average branching factor for a player and d is the depth of the EFG) compared to the prior state-of-the-art results from Kroer et al. [2015]. Our bounds parallel the simplex case for matrix games where the entropy function achieves a logarithmic dependence on the dimension of the simplex domain.",
      "startOffset" : 100,
      "endOffset" : 2543
    }, {
      "referenceID" : 1,
      "context" : "Bowling et al. [2015] used it to essentially solve the game limit Texas hold’em.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 25,
      "context" : "A slight variation2 of CFR+ was used in the DeepStack agent Moravč́ık et al. [2017], which beat a group of professional players.",
      "startOffset" : 60,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "We also test the impact of stronger bounds on the strong convexity parameter: we instantiate EGT with the parameters developed in this paper, and compare the performance to the parameters developed by Kroer et al. [2015]. These experiments illustrate that the tighter parameters developed here lead to better practical convergence rate.",
      "startOffset" : 201,
      "endOffset" : 221
    }, {
      "referenceID" : 31,
      "context" : "These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010].",
      "startOffset" : 122,
      "endOffset" : 138
    }, {
      "referenceID" : 39,
      "context" : "The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al.",
      "startOffset" : 146,
      "endOffset" : 170
    }, {
      "referenceID" : 22,
      "context" : ", 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+).",
      "startOffset" : 60,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree.",
      "startOffset" : 8,
      "endOffset" : 290
    }, {
      "referenceID" : 6,
      "context" : ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold’em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 · 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate.",
      "startOffset" : 8,
      "endOffset" : 1449
    }, {
      "referenceID" : 6,
      "context" : ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold’em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 · 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT.",
      "startOffset" : 8,
      "endOffset" : 1665
    }, {
      "referenceID" : 6,
      "context" : ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold’em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 · 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT. Kroer et al. [2015] improved these result for the dilated entropy function.",
      "startOffset" : 8,
      "endOffset" : 1771
    }, {
      "referenceID" : 33,
      "context" : "Sequential game abstraction approaches with solution quality bounds have also emerged for stochastic [Sandholm and Singh, 2012] and extensive-form [Lanctot et al.",
      "startOffset" : 101,
      "endOffset" : 127
    }, {
      "referenceID" : 0,
      "context" : "Finally, Bosansky et al. [2014] develop an iterative double-oracle algorithm for exact equilibrium computation.",
      "startOffset" : 9,
      "endOffset" : 32
    }, {
      "referenceID" : 16,
      "context" : "This is known as the sequence-form formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the nonnegative strategy vectors for players 1 and 2 and the sets X ,Y are convex polyhedral reformulations of the sequential strategy space of these players. Here X ,Y are defined by the constraints Ex = e, Fy = f , where each row of E,F encodes part of the sequential nature of the strategy vectors, the right hand-side vectors e, f are |I1| , |I2|-dimensional vectors, and Ii is the information sets for player i. For a complete treatment of this formulation, see von Stengel [1996]. Our theoretical developments mainly exploit the treeplex domain structure and are independent of other structural assumptions resulting from EFGs.",
      "startOffset" : 67,
      "endOffset" : 637
    }, {
      "referenceID" : 16,
      "context" : "We follow the presentation and notation of Juditsky and Nemirovski [2011a,b] for BSPPs. For notation and presentation of treeplex structure, we follow Kroer et al. [2015].",
      "startOffset" : 43,
      "endOffset" : 171
    }, {
      "referenceID" : 28,
      "context" : "Nesterov [2005b] shows that the gradients of the functions φμ2(x) and φ μ1 (y) exist and are Lipschitz continuous.",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 28,
      "context" : "Based on this setup, we formally state the Excessive Gap Technique (EGT) of Nesterov [2005a] in Algorithm 1.",
      "startOffset" : 76,
      "endOffset" : 93
    }, {
      "referenceID" : 37,
      "context" : "For treeplexes, von Stengel [1996] has suggested a polyhedral representation of the form Eu = e where the matrix E has its entries from {−1, 0, 1} and the vector e has its entries in {0, 1}.",
      "startOffset" : 20,
      "endOffset" : 35
    }, {
      "referenceID" : 20,
      "context" : "Note that we allow more than two-way branches; hence our formulation follows that of Kroer et al. [2015] and differs from that of Hoda et al.",
      "startOffset" : 85,
      "endOffset" : 105
    }, {
      "referenceID" : 13,
      "context" : "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 13,
      "context" : "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al. [2010], it is possible to model sequence-form games by treeplexes that use only two-way branches.",
      "startOffset" : 32,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "The treeplex structure is naturally related to the dilation operation [Hiriart-Urruty and Lemaréchal, 2001] defined as follows: Given a compact set K ⊆ Rd and a function f : K → R, we first define",
      "startOffset" : 70,
      "endOffset" : 107
    }, {
      "referenceID" : 15,
      "context" : "It is well-known that ωe(·) is strongly convex with modulus 1 with respect to the `1 norm on ∆n (see Juditsky and Nemirovski [2011a]).",
      "startOffset" : 101,
      "endOffset" : 133
    }, {
      "referenceID" : 13,
      "context" : "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 13,
      "context" : "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes. Since the entropy prox function can be computed in closed form on a simplex, the dilated entropy function can be computed by a single treeplex traversal involving closed-form expressions on each simplex. Definition 3 above leads to a subset of the DGFs considered by Hoda et al. [2010]. Our main theoretical result shows that by a careful selection of the weights βj , we can significantly improve the strong convexity bounds associated with the dilated entropy function.",
      "startOffset" : 0,
      "endOffset" : 532
    }, {
      "referenceID" : 21,
      "context" : "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights βj = 2 MQj they show strong convexity modulus 1 |SQ| w.",
      "startOffset" : 89,
      "endOffset" : 109
    }, {
      "referenceID" : 21,
      "context" : "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights βj = 2 MQj they show strong convexity modulus 1 |SQ| w.r.t. the `1 norm. Corollary 1 improves the prior bounds by exchanging a factor of |SQ| with a factor of MQ. Note that |SQ| is tied to the branching factor associated with branching operations in the treeplex Q whereas MQ is not. Thus, our result removes the dependence of the strong convexity parameter on the branching factor and hence significantly improves upon Kroer et al. [2015]. In Theorem 3 we use our strong convexity result to establish a polytope diameter that has only a logarithmic dependence on the branching factor.",
      "startOffset" : 89,
      "endOffset" : 564
    }, {
      "referenceID" : 21,
      "context" : "Compared to the rate obtained by [Kroer et al., 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al.",
      "startOffset" : 33,
      "endOffset" : 53
    }, {
      "referenceID" : 21,
      "context" : ", 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al., 2015] by a factor of Ω(dX · adX + dY · adY ).",
      "startOffset" : 192,
      "endOffset" : 212
    }, {
      "referenceID" : 13,
      "context" : "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen.",
      "startOffset" : 25,
      "endOffset" : 44
    }, {
      "referenceID" : 13,
      "context" : "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen. 2) At each depth d, a Cartesian product operation of size k is applied. 3) Each element in a Cartesian product is an instance of the base treeplex with a size b branching operation leading to depth d − 1 uniform treeplexes constructed in the same way. Given bounds Ωb, φb for the base treeplex, the bound of Hoda et al. [2010] for a uniform treeplex with d uniform treeplex levels (note that the total depth of the constructed treeplex is d · dQb , where dQb is the depth of the base treeplex Qb) is",
      "startOffset" : 25,
      "endOffset" : 574
    }, {
      "referenceID" : 22,
      "context" : "CFR has a O( 1 2 ) convergence rate; but its dependence on the number of information sets is only linear (and sometimes sublinear [Lanctot et al., 2009]).",
      "startOffset" : 130,
      "endOffset" : 152
    }, {
      "referenceID" : 22,
      "context" : "MCCFR and CFR+ have a similar convergence rate [Lanctot et al., 2009], though MCCFR has cheaper iterations.",
      "startOffset" : 47,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 9,
      "context" : "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix. Specifically, their iteration bound for sequential games is O( ‖A‖2,2·ln(‖A‖2,2/ )· √ D δ(A) ), where δ(A) is the condition number of A, ‖A‖2,2 = supx 6=0 ‖Ax‖2 ‖x‖2 is the Euclidean matrix norm, and D = maxx,x̄∈X ,y,ȳ∈Y ‖(x, y) − (x̄, ȳ)‖2. Unfortunately, the condition number δ(A) is only shown to be finite for these games. Without any such unknown quantities based on condition numbers, Gilpin et al. [2012] establish a convergence rate of O( ‖A‖2,2·D ).",
      "startOffset" : 0,
      "endOffset" : 587
    }, {
      "referenceID" : 35,
      "context" : "We test these algorithms on a scaled up variant of the poker game Leduc holdem [Southey et al., 2005], a benchmark problem in the imperfect-information game-solving community.",
      "startOffset" : 79,
      "endOffset" : 101
    }, {
      "referenceID" : 35,
      "context" : "We compare the performance of EGT to that of CFR and CFR+ algorithms on a scaled up variant of the poker game Leduc hold’em [Southey et al., 2005], a benchmark problem in the",
      "startOffset" : 124,
      "endOffset" : 146
    }, {
      "referenceID" : 21,
      "context" : "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set βj relative to αj .",
      "startOffset" : 130,
      "endOffset" : 150
    }, {
      "referenceID" : 21,
      "context" : "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set βj relative to αj . Experimentally, we found that the best way to instantiate the recurrence is to use βj = αj for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights).",
      "startOffset" : 130,
      "endOffset" : 523
    }, {
      "referenceID" : 21,
      "context" : "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set βj relative to αj . Experimentally, we found that the best way to instantiate the recurrence is to use βj = αj for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights). Figure 2 shows the result of running EGT with the old and the new weights. For both the old and the new weights, we found that the scalars MQ and |SQ| applied to each DGF in order to achieve strong convexity modulus 1 according to Corollary 1 and Theorem 5.4 of Kroer et al. [2015], respectively, are too conservative.",
      "startOffset" : 130,
      "endOffset" : 846
    }, {
      "referenceID" : 21,
      "context" : "Figure 2: Regret as a function of the number of iterations for EGT with our weighting scheme (EGT new) and with the weighting scheme from Kroer et al. [2015] (EGT old).",
      "startOffset" : 138,
      "endOffset" : 158
    }, {
      "referenceID" : 19,
      "context" : "In Kroer et al. [2015] it was found that, while EGT has better convergence rate, CFR (which performs worse than CFR+) had better initial performance, and it was only after a certain number of iterations that EGT took over.",
      "startOffset" : 3,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "This sentiment has been mirrored by Brown and Sandholm [2016]. In contrast to this, we find that our DGF along with proper initialization leads to EGT performing better than",
      "startOffset" : 36,
      "endOffset" : 62
    }, {
      "referenceID" : 15,
      "context" : "For games where accelerated bestresponse calculation [Johanson et al., 2011] can be applied, e.",
      "startOffset" : 53,
      "endOffset" : 76
    }, {
      "referenceID" : 4,
      "context" : "But, for some other games, this aspect can be important, though note that Brown et al. [2017] showed experimentally that pruning can be used in EGT as well.",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 31,
      "context" : "On a separate note, in practice CFR is often paired with an abstraction technique [Sandholm, 2010] such as those mentioned in Section 2.",
      "startOffset" : 82,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "Effective ways to pair FOMs such as MP and EGT with practical abstraction techniques [Brown et al., 2015] or abstraction techniques that achieve solution-quality guarantees [Lanctot et al.",
      "startOffset" : 85,
      "endOffset" : 105
    } ],
    "year" : 2017,
    "abstractText" : "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function—a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that only a logarithmic dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of Ω(bd), where b is the branching factor of the player, and d is the depth of the game tree. Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice.",
    "creator" : "LaTeX with hyperref package"
  }
}