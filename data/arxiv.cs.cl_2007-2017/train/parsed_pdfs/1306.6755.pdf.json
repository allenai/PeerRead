{
  "name" : "1306.6755.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "kdarwish@qf.org.qa" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 6.\n67 55\nv1 [\ncs .C\nL ]\n2 8\nJu n\nArabizi is Arabic text that is written using Latin characters. Arabizi is used to present both Modern Standard Arabic (MSA) or Arabic dialects. It is commonly used in informal settings such as social networking sites and is often with mixed with English. In this paper we address the problems of: identifying Arabizi in text and converting it to Arabic characters. We used word and sequence-level features to identify Arabizi that is mixed with English. We achieved an identification accuracy of 98.5%. As for conversion, we used transliteration mining with language modeling to generate equivalent Arabic text. We achieved 88.7% conversion accuracy, with roughly a third of errors being spelling and morphological variants of the forms in ground truth."
    }, {
      "heading" : "1 Introduction",
      "text" : "Arabic is often written using Latin characters in transliterated form, which is often referred to as Arabizi, Arabish, Franco-Arab, and other names. Arabizi uses numerals to represent Arabic letters for which there is no phonetic equivalent in English or to account for the fact that Arabic has more letters than English. For example, “2” and “3” represent the letters @ (that sounds like “a” as in apple) and ¨ (that is a guttural “aa”) respectively. Arabizi is particularly popular in Arabic social media. Arabizi has grown out of a need to write Arabic on systems that do not support Arabic script natively. For example, Internet Explorer 5.0, which was released in March 1999, was the first version\nof the browser to support Arabic display natively1. Windows Mobile and Android did not support Arabic except through third party support until versions 6.5x and 3.x respectively. Despite the increasing support of Arabic in many platforms, Arabizi continues to be popular due to the familiarity of users with it and the higher proficiency of users to use an English keyboard compared to an Arabic keyboard. Arabizi is used to present both MSA as well as different Arabic dialects, which lack spelling conventions and differ morphologically and phonetically from MSA. Additionally, due to the fact that many of the Arabic speakers are bilingual (with their second language being either English or French), another commonly observed phenomenon is the presence of English (or French) and Arabizi mixed together within sentences, where users code switch between both languages. In this paper we focus on performing two tasks, namely: detecting Arabizi even when juxtaposed with English; and converting Arabizi to Arabic script regardless of being MSA or dialectal. Detecting and converting Arabizi to Arabic script would help: ease the reading of the text, where Arabizi is difficult to read; allow for the processing of Arabizi (post conversion) using existing NLP tools; and normalize Arabic and Arabizi into a unified form for text processing and search. Detecting and converting Arabizi are complicated by the following challenges:\n1. Due to the lack of spelling conventions for Arabizi and Arabic dialectal text, which Arabizi often encodes, building a comprehensive dictio-\n1http://en.wikipedia.org/wiki/Internet_Explorer\nnary of Arabizi words is prohibitive. Consider the following examples:\n(a) The MSA word QK Qm ' (liberty) has the fol-\nlowing popular Arabizi spellings: ta7rir, t7rir, tahrir, ta7reer, tahreer, etc.\n(b) The dialectal equivalents to the MSA I. ªÊK B (he does not play) could be .ªÊJ K. AÓ, .ªÊK. AÓ, .ªÊJ Ó, .ªÊK AÓ\netc. The resultant Arabizi could be: mayel3absh, mabyelaabsh, mabyel3absh, etc.\n2. Some Arabizi and English words share a common spelling, making solely relying on an English dictionary insufficient to identify English words. Consider the following examples (ambiguous words are bolded):\n(a) Ana 3awez aroo7 men America leh Canada (I want to go from America to Canada). The word “men” meaning “from” is also an English word.\n(b) I called Mohamed last night. “Mohamed” in this context is an English word, though it is a transliterated Arabic name.\n3. Within social media, users often use creative spellings of English words to shorten text, emphasize, or express emotion. This can complicate the differentiation of English and Arabizi. Consider the following examples:\n(a) I want 2 go with u tmrw, cuz my car is broken.\n(b) Woooooow. Ur car is cooooooool.\nDue to these factors, classifying a word as Arabizi or English has to be done in-context. Thus, we employed sequence labeling using Conditional Random Fields (CRF) to detect Arabizi in context. The CRF was trained using word-level and sequencelevel features. For converting Arabizi to Arabic script, we used transliteration mining in combination with a large Arabic language model that covers both MSA and other Arabic dialects to properly choose the best transliterations in context.\nThe contributions of this paper are:\n• We employed sequence labeling that is trained using word-level and sequence-level features to identify in-sentence code-switching between two languages that share a common alphabet.\n• We used transliteration mining and language modeling to convert form Arabizi to Arabic script.\n• We plan to publicly release all our training and test data.\nThe remainder of the paper is organized as follows: Section 2 provides related work; Section 3 presents our Arabizi detection and reports on the detection accuracy; Section 4 describes our Arabizi to Arabic conversion approach and reports the accuracy of conversion; and Section 5 concludes the paper."
    }, {
      "heading" : "2 Related Work",
      "text" : "There are two aspects to this work: the first is language identification, and the second is transliteration. There is much work on language identification including open source utilities, such as the Language Detection Library for Java2. Murthy and Kumar (2006) surveyed many techniques for language identification. Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regressionlike classification that employed so-called “aksharas” which are sub-word character sequences as features for identifying different Indian languages. Ehara and Tanaka-Ishii (2008) developed an online language detection system that detects code switching during typing, suggests the language to switch to to the user, and interactively invokes the appropriate text entry method. They used HMM based language identification in conjunction with an n-gram character language model. They reported up to 97% accuracy when detecting between two languages on a synthetic test set. In our work, we performed offline word-level language identification using CRF sequence labeling, which con-\n2http://code.google.com/p/language-detection/\nceptually combines logistic regression-like discriminative classification with an HMM-like generative model (Lafferty et al., 2001). We opted to use a CRF sequence labeling because it allowed us to use both state and sequence features, which in our case corresponded to word- and sequence-level features respectively. One of the downsides of using a CRF sequence labeler is that most implementations, including CRF++ which was used in this work, only use nominal features. This required us to quantize all real-valued features.\nConverting between from Arabizi to Arabic is akin to transliteration or Transliteration Mining (TM). In transliteration, a sequence in a source alphabet or writing system is used to generate a phonetically similar sequence in a target alphabet or writing system. In TM, a sequence in a source alphabet or writing system is used to find the most similar sequence in a lexicon that is written in the target alphabet or writing system. Both problems are fairly well studied with multiple evaluation campaigns, particularly at the different editions of the Named Entities Workshop (NEWS) (Zhang et al., 2011; Zhang et al., 2012). In our work we relied on TM from a large corpus of Arabic microblogs. TM typically involves using transliteration pairs in two different writing systems or alphabets to learning character (or character-sequence) level mappings between them. The learning can be done using the EM algorithm (Kuo et al., 2006) or HMM alignment (Udupa et al., 2009). Once these mappings are learned, a common approach involves using a generative model that attempts to generate all possible transliterations of a source word, given the character mappings between two languages, and restricting the output to words in the target language (El-Kahki et al., 2011; Noeman and Madkour, 2010). Other approaches include the use of locality sensitive hashing (Udupa and Kumar, 2010) and classification (Jiampojamarn et al., 2010). Another dramatically different approaches involves the unsupervised learning of transliteration mappings from a large parallel corpus instead of transliteration pairs (Sajjad et al., 2012). In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that\nconvert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5. Since they are IMEs, they only work in an interactive mode and don’t allow for batch processing. Thus they are difficult to compare against. Also, from interactively using Arabic IMEs, it seems that they only use unigram language modeling."
    }, {
      "heading" : "3 Identifying Arabizi",
      "text" : "As mentioned earlier, classifying words as English or Arabizi requires the use of word-level and sequence-level features. We opted to use CRF sequence labeling to identify Arabizi words. We used the CRF++ implementation with default parameters (Sha and Pereira, 2003). We constructed training and test sets for word-level language classification from tweets that contain English, Arabizi, or a mixture of English and Arabizi. We collected the tweets in the following manner:\n1. We issued commonly used Arabizi words as queries against Twitter multiple times. These words were “e7na” (we), “3shan” (because), and “la2a” (no). We issued these queries every 30 seconds for roughly 1 hour. We put large time gaps between queries to insure that the results were refreshed.\n2. We extracted the user IDs of all the authors of the tweets that we found, and used the IDs as queries to Twitter to get the remaining tweets that they have authored. Our intuition was that tweeps who authored once in Arabizi would likely have more Arabizi tweets. Doing so helped us find Arabizi tweets that don’t necessarily have the aforementioned common words and helped us find significantly more Arabizi text. In all we identified 265 tweeps who authored 16,507 tweets in the last 7 days, containing 132,236 words. Of the words in the tweets, some of them were English, but most of them were Arabizi.\nWe filtered tweets where most of the words contained Arabic letters. As in Table 1, all the tokens in the set were manually labeled as English (“e”), Arabizi (“a”), or other (“o”). For training, we used 522\n3http://www.yamli.com/editor/ar/ 4http://www.getmaren.com 5http://www.google.com/ta3reeb\ntweets, containing 5,207 tokens. The breakdown of tokens is: 3,307 English tokens; 1,203 Arabizi tokens; and 697 other tokens. For testing, we used 101 tweets containing 3,491 tokens. The breakdown of the tokens is: 797 English tokens; 1,926 Arabizi tokens; and 768 other tokens. Though there is some mismatch in the distribution of English and Arabizi tokens between training and test sets, this mismatch happened naturally and is unlikely to affect overall accuracy numbers. For language models, we trained two character level language models: the first using 9.4 million English words; and the second using 1,000 Arabizi words (excluding words in the test set). We used the BerkeleyLM language modeling toolkit.\nWe trained the CRF++ implementation of CRF sequence labeler using the features in Table 2 along with the previous word and next word. The Table describes each feature and shows the features values for the word “Yesss”.\nTable 3 reports on the language identification results and breaks down the results per word type and provides examples of mislabeling. Overall we achieved a word-level language identification accuracy of 98.5%. As the examples in the table show, the few mislabeling mistakes included: Arabized English words, Arabizi words that happen to be English words, single Arabizi words surrounded by English words (or vice versa), and misspelled English words."
    }, {
      "heading" : "4 Arabizi to Arabic",
      "text" : "As mentioned earlier, Arabizi is simply Arabic, whether MSA or dialectal, that is written using Latin characters. We were able to collecting Arabizi text by searching for common Arabizi words on Twitter, identifying the authors of these tweets, and then scraping their tweets to find more tweets written in Arabizi. In all, we constructed a collection that contained 3,452 training pairs that have both Arabizi and Arabic equivalents. All Arabizi words were\nmanually transliterated into Arabic manually by a native Arabic speaker. Some example pairs are:\n• 3endek → ¼Y J« (meaning “in your care”) • bytl3 → ©Ê¢J K. (meaning “he ascends”)\nFor testing, we constructed a set of 127 random Arabizi tweets containing 1,385 word. Again, we had a native Arabic speaker transliterate all tweets into Arabic script. An example sentences is:\n• sa7el eih ? howa ntii mesh hatigi bokra → èQºK. ú j. J Jë Ó ú\næ K @ ñë ? éK @ ÉgA • meaning: what coast ? aren’t you coming to-\nmorrow\nWe applied the following preprocessing steps on the training and test data:\n• We performed the following Arabic letter normalizations (Habash, 2010):\n– ø (alef maqsoura) → ø (ya)\n– @ (alef maad), @ (alef with hamza on top),\nand @ (alef with hamza on the bottom) → @ (alef)\n– ð' (hamza on w), and Zø' (hamza on ya) → Z (hamza)\n– è (taa marbouta) → è (haa)\n• Since people often repeat letters in tweets to indicate stress or to express emotions, we removed any repetition of a letter beyond 2 repetitions (Darwish et al., 2012). For example, we transformed the word “salaaaam” to “salaam”.\n• Many people tend to segment Arabic words in Arabizi into separate constituent parts. For example, you may find “w el kitab” (meaning “and the book”) as 3 separate tokens, while in Arabic they are concatenated into a single token, namely “H. A JºË @ð”. Thus, we concatenated short tokens that represent coordinating conjunctions and prepositions to the tokens that follow them. These tokens are: w, l, el, ll, la, we, f, fel, fil, fl, lel, al, wel, and b.\n• We directly transliterated the words “isA” and “jAk” to “ é <Ë @ Z A à@ ” (meaning “God welling”) and to “ @Q g é\n<Ë @ ¼@ Qk. ” (meaning “may God reward you”) respectively.\nFor training, we aligned the word-pairs at character level. The pairs were aligned using GIZA++ and the phrase extractor and scorer from the Moses machine translation package (Koehn et al., 2007) . To apply a machine translation analogy, we treated words as sentences and the letters from which were constructed as tokens. The alignment produced letter sequence mappings. The alignment produced mappings between Latin letters sequences and Ara-\nbic letter sequences with associated mapping probabilities. For example, here is a sample mapping:\n• 2r → Q̄ (p = 0.459) To generate Arabic words from Arabizi words, we made the fundamental simplifying assumption that any generated Arabic word should exist in a large word list. Though the assumption fundamentally limits generation to previously seen words only, we built the word list from a large set of tweets. Thus, the probability that a correctly generated word did not exist in the word list would be negligible. This assumption allowed us to treat the problem as a mining problem instead of a generation problem where\nour task was to find a correct transliteration in a list of words instead of generating an arbitrary word. We built the word list from a tweet set containing a little over 112 million Arabic tweets that we scraped from Twitter between November 20, 2011 and January 9, 2012. We collected the tweets by issuing the query “lang:ar” against Twitter. We utilized the tweet4j package for collection. The tweet set had 5.1 million unique words, and nearly half of them appeared only once.\nOur method involved doing two steps:\nProducing candidate transliterations: We implemented transliteration in a manner that is akin to the baseline system in El-Kahki et al. (2011). Given an Arabizi word waz , we produced all its possible segmentations along with their associated mappings into Arabic characters. Valid target sequences were retained and sorted by the product of the constituent mapping probabilities. The top n (we picked n = 10) candidates, war1..n with the highest probability were generated. Using Bayes rule, we computed:\nargmax wari∈1..n\np(wari |waz) = p(waz|wari)p(wari) (1)\nwhere p(waz|wari) is the posterior probability of mapping, which is computed as the product of the mappings required to generate waz from wari , and p(wari) is the prior probability of the word.\nPicking the best candidate in context: We utilized a large word language model to help pick the best transliteration candidate in context. We built a trigram language model using the IRSTLM language modeling toolkit (Federico et al., 2008). The advantage of this language model was that it contained both MSA and dialectal text. Given the top transliteration candidates and the language model we trained, we wanted to find the transliteration that would maximize the transliteration probability and language model probability. Given a word wi with candidates wi1−10 , we wanted to find wi ∈ wi1−10 that maximizes the product of the transliteration probabilities (for all the candidates for all the words in the path) and the path probability, where the probability of the path is estimated using the trigram language model.\nFor testing, we used the aforementioned set of 127 random Arabizi tweets containing 1,385 word. We performed two evaluations as follows:\nOut of context evaluation. In this evaluation we wanted to evaluate the quality of the generated list of candidates. Intuitively, a higher rank for the correct transliteration in the list of transliterations is desirable. Thus, we used Mean Reciprocal Rank (MRR) to evaluate the generated candidates. Reciprocal Rank (RR) is simply 1\nrank of the correct candi-\ndate. If the correct candidate is not in the generated list, we assumed that the rank was very large and we set RR = 0. MRR is the average across all test cases. Notice that RR is 1 if the correct candidate is at position 1, 0.5 if correct is at position 2, etc. Thus the penalty for not being at rank 1 is quite severe. For out of context evaluation, we achieved an MRR of 0.84. Table 4 shows the breakdown of the ranks of the correct transliterations in the test set. As can be seen, the correct candidate was at position one 77.1% of the time. No correct candidates were found 4.9% of the time. This meant that the best possible accuracy that we could achieve for in context evaluation was 95.1%. Further, we examined the 68 words for which we did not generate a correct candidate. Table 5 categorizes the 68 words (words are presented using Arabic script and Buckwalter encoding). Since Arabic dialects do not have a standard spelling convention, some of the word that we generated had a variant spelling from the ground truth. Also in other cases, the correct morphological form did not exist in the word list or was infrequent. In some of these cases, we generated morphologically\nrelated candidates that have an affix added or removed. Some example affixes including coordinating conjunctions, prepositions, and feminine markers.\nIn context evaluation. In this evaluation, we computed accuracy of producing the correct transliterated equivalent in context. For in context evaluation, if we used a baseline that used the top out-ofcontext choice, we would achieve 77.1% accuracy. Adding a trigram language model, we achieved an accuracy of 88.7% (157 wrong out of 1,385). Of the wrong guesses, 91 were completely unrelated words and 46 were spelling or morphological variants."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we presented methods of detecting Arabizi that is mixed with English text and converting Arabizi to Arabic. For language detection we used a sequence labeler that used word and character level features. Language detection was trained and tested on datasets that were constructed from tweets.\nWe achieved an overall accuracy of 98.5%. For converting from Arabizi to Arabic, we trained a transliteration miner that attempted to find the most likely Arabic word that could have generated an Arabizi word. We used both character transliteration probabilities as well as language modeling. We achieved 88.7% transliteration accuracy.\nFor future work, we would like to experiment with additional training data and improved language models that account for the morphological complexities of Arabic. Also, the lack of spelling conventions for Arabic dialects may warrant detecting variant spellings of individual dialectal words and perhaps converting from dialectal text to MSA."
    } ],
    "references" : [ {
      "title" : "Using foreign inclusion detection to improve parsing performance",
      "author" : [ "Alex et al.2007] B. Alex", "A. Dubey", "F. Keller" ],
      "venue" : "In Proceedings of EMNLP-CoNLL",
      "citeRegEx" : "Alex et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Alex et al\\.",
      "year" : 2007
    }, {
      "title" : "Language Identifier: A computer program for automatic natural-language identification of on-line text",
      "author" : [ "K. Beesley" ],
      "venue" : "Proceedings of the 29th Annual Conference of the American Translators Association,",
      "citeRegEx" : "Beesley.,? \\Q1988\\E",
      "shortCiteRegEx" : "Beesley.",
      "year" : 1988
    }, {
      "title" : "Language processing for arabic microblog retrieval",
      "author" : [ "Walid Magdy", "Ahmed Mourad" ],
      "venue" : "Proceedings of the 21st ACM international conference on Information and knowledge management",
      "citeRegEx" : "Darwish et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Darwish et al\\.",
      "year" : 2012
    }, {
      "title" : "Statistical identification of language",
      "author" : [ "T. Dunning" ],
      "venue" : "Technical Report, CRL MCCS-94273,",
      "citeRegEx" : "Dunning.,? \\Q1994\\E",
      "shortCiteRegEx" : "Dunning.",
      "year" : 1994
    }, {
      "title" : "Multilingual text entry using automatic language detection",
      "author" : [ "Ehara", "Tanaka-Ishii2008] Y. Ehara", "K. Tanaka-Ishii" ],
      "venue" : "In Proceedings of IJCNLP-2008",
      "citeRegEx" : "Ehara et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Ehara et al\\.",
      "year" : 2008
    }, {
      "title" : "Improved transliteration mining using graph reinforcement",
      "author" : [ "Kareem Darwish", "Ahmed Saad Aldein", "Mohamed Abd El-Wahab", "Ahmed Hefny", "Waleed Ammar" ],
      "venue" : "In Proceedings of the Conference on Empirical Methods",
      "citeRegEx" : "El.Kahky et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "El.Kahky et al\\.",
      "year" : 2001
    }, {
      "title" : "IRSTLM: an open source toolkit for handling large scale language models",
      "author" : [ "Nicola Bertoldi", "Mauro Cettolo" ],
      "venue" : "Proceedings of Interspeech",
      "citeRegEx" : "Federico et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Federico et al\\.",
      "year" : 2008
    }, {
      "title" : "Introduction to Arabic natural language processing",
      "author" : [ "Nizar Habash" ],
      "venue" : "Synthesis Lectures on Human Language Technologies",
      "citeRegEx" : "Habash.,? \\Q2010\\E",
      "shortCiteRegEx" : "Habash.",
      "year" : 2010
    }, {
      "title" : "Language identification",
      "author" : [ "Bharadwaja Kumar" ],
      "venue" : null,
      "citeRegEx" : "Kumar.,? \\Q2006\\E",
      "shortCiteRegEx" : "Kumar.",
      "year" : 2006
    }, {
      "title" : "A Statistical Model for Unsu",
      "author" : [ "mut Schmid" ],
      "venue" : null,
      "citeRegEx" : "Schmid.,? \\Q2012\\E",
      "shortCiteRegEx" : "Schmid.",
      "year" : 2012
    }, {
      "title" : "They Are Out",
      "author" : [ "Anton Bakalov", "Abhijit Bhole" ],
      "venue" : null,
      "citeRegEx" : "Bakalov and Bhole.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bakalov and Bhole.",
      "year" : 2009
    }, {
      "title" : "Language identification",
      "author" : [ "G. Almpanidis", "I. Pitas" ],
      "venue" : null,
      "citeRegEx" : "Almpanidis and Pitas.,? \\Q2004\\E",
      "shortCiteRegEx" : "Almpanidis and Pitas.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al.",
      "startOffset" : 67,
      "endOffset" : 97
    }, {
      "referenceID" : 3,
      "context" : "Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al.",
      "startOffset" : 67,
      "endOffset" : 97
    }, {
      "referenceID" : 3,
      "context" : "Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994).",
      "startOffset" : 209,
      "endOffset" : 249
    }, {
      "referenceID" : 6,
      "context" : "Murthy and Kumar (2006) surveyed many techniques for language identification.",
      "startOffset" : 11,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "Some of the more successful techniques use character n-gram models (Beesley, 1988; Dunning, 1994) in combination with a machine learning technique such as hidden Markov models (HMM) or Bayesian classification (Xafopoulos et al., 2004; Dunning, 1994). Murthy and Kumar (2006) used logistic regression-",
      "startOffset" : 68,
      "endOffset" : 275
    }, {
      "referenceID" : 5,
      "context" : "In our work, we used the baseline system of El-Kahky et al. (2011). There are three commercial Input Method Editors (IMEs) that convert from Arabizi to Arabic, namely: Yamli3, Microsoft Maren4, and Google t3reeb5.",
      "startOffset" : 44,
      "endOffset" : 67
    }, {
      "referenceID" : 7,
      "context" : "• We performed the following Arabic letter normalizations (Habash, 2010):",
      "startOffset" : 58,
      "endOffset" : 72
    }, {
      "referenceID" : 2,
      "context" : "titions (Darwish et al., 2012).",
      "startOffset" : 8,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "guage modeling toolkit (Federico et al., 2008).",
      "startOffset" : 23,
      "endOffset" : 46
    } ],
    "year" : 2013,
    "abstractText" : "Arabizi is Arabic text that is written using Latin characters. Arabizi is used to present both Modern Standard Arabic (MSA) or Arabic dialects. It is commonly used in informal settings such as social networking sites and is often with mixed with English. In this paper we address the problems of: identifying Arabizi in text and converting it to Arabic characters. We used word and sequence-level features to identify Arabizi that is mixed with English. We achieved an identification accuracy of 98.5%. As for conversion, we used transliteration mining with language modeling to generate equivalent Arabic text. We achieved 88.7% conversion accuracy, with roughly a third of errors being spelling and morphological variants of the forms in ground truth.",
    "creator" : "LaTeX with hyperref package"
  }
}