{
  "name" : "1202.6157.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Distributed Power Allocation with SINR Constraints Using Trial and Error Learning",
    "authors" : [ "Luca Rose", "Samir M. Perlaza", "Mérouane Debbah", "Christophe J. Le Martret" ],
    "emails" : [ "luca.rose@thalesgroup.com", "merouane.debbah)@supelec.fr", "martret@thalesgroup.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nIn this paper, we consider a network where several transmitter-receiver pairs communicate through a common bandwidth divided into several orthogonal sub-bands, thus, subject to mutual interference. All devices must guarantee certain quality of service (QoS), expressed in terms of signal to interference plus noise ratio (SINR). The behaviour of the devices is designed for achieving a stable network operating point (equilibrium) where the maximum number of communicating pairs satisfy their QoS with the minimum global power consumption. Network operating point must be achieved by the radio devices in a fully decentralized way by selecting their power allocation policy, i.e., selecting a sub-band and a power level for each transmission. In this scenario, all communications take place in absence of a centralized controller and neither cooperation nor exchange of information between different pairs are considered. For instance, this scenario may model the case of tactical radios and ad hoc networks, where, in order to set power and channel, current solutions require a certain level of cooperation with exchange of information between the devices or a manual setting. The closest works to ours are [1], [2] and [3]. In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game,\nthen best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE. It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.e, the possible power allocation (PA) vectors may take any value in the corresponding simplex. Conversely, in our work, we consider a finite action set by quantizing the possible available powers into a certain amount of levels. Basically, this is because in practice power levels must be expressed in a finite amount of bits. Moreover, several authors have pointed out that better global performance (e.g. spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8]. Indeed, this effect has been reported as a Braess kind paradox [9]. In this paper, our contribution is twofold: first, we present a fully decentralized learning algorithm able to keep the SINR level above a certain threshold a high proportion of the time, by means of only one bit feedback and relying only on local information [4]; second, we analytically study the convergence properties and the convergence point, which is shown to be an efficient Nash equilibrium (NE) in terms of global performance. The paper is organized as follows. In Sec. II, we describe the wireless scenario and we formalize the problem; in Sec. III, we model the system as a game in normal form and in satisfaction form; in Sec. IV we present the trial and error algorithm as introduced in [10]; in Sec. V, we present a formal analytical study of the convergence properties (i.e., expected number of iterations to reach the NE and the satisfaction equilibrium (SE)), as well as, the expected fraction of time the system is at the NE and at the SE; in Sec. VI we validate our analysis through numerical simulations; the paper is concluded in Sec. VII."
    }, {
      "heading" : "II. SYSTEM MODEL",
      "text" : "Let us consider the system described in Fig. 1. Here, a set K 4= {1, ...,K} of transmitter-receiver pairs share a set C 4= { b(1), ..., b(C) } of orthogonal sub-bands. Transmitter k\nis allowed to transmit over one sub-band at a time at a given power level. We denote by pk ∈ P, with P 4 = {0, ..., PMAX}, |P| = Q, and bk ∈ C, the power level and the frequency sub-band chosen by transmitter k respectively. We denote by\nar X\niv :1\n20 2.\n61 57\nv1 [\ncs .G\nT ]\n2 8\nFe b\n20 12\nTx Rx\np = (p1, p2, ..., pK) the network power allocation vector, by b = (b1, b2, ..., bK) the spectrum occupation vector and by a = (a1, a2, ..., aK) a network configuration vector, where ak = (pk, bk). To communicate, pairs have to achieve a sufficient SINR level, i.e., SINRk > Γ where we denote by Γ the minimum SINR threshold allowing transmission. Receivers treat interference as Gaussian noise, thus:\nSINRk (a) = pkg\n(bk) k,k σ2 + ∑ l∈K\\k plg (bl) k,l 1{bl=bk} , (1)\nwhere g(b)k,l represents the channel power gain between transmitter l and receiver k over sub-band b, σ2 is the power of the thermal noise assumed constant over the whole spectrum and 1{} represents the indicator function. In our scenario, we assume block-fading channels, i.e., channel realizations are time invariant for the whole transmission. Our objective is the satisfaction of the SINR constraints for the largest possible set of pairs by using the lowest global energy consumption. Formally, we want the network configuration vector a∗ to be a solution of the following optimization problem{\nminp∈PK ∑K k=1 pk(n) s.t. SINRk (a) > Γ ∀k ∈ K∗ , (2)\nwhere we denote by K∗ ⊆ K the largest subset of links able to simultaneously achieve a sufficient SINR level. Generally, to achieve this goal a central controller knowing all the network’s parameters is required. In the following sections, we propose a decentralized algorithm demanding no information on the network which will steer the system to a solution of (2)."
    }, {
      "heading" : "III. GAME FORMULATION",
      "text" : "In this section, we model the scenario presented in Sec 1 in two different formulations: a normal-form game and a satisfaction-form [11] game.\nA. Normal form formulation\nWe model the network described above by the game in normal form\nG = ( K,A, {uk}k∈K ) . (3)\nHere, K represents the set of players, A is the joint set of actions, that is, A = A1 × A2 × ... × AK where Ak = C × P and we introduce the utility function uk : A → R defined by:\nuk(a) = 1\n1 + β ( PMAX − pk PMAX + β1{SINRk(a)>Γ} ) , (4)\nwhere β is a design parameter discussed in Sec V. This function has been designed to be monotonically decreasing with the power consumption, and monotonically increasing with the number of players who achieve the minimum SINR. In the following, we show that, with this utility function, the NE of the game G can solve the problem stated in (2). Moreover, note that to evaluate (4) each transmitter only requires local information, since 1{SINRk(a)>Γ} can easily be fed back by the receiver with 1 bit.\nDefinition 1: (Interdependent game). G is said to be interdependent if for every non-empty subset K+ ⊂ K and every action profile a = (aK+ ,a−K+)\n1 such that aK+ is the action profile of all players in K+, it holds that:\n∃i /∈ K+, ∃a′K+ 6= aK+ : ui(a ′ K+ ,a−K+) 6= ui(aK+ ,a−K+)\n(5) In the following, we assume that game G is interdependent. This is a reasonable assumption, since, physically, this means that no link is isolated from the others. The solution concept used under this formulation is the Nash equilibrium, which we define as follows:\nDefinition 2: (Nash equilibrium in pure strategies). An action profile a∗ ∈ A is a NE of game G if ∀ k ∈ K and ∀a′k ∈ Ak\nuk(a ∗ k, a ∗ −k) ≥ uk(a ′ k, a ∗ −k). (6)\nTo measure the efficiency of each NE, we introduce the social welfare function, defined by the sum of all individual utilities: W (a) = ∑K k=1 uk(a).\nB. Satisfaction form\nThe satisfaction form is a game theoretical formulation modelling scenarios where players are exclusively interested in the satisfaction of their individual QoS constraints. Let us define the game as\nG′ = ( K,A, {fk}k∈K ) , (7)\nwhere K, A follow the previous definitions and the satisfaction correspondence fk : A−k → R is defined by\nfk(a−k) = (ak ∈ Ak : SINRk(ak,a−k, ) ≥ Γ) . (8)\nThe solution concept used under this formulation is the satisfaction equilibrium (SE) defined as:\nDefinition 3: (Satisfaction equilibrium). A satisfaction equilibrium of game G′ is an action profile a′ ∈ A such that ∀k ∈ K,\na′k ∈ fk ( a′−k ) . (9)\nMoreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] Φk : Ak → [0, 1]. We can, then, define an efficient satisfaction equilibrium (ESE) as:\nDefinition 4: (Efficient satisfaction equilibrium). A satisfaction equilibrium a′ is said to be efficient, if ∀k ∈ K\na′k ∈ arg min ak∈fk(a′−k) Φk(ak) (10)\n1Here, a−K+ refers to the action profile of all the players that are not in K+\nIn brief, an ESE is an action profile where all players are satisfied and no player may decrease its individual effort by unilateral deviation. Since our optimization problem is to minimize the overall transmit power, we identify the effort by the function: Φk(ak) = pk."
    }, {
      "heading" : "IV. ALGORITHM DESCRIPTION",
      "text" : "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12]. Later, we characterize the degrees of freedom of the system to fit in our scenario. In TE learning, each player k locally implements a state machine, at each iteration n, a state is defined by the triplet:\nZk(n) = {mk(n), āk(n), ūk(n)} , (11)\nwhere mk(n) ∈ {C,C+, C−, D} represents a ”mood”, i.e., a characteristic that defines the machine reaction to its experience of the environment, āk ∈ A and ūk ∈ [0, 1] represents a benchmark action and benchmark utility, respectively. There are four possible moods: content (C), watchful (C−), hopeful (C+), discontent (D). In the following, we characterize the behaviour of each player in every possible mood. • Content\nIf at stage n player k is content, it uses the benchmarked action āk(n) with probability (1 − ) and experiments a new action a′k(n) with probability . If at stage n the player decided to experiment, at stage (n + 1) it evaluates the utility u′k(n + 1) associated with a′k(n) as follows: if u ′ k(n + 1) < ūk(n) then Zk(n + 1) = Zk(n), otherwise if u′k(n + 1) > ūk(n), then, with probability G(u ′ k(n+1)−ūk(n)), a new action and utility benchmark are set out, i.e., ūk(n+ 1) = u′k(n+ 1) and āk(n+ 1) = a′k(n), respectively. Here, G(·) must be such that:\n0 < G(∆u) < 1\n2 , (12)\nwe opt for a linear formulation: G(∆u) = −0.2∆u+ 0.2. • Hopeful-Watchful\nIf player k achieves an increment or a decrement in its utility without having experimented at the previous stage, then the mood become hopeful or watchful, according to the following rule: (i) if u′k(n + 1) > ūk(n) then, mk(n + 1) = C+, āk(n + 1) = āk(n) and ūk(n + 1) = ūk(n); (ii) if mk(n + 1) = C−, then āk(n + 1) = āk(n) and ūk(n + 1) = ūk(n). If player k observes an improvement also at the next stage (i.e., u′k(n + 2) > ūk(n + 1)), then the mood switches to content and the benchmark utility is updated with the new one: mk(n+2) = C and ūk(n+2) = u′k(n+1). On the contrary, if a loss is observed also at the next stage (i.e., u′k(n + 2) < ūk(n + 1)), then the mood switches to discontent mk(n+ 2) = D. • Discontent If player k is discontent, it experiments a new action (a′k(n)) at each step n. We refer to this behaviour as noisy search. When the corresponding utility u′k(n+1) is observed, with probability p = F (u ′ k(n+1) the mood turns to content mk(n + 1) = C, a new action and utility benchmark are set up, ūk(n + 1) = u′k(n + 1) and āk(n + 1) = a ′ k(n + 1), while, with probability\n(1−p) it continues the noisy search. Note that function F must be such that\n0 < F (u) < 1\n2K , (13)\nwe opt for a linear formulation: F (u) = − 0.2K u+ 0.2 K .\nA. Algorithm properties\nHereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.\nTheorem 1: Let G have at least one pure Nash equilibrium and let be small enough. Then, a pure Nash equilibrium is played at least (1− δ) of the time. This theorem introduces a different notion of convergence. Generally [4], we say that an algorithm converges when it approaches a certain solution as n→∞ while, here, it means that this solution is played with a high probability an high proportion of the total time.\nTheorem 2: Let G have at least one pure Nash equilibrium and let each player employ TE, then a Nash equilibrium that maximizes the sum utility among all equilibrium states is played a large proportion of the time.\nNote that, generally, different equilibria are associated with different social welfare values. Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance."
    }, {
      "heading" : "V. MAIN RESULTS",
      "text" : "A. Working point properties\nIn this section, we present our results based on the previous analysis. Proofs are omitted due to space constraints. Based on the game theoretical formulation in Sec. III and the algorithm properties in Sec. IV we state the following:\nTheorem 3: Let N 6= ∅ be the set of NE of G, let β > K and let us denote by Kl the number of players satisfied at the l-th NE. Then, TE converges to the NE where Kl is maximized. This theorem states that, if β > K, then TE converges to a state where the largest possible number of players are satisfied and are at the NE. Here, β represents the interest a network designer has in satisfying the largest set of players over the minimization of the network power consumption. The next two theorems allow us to link this result with the original global design problem expressed in (2).\nTheorem 4: Let (i) A† 6= ∅ be the set of solutions of (2) with K∗ = K, (ii) N 6= ∅ be the set of NE of G and N ∩A† 6= ∅ and let β > K. Then, TE learning converges to an action profile a∗ such that a∗ ∈ N ∩A† and is an ESE. This theorem links together the concept of ESE of game G′, the NE of game G and the solutions of (2). Indeed, when the assumptions are met, the TE algorithm will reach a network state where: (i) all players are satisfied, (ii) the network power consumption is minimized. Note that, generally, it is possible for (2) to have a solution that is not a NE of G.\nTheorem 5: Let (2) have no solution forK∗ = K and fix β > K. Let K∗ be the largest number of players that can be simultaneously satisfied and let K∗m be the m-th set, such that |K∗m| = K∗, where (2) has a solution; let also beA∗m the corresponding set of solutions.\nLet us define A∗ = ⋃ mA ∗ m and N 6= ∅ the set of NE. Then, TE learning converges to an action profile a∗ such that a∗ ∈ N ∩A∗. The previous theorem states that, when some players cannot satisfy their SINR condition, the TE algorithm selects the subset K∗m among all possible K∗ such that: (i) the highest number of players are satisfied, (ii) the network power consumption is minimized (with the unsatisfied players employing 0 power).\nCorollary 1: Let ∀k and ∀b be g(b)k,k ≥ Γσ2 PMAX , let C ≥ K and fix β > K. Then, TE converges to a solution of (2). Basically, this corollary means that, if transmitters and receivers are satisfiable on each channel (high SNR regime), then TE converges to an optimal working point.\nB. Convergence analysis\nTE algorithm defines a discrete time Markov chain (DTMC) on the set of the states. Studying the behaviour of the algorithm on the complete chain is an intractable problem due to the number of states, transitions and parameters. In the following, we provide an approximated DTMC that allows us to estimate: (a) the expected converging time at the NE and at the SE, (b) the expected fraction of time the system is at the NE and at the SE. Under the light of the description made in Sec. IV, we state the following: (i) the fraction of time spent in the watchful or hopeful states is negligible compared to the one in discontent or content one; (ii) at any time, the probability of having more than one player discontent is negligible. In the following, we assume C > K and a simplified channel model, defined as {\ng (c) k,k = 1 ∀k, ∀c g\n(c) j,k = 1 2 ∀k, ∀j 6= k, ∀c\n. (14)\nIn Sec. VI we will show that these results are good approximations also under less restrictive conditions. The resulting DTMC for studying TE behaviour is represented in Fig. 2. When interested in convergence time and occupancy frequency of the NE, state Eq represents the NE, and CK−k a state where K−k players are using an individually optimal action and D a state where one player is discontent. The transition probabilities we evaluate are listed hereunder, the detailed description is omitted due to space constraints.\nP (NE,D) = K(K−1)2 2\nC2\n( Q−1 Q )2 (15)\nP (D,NE) = (C−K+1))\nCQ (16)\nP (D,CK−k) = (C−K+k) Ck (K−1)! (K−k)! (17)\nP (CK−k, CK−k−1) = (K − k)C−kCQ 1+G(∆u). (18)\nThe analysis of this DTMC allows us to state the following theorems:\nTheorem 6: The expected number of iterations needed before reaching the NE for the first time T̄NE is bounded as follows:\nT̄NE ≤ CQ\n(1+G(∆u)) (C −K)\n( 1 + log ( K (C −K + 1)\nC + 1 )) T̄NE ≥ CQ\n(1+G(∆u)) (C −K)\n( γ + log ( K (C −K)\nC\n)) ;\nwhere, γ ' 0.577 is the Euler-Mascheroni constant. Note that, the time demanded to converge is directly proportional to the degree of freedom (i.e., |Ak| = CQ) and inversely to the experimentation probability . Nonetheless, as we shall see, choosing a large increases the instability of the NE and, consequentially, the network performance.\nTheorem 7: The expected fraction of time the system is at a NE (1− δ) is:\n(1− δ) = 1 1 + P (NE,D)TBNE , (19)\nwhere\nTBNE ≤ K∑ k=1 P (D,CK−k)TCNE(k) + P (D,NE) (1− P (D,D))2\nTCNE(k) = CQ\n1+G(∆u) (C −K)\n( γ + log ( K (C − k + 1)\nC + 1 )) P (D,D) = 1− P (D,NE)−\nK∑ k=1 P (D,CK−k).\nHere, (1 − δ) depends on 1 2 as in (15). This means that, the larger the the shorter the time the system is at a NE. To evaluate convergence time and occupancy frequency of the SE we, again, make use of Fig. 2. In this case, state Eq represents the SE, CK−k is a state where K − k players are satisfied and D a state where one user is discontent. The corresponding transition probabilities are listed hereunder.\nP (SE,D) = K(K−1)2 2\nC2\n( Q−1 Q )2 (20)\nP (D,SE) = (C−K+1)\nC (21)\nP (D,CK−k) = 1 Ck (K−1)! (K−k)! (C −K + k) (22)\nP (CK−k, CK−k−1) = (K − k)QS (C−k) 1+G(∆u) CQ . (23)\nGiven the model in (14) and C > K, the term QS < Q represents the number of power quantization levels that a player can employ to successfully achieve SINRk > Γ on any free channel. We can, then, state the following theorems:\nTheorem 8: The expected number of iterations needed before reaching the SE for the first time T̄SE is bounded as follows:\nT̄SE ≤ CQ/QS\n(1+G(∆u) (C −K)\n( 1 + log ( K (C −K + 1)\nC + 1 )) T̄SE ≥ CQ/QS\n(1+G(∆u) (C −K)\n( γ + log ( K (C −K)\nC\n)) .\nUnder assumption (14), being satisfied is a weaker condition than being at the NE, thus, it results that TNE ≥ TSE . Predictably, larger PMAX and lower Γ increasing QS , are able to improve the converging speed.\nTheorem 9: The expected fraction of time the system is at a SE FSE is:\nFSE = 1\n1 + P (SE,D)TBSE (24)\nwhere\nTBSE ≤ K∑ k=1 P (D,CK−k)TCSE(k) + P (D,SE) (1− P (D,D))2\nTCSE(k) = CQ\n(C −K)QS\n( γ + log ( K (C − k + 1)\nC + 1 )) P (D,D) = 1− P (D,SE)−\nK∑ k=1 P (D,CK−k)."
    }, {
      "heading" : "VI. SIMULATION RESULTS",
      "text" : "The purpose of this section is threefold. First, we run simulations to numerically validate the DTMCs introduced in Sec. V, second, we validate the results on more general channel models, then, we evaluate the performance of the algorithm in terms of satisfaction and power employed. The first two experiments have been run for two different sets of parameters. The first set is composed by: K = 3, C = 4, = 0.02 and 6 ≤ Q ≤ 10. The second set is composed by K = 4, C = 5, = 0.02 and 6 ≤ Q ≤ 10. In our first experiment, we run 107 iterations to estimate (1 − δ) under two different channel models: the simple channels expressed in (14) and a Rayleigh channel. The results are summarized in Figure 3. As we can see, the analysis, brought on particular channel model, proves to be sufficiently precise also under more general formulations. In our second experiment, we estimated the converging time and compared with the analytical results in Figure 4. As we can see, increasing the action set dimension, i.e., increasing C or Q, brings slower convergence rate since the algorithm requires more time to explore all the possibilities. Note that, here, convergence time means the time needed by the system to work at the NE for the first time. The third experiment’s parameter set is composed as follows: K = 4, C = 5, = 0.02 Q = 8 with the simplified channel model as in (14). Here, we have run 103 tests, each one composed by 6000 iteration of TE. The results are showed in Fig 5, where the upper curve represents the fraction of players satisfied, while the lower curve represents the ratio between the average power employed by the network and the optimal power that should be employed to satisfy all the players. In average, in accordance with Figure 3, the system reaches an optimal equilibrium (all players satisfied\nand minimum amount of power employed) after around 2200 iterations. Note that, even though, for some specific scenarios, this number may be too high, the configurations selected by the algorithm before the convergence are just slightly inefficient. Indeed, a configuration where all the players are able to satisfy their SINR constraints is averagely reached after 600 iterations. Moreover, before this, we observe that only a fraction of satisfiable players is satisfied, in spite of the amount of power used."
    }, {
      "heading" : "VII. CONCLUSION",
      "text" : "In this paper, we have studied a power control problem in a self configuring decentralized network. We presented a new decentralized algorithm able to steer the network into a working point where the maximum number of transmitterreceiver pairs achieves a sufficient SINR while minimizing the network power consumption. The algorithm does not assume\nany prior knowledge of the network and can learn an efficient equilibrium with only one bit of feedback. By assuming a particular channel realization, we have analytically estimated the expected performance of the algorithm through a Markov chain description of the algorithm behaviour. Finally we have shown through Monte-Carlo simulations that the analysis is approximatively correct also for general channel models."
    }, {
      "heading" : "VIII. ACKNOWLEDGEMENT",
      "text" : "This research work was carried out in the framework of the\nCORASMA EDA Project B-0781-IAP4-GC."
    } ],
    "references" : [ {
      "title" : "Fixed point optimization algorithm and its application to power control in CDMA data networks",
      "author" : [ "H. Iiduka" ],
      "venue" : "Mathematical Programming, Oct. 2010.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "S-modular games and power control in wireless networkse",
      "author" : [ "E. Altman", "Z. Altman" ],
      "venue" : "IEEE Trans. Automat. Contr.s, vol. 48, no. 5, pp. 839–842, May 2003.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Distributed power allocation with rate constraints in Gaussian parallel interference channels",
      "author" : [ "J.-S. Pang", "G. Scutari", "F. Facchinei", "C. Wang" ],
      "venue" : "IEEE Trans. on Info. Theory, vol. 54, no. 8, pp. 3471–3489, Aug. 2008.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Learning equilibria with partial information in decentralized wireless networks",
      "author" : [ "L. Rose", "S. Lasaulce", "S.M. Perlaza", "M. Debbah" ],
      "venue" : "IEEE Communications Magazine, vol. 49, no. 8, pp. 136 –142, Aug. 2011.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Water filling may not good neighbors make",
      "author" : [ "O. Popescu", "C. Rose" ],
      "venue" : "In Proceedings 2003 IEEE Global Telecommunications Conference - GLOBECOM 03, 2003, pp. 1766–1770.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "On the Nash equilibria in decentralized parallel interference channels",
      "author" : [ "L. Rose", "S.M. Perlaza", "M. Debbah" ],
      "venue" : "IEEE Workshop on Game Theory and Resource Allocation for 4G, Kyoto, Japan, Jun. 2011.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A Braess type paradox in power control over interference channels",
      "author" : [ "E. Altman", "V. Kamble", "H. Kameda" ],
      "venue" : "1st International ICST Workshop on Physics Inspired Paradigms for Wireless Communications and Network, May 2008.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "On the benefits of bandwidth limiting in decentralized vector multiple access channels",
      "author" : [ "S.M. Perlaza", "M. Debbah", "S. Lasaulce", "H. Bogucka" ],
      "venue" : "Proc. 4th Intl. Conf. on Cognitive Radio Oriented Wireless Networks and Comm. (CROWNCOM), May 2009.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On a paradox of traffic planning",
      "author" : [ "D. Braess", "A. Nagurney", "T. Wakolbinger" ],
      "venue" : "Transportation Science, vol. 39, pp. 446–450, November 2005.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Learning by trial and error",
      "author" : [ "H.P. Young" ],
      "venue" : "Tech. Rep., 2008.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Quality-ofservice provisioning in decentralized networks: A satisfaction equilibrium approach",
      "author" : [ "S.M. Perlaza", "H. Tembine", "S. Lasaulce", "M. Debbah" ],
      "venue" : "IEEE Journal of Selected Topics in Signal Processing, Feb. 2012.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Efficiency and equilibrium in trial and error learning",
      "author" : [ "B.S. Pradelski", "H.P. Young" ],
      "venue" : "Tech. Rep., 2010.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Optimal linear precoding strategies for wideband non-cooperative systems based on game theory – part II: Algorithms",
      "author" : [ "G. Scutari", "D. Palomar", "S. Barbarossa" ],
      "venue" : "IEEE Trans. on Signal Processing, vol. 56, no. 3, pp. 1250–1267, mar. 2008.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The closest works to ours are [1], [2] and [3].",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "The closest works to ours are [1], [2] and [3].",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 2,
      "context" : "The closest works to ours are [1], [2] and [3].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 0,
      "context" : "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 1,
      "context" : "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 3,
      "context" : "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.",
      "startOffset" : 239,
      "endOffset" : 242
    }, {
      "referenceID" : 2,
      "context" : "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.",
      "startOffset" : 297,
      "endOffset" : 300
    }, {
      "referenceID" : 0,
      "context" : "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 1,
      "context" : "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 2,
      "context" : "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 4,
      "context" : "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].",
      "startOffset" : 85,
      "endOffset" : 88
    }, {
      "referenceID" : 5,
      "context" : "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 6,
      "context" : "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 7,
      "context" : "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 8,
      "context" : "Indeed, this effect has been reported as a Braess kind paradox [9].",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "In this paper, our contribution is twofold: first, we present a fully decentralized learning algorithm able to keep the SINR level above a certain threshold a high proportion of the time, by means of only one bit feedback and relying only on local information [4]; second, we analytically study the convergence properties and the convergence point, which is shown to be an efficient Nash equilibrium (NE) in terms of global performance.",
      "startOffset" : 260,
      "endOffset" : 263
    }, {
      "referenceID" : 9,
      "context" : "IV we present the trial and error algorithm as introduced in [10]; in Sec.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 10,
      "context" : "GAME FORMULATION In this section, we model the scenario presented in Sec 1 in two different formulations: a normal-form game and a satisfaction-form [11] game.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 10,
      "context" : "Moreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] Φk : Ak → [0, 1].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "Moreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] Φk : Ak → [0, 1].",
      "startOffset" : 129,
      "endOffset" : 135
    }, {
      "referenceID" : 9,
      "context" : "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 11,
      "context" : "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 0,
      "context" : ", a characteristic that defines the machine reaction to its experience of the environment, āk ∈ A and ūk ∈ [0, 1] represents a benchmark action and benchmark utility, respectively.",
      "startOffset" : 107,
      "endOffset" : 113
    }, {
      "referenceID" : 9,
      "context" : "Hereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "Hereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "Generally [4], we say that an algorithm converges when it approaches a certain solution as n→∞ while, here, it means that this solution is played with a high probability an high proportion of the total time.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 3,
      "context" : "Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : "Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance.",
      "startOffset" : 53,
      "endOffset" : 57
    } ],
    "year" : 2012,
    "abstractText" : "In this paper, we address the problem of global transmit power minimization in a self-configuring network where radio devices are subject to operate at a minimum signal to interference plus noise ratio (SINR) level. We model the network as a parallel Gaussian interference channel and we introduce a fully decentralized algorithm (based on trial and error) able to statistically achieve a configuration where the performance demands are met. Contrary to existing solutions, our algorithm requires only local information and can learn stable and efficient working points by using only one bit feedback. We model the network under two different game theoretical frameworks: normal form and satisfaction form. We show that the converging points correspond to equilibrium points, namely Nash and satisfaction equilibrium. Similarly, we provide sufficient conditions for the algorithm to converge in both formulations. Moreover, we provide analytical results to estimate the algorithm’s performance, as a function of the network parameters. Finally, numerical results are provided to validate our theoretical conclusions.",
    "creator" : "LaTeX with hyperref package"
  }
}