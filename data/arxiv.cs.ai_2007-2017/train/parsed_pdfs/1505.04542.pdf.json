{
  "name" : "1505.04542.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Scalable Parallel Numerical Constraint Solver Using Global Load Balancing",
    "authors" : [ "Daisuke Ishii", "Kazuki Yoshizoe", "Toyotaro Suzumura" ],
    "emails" : [ "dsksh@acm.org", "yoshizoe@acm.org", "suzumura@acm.org" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Categories and Subject Descriptors D.1.3 [Concurrent Programming]: Parallel Programming\nGeneral Terms Algorithms, Artificial Intelligence\nKeywords Interval Analysis, Constraint Programming, Parallel Programming, Global Load Balancing, X10"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "Numerical constraint satisfaction problems (NCSPs, Section 3) and their dedicated solvers have been successfully applied to problems in the domain of real numbers [22, 6, 5]. Given a NCSP with a search space represented by a box (i.e., interval vectors), the branch and prune algorithm bisects the box or filters an inconsistent portion of the box repeatedly, until finally obtaining a paving (i.e., a set of boxes that precisely enclose the solutions set). However, the exponential computational complexity of NCSPs limits the number of tractable instances; therefore, parallelization of NCSP solvers that can scale on a number of cores is a promising approach for the further development of numerical constraint programming [7].\nSearch-space splitting is a simple and efficient approach for parallelization of CSP solvers, yet state-of-the-art implementations are still limited to scaling up to a few hundred cores (Section 2). Recently, Saraswat et al. [20] have proposed a global load balancing framework: a scalable scheme for the global workload distribution and termination detection of irregular parallel computation, which typically applies to the CSP solving process (Section 4.1). That framework is implemented with X10 and is available in the official distribution of X10 as the GLB library [24].\nIn this work, we propose a parallel NCSP solver that uses the GLB library (Section 4.2). The solver is simply implemented with X10 by adopting the (sequential) constraint propagator of the Realpaver solver as a unit process of GLB. Section 5 reports the experimental results obtained when our method was deployed on 600 cores of the TSUBAME2.5 supercomputer. Optimal configurations of the GLB parameters are analyzed on the basis of those experimental results."
    }, {
      "heading" : "2. RELATED WORK",
      "text" : "A survey by Gent et al. [8] describes existing parallel CSP solvers by classifying them into three categories: searchspace splitting methods, cooperative methods for heterogeneous workers (e.g. portfolios and parallel local search)[4], and parallelization of the constraint propagation process [9]. Our work focuses on the first approach.\nThe main difficulty of the search-space splitting approach lies in the balanced distribution of the sub-trees, which keeps worker solvers active. When the search tree becomes highly unbalanced, it becomes difficult to predict the appropriate splitting of the search tree, so a dynamic load balancing scheme becomes necessary. A work stealing scheme is typically used for this purpose: when a worker is starving, it sends a request to other workers, and workloads are communicated in response. Most existing works experiment with a limited number (e.g., 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].\nA substantial amount of work exists regarding the parallelization of the branch and bound algorithm with both search-space splitting and work stealing [11, 15, 18]. Although the branch and bound algorithm resembles the solving process of NCSPs, existing works consider the discrete domain; our work explores an efficient parallel method that handles the continuous domain with interval computation.\nThere exist parallel CSP/SAT solvers implemented with X10 [3, 2, 7, 17]. None has yet utilized the GLB library in its implementation."
    }, {
      "heading" : "3. NUMERICAL CONSTRAINT PROGRAMMING",
      "text" : "Numerical constraint programming is an extension of discrete constraint programming [19] and uses techniques that are inherited from interval analysis [16]. Their variable domains are continuous subsets of R: (machine-representable) intervals [a, b] := {r ∈ R | a ≤ r ≤ b}, where a and b are floating-point numbers, and boxes (or vectors of intervals)\nar X\niv :1\n50 5.\n04 54\n2v 1\n[ cs\n.D C\n] 1\n8 M\nay 2\n01 5\n([a1, b1], . . . , [an, bn]). In the following, boldface characters (e.g., v) denote intervals and boxes. I denotes the set of intervals and In denotes the set of n dimensional boxes. Numerical constraint solving resorts to validated interval computation and the branch and prune scheme: the solvers evaluate an interval extension of a real function in a reliable manner, e.g., an interval extension of addition is computed as [a1, b1] + [a2, b2] := [ba1 +a2c, db1 + b2e] where b·c and d·e denote the downward and upward rounding mode control, and the branch and prune algorithm enumerates interval assignments based on the dichotomy principle.\nA numerical constraint satisfaction problem (NCSP) is defined as a triple (v,v0, c) that consists of a vector of variables v = (v1, . . . , vn), an initial domain in the form of a box v0 ∈ In, and a constraint c(v) := f(v) = 0 ∧ g(v) < 0, where f : Rn → Rnf and g : Rn → Rng , i.e., a conjunction of nf equations and ng inequalities. A solution of a NCSP is an assignment of its variables ṽ ∈ v0 that satisfies the constraint c(ṽ). The solution set Σ is the region {ṽ ∈ v0 | c(ṽ)}. A NCSP is well-constrained when n = nf , under-constrained when n > nf , and over-constrained when n < nf . In general, a well-constrained NCSP has a discrete solution set and an under-constrained NCSP has a continuous solution set.\nExample 1. We can model the intersection of two disks in the (v1, v2) plane as an under-constrained NCSP, where v := (v1, . . . , v4), v0 = ([−1, 1], [−1, 1], [0, 1], [0, 1]), and\nc ≡ (v21 + v22 − v3, (v1 − 1)2 + v22 − v4) = 0.\nThe solution set projected onto the (v1, v2) plane is depicted in Figure 2."
    }, {
      "heading" : "3.1 Branch and Prune Algorithm",
      "text" : "The branch and prune algorithm [22] is the standard solving method for NCSPs. It takes a NCSP and a precision as input and outputs a set of boxes (or paving) S that approximates the solution set with precision .\nFigure 1 presents the algorithm. In the main loop at Lines 2–11, the algorithm first takes the first element of the queue L of boxes and applies the Prune procedure that shaves boundary portions of the considered box (Line 3). In this work, we use a basic implementation HC4Revise [1] for well-constrained problems; for under-constrained problems, we use an implementation proposed in [6] that provides a verification process based on an interval Newton method combined with HC4Revise. As a result of Prune, a box becomes either empty, precise enough (its width is smaller than ), verified as an inner box of the solution set Σ, or undecided. Precise and inner boxes are appended to S (Line 6) and undecided boxes are passed to Branch. Next, the Branch procedure bisects the box at the midpoint along a component corresponding to a variable and the sub-boxes are put back into the queue (Line 8). In this work, we assume that Branch selects variables in an order that makes the search behave in a breadth-first manner.\nRealpaver[12] has been developed as a (sequential) implementation of a NCSP solver.\nExample 2. A set of boxes enclosing the solution set of the NCSP from Example 1, which is computed with = 0.01, is shown in Figure 2.\nThere are some characteristics that make the parallel solving of NCSPs different from that of other CSPs. First, computing Prune is expensive and causes a bottleneck during\nInput: NCSP (v,v0, c), precision Output: set of boxes S 1: L := {v0}; S := ∅ 2: while L 6= ∅ do 3: v := Prunec(PollFirst(L)) 4: if v 6= ∅ then 5: if widv ≤ ∨ v is an inner box then 6: S := S ∪ {v} 7: else 8: L := AddLast(L,Branch(v)) 9: end if 10: end if 11: end while 12: return S\nFigure 1: Branch and prune algorithm\n0 1\n0\n1\n-1 v1\nv2\nFigure 2: Paving of a solution set\nthe solving process; in our experiments, a Prune call takes around 1ms in average. Second, Prune applications result in unbalanced search trees. Under certain conditions, Prune contracts a large portion of a considered box (cf. quadratic convergence of the interval Newton methods) and may even filter out the entire box if the box in question is verified as an inner or totally inconsistent region. Thus, it is crucial for efficient NCSP solving to execute Prune at each step while traversing the search tree, which, on the other hand, makes it more difficult to distribute a search path among processors. Third, the number of solutions is large when a problem is under-constrained and a small is given; this causes the search tree to spread toward the bottom. Last, the search processes for different branches do not require communication; thus, it is safe to run processes on different cores in parallel, without any modification."
    }, {
      "heading" : "4. PARALLELIZATION USING GLOBAL LOAD BALANCING",
      "text" : "We parallelize the branch and prune algorithm by splitting and distributing a search space (represented as queue L content) among the workers that run the branch and prune processes homogeneously. A balanced distribution is not straightforward; a naive method is to create a frontier of sufficient number of nodes in the search tree, and distribute them evenly across the workers; however, a breadth-first search computation of such a frontier is not efficient because of the time-consuming Prune process.\nThe proposed method is implemented simply with X10 and the global load balancing (GLB), which is an efficient scheme for load balancing of irregular tasks.\nInput: environment E, TaskQueue instance Q Output: task result Parameter: i ∈ R≥0, w, l, z ∈ N 1: LL := InitLifelineE(l, z) 2: repeat 3: while Q.process(i) do {active phase} 4: DistributeToThievesE(Q) 5: end while"
    }, {
      "heading" : "4.1 X10 GLB Library",
      "text" : "GLB is a global load balancing library [24] in the X10 standard library that implements the lifeline graph workstealing algorithm [20]. GLB is suitable for parallelizing irregular tasks, where the workload for each subtask is not predictable, such as search algorithms for AI applications.\nGLB computation is performed by multiple cooperative workers. Each worker runs on an X10 place and homogeneously processes a divided workload. The load balancing between workers is done in two phases: first, work stealing via requests sent from one worker to randomly selected other workers; then, work stealing and termination detection via a hyper-cube network of workers called a lifeline. GLB is simply implemented with X10 with configurable parameters and scales up to 16K places when applied to several benchmarks. For each GLB application, a sequential computation that processes a workload is implemented as an X10 class TaskQueue and an instance is given to a worker as input. There are four parameters: i ∈ R≥0 specifies the lower bound on the time (in seconds) taken by a unit of sequential process1; w ∈ N specifies the number of attempted workload steals in the first phase; and l ∈ N and z ∈ N specify the diameter of the lifeline graph and the number of branches of each node, respectively. w = 0 turns off the random stealing process. We assume lz is greater than or equals to the number of workers. A tight lifeline graph is built by setting l = 2; broadcasting is done in two hops.\nA pseudo algorithm in Figure 3 mimics the worker process. When the TaskQueue instance Q contains a workload, a worker becomes active and iterates the loop at Lines 3– 5. A call to the process(i) method of Q invokes a unit sequential computation that should take at least i seconds. DistributeToThieves sends portions of the available workload (i.e. Q.split()) to other idling workers; otherwise, it signals that the worker has no workload available. When all workload is processed and property Q.empty becomes true, the\n1We modified GLB to use the parameter i instead of n, which specified the number of processed unit tasks.\nworker enters the two-stage idle phase: at Lines 6–8, the worker randomly selects another worker, sends a request, and waits for the victim’s DistributeToThieves to respond; at Lines 9–14, the worker sends a request following the lifeline graph. When the steal succeeds, the loot L̃ is merged by executing Q.merge(L̃). When Q is still empty, the worker process terminates and outputs the task result."
    }, {
      "heading" : "4.2 Implementation of NCSP Solver with GLB",
      "text" : "We implement TaskQueue to encapsulate computation of the branch and prune algorithm. TaskQueue holds the queue L of undecided boxes and the solution set S. Initially, a worker possesses the initial domain v0 in L and the queues of other workers are left empty. Methods of TaskQueue are implemented as follows:\n• process(i) computes the main loop of the branch and prune algorithm until the time i elapses. For Prune, the C++ implementation of Realpaver is used. • split() divides L equally into two and returns a portion. • merge(L̃) is given a set L̃ of boxes and appends the\nboxes to L. • getResult() returns |S|. Our implementation does not\ngather S in one place, thus avoiding unnecessary overhead. Indeed, S might be better distributed in the post-process of many applications.\nThe implementation consists of about 1,000 lines of X10 and 2,400 lines of C++ code. In NCSP applications, the solving process must be tweaked by trying several combinations of Prune implementations and search strategies. In this respect, our simple X10 framework that is interfaced with C++ solver implementations will serve as a practical tool."
    }, {
      "heading" : "5. PERFORMANCE EVALUATION",
      "text" : "We evaluated our parallel NCSP solver with several problems from existing literature. The experiments were operated on the TSUBAME2.5 supercomputer, which is a supercomputer at Tokyo Institute of Technology.2 Each node of TSUBAME2.5 has two Intel Westmere EP 2.93GHz processors (12 cores in total) and 54GB of local memory. We used 50 nodes; thus, each experiment was run with up to 600 X10 places on 600 cores. We used native X10 version 2.4.3.2 and its MPI backend (based on Open MPI 1.6.5)."
    }, {
      "heading" : "5.1 Experimental Results",
      "text" : "We solved four instances of two well-constrained (WC) problems taken from [13, 10] and six instances of two underconstrained (UC) problems taken from [6, 5]. For each of the first three problems, we prepared two instances by varying the number of variables and constraints. For the UC problems, we solved with two different precisions. Every instance was solved with the following seven GLB parameter configurations:\n(1) i = 0.001s, l = 2, and w = 0. (2) i = 0.001s, l = 2, and w = 1. (3) i = 0.001s, l = 2, and w = z. (4) i = 0.001s, l = P , and w = 0. (5) i = 0.001s, l = P , and w = z. (6) i = 0.1s, l = 2, and w = 0. (7) i = 0.1s, l = 2, and w = z.\n2http://tsubame.gsic.titech.ac.jp/en\nTable 1: Considered problems and experimental results\nproblem size # sol # br w t1 t300 t600 ar600 # sb600 Economics 8 10−8 8 63 478 0 58s 0.40s 0.41s 64% 47 000 (eco8 ) 1 0.78s 0.77s 25% 27 500 Economics 10 10−8 16 3 614 945 0 5 970s 22.0s 11.8s 88% 2 550 000 (eco10 ) 1 21.4s 11.5s 93% 1 150 000 Periodic orbits 48 10−8 2 939 28 742 0 1 330s 8.5s 5.0s 58% 34 800 (henon24 ) 1 6.8s 4.4s 63% 19 000 Periodic orbits 56 10−8 16 105 174 446 0 12 530s 60.2s 31.2s 65% 201 000 (henon28 ) 1 45.7s 25.1s 87% 81 000 2D sphere 2+2 0.004 312 064 364 961 0 122s 0.6s 0.5s 75% 295 000 and plane 1 0.8s 0.9s 39% 153 000 (sp2-2 ) 0.001 2 490 988 2 936 705 0 780s 3.8s 2.2s 87% 2 300 000 1 3.9s 2.6s 78% 955 000 4D sphere 2+4 0.004 1 459 225 2 488 689 0 1 202s 7.0s 3.8s 85% 1 790 000 and plane 1 6.6s 4.1s 85% 662 000 (sp2-4 ) 0.001 11 759 158 20 082 197 0 12 800s 52s 27s 92% 12 850 000 1 50s 26s 97% 4 600 000 3-RPR robot 3+3 0.2 1 488 388 1 936 939 0 598s 2.8s 1.7s 80% 1 550 000 (3rpr) 1 2.9s 2.1s 71% 675 000\n0.1 5 649 780 7 186 845 0 2 135s 9.0s 5.0s 86% 5 600 000 1 8.7s 5.2s 88% 2 300 000\nz was set as dlogl P e (such that lz ≥ P ). Specification of the instances and experimental results using configurations (1) and (2), which were performed most efficiently, are shown in Table 1. The columns “problem”, “size”, “ ”, “# sol”, “# br”, and “w” represent the name of the problem, size (i.e., the number of variables n; for UC problems, the number of equality constraints nf that are separated with ‘+’), precision, number of solutions, number of branches, and value of w, respectively. The rest of the columns provide some experimental results. tj represents the running time using j X10 places (best timings are underlined). ar600 represents the mean of the ratio of active time versus the total solving time at each place when computed with 600 places. # sb600 represents the total number of sent boxes from 600 places for load balancing. Figure 4 shows the number of paths per depth in each search tree of the four instances. Figure 5 illustrates the speedups of the parallel solving processes for the seven instances. Figure 6 illustrates the fraction of the three worker states within the CPU timing for the two instances. Each layer, from bottom to top, corresponds to the time taken for Prune, DistributeToThieves, and the idle phase (Lines 6–14 in Figure 3), respectively.3\n5.2 DiscussionIn the experiments, our parallel solver scaled up to 600 places/cores and achieved up to 516-fold speedup (an efficiency of 0.84).\nAs can be seen from Figure 4, each of the search trees for the instances considered has a number of paths whose lengths are close to the height of the tree; thus, a certain level of parallelism exists. Furthermore, comparing the graphs of the different instances of the same problem, we see that the shapes of graphs are similar, but the size of the tree of larger instances increases exponentially, indicating that parallelization should be easier for larger instances.\n3The timings for Prune differed per number of places. As a reason, we predicted and confirmed that the CPU cache hit ratio differed in the parallel processes.\n10 20 30 40 50 60 500\n1000 1500 2000 2500 3000 3500\n20 30 40 50 60 70 80\n50 000 100 000 150 000 200 000 250 000\n(a) eco8 (left); eco10 (right).\n5 10 15 20 25 30 35\n10 000 20 000 30 000 40 000\n20 30 40 50 60\n500 000\n1.0 106 1.5 106\n(b) sp2-2, = 0.004 (left); sp2-4, = 0.001 (right).\nFigure 4: Number of search paths (vertical axis) per depth (horizontal axis)\nFor most instances (excluding the large ones), the best speedups were accomplished with configuration (1): the parallel process with the most frequent load balancing that used the lifeline graph with the broadest distribution and did not perform random stealing. The efficiency of load balancing is evident in the active ratio of workers (see ar600 in Table 1 and the left-hand figures of Figure 6). Despite its large communication overhead (see the last column of Table 1), load balancing that used the lifeline resulted in quick workload distribution and termination.\nFor large instances, such as eco10 (Figure 5(a), right), henon28, and sp4 ( = 0.001; Figure 5(b), right), configurations (2), (3), and (5), which had frequent random stealing, outperformed configuration (1). Their performance also appeared in the active ratio (Figure 6(a), right). Among these configurations, configuration (2) performed the best probably because of its quick termination process.\nRegarding time interval i of the load balancing, the most frequent setting, i = 0.001s, performed well. With this set-\nting, workload was distributed between almost every call to Prune which takes around 1ms on average and, in total, occupies around 90% of the running time.\nConfiguration (4) always performed poorly. Its load balancing, which used a lifeline formed as a 1D hyper cube (i.e. ring), was slow and led to its poor performance. Its performance improved dramatically by enabling the random stealing process (configuration (5)).\nIn some experiments, such as sp4 ( = 0.004; Figure 5(b), middle), 3rpr ( = 0.1; Figure 5(c), right), and 3rrr ( = 0.1), configuration (1) scaled well and outperformed other configurations when using 600 cores. It would appear that the random stealing process, when using many cores, suffered from large communication overhead; such large overhead can be confirmed with configuration (2), shown in the right-hand side of Figure 6(b).\nFinally, the running times of some experiments were quite short. For example, eco8 and sp2-2 ( = 0.004) took 58s and 122s, respectively, with a single core, and certain speedups were achieved: 141- and 252-fold with 600 cores."
    }, {
      "heading" : "6. CONCLUSIONS",
      "text" : "In this work, we show that the parallelization of the branch and prune search is a good application of the X10 GLB framework. In the experiments, we achieved nearly linear speedups up to 600 X10 places/cores and are expected to be able to scale further. In future work, we plan further experiments on realistic problems including optimization problems, using a greater number of cores.\nAcknowledgments. This work was partially funded by JSPS (KAKENHI 25880008, 15K15968, 25700038, 26280024, and 23240005) and JST ERATO Project."
    }, {
      "heading" : "7. REFERENCES",
      "text" : "[1] F. Benhamou, L. Granvilliers, F. Goualard, and J.-F.\nPuget. Revising Hull and Box Consistency. In ICLP, pages 230–244, 1999.\n[2] D. Bergman, A. A. Cire, A. Sabharwal, H. Samulowitz, V. Saraswat, and W.-J. V. Hoeve. Parallel Combinatorial Optimization with Decision Diagrams. In CPAIOR, LNCS 8451, pages 351–367, 2014.\n[3] B. Bloom, D. Grove, B. Herta, A. Sabharwal, H. Samulowitz, and V. Saraswat. SatX10: A Scalable Plug & Play Parallel SAT Framework. In SAT, LNCS 7317, pages 463–468, 2012.\n[4] L. Bordeaux, Y. Hamadi, and H. Samulowitz. Experiments with Massively Parallel Constraint Solving. In IJCAI, pages 443–448, 2006.\n[5] S. Caro, D. Chablat, A. Goldsztejn, D. Ishii, and C. Jermann. A branch and prune algorithm for the computation of generalized aspects of parallel robots. Artificial Intelligence, 211:34–50, 2014.\n[6] D. Ishii, A. Goldsztejn, and C. Jermann. Interval-based projection method for under-constrained numerical systems. Constraints Journal, 17(4):432–460, 2012.\n[7] D. Ishii, K. Yoshizoe, and T. Suzumura. Scalable Parallel Numerical CSP Solver. In CP, LNCS 8656, pages 398–406, 2014.\n[8] I. P. Gent, C. Jefferson, I. Miguel, N. C. A. Moore, P. Nightingale, P. Prosser, and C. Unsworth. A Preliminary Review of Literature on Parallel Constraint Solving. In Workshop on Parallel Methods for Constraint Solving, 2011.\n[9] A. Goldsztejn and F. Goualard. Box consistency through adaptive shaving. SAC, pages 2049–2054, 2010.\n[10] A. Goldsztejn, L. Granvilliers, C. Jermann, and L. Umr. Constraint Based Computation of Periodic Orbits of Chaotic Dynamical Systems. In CP, pages 774–789, 2013.\n[11] A. Grama, A. Gupta, G. Karypis, and V. Kumar. Introduction to Parallel Computing. Addison Wesley, 2003.\n[12] L. Granvilliers and F. Benhamou. Algorithm 852: RealPaver: An Interval Solver using Constraint Satisfaction Techniques. ACM Transactions on Mathematical Software, 32(1):138–156, 2006.\n[13] P. V. Hentenryck, L. Michel, and F. Benhamou. Newton: Constraint Programming over Nonlinear Constraints. Science of Computer Programming, 30(1-2):83–118, 1998.\n[14] J. Jaffar, A. Santosa, R. Yap, and K. Zhu. Scalable distributed depth-first search with greedy work stealing. In ICTAI, pages 98–103. IEEE, 2004.\n[15] R. Lüling, B. Monien, A. Reinefeld, and S. Tschöke. Mapping Tree-Structured Combinatorial Optimization Problems onto Parallel Computers. In Solving Combinatorial Optimization Problems in Parallel, volume 7141, pages 115–144, 1996.\n[16] R. E. Moore. Interval Analysis. Prentice-Hall, 1966.\n[17] D. Munera, D. Diaz, S. Abreu, and P. Codognet. A Parametric Framework for Cooperative Parallel Local Search. In 14th European Conference on Evolutionary Computation in Combinatorial Optimisation (EvoCOP), LNCS 8600, pages 13–24, 2014.\n[18] L. Otten and R. Dechter. Towards Parallel Search for Optimization in Graphical Models. In ISAIM, 2010.\n[19] F. Rossi, P. V. Beek, and T. Walsh. Handbook of Constraint Programming, volume 2 of Foundations of Artificial Intelligence. Elsevier, 2006.\n[20] V. Saraswat, P. Kambadur, S. Kodali, D. Grove, and S. Krishnamoorthy. Lifeline-based global load balancing. In PPoPP, pages 201–212, 2011.\n[21] C. Schulte. Parallel search made simple. In TRICS (Techniques foR Implementing Constraint programming Systems), pages 41–57, 2000.\n[22] P. Van Hentenryck, D. McAllester, and D. Kapur. Solving Polynomial Systems Using a Branch and Prune Approach. SIAM Journal on Numerical Analysis, 34(2):797–827, 1997.\n[23] F. Xie and A. Davenport. Massively Parallel Constraint Programming for Supercomputers : Challenges and Initial Results. In CPAIOR, LNCS 6140, pages 334–338, 2010.\n[24] W. Zhang, O. Tardieu, D. Grove, B. Herta, T. Kamada, and V. Saraswat. GLB : Lifeline-based Global Load Balancing Library in X10. In PPAA, pages 31–40, 2014."
    } ],
    "references" : [ {
      "title" : "Revising Hull and Box Consistency",
      "author" : [ "F. Benhamou", "L. Granvilliers", "F. Goualard", "J.-F. Puget" ],
      "venue" : "ICLP, pages 230–244",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Parallel Combinatorial Optimization with Decision Diagrams",
      "author" : [ "D. Bergman", "A.A. Cire", "A. Sabharwal", "H. Samulowitz", "V. Saraswat", "W.-J.V. Hoeve" ],
      "venue" : "CPAIOR, LNCS 8451, pages 351–367",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "SatX10: A Scalable Plug & Play Parallel SAT Framework",
      "author" : [ "B. Bloom", "D. Grove", "B. Herta", "A. Sabharwal", "H. Samulowitz", "V. Saraswat" ],
      "venue" : "SAT, LNCS 7317, pages 463–468",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Experiments with Massively Parallel Constraint Solving",
      "author" : [ "L. Bordeaux", "Y. Hamadi", "H. Samulowitz" ],
      "venue" : "IJCAI, pages 443–448",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "A branch and prune algorithm for the computation of generalized aspects of parallel robots",
      "author" : [ "S. Caro", "D. Chablat", "A. Goldsztejn", "D. Ishii", "C. Jermann" ],
      "venue" : "Artificial Intelligence, 211:34–50",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Interval-based projection method for under-constrained numerical systems",
      "author" : [ "D. Ishii", "A. Goldsztejn", "C. Jermann" ],
      "venue" : "Constraints Journal, 17(4):432–460",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Scalable Parallel Numerical CSP Solver",
      "author" : [ "D. Ishii", "K. Yoshizoe", "T. Suzumura" ],
      "venue" : "CP, LNCS 8656, pages 398–406",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A Preliminary Review of Literature on Parallel Constraint Solving",
      "author" : [ "I.P. Gent", "C. Jefferson", "I. Miguel", "N.C.A. Moore", "P. Nightingale", "P. Prosser", "C. Unsworth" ],
      "venue" : "Workshop on Parallel Methods for Constraint Solving",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Box consistency through adaptive shaving",
      "author" : [ "A. Goldsztejn", "F. Goualard" ],
      "venue" : "SAC, pages 2049–2054",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Constraint Based Computation of Periodic Orbits of Chaotic Dynamical Systems",
      "author" : [ "A. Goldsztejn", "L. Granvilliers", "C. Jermann", "L. Umr" ],
      "venue" : "CP, pages 774–789",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Introduction to Parallel Computing",
      "author" : [ "A. Grama", "A. Gupta", "G. Karypis", "V. Kumar" ],
      "venue" : "Addison Wesley",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Algorithm 852: RealPaver: An Interval Solver using Constraint Satisfaction Techniques",
      "author" : [ "L. Granvilliers", "F. Benhamou" ],
      "venue" : "ACM Transactions on Mathematical Software, 32(1):138–156",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Newton: Constraint Programming over Nonlinear Constraints",
      "author" : [ "P.V. Hentenryck", "L. Michel", "F. Benhamou" ],
      "venue" : "Science of Computer Programming, 30(1-2):83–118",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Scalable distributed depth-first search with greedy work stealing",
      "author" : [ "J. Jaffar", "A. Santosa", "R. Yap", "K. Zhu" ],
      "venue" : "ICTAI, pages 98–103. IEEE",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Mapping Tree-Structured Combinatorial Optimization Problems onto Parallel Computers",
      "author" : [ "R. Lüling", "B. Monien", "A. Reinefeld", "S. Tschöke" ],
      "venue" : "Solving Combinatorial Optimization Problems in Parallel, volume 7141, pages 115–144",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Interval Analysis",
      "author" : [ "R.E. Moore" ],
      "venue" : "Prentice-Hall",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1966
    }, {
      "title" : "A Parametric Framework for Cooperative Parallel Local Search",
      "author" : [ "D. Munera", "D. Diaz", "S. Abreu", "P. Codognet" ],
      "venue" : "14th European Conference on Evolutionary Computation in Combinatorial Optimisation (EvoCOP), LNCS 8600, pages 13–24",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Towards Parallel Search for Optimization in Graphical Models",
      "author" : [ "L. Otten", "R. Dechter" ],
      "venue" : "ISAIM",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Handbook of Constraint Programming",
      "author" : [ "F. Rossi", "P.V. Beek", "T. Walsh" ],
      "venue" : "volume 2 of Foundations of Artificial Intelligence. Elsevier",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Lifeline-based global load balancing",
      "author" : [ "V. Saraswat", "P. Kambadur", "S. Kodali", "D. Grove", "S. Krishnamoorthy" ],
      "venue" : "PPoPP, pages 201–212",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Parallel search made simple",
      "author" : [ "C. Schulte" ],
      "venue" : "TRICS (Techniques foR Implementing Constraint programming Systems), pages 41–57",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Solving Polynomial Systems Using a Branch and Prune Approach",
      "author" : [ "P. Van Hentenryck", "D. McAllester", "D. Kapur" ],
      "venue" : "SIAM Journal on Numerical Analysis, 34(2):797–827",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Massively Parallel Constraint Programming for Supercomputers : Challenges and Initial Results",
      "author" : [ "F. Xie", "A. Davenport" ],
      "venue" : "CPAIOR, LNCS 6140, pages 334–338",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "GLB : Lifeline-based Global Load Balancing Library in X10",
      "author" : [ "W. Zhang", "O. Tardieu", "D. Grove", "B. Herta", "T. Kamada", "V. Saraswat" ],
      "venue" : "PPAA, pages 31–40",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Numerical constraint satisfaction problems (NCSPs, Section 3) and their dedicated solvers have been successfully applied to problems in the domain of real numbers [22, 6, 5].",
      "startOffset" : 163,
      "endOffset" : 173
    }, {
      "referenceID" : 5,
      "context" : "Numerical constraint satisfaction problems (NCSPs, Section 3) and their dedicated solvers have been successfully applied to problems in the domain of real numbers [22, 6, 5].",
      "startOffset" : 163,
      "endOffset" : 173
    }, {
      "referenceID" : 4,
      "context" : "Numerical constraint satisfaction problems (NCSPs, Section 3) and their dedicated solvers have been successfully applied to problems in the domain of real numbers [22, 6, 5].",
      "startOffset" : 163,
      "endOffset" : 173
    }, {
      "referenceID" : 6,
      "context" : "However, the exponential computational complexity of NCSPs limits the number of tractable instances; therefore, parallelization of NCSP solvers that can scale on a number of cores is a promising approach for the further development of numerical constraint programming [7].",
      "startOffset" : 268,
      "endOffset" : 271
    }, {
      "referenceID" : 19,
      "context" : "[20] have proposed a global load balancing framework: a scalable scheme for the global workload distribution and termination detection of irregular parallel computation, which typically applies to the CSP solving process (Section 4.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "That framework is implemented with X10 and is available in the official distribution of X10 as the GLB library [24].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 7,
      "context" : "[8] describes existing parallel CSP solvers by classifying them into three categories: searchspace splitting methods, cooperative methods for heterogeneous workers (e.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "portfolios and parallel local search)[4], and parallelization of the constraint propagation process [9].",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : "portfolios and parallel local search)[4], and parallelization of the constraint propagation process [9].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 20,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 13,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 12,
      "endOffset" : 19
    }, {
      "referenceID" : 3,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 12,
      "endOffset" : 19
    }, {
      "referenceID" : 6,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 1,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 22,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 144,
      "endOffset" : 151
    }, {
      "referenceID" : 1,
      "context" : ", 40[21], 64[14, 4], or 256 [7, 2]) of processors, and the load balancing tends to assume a central master process, which may limit scalability [23, 2].",
      "startOffset" : 144,
      "endOffset" : 151
    }, {
      "referenceID" : 10,
      "context" : "A substantial amount of work exists regarding the parallelization of the branch and bound algorithm with both search-space splitting and work stealing [11, 15, 18].",
      "startOffset" : 151,
      "endOffset" : 163
    }, {
      "referenceID" : 14,
      "context" : "A substantial amount of work exists regarding the parallelization of the branch and bound algorithm with both search-space splitting and work stealing [11, 15, 18].",
      "startOffset" : 151,
      "endOffset" : 163
    }, {
      "referenceID" : 17,
      "context" : "A substantial amount of work exists regarding the parallelization of the branch and bound algorithm with both search-space splitting and work stealing [11, 15, 18].",
      "startOffset" : 151,
      "endOffset" : 163
    }, {
      "referenceID" : 2,
      "context" : "There exist parallel CSP/SAT solvers implemented with X10 [3, 2, 7, 17].",
      "startOffset" : 58,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "There exist parallel CSP/SAT solvers implemented with X10 [3, 2, 7, 17].",
      "startOffset" : 58,
      "endOffset" : 71
    }, {
      "referenceID" : 6,
      "context" : "There exist parallel CSP/SAT solvers implemented with X10 [3, 2, 7, 17].",
      "startOffset" : 58,
      "endOffset" : 71
    }, {
      "referenceID" : 16,
      "context" : "There exist parallel CSP/SAT solvers implemented with X10 [3, 2, 7, 17].",
      "startOffset" : 58,
      "endOffset" : 71
    }, {
      "referenceID" : 18,
      "context" : "Numerical constraint programming is an extension of discrete constraint programming [19] and uses techniques that are inherited from interval analysis [16].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 15,
      "context" : "Numerical constraint programming is an extension of discrete constraint programming [19] and uses techniques that are inherited from interval analysis [16].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : ", v4), v0 = ([−1, 1], [−1, 1], [0, 1], [0, 1]), and c ≡ (v 1 + v 2 − v3, (v1 − 1) + v 2 − v4) = 0.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : ", v4), v0 = ([−1, 1], [−1, 1], [0, 1], [0, 1]), and c ≡ (v 1 + v 2 − v3, (v1 − 1) + v 2 − v4) = 0.",
      "startOffset" : 39,
      "endOffset" : 45
    }, {
      "referenceID" : 21,
      "context" : "The branch and prune algorithm [22] is the standard solving method for NCSPs.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 0,
      "context" : "In this work, we use a basic implementation HC4Revise [1] for well-constrained problems; for under-constrained problems, we use an implementation proposed in [6] that provides a verification process based on an interval Newton method combined with HC4Revise.",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 5,
      "context" : "In this work, we use a basic implementation HC4Revise [1] for well-constrained problems; for under-constrained problems, we use an implementation proposed in [6] that provides a verification process based on an interval Newton method combined with HC4Revise.",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 11,
      "context" : "Realpaver[12] has been developed as a (sequential) implementation of a NCSP solver.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 23,
      "context" : "GLB is a global load balancing library [24] in the X10 standard library that implements the lifeline graph workstealing algorithm [20].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 19,
      "context" : "GLB is a global load balancing library [24] in the X10 standard library that implements the lifeline graph workstealing algorithm [20].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 12,
      "context" : "We solved four instances of two well-constrained (WC) problems taken from [13, 10] and six instances of two underconstrained (UC) problems taken from [6, 5].",
      "startOffset" : 74,
      "endOffset" : 82
    }, {
      "referenceID" : 9,
      "context" : "We solved four instances of two well-constrained (WC) problems taken from [13, 10] and six instances of two underconstrained (UC) problems taken from [6, 5].",
      "startOffset" : 74,
      "endOffset" : 82
    }, {
      "referenceID" : 5,
      "context" : "We solved four instances of two well-constrained (WC) problems taken from [13, 10] and six instances of two underconstrained (UC) problems taken from [6, 5].",
      "startOffset" : 150,
      "endOffset" : 156
    }, {
      "referenceID" : 4,
      "context" : "We solved four instances of two well-constrained (WC) problems taken from [13, 10] and six instances of two underconstrained (UC) problems taken from [6, 5].",
      "startOffset" : 150,
      "endOffset" : 156
    } ],
    "year" : 2015,
    "abstractText" : "We present a scalable parallel solver for numerical constraint satisfaction problems (NCSPs). Our parallelization scheme consists of homogeneous worker solvers, each of which runs on an available core and communicates with others via the global load balancing (GLB) method. The parallel solver is implemented with X10 that provides an implementation of GLB as a library. In experiments, several NCSPs from the literature were solved and attained up to 516-fold speedup using 600 cores of the TSUBAME2.5 supercomputer.",
    "creator" : "LaTeX with hyperref package"
  }
}