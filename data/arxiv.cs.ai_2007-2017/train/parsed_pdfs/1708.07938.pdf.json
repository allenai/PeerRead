{
  "name" : "1708.07938.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Deep Style Match for Complementary Recommendation",
    "authors" : [ "Kui Zhao", "Xia Hu", "Jiajun Bu", "Can Wang" ],
    "emails" : [ "wcan}@zju.edu.cn", "hx@hznet.com.cn" ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "We have a common sense of style compatibility between items and can naturally answer questions like “Does this shirt go well with that pair of jeans?” These kind of style compatibility information can be exploited in many commercial applications, such as recommending items to users based on what they have already bought; or generating the whole purchase outfits (see Figure 1 for an example of clothes) to users querying certain items, if sufficient compatibility relationships between items are provided.\nTo identify these compatibility relationships, existing methods such as frequent itemset mining (Han, Pei, and Yin 2000) attempt to generate match items automatically by analyzing historical purchasing patterns. However, frequent itemset mining relies on historical purchasing records to find items frequently purchased together and new items will inevitably suffer from the “cold start” problem (Schein et al. 2002).\nRecently, McAuley et al. (McAuley et al. 2015) and Veit et al. (Veit et al. 2015) intend to discover the style match relationships between items using visual information presented in the images of items. However, besides being computationally expensive, image-based matching methods are\nCopyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nfrequently plagued by the plentiful contents presented in images. For instance, Figure 2 shows a part of the image for leggings from Taobao, which is the largest e-commerce platform in China. Besides leggings, the image also contains a coat, a pair of shoes and a very complex background etc. These contents will confuse the learning machines if only leggings are expected.\nTo overcome the limitations of existing methods, we propose in this paper a novel style match approach using the title descriptions of items in online stores. The basic assumption of our work is that online sellers will place most of the important attributes of a product in its title description, so that the product can be easily found by a keyword-based query. Therefore, the title description is a highly condensed collection of attribute descriptions for a product. So it is fea-\nar X\niv :1\n70 8.\n07 93\n8v 1\n[ cs\n.A I]\n2 6\nA ug\n2 01\n7\nsible to model compatibility between two items better if we are capable of mapping the title pairs from the original space of symbolic words into some embedded style space.\nWe here design a Siamese Convolutional Neural Network architecture for matching title sentences. It will map two title sentences from an item pair into low-dimensional vectors respectively in parallel, which are then used to learn the compatibility between these two items in the style space. When designing the amalgamation part of Siamese CNN for computing compatibility, we have considered the ability of our model to be extended to big data scenarios, which is critical for real-world recommendation applications. We test our approach on two large datasets: a Chinese dataset from Taobao provided by Alibaba Group and an English dataset from Amazon provided by (McAuley et al. 2015). Our approach demonstrates strong performance on both datasets, which indicates its ability of learning human sense of style compatibility between items."
    }, {
      "heading" : "Related Work",
      "text" : "Finding complementary items has been studied for a long time. The early works can be traced back to frequent itemset mining (Han, Pei, and Yin 2000), which generates match items automatically by analyzing history purchasing patterns. Frequent itemsets such as “beer and diaper” sometimes have nothing to do with compatibility. What’s more, they are challenged by the “cold-start” problem, which means new products with no historical records are invisible to the algorithm (Schein et al. 2002).\nMany approaches such as content-based recommendation or social recommendation are proposed to address this problem (see (Pazzani and Billsus 2007) for a survey). Closely related to our work are (McAuley et al. 2015) and (Veit et al. 2015), in which McAuley et al. and Veit et al. attempt to learn clothing style similarity based on their appearance in images. However, our work differs from (McAuley et al. 2015) and (Veit et al. 2015) in the following two aspects: (1) we use title descriptions, which contain rich attribute information instead of item images; (2) the objective of our method is to find matching items from their attribute description instead of learning visual similarities from item images."
    }, {
      "heading" : "Problem formulation",
      "text" : "We here describe the problem in a formal way: given a query item set Q = {q1, · · · , qm} and a candidate item set C = {c1, · · · , cn}, where each query item qi ∈ Q comes together with the compatibility judgements {yi1 , · · · , yin}. The complementary item cj ∈ C is labeled with yij = 1 and yij = 0 otherwise. Our goal is to build a model to compute the compatibility probability between qi and cj :\nP (y = 1|qi, cj) = f(φ(qi, θ1), φ(cj , θ1), θ2), (1)\nwhere function φ(·) is the sentence model mapping a title sentence into a low-dimensional representation vector and function f(·) computes the compatibility probability between two items in the style space. The parameter vectors θ1 and θ2 are learned in the training process."
    }, {
      "heading" : "Style Match",
      "text" : "The main building block of our approach is a sentence model based on CNN. This sentence model will map two title sentences from an item pair into low-dimensional vectors respectively in parallel, which are then used to learn the compatibility between two items in the style space."
    }, {
      "heading" : "Sentence model",
      "text" : "We model sentences with function φ(·), which is a convolutional architecture as shown in Figure 3.\nIn the following, we give a brief explanation of the main components in our Convolutional Neural Network.\nSentence matrix. Our sentence model takes a sentence s as the input, where it is treated as a sequence of raw words: [s1, · · · , s|s|] and each word si is from a vocabulary V .\nFirstly, each word si is represented by a distributional representation vector wi ∈ Rd, looked up from the word-level embedding matrix W ∈ Rd×|V |. Then a sentence matrix S ∈ Rd×|s| can be built for the input sentence s:\nS = [ | | | w1 · · · w|s| | | | ] , (2)\nwhere the i-th column is the distributional representation vector wi for the i-th word in s. The values in the embedding matrix W are parameters initialized with an unsupervised neural language model (Mikolov et al. 2013) and sequentially optimized during training. The embedding dimension d is a hyper-parameter of the model.\nAs shown in Figure 3, for the sentence s=[Uniforms, Men’s, Short, Sleeve, Polo, Shirt], when the embedding dimension d is 4, the sentence matrix is a matrix in R4×6.\nConvolutional feature maps. Convolution can be seen as a special kind of linear operation and aimed to extract local patterns. We use the one-dimensional convolution to recognize discriminative word sequences from the input sentences. The one-dimensional convolution is an operation between two vectors f ∈ Rm and s ∈ R|s|. The vector f is called as a filter of size m and the vector s is a sequence of size |s|. The specific operation is to take the dot product of\nthe vector f with each m-gram sliding along the sequence s and obtain a new sequence c where:\ncj = f Tsj−m+1:j . (3)\nIn practice, we usually add a bias b to the dot product result:\ncj = f Tsj−m+1:j + b. (4)\nThere are two types of convolution depending on the allowed range of index j: narrow and wide. The narrow type restricts j in the range [m, |s|] and the wide type restricts j in the range [1, |s| + m − 1]. The benefits of wide type over the narrow type in text processing are discussed in detail in (Blunsom et al. 2014). Briefly speaking, unlike the narrow convolution where words close to margins are seen fewer times, wide convolution gives equal attention to all words in the sentence and so is better at handling words at margins. More importantly, a wide convolution always produces a valid non-empty result c even when |s| < m. For these reasons, we use wide convolution in our model.\nThe sentence matrix S is not just a sequence of single values but a sequence of vectors, where the dimension of each vector is d. So when we apply the one-dimensional convolution on the sentence matrix S, we need a filter bank F ∈ Rd×m consisting of d filters of size m and a bias bank B ∈ Rd consisting of d baises. Each row of S is convoluted with the corresponding row of F and then the corresponding row of B is added to the convolution result. After that, we obtain a matrix C ∈ Rd×(|s|+m−1):\nconv(S,F,B) : Rd×|s| → Rd×(|s|+m−1). (5)\nThe values in filter bank F and bias bank B are parameters optimized during training. The filter size m is a hyperparameter of the model.\nIn Figure 3, after applying a 4 × 3 filter bank and a bias bank of size 4 on the 4 × 6 sentence matrix, we obtain an intermediate matrix of size 4× 8.\nActivation function. To make the network capable of learning non-linear functions, a non-linear activation α(·) need to be applied in an element-wise way to the output of the preceding layer and a matrix A ∈ Rd×(|s|+m−1) is then obtained:\nα(C) : Rd×(|s|+m−1) → Rd×(|s|+m−1). (6)\nPopular choices of α(·) include: sigmod, tanh and relu (rectified linear defined as max(0, x)). In practice, our experimental results are not very sensitive to the choice of activation, so we choose relu due to its simplicity and computing efficiency. In addition, we can see the bias b in (4) plays the role of setting an appropriate threshold for controlling units to be activated.\nPooling. Pooling layer will aggregate the information in the output of preceding layer. This operation aims to make the representation more robust and invariant to small translations in the input. More importantly, pooling helps to handle inputs with varying size, e.g. processing sentences with uncertain length.\nFor a given vector a ∈ R|a|, traditional pooling aggregates it into a single value:\npooling(a) : R|a| → R. (7)\nThe way of aggregating the information defines two types of pooling operations: average and max. Max pooling is used more widely in practice. Recently, max pooling has been generalized to k-max pooling (Blunsom et al. 2014), in which k max values are selected from the vector a and arranged in their original order:\nk-pooling(a) : R|a| → Rk, (8) where k is a hyper-parameter of the model.\nWhen we apply k-max pooling on the matrix A, each row of A is pooled respectively and we obtain a matrix P ∈ Rd×k:\nk-pooling(A) : Rd×|a| → Rd×k. (9) In Figure 3, after applying k-max pooling (with k = 5) on the intermediate matrix of size 4 × 8, we obtain a new intermediate matrix of size 4× 5. Multiple feature maps. After a group of above operations, we obtain the first order representation learning to recognize the specific m-grams in the input sentence. To obtain higher order representations, we can use a deeper network by repeating these operations. The higher order representations can capture patterns of the sentence in much longer range.\nMeanwhile, we can also extend network to learning multiaspect representations. Let Pi denote the i-th order representation. We can computeKi representations Pi1, · · · ,PiKi in parallel at the same i-th order. Each representation Pij is computed by two steps. First, we compute convolution on each representation Pi−1k at the lower order i − 1 with the distinct filter bank Fij,k and bias bank B i j,k and then sum up the results. Second, non-linear activation and k-max pooling are applied to the summation result:\nPij = k-pooling(α( Ki−1∑ k=1 conv(Pi−1k ,F i j,k,B i j,k))). (10)\nIn Figure 3, there are two representations at the first order and two representations at the second order: P11 ∈ R4×5,P12 ∈ R4×5 and P21 ∈ R4×3,P22 ∈ R4×3. Full connection. Full connection is a linear operation to combine all representations at the highest order into a single vector. More specifically, for the highest order representations Ph1 , · · · ,PhKh (assume P h k ∈ Rd×l), we first flat them into a vector p ∈ RKh×d×l. Then we transform it with a dense matrix H ∈ R(Kh×d×l)×n:\nx = pTH, (11)\nwhere x ∈ Rn is the final representation vector. The values in matrix H are parameters optimized during training. The representation size n is a hyper-parameter of the model.\nIn Figure 3, we finally represent the input sentence with a vector of size n = 5."
    }, {
      "heading" : "Matching items",
      "text" : "We compute the compatibility probability between two items with function f(·), which is a Siamese Convolutional Neural Network as shown in Figure 4."
    }, {
      "heading" : "Same Parameter",
      "text" : "Siamese setup is introduced by Hadsell et al. (Hadsell, Chopra, and LeCun 2006) and used widely in learning distance metrics. When designing the amalgamation part of our model, we have considered its scalability for big data scenarios, which is critical for real-world applications.\nStyle space. For two given items q and c, after generating the representation vectors xq ∈ Rn and xc ∈ Rn of their title sentences respectively, we compute the compatibility probability between them as follow:\nP (y = 1|q, c) = σ(xTq Mxc + b)\n= 1\n1 + e−(x T q Mxc+b)\n, (12)\nwhere M ∈ Rn×n is a matrix and b is a scalar. We call M as the compatibility matrix and the space spanned by M as the style space. After transformation x′q = x T q M, x ′ q represents the item which is most style compatible to q. We seek items whose representations are close to x′q under linear kernel distance. The values in compatibility matrix M and the bias b are parameters optimized during the training.\nOn the other hand, xTq Mxc in (12) can be viewed as a noisy-channel model, which has been widely used in the information retrieval and QA system (Echihabi and Marcu 2003) (Bordes, Weston, and Usunier 2014)."
    }, {
      "heading" : "Recommendation",
      "text" : "In recommendation applications, we are usually given a query item set Q = {q1, q2, · · · , qm} and a candidate item set C = {c1, c2, · · · , cn}, where the query item set is relatively small and the candidate item set is usually very large. For each query item qi, we intend to query its K most complementary items from the candidate set C and rank them from high compatibility to low compatibility. When the item candidate set is very large, it is inefficient and even unacceptable to compute the compatibility for all item pairs (qi, cj) and then sort them.\nOur approach can be easily extended to handle these big data scenarios. Given two items q and c, we first generate their representation vectors xq and xc respectively. Then their compatibility probability is computed according to (12). We notice that the function σ(·) in (12) is a monotonic increasing function and b is a learned constant. Thus\nfor a query item q and two candidate items c1, c2, we have:\nP (y = 1|q, c1) ≤ P (y = 1|q, c2) ⇔ xTq Mxc1 ≤ xTq Mxc2 .\n(13)\nBased on this property, we transform the original problem of querying the K most complementary items of q from the item candidate set C into another problem, namely searching K nearest neighbors of x′ (x′q = x T q M) from {xc1 , · · · ,xcn} under the linear kernel distance. It is well known as Maximum Inner Product Search (MIPS). There are many methods solving MIPS efficiently on the large scale data, such as tree techniques (Ram and Gray 2012) and hashing techniques (Shrivastava and Li 2014) (Shen et al. 2015) etc."
    }, {
      "heading" : "Training",
      "text" : "We train the model to maximize the likelihood of a observed relationship training setR, where rij ∈ R:\nrij = { 1 , if items i and j are compatible; 0 , otherwise.\n(14)\nMaximizing the likelihood is equal to minimizing the binary-cross entropy loss function:\nL = − ∑\nrij∈R [rij log(p) + (1− rij) log(1− p)] , (15)\nwhere p = P (y = 1|i, j). The parameters to be optimized in our network are θ1, θ2, which have been mentioned above:\nθ1 = {W,F,B,H} and θ2 = {M, b}, (16)\nnamely the word embeddings matrix W, filter bank F, bias bank B, dense matrix H, compatibility matrix M and compatibility bias b. Note that there are multiple filter banks and bias banks to be learned.\nIn the following sections, we present several crucial details for training our deep learning model."
    }, {
      "heading" : "Regularization",
      "text" : "To alleviate the overfitting issue, we use a popular and efficient regularization technique named dropout (Srivastava et al. 2014). Dropout is applied to the flatted vector p (presented in (11)) before transforming it with the dense matrix H. A portion of units in p are randomly dropped out by setting them to zero during the forward phase, which is helpful for preventing the feature co-adaptation. The dropout rate is a hyper-parameters of the model."
    }, {
      "heading" : "Hyper-parameters",
      "text" : "The hyper-parameters in our deep learning model are set as follows: the embedding dimension is d = 100; the size of filters at the first order representation is m = 3; the number of max values selected by k-max pooling at the first order representation is k = 5; the size of filters at the second order representation is m = 2; the number of max values selected by k-max pooling at the second order representation is\nk = 3; the dimension of the vector used to represent the sentence is n = 100; the dropout rate is p = 0.2. What’s more, there are K1 = 100 representations computed in parallel at the first order representation and K2 = 100 representations computed in parallel at the second order representation."
    }, {
      "heading" : "Optimization",
      "text" : "To optimize our network, we use the Stochastic Gradient Descent (SGD) algorithm with shuffled mini-batches. The parameters are updated through the back propagation framework with Adagrad rule (Duchi, Hazan, and Singer 2011). The batch size is set to 256 and the network is trained for 20 epochs. The training progress will be early stopped if there is no more update to the best loss on the validation set for the last 5 epochs.\nWe train our network on a GPU for speeding up. A Python implementation using Keras1 powered by Theano (Bastien et al. 2012) can process 428k text pairs per minute on a single NVIDIA K2200 GPU."
    }, {
      "heading" : "Experiments",
      "text" : "We evaluate our method on two large datasets: a Chinese dataset from Taobao and an English dataset from Amazon."
    }, {
      "heading" : "Datasets",
      "text" : "Taobao. This dataset is collected from Taobao.com and provide by Alibaba Group2. It includes a Clothing category and there are about 406k compatibility relationships covering 61k items. The compatibility relationships in this dataset are labelled manually by clothes collocation experts.\nAmazon. This dataset is collected from Amazon.com and provided by (McAuley et al. 2015). Though it includes multiple categories, in order to investigate the performance of our approach on both datasets, we mainly focus on the Clothing category. In this category, there are about 12 million compatibility relationships covering 662k items. Unlike the Taobao dataset, the compatibility relationships in Amazon dataset are not labelled manually. They are the copurchase data from Amazon’s recommendations (Linden, Smith, and York 2003)."
    }, {
      "heading" : "Setup",
      "text" : "Our goal is to differentiate compatibility relationships from non-compatibility ones. We consider all positive relationships (compatibility) and generate random non-relationship distractors of the equal size. That is to say the ratio between positive and negative samples in the dataset is 50:50. Then we separate the whole dataset into training, validation and testing sets according to the ratios 80:10:10. Although we do not expect overfitting to be a serious issue in our experiment with the large training set, we still carefully tune our model on the validation set to avoid overfitting on testing set. We compare our approach against baselines from two aspects: visual one and non-visual ones.\n1http://keras.io 2http://tianchi.aliyun.com/datalab/index.htm\nVisual baseline. We take the method in (Veit et al. 2015) as the visual comparison since it is also in the end-to-end fashion. In particular, we consider the specific setting configured with GoogLeNet and naive sampling for two considerations. First, in all situations of their experiments, GoogLeNet (Szegedy et al. 2015) outperforms AlexNet (Krizhevsky, Sutskever, and Hinton 2012). Second, naive sampling means sampling randomly from the dataset, which is consistent with the setup in our experiments. We experiment their method on the Taobao dataset and take the results on the Amazon dataset directly from (Veit et al. 2015).\nNon-visual baselines. We take three methods as the nonvisual comparison:\n1) Naive Bayes on Bag of Words (NBBW). We treat the title sentences from an item pair as the bag-of-words and feed Naive Bayes classifier with it as the feature vector;\n2) Random Forest on Bag of Words (RFBW). Random Forest is capable of modeling extremely complex classification surface. We apply Random Forest classifier on the bag-ofwords representation of the title sentences from an item pair;\n3) Random Forest on Topic Model (RFTM). For the given item pair {q, c}, we first generate the topic representations xq,xc of items q, c by LDA model (Blei, Ng, and Jordan 2003) respectively, where the topic number is set as 100. Then we concatenate them into a single feature vector xq,c and process Random Forest classifier on it.\nThe implementation of Naive Bayes and Random Forest is taken from scikit-learn (Pedregosa et al. 2011). We turned their parameters to obtaine the best loss on the validation set.\nThere is no preprocess on images and texts. All results reported in the following section is on the testing set."
    }, {
      "heading" : "Results",
      "text" : "Comparison to baselines. Tabel 1 shows the corresponding areas under the ROC curves of compatibility prediction on the testing set . The results show clearly that our approach outperforms all other baselines.\nThe visual method collapses on the Taobao dataset because unlike Amazon, Taobao is a Consumer to Consumer (C2C) platform and has few strict requirement about quality of item images uploaded by users. A majority of images are like Figure 2, where the information is mixed up and confusing to learning machines. In contrast, the title description is a highly condensed collection of more attributes besides appearances with few noises. When using title descriptions, a simple method like Naive Bayes on Bag of Words can achieve an acceptable performance and a more sophisticated method like Random Forest on Bag of Words can generate\ncompetitive results. However, using topic models on title descriptions is not a good idea since most title descriptions are short texts. One important reason why our approach achieves better performance is that our approach can recognize specific m-grams and more complicated patterns not captured by bag-of-words models. For instance, the complementary styles of the item titled with “white shirt with blue stripes” and “blue shirt with white stripes” are very different, but they have the same bag-of-words representation.\nThe performance upper bound of our approach on Taobao dataset is limited by the segmentation quality of Chinese. This is one of the reasons that all AUC scores on the Taobao dataset are lower than that on the Amazon dataset.\nTuning sentence model. There are several crucial setups in the sentence model: 1) the word embedding dimension d; 2) the sentence representation dimension n; 3) whether the word embedding matrix W is initialized or not.\nWe show the first ten epochs of training processes of our model on the Taobao dataset with sentence models under different setups in Figure 5, where the standard setup means that we set d = 100, n = 100 and initialize the word embedding matrix with an unsupervised neural language model (Mikolov et al. 2013). We can see that the setup with larger d or n claims better performance. Furthermore, the performance can get better when we continue to increase the value of d or n. In practice, there is a tradeoff between the performance and resources requirement according to specific situations. What’s more, initializing the word embedding matrix W with an unsupervised neural language model is indeed benefit to the convergence rate and the final performance."
    }, {
      "heading" : "Discussion",
      "text" : "Toward general match. While the previous section mainly focuses on clothes matching, we also train classifiers on the other twenty top-level categories from the Amazon dataset and present the results in Table 2. As can be seen, we obtain good accuracy in predicting compatibility relationships in a variety of categories. What’s more, we have also tried to train a single model to predict compatibility relationships for all categories. There appears to be no “silver bullet” and the result is dissatisfactory: the AUC score of that single model is only 0.694.\nThe comparison across categories is particularly interesting. Our approach performs relatively poor on the categories “CDs & Vinyl” and “Digital Music” since the content of music is too rich to be described very clearly in a short title description. In contrast, the title description is long enough to describe an item from the category ‘Musical Instruments’ clearly and thus our approach performs very well on that. In a word, the better titles can describe the attributes of items in a category, the higher performance can be achieved on that category by our approach."
    }, {
      "heading" : "Conclusions",
      "text" : "In this paper, we present a novel approach to model the human sense of style compatibility between items. The basic assumption of our approach is that most of the important attributes for a product in an online store are included in its title description. We design a Siamese Convolutional Neural Network architecture to map the title descriptions of an item pair from the original space of symbolic words into some embedded style space. The compatibility probability between items can be then computed in the style space. Our approach takes only words as the input with few preprocessing and requires no laborious and expensive feature engineering. Moreover, it can be easily extended to big data scenarios with KNN searching techniques. The experiments on two large datasets confirm our assumption and show the possibility of modeling the human sense of style compatibility.\nThere are several interesting problems to be investigated in our future work: (1) we would like to use more sophisticated sentence models without injuring the simplicity of our approach; (2) we are wondering whether it is possible to use the text and image information simultaneously, e.g. hybrid model or mapping the texts and images of items into the same embedded space for mutual retrieval and matching."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank Alibaba Group and Julian McAuley for providing the valuable datasets. This work is supported by Zhejiang Provincial Natural Science Foundation of China (Grant no. LZ13F020001), Zhejiang Provincial Soft Science Project (Grant no. 2015C25053), National Science Foundation of China (Grant nos. 61173185, 61173186)."
    } ],
    "references" : [ {
      "title" : "Theano: new features and speed improvements",
      "author" : [ "Bastien" ],
      "venue" : "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop",
      "citeRegEx" : "Bastien,? \\Q2012\\E",
      "shortCiteRegEx" : "Bastien",
      "year" : 2012
    }, {
      "title" : "Latent dirichlet allocation. the Journal of machine Learning research 3:993–1022",
      "author" : [ "Ng Blei", "D.M. Jordan 2003] Blei", "A.Y. Ng", "M.I. Jordan" ],
      "venue" : null,
      "citeRegEx" : "Blei et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Blei et al\\.",
      "year" : 2003
    }, {
      "title" : "A convolutional neural network for modelling sentences",
      "author" : [ "Blunsom" ],
      "venue" : "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the 52nd Annual Meeting of the Association",
      "citeRegEx" : "Blunsom,? \\Q2014\\E",
      "shortCiteRegEx" : "Blunsom",
      "year" : 2014
    }, {
      "title" : "Open question answering with weakly supervised embedding models",
      "author" : [ "Weston Bordes", "A. Usunier 2014] Bordes", "J. Weston", "N. Usunier" ],
      "venue" : "In Machine Learning and Knowledge Discovery in Databases",
      "citeRegEx" : "Bordes et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2014
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "Hazan Duchi", "J. Singer 2011] Duchi", "E. Hazan", "Y. Singer" ],
      "venue" : "The Journal of Machine Learning Research 12:2121–2159",
      "citeRegEx" : "Duchi et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2011
    }, {
      "title" : "A noisy-channel approach to question answering",
      "author" : [ "Echihabi", "A. Marcu 2003] Echihabi", "D. Marcu" ],
      "venue" : "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume",
      "citeRegEx" : "Echihabi et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Echihabi et al\\.",
      "year" : 2003
    }, {
      "title" : "Dimensionality reduction by learning an invariant mapping",
      "author" : [ "Chopra Hadsell", "R. LeCun 2006] Hadsell", "S. Chopra", "Y. LeCun" ],
      "venue" : "In Computer vision and pattern recognition,",
      "citeRegEx" : "Hadsell et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hadsell et al\\.",
      "year" : 2006
    }, {
      "title" : "Mining frequent patterns without candidate generation",
      "author" : [ "Pei Han", "J. Yin 2000] Han", "J. Pei", "Y. Yin" ],
      "venue" : "In ACM SIGMOD Record,",
      "citeRegEx" : "Han et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2000
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 1097–1105",
      "author" : [ "Sutskever Krizhevsky", "A. Hinton 2012] Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Image-based recommendations on styles and substitutes",
      "author" : [ "McAuley" ],
      "venue" : null,
      "citeRegEx" : "McAuley,? \\Q2015\\E",
      "shortCiteRegEx" : "McAuley",
      "year" : 2015
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Mikolov" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Mikolov,? \\Q2013\\E",
      "shortCiteRegEx" : "Mikolov",
      "year" : 2013
    }, {
      "title" : "Content-based recommendation systems",
      "author" : [ "Pazzani", "M.J. Billsus 2007] Pazzani", "D. Billsus" ],
      "venue" : null,
      "citeRegEx" : "Pazzani et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Pazzani et al\\.",
      "year" : 2007
    }, {
      "title" : "Scikit-learn: Machine learning in Python",
      "author" : [ "Pedregosa" ],
      "venue" : null,
      "citeRegEx" : "Pedregosa,? \\Q2011\\E",
      "shortCiteRegEx" : "Pedregosa",
      "year" : 2011
    }, {
      "title" : "Maximum inner-product search using cone trees",
      "author" : [ "Ram", "P. Gray 2012] Ram", "A.G. Gray" ],
      "venue" : "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "Ram et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ram et al\\.",
      "year" : 2012
    }, {
      "title" : "Methods and metrics for coldstart recommendations",
      "author" : [ "Schein" ],
      "venue" : "In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,",
      "citeRegEx" : "Schein,? \\Q2002\\E",
      "shortCiteRegEx" : "Schein",
      "year" : 2002
    }, {
      "title" : "Learning binary codes for maximum inner product search",
      "author" : [ "Shen" ],
      "venue" : "In Proceedings of the IEEE International Conference on Computer Vision,",
      "citeRegEx" : "Shen,? \\Q2015\\E",
      "shortCiteRegEx" : "Shen",
      "year" : 2015
    }, {
      "title" : "Asymmetric lsh (alsh) for sublinear time maximum inner product search (mips)",
      "author" : [ "Shrivastava", "A. Li 2014] Shrivastava", "P. Li" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Shrivastava et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Shrivastava et al\\.",
      "year" : 2014
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "Srivastava" ],
      "venue" : "The Journal of Machine Learning Research",
      "citeRegEx" : "Srivastava,? \\Q2014\\E",
      "shortCiteRegEx" : "Srivastava",
      "year" : 2014
    }, {
      "title" : "Going deeper with convolutions",
      "author" : [ "Szegedy" ],
      "venue" : "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Szegedy,? \\Q2015\\E",
      "shortCiteRegEx" : "Szegedy",
      "year" : 2015
    }, {
      "title" : "Learning visual clothing style with heterogeneous dyadic co-occurrences",
      "author" : [ "Veit" ],
      "venue" : "In Proceedings of the IEEE International Conference on Computer Vision,",
      "citeRegEx" : "Veit,? \\Q2015\\E",
      "shortCiteRegEx" : "Veit",
      "year" : 2015
    } ],
    "referenceMentions" : [ ],
    "year" : 2017,
    "abstractText" : "Humans develop a common sense of style compatibility between items based on their attributes. We seek to automatically answer questions like “Does this shirt go well with that pair of jeans?” In order to answer these kinds of questions, we attempt to model human sense of style compatibility in this paper. The basic assumption of our approach is that most of the important attributes for a product in an online store are included in its title description. Therefore it is feasible to learn style compatibility from these descriptions. We design a Siamese Convolutional Neural Network architecture and feed it with title pairs of items, which are either compatible or incompatible. Those pairs will be mapped from the original space of symbolic words into some embedded style space. Our approach takes only words as the input with few preprocessing and there is no laborious and expensive feature engineering.",
    "creator" : "LaTeX with hyperref package"
  }
}