{
  "name" : "1703.06815.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "r.s.miller}@ucl.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 3.\n06 81\n5v 2\n[ cs\n.A I]\n3 0\nJu n\n20 17\nFoundations for a Probabilistic Event Calculus\nTechnical Report\nFabio A. D’Asaro, Antonis Bikakis, Luke Dickens and Rob Miller\n{uczcfad, a.bikakis, l.dickens, r.s.miller}@ucl.ac.uk\nDepartment of Information Studies\nUniversity College London"
    }, {
      "heading" : "1 Introduction",
      "text" : "The Event Calculus (EC) [9] is a well-known approach to reasoning about the effects of\na narrative of action occurrences (events) along a time line. This paper describes PEC, an\nadaptation of EC able to reason with probabilistic causal knowledge. There are numerous\napplications for this kind of probabilistic reasoning, e.g. in modelling medical, environ-\nmental, legal and commonsense domains, and in complex activity recognition and security\nmonitoring. PEC’s main characteristics are: i) it supports EC-style narrative reasoning, ii)\nit uses a possible worlds semantics to naturally allow for epistemic extensions, iii) it uses a\ntailored action language syntax and semantics, iv) its generality allows in principle for the\nuse of other models of uncertainty, e.g. Fuzzy Logic [20] or Dempster-Schafer Theory [4],\nand v) for a wide subset of domains it has a sound and complete ASP implementation.\nAlthough other formalisms exist for probabilistic reasoning about actions, PEC is, to our knowledge, the only framework to combine these features. We use the following two\nexample scenarios to illustrate the main definitions and characteristics of our framework.\nScenario 1 (Coin Toss). A coin initially (instant 0) shows Heads. A robot can attempt to toss the coin, but there is a small chance that it will fail to pick it up, leaving the coin unchanged. The robot attempts to toss the coin (instant 1).\nScenario 2 (Antibiotic). A patient has a rash often associated with a bacterial infection, and can take an antibiotic known to be reasonably effective. Treatment is not always successful,\nand if not may still clear the rash. Failed treatment leaves the bacteria resistant. The patient is treated twice (instants 1 and 3).\nScenario 3 (Keys). Leaving the house without first picking up the keys causes being locked\nout. In the context of a daily routine, there is a small chance that a person forgets to pick\nup the keys before leaving the house at 7:40 AM."
    }, {
      "heading" : "2 PEC",
      "text" : ""
    }, {
      "heading" : "2.1 Syntax",
      "text" : "Definition 1 (Domain Language). A domain language is a tuple L = 〈F ,A,V, vals,I,≤ , 0̄〉 consisting of a finite non-empty set F of fluents, a finite set A of actions, a finite non-\nempty set V of values such that {⊤,⊥} ⊆ V , a function vals : F∪A → 2V \\∅, a non-empty set I of instants and a minimum element 0̄ ∈ I w.r.t. a total ordering ≤ over I . For A ∈ A we impose vals(A) = {⊤,⊥}.\nExample 1. An appropriate domain language for Scenario 1 would be LC = 〈FC ,AC ,VC , valsC ,N,≤N, 0〉 where, FC = {Coin}, AC = {Toss}, VC = {⊤,⊥,Heads,Tails}, valsC(Coin) = {Heads,Tails} and valsC(Toss) = {⊤,⊥}, N is the set of natural numbers (including 0), and ≤N is the standard total ordering between naturals. Scenario 2 could be captured by a language 〈FA,AA,VA, valsA,N,≤N, 0〉 where FA = {Bacteria,Rash}, AA = {TakesMedicine}, VA = {⊤,⊥,Weak,Present,Resistant,Absent}, and valsA is defined by valsA(Bacteria) = {Weak,Resistant,Absent} and valsA(Rash) = {Present,Absent}.\nIn what follows, all definitions are with respect to a domain language L = 〈F ,A,V, vals,I,≤, 0̄〉.\nWe begin by defining what a (fluent) literal and a formula are in this language. Literals\nand formulas with time information attached are called i-literals and i-formulas respectively.\nDefinition 2 (Fluent and Action Literals, i-literals). A fluent literal is an expression of the form F =V for some F ∈ F and V ∈ vals(F ). A fluent is boolean if vals(F ) = {⊤,⊥}. An action literal is either A=⊤ or A=⊥. When no ambiguity can arise, Z=⊤ is sometimes abbreviated to Z and Z=⊥ is abbreviated to ¬Z for Z a fluent or action. An i-literal is an expression of the form [L]@I for some (fluent or action) literal L and some I ∈ I .\nDefinition 3 (Formulas, i-formulas). The set of formulas, denoted by Θ, is the closure of the set of literals under ∧ and ¬ (with ∨ and → being defined as shorthand in the usual way). The set of i-formulas, denoted by Φ, is the closure of the set of i-literals under ∧ and ¬. We use the shorthand [θ]@I for the i-formula formed from the formula θ and the instant I by replacing all literals L occurring in θ by [L]@I , e.g. [F =V → F ′=V ′]@3 is a shorthand for [F =V ]@3 → [F ′=V ′]@3.\nExample 2. In Scenario 1 the i-literal [Coin=Heads]@3 indicates that the coin shows heads at instant 3, while [¬Toss]@2 indicates that the robot does not attempt to toss the coin at instant 2. In Scenario 2, [Rash=Present]@0∧[Bacteria=Absent∧TakesMedicine]@3 indicates that the patient initially has a rash, and that she takes the medicine and the bacterial infection is absent at instant 3.\nDefinition 4 (State, Partial State, Fluent State). A state S is a set of literals, exactly one for each F ∈ F and A ∈ A. A partial state is a subset X ⊆ S of a state S. Given a partial state X, we call its subset containing all and only the fluent literals in X a partial fluent state, and we denote it as X↾F . For a state S we call S↾F a fluent state. We also define X↾A as the subset ofX containing all and only the action literals inX. The set of all states is denoted by S , the set of all partial states is denoted by X , and we use S̃ and X̃ to denote the sets {S↾F | S ∈ S} and {X↾F | X ∈ X} respectively.\nExample 3. One of the states we can build with the elements of the domain language 〈FA,AA,VA, valsA,N,≤N, 0〉 for Scenario 2 is S 1 A = {Bacteria=Resistant,Rash=Absent,¬TakesMedicine}. Its associated fluent state is\nS1A↾F = {Bacteria=Resistant,Rash=Absent}. Any arbitrary subset of S 1 A, e.g. X1A = {Rash=Absent,¬TakesMedicine}, is a partial state, whereas any arbitrary subset of S1A↾F , e.g. X 1 A↾F = {Rash=Absent}, is a partial fluent state. Definition 5 (Outcome, Projection Functions). An outcome is a pair of the form (X̃, P+) for some X̃ ∈ X̃ and P+ ∈ (0, 1]. The two projection functions χ and π are such that χ((X̃, P+)) = X̃ and π((X̃, P+)) = P+ for any outcome. The set of all outcomes X̃ × (0, 1] will be denoted by O.\nDefinition 6 (Weight of a Set of Outcomes). Given a finite set of outcomes\nB = {O1, O2, . . . , Om}\nwe define the weight of O as\nπ(B) = m ∑\ni=1\nπ(Oi).\nNotation 1. In the following, we will generally use:\nI, I ′, I1, I ′′, I2, . . . to denote elements of I , A,A′, A1, A ′′, A2, . . . to denote elements of A, F,F ′, F1, F ′′, F2, . . . to denote elements of F , V, V ′, V1, V ′′, V2, . . . to denote elements of V , θ, θ′, θ1, θ ′′, θ2, . . . to denote formulas, ϕ,ϕ′, ϕ1, ϕ ′′, ϕ2, . . . to denote i-formulas, P,P ′, P1, P ′′, P2, . . . to denote real values in [0, 1], P+, P+1 , P + 2 , . . . to denote real values in (0, 1], S, S′, S1, S ′′, S2, . . . to denote elements of S , X,X ′,X1,X ′′,X2, . . . to denote elements of X , S̃, S̃′, S̃1, S̃ ′′, S̃2, . . . to denote elements of S̃ , X̃, X̃ ′, X̃1, X̃ ′′, X̃2, . . . to denote elements of X̃ , O,O′, O1, O ′′, O2, . . . to denote outcomes.\nWe now introduce the standard propositions of our language: v-propositions are used\nto declare which value a fluent may take, c-propositions are used to model the causal rela-\ntionships of a domain, i-propositions declare the initial conditions, p-propositions are for\nthe action occurrences, and h-propositions state that a given i-formula holds.\nDefinition 7 (v-proposition). A v-proposition has the form\nF takes-values {V1, . . . , Vm} (1)\nwhere m ≥ 1 and {V1, . . . , Vm} = vals(F ).\nDefinition 8 (c-proposition, Head and Body of a c-proposition). A c-proposition c has the form\nθ causes-one-of {O1, O2, . . . , Om} (2)\nwhere Oi ∈ O, χ(Oi) 6= χ(Oj) when i 6= j, θ is a formula such that θ Herbrand-entails 1 A=⊤ for at least one A ∈ A, and π({O1, . . . , Om}) = 1. body(C) = θ and head(C) = {O1, . . . , Om} are the body and head of C , respectively. We often omit Oi from head(C) if χ(Oi) = ∅ (leaving it implicit since π({O1, . . . , Om}) = 1).\n1For two formulas θ and θ′ we write that θ Herbrand-entails θ′ if, taking literals as propositions, every\nclassical Herbrand model of θ is also a Herbrand model of θ′.\nDefinition 9 (i-proposition). An i-proposition has the form\ninitially-one-of {O1, O2, . . . , Om} (3)\nwhere Oi∈O, π({O1, . . . , Om})=1, χ(Oi)∈S̃ , and χ(Oi) 6=χ(Oj) when i 6=j.\nDefinition 10 (p-proposition). A p-proposition has the form\nA performed-at I with-prob P+ (4)\nwhere P+ ∈ (0, 1] and I is such that I < I ′ for some other I ′ ∈ I . When a p-proposition p has the form (4) we say that p has instant I .\nIn the following, we will frequently use"
    }, {
      "heading" : "A performed-at I",
      "text" : "as a shorthand for the p-proposition"
    }, {
      "heading" : "A performed-at I with-prob 1.",
      "text" : "Notation 2. In the following, we will generally use lowercase letters to denote propositions, e.g. c, c′, c1, c ′′, c2, . . . will be used for c-propositions.\nDefinition 11 (Domain Description). A domain description is a finite set D of vpropositions, c-propositions, p-propositions and i-propositions such that: (i) for any two distinct c-propositions in D with bodies θ and θ′ respectively, θ does not Herbrand-entail θ′, (ii) D contains exactly one i-proposition, (iii) D contains exactly one v-proposition for each F ∈ F and (iv) if a p-proposition “A performed-at I with-prob P ′” belongs to D, then there is no other p-proposition of the form “A performed-at I with-prob P ′′” for some P ′′ ∈ (0, 1] that belongs to D.\nDefinition 12 (Action Narrative). An action narrative is any finite set of p-propositions. For D a domain description, we define the action narrative narr(D) as the set of all ppropositions in D.\nExample 4. Scenario 1 can be modeled using the following domain description DC :\nCoin takes-values {Heads,Tails} (C1)\ninitially-one-of {({Coin = Heads}, 1)} (C2)\nToss causes-one-of (C3)\n{({Coin = Heads}, 0.49), ({Coin = Tails}, 0.49), (∅, 0.02)}\nToss performed-at 1 (C4)\nwhere (C1) is a v-proposition, (C2) is an i-proposition, (C3) is a c-proposition and (C4) is\na p-proposition.\nExample 5. Scenario 2 can be modeled using the following domain description DA:\nBacteria takes-values {Weak,Resistant,Absent} (A1)\nRash takes-values {Present,Absent} (A2)\ninitially-one-of (A3)\n{({Bacteria = Weak,Rash = Present}, 9/10), ({Bacteria = Absent,Rash = Present}, 1/10)}\nTakesMedicine ∧ Bacteria = Weak (A4) causes-one-of\n{({Bacteria = Absent,Rash = Absent}, 7/10), ({Bacteria = Resistant,Rash = Absent}, 1/10), ({Bacteria = Resistant}, 2/10)}\nTakesMedicine ∧ Bacteria = Resistant (A5) causes-one-of\n{({Bacteria = Absent,Rash = Absent}, 1/13), (∅, 12/13)}\nTakesMedicine performed-at 1 (A6)\nTakesMedicine performed-at 3 (A7)\nwhere (A1) and (A2) are v-propositions, (A3) is an i-proposition, (A4) and (A5) are c-\npropositions, (A6) and (A7) are p-propositions.\nExample 6. Scenario 3 can be modeled using the following domain description DK :\nHasKeys takes-values {⊤,⊥} (K1)\nLockedOut takes-values {⊤,⊥} (K2)\nLocation takes-values {Inside,Outside} (K3)\ninitially-one-of {({¬HasKeys,¬LockedOut,Location= Inside}, 1)} (K4)\nGoOut ∧ ¬HasKeys ∧ Location= Inside (K5) causes-one-of\n{({LockedOut,Location=Outside}, 1)}\nGoOut ∧ HasKeys ∧ Location= Inside (K6) causes-one-of {({Location=Outside}, 1)}\nPickupKeys ∧ Location= Inside (K7) causes-one-of {({HasKeys}, 1)}\nPickupKeys performed-at 7:30 AM with-prob 0.99 (K8)\nGoOut performed-at 7:40 AM (K9)\nFinally, we introduce h-propositions, whose role is that of being entailed by domain\ndescriptions:\nDefinition 13 (h-proposition). An h-proposition has the form\nϕ holds-with-prob P. (5)\nfor some i-formula ϕ.\nFor example, we will show in the following sections the formal sense in which DC entails the h-proposition “[Coin=Heads]@2 holds-with-prob 0.51”."
    }, {
      "heading" : "2.2 Semantics",
      "text" : "For the remainder of this paper, D is an arbitrary domain description.\nDefinition 14 (Worlds). A world is a functionW : I → S . The set of all worlds is denoted by W .\nNotation 3. In the following, we will use W,W ′,W ′′,W1,W2, . . . to denote worlds.\nDefinition 15 (Satisfaction of an i-formula, Logical Consequence for i-formulas). Given a world W and a literal L, W satisfies an i-formula [L]@I , written W ||= [L]@I , iff L ∈ W (I)2. Otherwise we write W ||6= [L]@I . The definition of ||= is recursively extended for arbitrary i-formulas as follows: if ϕ and ϕ′ are i-formulas, we write W ||= ϕ ∧ ϕ′ iff W ||= ϕ and W ||=′, and W ||= ¬ϕ iff W ||6= ϕ. ∨ and → are taken as shorthand in the usual way. Given a (possibly empty) set ∆ of i-formulas, we write W ||= ∆ iff W ||= ψ for all ψ ∈ ∆. Given an i-formula ϕ and a set ∆ of i-formulas we write ∆ ||= ϕ if for all W ∈ W such that W ||= ∆, W ||= ϕ also holds. For two i-formulas ψ and ϕ, we use ψ ||= ϕ as a shorthand for {ψ} ||= ϕ, and ||= ϕ as a shorthand for ∅ ||= ϕ.\nExample 7. Three worlds for Scenario 1 can be specified as follows:\nW1(0) = {Coin = Heads, Toss = ⊥}, W1(1) = {Coin = Heads, Toss = ⊤}, W1(I) = {Coin = Tails, Toss = ⊥} for all I ≥ 2.\nW2(0) = {Coin = Tails, Toss = ⊥}, W2(1) = {Coin = Heads, Toss = ⊥}, W2(I) = {Coin = Tails, Toss = ⊤} for all I ≥ 2.\nW3(0) = {Coin = Heads, Toss = ⊥}, W3(1) = {Coin = Heads, Toss = ⊤}, W3(I) = {Coin = Heads, Toss = ⊥} for all I ≥ 2.\n2The symbols ||= and ||6= should not be confused with |= and 6|=which we use for the classical propositional entailment\nIntuitively, W1 and W3 match the domain description in Example 4 as they represent a coherent history of what could have happened in Scenario 1, whereas W2 does not (e.g., changes occur when no action is performed, an infinite number of actions is being per-\nformed, etc. . . ). This intuition will be made precise in what follows.\nSince worlds are functions from instants to states, they can conveniently be depicted as\ntimelines as follows:\nW1 i\n{Coin = Heads,\nToss = ⊥}\n{Coin = Heads,\nToss = ⊤}\n{Coin = Tails,\nToss = ⊥}\n0 1 ≥ 2\nW2 i\n{Coin = Tails,\nToss = ⊥}\n{Coin = Heads,\nToss = ⊥}\n{Coin = Tails,\nToss = ⊤}\n0 1 ≥ 2\nW3 i\n{Coin = Heads,\nToss = ⊥}\n{Coin = Heads,\nToss = ⊤}\n{Coin = Heads,\nToss = ⊥}\n0 1 ≥ 2\nDefinition 16 (Closed World Assumption for Actions). A world W is said to satisfy the closed world assumption for actions (or CWA for actions, for short) w.r.t. D if it satisfies the following condition: for all A ∈ A and I ∈ I , if W ||= [A]@I then there exists some P+ ∈ (0, 1] such that “A performed-at I with-prob P+” is in D. Furthermore, if for some A ∈ A and I ∈ I the p-proposition “A performed-at I with-prob 1” is in D then it must be the case that W ||= [A]@I .\nExample 8. Let W1, W2 and W3 be the worlds in Example 7, and let DC be the domain description in Example 4. World W1 satisfies CWA for actions w.r.t. DC as Toss ∈ W1(I) if and only if I = 1, which is consistent with (C4) being the only p-proposition in DC . CWA is not satisfied by W2 as ¬Toss ∈ W2(1), i.e. W2 ||= [¬Toss]@1, but this is not consistent with (C4). W3 satisfies CWA for actions for the same reason as W1.\nDefinition 17 (Cause Occurrence). Let θ be the body of a c-proposition c in a domain description D and I ∈ I . If W ||= [θ]@I then we say that that a cause occurs at instant I in W w.r.t. to D, and that the c-proposition c is activated at I in W w.r.t. D. We write occD(W ) for the set {I ∈ I | a cause occurs at I inW}. The function cpropD with domain {(W, I) | W ∈ W, I ∈ occD(W )} is defined for instants I in its domain as cpropD(W, I) = c where c is the (unique) c-proposition activated at I in world W .\nExample 9. Let DC be as in Example 4 and W1, W2 and W3 be as in Example 7. Since W1 ||= [Toss]@I if and only if I = 1 (and similarly for W3), we derive that occDC (W1) = occDC (W3) = {1}, with cpropDC (W1, 1) = cpropDC (W3, 1) = (C3). For W2, occDC (W2) is defined as {I | I ∈ N, I ≥ 2} with cpropDC (W2, I) = (C3) for I ≥ 2.\nDefinition 18 (Initial Choice). LetD be a domain description and the unique i-proposition in D be of the form (3). Each O1, O2, . . . , Om is called an initial choice w.r.t. D.\nDefinition 19 (Effect Choice). Let W be a world and D a domain description. An effect choice for W w.r.t. D is a function ec : occD(W ) → O such that for all instants I ∈ occD(W ), ec(I) ∈ head(cpropD(W, I)).\nExample 10. Let DC be as in Example 4 and W1, W2 and W3 be as in Example 7. The only initial choice w.r.t. DC is ic1 = ({Coin = Heads}, 1). The only effect choices for W1 w.r.t. DC are ec1(1) = ({Coin = Tails}, 49/100), ec2(1) = ({Coin = Heads}, 49/100) and ec3(1) = (∅, 2/100). Notice that since occDC (W1) = occDC (W3), all the effect choices for W1 are also effect choices for W3. There are an (uncountably) infinite number of effect choices for W2 w.r.t. DC , each one mapping each instant I ≥ 2 to ({Coin = Heads}, 49/100), ({Coin = Tails}, 49/100) or (∅, 2/100).\nDefinition 20 (Initial Condition). A world W is said to satisfy the initial condition w.r.t. D if there exists an initial choice ic w.r.t. D such that W (0̄)↾F = χ(ic). If a world W satisfies the initial condition w.r.t. D for some initial choice ic, then we say that W and ic are consistent with each other w.r.t. D.\nExample 11. Let DC be as in Example 4, and W1, W2 and W3 be as in 7. Since ic1 = ({Coin = Heads}, 1) is the only initial choice w.r.t. DC as outlined in Example 10, W1 and W3 are consistent w.r.t. DC with it, since W1(0)↾F = W3(0)↾F = χ(ic1). Therefore, W1 and W3 satisfy the initial condition w.r.t. DC . Since W2(0)↾F 6= χ(ic1), W2 does not satisfy the initial condition.\nDefinition 21 (Intervals). Given two instants I and I ′ such that I ≤ I ′, the intervals [I, I ′], [I, I ′), (I, I ′] and (I, I ′) are defined in the standard way w.r.t. the total order ≤. We also use [I,+∞) as shorthand for the set {I ′ | I ′ ∈ I, I ′ ≥ I}, (−∞, I] as shorthand for {I ′ | I ′ ∈ I, I ′ ≤ I}, (I,+∞) as a shorthand for [I,∞) \\ {I} and (−∞, I) as a shorthand for (−∞, I] \\ {I}.\nDefinition 22 (Fluent State Update). Given a fluent state S̃ and a partial fluent state X̃, the update of S̃ w.r.t. X̃ , written S̃ ⊕ X̃ , is the fluent state (S̃ ⊖ X̃) ∪ X̃ , where S̃ ⊖ X̃ is the partial fluent state formed by removing all fluent literals from S̃ of the form F = V for some F and V ′ such that F = V ′ ∈ X̃ . The operator ⊕ is left-associative, so e.g. S̃ ⊕ X̃ ⊕ X̃ ′ is understood as ((S̃ ⊕ X̃)⊕ X̃ ′).\nDefinition 23 (Justified Change). A world W is said to satisfy the justified change condition w.r.t. D if and only if there exists an effect choice ec w.r.t. D such that for all instants I and I ′ with I < I ′, ec maps the possibly empty set of instants in occD(W ) ∩ [I, I\n′) = {I1, . . . , In} to O1, O2, . . . , On respectively, where I1, . . . , In are ordered w.r.t. ≤, and\nW (I ′)↾F = (W (I)↾F)⊕ χ(O1)⊕ χ(O2)⊕ · · · ⊕ χ(On) (6)\nIf a world W satisfies the justified change condition for some effect choice ec, W and ec are said to be consistent with each other w.r.t. D.\nExample 12. Let DC be as in Example 4,W1,W2 be as in Example 7, and ec1 be defined as in Example 10.\nFor any two instants I , I ′ ∈ N with I < I ′, if [I, I ′) ∩ occDC (W1) = ∅ then clearly W1(I ′)↾F = W1(I)↾F . Otherwise, if [I, I ′)∩occDC (W1) 6= ∅, i.e. [I, I\n′)∩occDC (W1) = {1} then (6) holds as W1(I)↾F ⊕ χ(ec1(1)) = {Coin = Tails} = W (I\n′)↾F . So the justified change condition w.r.t. DC is satisfied by W1.\nFor W to satisfy the justified change condition w.r.t. DC , equation (6) would require W2(0)↾F = W2(1)↾F (as occDC (W2) ∩ [1, 2) = ∅), but this is not the case. Hence, W2 does not satisfy the justified change condition w.r.t. DC .\nDefinition 24 (Well-behaved Worlds). A world is said to be well-behaved w.r.t. D if it satisfies CWA for actions, the initial condition and the justified change condition w.r.t. D. We denote the set of well-behaved worlds w.r.t. D withWD.\nExample 13. Let DC be as in Example 4 and W1, W2 be as in Example 7. W1 is wellbehaved as it satisfies CWA (see Example 8), the initial condition (see Example 11) and the justified change condition (see Example 12) w.r.t. DC . W2 is not well-behaved as it fails to satisfy any of these conditions.\nDefinition 25 (Candidate Trace, Trace). A candidate trace is a function tr : dom(tr) ∪ { ⊲⊳} → O where dom(tr) ⊆ I and ⊲⊳ is a new symbol such that ⊲⊳ /∈ I . For readability, we will sometimes write 〈tr( ⊲⊳)@ ⊲⊳, tr(I1)@I1, . . . , tr(Im)@Im〉 where dom(tr) = {I1, . . . , Im} and the instants are ordered w.r.t. ≤.\nIf W is well-behaved w.r.t. D and is consistent with the initial choice ic and the effect choice ec w.r.t. D, then tr is said to be a trace of W w.r.t. D if dom(tr) = occD(W ) and tr( ⊲⊳) = ic and for all I ∈ dom(tr), tr(I) = ec(I) and in this case we will sometimes write tr = (ic, ec).\nFor any W ∈ W , we write TRWD for the set of all traces of W w.r.t. D, and notice that TRWD 6= ∅ if and only if W is well-behaved.\nA well-behaved world can have multiple traces, as shown in the following example.\nExample 14. Let DC be as in Example 4, W3 be as in Example 7 and ic1, ec2, ec3 be as defined in Example 10. World W3 has two distinct traces, tr ′ 3 = (ic1, ec2) and tr ′′ 3 = (ic1, ec3), which disagree on the effect choice: in one case the robot manages to toss the coin producing Coin = Heads as a result (i.e., tr′3(1) = ({Coin = Heads}, 0.49)) whereas in the other case the robot fails to grab the coin (i.e., tr′′3(1) = (∅, 0.02)) leaving Coin = Heads to hold. These two traces are also the only traces of this world w.r.t. DC .\nHowever, for some candidate traces tr there exists no well-behaved worldW such that tr is a trace of W . We now generalise Definition 25 to domain descriptions:\nDefinition 26 (Trace of a Domain Description). Given a candidate trace tr, if there exists a well-behaved world W w.r.t. D such that tr is a trace of W w.r.t. D, then tr is said to be a trace of D.\nDefinition 27 (Evaluation of a Trace). Let tr be a candidate trace. The evaluation of tr, written ǫ(tr), is defined as:\nǫ(tr) = π(tr( ⊲⊳)) · ∏\nI∈dom(tr)\nπ(tr(I)) (7)\nDefinition 28 (Evaluation of a Narrative). Given a p-proposition p of the form “A performed-at I with-prob P+”, we define the evaluation of p w.r.t. W as\nǫ(p,W ) =\n{\nP+ if W ||= [A]@I 1− P+ otherwise (8)\nFor an action narrative N (see Definition 12) we extend the previous definition to:\nǫ(N,W ) = ∏\np∈N\nǫ(p,W ). (9)\nand write ǫD(W ) as a shorthand for ǫ(narr(D),W ). Conventionally, ǫ(N,W ) = 1 when N = ∅.\nDefinition 29 ([0, 1]-interpretation). A [0,1]-interpretation is a function from W to [0, 1].\nDefinition 30 (Model). A model of a domain description D is a [0, 1]-interpretation MD such that\n1. If W ∈ W is not well-behaved w.r.t. D,\nMD(W ) = 0, (10)\n2. If W ∈ W is well-behaved w.r.t. D,\nMD(W ) = ǫD(W ) · ∑\ntr∈TRWD\nǫ(tr). (11)\nExample 15. Let DC be as in Example 4 and W3 be as Example 7. As discussed in Example 14, W3 has exactly two traces tr ′ 3 = (ic1, ec2) and tr ′′ 3 = (ic1, ec3). Equations (7) and (11) yield:\nMDC (3) = ǫ(tr ′ 3) + ǫ(tr ′′ 3) = 0.49 + 0.02 = 0.51\nProposition 1. A domain description D has a unique model.\nProof. This can be derived from Definition 30 by considering that MD(W ) is calculated as a product of functions of the states of W .\nDefinition 31. We extend the model MD to a function M ∗ D : Φ → [0, 1] over i-formulas in the following way:\nM∗D(ϕ) = ∑\nW ||=ϕ\nMD(W ).\nDefinition 32 (Entailment for Domain Descriptions). Given a domain description D and an i-formula ϕ, we say that the h-proposition “ϕ holds-with-prob P” is entailed by D iff M∗D(ϕ) = P .\nExample 16. For DC as in Example 4, the only well-behaved world W such that W ||= [Coin=Heads]@2 isW3. Definition 31 and Example 15 yield\nM∗DC ([Coin=Heads]@2) = MDC (W3) = 0.51.\nThe reader can verify that [Coin=Heads]@0 yields\nM∗DC ([Coin=Heads]@0) = MDC (W1) +MDC (W3) = 1\nand from this we can derive that DC entails the two following h-propositions:\n[Coin=Heads]@2 holds-with-prob 0.51,\n[Coin=Heads]@0 holds-with-prob 1.\nExample 17. Let DK be as in Example 6. Assuming 0̄ = 7:30 AM, the only two wellbehaved worlds w.r.t. DK are:\nW1 i\n{¬HasKeys, ¬LockedOut,\nLocation= Inside,\nPickupKeys,\n¬GoOut}\n{HasKeys,\n¬LockedOut,\nLocation= Inside,\n¬PickupKeys,\nGoOut}\n{HasKeys,\n¬LockedOut,\nLocation=Outside,\n¬PickupKeys,\n¬GoOut}\n7:30 AM 7:40 AM >7:40 AM\nW2 i\n{¬HasKeys, ¬LockedOut,\nLocation= Inside,\n¬PickupKeys,\n¬GoOut}\n{¬HasKeys, ¬LockedOut,\nLocation= Inside,\n¬PickupKeys,\nGoOut}\n{¬HasKeys, LockedOut,\nLocation=Outside,\n¬PickupKeys,\n¬GoOut}\n7:30 AM 7:40 AM >7:40 AM\nSince both actions GoOut and PickupKeys have definite effects (i.e., outcomes in the head of the corresponding c-propositions have probability equal to 1), the only significant factors in the calculation ofMDK are those given by the evaluation of the action narrative:\nMDK (W1) = ǫDK (W1) = 0.99\nMDK (W2) = ǫDK (W2) = 0.01\nimplying that DK entails the following propositions:\n[LockedOut]@9AM holds-with-prob 0.01,\n[HasKeys]@9AM holds-with-prob 0.99."
    }, {
      "heading" : "2.3 Properties of a model",
      "text" : "We now introduce the concept of a probability function, adapted from [15]:\nDefinition 33 (Probability Function, Conditional Probability). A probability function (over i-formulas) is a function p : Φ → [0, 1] such that:\n1. if ||= ϕ, then p(ϕ) = 1,\n2. if ϕ ||= ¬ψ for two i-formulas ϕ and ψ, then p(ϕ ∨ ψ) = p(ϕ) + p(ψ).\nThe associated conditional probability of ϕ given ψ is defined as\np(ϕ | ψ) = p(ϕ ∧ ψ)\np(ψ) (12)\nfor p(ψ) 6= 0.\nWewill show thatM∗D is a probability function. To prove this, first we need to introduce some auxiliary definitions:\nDefinition 34 (Restricted Domain Description). IfD is a domain description, we denote by D≤I the domain description obtained from D by removing all the p-propositions occurring at instants > I , and similarly we denote by D<I the domain description obtained from D by removing all the p-propositions occurring at instants ≥ I . Finally, we denote by D∅ the domain description obtained from D by removing all p-propositions, i.e. D\n<0̄.\nDefinition 35 (Fluent-indistinguishability, Indistinguishability). A world W is said to be fluent-indistinguishable from W ′ up to an instant I if and only if W (I ′)↾F = W ′(I ′)↾F for all instants I ′ such that I ′ ≤ I . W is said to be indistinguishable from W ′ up to an instant I if and only if it is fluent indistinguishable from W ′ up to I and if for all I ′ < I it also satisfies A ∈ W (I ′) if and only if A ∈ W ′(I ′).\nIn the following example, we illustrate the two concepts of restricted domain descrip-\ntion and indistinguishability:\nExample 18. Let D′ be the domain description obtained from DC as in Example 4 by adding the following p-proposition:\nToss performed-at 2 (C5)\nand consider the following well-behaved world w.r.t. D′:\nW ′(0) = {Coin = Heads,¬Toss}, W ′(1) = W ′(2) = {Coin = Heads,Toss}, W ′(I) = {Coin = Tails,¬Toss} for all I > 2\nW ′ has exactly two traces tr′ = 〈({Coin = Heads}, 1)@ ⊲⊳, ({Coin = Heads}, 0.49)@1, ({Coin = Tails}, 0.49)@2〉 and tr′′ = 〈({Coin = Heads}, 1)@ ⊲⊳, (∅, 0.02)@1, ({Coin = Heads}, 0.49)@2〉.\nConsider D′<2 and notice that it coincides with DC as in the previous examples. There is a unique well-behaved world w.r.t. DC that is indistinguishable from W\n′ up to 2, and this world is W3 as in Example 7.\nDefinition 36 (Transition Set, Transition Function). Given a domain description D, a state S and a fluent state S̃′, the transition set tsetD(S, S̃\n′) is defined as follows: if D contains a (unique) c-proposition c such that S Herbrand-entails body(c), then tsetD(S, S̃\n′) = {O ∈ head(c) | (S↾F) ⊕ χ(O) = S̃′} if there is no such c-proposition and S↾F = S̃′ then tset(S, S̃′) = {(∅, 1)}; otherwise, tsetD(S, S̃\n′) = ∅. The transition function for a domain description D is the function tD : S × S̃ → [0, 1]\ndefined by tD(S, S̃ ′) = π(tsetD(S, S̃ ′)) (recall Definition 6 for the meaning of π in this case).\nInformally, the transition function gives the probability of moving from state S to the fluent state S̃′ within D, independently of its particular narrative.\nThe transition function for the coin toss example can be visualised as in Figure 1, where the nodes represent fluent states (in this case we have two nodes H and T standing for the\nfluent states {Coin = Heads} and {Coin = Tails} respectively), and if p = tD(S, S̃ ′) for some state S and some fluent state S̃′, then there is an arrow from a node representing S↾F to a node representing S̃′ which is labelled S↾A, p. The arrow is omitted in some trivial cases (for instance when the set of actions is empty).\nSimilarly, the transition function for the antibiotic domain can be pictured as in Figure\n2.\nwhere RPBR is the fluent state {Rash = Present,Bacteria = Resistant}, RPBW is the fluent state {Rash = Present,Bacteria = Weak}, RABA is the fluent state {Rash = Absent,Bacteria = Absent}, RABR is the fluent state {Rash = Absent,Bacteria = Resistant}, and TM = {TakesMedicine}.\nThe transition function can be conveniently used to express MD(W ) in terms of the model of a well-behaved world w.r.t. an appropriately restricted domain description:\nProposition 2. Let D be an arbitrary domain description and W be a world such that occD(W ) = {I1, . . . , In} 6= ∅ where I1, . . . , In are ordered w.r.t. ≤, and let c be the cproposition activated in W at In w.r.t. D. Then W is well-behaved w.r.t. D if and only if (i) there exists a unique world W ′ well-behaved w.r.t. D<In which is indistinguishable from W up to In, (ii) for all I > In,W (I)↾F = S̃\nW >In where S̃W>In = (W (In)↾F)⊕ χ(O) for some outcome O ∈ head(c) , and (iii) W satisfies CWA for actions w.r.t. D.\nFurthermore, for S̃W>In the unique fluent state taken byW at instants I > In:\nMD(W ) = ǫD(W )\nǫD<In (W ′) ·MD<In (W\n′) · tD(W (In), S̃ W >In) (13)\nProof. “Only if” subproof. Let W be well-behaved w.r.t. D. Let tr = 〈tr( ⊲⊳)@ ⊲⊳, tr(I1)@I1, . . . , tr(In)@In〉 be an arbitrary trace of W w.r.t. D and consider the candidate trace tr′ = 〈tr( ⊲⊳)@ ⊲⊳, tr(I1)@I1, . . . , tr(In−1)@In−1〉.\nSince W is well-behaved w.r.t. D, since D and D<In differ only by one p-proposition occurring at In, and since tr\n′ does not mention any instant strictly greater than In−1, it is possible to construct a world W ′ which has trace tr′ w.r.t. D<In and which is fluentindistinguishable fromW up to instant In by simply considering thatW\n′(0̄) = χ(tr′( ⊲⊳)) = W (0̄) makes the Initial Condition satisfied w.r.t. D<In as both D and D<In share the same i-proposition, and a similar argument applies to the Justified Change Condition w.r.t. D<In . Well-behavedness w.r.t. D and D<In guarantees that for all instants I ≤ In, W (I)↾F = tr( ⊲⊳) ⊕ · · · ⊕ tr(Ii) = tr ′( ⊲⊳) ⊕ · · · ⊕ tr′(Ii) = W ′(I)↾F for some i < n, hence W is fluent-indistinguishable from W ′ up to In. Such a W ′ might not be unique, but if we\nchoose W ′ as to satisfy A ∈ W (I) ⇔ A ∈ W ′(I) for all I < In then the uniqueness of W ′ is guaranteed. Then, (i) holds. Since W is well-behaved w.r.t. D and In is the greatest element in occD, χ(tr(In)) = O for some O ∈ head(c) and Justified Change implies W (I)↾F = (W (In)↾F) ⊕ χ(tr(In)) for all I > In, and if we let S̃\nW >In be such unique\nfluent state (ii) is also satisfied. Finally, (iii) holds by definition of well-behavedness w.r.t. D. “If” subproof. Let W ′ be a well-behaved world w.r.t. D<In and let occD<In (W\n′) = {I1, . . . , In−1}. Let tr ′ = 〈tr( ⊲⊳)@ ⊲⊳, tr(I1)@I1, . . . , tr(In−1)@In−1〉 be a trace of W ′ w.r.t. DIn and construct the candidate trace tr = 〈tr( ⊲ ⊳)@ ⊲⊳, tr(I1)@I1, . . . , O@In〉 for the outcome O ∈ head(c) such that (W (I)↾F) = (W (In)↾F) ⊕ χ(O) for all I > In. Since W ′ is well-behaved w.r.t. D<In and indistinguishable from W up to In by hypothesis (i), we derive that tr is a trace ofW ′ w.r.t. D by noticing again that both D and D<In share the same i-proposition, and a similarly arguments applies for the Justified Change Condition w.r.t. D (also using hypothesis (ii)). Since W also satisfies CWA for actions by hypothesis (iii), it is well-behaved.\n“Furthermore” subproof. Let S̃W>In and c be as in the statement of the proposition. The above proof implies that for any trace tr of W w.r.t. D this trace can be constructed from a trace tr′ of W ′ by letting tr(Ii) = tr\n′(Ii) for i < In and tr(In) = χ(O) for some O ∈ head(c) such that S̃W>In = (W (In)↾F) ⊕ χ(O) (and notice that there is at least such an outcome O since W is well-behaved), i.e. for some O ∈ tsetD(W (In), S̃ W >In\n). Definition 30 now implies\nMD(W ) = ǫD(W ) · ∑\ntr∈TRWD\nǫ(tr)\n= ǫD<In (W ′) ·\nǫD(W )\nǫD<In (W ′) · π(tsetD(W (In), S̃\nW >In\n)) · ∑ tr′∈TRW ′\nD<In\nǫ(tr′)\n= ǫD(W )\nǫD<In (W ′) · tD(W (In), S̃\nW >In ) ·\n\n   ǫD<In (W ′) ·\n∑\ntr′∈TRW ′\nD<In\nǫ(tr′)\n\n  \n= ǫD(W )\nǫD<In (W ′) · tD(W (In), S̃\nW >In) ·MD<In (W ′).\nwhich is well defined since ǫ(N,W ) > 0 for any action narrative N and world W .\nCorollary 1. Let D be any domain description and let I be any instant. Then W is wellbehaved w.r.t. D≤I if and only if (i) there exists a unique world W ′ well-behaved w.r.t. D<I which is indistinguishable from W up to I , (ii) for all I ′ > I then W (I ′)↾F = S̃W>In where S̃W>In = (W (I)↾F)⊕χ(O) for some outcome O ∈ head(c) if I ∈ occD≤I (W ), and S̃W>In = W (I)↾F otherwise, and (iii) W satisfies CWA for actions w.r.t. D≤I .\nFurthermore, for S̃W>In the unique fluent state taken byW at instants I > In:\nMD≤I (W ) = ǫD≤I (W )\nǫD<I (W ′) ·MD<I (W\n′) · tD(W (I), S̃ W >I) (14)\nProof. If I ∈ occD≤I (W ) then the corollary follows directly from Proposition 2 since the domain description D≤I satisfies all of its hypotheses. If I /∈ occD≤I (W ) then no change of state occurs at I in W , i.e. W (I)↾F = W (I ′)↾F = S̃W>I for any I ′ > I , and Equation (14) holds for tD(W (I), S̃ W >I) = 1.\nLemma 1. For any D and any state S,\n∑\nS̃′∈S̃\ntD(S, S̃ ′) = 1.\nProof. We prove this by cases:\nCase 1. If there is no c-proposition c such that S Herbrand-entails body(c), then it follows from Definition 36 that\n∑\nS̃′∈S̃\ntD(S, S̃ ′) = tD(S, S↾F) = π((∅, 1)) = 1\nwhich is what we want.\nCase 2. Let c be the unique c-proposition S Herbrand-entails body(c). Then, applying the definition of tD from Definition 36 gives\n∑\nS̃′∈S̃\ntD(S, S̃ ′) =\n∑\nS̃′∈S̃\nπ(tsetD(S, S̃ ′)) (15)\nNotice that for a fixed outcome O, it is impossible to have O ∈ tsetD(S, S̃ ′) and O ∈ tsetD(S, S̃ ′′) for two distinct fluent states S̃′, S̃′′ as this would imply S̃′ = (S↾F)⊕χ(O) = S̃′′. Hence it is sufficient to show that {O ∈ tsetD(S, S̃ ′) | S̃′ ∈ S̃} = head(c), as this implies that the sum (15) equals 1 since π(head(c)) = 1 by definition of a c-proposition. By definition of a transition set, {O ∈ tsetD(S, S̃\n′) | S̃′ ∈ S̃} ⊆ head(c). Conversely, for any O ∈ head(c), O ∈ tsetD(S, S̃\n′) for S̃′ = (S↾F) ⊕ χ(O), hence head(c) ⊆ {O ∈ tsetD(S, S̃ ′) | S̃′ ∈ S̃} which ends the proof of lemma.\nLemma 2. Let D be any domain description, I be any instant and NI be the possibly empty action narrative that contains exactly those p-propositions in D that occur at I . Let W1, . . . ,Wm be well-behaved worlds w.r.t. D such that Wi(I)↾F = Wj(I)↾F for all 1 ≤ i, j ≤ m and which represent all the equivalence classes such that W is equivalent to W ′ if and only if W (I) = W ′(I). Then,\nm ∑\nj=1\nǫ(NI ,Wj) = 1\nProof. Let p1, . . . , pk be the p-propositions in NI (possibly none, in which case k = 0) that have probabilities strictly less than 1 attached. Then, there are at least 2k well-behaved worlds w.r.t. D satisfyingW (I)↾F = W ′(I)↾F , of whichW1, . . . ,Wm are representatives of each possible assignment of actions to {⊤,⊥}. Therefore, if we let pi have the form “Ai performed-at I with-prob Pi” for all 1 ≤ i ≤ k, the sum ∑m j=1 ǫ(NI ,Wj) evaluates to:\nP1 · P2 . . . Pk + P1 · P2 . . . (1− Pk) + · · ·+ (1− P1) · (1− P2) . . . (1− Pk) = 1\nWe can now prove the central property of M∗:\nProposition 3. Given a model MD of a domain description D, its extension to M ∗ D is a probability function.\nProof. We show that for any domain description, requirements 1 and 2 as in Definition 33\nare always satisfied by a model of that domain description.\nProof of requirement 1. We need to show that for any ψ such that W ||= ψ for all worlds W ,\nM∗D(ψ) = ∑\nW∈W\nMD(W ) = ∑\nW∈WD\nMD(W ) = 1. (16)\nwhere the second equality is guaranteed by the fact that MD(W ) = 0 when W is not well-behaved.\nFor a p-proposition p we define hasInstant(p) as the instant p has, and for an action narrative N we extend this to:\nhasInstants(N) = ⋃\np∈N\nhasInstant(p)\nWe prove (16) by induction on hasInstants(narr(D)) = {I1, . . . , In} where I1, . . . , In are ordered w.r.t. ≤. Notice that D≤In = D.\nBase case. We consider D∅ first. Since there are no p-propositions in D∅, hasInstants(D∅) = ∅, ǫD∅(W ) = ∅ for all worlds W , and the sum (16) becomes:\nM∗D∅(ψ) = ∑\nW∈WD∅\n\n \n∑\ntr∈TRWD∅\nπ(tr( ⊲⊳))\n\n  (17)\nLet {O1, . . . , Om} be the outcomes occurring in the only i-proposition ofD∅. We prove that the well-behaved worlds w.r.t. D∅ are exactly those W s taking the form W (I)↾F = χ(Oi) and ¬A ∈ W (I) for all instants I and all action symbols A.\nIf W has this form, then it satisfies CWA (as there are no p-propositions in D∅, and this is consistent with ¬A ∈ W (I) for all I and A), it satisfies the initial condition w.r.t. D∅ as Oi is an initial choice w.r.t. D∅ and W (0̄)↾F = χ(Oi) by definition, and finally it also satisfies the justified change condition in the form (6) as occD∅(W ) = ∅, which in turn forces W (I)↾F = W (I ′)↾F for all I and I ′. The fact that if W is well-behaved then it is of the form above is a simple inversion of the previous chain of implications.\nNotice that each of these well-behaved worlds is consistent with a unique trace 〈Oi@ ⊲⊳〉 for some 1 ≤ i ≤ m, and let Wi denote the world having trace 〈Oi@ ⊲⊳〉 for 1 ≤ i ≤ m. Hence we can write WD∅ = {W1, . . . ,Wm}. For such Wi,\n∑\ntr∈TR Wi D∅\nπ(tr( ⊲⊳)) = π(Oi)\nand (17) evaluates to:\nM∗D∅(ψ) = ∑\nWi∈WD∅\nπ(Oi) =\nm ∑\ni=1\nπ(Oi) = 1 (18)\nas π({O1, . . . , Om}) = 1 by Definition 9 of an i-proposition. Inductive step. Assume that M∗D<Ii (ψ) = 1 for some i ≤ n. We prove that M∗D≤Ii (ψ) = 1.\nLet [W ′]ID be the set of well-behaved worlds w.r.t. D that are indistinguishable from W ′ up to I . Corollary 1 and Lemma 1 together with the inductive hypothesis allow us to turn Equation (16) into:\nM∗D≤Ii (ψ) =\n∑\nW∈WD≤Ii\nMD≤Ii (W )\nCor.1 =\n∑\nW ′∈WD<Ii\n∑\nW∈[W ′] Ii D≤Ii\nǫD≤Ii (W ) ǫD<Ii (W ′) ·MD<Ii (W ′) · tD(W (Ii), S̃ W >Ii )\n= ∑\nW ′∈WD<Ii\nMD<Ii (W ′)\n∑\nW∈[W ′] Ii D≤Ii\nǫD≤Ii (W ) ǫD<Ii (W ′) · tD(W (Ii), S̃ W >Ii )\nAccording to Corollary 1 every world in [W ′]IiD≤Ii can be reconstructed from its state at instant Ii and the unique state S̃ ′ that it takes at instants strictly greater than Ii. Consider\nthe equivalence relation such that two well-behaved worlds W and W ′ w.r.t. D≤Ii are equivalent if and only if W (Ii) = W\n′(Ii), and let W1, . . . ,Wm be representatives of all the equivalence classes. Then, the above chain of equalities continues as follows:\n= ∑\nW ′∈WD<Ii\nMD<Ii (W ′)\nm ∑\nj=1\nǫD≤Ii (Wj)\nǫD<Ii (W ′) · ∑\nS̃′∈S̃\ntD(Wj(Ii), S̃ ′)\nLem.1 =\n∑\nW ′∈WD<Ii\nMD<Ii (W ′)\nm ∑\nj=1\nǫD≤Ii (Wj) ǫD<Ii (W ′)\nLem.2 =\n∑\nW ′∈WD<Ii\nMD<Ii (W ′) Ind.Hyp. = 1\nProof of requirement 2. Letϕ and ψ be two i-formulas such that ϕ ||= ¬ψ. Obviously, since ϕ ||= ¬ψ if for some W ∈ W , W ||= ϕ, then W ||6= ψ and vice-versa, hence\nM∗D(ϕ ∨ ψ) = ∑\nW ||=ϕ∨ψ\nMD(W ) = ∑\nW ||=ϕ\nMD(W ) + ∑\nW ||=ψ\nMD(W ) = M ∗ D(ϕ) +M ∗ D(ψ).\nAn immediate consequence of the previous proposition is the following one:\nCorollary 2. For any given domain description D,WD 6= ∅."
    }, {
      "heading" : "2.4 Example entailments",
      "text" : "The following are example entailments from the formalisation of Scenarios 1, 2 and 3.\nDC as in Example 4 entails, among others:\n⊤ holds-with-prob 1 (||=C1)\n[Coin = Tails]@0 holds-with-prob 0 (||=C2)\n[Toss = ⊤]@1 holds-with-prob 1 (||=C3)\n[Coin = Heads]@2 holds-with-prob 0.51 (||=C4)\n[Coin = Heads]@1 ∧ [Coin = Tails]@3 (||=C5) holds-with-prob 0.49\nwhere ⊤ is any tautological i-formula (i.e., W ||= ⊤ for all W ∈ W). The following h-propositions are entailed by DA:\n[Bacteria = Weak]@0 holds-with-prob 0.9 (||=A1)\n[Bacteria = Weak ∧ Rash = Absent]@0 (||=A2) holds-with-prob 0\n[Bacteria = Resistant]@2 holds-with-prob 0.27 (||=A3)\n[Rash = Absent]@4 holds-with-prob 0.733846 (||=A4)\n[Bacteria = Absent ∧ Rash = Absent]@4 (||=A5) holds-with-prob 0.650769\nNotice that from (||=A4) and (||=A5) we can calculate the conditional probability that the medicine has cured the infection at instant 4, i.e. [Bacteria = Absent]@4, given that no sign of rash is visible at the end of the treatment, i.e. [Rash = Absent]@4. Applying (12) gives that this probability equals 0.650769/0.733846 ≈ 0.887.\nFinally, the following h-propositions are entailed by DK :\n[LockedOut]@8AM holds-with-prob 0.01, (||=K1)\n[HasKeys]@9AM holds-with-prob 0.99, (||=K2)\n[PickupKeys]@7:40AM holds-with-prob 0.99. (||=K3)"
    }, {
      "heading" : "3 Translation",
      "text" : "To aid the reader’s intuition, we outline the translation of a domain description D into an answer set program. The idea is that of generating all the traces of a domain description\nas distinct stable models of the translated domain description. These traces can then be processed by an external tool such as AWK in order to calculate the probability of given\nqueries.\nIn the following, we restrict the domain language to be such that I is a finite interval {0, 1, . . . ,maxinst} of N, with 0̄ = 0 and ≤=≤N being the usual ordering relation between naturals."
    }, {
      "heading" : "3.1 Translation of the domain-dependent part",
      "text" : "We start by introducing the full translation of the coin domain description from Example 4.\nExample 19 (Translation of the Coin Toss Domain). Let DC be as in Example 4. The translation of DC results in the following set of clauses:\nfluent(coin). (TC0) action(toss). instant(0..maxinst).\npossVal(coin, heads). (TC1) possVal(coin, tails).\nbelongsTo((coin, heads), id01). (TC2) initialCondition((id01, 1)).\nbelongsTo((coin, heads), id11). (TC3.1) causesOutcome((id11, 49/100), I) ←\nholds(((toss, true), I)).\nbelongsTo((coin, tails), id12). (TC3.2) causesOutcome((id12, 49/100), I) ←\nholds(((toss, true), I)).\ncausesOutcome((id13, 2/100), I) ← (TC3.3) holds(((toss, true), I)).\nperformed(toss, 1). (TC4)\nwhere, informally, the set of clauses (TC0) is the translation of the three sorts F , A and I; (TC1), (TC2) and (TC4) are the translation of (C1), (C2) and (C4) respectively; (TC3.1),\n(TC3.2) and (TC3.3) together give the translation of (C3), and each of them corresponds to\nan outcome in the corresponding c-proposition;\nSince in logic programming lowercase letters are conventionally used for constants, we\nswitch to that convention by letting lower case letters be the logic programming counterparts of (upper case) constants in PEC so that e.g. f is regarded as the translated fluent F . Furthermore, literals of the form X = V are translated into pairs of the form (x, v).\nThe three sorts F , A and I are translated to the three sets {fluent(f) | F ∈ F}, {action(a) | A ∈ A} and {instant(i) | I ∈ I} respectively (see e.g. (TC0) in Example 19).\nLet c be a c-proposition of the generic form (2):\nθ causes-one-of {O1, O2, . . . , Om}\nbut first considering the case where θ is a conjunction of the form X1 = V1 ∧ · · · ∧Xj = Vj . Given a conjunction θ as before, we write holds([θ]@I) as a shorthand for the logic programming conjunction\nholds(((x1, v1), I)), . . . , holds(((xj , vj), I)).\nFix an enumeration (without repetitions) of all the c-propositions in D, and let c be the nth proposition occurring in such enumeration. Then, c is translated to:\n{ belongsTo((x, v), idni ) | i = 1, . . . ,m,X = V ∈ χ(Oi) } ∪{ causesOutcome((idni , p), I) ← holds(θ, I) |\ni = 1, . . . ,m, , P = π(Oi) }\nwhere idn1 , . . . , id n m are new constants in the underlying ASP language. We write CD for the set of all translated c-propositions in D.\nExample 20. The clauses (TC3.1), (TC3.2) and (TC3.3) are the translation of the c-\nproposition (C2) from Example 4.\nAs a further example, consider the c-proposition (A5) as in Example 5, and notice that two outcomes occur in it, i.e. ({Bacteria = Absent,Rash = Absent}, 1/13) and (∅, 4/13). If we fix the enumeration of c-propositions inDA such that (A4) is first and (A5) is second, this c-proposition is translated to:\nbelongsTo((bacteria, absent), id21). (TA5.1) belongsTo((rash, absent), id21). causesOutcome((id21, 1/13), I) ←\nholds((takesMedicine, true), I), holds((bacteria, resistant), I).\ncausesOutcome((id22, 4/13), I) ← (TA5.2) holds((takesMedicine, true), I), holds((bacteria, resistant), I).\nIf θ is not a conjunction of literals, then represent it in Disjunctive Normal Form, i.e. in the form θ1 ∨ · · · ∨ θn with θ1, . . . , θn conjunctions of literals, and then for each rule write the precondition of each causes-one-of clause in the disjunctive form:\nholds([θ1]@I); . . . ; holds([θn]@I).\nThe translation of i-propositions works in a very similar way: if J is an i-proposition of the general form (3):\ninitially-one-of {O1, O2, . . . , Om}\nthen its translation is given by the following set of clauses:\n{ belongsTo((x, v), id0i ) | i = 1, . . . ,m,X = V ∈ χ(Oi) } ∪{ initialCondition((id0i , p)) | i = 1, . . . ,m, P = π(Oi) }\nand we write ID for the set of all translated i-propositions in D.\nExample 21. An example of translated i-proposition is the set of clauses (TC2), that trans-\nlate (C2) as in Example 19.\nThe i-proposition (A3) from Example 5 is translated to:\nbelongsTo((bacteria,weak), id01). (TA3.1) belongsTo((rash, present), id01). initialCondition((id01, 9/10)).\nbelongsTo((bacteria, absent), id02). (TA3.2) belongsTo((rash, present), id02). initialCondition((id02, 1/10)).\nFinally, the translation of p-propositions and v-propositions is straightforward: any\ngeneric p-proposition of the form (4) is translated to\nperformed(a, i).\nand we write PD for the set of all translated p-propositions in D, while any v-proposition of the form (1) is translated to:\n{ possVal(f, vi) | 1 ≤ i ≤ n }\nand we write VD for the set of all translated v-propositions in D.\nExample 22. The v-proposition (C1) and p-proposition (C4) from from Example 4 are\ntranslated to (TC1) and (TC4) as in Example 19, respectively, while (A1), (A2), (A6), (A7) from Example 5 are translated to:\npossVal(bacteria,weak). (TA1) possVal(bacteria, resistant). possVal(bacteria, absent).\npossVal(rash, present). (TA2) possVal(rash, absent).\nperformed(takesMedicine, 1). (TA6)\nperformed(takesMedicine, 3). (TA7)\nSince PD and VD contain only ground facts which clearly correspond to their semantic counterparts (i.e., p-propositions and v-propositions) we are not going to discuss their\ncorrectness in close detail.\nWe write ΠD for the set of translated propositions from D, e.g. if DC is the coin toss domain, ΠDC = (TC0–4)."
    }, {
      "heading" : "3.2 Translation of the domain-independent part",
      "text" : "We define the domain-independent part of our theory to be:\npossVal(A, true) ← action(A). (PEC1) possVal(A, false) ← action(A).\nfluentOrAction(X) ← fluent(X); action(X). (PEC2)\nliteral((X,V )) ← possVal(X,V ). (PEC3)\niLiteral((L, I)) ← literal(L), instant(I). (PEC4)\ndefinitelyPerformed(A, I) ← performed(A, I, 1). (PEC5)\npossiblyPerformed(A, I) ← performed(A, I, P ). (PEC6)\n1{ holds(((X,V ), I)) : iLiteral(((X,V ), I)) }1 (PEC7) ← instant(I), fluentOrAction(X).\ninOcc(I) ← instant(I), causesOutcome(O, I). (PEC8)\n1{ effectChoice(O, I) : causesOutcome(O, I) }1 (PEC9) ← inOcc(I).\n1{ initialChoice(O) : initialCondition(O) }1. (PEC10)\n⊥ ← action(A), instant(I), (PEC11) holds(((A, true), I)), not possiblyPerformed(A, I).\n⊥ ← action(A), instant(I), (PEC12) holds(((A, false), I)), definitelyPerformed(A, I).\n⊥ ← initialChoice((S,P )), literal(L), (PEC13) belongsTo(L,S), not holds((L, 0)).\n⊥ ← instant(I), effectChoice((X,P ), I), (PEC14) fluent(F ), belongsTo((F, V ),X), not holds(((F, V ), I + 1)), I < maxinst.\n⊥ ← instant(I), fluent(F ), not holds(((F, V ), I)), (PEC15) effectChoice((X,P ), I), not belongsTo((F, V ),X), holds(((F, V ), I + 1)), I < maxinst.\n⊥ ← fluent(F ), instant(I), holds(((F, V ), I)), (PEC16) not inOcc(I), not holds(((F, V ), I + 1)), I < maxinst.\neval(A, I, P ) ← action(A), instant(I), (PEC17) performed(A, I, P ), holds(((A, true), I)).\neval(A, I, 1 − P ) ← action(A), instant(I), (PEC18) performed(A, I, P ), holds(((A, false), I)).\n(PEC1–4) implement the basic predicates and sorts of PEC, namely: (PEC1) states that actions are boolean; (PEC2) defines a characteristic predicate for F ∪ A; (PEC3) and (PEC4) define literals and i-literals, respectively. (PEC5) and (PEC6) define the two auxil-\niary predicates definitelyPerformed and possiblyPerformed representing the sets of actions and instants such that A is certainly performed at I (i.e., with probability 1) and such that A might have been performed at I (i.e., with a probability greater than 0) respectively. Proving that (PEC1–6) correctly characterise the sorts and sets they stand for is trivial and is\nomitted here.\nIntuitively, axioms (PEC7–18) correspond to the definitions introduced in the previ-\nous section, namely: (PEC7) corresponds to Definition 14, (PEC8) defines a characteris-\ntic predicate for occ as in Definition 17, (PEC9) and (PEC14–16) correspond to justified\nchange, (PEC10) and (PEC13) corresponds to the initial condition, (PEC11) and (PEC12)\ncorrespond to CWA for actions.\nWe denote the domain-independent part of our theory, i.e. (PEC1–18), by ΠI . Notice that axioms (PEC11–16) are constraints, and in the following will be referred to as ΠC ."
    }, {
      "heading" : "4 Correctness",
      "text" : "We now show that the provided translation is sound and complete with respect to the def-\ninitions given in the previous sections. This proof relies on the Splitting Theorem [10], a useful tool to obtain the answer sets of a ground program. Informally, a set U of atoms is a splitting set for a program Π if, for every rule in Π, if U contains some atom in the head of such rule, then it also contains all the atoms occurring in that rule. For instance, if Π′ = {a ← not b, b ← c, c} then {a, b, c}, ∅, {b, c} and {c} are splitting sets for Π′, whereas {a, b}, {a} and {b} are not.\nA splitting set U splits an answer set program Π into a bottom program botU (Π) and a top program topU (Π) = Π \\ botU (Π). With the program Π\n′ defined as above, U ′ = {c} splits Π′ into botU ′(Π ′) = {c} and topU ′(Π ′) = {a ← not b, b ← c}.\nThe splitting set theorem states that the answer sets ofΠ are exactly those that can be expressed asX ∪Y forX an answer set of botU (Π) and Y an answer set of eU (topU (Π),X), where eU (Π, Z) for a generic program Π, set of atoms U and answer set Z denotes the partial evaluation of the program Π w.r.t. U which is defined as follows: a rule r is in eU (Π, Z) if and only if there exists a rule r\n′ ∈ Π such that all literals in the body of r′ with at least an atom of U occurring in them are also in Z , and the rule r is obtained from r′ by removing all the occurrences of such literals. If we consider Π′ and U ′ again and let X ′ be the only answer set {c} of botU ′(Π ′) = {c}, Π′′ = eU ′(topU ′(Π ′),X ′) = {a ← not b, b} and notice that now we can split Π′′ itself. If we let U ′′ = {b}, then botU ′′(Π ′′) = {b} and Π′′′ = eU ′′(topU ′′(Π ′′),X ′′) = ∅ for the only answer set X ′′ = {b} of botU ′′(Π\n′′). The answer sets of the original program Π′ can now be obtained as X ′ ∪X ′′ ∪X ′′′, where X ′ = {c} is the answer set of botU ′(Π ′), X ′′ = {b} is the answer set of botU ′′(Π ′′) = {c} andX ′′′ = ∅ is the answer set of Π′′′. Then, the program Π′ has only one answer set {b, c}. In the following, we will use the fact that answer sets of a choice rule {a1, . . . , an} are the power set {∅, {a1}, . . . , {an}, {a1, a2}, . . . , {a1, . . . , an}}, and that answer sets of a constrained choice rule X{a1, . . . , an}Y are the answer sets of {a1, . . . , an} with cardinality ≥ X and ≤ Y . Also, we use the fact that the only answer set of the program {p(X) : q(X), q(a1), . . . , q(an)}, where p(X) : q(X) is called a conditional literal, is {p(a1), . . . , p(an), q(a1), . . . , q(an)}. Notice that conditional literal and choice rules can be combined so that e.g. answer sets of the program {q(a, b), q(a, c), q(b, c), 1{p(X) : q(a,X)}1} are {q(a, b), q(a, c), q(b, c), p(b)} and {q(a, b), q(a, c), q(b, c), p(c)}. Finally, constraints are used to eliminate answer sets that satisfy its body, e.g. answer sets of the program {q(a, b), q(a, c), q(b, c), 1{p(X) : q(a,X)}1,⊥ ← p(b)} are the answer sets of {q(a, b), q(a, c), q(b, c), 1{p(X) : q(a,X)}1} that do not satisfy p(b), hence {q(a, b), q(a, c), q(b, c), p(c)} is its only answer set.\nThe splitting set theorem can only be applied to ground programs, hence in the fol-\nlowing we will interpret non-ground clauses as shorthand for the set of all their ground instances, e.g. the clause p(X) ← q(X,Y ) from the program {p(X) ← q(X,Y ), q(a, b)} is shorthand for the set {p(a) ← q(a, a), p(a) ← q(a, b), p(b) ← q(b, a), p(b) ← q(b, b)}.\nBefore proving the correctness of the implementation, we need to define a correspon-\ndence between answer sets and traces. This is the aim of the following definitions:\nDefinition 37 (Manifest Choice Element). We say that the choice element (X̃, P+)@I is manifest in the answer set Z if and only if there exists a symbol id such that effectChoice((id, p+), i) ∈ Z and such that L ∈ X̃ if and only if belongsTo(l, id) ∈ Z (recall that p+, i and l are the ASP representations of P+, I and L respectively).\nDefinition 38 (Trace of an answer set). The trace of an answer set Z is the trace 〈O ⊲⊳@ ⊲ ⊳, O1@I1, . . . , On@In〉 where O ⊲⊳@ ⊲ ⊳, O1@I1, . . . , On@In are exactly the manifest choice elements in Z ordered according to instants I1, . . . , In.\nProposition 4. A candidate trace tr is a trace of D if and only if there exists an answer set Ztr of ΠD ∪ΠI such that tr is a trace of Ztr.\nProof. Let Π be the ground program obtained by grounding ΠD ∪ ΠI . We split Π with respect to the set U of all possible groundings of the predicates fluent, action, instant and possVal. The bottom botU (Π) is guaranteed by the translation process to have a unique answer set ZL which includes a correct representation of the domain language L, i.e. of the three sorts F , A and I and of the function vals (note that the definition of V is implicitly derived from that of vals and that our implementation is restricted to the case where≤=≤N and 0̄ = 0).\nWe now split the partially evaluated top Π(1) = eU (topU (Π), ZL) using the set U (1) consisting of all possible groundings of the predicate holds. The bottom botU (1)(Π (1)) consists only of (PEC7) and has answer sets that correspond to any possible world in the\ndomain language, i.e., (PEC7) generates every possible function from instants to states, hence for a particular world W ∈ W we denote by ZW the corresponding answer set of botU (1)(Π\n(1)), and we are allowed to interpret holds(((x, v), i)) ∈ ZW as X=V ∈ W (I). Notice that for any fixed W ∈ W the three sets of propositions Π(2) =\neU (1)((PEC8–9) ∪ CD, ZW ), Π (3) = eU (1)((PEC10) ∪ ID, ZW ) and Π (4) = eU (1)((PEC17–18) ∪ PD, ZW ) are independent of each other so we can evaluate their answer sets separately.\nWe start with the set Π(2). If a c-proposition c =“θ causes-one-of {O1, O2, . . . , Om}” in D is activated at I in W w.r.t. D, i.e. W ||= [θ]@I , then also the preconditions of the translated c-proposition in CD are satisfied (as ZW correctly represents W ), and Π (2) will contain the facts causesOutcome((idnj , p), i) for 1 ≤ j ≤ m and c being the nth c-proposition in the enumeration fixed during the translation process (see Section 3.1 for reference), alongside the corresponding belongsTo facts in CD which we assume correctly represent the ∈ relation for outcomes, i.e., belongsTo((x, v), idnj ) ∈ Π (2) if and only if X=V ∈ Oj . The converse is a straightforward inversion of this reasoning. For a fixed I , if we denote by CW,I the set of facts of the form causesOutcome((idnj , p), i) that are in Π (2), what we have just shown yields:\nCW,I ⇔ a cause occurs in W at I (19)\nIf we now let U (2) be a splitting set such that it contains all possible groundings of the causesOutcome predicate, we get that the the only answer set of botU (2)(Π (2)) isBC ∪CW ,\nwhere BC is the set of belongsTo facts contained in CD and CW is defined as:\nCW = ⋃\nI∈I\nCW,I (20)\nThe partially evaluated top Π (2) 1 = eU (2)(Π (2), BC ∪CW ) includes the following set of facts:\nOW = {inOcc(i) | ∃o : causesOutcome(o, i) ∈ CW } = {inOcc(i) | I ∈ I, CW,I 6= ∅} = {inOcc(i) | a cause occurs inW at I}\nwhere we have used Equation (19) to derive the last equality. Therefore, we can interpret inOcc(i) ∈ OW as I ∈ inOccD(W ).\nLet U (2) 1 be the splitting set consisting of all possible groundings of inOcc. The only\nanswer set of bot U\n(2) 1\n(Π (2) 1 ) isOW , and we now need to evaluate and find the answer sets of\nΠ (2) 2 = eU (2)1 (top U (2) 1 (Π (2) 1 ), OW ) which now consists only of a partially evaluated (PEC7).\nThe role of (PEC7) is to implement the effectChoice function. Indeed, for each instant I such that I ∈ occD(W ), exactly one atom of the form effectChoice(o, i) is included in an answer set ofΠ (2) 2 for some o such that causesOutcome(o, i) ∈ CW . Since this is consistent with definition 19, we can interpret effectChoice(o, i) as its intended semantic counterpart ec(I) = O where ec is an effect choice function for W w.r.t. D. For an effect choice function ec for W w.r.t. D, we call the corresponding answer set that encodes it Eec.\nApplying the splitting theorem, we can now conclude that answer sets of Π(2) are exactly those given by the set {BC ∪ CW ∪ OW ∪ Eec | ec is an effect choice function for W w.r.t. D}.\nAnswer sets of Π(3) correspond to the initialChoice constant and can be worked out in a similar way as in the effect choice function case. It can be shown that initialChoice(o) correctly represents an initial choice ic as in definition 20, and answer sets ofΠ(3) are given by ID ∪ Iic, where the singleton set Iic consists only of an encoded ic for an initial choice ic w.r.t. D.\nFinally we need to derive answer sets of Π(4). We split it using U (4) consisting of all performed ground facts. The bottom botU (4)(Π (4)) has answer set PD itself (notice that PD contains only ground facts), and we are left with calculating answer sets of Π (4) 1 = eU (4)(topU (4)(Π (4), PD), PD). The aim of eval is that of implementing Equation (8). It is important to notice here that, thanks to requirement iv) in Definition 11, it is possible to label a p-proposition “A performed-at I with-prob P+” using only A and I . Comparing Equation (8) with (PEC17–18) immediately gives that the only answer set of Π(4) is PD ∪ EvW where EvW = { eval(a, i, p) | A ∈ A, I ∈ I, “A performed-at I with-prob P+” ∈ D,\nP = P+ if W ||= [A]@I, P = 1− P+ otherwise } .\nWe are now able to calculate the answer sets of the whole program Π \\ ΠC , which are\ngiven by the set {\nZL ∪ZW ∪BC ∪CW ∪OW ∪Eec ∪ ID ∪ Iic ∪PD ∪EvW , for W ∈ W ,\nan effect choice ec for W w.r.t. D and an initial choice ic w.r.t. D }\nFinally, we take into account the constraints ΠC , whose effect is that of implementing the Closed World Assumption and the effects of initialisation and persistence. Since\n(PEC11–16) are constraints, they eliminate those answer sets of Π \\ ΠC that satisfy their bodies.\nIf we let ZW be the world encoded in an answer set Z of Π \\ ΠC , (PEC11) and (PEC12) ensure that:\nholds(((a, true), i)) ∈ ZW ⇒ ∃p > 0, performed(a, i, p) ∈ ΠD ⇔ “A performed-at I with-prob P+” ∈ D\nand, conversely holds(((a, false), i)) ∈ ZW ⇒ performed(a, i, 1) ∈ ΠD ⇔ “A performed-at I with-prob 1” ∈ D\ntherefore the world encoded in ZW must satisfy CWA, i.e. definition 16. Let now “initially-one-of (O1, O2, . . . , Om)” be an i-proposition in D and ZW be as before. (PEC14) makes sure that:\nholds(((f, v), 0)) ∈ ZW ⇔ ∃s : {initialChoice((s, p)), belongsTo((f, v), s)} ⊆ ΠD ⇔ ∃O : O ∈ {O1, . . . , Om}, S̃ = χ(O), [F = V ] ∈ S̃.\nwhich satisfies the initial condition, i.e. definition 18.\nFinally we consider (PEC14–16). Let I, I ′ be two instants with I < I ′ as in definition 23, consider the world encoded in ZW and let W (I)↾F = S̃ and W (I\n′)↾F = S̃′. Assume that the effectChoice function encoded in Z maps instants in inOccD(W ) ∩ [I, I\n′) to outcomes O1, O2, . . . , On. Axiom (PEC16) makes sure that S̃ cannot be altered if I /∈ inOccD(W ). Therefore S̃ can only change at instants I ∈ inOccD(W ). We now show that S̃′ is actually equal to S̃ ⊕ O1 ⊕ O2 ⊕ · · · ⊕ On. If not, and considering that our implementation is restricted to a finite set of instants, either (i) there is a fluent literal L ∈ χ(O) for some O ∈ {O1, O2, . . . , On} and an instant I ′′ ∈ [I, I ′) such that L ∈ χ(O) but L /∈ W (I ′′ + 1), or (ii) for some O ∈ {O1, O2, . . . , On} and a fluent literal L = [F = V ] such that L /∈ O and L /∈ W (I ′′), L ∈ W (I ′′ + 1). Both (i) and (ii) are forbidden by (PEC15) and (PEC16) respectively, by considering that the answer set Z correctly represents the semantic objects that it encodes."
    }, {
      "heading" : "5 Related Work",
      "text" : "Although there is existing work on probabilistic reasoning about actions, most is based\non Reiter’s variant of Situation Calculus (SC) [16], with focus on hypothetical rather than\nnarrative reasoning. An exception is Prob-EC (see below).\nOf the SC approaches, the Bacchus-Halpern-Levesque framework [1] is a cornerstone\nof early work integrating probabilistic knowledge with logical formalisms for reasoning\nabout actions, and incorporates epistemic notions such as sensing actions. The Probabilis-\ntic Situation Calculus (PSC) [13] is extended to deal with knowledge-producing actions\nin [12]. A reasoning system based on PSC able to perform temporal projection has been\nimplemented by the authors in Wolfram Mathematica [19] and uses Monte Carlo methods\nfor tractability. The language PAL [2] focuses on building an elaboration tolerant representation for Markov Decision Processes. It is based on Language A [5] and oriented to\ncounterfactual reasoning and observation assimilation. PAL uses two kinds of unknown\nvariables – inertial and non-inertial – to achieve an elaboration tolerant representation of domains. The action language E+ [7], based on C+ [6], supports both non-deterministic and probabilistic actions. Its main focus is on providing algorithms for the efficient com-\nputation of plans.\nTo our knowledge, the Probabilistic Logic Programming Event Calculus (Prob-\nEC) [18] is the only EC-style language in this class of formalisms other than PEC able\nto support reasoning about explicit event occurrences (narratives). Unlike our framework,\nwhich has its own bespoke semantics, Prob-EC is a logic programming framework based\non the probabilistic logic programming language ProbLog [3] and therefore inherits and ex-\nploits its semantics. In [18] Prob-EC is applied to human activity recognition. The authors\ndescribe how a set of long-term activities (LTAs) can be detected from a set of short-term\nactivities (STAs). Such STAs, which constitute the input to the system, are treated as events\nhappening at given instants and have probabilities attached. This is a somewhat different\napproach than PEC’s, motivated by its application to activity recognition, analogous to at-\ntaching probabilities to p-propositions (rather than i- and c-propositions). In other words Prob-EC’s focus is on representing probabilistic knowledge about event occurrences rather\nthan about their general causal effects."
    }, {
      "heading" : "6 Summary",
      "text" : "In this work, we present PEC, an EC variant for reasoning about actions in a narrative\ndomain where actions can have probabilistic outcomes, and illustrated how for a wide sub-\nclass of domains it can be implemented in ASP in a sound and complete way. Unlike Prob-\nEC [18] which follows the “logic programming” tradition, our formalism belongs to the\n“action language” tradition (originating in [5], but see also [8] for the first EC style action\nlanguage), and therefore its own specialised semantics. This makes of PEC portable in the sense that it is independent of any particular computational implementation. Its semantics\nis defined in terms of (possible) worlds, with a view to adding epistemic features at a later\ndate (see e.g. [14], [17]).\nIn our initial experimentation with adding epistemic features to PEC, we have focused\non representing imperfect sensing actions and actions conditioned on knowledge acquired\nduring the progression of the narrative. These features are similar to those in the EFEC\nextension of FEC [11]. We envisage including s-propositions such as\nSee senses Coin with-accuracies\n(\n0.9 0.1 0.3 0.7\n)\nwhich represents that our coin-tossing robot can imperfectly sense the current face showing\non the coin, and conditional p-propositions such as\nToss performed-at 2 if-believes (Coin=Tails, (0.65, 1])\nwhich represents that the robot will toss again if it believes with a greater than 65% prob-\nability that the first toss resulted in Tails. Preliminary results indicate that our possible\nworlds semantics can be readily extended to cover these notions.\nThere are several other ways in which the present work can be continued. For instance, the problem of elaboration tolerance, which plays an important role in classical reasoning\nabout actions, needs to be reviewed and solved in our setting. This problem has already\nbeen tackled in [2], but needs to be restated in our framework due to the different way\nin which we introduce probabilities in PEC. A related point is that of underspecification,\ni.e. what an agent can reasonably infer from a domain in which the initial conditions and\nthe effects of actions are not entirely specified (even probabilistically). Finally, in our view a crucial point is that of computational efficiency. Indeed, the intractability of several\ncomputational problems arising in this setting (such as temporal projection) suggests that\ntechniques (e.g. Monte Carlo Markov Chain) are needed to efficiently approximate the\ncorrect answer to a given query with an appropriate degree of confidence."
    } ],
    "references" : [ {
      "title" : "Reasoning about noisy sensors and effectors in the situation calculus",
      "author" : [ "Fahiem Bacchus", "Joseph Y. Halpern", "Hector J. Levesque" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1999
    }, {
      "title" : "Reasoning about actions in a probabilistic setting",
      "author" : [ "Chitta Baral", "Nam Tran", "Le-Chi Tuan" ],
      "venue" : "In AAAI/IAAI,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2002
    }, {
      "title" : "Problog: A probabilistic prolog and its application in link discovery",
      "author" : [ "Luc De Raedt", "Angelika Kimmig", "Hannu Toivonen" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Upper and lower probabilities induced by a multivalued mapping",
      "author" : [ "Arthur P Dempster" ],
      "venue" : "The annals of mathematical statistics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1967
    }, {
      "title" : "Representing action and change by logic programs",
      "author" : [ "Michael Gelfond", "Vladimir Lifschitz" ],
      "venue" : "The Journal of Logic Programming,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1993
    }, {
      "title" : "Nonmonotonic causal theories",
      "author" : [ "Enrico Giunchiglia", "Joohyung Lee", "Vladimir Lifschitz", "Norman McCain", "Hudson Turner" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2004
    }, {
      "title" : "Reasoning about actions with sensing under qualitative and probabilistic uncertainty",
      "author" : [ "Luca Iocchi", "Thomas Lukasiewicz", "Daniele Nardi", "Riccardo Rosati" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "A simple declarative language for describing narratives with actions",
      "author" : [ "Antonios Kakas", "Rob Miller" ],
      "venue" : "The Journal of Logic Programming,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1997
    }, {
      "title" : "A logic-based calculus of events. In Foundations of knowledge base management, pages 23–55",
      "author" : [ "Robert Kowalski", "Marek Sergot" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1989
    }, {
      "title" : "Splitting a logic program",
      "author" : [ "Vladimir Lifschitz", "Hudson Turner" ],
      "venue" : "In ICLP, pages 23–37,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1994
    }, {
      "title" : "An epistemic event calculus for asp-based reasoning about knowledge of the past, present and future",
      "author" : [ "Jiefei Ma", "Rob Miller", "Leora Morgenstern", "Theodore Patkos" ],
      "venue" : "In LPAR-19,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Observations and the probabilistic situation calculus",
      "author" : [ "Paulo Mateus", "António Pacheco", "Javier Pinto" ],
      "venue" : "In KR,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2002
    }, {
      "title" : "Probabilistic situation calculus",
      "author" : [ "Paulo Mateus", "António Pacheco", "Javier Pinto", "Amı́lcar Sernadas", "Cristina Sernadas" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2001
    }, {
      "title" : "A Formal Theory of Knowledge and Action",
      "author" : [ "R.C. Moore" ],
      "venue" : "In Formal Theories of the Commonsense World,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1985
    }, {
      "title" : "The uncertain reasoner’s companion: a mathematical perspective, volume 39",
      "author" : [ "Jeff B Paris" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems",
      "author" : [ "Raymond Reiter" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2001
    }, {
      "title" : "Knowledge, action, and the frame problem",
      "author" : [ "Richard B. Scherl", "Hector J. Levesque" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2003
    }, {
      "title" : "A probabilistic logic programming event calculus",
      "author" : [ "Anastasios Skarlatidis", "Alexander Artikis", "Jason Filippou", "Georgios Paliouras" ],
      "venue" : "TPLP, 15:213–245,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "The Mathematica Book",
      "author" : [ "Stephen Wolfram" ],
      "venue" : "Wolfram Media, Incorporated,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The Event Calculus (EC) [9] is a well-known approach to reasoning about the effects of a narrative of action occurrences (events) along a time line.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "Fuzzy Logic [20] or Dempster-Schafer Theory [4], and v) for a wide subset of domains it has a sound and complete ASP implementation.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "to denote real values in [0, 1], P+, P 1 , P + 2 , .",
      "startOffset" : 25,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "Definition 29 ([0, 1]-interpretation).",
      "startOffset" : 15,
      "endOffset" : 21
    }, {
      "referenceID" : 0,
      "context" : "A [0,1]-interpretation is a function from W to [0, 1].",
      "startOffset" : 2,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "A [0,1]-interpretation is a function from W to [0, 1].",
      "startOffset" : 47,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "A model of a domain description D is a [0, 1]-interpretation MD such that 1.",
      "startOffset" : 39,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "We extend the model MD to a function M ∗ D : Φ → [0, 1] over i-formulas in the following way: M D(φ) = ∑",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 14,
      "context" : "3 Properties of a model We now introduce the concept of a probability function, adapted from [15]: Definition 33 (Probability Function, Conditional Probability).",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 0,
      "context" : "A probability function (over i-formulas) is a function p : Φ → [0, 1] such that: 1.",
      "startOffset" : 63,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "The transition function for a domain description D is the function tD : S × S̃ → [0, 1] defined by tD(S, S̃ ′) = π(tsetD(S, S̃ ′)) (recall Definition 6 for the meaning of π in this case).",
      "startOffset" : 81,
      "endOffset" : 87
    }, {
      "referenceID" : 9,
      "context" : "This proof relies on the Splitting Theorem [10], a useful tool to obtain the answer sets of a ground program.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 15,
      "context" : "Although there is existing work on probabilistic reasoning about actions, most is based on Reiter’s variant of Situation Calculus (SC) [16], with focus on hypothetical rather than narrative reasoning.",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 0,
      "context" : "Of the SC approaches, the Bacchus-Halpern-Levesque framework [1] is a cornerstone of early work integrating probabilistic knowledge with logical formalisms for reasoning about actions, and incorporates epistemic notions such as sensing actions.",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "The Probabilistic Situation Calculus (PSC) [13] is extended to deal with knowledge-producing actions in [12].",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 11,
      "context" : "The Probabilistic Situation Calculus (PSC) [13] is extended to deal with knowledge-producing actions in [12].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 18,
      "context" : "A reasoning system based on PSC able to perform temporal projection has been implemented by the authors in Wolfram Mathematica [19] and uses Monte Carlo methods for tractability.",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "The language PAL [2] focuses on building an elaboration tolerant representation for Markov Decision Processes.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 4,
      "context" : "It is based on Language A [5] and oriented to",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 6,
      "context" : "The action language E+ [7], based on C+ [6], supports both non-deterministic and probabilistic actions.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 5,
      "context" : "The action language E+ [7], based on C+ [6], supports both non-deterministic and probabilistic actions.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "To our knowledge, the Probabilistic Logic Programming Event Calculus (ProbEC) [18] is the only EC-style language in this class of formalisms other than PEC able to support reasoning about explicit event occurrences (narratives).",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "Unlike our framework, which has its own bespoke semantics, Prob-EC is a logic programming framework based on the probabilistic logic programming language ProbLog [3] and therefore inherits and exploits its semantics.",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 17,
      "context" : "In [18] Prob-EC is applied to human activity recognition.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 17,
      "context" : "Unlike ProbEC [18] which follows the “logic programming” tradition, our formalism belongs to the “action language” tradition (originating in [5], but see also [8] for the first EC style action language), and therefore its own specialised semantics.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 4,
      "context" : "Unlike ProbEC [18] which follows the “logic programming” tradition, our formalism belongs to the “action language” tradition (originating in [5], but see also [8] for the first EC style action language), and therefore its own specialised semantics.",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "Unlike ProbEC [18] which follows the “logic programming” tradition, our formalism belongs to the “action language” tradition (originating in [5], but see also [8] for the first EC style action language), and therefore its own specialised semantics.",
      "startOffset" : 159,
      "endOffset" : 162
    }, {
      "referenceID" : 13,
      "context" : "[14], [17]).",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[14], [17]).",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 10,
      "context" : "These features are similar to those in the EFEC extension of FEC [11].",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "This problem has already been tackled in [2], but needs to be restated in our framework due to the different way in which we introduce probabilities in PEC.",
      "startOffset" : 41,
      "endOffset" : 44
    } ],
    "year" : 2017,
    "abstractText" : "The Event Calculus (EC) [9] is a well-known approach to reasoning about the effects of a narrative of action occurrences (events) along a time line. This paper describes PEC, an adaptation of EC able to reason with probabilistic causal knowledge. There are numerous applications for this kind of probabilistic reasoning, e.g. in modelling medical, environmental, legal and commonsense domains, and in complex activity recognition and security monitoring. PEC’s main characteristics are: i) it supports EC-style narrative reasoning, ii) it uses a possible worlds semantics to naturally allow for epistemic extensions, iii) it uses a tailored action language syntax and semantics, iv) its generality allows in principle for the use of other models of uncertainty, e.g. Fuzzy Logic [20] or Dempster-Schafer Theory [4], and v) for a wide subset of domains it has a sound and complete ASP implementation. Although other formalisms exist for probabilistic reasoning about actions, PEC is, to our knowledge, the only framework to combine these features. We use the following two example scenarios to illustrate the main definitions and characteristics of our framework.",
    "creator" : "LaTeX with hyperref package"
  }
}