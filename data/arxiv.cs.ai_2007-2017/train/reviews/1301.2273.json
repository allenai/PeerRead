{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Robust Combination of Local Controllers", "abstract": "Planning problems are hard, motion planning, for example, isPSPACE-hard. Such problems are even more difficult in the presence of uncertainty. Although, Markov Decision Processes (MDPs) provide a formal framework for such problems, finding solutions to high dimensional continuous MDPs is usually difficult, especially when the actions and time measurements are continuous. Fortunately, problem-specific knowledge allows us to design controllers that are good locally, though having no global guarantees. We propose a method of nonparametrically combining local controllers to obtain globally good solutions. We apply this formulation to two types of problems : motion planning (stochastic shortest path) and discounted MDPs. For motion planning, we argue that usual MDP optimality criterion (expected cost) may not be practically relevant. Wepropose an alternative: finding the minimum cost path,subject to the constraint that the robot must reach the goal withhigh probability. For this problem, we prove that a polynomial number of samples is sufficient to obtain a high probability path. For discounted MDPs, we propose a formulation that explicitly deals with model uncertainty, i.e., the problem introduced when transition probabilities are not known exactly. We formulate the problem as a robust linear program which directly incorporates this type of uncertainty.", "histories": [["v1", "Thu, 10 Jan 2013 16:23:48 GMT  (1091kb)", "http://arxiv.org/abs/1301.2273v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI cs.SY", "authors": ["carlos e guestrin", "dirk ormoneit"], "accepted": false, "id": "1301.2273"}
