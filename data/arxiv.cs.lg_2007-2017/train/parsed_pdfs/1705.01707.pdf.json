{
  "name" : "1705.01707.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generative Convolutional Networks for Latent Fingerprint Reconstruction",
    "authors" : [ "Jan Svoboda", "Federico Monti", "Michael M. Bronstein" ],
    "emails" : [ "michael.bronstein}@usi.ch" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Fingerprints have been in used as a means of person authentication since ancient time. The first use of fingerprints in a criminal investigation dates back to 1880’s, when Francis Galton devised the first method for classifying fingerprints. In 1892, the first successful fingerprint-based identification helped convict a murderer. Since then, fingerprinting has underwent massive development and is nowadays an important part of crime scene investigation as well as modern biometric identification systems.\nBased on their acquisition process, fingerprints can be categorized as inked, sensor-scan (e.g. optical, capacitive, etc.), or latent. The first two categories are typically further subdivided into rolled (nail-to-nail fingerprints), flat (single finger) or slap (four finger flat). Those have been heavily researched in the past yielding several state-of-the-art methods [20, 19, 22].\nOn the other hand, latent fingerprints are impressions of the papillary lines that are unintentionally left by a subject at crime scenes. They are typically partial, blured, noisy, and exhibit poor ridge quality, as opposed to inked or sensor-\nscan fingerprints. Such fingerprints are usually lifted from the surface by means of special chemical procedures and photographed using high-resolution camera for further processing. Latent fingerprint matching is a challenging problem and state-of-the-art methods developed for inked and sensor-scan fingerprints do not work well (they typically fail to detect the minutiae or detect many false minutiae due to the imperfections mentioned above).\nIn practice, latent fingerprints are analyzed with the help of forensic examiners who perform a manual latent fingerprint identification procedure called ACE-V (Analysis,\nar X\niv :1\n70 5.\n01 70\n7v 1\n[ cs\n.C V\n] 4\nM ay\n2 01\nComparison, Evaluation, and Verification) [3]. This process is however very demanding and time consuming. In order to make identification efficient, forensic experts tend to restrict the population against which compare the latent fingerprints (focusing, for instance, only on suspects selected by witnesses or other evidence). This obviously reduces the likelihood of effectively identifying the culprit, thus making the overall process less reliable.\nNowadays, several systems supporting the work of forensic examiners are available. The biggest one, AFIS (Automated Fingerprint Identification System), allows examiners to match latent fingerprints against large databases in a semi-automatic manner. The process usually consists of manually marking the minutiae points; launching the AFIS matcher; and visually verifying the top candidate fingerprints. Such a process requires considerable amount of tedious manual labour.\nIn this paper, we improve latent fingerprint recognition by enhancing the input fingerprint image that allows using standard feature extraction methods more reliably. Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints. The neural network is trained on a synthetic dataset consisting of partial and blurry fingerprint impressions containing background noise; the output of the network is compared to the groundtruth fingerprint image. The training set was generated using the open source implementation [2] of the SFinGE fingerprint generator [8].\nWe evaluate our method on two publicly available latent fingerprint datasets: IIIT-Delhi latent fingerprint [30] (for latent-to-latent fingerprints matching) and IIIT-Delhi MOLF [31] (for latent-to-sensor-scan fingerprints matching). We show the broad applicability of our approach and discuss the possible future directions. All the evaluations were done using only open source software. We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching. We show that using our fingerprint enhancement method, the performance of non-commercial fingerprint matching algorithms can be improved and becomes comparable to some of the commercial ones.\nThe rest of the paper is organized as follows. In Section II, previous works are reviewed. Section III describes the objective function used for training the model. Section IV describes the convolutional autoencoder architecture. Section V presents the experimental results. Finally, Section VI concludes the paper and discusses possible future research directions."
    }, {
      "heading" : "2. Related work",
      "text" : "Different solutions for improving latent fingerprint matching systems have been explored in the past. Many works have improved latent fingerprint matching by using extended features that require manual annotation [16, 33]. However, performing the annotation in low-quality latent fingerprints may be very time-consuming and even infeasible in some settings. Other works have strived towards reducing the amount of manual input to only selection region of interest (ROI) and singular points [33, 34]. Approaches performing fusion of multiple matchers or multiple latent fingerprints were explored in [30].\nA different direction for improving fingerprint matching concerns the enhancement of the acquired latent fingerprint images. Yoon et al. [33] proposed a semi-automated method for enhancing the ridge information using the estimated orientation image. A more robust orientation field estimation technique based on Short-Time Fourier Transform and RANSAC has been proposed in [34]. Feng et al. [10] proposed an approach capable of using prior knowledge on the fingerprint ridge structure employing a dictionary of reference orientated patches. Cao et al. [5] introduced a coarse-to-fine dictionary-based ridge enhancement technique.\nMost recent work similar to the proposed approach is Schuch et al. [32], who used a convolutional autoencoder for inked and sensor-scan fingerprints ridge enhancement. Their network had a rather simple architecture and was not evaluated in challenging latent fingerprint recognition settings."
    }, {
      "heading" : "3. Gradient-based fingerprint similarity",
      "text" : "Since our method is based on Convolutional Neural Networks (CNN), the gradient analysis of the fingerprint image ridge pattern becomes a natural choice as the computation of the image gradient can be implemented using the convolutional operator.\nGradient filters. We compute the directional derivatives of the fingerprint image I by convolving it with the directional kernel Sθ\nGθ(I) = I ? Sθ, (1)\nwhere θ is the direction in which we want to compute the gradient (we use 0, 45, 90, and 135 degrees).\nAs a criterion of similarity of two fingerprint images (target image It and reconstructed image Ir), we used the average Mean Squared Error (MSE) on all the directions,\nEgrad(It, Ir) =\n∑ θ∈T 1 n‖(It − Ir) ? Sθ‖ 2 2\n|T | , (2)\nwhere T = {0, 45, 90, 135} is the set of considered orientations and n is the number of image pixels.\nRidge pattern orientation. Orientation of the ridge pattern can be defined through image moments using the already computed image gradients. Considering Gx = G0 and Gy = G90, we define the covariance matrix of the image using second order central moments (µ′20, µ ′ 02, µ ′ 11) [14]:\nCov(I(x, y)) =\n( µ′20 µ ′ 11\nµ′11 µ ′ 02\n) = ( Gxx Gxy Gxy Gyy ) , (3)\nwhere Gxx = gΣs ? (Gx ·Gx), Gyy = gΣs ? (Gy ·Gy) and Gxy = gΣs ?(Gx ·Gy). gΣ represents a Gaussian smoothing kernel with covariance Σ and · denotes the element-wise product.\nEigenvectors of the covariance matrix Cov(I(x, y)) point in the directions of the major and minor intensity of image I . This information is enough to compute the orientation as the angle between the eigenvector corresponding to the largest eigenvalue and the x-axis is expressed by formula:\nΘ = 1\n2 tan−1\n( 2Gxy\nGxx −Gyy\n) . (4)\nIn order to strengthen the similarity between the reconstructed image and the associated ground-truth, we further calculate the reliability orientation field [17]. The ridge orientation image is converted into a continuous vector field as\n(Φx,Φy) = (cos(2Θ), sin(2Θ)), (5)\nSubsequently, we apply Gaussian low-pass filter on the resulting vector field,\n(Φ′x,Φ ′ y) = (gΣo ? Φx, gΣo ? Φy). (6)\nThe reliability measure R is then defined by means of minimum inertia Imin and maximum inertia Imax as follows:\nImin = (Gyy +Gxx)− (Gxx −Gyy)Φ′x −GxyΦ′y\n2 , (7)\nImax = Gyy +Gxx − Imin, (8)\nR = 1− Imin Imax . (9)\nThe intuition behind is that when the ratio Imin/Imax close to 1, there is very little orientation information at that point.\nFinally, we define the orientation energy Eori and reliability energy Erel as the MSE of the orientation and reliability measures computed on the target image It and the reconstructed image Ir,\nEori = 1\nn ‖Θ(It)−Θ(Ir)‖22, (10)\nErel = 1\nn ‖R(It)−R(Ir)‖22. (11)"
    }, {
      "heading" : "4. Fingerprint reconstruction model",
      "text" : "Following the principles described in the previous sections and the guidelines presented in [29], we approached the fingerprint reconstruction problem using a fully convolutional autencoder network.\nArchitecture. The encoding part corresponds to a fully convolutional neural network comprising five convolutional layers. It receives as input tensors of dimensions 1@260x320 and produces as output tensors of dimensions 1024@8x10 (F@WxH is a compact notation for tensors with width W, height H and F different feature channels). The convolutional layers have stride equal to 2 and are equipped with REctified Linear Unit (RELU) [25]. Batch normalization is applied to each layer for faster convergence [15].\nThe output of the encoder is directly fed as an input to the decoding part. The decoder copies the architecture of the encoder performing the following changes. Each convolutional layer is replaced with de-convolutional layer (i.e. a fractionally-strided convolutional layer with stride equal to 0.5 [29]), and each RELU with a Leaky-RELU [21]. In order to reproduce the original grey scale image, a further convolutional layer equipped with a sigmoid activation function is applied at the end of the decoder. Figure 2 depicts our architecture.\nTraining objective. Based on the analysis described in Section 3, we define an objective function that allows to efficiently train our convolutional autoencoder to reconstruct corrupted parts of the fingerprint images. The objective function corresponds to a weighted average of three different losses:\nE = Egrad + λ(Eori + Erel), (12)\nwhere Egrad, Eori and Erel are as defined in the previous section, and λ is a parameter weighting the contribution of the orientation and reliability regularizers.\nTraining. For the purpose of training our model, we generated a dataset of synthetic fingerprints. From these fingerprint images, we simulated latent fingerprint images by applying rotation, translation, directional blur and morphological dilation, and blend the results with several different backgrounds. This way, we aim to simulate the latent fingerprint formation as reliably as possible. We binarize the groudtruth (target) images using approach based on [4]. The network is applied to the synthetic latent fingerprint images and tries to reconstruct the underlying groundtruth image by minimizing the above objective function between the output and the groundtruth image. Since the groundtruth images\nInput 1@256x320 13x13 kernel\nare binarized, our model learns this way not only to reconstruct the fingerprints, but also to directly produce binary images.\nOverall, we used 15000 synthetic fingerprint images for training. Data augmentation was performed by adding random Gaussian i.i.d. noise with µ = 0 and σ = 3.5 · 10−3. The network was trained for 400 epochs (each epoch consisting of 64 iterations). In each iteration, we fed the network with a batch of 12 latent/groundtruth image pairs. We employed Adam [18] updates with β1 = 0.5 and weight decay using L2 regularization with µ = 10−4. The learning rate is set to 2 · 10−4. The weighting parameter λ was set to 0.1."
    }, {
      "heading" : "5. Experiments",
      "text" : "We demonstrate the proposed method on several settings of latent fingerprint recognition. The experiments were carried out using publicly available datasets. Latent fingerprint enhancement was evaluated using the IIIT-Delhi Latent fingerprint [30] and IIIT-Delhi MOLF [31] datasets.\nFor the first evaluation, we applies standard fingerprint recognition algorithms on original fingerprint images and those enhanced by our method. We employed two different feature extraction methods: ABR11 proposed by Abraham et al. [1] and MINDTCT from NBIS [27]. Extracted features were subsequently compared using two different methods, BOZORTH3 [27] (abbreviated to BOZ in the following) and Minutia Cylinder Code (MCC) [6, 7, 11, 12]. For the other evaluations, we used the combination ABR11 + MCC as the best performing one for latent fingerprint matching. Results of latent fingerprint enhancement were presented using TopX measure and Cumulative Match Characteristic (CMC) curves.\nLatent-to-Latent matching. We evaluated latent-tolatent fingerprint matching using the protocol described in [30]. The whole IIIT-Delhi latent fingerprint dataset contained 1046 samples of all the ten fingerprints collected from 15 different subjects. We followed the dataset split strategy proposed in [30], randomly choosing 395 images as gallery and 520 as probes, making sure that each class contained\nat least one gallery sample. 131 images were left out since Sankaran et al. used them for training. We performed 10- fold cross-validation in order to ensure the random splitting does not influence the reported performance.\nTable 1, shows Rank-1 and Rank-10 accuracy for both recognition methods with and without our enhancement. Our approach significantly improves the matching accuracy. Comparing to [30], we outperform all the fingerprint matching methods they have evaluated. It is worth emphasizing that differently from Sankaran et al. we do not need to train on the subset of the data as they do.\nThe CMC curves for this experiment are shown in Figure 3. Our model boosts the performance of ABR11 + MCC much more than that of NBIS. We attribute this to the fact that the energy we minimize while training our model performs very similar operations as the ridge binarization part of the ABR11 feature extraction algorithm.\nLatent-to-Sensor matching. Our second set of experiments tackled an even more challenging task. We used the MOLF dataset containing all ten fingerprints of 100 different subjects. The samples in this dataset were of very different quality, including some very poor samples where no ridge structure was visible at all. Fingerprints of each participant were captured with several commercial fingerprint scanners (Lumidigm, Secugen and Crossmatch). In addition, each participant provided a set of latent fingerprints. It is therefore possible to match latent fingerprints to those acquired by a sensor. Following the testing protocol by Sankaran et al. [31], we considered the first and second instance fingerprints for each user from a sensor scanned database as the gallery. The whole latent fingerprint database consisting of 4400 samples was considered as probe set.\nFor this experiment, we refer to the case from [31], where minutiae were extracted automatically and afterwards matched using one of the standard algorithms. Sankaran et al. evaluated the performance of publicly available NBIS and commercial VeriFinger [26] fingerprint matching methods, reporting very poor performance for both. Here, we used the ABR11 + MCC method for matching. Table 2 shows that using our enhancement algorithm,\nABR11 + MCC performs very poorly, consistently with the finding of [31]. Performing the enhancement with our model significantly improves the performance. CMC curves for this experiment are shown Figure 4.\nCross-dataset Latent-to-Sensor matching. To support the fact that our method works not only matching latent fingerprints to Lumidigm (MOLF DB1) sensor scanned fingerprints, we provide a comparison of matching latent finger-\nprints to Secugen (MOLF DB2) and Crossmatch (MOLF DB3) sensor samples as well using the combination of ABR11 feature extractor and MCC matching method. As samples from various sensors are of different quality, the performance can differ slightly. However, Table 3 indicates that independently of the source sensor, our enhancement algorithm provides significant performance improvement. The CMC curves for this experiment are shown in Figure 5.\nFingerprint quality. In order to qualitatively demonstrate how well our model reconstructs the latent fingerprints, we perform quality assessment using the NFIQ utility (part of NBIS [27]), which assigns a fingerprint image a numerical score from 1 (best quality) to 5 (poorest quality). The distribution of score values shown in Figure 6 clearly indicates that our method improves the fingerprint quality.\nMoreover, we show several successful and several unsuccessful latent fingerprint reconstructions for both real (Figure 7) and synthetic (Figure 8) data. It is clearly visible that our model enhances the ridge information well when it is present and has problems in places where the original images does not contain discernible ridges. This suggests that very poor samples might not contain any meaningful information for the reconstruction process."
    }, {
      "heading" : "6. Conclusion",
      "text" : "Convolutional autoencoders are amongst popular methods extensively used in image processing tasks for image denoising and inpainting. Inspired by the previous applications, we have explored the possibility of using the convolutional autoencoders to reconstruct latent or damaged fingerprints. With regard to principles of some of the fingerprint\nfeature extraction and matching algorithms, we have carefully designed an objective function that should both well reflect on the important fingerprint properties and be efficient to optimize as it is based on gradient analysis, which has been already implemented on the GPUs. Our method is based on learning, however, in comparison to some of the previous research, we do not need any real training data and we effectively train our model on well designed synthetic dataset, which gives us the advantage of no training set size limitation.\nWe obtain state-of-the-art results on several challenging tasks such as latent-to-latent fingerprint matching and latent-to-sensor database fingerprint matching on IIIT-D standard datasets, outperforming the existing results using on the same data by a margin. Especially evaluation on very challenging IIIT-D MOLF dataset compensates for the fact that we cannot evaluate on NIST-SD27 as it is discontinued and no longer provided by NIST.\nOn the other hand, we observe that the reconstruction is not always successful, showing some of the failure cases that are prone to generate false minutiae. We would like to further examine this issue as future work.\nAs we do not aim to directly extract minutiae or per-\nform matching, but rather reconstruct the correct ridge pattern of the poor-quality fingerprint, our method has broad applications ranging from latent fingerprint enhancement to possibly reconstruction of fingerprints affected by diseases, which is another of our desired future directions."
    }, {
      "heading" : "7. Acknowledgements",
      "text" : "The authors are supported in part by ERC Starting Grant No. 307047 (COMET), ERC Consolidator Grant No. 724228 (LEMAN) and Nvidia equipment grant."
    } ],
    "references" : [ {
      "title" : "Fingerprint Matching using A Hybrid Shape and Orientation Descriptor",
      "author" : [ "J. Abraham", "P. Kwan", "J. Gao" ],
      "venue" : "State of the art in Biometrics. InTech",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Generation and storage of large synthetic fingerprint database",
      "author" : [ "A.H. Ansari" ],
      "venue" : "Master’s thesis, IISc,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Handbook of Fingerprint Recognition",
      "author" : [ "D.R. . Ashbaugh" ],
      "venue" : "CRC Press,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1999
    }, {
      "title" : "Adaptive fingerprint binarization by frequency domain analysis",
      "author" : [ "J.S. Bartunek", "M. Nilsson", "J. Nordberg", "I. Claesson" ],
      "venue" : "In Proc. ACSSC,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "Segmentation and enhancement of latent fingerprints: A coarse to fine ridgestructure dictionary",
      "author" : [ "K. Cao", "E. Liu", "A.K. Jain" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Minutia cylindercode: A new representation and matching technique for fingerprint recognition",
      "author" : [ "R. Cappelli", "M. Ferrara", "D. Maltoni" ],
      "venue" : "PAMI, 32(12)",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Fingerprint indexing based on minutia cylinder-code",
      "author" : [ "R. Cappelli", "M. Ferrara", "D. Maltoni" ],
      "venue" : "PAMI, 33(5):1051– 1057",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Synthetic fingerprintimage generation",
      "author" : [ "R. Cappelli", "D. Maio", "D. Maltoni" ],
      "venue" : "pages 475–478",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Learning to generate chairs with convolutional neural networks",
      "author" : [ "A. Dosovitskiy", "J.T. Springenberg", "T. Brox" ],
      "venue" : "CoRR",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Orientation field estimation for latent fingerprint enhancement",
      "author" : [ "J. Feng", "J. Zhou", "A.K. Jain" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Noninvertible minutia cylinder-code representation",
      "author" : [ "M. Ferrara", "D. Maltoni", "R. Cappelli" ],
      "venue" : "IEEE Trans. on Information Forensics and Security, 7(6):1727–1737",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A two-factor protection scheme for mcc fingerprint templates",
      "author" : [ "M. Ferrara", "D. Maltoni", "R. Cappelli" ],
      "venue" : "Proc. BIOSIG, pages 1–8",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Decoupled deep neural network for semi-supervised semantic segmentation",
      "author" : [ "S. Hong", "H. Noh", "B. Han" ],
      "venue" : "CoRR",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Visual Pattern Recognition by Moment Invariants",
      "author" : [ "M.K. Hu" ],
      "venue" : "IRE Trans. on Information Theory,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1962
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "S. Ioffe", "C. Szegedy" ],
      "venue" : "CoRR",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Latent fingerprint matching",
      "author" : [ "A.K. Jain", "J. Feng" ],
      "venue" : "PAMI, 33(1):88–100",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Deducting fingerprint singular points using orientation field reliability",
      "author" : [ "M.S. Khalil" ],
      "venue" : "In Proc. RVSP,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D.P. Kingma", "J. Ba" ],
      "venue" : "CoRR",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Automated Fingerprint Identification Systems (AFIS)",
      "author" : [ "P. Komarinski" ],
      "venue" : "Academic Press",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Advances in Fingerprint Technology",
      "author" : [ "H.C. Lee", "R. Ramotowski", "R.E. Gaensslen" ],
      "venue" : "CRC Press",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Rectifier nonlinearities improve neural network acoustic models",
      "author" : [ "A.L. Maas", "A.Y. Hannun", "A.Y. Ng" ],
      "venue" : "Proc. ICML, volume 30",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Handbook of Fingerprint Recognition",
      "author" : [ "D. Maltoni", "D. Maio", "A.K. Jain", "S. Prabhakar" ],
      "venue" : "Springer Publishing Company, Incorporated, 2nd edition",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Image restoration using convolutional auto-encoders with symmetric skip connections",
      "author" : [ "X. Mao", "C. Shen", "Y. Yang" ],
      "venue" : "CoRR",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction",
      "author" : [ "J. Masci", "U. Meier", "D. Cireşan", "J. Schmidhuber" ],
      "venue" : "pages 52–59. Springer Berlin Heidelberg, Berlin, Heidelberg",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "V. Nair", "G.E. Hinton" ],
      "venue" : "J. Frnkranz and T. Joachims, editors, Proc. ICML, pages 807–814. Omnipress",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Learning deconvolution network for semantic segmentation",
      "author" : [ "H. Noh", "S. Hong", "B. Han" ],
      "venue" : "CoRR",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "author" : [ "A. Radford", "L. Metz", "S. Chintala" ],
      "venue" : "CoRR",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "On matching latent to latent fingerprints",
      "author" : [ "A. Sankaran", "T.I. Dhamecha", "M. Vatsa", "R. Singh" ],
      "venue" : "In Proc. IJCB,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2011
    }, {
      "title" : "Multisensor optical and latent fingerprint database",
      "author" : [ "A. Sankaran", "M. Vatsa", "R. Singh" ],
      "venue" : "IEEE Access, 3:653–665",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "De-convolutional autoencoder for enhancement of fingerprint samples",
      "author" : [ "P. Schuch", "S. Schulz", "C. Busch" ],
      "venue" : "In Proc. IPTA,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2016
    }, {
      "title" : "On latent fingerprint enhancement",
      "author" : [ "S. Yoon", "J. Feng", "A.K. Jain" ],
      "venue" : null,
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2010
    }, {
      "title" : "Latent fingerprint enhancement via robust orientation field estimation",
      "author" : [ "S. Yoon", "J. Feng", "A.K. Jain" ],
      "venue" : "pages 1–8",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Stacked what-where auto-encoders",
      "author" : [ "J.J. Zhao", "M. Mathieu", "R. Goroshin", "Y. LeCun" ],
      "venue" : "CoRR",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "Those have been heavily researched in the past yielding several state-of-the-art methods [20, 19, 22].",
      "startOffset" : 89,
      "endOffset" : 101
    }, {
      "referenceID" : 18,
      "context" : "Those have been heavily researched in the past yielding several state-of-the-art methods [20, 19, 22].",
      "startOffset" : 89,
      "endOffset" : 101
    }, {
      "referenceID" : 21,
      "context" : "Those have been heavily researched in the past yielding several state-of-the-art methods [20, 19, 22].",
      "startOffset" : 89,
      "endOffset" : 101
    }, {
      "referenceID" : 2,
      "context" : "Comparison, Evaluation, and Verification) [3].",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 23,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 32,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 22,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 25,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 12,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 8,
      "context" : "Inspired by the previous success of convolutional autoencoders (CAE) for image processing tasks [24, 35, 23, 28, 13, 9], we design a convolutional autoencoder neural network capable at reconstructing high-quality fingerprint images from latent fingerprints.",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 1,
      "context" : "The training set was generated using the open source implementation [2] of the SFinGE fingerprint generator [8].",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 7,
      "context" : "The training set was generated using the open source implementation [2] of the SFinGE fingerprint generator [8].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 27,
      "context" : "We evaluate our method on two publicly available latent fingerprint datasets: IIIT-Delhi latent fingerprint [30] (for latent-to-latent fingerprints matching) and IIIT-Delhi MOLF [31] (for latent-to-sensor-scan fingerprints matching).",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 28,
      "context" : "We evaluate our method on two publicly available latent fingerprint datasets: IIIT-Delhi latent fingerprint [30] (for latent-to-latent fingerprints matching) and IIIT-Delhi MOLF [31] (for latent-to-sensor-scan fingerprints matching).",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 0,
      "context" : "We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching.",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 5,
      "context" : "We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching.",
      "startOffset" : 126,
      "endOffset" : 140
    }, {
      "referenceID" : 6,
      "context" : "We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching.",
      "startOffset" : 126,
      "endOffset" : 140
    }, {
      "referenceID" : 10,
      "context" : "We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching.",
      "startOffset" : 126,
      "endOffset" : 140
    }, {
      "referenceID" : 11,
      "context" : "We used MINDTCT [27] and an implementation of [1] for features extraction, and BOZORTH3 [27] and MCC (Minutiae Cylinder Code) [6, 7, 11, 12] for fingerprints matching.",
      "startOffset" : 126,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "Many works have improved latent fingerprint matching by using extended features that require manual annotation [16, 33].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 30,
      "context" : "Many works have improved latent fingerprint matching by using extended features that require manual annotation [16, 33].",
      "startOffset" : 111,
      "endOffset" : 119
    }, {
      "referenceID" : 30,
      "context" : "Other works have strived towards reducing the amount of manual input to only selection region of interest (ROI) and singular points [33, 34].",
      "startOffset" : 132,
      "endOffset" : 140
    }, {
      "referenceID" : 31,
      "context" : "Other works have strived towards reducing the amount of manual input to only selection region of interest (ROI) and singular points [33, 34].",
      "startOffset" : 132,
      "endOffset" : 140
    }, {
      "referenceID" : 27,
      "context" : "Approaches performing fusion of multiple matchers or multiple latent fingerprints were explored in [30].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 30,
      "context" : "[33] proposed a semi-automated method for enhancing the ridge information using the estimated orientation image.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "A more robust orientation field estimation technique based on Short-Time Fourier Transform and RANSAC has been proposed in [34].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 9,
      "context" : "[10] proposed an approach capable of using prior knowledge on the fingerprint ridge structure employing a dictionary of reference orientated patches.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 4,
      "context" : "[5] introduced a coarse-to-fine dictionary-based ridge enhancement technique.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 29,
      "context" : "[32], who used a convolutional autoencoder for inked and sensor-scan fingerprints ridge enhancement.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "Considering Gx = G0 and Gy = G90, we define the covariance matrix of the image using second order central moments (μ20, μ ′ 02, μ ′ 11) [14]:",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 16,
      "context" : "In order to strengthen the similarity between the reconstructed image and the associated ground-truth, we further calculate the reliability orientation field [17].",
      "startOffset" : 158,
      "endOffset" : 162
    }, {
      "referenceID" : 26,
      "context" : "Following the principles described in the previous sections and the guidelines presented in [29], we approached the fingerprint reconstruction problem using a fully convolutional autencoder network.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 24,
      "context" : "The convolutional layers have stride equal to 2 and are equipped with REctified Linear Unit (RELU) [25].",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 14,
      "context" : "Batch normalization is applied to each layer for faster convergence [15].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 26,
      "context" : "5 [29]), and each RELU with a Leaky-RELU [21].",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 20,
      "context" : "5 [29]), and each RELU with a Leaky-RELU [21].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 3,
      "context" : "We binarize the groudtruth (target) images using approach based on [4].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 17,
      "context" : "We employed Adam [18] updates with β1 = 0.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 27,
      "context" : "Latent fingerprint enhancement was evaluated using the IIIT-Delhi Latent fingerprint [30] and IIIT-Delhi MOLF [31] datasets.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 28,
      "context" : "Latent fingerprint enhancement was evaluated using the IIIT-Delhi Latent fingerprint [30] and IIIT-Delhi MOLF [31] datasets.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : "[1] and MINDTCT from NBIS [27].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "Extracted features were subsequently compared using two different methods, BOZORTH3 [27] (abbreviated to BOZ in the following) and Minutia Cylinder Code (MCC) [6, 7, 11, 12].",
      "startOffset" : 159,
      "endOffset" : 173
    }, {
      "referenceID" : 6,
      "context" : "Extracted features were subsequently compared using two different methods, BOZORTH3 [27] (abbreviated to BOZ in the following) and Minutia Cylinder Code (MCC) [6, 7, 11, 12].",
      "startOffset" : 159,
      "endOffset" : 173
    }, {
      "referenceID" : 10,
      "context" : "Extracted features were subsequently compared using two different methods, BOZORTH3 [27] (abbreviated to BOZ in the following) and Minutia Cylinder Code (MCC) [6, 7, 11, 12].",
      "startOffset" : 159,
      "endOffset" : 173
    }, {
      "referenceID" : 11,
      "context" : "Extracted features were subsequently compared using two different methods, BOZORTH3 [27] (abbreviated to BOZ in the following) and Minutia Cylinder Code (MCC) [6, 7, 11, 12].",
      "startOffset" : 159,
      "endOffset" : 173
    }, {
      "referenceID" : 27,
      "context" : "We evaluated latent-tolatent fingerprint matching using the protocol described in [30].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 27,
      "context" : "We followed the dataset split strategy proposed in [30], randomly choosing 395 images as gallery and 520 as probes, making sure that each class contained at least one gallery sample.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 27,
      "context" : "Comparing to [30], we outperform all the fingerprint matching methods they have evaluated.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 28,
      "context" : "[31], we considered the first and second instance fingerprints for each user from a sensor scanned database as the gallery.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "For this experiment, we refer to the case from [31], where minutiae were extracted automatically and afterwards matched using one of the standard algorithms.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 28,
      "context" : "ABR11 + MCC performs very poorly, consistently with the finding of [31].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 28,
      "context" : "36% [31] NBIS N/A 6.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 28,
      "context" : "06% [31] VeriFinger N/A 6.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 28,
      "context" : "Two more methods listed in [31] are compared.",
      "startOffset" : 27,
      "endOffset" : 31
    } ],
    "year" : 2017,
    "abstractText" : "Performance of fingerprint recognition depends heavily on the extraction of minutiae points. Enhancement of the fingerprint ridge pattern is thus an essential pre-processing step that noticeably reduces false positive and negative detection rates. A particularly challenging setting is when the fingerprint images are corrupted or partially missing. In this work, we apply generative convolutional networks to denoise visible minutiae and predict the missing parts of the ridge pattern. The proposed enhancement approach is tested as a pre-processing step in combination with several standard feature extraction methods such as MINDTCT, followed by biometric comparison using MCC and BOZORTH3. We evaluate our method on several publicly available latent fingerprint datasets captured using different sensors.",
    "creator" : "LaTeX with hyperref package"
  }
}