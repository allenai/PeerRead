{
  "name" : "1510.07439.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Abinash Tripathy", "Santanu Kumar Rath" ],
    "emails" : [ "abi.tripathy@gmail.com", "skrath@nitrkl.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n51 0.\n07 43\n9v 1\n[ cs\n.S E\n] 2\n6 O\nct 2\n01 5 Object Oriented Analysis using Natural Language Processing concepts: A Review\nAbinash Tripathya, Santanu Kumar Rathb\naDepartment of Computer Science and Engineering, National Institute of Technology, Rourkela, Odisha, India, Contact: abi.tripathy@gmail.com\nbDepartment of Computer Science and Engineering, National Institute of Technology, Rourkela, Odisha, India, Contact: skrath@nitrkl.ac.in\nThe Software Development Life Cycle (SDLC) starts with eliciting requirements of the customers in the form of Software Requirement Specification (SRS). SRS document needed for software development is mostly written in Natural Language(NL) convenient for the client. From the SRS document only, the class name, its attributes and the functions incorporated in the body of the class are traced based on pre-knowledge of analyst.\nThe paper intends to present a review on Object Oriented (OO) analysis using Natural Language Processing (NLP) techniques. This analysis can be manual where domain expert helps to generate the required diagram or automated system, where the system generates the required digram, from the input in the form of SRS.\nKeywords : Software Development Life Cycle (SDLC), Software Requirement Specification (SRS), Natural Language Processing (NLP), Natural Language (NL), Parts Of Speech (POS), Object oriented (OO).\n1. Introduction\nSoftware Requirement Specification (SRS) document forms the basis of problem analysis between client and developer. SRS needs to be very specific, while serving as a basis, to proceed towards implementation of desired software. It is very often observed that SRS is expressed in any natural language as comprehensible by the client. But it may be ambiguous, possibly inconsistent, and probably unmanageably large from the software analyst’s point of view. Identifying major functionalities from the OO analysis point of view plays an important role in project success. The use of formal languages like Unified Modeling Language (UML) have been applied to avoid the inherent problems of natural language such as incompleteness and ambiguity [1]. Earlier analysis was used to help for an explanatory model called as build and fix programming style. But this style was observed to be very informal and there are no set of rules as to which one is superior. Every programmer formulates his own software development technique\nsolely guided by his expertize and in his own language and style [2]. In recent years, the object-oriented software development style is a preferred style over conventional style by developers as the present day software development languages are object oriented in nature. Hence, OO analysis of software helps to find out the candidate for class, function, and the attributes associated with those classes. Natural Language Processing (NLP) combines the effect of computer science and linguistics branch which are concerned with the interaction between the computer and human languages [3]. Natural Language generation systems mostly extracts right information from statements which are in human readable form. The aim of the work is to present a review on existing literature of application of NLP in Object Oriented Analysis (OOA) based on literature available such as: Abbott [5], Saekai and Enamoto [6], Nanduri and Rugaber [7], Juristo and Moreno [8], D. Popescu et al. [9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13]. Among these literatures few authors suggested auto-\n1\nmated tools, other use manual approach and few combine both tool and manual approach to obtain the different elements of OO analysis .\nIn order to examine each proposal, the following dimensions may be considered\n• Steps to modify the SRS into required form: As discussed above the SRS is written in a form i.e., convenient to the user. During this step the SRS is modified to a format by which the process of finding the keywords became easier for analysts.\n• Finding out the candidate for class and object from modified SRS: After transforming the SRS to the required format for analysis, then the candidates for the class name and its details are traced out. The process of identification of the class name and its detail can be a manual or a automated process. In manual process, the domain expert analyzes text to bring out “intermediate output” then automated process considers the intermediate output to generate the desired output.\nThe objective of this work is two-fold:\n1. This analysis provides information on available techniques for use of NLP, further to be considered under OO analysis.\n2. It provides an overview of the current state for the use of NLP in OO analysis, focusing on the strengths and weaknesses of existing proposal. Thus researchers can have a broad knowledge into the work that already being done and that still can be carried out in this field.\nThe paper is organized as follows: In section 2 the existing proposals of the use of NLP for OOA analysis are presented. Section 3 presents an analysis on all proposals. Finally, section 4 discusses on some concluding remarks and highlights the future trend.\n2. Proposal of the use of NLP in OO Analysis\n2.1. Historical review on NLP Jones in his paper presented a review paper on NLP based on the historical study [4]. The paper reviews study of NLP from late 1940’s to present by distinguishing four phases in the history of NLP. The impact of use of machine translation, artificial intelligence influence, logicogrammatical style adaption and massive language data attack act as the basis of the phase division.\nPhase 1. The early phase of study on NLP was during late 1940s to late 1960s and in this period focus was mainly in Machine Translation (MT). Noticeable amount of work done in USSR, USA, Europe and Japan during this period. Thus the languages considered for research in this period were mostly Russian and English [14]. Language syntax was mainly the area of research in this period as syntactic processing was manifestly necessary, and partly carried out through implicit or explicit endorsement of the idea of syntax-driven processing. Though during this period use of computers for literary and linguistic study has began, but it has never been linked with NLP.\nPhase 2. Next phase of study was undertaken from late 1960s to late 1970s and the work mainly focused on use of artificial intelligence (AI) in NLP, with much more priority on word knowledge and on its implementation in the construction and manipulation of meaning representations. AI was mainly considered during this period for construction and addressing of knowledge base or data. In late 1960s, the prevalent theory of linguistic is transformational grammar, which provides the semantic information about NLP.\nPhase 3. This phase was mainly concerned to the period of late 1970s to late 1980s and characterized as grammatico-logical phase. The requirement of development of gram-\nmatical theory and movement towards incorporation of logic in knowledge representation and reasoning triggered during 70s. During this phase, deliberate attempts made to transform the commercially available dictionary to machine-readable form which further helps in text corpora validation and customizing lexical data.\nPhase 4. The forth and the final phase can be attributed as the study carried out from late 1980’s onwards. During this phase, the main area of research is statistical language data processing. The identification of linguistic occurrence and patterns in the corpus for both syntactic and semantic analysis, drew interest in this period. The present attention on lexicon, retrieving statistical information, and restore interest in MT.\nTable 1 compares the NLP research based on time period\n2.2. OO Analysis using NLP approaches In course of this section, the study made by various authors are analyzed on the basic of how they transform the SRS and how the candidate for the class name and its details are found out from transformed SRS.\n2.2.1. Abbott, 1983 [5] The study made byAbbott proposes a method to derive the elements of object oriented analysis i.e., data type, variables, operators, attributes and candidate for class name form English statements. This paper shows the process of analysis of the English statement of SRS and helps to generate elements of OO analysis. The approach used in this paper is divided into three different sections. These are as follows\ni. Development of informal strategy for the problem: The informal strategy should suggest the problem solution on the conceptual level. This step express the solution of the problem in terms of problem domain.\nii. Formalize the Strategy: The second step is formalizing the solution by finding out its data types, objects, operators, and control constructs. The steps of formalization are:\n(a) Identify the Data types: The data types are suggested by the common nouns. The name of a class of beings or things are known as common noun.\n(b) Identify the objects of those types: Objects are suggested by Proper Nouns or Direct References. The name of specific things or beings is known as proper noun. A specific, previously identified being or thing without necessarily referring to it by name is known as direct reference.\n(c) Identify the operators for the objects: Operators are suggested by verb, attribute, predicate or descriptive expression. Attribute is a property, association, characteristics or component of something. Predicate designates a property or relation that can be consider True or false i.e., to hold or not to hold. A descriptive expression is a characterization for which there may be some particular object.\n(d) The control structures are directly provided by the English language.\niii. Segregate the solution into two parts, A package and subprogram: The package will contain the formalization of the problem domain, that is, the data types and their operators. Then subprogram(s) will contain the specific steps (expressed in terms of the data types and operators defined in the package) for solving the particular problem.\nDuring the course of the paper, different types of nouns are analyzed i.e., the difference of common noun with proper noun, direct references and mass nouns are provided. Classes of objects are referred by Common Noun but specific and individual objects are referred by Proper noun. Mass nouns are names of qualities, substances, and activity that do not have an a priori organization into individual units or instances.\nIn this paper Abbott had taken an example of “Calculating the days between two given dates” to explain his technique. As per the analysis referred in the paper, the process is divided into three different steps:\n• In step 1, an informal strategy of the problem analysis is provided. In this step the process of getting the detailed solution is being analyzed.\n• In step 2, the data types, objects, operators, and control structures are found for the specific problem form the informal specification.\n• In step 3, the final solution is being prepared. The package for the problem is assigned and the subprogram details are provided in this step.\nThough this paper is comparatively easy in solving the problem of finding the candidate for class name and its details but the process is manual. A software engineer having a good knowledge about the domain requires to provide the step-wise solution of the problem.\n2.2.2. Saeki et al., 1989 [6] The paper by Saeki et al. discusses the process of derivation of formal specification from\nan informal specification written in natural language. The informal specification contains important information leading to their formal specification or the prototype program. Then the similarity between the structure of the words and the structure of software component is analyzed. In this paper, the “Lift Control System” example has been explained as an informal specification to explain the process. The process consist of three major steps as follows:\ni. Design Activity: The purpose of this step is to construct a module design document from informal specification. The modular design document presents the modular structure of a formal specification, i.e., external design of class modules which contain class names, method names and message protocols. This design activity consists of several sub-activities. Each of them produce an intermediate product using the informal specification. The intermediate products obtained are as follows:\n• Noun table: This table contains information about extracted nouns. According to the author, noun can be classified into different group, i.e., Class noun identifies object or set of objects, Value noun identifies the values or set of values, Attribute noun identifies the attribute of the objects and Action noun identifies the actions to be carried out.\n• Verb table: This table contains information about extracted verbs, i.e., verb names, their categories, their subjects and objectives. According to the author, verbs can also be classified into different groups. Relation verb specifies the relation between objects or between objects and their attributes. State verb specifies the internal state of the object or the attribute values of the object. Action verb specifies the action to the objects and Action relational verb specifies the relation between the actions.\n• Action table: This table presents the extracted actions, their agents, target\nobjects and input output parameter associated with them. For each action verb, there is always an agent and its target object. The action verb changes the state of the target object. In order to extract a target object from a sentence, verb patterns that appear in various kinds of natural language specification are examined.\n• Action Relation table: The informal specification, its verb table and its action verb are needed to identify the relationship between the actions. For every action to be performed, the sender, receiver and the message transmission between them need to be identified. in this paper, the authors have used a rule called “action relation rule” to generate a few candidate for a sender-receiver pair.\n• Module Design Document: A module design document is constructed using above mentioned tables. The noun table helps to identify objects and their attributes. The verb table is used to extract relationship among objects and kind of attributes, each object possess. The module design document can have both graphical and textual representation. Both of them are based on syntax of formal specification language TELL and object oriented language Smalltalk80.\nii. Elaborate - Design Activity Cycle: The task of this activity is to refine and rewrite the informal specification as per module design document. The output of this activity is a natural language description which is accurate, detailed, structured yet informal. Whenever the elaborate-design cycle is carried out, a pair of informal specification and its module design document is obtained. The elaborate activity consists of sub-activities such as paste ,refine and an intermediate product a paste document is generated.\n• Paste: During this phase, the sentences of informal specification may be paraphrased to accurate sentence and then replace the original one. In the updated expression, the nouns and verbs are extracted as classes, and attributes or method to be used respectively.\n• Refine: The informal specification of each pasted module are constructed during refine activity. During this phase, the internal behavior and property of each class module is rewritten again, which are used for construction of each class.\n• Design activity for elaborate Informal\nSpecification: Before this activity, the module design document for each class is constructed from elaborate informal specification. During this activity, each class module and method module are composed into small sub module to realize the internal behavior and property.\nThe cycle continues until a formal specification is obtained from the informal specification. The requirements need to be refined and made simpler and smaller during this cycle.\niii. Software process based on Natural Language: During this process the design and elaborate process are embedded. Before this phase, the informal specification is already converted to formal specification, the rest steps are as follows\n• Analyze activity: This step acquires a problem description by means of interaction between customer and developer. An informal specification is obtained as an output of this step.\n• Evaluate activity: During this activity, the obtained formal specification is executed and verified. The diagnostic document keeps a record of the execution and verification.\n• Evolve activity: During this activity, the developers check the diagnostics docu-\nment and find whether something is to be modified or not. If so, they create a new version of informal specification, this process is called as “evolve activity”. From this new document, new module design document, new formal specification, new diagnosis document are produced.\n• Instantiate activity: When the developers judge that the formal specification is accepted to the customer’s need, they finally produce the concrete program code. This activity is called as instantiate activity. A formal specification is considered to be a generalization or abstraction of program code.\nIn this paper, the author has presented a software design process based on natural language and obtained formal specification from informal one through the design and elaborate activity. The technique used in this paper is verb-oriented which has an impact on the dynamic nature of informal specification. Along with this, nouns also needed to extract the hierarchy of class.\n2.2.3. D. Popescu et. al.,2008 [9] This paper by D. Popescu et. al. proposed an approach to help the writer or reviewer in identifying the ambiguities in NL SRS. A tool named “Dowser” is proposed by them which creates OO digram from NL SRS. Their approach consists of three steps\nStep 1: The NL SRS is parsed according to a constraining grammar.\nStep 2: From the obtained relationship after parsing, the tool creates the elements of object-oriented analysis model of the specified system.\nStep 3: The diagram of the model is generated, which is reviewed by human reviewer to detect any inconsistency or ambiguity.\nThe authors in this paper prefer the use of model over analysis of the whole NL SRS due to following reason\n• All software companies irrespective of their domain use NL SRS for description of software system.\n• An Object Oriented Analysis Module (OOAM) shows the concepts and the relationship among them.\n• The OOAMmodel for each sentence is identified while OO design selects parts of the sentences, such as class from subject, attributes from adjective and methods from verb.\nDuring the course of the paper, the authors had used few concepts such as\n• Constraining Grammar: It is different from the internal grammar that parser uses. The constraining grammar attempts to reduce the number of way a statement can be represented and also try to make it uniguous (not ambiguous). On the other hand, the NL parser grammar checks the legitimacy of the sentence only, without checking whether it is ambiguous or not.\nThis paper used the constraining grammar proposed by Juristo et.al., in their paper [8]. It attempts to generate an unambiguous mapping form this grammar to OOAM. The constraining grammar influences the structure of NL SRS as it uses simple sentence consisting of subject, object and verbs.\n• Natural Language Parsing : As OOAM is generated using syntactic information automatically, parsing of NL SRS is needed to obtain the required information. The parser uses the link-grammar that consists of set of words. These words act as terminal symbols and have different liner requirements.\n• Transformation Rules: These rule helps to transform the obtained syntactic information to targeted OOAM. Dowser have thirteen different transformation rules, the most generally used rules are:\n– If the sentence contains both subject and object link after parsing, then two\ndifferent classes are created with association named as verb.\n– To find aggregation, if the parsed sentence consists of both subject and object link and the verb is one of “have, posses, contain or include” then the object is aggregated to subject.\n– “if or when ” always represent the start of an event. If an event is detected by Dowser and the main clause only consists of subject link, then class is created with the noun present in subject link and verb acts as a method to it.\n– If genitivity detected by Dowser, two different classes are created with one linking aggregation. In order to fix whether both became aggregated class or one became attribute of other, both syntactic and semantic information of the sentence are needed.\n– Though active clauses preferred in NL SRS still passive clause helps to describe relations and states. The passive verb and its connecting word describe the association.\nDowser applied two post processing rules after transforming NL SRS. These are\ni. It converts all classes that aggregated to another class as attribute of other class.\nii. It removes class “system” from OOAM.\n• Domain-Specific Terms(DST): Special domain data dictionary is needed by the parser to interpret the DST. But for each domain such dictionary does not exist. Hence, to improve the DST recall, the link grammar has a guessing mode that uses the syntactic role of unknown terms.\n• Diagramming OOAM: The textual OOAM is created using previous steps. The\ntool UMLGraph transforms the textual information into a dot file while then transforms into graphic format using Graphviz tool.\n• Interpretation of OOAM: In this step, a human analyst checks for ambiguity in generated diagram. The defects that can be found out in OOAM are as follows\n– An association can be ambiguous; so, the analyst checks whether different classes transmit message to same class or not.\n– The classes should represent only one concept. As Dowser does not allow generalization principle, the concepts such as cash payment and on-line payment are not combined to form payment as a whole; but can be identified as two different classes.\n– If the classes have attributes that are not of primitive type, proper definition added to it so, it can be represented in own class.\n– The class must be associated with other class otherwise it becomes unspecified.\nThis paper only supports the static behavior/ relationship of OOAM present in NL SRS. It does not manage the modeling behavior.\n2.2.4. Ibrahim and Ahmad, 2010 [10] This paper of Ibrahim and Ahmad proposes method to facilitate requirement analysis process and extraction of class diagram from requirements using NLP and Domain Ontology. A tool named “ Requirements Analysis and Class Diagram Extraction (RACE) ” is being proposed by the authors that analyzes the textual requirements, finding out the relationships and finally extracts the class diagram. The RACE system consists of different internal and external components or sub-systems. These can be described as follows:\ni. OpenNLP Parser: The OpenNLP parser used in this paper for lexical and syntactic\nparsing. The parser takes English text as input and provides corresponding POS tag for each word as output.\nii. RACE Stemming Algorithm: Stemming is a process of removing affixes and suffixes from a word and generating the base word. The generated base word reduces the redundancy and increases efficiency.\niii. WordNet: It is used to validate the semantic of the sentences that generated after syntactic analysis. It also helps to display hyponyms for a selected noun, which helps to know the “a kind of” relationship.\niv. Concept Extraction Engine: This module is used to extract concepts according to the requirement document. The algorithm for this module is as follows:\nStep 1. Requirement document is taken as input.\nStep 2. Stop words are identified and stored as Stop-words Found list\nStep 3. Calculate the frequency of each words in the document except the Stop words.\nStep 4. Use RACE stemming algorithm to stem each words and store them in a list.\nStep 5. Use OpenNLP to parse whole document.\nStep 6. From the parsed output extract the words with POS Proper Nouns (NN), Noun Phrases (NP), verb (VB) and store them in Concept-list.\nStep 7. For each concept in concept-list, if any other concept is synonym with present one, then it can be conveyed that both are semantically related.\nStep 8. For each concept in concept-list, if any other concept is item Requirement document is taken as input.\nStep 9. Stop words are identified and stored as Stop-words Found list\nStep 10. Calculate the frequency of each words in the document, except the Stop words.\nStep 11. Use RACE stemming algorithm to stem each word and store them in a list.\nStep 12. Use OpenNLP to parse whole document.\nStep 13. From the parsed output extract the words with POS Proper Nouns(NN), Noun Phrases (NP), verb (VB) and store them in Concept-list.\nStep 14. For each concept in concept-list, if any other concept is synonym with present one then it can be conveyed that both are semantically related.\nStep 15. For each concept in concept-list, if any other concept is hyponyms with present one i.e., lexically same then it can be conveyed that former is a kind of later and saved in Generalizationlist. with present one i.e., lexically same then it can be conveyed that former is a kind of later and saved in Generalization-list.\nv. Domain Ontology: It is used to improve the performance of concept identification. In RACE system Library system ontology is being used. XML is being used to build the ontology.\nvi. Class Extraction Engine: The input to this module is the output of “Concept Extraction Engine”. During this step, some heuristic rules are used by the authors to extract the class diagram. The rules are as follows\n• Class Identification Rules: The rules used for extraction of classes are:\n– If the occurrence of the concept is only one or frequency is 2%, then the concept is ignored as class.\n– If the concept is related to design elements, location name or person name, then ignore as class.\n– If the concept found in high level of hypernyms tree or an attribute then ignore it as a class.\n– If the concept is a noun phase and the second part is an attribute then consider the first part for class name.\n• Attribute Identification Rules: The rules for attribute identification is as follows\n– If the concept is a noun phase including underscore between two nouns, then the first noun is a candidate for class name and the second part is attribute of that class.\n– If the concept has only one value then it is an attribute.\n• Relationship Identification Rules: The rules for relationship identification is as follows:\n– Using step 8 of concept extraction engine, the element of generalization-list transferred as Generalization (is-a) relationship.\n– If there exists a sentence having (CT1-VB-CT2) where CT1 and CT2 are classes, then VB is an association rule.\n– If the sentence is of the form CT1+R1+CT2+“AND”+CT3 where CT1, CT2 and CT3 are classes and R1 is the relationship, then there exists relationship between (CT1,CT2) and (CT1,CT3).\nvii. RACE Concept Management: User interaction is important in RACE system. The UI helps to perform tasks such as creating and printing requirement and acts as an interface to add, modify, view and organize relationships.\nThe RACE system is implemented using C#, MS Access is being used for database operation, and to open textual requirements word document, text file, rich text file, and HTML file are being used.\n2.2.5. Overmyer and Rambow,2001 [12] This paper of Overmyer and Rambow proposes a tool called Linguistic assistant for Domain Analysis (LIDA) that provides linguistic assistance for model development process. This tool helps to obtain the OO model for a domain using UML. In order to perform this task, large volume of text from “Legacy system” is collected. The LIDA tool considers the following features\n• Domain independent linguistic processing used to group different form of base words using POS and to find multi-word terms.\n• The final output is in the form of full text, word-list and UML model in parallel. So the user can compare all of them.\n• KeyWord In Context ‘KWIC’ view displays the words or group of words in sentences.\n• Hypertext description model used to help in documentation of the model.\n• Completed model can be exported any CASE tool or any model can be imported from any CASE tool to LIDA.\nLIDA consists of following components:\ni. Text analysis environment: This component is the main component of LIDA as it provides the central functionality. The main functionalities this component performs are:\n• It takes the text input in RTF and ASCII format.\n• Then it assigns POS tag to each word. For POS tagging, It uses MXPOST, a software tool developed at University of Pennsylvania,USA.\n• Base word is obtained form each word and their frequency is calculated.\n• Multi-word phases are checked for a given base word.\n• Users are allowed to mark the words or phases as candidate model and highlights these words in the text .\n• Retrieve textual context of marked words.\nMode editing environment: This model offers the functionality requirement to generate a model from the proposed model marked in LIDAs Text Analyzing Environment. The functional features of this components are:\n• Display list of candidate model element marked and add them to model editing environment. Transfer of information between text analysis environment and mode editing environment helps developer to analyze the problem in details.\n• Suggest operations for combining elements to class model.\n• Add textual context helpful for processing model builder.\n• Generate textual description of model for documentation and validation of model with domain expert.\nii. LIDA text description: LIDA uses ModelExplainer an integrated tool, which generates the hypertext description document for object model. This document is generated from customized text which includes the class information like superclass, subclass, attributes, operation and association with other class. These descriptions help to obtain additional information about the final result.\nThe following Table 2 provides a comparative analysis of the approaches to obtain the elements of OO analysis from SRS.\n3. Analysis of Approaches\nIn present day scenario, the use of object oriented system is widely applied for software development. The customer mention all it’s requirements in a document called Software requirement specification. This SRS document is written in NL which is understandable by the customer side, but it is sometimes incomplete and ambiguous. The development team need to go through these document and generate UML diagram and analyze on basic of OO analysis. The UML being\nvery often used for OOA tries to fix the class diagram where class is also basic element of OO system. During the course of the paper, it can be found out that different approaches are adapted to generate the class diagram and its corresponding details. These approaches can be mentioned as follows:\n• The software requirement document is considered as an input for the analysis.\n• As it is written in NL, it contains some ambiguities or unwanted information. So, in order to remove that different steps are car-\nried out in all papers.\n• Each words in the text is tagged with a POS. Then the words are combined together depending upon their POS.\n• The noun and verb tagged words are mainly used for class name and their operations respectively. So these words are then stemmed to obtain the root word and their suffixes.\n• After obtaining the root noun words, the higher frequency nouns are considered and they are the most eligible onces for fixing class name.\n• For operations in class, the verbs present in the sentence are the best candidate.\n• The Adjectives present in text act as an attribute for the class for that noun it tries to modify.\n• In order to find the relationship between classes, the relation between the subject and object of a sentence is found out.\n• For other rules like multiplicity determines are used that specify the relationship like one-one, one-many, many-one, many-many.\n4. Conclusion and Future scope\nThere are different tools that have been developed to analyze the text; but as there is no exhaustive dictionary which helps to provide POS for each words. Although few tools generate the class diagram but different authors suggest that a manual intervention is needed to improve the final result. Until and unless there is specific rules for writing the SRS document, the ambiguities continue to be present in it and that cause issue in compiling the SRS. Though many approaches have been proposed and also are used to obtain the elements of OO analysis still there is scope for research in this area. To automated understanding the SRS written in informal NL is also an issue in research.\nREFERENCES\n1. J. Rumbaugh, I. Jacobson, and G. Booch, Unified Modeling Language Reference Man-\nual, The. Pearson Higher Education, 2004. 2. R. S. Pressman, Software engineering: a prac-\ntitioner’s approach. McGraw-hill New York, 2010, vol. 7. 3. E. Kumar, Natural language processing. IK International Pvt Ltd, 2011. 4. K. S. Jones, “Natural language processing: a historical review,” in Current Issues in Computational Linguistics: in Honour of Don\nWalker. Springer, 1994, pp. 3–16. 5. R. J. Abbott, “Program design by infor-\nmal english descriptions,” Commun. ACM, vol. 26, no. 11, pp. 882–894, Nov. 1983. 6. M. Saeki, H. Horai, and H. Enomoto, “Software development process from natural language specification,” in Proceedings of the 11th international conference on Software en-\ngineering, ser. ICSE ’89. New York, NY, USA: ACM, 1989, pp. 64–73. 7. S. Nanduri and S. Rugaber, “Requirements validation via automated natural language parsing,” in System Sciences, 1995. Proceedings of the Twenty-Eighth Hawaii Interna-\ntional Conference on, vol. 3. IEEE, 1995, pp. 362–368. 8. N. Juristo, A. M. Moreno, and M. López, “How to use linguistic instruments for objectoriented analysis,” IEEE software, vol. 17, no. 3, pp. 80–89, 2000. 9. D. Popescu, S. Rugaber, N. Medvidovic, and D. M. Berry, “Reducing ambiguities in requirements specifications via automatically created object-oriented models,” in Innovations for Requirement Analysis. From Stake-\nholders Needs to Formal Designs. Springer, 2008, pp. 103–124. 10. M. Ibrahim and R. Ahmad, “Class diagram extraction from textual requirements using natural language processing (nlp) techniques,” in Computer Research and Development, 2010 Second International Conference\non. IEEE, 2010, pp. 200–204. 11. H. M. Harmain and R. Gaizauskas, “Cm-\nbuilder: an automated nl-based case tool,” in\nAutomated Software Engineering, 2000. Proceedings ASE 2000. The Fifteenth IEEE International Conference on. IEEE, 2000, pp. 45–53. 12. S. P. Overmyer, B. Lavoie, and O. Rambow, “Conceptual modeling through linguistic analysis using lida,” in Proceedings of the 23rd international conference on Software en-\ngineering. IEEE Computer Society, 2001, pp. 401–410. 13. L. Mich and R. Garigliano, “Nl-oops: A requirements analysis tool based on natural language processing,” in Proceedings of Third International Conference on Data Min-\ning Methods and Databases for Engineering,\nBologna, Italy, 2002. 14. A. D. Booth, Machine Translation. North-\nHolland Publishing Company, 1967. 15. J. Rumbaugh, M. Blaha, W. Premerlani,\nF. Eddy, W. E. Lorensen et al., Objectoriented modeling and design. Prentice-hall Englewood Cliffs, NJ, 1991, vol. 199. 16. F. N. Paulisch and W. F. Tichy, “Edge: An extendible graph editor,” Software: Practice and Experience, vol. 20, no. S1, pp. S63–S88, 1990. 17. M. Jackson, “Developing ada programs using the vienna development method (vdm),” Software: Practice and Experience, vol. 15, no. 3, pp. 305–318, 1985. 18. R. Gaizauskas, K. Humphreys, H. Cunningham, and Y. Wilks, “University of sheffield: description of the lasie system as used for muc-6,” in Proceedings of the 6th conference on Message understanding. Association for Computational Linguistics, 1995, pp. 207– 220. 19. R. E. Callan, Building Object-Oriented Systems: An introduction from concepts to im-\nplementation in C++. Computational Mechanics, 1994.\nAbinash Tripathy is currently pursing his Ph.D. at National Institute of Technology, Rourkela. He obtained his Master degrees, M.Sc. Computer Science from Utkal University, Bhubaneswar and\nM.Tech. Computer Science and Engg. from KIIT University, Bhubaneswar. His research interest are Software testing, UML, Natural Language Processing and Sentiment analysis.\nDr. Santanu Kumar Rath is a Professor in the Department of Computer Science and Engineering, NIT Rourkela since 1988. His research interests are in Software Engineering,\nSystem Engineering, Bioinformatics, Natural Language Processing and Management. He is a Senior Member of the IEEE, USA and ACM, USA and Petri Net Society, Germany."
    } ],
    "references" : [ {
      "title" : "Unified Modeling Language Reference Manual, The",
      "author" : [ "J. Rumbaugh", "I. Jacobson", "G. Booch" ],
      "venue" : "Pearson Higher Education,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2004
    }, {
      "title" : "Software engineering: a practitioner’s approach",
      "author" : [ "R.S. Pressman" ],
      "venue" : "McGraw-hill New York,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2010
    }, {
      "title" : "Natural language processing",
      "author" : [ "E. Kumar" ],
      "venue" : "IK International Pvt Ltd,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Natural language processing: a historical review,",
      "author" : [ "K.S. Jones" ],
      "venue" : "Current Issues in Computational Linguistics: in Honour of Don Walker. Springer,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1994
    }, {
      "title" : "Program design by informal english descriptions,",
      "author" : [ "R.J. Abbott" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1983
    }, {
      "title" : "Software development process from natural language specification,",
      "author" : [ "M. Saeki", "H. Horai", "H. Enomoto" ],
      "venue" : "Proceedings of the 11th international conference on Software engineering, ser. ICSE ’89",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1989
    }, {
      "title" : "Requirements validation via automated natural language parsing,",
      "author" : [ "S. Nanduri", "S. Rugaber" ],
      "venue" : "in System Sciences,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1995
    }, {
      "title" : "How to use linguistic instruments for objectoriented analysis,",
      "author" : [ "N. Juristo", "A.M. Moreno", "M. López" ],
      "venue" : "IEEE software,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "Reducing ambiguities in requirements specifications via automatically created object-oriented models,” in Innovations for Requirement Analysis",
      "author" : [ "D. Popescu", "S. Rugaber", "N. Medvidovic", "D.M. Berry" ],
      "venue" : "From Stakeholders Needs to Formal Designs. Springer,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "Class diagram extraction from textual requirements using natural language processing (nlp) techniques,",
      "author" : [ "M. Ibrahim", "R. Ahmad" ],
      "venue" : "Computer Research and Development,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Cmbuilder: an automated nl-based case tool,",
      "author" : [ "H.M. Harmain", "R. Gaizauskas" ],
      "venue" : "Abinash Tripathy, et al. Automated Software Engineering,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2000
    }, {
      "title" : "Conceptual modeling through linguistic analysis using lida,",
      "author" : [ "S.P. Overmyer", "B. Lavoie", "O. Rambow" ],
      "venue" : "Proceedings of the 23rd international conference on Software engineering. IEEE Computer Society,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2001
    }, {
      "title" : "Nl-oops: A requirements analysis tool based on natural language processing,",
      "author" : [ "L. Mich", "R. Garigliano" ],
      "venue" : "Proceedings of Third International Conference on Data Mining Methods and Databases for Engineering,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2002
    }, {
      "title" : "Developing ada programs using the vienna development method (vdm),",
      "author" : [ "M. Jackson" ],
      "venue" : "Software: Practice and Experience,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1985
    }, {
      "title" : "University of sheffield: description of the lasie system as used for muc-6,",
      "author" : [ "R. Gaizauskas", "K. Humphreys", "H. Cunningham", "Y. Wilks" ],
      "venue" : "Proceedings of the 6th conference on Message understanding. Association for Computational Linguistics,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1995
    }, {
      "title" : "Building Object-Oriented Systems: An introduction from concepts to implementation in C++",
      "author" : [ "R.E. Callan" ],
      "venue" : "Computational Mechanics,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The use of formal languages like Unified Modeling Language (UML) have been applied to avoid the inherent problems of natural language such as incompleteness and ambiguity [1].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 1,
      "context" : "Every programmer formulates his own software development technique solely guided by his expertize and in his own language and style [2].",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "Natural Language Processing (NLP) combines the effect of computer science and linguistics branch which are concerned with the interaction between the computer and human languages [3].",
      "startOffset" : 179,
      "endOffset" : 182
    }, {
      "referenceID" : 4,
      "context" : "The aim of the work is to present a review on existing literature of application of NLP in Object Oriented Analysis (OOA) based on literature available such as: Abbott [5], Saekai and Enamoto [6], Nanduri and Rugaber [7], Juristo and Moreno [8], D.",
      "startOffset" : 168,
      "endOffset" : 171
    }, {
      "referenceID" : 5,
      "context" : "The aim of the work is to present a review on existing literature of application of NLP in Object Oriented Analysis (OOA) based on literature available such as: Abbott [5], Saekai and Enamoto [6], Nanduri and Rugaber [7], Juristo and Moreno [8], D.",
      "startOffset" : 192,
      "endOffset" : 195
    }, {
      "referenceID" : 6,
      "context" : "The aim of the work is to present a review on existing literature of application of NLP in Object Oriented Analysis (OOA) based on literature available such as: Abbott [5], Saekai and Enamoto [6], Nanduri and Rugaber [7], Juristo and Moreno [8], D.",
      "startOffset" : 217,
      "endOffset" : 220
    }, {
      "referenceID" : 7,
      "context" : "The aim of the work is to present a review on existing literature of application of NLP in Object Oriented Analysis (OOA) based on literature available such as: Abbott [5], Saekai and Enamoto [6], Nanduri and Rugaber [7], Juristo and Moreno [8], D.",
      "startOffset" : 241,
      "endOffset" : 244
    }, {
      "referenceID" : 8,
      "context" : "[9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13].",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 10,
      "context" : "[9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13].",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 11,
      "context" : "[9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 12,
      "context" : "[9], Ibrahim and Ahmed [10],Harmain and Gaizauskas [11], Overmyer and Rambow [12], Mich [13].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 3,
      "context" : "Historical review on NLP Jones in his paper presented a review paper on NLP based on the historical study [4].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 4,
      "context" : "Abbott, 1983 [5] The study made byAbbott proposes a method to derive the elements of object oriented analysis i.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 5,
      "context" : ", 1989 [6] The paper by Saeki et al.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 8,
      "context" : ",2008 [9] This paper by D.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 7,
      "context" : ", in their paper [8].",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "Ibrahim and Ahmad, 2010 [10] This paper of Ibrahim and Ahmad proposes method to facilitate requirement analysis process and extraction of class diagram from requirements using NLP and Domain Ontology.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 11,
      "context" : "Overmyer and Rambow,2001 [12] This paper of Overmyer and Rambow proposes a tool called Linguistic assistant for Domain Analysis (LIDA) that provides linguistic assistance for model development process.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "Abbott [5] This paper analyzes the English statement of SRS and generate elements of OO analysis.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 5,
      "context" : "[6] This paper derive formal specification from informal specification in English and from that obtain elements of OO.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "Nanduri and Rugaber [7] This paper extract the candidate objects, methods and its association from requirement document then composing them to generate object model.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 7,
      "context" : "[8] This paper uses the linguistic information from informal specification.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] This paper identify the ambiguities in NL SRS.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "Ibrahim and Ahmad [10] This paper uses the requirement analysis process and extract class diagram using NLP and Domain Ontology.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 10,
      "context" : "Harmain and Gaizauskas [11] This paper uses CM-Builder tool for OO analysis.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 11,
      "context" : "Overmyer and Rambow [12] The paper uses LIDA tool to provide linguistic information assistance in model development process.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 12,
      "context" : "Mich [13] This paper uses an NL-OOPS tool based on LOLITA.",
      "startOffset" : 5,
      "endOffset" : 9
    } ],
    "year" : 2015,
    "abstractText" : "The Software Development Life Cycle (SDLC) starts with eliciting requirements of the customers in the form of Software Requirement Specification (SRS). SRS document needed for software development is mostly written in Natural Language(NL) convenient for the client. From the SRS document only, the class name, its attributes and the functions incorporated in the body of the class are traced based on pre-knowledge of analyst. The paper intends to present a review on Object Oriented (OO) analysis using Natural Language Processing (NLP) techniques. This analysis can be manual where domain expert helps to generate the required diagram or automated system, where the system generates the required digram, from the input in the form of SRS.",
    "creator" : "LaTeX with hyperref package"
  }
}