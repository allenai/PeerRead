{
  "name" : "1709.00028.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Glyph-aware Embedding of Chinese Characters",
    "authors" : [ "Falcon Z. Dai", "Zheng Cai" ],
    "emails" : [ "dai@ttic.edu,", "jontsai@ttic.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recently, in combination with deep learning, character-level and subword-unit-level models has achieved the state-of-the-art performance in various natural language processing (NLP) tasks involving Western languages (Wu et al., 2016), we consider the equivalent modeling problem for solving NLP tasks in Chinese. Unlike English script which is alphabetic with a small alphabet, Chinese script is logographic with a large set of characters which are meaningful individually. According to Table of General Standard Characters\n∗These authors contributed equally and their names are randomly ordered.\n(通⽤规范汉字表) compiled by the Chinese government in 2013, there are 3,500 level-1 (being the most common) characters and more than 8,105 characters in total (Wikipedia, 2017). At the same time, it is not correct to treat Chinese characters as equivalent to English words because the distribution of Chinese characters deviate markedly from Zipf’s law (Zipf, 1935; Shtrikman, 1994). Furthermore, there is evidence suggesting that segmented Chinese words, - some of them are unigrams -, distribute according to Zipf’s law (Xiao, 2008). Arguably, the closest equivalent linguistic unit in English corresponding to a Chinese character is a subword unit, i.e., word fragments. Furthermore, there is a strong case for modeling at character-level for task involving Chinese corpora, since Chinese text is usually written without word boundaries to indicate the segmentation of characters into words. As a consequence, wordsegmented corpora is rare. Traditionally, systems are designed to process words as input, so often, a separately trained or hand crafted routine would first segment the contiguous sequence of characters into words as part of the preprocessing. However, this pipeline design might unnecessarily accumulate error due to segmentation ambiguity that can be resolved in a later stage. The trend of endto-end training of differentiable, neural networkbased models also enables training character-level models jointly with the rest of the system under the task objective. It is well-known that many Chinese characters’ written form, their glyphs, share common sub-structures and some of these substructure are informative of the semantics, syntactic role and phonetics of the characters. For example, for semantics,⾬ (rain)雪 (snow)雹 (hail)雷 (thunder) all have a sub-structure ⾬, which commonly denote meteorological phenomena.1 For\n1A sub-structure such as⾬ in雪 is called a radical.\nsyntactic roles, 打 (hit) 提 (lift) 抓 (grab) all contain ⺘ which is indicative of a verb. For phonetics, ⼄ (yǐ) 亿 (yì) 忆 (yì) all share ⼄. However, as far as we are aware of, at the time of our work2, there is no study that explicitly exploits the spatio-structural information of a Chinese character’s glyph for NLP tasks.3 In this work, we explore the effect of incorporating glyphs as additional features in the context of two common Chinese NLP tasks, segmentation and language modeling, resulting in a novel glyph-aware embedding of Chinese characters. This work’s major contributions are\n• a novel character embedding model that explicitly incorporates visual appearance of Chinese characters.\n• new state-of-the-art results on a segmentation benchmark task."
    }, {
      "heading" : "2 Hypotheses",
      "text" : "We hypothesize that the semantic and syntactic information of sub-glyph structures can help improve the character embeddings and thus improve performance in Chinese NLP tasks. Intuitively, representing each character only by their ID’s implies that any pair of characters are as distinct as any other pair. This ignores any common sub-glyph structures shared by characters. Therefore incorporating the glyph’s visual information we should be able to generalize knowledge learned about a character to another via their shared sub-glyph structures. However, this hypothesis is not trivial because there are many Chinese characters that share strikingly similar visual appearances yet not their meanings. For example, ⼟ (soil) ↔ ⼠ (roughly means -er as fighter translates to⽃ (fight)⼠), and ⼈ (person) ↔ ⼊ (enter). By identifying a character with only its visual appearance, we are vulnerable to this new source of ambiguity which can harm performance. Due to this concern, we also include a mixed embedding in our experiments which combine both ID and glyph representation.\n2Since then, we discovered two independent, concurrent studies with approaches similar to ours by Liu et al. (2017) and Costa-jussà et al. (2017).\n3A character’s visual appearance is essential in solving hand-writing recognition tasks which are challenges in computer vision."
    }, {
      "heading" : "3 Method",
      "text" : "In keepingwith the common neural networkmodel architectures, we decided to feed the glyph as an input to a feed-forward neural network (FNN) model, an embedder, that outputs an embedding vector which, in both the segmentation task and the language modeling task, is then consumed by a recurrent neural network to make predictions. In order to compare the proposed glyph-aware embeddings with the glyph-unaware embeddings, we shall keep the recurrent neural network (RNN) architecture fixed and only change the embedder in our experiments. Considering that there are many different layouts for sub-glyph structures4, and the same radical can appear at different positions5, we think the most promising representation that preserves both the identities and the spatial arrangement of substructures is to use the raw pixels of a glyph. Being inspired by the success of convolutional neural networks (CNN) (LeCun et al., 1995) in learning feature representation in computer vision (Krizhevsky et al., 2012), we used CNN to implement the embedder (see Figure 1). We believe that the spatial translational invariance induced by CNN’s filter structure is particularly suited for modeling radicals that can appear at different locations of a glyph. After the CNN, a fully connected layer outputs an embedding vector of some dimension k. To apply our method, we first render the glyph for a character using a font file6 and then feed the glyph as a gray-scale image into the CNN embedder. We implemented our models and experiments efficiently with Tensorflow (Abadi et al., 2016). In particular, we cached rendered glyphs to reduce repeated render calls of the same character by 1,000 times. We open-source our implementation7 for replicability"
    }, {
      "heading" : "4 Results",
      "text" : ""
    }, {
      "heading" : "Chinese language modeling",
      "text" : "Following the common approach in languagemodeling (LM), we model the likelihood of a sentence\n4昌 has a vertical layout, 明, horizontal, and 晶, compound.\n5the radical ⼝ (mouth) can appear on the left 喊, top 员, bottom含, inner向.\n6We used Google’s free Noto font (Google Inc.) throughout this work including the Chinese characters rendered in this paper.\n7http://github.com/falcondai/chinese-char-lm\nas\np(c1, · · · , cn) = p(c1) n∏\ni=2\np(ci|c1, · · · , ci−1)\nwhere ci is the i-th character in a sentence of n characters. The conditional distribution of p(ci|c1, · · · , ci−1) is modeled as a gated recurrent unit (GRU) (Chung et al., 2014) together with an embedder. In all the experiments, we used a GRU with a 128-dimensional hidden state, and 300- dimensional embedding vectors for all embedders. For the CNN embedder, we use a two layer CNN: 32 (7, 7) filters with (2, 2) stride in the first layer, 16 (5, 5) filters (2, 2) stride in the second layer, and a fully-connected layer at the end. For all the layers, we use ReLU non-linearity throughout (Nair and Hinton, 2010). For the linear embedder, we used only one fully-connected layer. For the last row “ID + CNN embedder” in Table. 1, we combine the embedding vectors output by ID and CNN embedders via vector addition. In all the runs, we limited the vocabulary size to 4000 with one unknown class. We experimented with language modeling on the Microsoft Research dataset (MSR) from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005). First, we should note that the CNN embedder outperformed the linear embedder by a largemargin (see the second and the third row in Table. 1. This is expected as the CNN is more suitable for modeling image data. Second,\nthe ID embedder (see the first row in Table. 1) remains a very strong baseline and themixed embedder is only as good as the ID embedder by itself (see the fourth row in Table. 1). It seems that CNN embedder did not provide extra information useful for the task."
    }, {
      "heading" : "Chinese word segmentation",
      "text" : "We use Peking University dataset (PKU) and Microsoft Research dataset (MSR) from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005) to compare the proposedCNN embedder with the ID embedder. We formulated the segmentation task as a structured prediction problem of predicting whether to insert word boundary behind a character for each character given the whole input sentence. An example would be:\n这 是 ⼀句 话 。 1 1 0 1 1 1\nWe experimented with both single-directional GRU and bidirectional long short-term memory (LSTM) recurrent networks (Graves and Schmidhuber, 2005; Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) as the sequence prediction models in our experiments (RNN segmentor). (see Table. 2 and Table. 3). RNN segmentor takes sequence of embeddings from embedder. For the CNN embedder, we used a single layer ReLU-gated CNN: 16 (5,5) filters with (2,2) stride and a fully-connected layer to output a 100- dimensional embedding vector at the end. For the RNN segmentor, the hidden unit is set to be 100 dimensional with a fully-connected layer mapping the output hidden state to a binary prediction at each character. Overall, on both PKU and MSR, the proposed mixed embedder and bidirectional LSTM achieved the best performance outperforming the previous state-of-the-art on by a significant margin. Similar to the LM experiments, we use a vocabulary of 4000 and one unknown class.\nWe use Adam (Kingma and Ba, 2014) optimizer throughout all our experiments."
    }, {
      "heading" : "5 Analysis",
      "text" : "Due to the lack of improvement of the proposed mixed embedder over the ID embedder in the language modeling task, we suspect that the CNN embedder is under-trained. Unlike a digit class in MNIST (LeCun et al., 2010) which has 6,000 training examples, given one font, a character only has one glyph and every sub-glyph structure appears on average in only about 40 characters. Thus we suspect that the variability in input to the CNN is too limited. Modeling after common image augmentation technique (Krizhevsky et al., 2012), we applied random jitters, i.e., 2D translation with ∆x,∆y ∈ {−2,−1, 0,+1,+2}, to the input glyphs at training time. This increases the input variations by 25-fold but the perplexity degrades slightly to 49.66. Since we mix the ID embedding and CNN embedding by summation in the proposed mixed embedder, the norm of each component embedding determines the relative importance of that representation in the resulting embedding. In Figure. 2, we observe that the CNN embeddings distribute differently in the trained segmentation model and the trained language modeling model. In the case of language modeling, the norm of CNN embeddings is squashed suggesting that CNN embedding is largely ignored."
    }, {
      "heading" : "6 Discussion",
      "text" : "It should be noted that the number of parameters of the proposed CNN embedder is different than that of the ID embedder. Suppose the dimensionality of the embedding vectors is K, and the vocabulary size isN , the CNN embedder has O(N +K) many parameters: O(K) many trainable parameters andO(N) glyphs rendered from a font file. In contrast, the ID embedder has O(N K) many parameters, all of which are trainable. This means that the CNN embedder is a more compact representation with competitive performance as the ID embedder."
    }, {
      "heading" : "Related work",
      "text" : "Shi et al. (2015) represented a character by its radicals based on Wubi input method but this ignores the scales and spatial arrangement of each radical\nwhich are present in our rendered glyphs. It came to our late attention that independently, Liu et al. (2017) considered the same characterlevel modeling problem and experimented with vanilla CNNmodels almost identical to ours. They evaluated their method on a new document classification task instead of the commonly considered tasks or benchmarks we considered in this work. Consistent with their findings, we also observed similar effects of CNN embedder, ID embedder and mixed embedder in our tasks. Our mixed embedded corresponds roughly to their early fusion model. Costa-jussà et al. (2017) also considered incorporating Chinese glyphs as additional features in their Chinese-Spanish machine translation system and their modeling approach corresponds roughly to our linear embedder."
    }, {
      "heading" : "Future work",
      "text" : "We hope to delve deeper into the cause of the CNN embedder’s low performance in the LM task. In particular, we want to experiment with using bagof-stroke prediction in a multi-task loss to provide CNN with extra supervision during training. Furthermore, we have only explored two NLP tasks that emphasize semantic and syntactic information in this work. In the future, we hope to explore tasks that requires more phonetic information to do well, such as phoneme prediction."
    }, {
      "heading" : "7 Conclusion",
      "text" : "Our experiments show that glyph-aware embedding can improve performance in some Chinese NLP tasks, in particular, the word segmentation task. Further studies are needed to understand the usefulness of glyph features in a more comprehensive way. However, given the visual ambiguity inherent in Chinese characters and the difficulty to interpret neural network models, any further research that uses glyph features and deep learning methods should exercise caution when measuring and verifying the contribution of the glyph features."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We thank Kevin Gimpel, Matthew Walter and Karen Livescu for their kind support and helpful comments during our investigation. We also thank the anonymous reviewers for their constructive suggestions."
    } ],
    "references" : [ {
      "title" : "Neural word segmentation learning for chinese",
      "author" : [ "Deng Cai", "Hai Zhao." ],
      "venue" : "CoRR.",
      "citeRegEx" : "Cai and Zhao.,? 2016",
      "shortCiteRegEx" : "Cai and Zhao.",
      "year" : 2016
    }, {
      "title" : "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "author" : [ "Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio." ],
      "venue" : "CoRR.",
      "citeRegEx" : "Chung et al\\.,? 2014",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2014
    }, {
      "title" : "Chinese–spanish neural machine translation enhanced with character and word bitmap fonts",
      "author" : [ "Marta R Costa-jussà", "David Aldón", "José AR Fonollosa." ],
      "venue" : "Machine Translation, pages 1–13.",
      "citeRegEx" : "Costa.jussà et al\\.,? 2017",
      "shortCiteRegEx" : "Costa.jussà et al\\.",
      "year" : 2017
    }, {
      "title" : "Second international chinese word segmentation bakeoff",
      "author" : [ "Tom Emerson." ],
      "venue" : "http://sighan.cs. uchicago.edu/bakeoff2005/. Accessed: 201704-15.",
      "citeRegEx" : "Emerson.,? 2005",
      "shortCiteRegEx" : "Emerson.",
      "year" : 2005
    }, {
      "title" : "Framewise phoneme classification with bidirectional lstm and other neural network architectures",
      "author" : [ "Alex Graves", "Jürgen Schmidhuber." ],
      "venue" : "Neural Networks, 18(5):602–610.",
      "citeRegEx" : "Graves and Schmidhuber.,? 2005",
      "shortCiteRegEx" : "Graves and Schmidhuber.",
      "year" : 2005
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba." ],
      "venue" : "CoRR.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "ImageNet Classification with Deep Convolutional Neural Networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton." ],
      "venue" : "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems",
      "citeRegEx" : "Krizhevsky et al\\.,? 2012",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Convolutional networks for images, speech, and time series",
      "author" : [ "Yann LeCun", "Yoshua Bengio" ],
      "venue" : "The handbook of brain theory and neural networks,",
      "citeRegEx" : "LeCun and Bengio,? \\Q1995\\E",
      "shortCiteRegEx" : "LeCun and Bengio",
      "year" : 1995
    }, {
      "title" : "Mnist handwritten digit database",
      "author" : [ "Yann LeCun", "Corinna Cortes", "Christopher JC Burges." ],
      "venue" : "AT&T Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2.",
      "citeRegEx" : "LeCun et al\\.,? 2010",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning Character-level Compositionality with Visual Features",
      "author" : [ "Frederick Liu", "Han Lu", "Chieh Lo", "Graham Neubig." ],
      "venue" : "CoRR. ArXiv: 1704.04859.",
      "citeRegEx" : "Liu et al\\.,? 2017",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2017
    }, {
      "title" : "Rectified linear units improve restricted boltzmann machines",
      "author" : [ "Vinod Nair", "Geoffrey E Hinton." ],
      "venue" : "Proceedings of the 27th international conference on machine learning (ICML-10), pages 807–814.",
      "citeRegEx" : "Nair and Hinton.,? 2010",
      "shortCiteRegEx" : "Nair and Hinton.",
      "year" : 2010
    }, {
      "title" : "Bidirectional recurrent neural networks",
      "author" : [ "Mike Schuster", "Kuldip K Paliwal." ],
      "venue" : "IEEE Transactions on Signal Processing, 45(11):2673–2681.",
      "citeRegEx" : "Schuster and Paliwal.,? 1997",
      "shortCiteRegEx" : "Schuster and Paliwal.",
      "year" : 1997
    }, {
      "title" : "Radical embedding: Delving deeper to chinese radicals",
      "author" : [ "Xinlei Shi", "Junjie Zhai", "Xudong Yang", "Zehua Xie", "Chao Liu." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint",
      "citeRegEx" : "Shi et al\\.,? 2015",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2015
    }, {
      "title" : "Some comments on Zipf’s law for the Chinese language",
      "author" : [ "S. Shtrikman." ],
      "venue" : "Journal of Information Science, 20(2):142–143.",
      "citeRegEx" : "Shtrikman.,? 1994",
      "shortCiteRegEx" : "Shtrikman.",
      "year" : 1994
    }, {
      "title" : "Table of general standard chinese characters—wikipedia, the free encyclopedia",
      "author" : [ "Wikipedia." ],
      "venue" : "[Online; accessed 21-July-2017].",
      "citeRegEx" : "Wikipedia.,? 2017",
      "shortCiteRegEx" : "Wikipedia.",
      "year" : 2017
    }, {
      "title" : "On the Applicability of Zipf’s Law in Chinese Word Frequency Distribution",
      "author" : [ "Hang Xiao." ],
      "venue" : "Journal of Chinese Language and Computing, 18(1):33–46.",
      "citeRegEx" : "Xiao.,? 2008",
      "shortCiteRegEx" : "Xiao.",
      "year" : 2008
    }, {
      "title" : "The psychology of language",
      "author" : [ "George K Zipf." ],
      "venue" : "NY Houghton-Mifflin.",
      "citeRegEx" : "Zipf.,? 1935",
      "shortCiteRegEx" : "Zipf.",
      "year" : 1935
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "the most common) characters and more than 8,105 characters in total (Wikipedia, 2017).",
      "startOffset" : 68,
      "endOffset" : 85
    }, {
      "referenceID" : 17,
      "context" : "At the same time, it is not correct to treat Chinese characters as equivalent to English words because the distribution of Chinese characters deviate markedly from Zipf’s law (Zipf, 1935; Shtrikman, 1994).",
      "startOffset" : 175,
      "endOffset" : 204
    }, {
      "referenceID" : 14,
      "context" : "At the same time, it is not correct to treat Chinese characters as equivalent to English words because the distribution of Chinese characters deviate markedly from Zipf’s law (Zipf, 1935; Shtrikman, 1994).",
      "startOffset" : 175,
      "endOffset" : 204
    }, {
      "referenceID" : 16,
      "context" : "Furthermore, there is evidence suggesting that segmented Chinese words, - some of them are unigrams -, distribute according to Zipf’s law (Xiao, 2008).",
      "startOffset" : 138,
      "endOffset" : 150
    }, {
      "referenceID" : 9,
      "context" : "2Since then, we discovered two independent, concurrent studies with approaches similar to ours by Liu et al. (2017) and Costa-jussà et al.",
      "startOffset" : 98,
      "endOffset" : 116
    }, {
      "referenceID" : 2,
      "context" : "(2017) and Costa-jussà et al. (2017). 3A character’s visual appearance is essential in solving hand-writing recognition tasks which are challenges in computer vision.",
      "startOffset" : 11,
      "endOffset" : 37
    }, {
      "referenceID" : 7,
      "context" : ", 1995) in learning feature representation in computer vision (Krizhevsky et al., 2012), we used CNN to implement the embedder (see Figure 1).",
      "startOffset" : 62,
      "endOffset" : 87
    }, {
      "referenceID" : 1,
      "context" : "The conditional distribution of p(ci|c1, · · · , ci−1) is modeled as a gated recurrent unit (GRU) (Chung et al., 2014) together with an embedder.",
      "startOffset" : 98,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "For all the layers, we use ReLU non-linearity throughout (Nair and Hinton, 2010).",
      "startOffset" : 57,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "We experimented with language modeling on the Microsoft Research dataset (MSR) from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005).",
      "startOffset" : 143,
      "endOffset" : 158
    }, {
      "referenceID" : 3,
      "context" : "We use Peking University dataset (PKU) and Microsoft Research dataset (MSR) from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005) to compare the proposedCNN embedder with the ID embedder.",
      "startOffset" : 140,
      "endOffset" : 155
    }, {
      "referenceID" : 4,
      "context" : "We experimented with both single-directional GRU and bidirectional long short-term memory (LSTM) recurrent networks (Graves and Schmidhuber, 2005; Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) as the sequence pre-",
      "startOffset" : 116,
      "endOffset" : 208
    }, {
      "referenceID" : 5,
      "context" : "We experimented with both single-directional GRU and bidirectional long short-term memory (LSTM) recurrent networks (Graves and Schmidhuber, 2005; Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) as the sequence pre-",
      "startOffset" : 116,
      "endOffset" : 208
    }, {
      "referenceID" : 12,
      "context" : "We experimented with both single-directional GRU and bidirectional long short-term memory (LSTM) recurrent networks (Graves and Schmidhuber, 2005; Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) as the sequence pre-",
      "startOffset" : 116,
      "endOffset" : 208
    }, {
      "referenceID" : 0,
      "context" : "15 NWS (Cai and Zhao, 2016) 95.",
      "startOffset" : 7,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "43 NWS (Cai and Zhao, 2016) 96.",
      "startOffset" : 7,
      "endOffset" : 27
    }, {
      "referenceID" : 6,
      "context" : "We use Adam (Kingma and Ba, 2014) optimizer throughout all our experiments.",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "Unlike a digit class in MNIST (LeCun et al., 2010) which has 6,000 training examples, given one font, a character only has one glyph and every sub-glyph structure appears on average in only about 40 characters.",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 7,
      "context" : "Modeling after common image augmentation technique (Krizhevsky et al., 2012), we applied random jitters, i.",
      "startOffset" : 51,
      "endOffset" : 76
    }, {
      "referenceID" : 10,
      "context" : "It came to our late attention that independently, Liu et al. (2017) considered the same characterlevel modeling problem and experimented with vanilla CNNmodels almost identical to ours.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 2,
      "context" : "Costa-jussà et al. (2017) also considered incorporating Chinese glyphs as additional features in their Chinese-Spanish machine translation system and their modeling approach corresponds roughly to our linear embedder.",
      "startOffset" : 0,
      "endOffset" : 26
    } ],
    "year" : 2017,
    "abstractText" : "Given the advantage and recent success of English character-level and subword-unit models in several NLP tasks, we consider the equivalent modeling problem for Chinese. Chinese script is logographic and many Chinese logograms are composed of common substructures that provide semantic, phonetic and syntactic hints. In this work, we propose to explicitly incorporate the visual appearance of a character’s glyph in its representation, resulting in a novel glyph-aware embedding of Chinese characters. Being inspired by the success of convolutional neural networks in computer vision, we use them to incorporate the spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In the context of two basic Chinese NLP tasks of language modeling and word segmentation, the model learns to represent each character’s task-relevant semantic and syntactic information in the character-level embedding.",
    "creator" : "LaTeX with hyperref package"
  }
}