{
  "name" : "1611.10328.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The observer-assisted method for adjusting hyper-parameters in deep learning algorithms",
    "authors" : [ "Maciej Wielgosza" ],
    "emails" : [ "wielgosz@agh.edu.pl" ],
    "sections" : [ {
      "heading" : null,
      "text" : "This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.\nKeywords: Deep Learning, Hyper-Parameters, Optimization"
    }, {
      "heading" : "1. Introduction",
      "text" : "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1–4]. It is important, because virtually all the currently used algorithms feature macro parameters, which shape their final architecture. This in turn has a direct impact on a performance of solutions based on those algorithms. Unfortunately, despite the fact that deep learning algorithms have been around for a long time, there are no wellestablished procedures for hyper-parameters tuning, such as back-propagation for a model training [5]. Instead, a set of custom techniques, such as grid, random and heuristic search [6, 7], have been developed and used by most of DL systems designers.\nIn the author’s view a process of adjusting hyper-parameters should account for both data and the algorithm. This in turn requires an external agent denoted herein as ‘observer’. Such an observer learns how a given set of hyper-parameters affects a performance of a deep learning algorithm in terms of a chosen quality measurement such as F1 score or accuracy (Fig. 1).\nThe basic idea is to offset a learning process from a complex AI algorithm which is hard to control to a simpler one with easily adjustable set of hyper-parameters [4]. For instance choosing a set of hyper-parameters for Hierarchical Temporal Memory\nEmail address: wielgosz@agh.edu.pl (Maciej Wielgosz)\nPreprint submitted to arXiv December 1, 2016\nar X\niv :1\n61 1.\n10 32\n8v 1\n[ cs\n.L G\n] 3\n0 N\nov 2\n(HTM) [8–10] is very time consuming and demanding process. It can be replaced by using feed-forward neural network to model HTM and predict the right values of hyper-parameters such as number of cells, columns and synapses."
    }, {
      "heading" : "2. Algorithm",
      "text" : "The observer learns a response of a deep learning algorithm for different sets of hyper-parameters in terms of a selected quality measurement score (Fig. 1). Based on this information, it is able to reason about the best set of the hyper-parameters. However, in order to be able to learn a relationship between the hyper-parameters and the performance, a range of experiments with a random set of the parameters must be conducted. The more experiments are done, the more reliable predictions can be made by the observer. It is worth keeping in mind that the observer models the deep learning algorithm. Therefore, a quality of a model used as the observer has a substantial impact on the hyper-parameters being adjusted.\nA key component of the observer algorithm is presented in Fig. 2, where a series of evaluators are shown. Each of the evaluators provides information regarding a value of a selected hyper-parameter and quality score. Taking the evaluators outputs into account, a decision about which hyper-parameter is updated in the next step is made by the updater module. Each evaluator consist of two mappers (Fig. 3). The first mapper, unique for each evaluator, is responsible for hyper-parameter value evaluation. The second one is used to predict quality score for a given set of hyper-parameters. In general, mappers may be implemented as any kind of an algorithm such as CNN, linear or logistic regression [11]. It is worth keeping in mind that a regression algorithm as\nsuch is not as important as its prediction quality. However, poor prediction does not necessarily mean lack of the algorithm convergence."
    }, {
      "heading" : "2.1. Basic algorithm",
      "text" : "The observer-assisted hyper-parameters adjusting algorithm presented in Alg. 1 assumes predefined values of max_iterations, max_idle and min_contribution, as well as expected (target) quality score q_ex. The author of the paper assumed that the threshold can be arbitrarily chosen, but in practice there are probably very few cases when a designer expects quality score q_ex < 1.\nIn the first part of the algorithm, hyper-parameters hp0, hp1, . . . , hpn−1 are initialized with random values from appropriate ranges, iterations counter, idle iterations counter and current quality score value are set to 0. Iterations counter is used to prevent algorithm from running infinitely. Idle iterations counter is used to stop the adjusting process after a certain time when there is no progress.\nThe main work of the algorithm is done inside the while loop. In steps 7 – 9, each mapper evaluates a hyper-parameter value based on the current hyper-parameters set and expected quality score. This results in a creation of an array with the proposed values of all hyper-parameters that can potentially yield better results than current set. In steps 10 – 12 those propositions are evaluated with predicted quality scores stored in q_eval array. After that, a single parameter, for which evaluated quality score was the highest, is chosen as a replacement in the current hyper-parameters set (Alg. 2). If best evaluated quality score is better than previous best one, it is (along with its parameters set) remembered for the future and idle iterations counter is reset. Otherwise, iteration is counted as idle."
    }, {
      "heading" : "2.2. Algorithm with increasing expected quality score (multi-pass approach)",
      "text" : "The proposed Alg. 1 approaches hyper-parameters adjusting problem in a single pass, i.e. it sets the expected quality score to the highest possible value (e.g. q_ex = 1). Another option is to reach target quality score in multiple passes (shown in Alg. 3),\nAlgorithm 1 Basic hyper-parameters adjusting Require: q_ex Ensure: q_best, hp_best\n1: hp← get_random_hyperparams() 2: hp_best ← hp 3: iterations← 0 4: idle← 0 5: q_best ← map_q(hp0, . . . , hpn−1) 6: while q_best < q_ex and idle < max_idle and iterations < max_iterations do 7: for i = 0 to n − 1 do 8: hp_evali ← mapi(hp0, . . . , hpi−1, hpi+1, . . . , hpn−1, q_ex) 9: end for\n10: for i = 0 to n − 1 do 11: q_evali ← map_q(hp0, . . . , hpi−1, hp_evali, hpi+1, . . . , hpn−1) 12: end for 13: idx← get_updated_hyperparam_index(q_eval) 14: hpidx ← hp_evalidx 15: if q_evalidx − q_best > min_contribution then 16: q_best ← q_evalidx 17: hp_best ← hp 18: idle← 0 19: else 20: idle← idle + 1 21: end if 22: iterations← iterations + 1 23: end while\nAlgorithm 2 Basic updated hyper-parameter selection (see Alg. 1 step 13) Require: q_eval Ensure: idx\n1: idx← 0 2: for i = 1 to n − 1 do 3: if q_evalidx < q_evali then 4: idx← i 5: end if 6: end for\nincreasing expected quality score a little with each pass. Such a strategy may lead to a faster algorithm convergence and/or prevent it from being unable to leave a local minimum.\nAlgorithm 3 Multi-pass hyper-parameters adjusting 1: q_ex← q_init 2: stagnation← 0 3: while q_best < q_target and stagnation < max_stagnation do 4: q_best, hp_best ← run_basic_algorithm(q_ex) 5: if q_best < q_ex then 6: stagnation← stagnation + 1 7: else 8: stagnation← 0 9: end if 10: q_step← get_q_step() 11: q_ex← q_ex + q_step 12: end while\nInitially, q_ex = q_init. In the concurrent passes of the algorithm, q_ex value is increased by q_step. There are two strategies of choosing q_step: it may be constant and small throughout all the passes or it may be progressively decreased with a rising number of passes. The decision about starting a new pass depends on the algorithm achieving the previously set expected quality score and whether stagnation counter reached its upper limit."
    }, {
      "heading" : "2.3. Algorithm with a modified updated hyper-parameter selection (cost-based)",
      "text" : "In basic version of the algorithm, selection of the updated hyper-parameter is done using a simple criteria of evaluated quality score comparison, with hyper-parameter yielding the highest quality score being chosen (see Alg. 2). The numerical value of the selection criteria for each hpidx hyper-parameter, henceforth denoted as ‘contribution’, can be expressed as in Eq.1:\ncontributionidx = q_evalidx − q_best (1)\nThis results in contributionidx ∈ [−1, 1], with higher values being desirable. However, a deep-learning algorithm can have a set of hyper-parameters, usually related to the network structure, increase (or decrease) in which incurs a computational cost. Using the above contribution formula could potentially cause a huge increase in the deep-learning algorithm hardware requirements or calculation time for a very small gain in terms of quality score. In such cases, an alternative method of contribution calculation may be employed (Eq. 2).\ncontributionidx = ( q_evalidx − q_best ) ( 1 − θidx(hp_evalidx) ) (2)\nθidx(hp_evalidx) is a cost function, which output depends on the computational cost related to evaluated hyper-parameter value (Eq. 3).\nθidx : hp_evalidx → cost ∧ cost ∈ [0, 1] (3) Exact mapping done by the cost function can depend on factors such as observed deep-learning algorithm, hyper-parameter being adjusted, hardware being used etc. When θidx returns 0, Eq. 2 is equivalent to Eq. 1. As such, Alg. 2 can be replaced with Alg. 4 for all types of hyper-parameters, with appropriate θidx definitions.\nAlgorithm 4 Modified updated hyper-parameter selection Require: q_eval, q_best, hp_eval Ensure: idx\n1: for i = 0 to n − 1 do 2: contributioni = (q_evali − q_best)(1 − θi(hp_evali)) 3: end for 4: idx← 0 5: for i = 1 to n − 1 do 6: if contributionidx < contributioni then 7: idx← i 8: end if 9: end for"
    }, {
      "heading" : "3. Conclusions and Future Work",
      "text" : "This paper introduces a concept of a new method to be used in a demanding and important task of deep learning algorithms hyper-parameters adjusting. The proposed method is based on an external agent denoted as ‘observer’, which learns about an algorithm efficiency in terms of chosen quality score. This allows to model a performance of the algorithm with respect to its hyper-parameters. The author also proposes a method for incorporation of hardware resources consumption in the process of adjusting hyper-parameters. As a future work the author is going to implement the described method and conduct a series of experiments in order to compare its efficiency with other methods [2, 7]."
    } ],
    "references" : [ {
      "title" : "Random search for hyper-parameter optimization",
      "author" : [ "J. Bergstra", "Y. Bengio" ],
      "venue" : "Journal of Machine Learning Research",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2012
    }, {
      "title" : "Hyper-parameter optimization of deep convolutional networks for object recognition",
      "author" : [ "S.S. Talathi" ],
      "venue" : "in: Image Processing (ICIP),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "Practical bayesian optimization of machine learning algorithms",
      "author" : [ "J. Snoek", "H. Larochelle", "R.P. Adams" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Practical recommendations for gradient-based training of deep architectures (Jun",
      "author" : [ "Y. Bengio" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Brief Introduction of Back Propagation (BP) Neural Network Algorithm and Its Improvement",
      "author" : [ "J. Li", "J.-h. Cheng", "J.-y. Shi", "F. Huang" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2012
    }, {
      "title" : "A Framework for Selecting Deep Learning Hyperparameters",
      "author" : [ "J.O. Donoghue", "M. Roantree" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "Optimizing deep learning hyper-parameters through an evolutionary algorithm, in: Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments, MLHPC ’15",
      "author" : [ "S. Young", "D.C. Rose", "T.P. Karnowski", "S.-H. Lim", "R.M. Patton" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2015
    }, {
      "title" : "How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites (jan 2016)",
      "author" : [ "S. Ahmad", "J. Hawkins" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2016
    }, {
      "title" : "Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory (mar",
      "author" : [ "S. Ahmad", "J. Hawkins" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Using Spatial Pooler of Hierarchical Temporal Memory for object classification in noisy video streams",
      "author" : [ "M. Wielgosz", "M. Pietroń", "K. Wiatr" ],
      "venue" : "Proceedings of the 2016 Federated Conference on Computer Science and Information Systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2016
    }, {
      "title" : "Visualizing and Understanding Convolutional Networks, Springer International Publishing",
      "author" : [ "M.D. Zeiler", "R. Fergus" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1–4].",
      "startOffset" : 84,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1–4].",
      "startOffset" : 84,
      "endOffset" : 89
    }, {
      "referenceID" : 2,
      "context" : "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1–4].",
      "startOffset" : 84,
      "endOffset" : 89
    }, {
      "referenceID" : 3,
      "context" : "Hyper-parameters adjusting is a challenging task which was addressed in many papers [1–4].",
      "startOffset" : 84,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "Unfortunately, despite the fact that deep learning algorithms have been around for a long time, there are no wellestablished procedures for hyper-parameters tuning, such as back-propagation for a model training [5].",
      "startOffset" : 211,
      "endOffset" : 214
    }, {
      "referenceID" : 5,
      "context" : "Instead, a set of custom techniques, such as grid, random and heuristic search [6, 7], have been developed and used by most of DL systems designers.",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "Instead, a set of custom techniques, such as grid, random and heuristic search [6, 7], have been developed and used by most of DL systems designers.",
      "startOffset" : 79,
      "endOffset" : 85
    }, {
      "referenceID" : 3,
      "context" : "The basic idea is to offset a learning process from a complex AI algorithm which is hard to control to a simpler one with easily adjustable set of hyper-parameters [4].",
      "startOffset" : 164,
      "endOffset" : 167
    }, {
      "referenceID" : 7,
      "context" : "(HTM) [8–10] is very time consuming and demanding process.",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 8,
      "context" : "(HTM) [8–10] is very time consuming and demanding process.",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 9,
      "context" : "(HTM) [8–10] is very time consuming and demanding process.",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 10,
      "context" : "In general, mappers may be implemented as any kind of an algorithm such as CNN, linear or logistic regression [11].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : ", hp_bestn−1 evaluated hyper-parameters yielding best quality score during algorithm lifetime q_ex expected quality score; q_ex ∈ [0, 1] q_eval0, q_eval1, .",
      "startOffset" : 130,
      "endOffset" : 136
    }, {
      "referenceID" : 0,
      "context" : ", q_evaln−1 evaluated quality scores; q_evalidx ∈ [0, 1]",
      "startOffset" : 50,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "q_best best evaluated quality score during algorithm lifetime; q_best ∈ [0, 1]",
      "startOffset" : 72,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : "θidx : hp_evalidx → cost ∧ cost ∈ [0, 1] (3) Exact mapping done by the cost function can depend on factors such as observed deep-learning algorithm, hyper-parameter being adjusted, hardware being used etc.",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 1,
      "context" : "As a future work the author is going to implement the described method and conduct a series of experiments in order to compare its efficiency with other methods [2, 7].",
      "startOffset" : 161,
      "endOffset" : 167
    }, {
      "referenceID" : 6,
      "context" : "As a future work the author is going to implement the described method and conduct a series of experiments in order to compare its efficiency with other methods [2, 7].",
      "startOffset" : 161,
      "endOffset" : 167
    } ],
    "year" : 2016,
    "abstractText" : "This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.",
    "creator" : "LaTeX with hyperref package"
  }
}