{
  "name" : "1505.03823.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Distant Supervision for Entity Linking",
    "authors" : [ "Miao Fan", "Qiang Zhou", "Thomas Fang Zheng" ],
    "emails" : [ "fanmiao.cslt.thu@gmail.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "To build the “Digital Alexandria Library” for our human race, researchers in the NLP community have dedicated themselves to Information Extraction (Sarawagi, 2008) over the past decades. Information extraction focuses on processing natural language text to produce structured knowledge, which is usually represented as triples (two entities\nand their relation) for the convenience of storage in a database, retrieval, or even automatic reasoning. For example, if we send a natural language sentence, Michael Jordan visited CMU yesterday, to the pipeline of information extraction machine, it will be processed by three operations in advance, i.e.,\n• Named Entity Recognition (Nadeau and Sekine, 2007): Entities should firstly be identified and classified into predefined categories, such as person (PER), location (LOC) and organization (ORG). The sentence will be annotated as [Michael Jordan]/PER visited [CMU]/ORG yesterday, after being processed by this operation.\n• Coreference Resolution (Ng, 2010): Some entities may have alias or abbreviations. It is well known that CMU is the abbreviation for Carnegie Mellon University. The knowledge repository may only store the regularized name, e.g., Carnegie Mellon University, for this named entity, so coreference resolution is indeed necessary.\n• Relation Extraction (Bach and Badaskar, 2007): After both of the named entities ([Michael Jordan]/PER and [Carnegie Mellon University]/ORG) are recognized and regularized, we begin to study on the relation between them. In this case, we extract the verb visited and map it to the relation visit. Then the output will be a triple, i.e., (Michael Jordan [PER], visit, Carnegie Mellon University [ORG]).\nSo far, we only abstract the triple as the structured knowledge from the natural language sentence. However, it devotes nothing to increasing the scale of the knowledge repository such as Free-\nar X\niv :1\n50 5.\n03 82\n3v 3\n[ cs\n.C L\n] 5\nA ug\n2 01\n5\nbase (Bollacker et al., 2007) which is a huge1, public2, collaborative3(Bollacker et al., 2008) and online knowledge base with billions of triples and millions of disambiguated entities, and is primarily maintained by Google Inc., because we even do not know which exact Michael Jordan the triple (Michael Jordan [PER], visit, Carnegie Mellon University [ORG]) refers to in Freebase. As illustrated in Figure 1, there are three different persons named Michael Jordan in Freebase and each of them may be the protagonist of that news. Therefore, to populate knowledge repositories (Ji and Grishman, 2011), we need the fourth operation:\n• Entity Linking (Rao et al., 2013): It concerns about the study of aligning a textual entity mention to the corresponding disambiguated entry in a knowledge repository. More specifically, since there are several Michael Jordan disambiguated by different MIDs (machine identifiers) as illustrated in Figure 1, we may build a classifier that can help assign the Michael Jordan in the extracted triplet (Michael Jordan [PER], visit, Carnegie Mellon University [ORG]) to the exact named entity in Freebase or find out that this Michael Jordan is a newly discovered named entity (NIL).\nHachey et al. (2013) and Rao et al. (2013) elucidate that most of the literatures (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al., 2010) concentrate on linking ambiguous entities to the entries in Wikipedia, whereas our ultimate goal is to populate the structured knowledge repository, e.g., Freebase. However, to the best of our knowledge, few works (Zheng et al., 2012) concern about disambiguating named entities using Freebase which contains much more entries but less text information for each entry than Wikipedia.\n1According to the statistics released on 10th March, 2014 by Google Inc., there are about 1.9 billion Freebase triples and 43 million entities.\n2The whole dump of Freebase can be downloaded from https://developers.google.com/freebase/ data\n3One can access to Freebase and contribute more knowledge.\n4http://www.nist.gov/tac/2013/KBP/ EntityLinking/index.html\nOverall, Hachey et al. (2013) and Zheng et al. (2012) represent two research directions leveraging Wikipedia and Freebase, respectively. As both of the two collaborative web resources have their respective superiorities, i.e., more context information and more disambiguated entities, we begin to study a new paradigm that could bridge the gap between those two separated repositories and benefit from their respective advantages. From the perspective of supervised learning, entity linking can be naturally regarded as a classification problem. To build a training dataset for disambiguating a set of entities with the same name, we can firstly collect the sentences that mention that name from webpages, such as Wiki pages5, and then manually annotate each entity mention with its unique machine identifier (MID) in Freebase given the contexts of sentences that it occurs in. However, hand-labeled data is time consuming and usually applicable to some specific classes of entities, such as person (PER), location (LOC) and organization (ORG). Therefore, we look forward to an approach that averts the tedious and laborious work.\nInspired by the idea of weak labeling (Fan et al., 2014; Craven et al., 1999), we contribute a new paradigm called distantly supervised entity linking (DSEL) without manual annotation in this paper. More specifically, we take advantage of a heuristic alignment assumption based on crowd sourcing to connect a certain disambiguated entity in Freebase with its related webpages. In these webpages, feature vectors can be extracted from the\n5The Wiki page for the famous basketball player, Michael Jordan, is http://en.wikipedia.org/wiki/ Michael_jordan.\nsentence-level textual contexts of that entity mention, and be labeled by its corresponding MID in Freebase. Then we can produce a large scale of weakly labeled6 dataset in this way. Moreover, it is unrealistic to learn a specific classifier for each entity, as there are about 43 million disambiguated entities in Freebase. To tackle with those challenges, we propose a strategy of training a general classifier for disambiguating multiple entities and select a well known classifier, i.e., liblinear (Fan et al., 2008) to self-learn the weights among the high-dimensional sparse and noisy features. Experiments are conducted on a dataset of 140,000 items and 60,000 features. DSEL achieves a baseline F1-measure of 0.517. Furthermore, we analyze the performance influenced by other different features, and finally the F1-measure is improved to 0.545."
    }, {
      "heading" : "2 Paradigm",
      "text" : "Traditional supervised learning methods for entity disambiguation require tedious labor on manual annotation to build training datasets. Manual annotation costs a lot, and can only cover some specific category, e.g., person names (Christen, 2006) as well. Therefore, we look forward to exploring a paradigm that could automatically generate large scale of open-category training datasets without manual annotation. Based on the dataset, we aim to build a practical classifier and generalize it to disambiguate more unlinked entity mentions in free texts.\nFreebase contains 43 million disambiguated entities falling into 76 categories. Each entity is assigned by a unique machine identifer (MID). Those MIDs are the natural labels for the newly identified entity mentions linking to. However,\n6Auto-labeling via crowd sourcing may naturally bring about noise. Therefore, we regard the dataset weakly labeled.\nthere are inadequate free texts locally for extracting features, as Freebase is a well-structured knowledge repository with billions of triples. Therefore, we resort to other free-text corpus that could be distantly supervised by Freebase and the key challenge is to find the bridge of supervision.\nFortunately, every entity in Freebase maintains a list of links to its topic equivalent webpages via crowd sourcing (Howe, 2006) as shown in Figure 2. These links will guide us to find the description webpages for that entity. Even though those links involves in different languages, we only choose the English Wiki pages to conduct experiments. Overall, we jointly exploit Freebase and Wikipedia to automatically construct the data for training a classifier."
    }, {
      "heading" : "3 Feature",
      "text" : "For each entity in Freebase, we find its topicequivalent Wiki page and extract the contextual features of its mention at sentence level.\nGenerally, we simultaneously choose K (K = 1, 2, 3) open-class words (Van Petten and Kutas, 1991), namely nouns, verbs, adjectives and adverbs, in front and behind the given entity mention. If we ignore the sequence of these words, we can gain the bag-of-words feature, whereas the word sequence feature. Furthermore, we use Stanford NLP core7 and add the part-of-speech tagging feature which may help disambiguate those contextual words. Therefore, for each K size window surrounding the entity mention, we could extract four kinds of different features, i.e., bag of words (BOW), word sequence (WS), bag of words plus part-of-speech tagging (BOW + POS) and word sequence plus part-of-speech tagging (WS + POS). In total, there are twelve kinds of lexical features.\nTo elucidate the various kinds of contextual features, we randomly pick up a sentence from the Wiki page of the famous basketball player as example, i.e.,\nHis biography on the National Basketball Association (NBA) website states, “By acclamation, Michael Jordan is the greatest basketball player of all time.”\nThe twelve kinds of lexical features for the sentence above are listed in Table 1. We will compare the performance among these features in Section\n7http://nlp.stanford.edu/software/ corenlp.shtml\n5."
    }, {
      "heading" : "4 Implementation",
      "text" : "As we have already automatically produced a training dataset based on the proposed distant supervision paradigm, an intuitive idea is to feed a specific classifier for each ambiguous name with its unambiguous MIDs and the corresponding feature vectors. However, Table 2 shows that there are at least 5.5 million names that denominate more than one entity (MID) in Freebase. Therefore, it is infeasible to build 5.5 million specific classifiers. To train a general classifier that does not restrict itself to disambiguating a certain name, we adopt a strategy that merges those specific classifiers. Concretely, we transform MIDs, the original labels into features and use 1/0 to indicate whether the contextual features from Wiki pages and MIDs in Freebase match or not with each other. If we choose the BOW (K = 3) feature in Table 1 for instance, one positive training sample will contain a new feature vector (<{website}, {states}, {acclamation}, {is}, {greatest}, {basketball}, {MID:054c1}>) labeled by 1. To balance the training dataset, we randomly pick up features from other entities uniformly named to generate negative samples. For example, another well-known Michael Jordan (MID:0bby3vs) is an English mycologist. We can extract a BOW (K = 3) feature vector, i.e., <{is}, {English}, {mycologist}> , and it concatenates {MID:054c1} to construct a negative sample labeled by 0.\nThe distant supervision paradigm and the strategy of building the training set for a general classifier lead to high-dimensional noisy and sparse features. Moreover, given the millions of training samples produced by aligning Freebase and Wikipedia, we choose a linear classifier that is based on logistic regression approach, i.e., Liblinear (Fan et al., 2008), to rapidly self-learn the weights among the high-dimensional sparse and noisy features.\nFor a newly discovered entity mention in the testing corpus, we firstly extract its contextual feature, e.g., bag of words as above. Then the feature concatenates all the candidate MIDs that share the same name with that entity mention. Each testing sample within the same name collection will predict a score indicating the strength of linking. For each collection, the Top-N predictions with higher\nprobabilities are selected for evaluation. We summarize the procedures of implementing our proposed paradigm and use Figure 3 to demonstrate the architecture of DSEL system."
    }, {
      "heading" : "5 Experiments",
      "text" : "In this section ,we report the experimental results following the procedures described in Section 4. To evaluate the performance of different features, we adopt three widely used metrics (Meij et al., 2013), namely precision, recall and F1-measure."
    }, {
      "heading" : "5.1 Dataset",
      "text" : "We randomly select 20,000 ambiguous names (collections) in Freebase. About 82,000 sentences that contain at least one entity mention are extracted from the topic-equivalent Wiki pages. For each collection, 80% sentences are randomly picked up for constructing the training set and 20% remains are for held-out evaluation. Following the procedures of building training samples described in Section 4, we gain a dataset including around 140,000 items and 60,000 features."
    }, {
      "heading" : "5.2 Evaluation metrics",
      "text" : "Precision and recall are widely used metrics to evaluate different rank-based approaches on entity linking. F1-measure synthetically measures precision and recall by calculating the harmonic mean of them. Suppose that C denotes the whole collection set for testing. Ci,j represents the set of Top-j predictions with higher probabilities in the i-th collection. Gi stands for the set of gold standards of the i-th collection. #(S) is the function that counts the entries in set S. Then the formulae to calculate precision, recall and F1-measure are as follows,\nPrecision = ∑ i ∑ j #(Ci,j ∧ Gi) #(Ci,j) ,\nRecall = ∑ i ∑ j #(Ci,j ∧ Gi) #(C) ,\nF1-measure = 2× Precision×Recall Precision+Recall ."
    }, {
      "heading" : "5.3 Feature comparison",
      "text" : "For each type of feature, we conduct one trial and tune the parameters for the logistic classifier using\n5-fold cross validation. Then we adopt held-out testing taking advantage of the 20% sentences left.\nFigure 4 and Figure 5 show the precision-recall curves for the twelve lexical features, and Table 3 displays the average F1-measure comparison among different features. We find out that the WS-class features generally outperform the BOWclass features, and the short-distance contextual features (K = 1) are more effective than the longdistance ones (K = 2, 3)."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "As far as we know, it is the first attempt to deal with the task of entity linking based on the idea of distant supervision. We leverage a heuristic alignment assumption, i.e., the topic equivalent pages, to bridge the gap between Freebase and Wikipedia and jointly use those two knowledge bases to automatically produce training data without manual annotation. Moreover, we propose a strategy that transforms labels into features and feed them to a general classifier, rather than building an individualized classifier for each ambiguous name for millions of entities.\nFor the future work, we believe that this new paradigm leaves several open questions:\n• Besides the entities (MIDs) that have already been stored in knowledge repositories (Freebase), new entity instances (NIL) with the same name need to be discovered. Therefore, further study could focus on extending paradigm to identify unknown entities.\n• The link for many other webpages in different languages are also provided in Freebase, as illustrated in Figure 2. It may facilitate the research of cross-lingual entity linking.\n• The alignment assumption is simple and heuristic. Further studies may dedicate on discovering other reasonable alignment principles.\n• Even though the strategy for generating training data that fits a general classifier, it rises the problem that high-dimensional sparse and noisy features impact the effectiveness and efficiency of the proposed paradigm.\nGenerally speaking, the experiments prove that our new proposed paradigm is promising and it is worthy of being further studied."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work is mainly supported by National Program on Key Basic Research Project (973 Program) under Grant 2013CB329304, National Science Foundation of China (NSFC) under Grant No. 61373075. Thanks to Yulong Gu, Yingnan Xiao and anonymous reviewers for their insightful comments."
    } ],
    "references" : [ {
      "title" : "Freebase: A shared database of structured general human knowledge",
      "author" : [ "Robert Cook", "Patrick Tufts" ],
      "venue" : "In Proceedings of the national conference on Artificial Intelligence,",
      "citeRegEx" : "Bollacker et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Bollacker et al\\.",
      "year" : 2007
    }, {
      "title" : "Freebase: a collaboratively created graph database for structuring human knowledge",
      "author" : [ "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor" ],
      "venue" : "In Proceedings of the 2008 ACM SIGMOD international",
      "citeRegEx" : "Bollacker et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Bollacker et al\\.",
      "year" : 2008
    }, {
      "title" : "Using encyclopedic knowledge for named entity disambiguation",
      "author" : [ "Bunescu", "Pasca2006] Razvan C Bunescu", "Marius Pasca" ],
      "venue" : "In EACL,",
      "citeRegEx" : "Bunescu et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bunescu et al\\.",
      "year" : 2006
    }, {
      "title" : "A comparison of personal name matching: Techniques and practical issues",
      "author" : [ "Peter Christen" ],
      "venue" : "In Data Mining Workshops,",
      "citeRegEx" : "Christen.,? \\Q2006\\E",
      "shortCiteRegEx" : "Christen.",
      "year" : 2006
    }, {
      "title" : "Constructing biological knowledge bases by extracting information from text sources",
      "author" : [ "Craven et al.1999] Mark Craven", "Johan Kumlien" ],
      "venue" : "In ISMB,",
      "citeRegEx" : "Craven and Kumlien,? \\Q1999\\E",
      "shortCiteRegEx" : "Craven and Kumlien",
      "year" : 1999
    }, {
      "title" : "Large-scale named entity disambiguation based on wikipedia data",
      "author" : [ "Silviu Cucerzan" ],
      "venue" : "In EMNLP-CoNLL,",
      "citeRegEx" : "Cucerzan.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cucerzan.",
      "year" : 2007
    }, {
      "title" : "Liblinear: A library for large linear classification",
      "author" : [ "Fan et al.2008] Rong-En Fan", "Kai-Wei Chang", "ChoJui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Fan et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2008
    }, {
      "title" : "Distant supervision for relation extraction with matrix completion",
      "author" : [ "Fan et al.2014] Miao Fan", "Deli Zhao", "Qiang Zhou", "Zhiyuan Liu", "Thomas Fang Zheng", "Edward Y Chang" ],
      "venue" : "In Proceedings of the 52nd Annual Meeting of the Association",
      "citeRegEx" : "Fan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2014
    }, {
      "title" : "Evaluating entity linking with wikipedia",
      "author" : [ "Hachey et al.2013] Ben Hachey", "Will Radford", "Joel Nothman", "Matthew Honnibal", "James R Curran" ],
      "venue" : "Artificial intelligence,",
      "citeRegEx" : "Hachey et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Hachey et al\\.",
      "year" : 2013
    }, {
      "title" : "The rise of crowdsourcing",
      "author" : [ "Jeff Howe" ],
      "venue" : "Wired magazine,",
      "citeRegEx" : "Howe.,? \\Q2006\\E",
      "shortCiteRegEx" : "Howe.",
      "year" : 2006
    }, {
      "title" : "Knowledge base population: Successful approaches and challenges",
      "author" : [ "Ji", "Grishman2011] Heng Ji", "Ralph Grishman" ],
      "venue" : "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-",
      "citeRegEx" : "Ji et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2011
    }, {
      "title" : "Overview of the tac 2010 knowledge base population track",
      "author" : [ "Ji et al.2010] Heng Ji", "Ralph Grishman", "Hoa Trang Dang", "Kira Griffitt", "Joe Ellis" ],
      "venue" : "In Third Text Analysis Conference (TAC",
      "citeRegEx" : "Ji et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2010
    }, {
      "title" : "Overview of the tac 2009 knowledge base population track",
      "author" : [ "McNamee", "Dang2009] Paul McNamee", "Hoa Trang Dang" ],
      "venue" : "In Text Analysis Conference (TAC),",
      "citeRegEx" : "McNamee et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "McNamee et al\\.",
      "year" : 2009
    }, {
      "title" : "Entity linking and retrieval",
      "author" : [ "Meij et al.2013] Edgar Meij", "Krisztian Balog", "Daan Odijk" ],
      "venue" : "In Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval,",
      "citeRegEx" : "Meij et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Meij et al\\.",
      "year" : 2013
    }, {
      "title" : "Wikify!: linking documents to encyclopedic knowledge",
      "author" : [ "Mihalcea", "Csomai2007] Rada Mihalcea", "Andras Csomai" ],
      "venue" : "In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,",
      "citeRegEx" : "Mihalcea et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Mihalcea et al\\.",
      "year" : 2007
    }, {
      "title" : "Learning to link with wikipedia",
      "author" : [ "Milne", "Witten2008] David Milne", "Ian H Witten" ],
      "venue" : "In Proceedings of the 17th ACM conference on Information and knowledge management,",
      "citeRegEx" : "Milne et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Milne et al\\.",
      "year" : 2008
    }, {
      "title" : "A survey of named entity recognition and classification",
      "author" : [ "Nadeau", "Sekine2007] David Nadeau", "Satoshi Sekine" ],
      "venue" : "Lingvisticae Investigationes,",
      "citeRegEx" : "Nadeau et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Nadeau et al\\.",
      "year" : 2007
    }, {
      "title" : "Supervised noun phrase coreference research: The first fifteen years",
      "author" : [ "Vincent Ng" ],
      "venue" : "In Proceedings of the 48th annual meeting of the association for computational linguistics,",
      "citeRegEx" : "Ng.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ng.",
      "year" : 2010
    }, {
      "title" : "Entity linking: Finding extracted entities in a knowledge base. In Multi-source, multilingual information extraction and summarization",
      "author" : [ "Rao et al.2013] Delip Rao", "Paul McNamee", "Mark Dredze" ],
      "venue" : null,
      "citeRegEx" : "Rao et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Rao et al\\.",
      "year" : 2013
    }, {
      "title" : "Local and global algorithms for disambiguation to wikipedia",
      "author" : [ "Ratinov et al.2011] Lev Ratinov", "Dan Roth", "Doug Downey", "Mike Anderson" ],
      "venue" : "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:",
      "citeRegEx" : "Ratinov et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ratinov et al\\.",
      "year" : 2011
    }, {
      "title" : "Influences of semantic and syntactic context on open-and closed-class words",
      "author" : [ "Van Petten", "Kutas1991] Cyma Van Petten", "Marta Kutas" ],
      "venue" : "Memory & Cognition,",
      "citeRegEx" : "Petten et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Petten et al\\.",
      "year" : 1991
    }, {
      "title" : "Entity disambiguation with freebase",
      "author" : [ "Zheng et al.2012] Zhicheng Zheng", "Xiance Si", "Fangtao Li", "Edward Y Chang", "Xiaoyan Zhu" ],
      "venue" : "In Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intel-",
      "citeRegEx" : "Zheng et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "• Coreference Resolution (Ng, 2010): Some entities may have alias or abbreviations.",
      "startOffset" : 25,
      "endOffset" : 35
    }, {
      "referenceID" : 0,
      "context" : "base (Bollacker et al., 2007) which is a huge1, public2, collaborative3(Bollacker et al.",
      "startOffset" : 5,
      "endOffset" : 29
    }, {
      "referenceID" : 1,
      "context" : ", 2007) which is a huge1, public2, collaborative3(Bollacker et al., 2008) and online knowledge base with billions of triples and millions of disambiguated entities, and is primarily maintained by Google Inc.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 18,
      "context" : "• Entity Linking (Rao et al., 2013): It concerns about the study of aligning a textual entity mention to the corresponding disambiguated entry in a knowledge repository.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 5,
      "context" : "(2013) elucidate that most of the literatures (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al.",
      "startOffset" : 46,
      "endOffset" : 160
    }, {
      "referenceID" : 19,
      "context" : "(2013) elucidate that most of the literatures (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al.",
      "startOffset" : 46,
      "endOffset" : 160
    }, {
      "referenceID" : 11,
      "context" : ", 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al., 2010) concentrate on linking ambiguous entities to the entries in Wikipedia, whereas our ultimate goal is to populate the structured knowledge repository, e.",
      "startOffset" : 50,
      "endOffset" : 91
    }, {
      "referenceID" : 21,
      "context" : "However, to the best of our knowledge, few works (Zheng et al., 2012) concern about disambiguating named entities using Freebase which contains much more entries but less text information for each entry than Wikipedia.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "Overall, Hachey et al. (2013) and Zheng et al.",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "Overall, Hachey et al. (2013) and Zheng et al. (2012) represent two research directions leveraging Wikipedia and Freebase, respectively.",
      "startOffset" : 9,
      "endOffset" : 54
    }, {
      "referenceID" : 7,
      "context" : "Inspired by the idea of weak labeling (Fan et al., 2014; Craven et al., 1999), we contribute a new paradigm called distantly supervised entity linking (DSEL) without manual annotation in this paper.",
      "startOffset" : 38,
      "endOffset" : 77
    }, {
      "referenceID" : 6,
      "context" : ", liblinear (Fan et al., 2008) to self-learn the weights among the high-dimensional sparse and noisy features.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : ", person names (Christen, 2006) as well.",
      "startOffset" : 15,
      "endOffset" : 31
    }, {
      "referenceID" : 9,
      "context" : "Fortunately, every entity in Freebase maintains a list of links to its topic equivalent webpages via crowd sourcing (Howe, 2006) as shown in Figure 2.",
      "startOffset" : 116,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : ", Liblinear (Fan et al., 2008), to rapidly self-learn the weights among the high-dimensional sparse and noisy features.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 13,
      "context" : "To evaluate the performance of different features, we adopt three widely used metrics (Meij et al., 2013), namely precision, recall and F1-measure.",
      "startOffset" : 86,
      "endOffset" : 105
    } ],
    "year" : 2015,
    "abstractText" : "Entity linking is an indispensable operation of populating knowledge repositories for information extraction. It studies on aligning a textual entity mention to its corresponding disambiguated entry in a knowledge repository. In this paper, we propose a new paradigm named distantly supervised entity linking (DSEL), in the sense that the disambiguated entities that belong to a huge knowledge repository (Freebase) are automatically aligned to the corresponding descriptive webpages (Wiki pages). In this way, a large scale of weakly labeled data can be generated without manual annotation and fed to a classifier for linking more newly discovered entities. Compared with traditional paradigms based on solo knowledge base, DSEL benefits more via jointly leveraging the respective advantages of Freebase and Wikipedia. Specifically, the proposed paradigm facilitates bridging the disambiguated labels (Freebase) of entities and their textual descriptions (Wikipedia) for Web-scale entities. Experiments conducted on a dataset of 140,000 items and 60,000 features achieve a baseline F1measure of 0.517. Furthermore, we analyze the feature performance and improve the F1-measure to 0.545.",
    "creator" : "LaTeX with hyperref package"
  }
}