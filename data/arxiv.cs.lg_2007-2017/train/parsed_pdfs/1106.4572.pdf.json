{
  "name" : "1106.4572.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Specific-to-General Learning for Temporal Events with Application to Learning Event Definitions from Video",
    "authors" : [ "Alan Fern", "Robert Givan", "Jeffrey Mark Siskind" ],
    "emails" : [ "AFERN@PURDUE.EDU", "GIVAN@PURDUE.EDU", "QOBI@PURDUE.EDU" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ple temporal logic and use the resulting algorithm to learn visual event definitions from video sequences. First, we introduce a simple, propositional, temporal, event-description language called AMA that is sufficiently expressive to represent many events yet sufficiently restrictive to support learning. We then give algorithms, along with lower and upper complexity bounds, for the subsumption and generalization problems for AMA formulas. We present a positive-examples–only specific-to-general learning method based on these algorithms. We also present a polynomialtime–computable “syntactic” subsumption test that implies semantic subsumption without being equivalent to it. A generalization algorithm based on syntactic subsumption can be used in place of semantic generalization to improve the asymptotic complexity of the resulting learning algorithm. Finally, we apply this algorithm to the task of learning relational event definitions from video and show that it yields definitions that are competitive with hand-coded ones."
    }, {
      "heading" : "1. Introduction",
      "text" : "Humans conceptualize the world in terms of objects and events. This is reflected in the fact that we talk about the world using nouns and verbs. We perceive events taking place between objects, we interact with the world by performing events on objects, and we reason about the effects that actual and hypothetical events performed by us and others have on objects. We also learn new object and event types from novel experience. In this paper, we present and evaluate novel implemented techniques that allow a computer to learn new event types from examples. We show results from an application of these techniques to learning new event types from automatically constructed relational, force-dynamic descriptions of video sequences.\nWe wish the acquired knowledge of event types to support multiple modalities. Humans can observe someone faxing a letter for the first time and quickly be able to recognize future occurrences of faxing, perform faxing, and reason about faxing. It thus appears likely that humans use and learn event representations that are sufficiently general to support fast and efficient use in multiple modalities. A long-term goal of our research is to allow similar cross-modal learning and use of event representations. We intend the same learned representations to be used for vision (as described in this paper), planning (something that we are beginning to investigate), and robotics (something left to the future).\nA crucial requirement for event representations is that they capture the invariants of an event type. Humans classify both picking up a cup off a table and picking up a dumbbell off the floor as picking up. This suggests that human event representations are relational. We have an abstract\nc 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nFERN, GIVAN, & SISKIND\nrelational notion of picking up that is parameterized by the participant objects rather than distinct propositional notions instantiated for specific objects. Humans also classify an event as picking up no matter whether the hand is moving slowly or quickly, horizontally or vertically, leftward or rightward, or along a straight path or circuitous one. It appears that it is not the characteristics of participant-object motion that distinguish picking up from other event types. Rather, it is the fact that the object being picked up changes from being supported by resting on its initial location to being supported by being grasped by the agent. This suggests that the primitive relations used to build event representations are force dynamic (Talmy, 1988).\nAnother desirable property of event representations is that they be perspicuous. Humans can introspect and describe the defining characteristics of event types. Such introspection is what allows us to create dictionaries. To support such introspection, we prefer a representation language that allows such characteristics to be explicitly manifest in event definitions and not emergent consequences of distributed parameters as in neural networks or hidden Markov models.\nWe develop a supervised learner for an event representation possessing these desired characteristics as follows. First, we present a simple, propositional, temporal logic called AMA that is a sublanguage of a variety of familiar temporal languages (e.g. linear temporal logic, or LTL Bacchus & Kabanza, 2000, event logic Siskind, 2001). This logic is expressive enough to describe a variety of interesting temporal events, but restrictive enough to support an effective learner, as we demonstrate below. We proceed to develop a specific-to-general learner for the AMA logic by giving algorithms and complexity bounds for the subsumption and generalization problems involving AMA formulas. While we show that semantic subsumption is intractable, we provide a weaker syntactic notion of subsumption that implies semantic subsumption but can be checked in polynomial time. Our implemented learner is based upon this syntactic subsumption.\nWe next show means to adapt this (propositional) AMA learner to learn relational concepts. We evaluate the resulting relational learner in a complete system for learning force-dynamic event definitions from positive-only training examples given as real video sequences. This is not the first system to perform visual-event recognition from video. We review prior work and compare it to the current work later in the paper. In fact, two such prior systems have been built by one of the authors. HOWARD (Siskind & Morris, 1996) learns to classify events from video using temporal, relational representations. But these representations are not force dynamic. LEONARD (Siskind, 2001) classifies events from video using temporal, relational, force-dynamic representations but does not learn these representations. It uses a library of hand-code representations. This work adds a learning component to LEONARD, essentially duplicating the performance of the hand-coded definitions automatically.\nWhile we have demonstrated the utility of our learner in the visual-event–learning domain, we note that there are many domains where interesting concepts take the form of structured temporal sequences of events. In machine planning, macro-actions represent useful temporal patterns of action. In computer security, typical application behavior, represented perhaps as temporal patterns of system calls, must be differentiated from compromised application behavior (and likewise authorized-user behavior from intrusive behavior).\nIn what follows, Section 2 introduces our application domain of recognizing visual events and provides an informal description of our system for learning event definitions from video. Section 3 introduces the AMA language, syntax and semantics, and several concepts needed in our analysis of the language. Section 4 develops and analyzes algorithms for the subsumption and generalization problems in the language, and introduces the more practical notion of syntactic subsumption. Sec-\nLEARNING TEMPORAL EVENTS\ntion 5 extends the basic propositional learner to handle relational data and negation, and to control exponential run-time growth. Section 6 presents our results on visual-event learning. Sections 7 and 8 compare to related work and conclude."
    }, {
      "heading" : "2. System Overview",
      "text" : "This section provides an overview of our system for learning to recognize visual events from video. The aim is to provide an intuitive picture of our system before providing technical details. A formal presentation of our event-description language, algorithms, and both theoretical and empirical results appears in Sections 3–6. We first introduce the application domain of visual-event recognition and the LEONARD system, the event recognizer upon which our learner is built. Second, we describe how our positive-only learner fits into the overall system. Third, we informally introduce the AMA event-description language that is used by our learner. Finally, we give an informal presentation of the learning algorithm."
    }, {
      "heading" : "2.1 Recognizing Visual Events",
      "text" : "LEONARD (Siskind, 2001) is a system for recognizing visual events from video camera input— an example of a simple visual event is “a hand picking up a block.” This research was originally motivated by the problem of adding a learning component to LEONARD—allowing LEONARD to learn to recognize an event by viewing example events of the same type. Below, we give a high-level description of the LEONARD system.\nLEONARD is a three-stage pipeline depicted in Figure 1. The raw input consists of a video-frame image sequence depicting events. First, a segmentation-and-tracking component transforms this input into a polygon movie: a sequence of frames, each frame being a set of convex polygons placed around the tracked objects in the video. Figure 2a shows a partial video sequence of a pick up event that is overlaid with the corresponding polygon movie. Next, a model-reconstruction component transforms the polygon movie into a force-dynamic model. This model describes the changing support, contact, and attachment relations between the tracked objects over time. Constructing this model is a somewhat involved process as described in Siskind (2000). Figure 2b shows a visual depiction of the force-dynamic model corresponding to the pick up event. Finally, an eventrecognition component armed with a library of event definitions determines which events occurred in the model and, accordingly, in the video. Figure 2c shows the text output and input of the event-recognizer for the pick up event. The first line corresponds to the output which indicates the interval(s) during which a pick up occurred. The remaining lines are the text encoding of the event-recognizer input (model-reconstruction output), indicating the time intervals in which various force-dynamic relations are true in the video.\nThe event-recognition component of LEONARD represents event types with event-logic formulas like the following simplified example, representing x picking up y off of z. PICKUP(x; y; z) 4= (SUPPORTS(z; y) ^ CONTACTS(z; y)); (SUPPORTS(x; y) ^ ATTACHED(x; y)) This formula asserts that an event of x picking up y off of z is defined as a sequence of two states where z supports y by way of contact in the first state and x supports y by way of attachment in the second state. SUPPORTS, CONTACTS, and ATTACHED are primitive force-dynamic relations. This formula is a specific example of the more general class of AMA formulas that we use in our learning.\nFERN, GIVAN, & SISKIND"
    }, {
      "heading" : "2.2 Adding a Learning Component",
      "text" : "Prior to the work reported in this paper, the definitions in LEONARD’s event-recognition library were hand coded. Here, we add a learning component to LEONARD so that it can learn to recognize events. Figure 1 shows how the event learner fits into the overall system. The input to the event learner consists of force-dynamic models from the model-reconstruction stage, along with event labels, and its output consists of event definitions which are used by the event recognizer. We take a supervised-learning approach where the force-dynamic model-reconstruction process is applied to training videos of a target event type. The resulting force-dynamic models along with labels indicating the target event type are then given to the learner which induces a candidate definition of the event type.\nFor example, the input to our learner might consist of two models corresponding to two videos, one of a hand picking up a red block off of a green block with label PICKUP(hand; red; green) and one of a hand picking up a green block off of a red block with label PICKUP(hand; green; red)—the output would be a candidate definition of PICKUP(x; y; z) that is applicable to previously unseen pick up events. Note that our learning component is positive-only in the sense that when learning a target event type it uses only positive training examples (where the target event occurs) and does not use negative examples (where the target event does not occur). The positive-only setting is of interest as it appears that humans are able to learn many event definitions given primarily or only positive examples. From a practical standpoint, a positive-only learner removes the often difficult task of collecting negative examples that are representative of what is not the event to be learned (e.g., what is a typical “non-pickup” event?).\nThe construction of our learner involves two primary design choices. First, we must choose an event representation language to serve as the learner’s hypothesis space (i.e., the space of event definitions it may output). Second, we must design an algorithm for selecting a “good” event definition from the hypothesis space given a set of training examples of an event type."
    }, {
      "heading" : "2.3 The AMA Hypothesis Space",
      "text" : "The full event logic supported by LEONARD is quite expressive, allowing the specification of a wide variety of temporal patterns (formulas). To help support successful learning, we use a more\nLEARNING TEMPORAL EVENTS\nFERN, GIVAN, & SISKIND\nrestrictive subset of event logic, called AMA, as our learner’s hypothesis space. This subset excludes many practically useless formulas that may “confuse” the learner, while still retaining substantial expressiveness, thus allowing us to represent and learn many useful event types. Our restriction to AMA formulas is a form of syntactic learning bias.\nThe most basic AMA formulas are called states which express constant properties of time intervals of arbitrary duration. For example, SUPPORTS(z; y)^CONTACTS(z; y) is a state which tells us that z must support and be in contact with y. In general, a state can be the conjunction of any number of primitive propositions (in this case force-dynamic relations). Using AMA we can also describe sequences of states. For example, (SUPPORTS(z; y) ^ CONTACTS(z; y)) ; (SUPPORTS(x; y) ^ ATTACHED(x; y)) is a sequence of two states, with the first state as given above and the second state indicating that x must support and be attached to y. This formula is true whenever the first state is true for some time interval, followed immediately by the second state being true for some time interval “meeting” the first time interval. Such sequences are called MA timelines since they are the Meets of Ands. In general, MA timelines can contain any number of states. Finally, we can conjoin MA timelines to get AMA formulas (Ands of MA’s). For example, the AMA formula[(SUPPORTS(z; y) ^ CONTACTS(z; y)) ; (SUPPORTS(x; y) ^ ATTACHED(x; y))℄^[(SUPPORTS(u; v) ^ ATTACHED(u; v)) ; (SUPPORTS(w; v) ^ CONTACTS(w; v))℄ defines an event where two MA timelines must be true simultaneously over the same time interval. Using AMA formulas we can represent events by listing various property sequences (MA timelines), all of which must occur in parallel as an event unfolds. It is important to note, however, that the transitions between states of different timelines in an AMA formula can occur in any relation to one another. For example, in the above AMA formula, the transition between the two states of the first timeline can occur before, after, or exactly at the transition between states of the second timeline.\nAn important assumption leveraged by our learner is that the primitive propositions used to construct states describe liquid properties (Shoham, 1987). For our purposes, we say that a property is liquid if when it holds over a time-interval it holds over all of its subintervals. The force-dynamic properties produced by LEONARD are liquid—e.g., if a hand SUPPORTS a block over an interval then clearly the hand supports the block over all subintervals. Because primitive propositions are liquid, properties described by states (conjunctions of primitives) are also liquid. However, properties described by MA and AMA formulas are not, in general, liquid."
    }, {
      "heading" : "2.4 Specific-to-General Learning from Positive Data",
      "text" : "Recall that the examples that we wish to classify and learn from are force-dynamic models, which can be thought of (and are derived from) movies depicting temporal events. Also recall that our learner outputs definitions from the AMA hypothesis space. Given an AMA formula, we say that it covers an example model if it is true in that model. For a particular target event type (such as PICKUP), the ultimate goal is for the learner to output an AMA formula that covers an example model if and only if the model depicts an instance of the target event type. To understand our learner, it is useful to define a generality relationship between AMA formulas. We say that AMA formula 1 is more general (less specific) than AMA formula 2 if and only if 2 covers every example that 1 covers (and possibly more).1\n1. In our formal analysis, we will use two different notions of generality (semantic and syntactic). In this section, we ignore such distinctions. We note, however, that the algorithm we informally describe later in this section is based on the syntactic notion of generality.\nLEARNING TEMPORAL EVENTS\nIf the only learning goal is to find an AMA formula that is consistent with a set of positiveonly training data, then one result can be the trivial solution of returning the formula that covers all examples. Rather than fix this problem by adding negative training examples (which will rule out the trivial solution), we instead change the learning goal to be that of finding the least-general formula that covers all of the positive examples.2 This learning approach has been pursued for a variety of different languages within the machine-learning literature, including clausal first-order logic (Plotkin, 1971), definite clauses (Muggleton & Feng, 1992), and description logic (Cohen & Hirsh, 1994). It is important to choose an appropriate hypothesis space as a bias for this learning approach or the hypothesis returned may simply be (or resemble) one of two extremes, either the disjunction of the training examples or the universal hypothesis that covers all examples. In our experiments, we have found that, with enough training data, the least-general AMA formula often converges usefully.\nWe take a standard specific-to-general machine-learning approach to finding the least-general AMA formula that covers a set of positive examples. The approach relies on the computation of two functions: the least-general covering formula (LGCF) of an example model and the least-general generalization (LGG) of a set of AMA formulas. The LGCF of an example model is the least general AMA formula that covers the example. Intuitively, the LGCF is the AMA formula that captures the most information about the model. The LGG of any set of AMA formulas is the least-general AMA formula that is more general than each formula in the set. Intuitively, the LGG of a formula set is the AMA formula that captures the largest amount of common information among the formulas. Viewed differently, the LGG of a formula set covers all of the examples covered by those formulas, but covers as few other examples as possible (while remaining in AMA).3\nThe resulting specific-to-general learning approach proceeds as follows. First, use the LGCF function to transform each positive training model into an AMA formula. Second, return the LGG of the resulting formulas. The result represents the least-general AMA formula that covers all of the positive training examples. Thus, to specify our learner, all that remains is to provide algorithms for computing the LGCF and LGG for the AMA language. Below we informally describe our algorithms for computing these functions, which are formally derived and analyzed in Sections 3.4 and 4."
    }, {
      "heading" : "2.5 Computing the AMA LGCF",
      "text" : "To increase the readability of our presentation, in what follows, we dispense with presenting examples where the primitive properties are meaningfully named force-dynamic relations. Rather, our examples will utilize abstract propositions such as a and b. In our current application, these propositions correspond exclusively to force-dynamic properties, but may not for other applications. We now demonstrate how our system computes the LGCF of an example model.\nConsider the following example model: fa [1; 4℄; b [3; 6℄; [6; 6℄; d [1; 3℄; d [5; 6℄g . Here, we take each number (1, . . . , 6) to represent a time interval of arbitrary (possibly varying with the number) duration during which nothing changes, and then each fact p [i; j℄ indicates that proposition p is continuously true throughout the time intervals numbered i through j. This model can be depicted graphically, as shown in Figure 3. The top four lines in the figure indicate the time\n2. This avoids the need for negative examples and corresponds to finding the specific boundary of the version space (Mitchell, 1982). 3. The existence and uniqueness of the LGCF and LGG defined here is a formal property of the hypothesis space and is proven for AMA in Sections 3.4 and 4, respectively.\nintervals over which each of the propositions a; b; , and d are true in the model. The bottom line in the figure shows how the model can be divided into five time intervals where no propositions change truth value. This division is possible because of the assumption that our propositions are liquid. This allows us, for example, to break up the time-interval where a is true into three consecutive subintervals where a is true. After dividing the model into intervals with no transitions, we compute the LGCF by simply treating each of those intervals as a state of an MA timeline, where the states contain only those propositions that are true during the corresponding time interval. The resulting five-state MA timeline is shown at the bottom of the figure. We show later that this simple computation returns the LGCF for any model. Thus, we see that the LGCF of a model is always an MA timeline."
    }, {
      "heading" : "2.6 Computing the AMA LGG",
      "text" : "We now describe our algorithm for computing the LGG of two AMA formulas—the LGG of m formulas can be computed via a sequence of m 1 pairwise LGG applications, as discussed later.\nConsider the two MA timelines: 1 = (a^b^ ); (b^ ^d); e and 2 = (a^b^e); a; (e^d). It is useful to consider the various ways in which both timelines can be true simultaneously along an arbitrary time interval. To do this, we look at the various ways in which the two timelines can be aligned along a time interval. Figure 4a shows one of the many possible alignments of these timelines. We call such alignments interdigitations—in general, there are exponentially many interdigitations, each one ordering the state transitions differently. Note that an interdigitation is allowed to constrain two transitions from different timelines to occur simultaneously (though this is not depicted in the figure).4\n4. Thus, an interdigitation provides an “ordering” relation on transitions that need not be anti-symmetric, but is reflexive, transitive, and total.\nGiven an interdigitation of two timelines, it is easy to construct a new MA timeline that must be true whenever either of the timelines is true (i.e., to construct a generalization of the two timelines). In Figure 4b, we give this construction for the interdigitation given in Figure 4a. The top two horizontal lines in the figure correspond to the interdigitation, only here we have divided every state on either timeline into two identical states, whenever a transition occurs during that state in the other timeline. The resulting pair of timelines have only simultaneous transitions and can be viewed as a sequence of state pairs, one from each timeline. The bottom horizontal line is then labeled by an MA timeline with one state for each such state pair, with that state being the intersection of the proposition sets in the state pair. Here, true represents the empty set of propositions, and is a state that is true anywhere.\nWe call the resulting timeline an interdigitation generalization (IG) of 1 and 2. It should be clear that this IG will be true whenever either 1 or 2 are true. In particular, if 1 holds along a time-interval in a model, then there is a sequence of consecutive (meeting) subintervals where the sequence of states in 1 are true. By construction, the IG can be aligned relative to 1 along the interval so that when we view states as sets, the states in the IG are subsets of the corresponding aligned state(s) in 1. Thus, the IG states are all true in the model under the alignment, showing that the IG is true in the model.\nIn general, there are exponentially many IGs of two input MA timelines, one for each possible interdigitation between the two. Clearly, since each IG is a generalization of the input timelines, then so is the conjunction of all the IGs. This conjunction is an AMA formula that generalizes the input MA timelines. In fact, we show later in the paper that this AMA formula is the LGG of the two timelines. Below we show the conjunction of all the IGs of 1 and 2 which serves as their LGG.\nFERN, GIVAN, & SISKIND[(a ^ b); b; e; true; e℄ ^[(a ^ b); b; true; e℄ ^[(a ^ b); b; true; true; e℄ ^[(a ^ b); b; true; e℄ ^[(a ^ b); b; true; d; e℄ ^[(a ^ b); true; true; e℄ ^[(a ^ b); true; e℄ ^[(a ^ b); true; d; e℄ ^[(a ^ b); a; true; true; e℄ ^[(a ^ b); a; true; e℄ ^[(a ^ b); a; true; d; e℄ ^[(a ^ b); a; d; e℄ ^[(a ^ b); a; true; d; e℄ While this formula is an LGG, it contains redundant timelines that can be pruned. First, it is clear that different IGs can result in the same MA timelines, and we can remove all but one copy of each timeline from the LGG. Second, note that if a timeline 0 is more general than a timeline , then ^ 0 is equivalent to —thus, we can prune away timelines that are generalizations of others. Later in the paper, we show how to efficiently test whether one timeline is more general than another. After performing these pruning steps, we are left with only the first and next to last timelines in the above formula—thus, [(a^ b); a; d; e℄ ^ [(a^ b); b; e; true; e℄ is an LGG of 1 and 2.\nWe have demonstrated how to compute the LGG of pairs of MA timelines. We can use this procedure to compute the LGG of pairs of AMA formulas. Given two AMA formulas we compute their LGG by simply conjoining the LGGs of all pairs of timelines (one from each AMA formula)— i.e., the formula m̂i n̂j LGG( i; 0j) is an LGG of the two AMA formulas 1 ^ ^ m and 01 ^ ^ 0n, where the i and 0j are MA timelines.\nWe have now informally described the LGCF and LGG operations needed to carry out the specific-to-general learning approach described above. In what follows, we more formally develop these operations and analyze the theoretical properties of the corresponding problems, then discuss the needed extensions to bring these (exponential, propositional, and negation-free) operations to practice."
    }, {
      "heading" : "3. Representing Events with AMA",
      "text" : "Here we present a formal account of the AMA hypothesis space and an analytical development of the algorithms needed for specific-to-general learning for AMA. Readers that are primarily interested in a high-level view of the algorithms and their empirical evaluation may wish to skip Sections 3 and 4 and instead proceed directly to Sections 5 and 6, where we discuss several practical extensions to the basic learner and then present our empirical evaluation.\nWe study a subset of an interval-based logic called event logic (Siskind, 2001) utilized by LEONARD for event recognition in video sequences. This logic is interval-based in explicitly rep-\nLEARNING TEMPORAL EVENTS\nresenting each of the possible interval relationships given originally by Allen (1983) in his calculus of interval relations (e.g., “overlaps,” “meets,” “during”). Event-logic formulas allow the definition of event types which can specify static properties of intervals directly and dynamic properties by hierarchically relating sub-intervals using the Allen relations. In this paper, the formal syntax and semantics of full event logic are needed only for Proposition 4 and are given in Appendix A.\nHere we restrict our attention to a much simpler subset of event logic we call AMA, defined below. We believe that our choice of event logic rather than first-order logic, as well as our restriction to the AMA fragment of event logic, provide a useful learning bias by ruling out a large number of “practically useless” concepts while maintaining substantial expressive power. The practical utility of this bias is demonstrated via our empirical results in the visual-event–recognition application. AMA can also be seen as a restriction of LTL (Bacchus & Kabanza, 2000) to conjunction and “Until,” with similar motivations. Below we present the syntax and semantics of AMA along with some of the key technical properties of AMA that will be used throughout this paper."
    }, {
      "heading" : "3.1 AMA Syntax and Semantics",
      "text" : "It is natural to describe temporal events by specifying a sequence of properties that must hold over consecutive time intervals. For example, “a hand picking up a block” might become “the block is not supported by the hand and then the block is supported by the hand.” We represent such sequences with MA timelines5, which are sequences of conjunctive state restrictions. Intuitively, an MA timeline is given by a sequence of propositional conjunctions, separated by semicolons, and is taken to represent the set of events that temporally match the sequence of consecutive conjunctions. An AMA formula is then the conjunction of a number of MA timelines, representing events that can be simultaneously viewed as satisfying each of the conjoined timelines. Formally, the syntax of AMA formulas is given by,\nstate ::= true j prop j prop ^ state MA ::= (state) j (state);MA // may omit parens\nAMA ::= MA j MA ^ AMA where prop is any primitive proposition (sometimes called a primitive event type). We take this grammar to formally define the terms MA timeline, MA formula, AMA formula, and state. A kMA formula is an MA formula with at most k states, and a k-AMA formula is an AMA formula all of whose MA timelines are k-MA timelines. We often treat states as proposition sets withtrue the empty set and AMA formulas as MA-timeline sets. We may also treat MA formulas as sets of states—it is important to note, however, that MA formulas may contain duplicate states, and the duplication can be significant. For this reason, when treating MA timelines as sets, we formally intend sets of state-index pairs (where the index gives a states position in the formula). We do not indicate this explicitly to avoid encumbering our notation, but the implicit index must be remembered whenever handling duplicate states.\nThe semantics of AMA formulas is defined in terms of temporal models. A temporal modelM = hM; Ii over the set PROP of propositions is a pair of a mapping M from the natural numbers (representing time) to the truth assignments over PROP, and a closed natural-number interval I . We note that Siskind (2001) gives a continuous-time semantics for event logic where the models\n5. MA stands for “Meets/And,” an MA timeline being the “Meet” of a sequence of conjunctively restricted intervals.\nFERN, GIVAN, & SISKIND\nare defined in terms of real-valued time intervals. The temporal models defined here use discrete natural-number time-indices. However, our results here still apply under the continuous-time semantics. (That semantics bounds the number of state changes in the continuous timeline to a countable number.) It is important to note that the natural numbers in the domain of M are representing time discretely, but that there is no prescribed unit of continuous time represented by each natural number. Instead, each number represents an arbitrarily long period of continuous time during which nothing changed. Similarly, the states in our MA timelines represent arbitrarily long periods of time during which the conjunctive restriction given by the state holds. The satisfiability relation for AMA formulas is given as follows: A state s is satisfied by a model hM; Ii iff M [x℄ assigns P true for every x 2 I and P 2 s. An MA timeline s1; s2; : : : ; sn is satisfied by a model hM; [t; t0℄i iff there exists some t00\nin [t; t0℄ such that hM; [t; t00℄i satisfies s1 and either hM; [t00; t0℄i or hM; [t00 + 1; t0℄i satisfiess2; : : : ; sn. An AMA formula 1 ^ 2 ^ ^ n is satisfied by M iff each i is satisfied by M. The condition defining satisfaction for MA timelines may appear unintuitive at first due to the fact that there are two ways that s2; : : : ; sn can be satisfied. The reason for this becomes clear by recalling that we are using the natural numbers to represent continuous time intervals. Intuitively, from a continuous-time perspective, an MA timeline is satisfied if there are consecutive continuous-time intervals satisfying the sequence of consecutive states of the MA timeline. The transition between consecutive states si and si+1 can occur either within an interval of constant truth assignment (that happens to satisfy both states) or exactly at the boundary of two time intervals of constant truth value. In the above definition, these cases correspond to s2; : : : ; sn being satisfied during the time intervals [t00; t0℄ and [t00 + 1; t0℄ respectively.\nWhen M satisfies we say that M is a model of or that covers M. We say that AMA 1 subsumes AMA 2 iff every model of 2 is a model of 1, written 2 1, and we say that 1 properly subsumes 2, written 2 < 1, when we also have 1 6 2. Alternatively, we may state 2 1 by saying that 1 is more general (or less specific) than 2 or that 1 covers 2. Siskind (2001) provides a method to determine whether a given model satisfies a given AMA formula.\nFinally, it will be useful to associate a distinguished MA timeline to a model. The MA projection of a model M = hM; [i; j℄i written as MAP(M) is an MA timeline s0; s1; : : : ; sj i where state sk gives the true propositions in M(i + k) for 0 k j i. Intuitively, the MA projection gives the sequence of propositional truth assignments from the beginning to the end of the model. Later we show that the MA projection of a model can be viewed as representing that model in a precise sense.\nThe following two examples illustrate some basic behaviors of AMA formulas:\nExample 1 (Stretchability). S1;S2;S3, S1;S2;S2; : : : ;S2;S3, and S1;S1;S1;S2;S3;S3;S3 are all equivalent MA timelines. In general, MA timelines have the property that duplicating any state results in a formula equivalent to the original formula. Recall that, given a model hM; Ii, we view each truth assignment M [x℄ as representing a continuous time-interval. This interval can conceptually be divided into an arbitrary number of subintervals. Thus if state S is satisfied byhM; [x; x℄i, then so is the state sequence S;S; : : : ;S.\nLEARNING TEMPORAL EVENTS\nExample 2 (Infinite Descending Chains). Given propositions A and B, the MA timeline =(A ^ B) is subsumed by each of the formulas A;B, A;B;A;B, A;B;A;B;A;B, . . . . This is intuitively clear when our semantics are viewed from a continuous-time perspective. Any interval in which both A and B are true can be broken up into an arbitrary number of subintervals where both A and B hold. This example illustrates that there can be infinite descending chains of AMA formulas where the entire chain subsumes a given formula (but no member is equivalent to the given formula). In general, any AMA formula involving only the propositions A and B will subsume ."
    }, {
      "heading" : "3.2 Motivation for AMA",
      "text" : "MA timelines are a very natural way to capture stretchable sequences of state constraints. But why consider the conjunction of such sequences, i.e., AMA? We have several reasons for this language enrichment. First of all, we show below that the AMA least-general generalization (LGG) is unique—this is not true for MA. Second, and more informally, we argue that parallel conjunctive constraints can be important to learning efficiency. In particular, the space of MA formulas of length k grows in size exponentially with k, making it difficult to induce long MA formulas. However, finding several shorter MA timelines that each characterize part of a long sequence of changes is exponentially easier. (At least, the space to search is exponentially smaller.) The AMA conjunction of these timelines places these shorter constraints simultaneously and often captures a great deal of the concept structure. For this reason, we analyze AMA as well as MA and, in our empirical work, we consider k-AMA.\nThe AMA language is propositional. But our intended applications are relational, or first-order, including visual-event recognition. Later in this paper, we show that the propositional AMA learning algorithms that we develop can be effectively applied in relational domains. Our approach to first-order learning is distinctive in automatically constructing an object correspondence across examples (cf. Lavrac, Dzeroski, & Grobelnik, 1991; Roth & Yih, 2001). Similarly, though AMA does not allow for negative state constraints, in Section 5.4 we discuss how to extend our results to incorporate negation into our learning algorithms, which is crucial in visual-event recognition."
    }, {
      "heading" : "3.3 Conversion to First-Order Clauses",
      "text" : "We note that AMA formulas can be translated in various ways into first-order clauses. It is not straightforward, however, to then use existing clausal generalization techniques for learning. In particular, to capture the AMA semantics in clauses, it appears necessary to define subsumption and generalization relative to a background theory that restricts us to a “continuous-time” first-order– model space.\nFor example, consider the AMA formulas 1 = A ^ B and 2 = A;B where A and B are propositions—from Example 2 we know that 1 2. Now, consider a straightforward clausal translation of these formulas giving C1 = A(I)^B(I) and C2 = A(I1)^B(I2)^MEETS(I1; I2)^I = SPAN(I1; I2), where the I and Ij are variables that represent time intervals, MEETS indicates that two time intervals meet each other, and SPAN is a function that returns a time interval equal to the union of its two time-interval arguments. The meaning we intend to capture is for satisfying assignments of I in C1 and C2 to indicate intervals over which 1 and 2 are satisfied, respectively. It should be clear that, contrary to what we want, C1 6 C2 (i.e., 6j= C1 ! C2), since it is easy to find unintended first-order models that satisfy C1, but not C2. Thus such a translation, and other similar translations, do not capture the continuous-time nature of the AMA semantics.\nFERN, GIVAN, & SISKIND\nIn order to capture the AMA semantics in a clausal setting, one might define a first-order theory that restricts us to continuous-time models—for example, allowing for the derivation “if property B holds over an interval, then that property also holds over all sub-intervals.” Given such a theory , we have that j= C1 ! C2, as desired. However, it is well known that least-general generalizations relative to such background theories need not exist (Plotkin, 1971), so prior work on clausal generalization does not simply subsume our results for the AMA language.\nWe note that for a particular training set, it may be possible to compile a continuous-time background theory into a finite but adequate set of ground facts. Relative to such ground theories, clausal LGGs are known to always exist and thus could be used for our application. However, the only such compiling approaches that look promising to us require exploiting an analysis similar to the one given in this paper—i.e., understanding the AMA generalization and subsumption problem separately from clausal generalization and exploiting that understanding in compiling the background theory. We have not pursued such compilations further.\nEven if we are given such a compilation procedure, there are other problems with using existing clausal generalization techniques for learning AMA formulas. For the clausal translations of AMA we have found, the resulting generalizations typically fall outside of the (clausal translations of formulas in the) AMA language, so that the language bias of AMA is lost. In preliminary empirical work in our video-event recognition domain using clausal inductive-logic-programming (ILP) systems, we found that the learner appeared to lack the necessary language bias to find effective event definitions. While we believe that it would be possible to find ways to build this language bias into ILP systems, we chose instead to define and learn within the desired language bias directly, by defining the class of AMA formulas, and studying the generalization operation on that class."
    }, {
      "heading" : "3.4 Basic Concepts and Properties of AMA",
      "text" : "We use the following convention in naming our results: “propositions” and “theorems” are the key results of our work, with theorems being those results of the most technical difficulty, and “lemmas” are technical results needed for the later proofs of propositions or theorems. We number all the results in one sequence, regardless of type. Proofs of theorems and propositions are provided in the main text—omitted proofs of lemmas are provided in the appendix.\nWe give pseudo-code for our methods in a non-deterministic style. In a non-deterministic language functions can return more than one value non-deterministically, either because they contain non-deterministic choice points, or because they call other non-deterministic functions. Since a nondeterministic function can return more than one possible value, depending on the choices made at the choice points encountered, specifying such a function is a natural way to specify a richly structured set (if the function has no arguments) or relation (if the function has arguments). To actually enumerate the values of the set (or the relation, once arguments are provided) one can simply use a standard backtracking search over the different possible computations corresponding to different choices at the choice points."
    }, {
      "heading" : "3.4.1 SUBSUMPTION AND GENERALIZATION FOR STATES",
      "text" : "The most basic formulas we deal with are states (conjunctions of propositions). In our propositional setting computing subsumption and generalization at the state level is straightforward. A state S1 subsumes S2 (S2 S1) iff S1 is a subset of S2, viewing states as sets of propositions. From this, we derive that the intersection of states is the least-general subsumer of those states and that the union of states is likewise the most general subsumee.\nLEARNING TEMPORAL EVENTS"
    }, {
      "heading" : "3.4.2 INTERDIGITATIONS",
      "text" : "Given a set of MA timelines, we need to consider the different ways in which a model could simultaneously satisfy the timelines in the set. At the start of such a model (i.e., the first time point), the initial state from each timeline must be satisfied. At some time point in the model, one or more of the timelines can transition so that the second state in those timelines must be satisfied in place of the initial state, while the initial state of the other timelines remains satisfied. After a sequence of such transitions in subsets of the timelines, the final state of each timeline holds. Each way of choosing the transition sequence constitutes a different interdigitation of the timelines.\nViewed differently, each model simultaneously satisfying the timelines induces a co-occurrence relation on tuples of timeline states, one from each timeline, identifying which tuples co-occur at some point in the model. We represent this concept formally as a set of tuples of co-occurring states, i.e., a co-occurrence relation. We sometimes think of this set of tuples as ordered by the sequence of transitions. Intuitively, the tuples in an interdigitation represent the maximal time intervals over which no MA timeline has a transition, with those tuples giving the co-occurring states for each such time interval.\nA relation R on X1 Xn is simultaneously consistent with orderings 1,. . . , n, if, whenever R(x1; : : : ; xn) and R(x01; : : : ; x0n), either xi i x0i, for all i, or x0i i xi, for all i. We sayR is piecewise total if the projection of R onto each component is total—i.e., every state in any Xi appears in R. Definition 1 (Interdigitation). An interdigitation I of a set f 1; : : : ; ng of MA timelines is a cooccurrence relation over 1 n (viewing timelines as sets of states6) that is piecewise total and simultaneously consistent with the state orderings of each i. We say that two states s 2 i and s0 2 j for i 6= j co-occur in I iff some tuple of I contains both s and s0. We sometimes refer toI as a sequence of tuples, meaning the sequence lexicographically ordered by the i state orderings. We note that there are exponentially many interdigitations of even two MA timelines (relative to the total number of states in the timelines). Example 3 on page 396 shows an interdigitation of two MA timelines. Pseudo-code for non-deterministically generating an arbitrary interdigitation for a set of MA timelines can be found in Figure 5. Given an interdigitation I of the timelines s1; s2; : : : ; sm and t1; t2; : : : ; tn (and possibly others), the following basic properties of interdigitations are easily verifiable:\n1. For i < j, if si and tk co-occur in I then for all k0 < k, sj does not co-occur with tk0 in I . 2. I(s1; t1) and I(sm; tn). We first use interdigitations to syntactically characterize subsumption between MA timelines.\nDefinition 2 (Witnessing Interdigitation). An interdigitation I of two MA timelines 1 and 2 is a witness to 1 2 iff for every pair of co-occurring states s1 2 1 and s2 2 2, we have thats2 is a subset of s1 (i.e., s1 s2). The following lemma and proposition establish the equivalence between witnessing interdigitations and MA subsumption.\n6. Recall, that, formally, MA timelines are viewed as sets of state-index pairs, rather than just sets of states. We ignore this distinction in our notation, for readability purposes, treating MA timelines as though no state is duplicated.\nFERN, GIVAN, & SISKIND\nLemma 1. For any MA timeline and any model M, if M satisfies , then there is a witnessing interdigitation for MAP(M) . Proposition 2. For MA timelines 1 and 2, 1 2 iff there is an interdigitation that witnesses 1 2. Proof: We show the backward direction by induction on the number of states n in timeline 1. Ifn = 1, then the existence of a witnessing interdigitation for 1 2 implies that every state in 2 is a subset of the single state in 1, and thus that any model of 1 is a model of 2 so that 1 2. Now, suppose for induction that the backward direction of the theorem holds whenever 1 has n or fewer states. Given an arbitrary model M of an n + 1 state 1 and an interdigitation W that witnesses 1 2, we must show that M is also a model of 2 to conclude 1 2 as desired.\nWrite 1 as s1; : : : ; sn+1 and 2 as t1; : : : ; tm. As a witnessing interdigitation, W must identify some maximal prefix t1; : : : ; tm0 of 2 made up of states that co-occur with s1 and thus that are subsets of s1. Since M = hM; [t; t0℄i satisfies 1, by definition there must exist a t00 2 [t; t0℄ such that hM; [t; t00℄i satisfies s1 (and thus t1; : : : ; tm0) and hM; I 0i satisfies s2; : : : ; sn+1 for I 0 equal to either [t00; t0℄ or [t00 + 1; t0℄. In either case, it is straightforward to construct, from W , a witnessing interdigitation for s2; : : : ; sn+1 tm0+1; : : : ; tm and use the induction hypothesis to then show thathM; I 0i must satisfy tm0+1; : : : ; tm. It follows that M satisfies 2 as desired.\nFor the forward direction, assume that 1 2, and let M be any model such that 1 = MAP(M). It is clear that such an M exists and satisfies 1. It follows that M satisfies 2. Lemma 1 then implies that there is a witnessing interdigitation for MAP(M) 2 and thus for 1 2. 2\nLEARNING TEMPORAL EVENTS"
    }, {
      "heading" : "3.4.3 LEAST-GENERAL COVERING FORMULA",
      "text" : "A logic can discriminate two models if it contains a formula that satisfies one but not the other. It turns out that AMA formulas can discriminate two models exactly when much richer internal positive event logic (IPEL) formulas can do so. Internal formulas are those that define event occurrence only in terms of properties within the defining interval. That is, satisfaction by hM; Ii depends only on the proposition truth values given by M inside the interval I . Positive formulas are those that do not contain negation. Appendix A gives the full syntax and semantics of IPEL (which are used only to state and prove Lemma 3 ). The fact that AMA can discriminate models as well as IPEL indicates that our restriction to AMA formulas retains substantial expressive power and leads to the following result which serves as the least-general covering formula (LGCF) component of our specific-to-general learning procedure. Formally, an LGCF of model M within a formula languageL (e.g. AMA or IPEL) is a formula in L that covers M such that no other covering formula inL is strictly less general. Intuitively, the LGCF of a model, if unique, is the “most representative” formula of that model. Our analysis uses the concept of model embedding. We say that model M embeds model M0 iff MAP(M) MAP(M0). Lemma 3. For any E 2 IPEL, if model M embeds a model that satisfies E, then M satisfies E. Proposition 4. The MA projection of a model is its LGCF for internal positive event logic (and hence for AMA), up to semantic equivalence.\nProof: Consider model M. We know that MAP(M) covers M, so it remains to show that MAP(M) is the least general formula to do so, up to semantic equivalence.\nLetE be any IPEL formula that coversM. LetM0 be any model that is covered by MAP(M)— we want to show that E also covers M0. We know, from Lemma 1, that there is a witnessing interdigitation for MAP(M0) MAP(M). Thus, by Proposition 2, MAP(M0) MAP(M) showing that M0 embeds M. Combining these facts with Lemma 3 it follows that E also coversM0 and hence MAP(M) E. 2\nProposition 4 tells us that, for IPEL, the LGCF of a model exists, is unique, and is an MA timeline. Given this property, when an AMA formula covers all the MA timelines covered by another AMA formula 0, we have 0 . Thus, for the remainder of this paper, when considering subsumption between formulas, we can abstract away from temporal models and deal instead with MA timelines. Proposition 4 also tells us that we can compute the LGCF of a model by constructing the MA projection of that model. Based on the definition of MA projection, it is straightforward to derive an LGCF algorithm which runs in time polynomial in the size of the model7. We note that the MA projection may contain repeated states. In practice, we remove repeated states, since this does not change the meaning of the resulting formula (as described in Example 1)."
    }, {
      "heading" : "3.4.4 COMBINING INTERDIGITATION WITH GENERALIZATION OR SPECIALIZATION",
      "text" : "Interdigitations are useful in analyzing both conjunctions and disjunctions of MA timelines. When conjoining a set of timelines, any model of the conjunction induces an interdigitation of the timelines such that co-occurring states simultaneously hold in the model at some point (viewing states as sets, the the states resulting from unioning co-occurring states must hold). By constructing an\n7. We take the size of a model M = hM; Ii to be the sum over x 2 I of the number of true propositions in M(x).\nFERN, GIVAN, & SISKIND\ninterdigitation and taking the union of each tuple of co-occurring states to get a sequence of states, we get an MA timeline that forces the conjunction of the timelines to hold. We call such a sequence an interdigitation specialization of the timelines. Dually, an interdigitation generalization involving intersections of states gives an MA timeline that holds whenever the disjunction of a set of timelines holds.\nDefinition 3. An interdigitation generalization (specialization) of a set of MA timelines is an MA timeline s1; : : : ; sm, such that, for some interdigitation I of with m tuples, sj is the intersection (respectively, union) of the components of the j’th tuple of the sequence I . The set of interdigitation generalizations (respectively, specializations) of is called IG( ) (respectively, IS( )). Example 3. Suppose that s1; s2; s3; t1; t2; and t3 are each sets of propositions (i.e., states). Consider the timelines S = s1; s2; s3 and T = t1; t2; t3. The relationf hs1; t1i ; hs2; t1i ; hs3; t2i ; hs3; t3i g is an interdigitation of S and T in which states s1 and s2 co-occur with t1, and s3 co-occurs witht2 and t3. The corresponding IG and IS members ares1 \\ t1; s2 \\ t1; s3 \\ t2; s3 \\ t3 2 IG(fS; Tg)s1 [ t1; s2 [ t1; s3 [ t2; s3 [ t3 2 IS(fS; Tg): If t1 s1; t1 s2; t2 s3; and t3 s3, then the interdigitation witnesses S T .\nEach timeline in IG( ) (dually, IS( )) subsumes (is subsumed by) each timeline in —this is easily verified using Proposition 2. For our complexity analyses, we note that the number of states in any member of IG( ) or IS( ) is bounded from below by the number of states in any of the MA timelines in and is bounded from above by the total number of states in all the MA timelines in . The number of interdigitations of , and thus of members of IG( ) or IS( ), is exponential in that same total number of states. The algorithms that we present later for computing LGGs require the computation of both IG( ) and IS( ). Here we give pseudo-code to compute these quantities. Figure 6 gives pseudo-code for the function an-IG-member that non-deterministically computes an arbitrary member of IG( ) (an-IS-member is the same, except that we replace intersection by union). Given a set of MA timelines we can compute IG( ) by executing all possible deterministic computation paths of the function call an-IG-member( ), i.e., computing the set of results obtainable from the non-deterministic function for all possible decisions at non-deterministic choice points.\nWe now give a useful lemma and a proposition concerning the relationships between conjunctions and disjunctions of MA concepts (the former being AMA concepts). For convenience here, we use disjunction on MA concepts, producing formulas outside of AMA with the obvious interpretation.\nLemma 5. Given an MA formula that subsumes each member of a set of MA formulas, also subsumes some member 0 of IG( ). Dually, when is subsumed by each member of , we have that is also subsumed by some member 0 of IS( ). In each case, the length of 0 is bounded by the size of .\nLEARNING TEMPORAL EVENTS\nProposition 6. The following hold:\n1. (and-to-or) The conjunction of a set of MA timelines equals the disjunction of the timelines in IS( ).\n2. (or-to-and) The disjunction of a set of MA timelines is subsumed by the conjunction of the timelines in IG( ).\nProof: To prove or-to-and, recall that, for any 2 and any 0 2 IG( ), we have that 0. From this it is immediate that (W ) (V IG( )). Using a dual argument, we can show that(W IS( )) (V ). It remains to show that (V ) (W IS( )), which is equivalent to showing that any timeline subsumed by (V ) is also subsumed by (W IS( )) (by Proposition 4). Consider any MA timeline such that (V )—this implies that each member of subsumes . Lemma 5 then implies that there is some 0 2 IS( ) such that 0. From this we get that (W IS( )) as desired. 2\nUsing and-to-or, we can now reduce AMA subsumption to MA subsumption, with an exponential increase in the problem size.\nProposition 7. For AMA 1 and 2, 1 2 if and only if for all 1 2 IS( 1) and 2 2 2; 1 2. Proof: For the forward direction we show the contrapositive. Assume there is a 1 2 IS( 1) and a 2 2 2 such that 1 6 2. Thus, there is an MA timeline such that 1 but 6 2. This tells us that (W IS( 1)) and that 6 2, thus (W IS( 1)) 6 2 and by “and-to-or” we get that 1 6 2.\nFor the backward direction assume that for all 1 2 IS( 1) and 2 2 2 that 1 2. This tells us that for each 1 2 IS( 1), that 1 2—thus, 1 = (W IS( 1)) 2. 2"
    }, {
      "heading" : "4. Subsumption and Generalization",
      "text" : "In this section we study subsumption and generalization of AMA formulas. First, we give a polynomial-time algorithm for deciding subsumption between MA formulas and then show that deciding subsumption for AMA formulas is coNP-complete. Second we give algorithms and complexity bounds for the construction of least-general generalization (LGG) formulas based on our\nFERN, GIVAN, & SISKIND\nanalysis of subsumption, including existence, uniqueness, lower/upper bounds, and an algorithm for the LGG on AMA formulas. Third, we introduce a polynomial-time–computable syntactic notion of subsumption and an algorithm that computes the corresponding syntactic LGG that is exponentially faster than our semantic LGG algorithm. Fourth, in Section 4.4, we give a detailed example showing the steps performed by our LGG algorithms to compute the semantic and syntactic LGGs of two AMA formulas."
    }, {
      "heading" : "4.1 Subsumption",
      "text" : "All our methods rely critically on a novel algorithm for deciding the subsumption question 1 2 between MA formulas 1 and 2 in polynomial-time. We note that merely searching the possible interdigitations of 1 and 2 for a witnessing interdigitation provides an obvious decision procedure for the subsumption question—however, there are, in general, exponentially many such interdigitations. We reduce the MA subsumption problem to finding a path in a graph on pairs of states in 1 2, a polynomial-time operation. Pseudo-code for the resulting MA subsumption algorithm is shown in Figure 7. The main data structure used by the MA subsumption algorithm is the subsumption graph.\nDefinition 4. The subsumption graph of two MA timelines 1 = s1; ; sm and 2 = t1; ; tn (written SG( 1; 2)) is a directed graph G = hV;Ei with V = fvi;j j 1 i m; 1 j ng. The (directed) edge set E equals hvi;j; vi0;j0i j si tj; si0 tj0; i i0 i+ 1; j j0 j + 1 .\nTo achieve a polynomial-time bound one can simply use any polynomial-time pathfinding algorithm. In our case the special structure of the subsumption graph can be exploited to determine if\nLEARNING TEMPORAL EVENTS\nthe desired path exists in O(mn) time, as the example method shown in the pseudo-code illustrates. The following theorem asserts the correctness of the algorithm assuming a correct polynomial-time path-finding method is used.\nLemma 8. Given MA timelines 1 = s1; : : : ; sm and 2 = t1; : : : ; tn, there is a witnessing interdigitation for 1 2 iff there is a path in the subsumption graph SG( 1; 2) from v1;1 tovm;n. Theorem 9. Given MA timelines 1 and 2, MA-subsumes( 1; 2) decides 1 2 in polynomial time.\nProof: The algorithm clearly runs in polynomial time. Lemma 8 tells us that line 2 of the algorithm will return TRUE iff there is a witnessing interdigitation. Combining this with Proposition 2 shows that the algorithm returns TRUE iff 1 2. 2\nGiven this polynomial-time algorithm for MA subsumption, Proposition 7 immediately suggests an exponential-time algorithm for deciding AMA subsumption—by computing MA subsumption between the exponentially many IS timelines of one formula and the timelines of the other formula. Our next theorem suggests that we cannot do any better than this in the worst case—we argue that AMA subsumption is coNP-complete by reduction from boolean satisfiability. Readers uninterested in the technical details of this argument may skip directly to Section 4.2.\nTo develop a correspondence between boolean satisfiability problems, which include negation, and AMA formulas, which lack negation, we imagine that each boolean variable has two AMA propositions, one for “true” and one for “false.” In particular, given a boolean satisfiability problem over n variables p1; : : : ; pn, we take the set PROPn to be the set containing 2n AMA propositions Truek and Falsek for each k between 1 and n. We can now represent a truth assignment A to the pi variables with an AMA state sA given as follows:sA = fTruei j 1 i n; A(pi) = trueg [ fFalsei j 1 i n; A(pi) = falseg\nAs Proposition 7 suggests, checking AMA subsumption critically involves the exponentially many interdigitation specializations of the timelines of one of the AMA formulas. In our proof, we design an AMA formula whose interdigitation specializations can be seen to correspond to truth assignments8 to boolean variables, as shown in the following lemma.\nLemma 10. Given some n, let be the conjunction of the timelinesn[i=1f(PROPn;Truei;Falsei;PROPn); (PROPn;Falsei;Truei;PROPn)g: We have the following facts about truth assignments to the Boolean variables p1; : : : ; pn:\n1. For any truth assignment A, PROPn; sA;PROPn is semantically equivalent to a member of IS( ).\n2. For each 2 IS( ) there is a truth assignment A such that PROPn; sA;PROPn. 8. A truth assignment is a function mapping boolean variables to true or false.\nFERN, GIVAN, & SISKIND\nWith this lemma in hand, we can now tackle the complexity of AMA subsumption.\nTheorem 11. Deciding AMA subsumption is coNP-complete.\nProof: We first show that deciding the AMA-subsumption of 1 by 2 is in coNP by providing a polynomial-length certificate for any “no” answer. This certificate for non-subsumption is an interdigitation of the timelines of 1 that yields a member of IS( 1) not subsumed by 2. Such a certificate can be checked in polynomial time: given such an interdigitation, the corresponding member of IS( 1) can be computed in time polynomial in the size of 1, and we can then test whether the resulting timeline is subsumed by each timeline in 2 using the polynomial-time MAsubsumption algorithm. Proposition 7 guarantees that 1 6 2 iff there is a timeline in IS( 1) that is not subsumed by every timeline in 2, so that such a certificate will exist exactly when the answer to a subsumption query is “no.” To show coNP-hardness we reduce the problem of deciding the satisfiability of a 3-SAT formulaS = C1 ^ ^Cm to the problem of recognizing non-subsumption between AMA formulas. Here, each Ci is (li;1 _ li;2 _ li;3) and each li;j either a proposition p chosen from P = fp1; : : : ; png or its negation :p. The idea of the reduction is to construct an AMA formula for which we view the exponentially many members of IS( ) as representing truth assignments. We then construct an MA timeline that we view as representing :S and show that S is satisfiable iff 6 .\nLet be as defined in Lemma 10. Let be the formula s1; : : : ; sm, wheresi = fFalsej j li;k = pj for some kg [fTruej j li;k = :pj for some kg: Each si can be thought of as asserting “not Ci.” We start by showing that if S is satisfiable then 6 . Assume that S is satisfied via a truth assignment A—we know from Lemma 10 that there is a 0 2 IS( ) that is semantically equivalent to PROPn; sA;PROPn. We show that PROPn; sA;PROPn is not subsumed by , to conclude 6 using Proposition 7, as desired. Suppose for contradiction that PROPn; sA;PROPn is subsumed by —then the state sA must be subsumed by some state si in . Consider the corresponding clause Ci of S. Since A satisfies S we have that Ci is satisfied and at least one of its literals li;k must be true. Assume that li;k = pj (a dual argument holds for li;k = :pj), then we have that si contains Falsej while sA contains Truej but not Falsej—thus, we have that sA 6 si (since si 6 sA), contradicting our choice of i.\nTo complete the proof, we now assume that S is unsatisfiable and show that . Using Proposition 7, we consider arbitrary 0 in IS( )—we will show that 0 . From Lemma 10 we know there is some truth assignment A such that 0 PROPn; sA;PROPn. Since S is unsatisfiable we know that some Ci is not satisfied by A and hence :Ci is satisfied by A. This implies that each primitive proposition in si is in sA. Let W be the following interdigitation between T = PROPn; sA;PROPn and = s1; : : : ; sm:fhPROPn; s1i hPROPn; s2i hPROPn; sii hsA; sii hPROPn; sii hPROPn; si+1i hPROPn; smig We see that in each tuple of co-occurring states given above that the state from T is subsumed by the state from . Thus W is a witnessing interdigitation to PROPn; sA;PROPn , which then holds by Proposition 2—combining this with 0 PROPn; sA;PROPn we get that 0 . 2\nGiven this hardness result we later define a weaker polynomial-time–computable subsumption notion for use in our learning algorithms.\nLEARNING TEMPORAL EVENTS"
    }, {
      "heading" : "4.2 Least-General Generalization.",
      "text" : "An AMA LGG of a set of AMA formulas is an AMA formula that is more general than each formula in the set and not strictly more general than any other such formula. The existence of an AMA LGG is nontrivial as there can be infinite chains of increasingly specific formulas all of which generalize given formulas. Example 2 demonstrated such chains for an MA subsumee and can be extended for AMA subsumees. For example, each member of the chain P ;Q, P ;Q;P ;Q,P ;Q;P ;Q;P ;Q; : : : covers 1 = (P ^Q);Q and 2 = P ; (P ^Q). Despite such complications, the AMA LGG does exist.\nTheorem 12. There is an LGG for any finite set of AMA formulas that is subsumed by all other generalizations of . Proof: Let be the set S 02 IS( 0). Let be the conjunction of all the MA timelines that generalize while having size no larger than . Since there are only a finite number of primitive propositions, there are only a finite number of such timelines, so is well defined9. We show that is a least-general generalization of . First, note that each timeline in generalizes and thus (by Proposition 6), so must generalize . Now, consider arbitrary generalization 0 of . Proposition 7 implies that 0 must generalize each formula in . Lemma 5 then implies that each timeline of 0 must subsume a timeline that is no longer than the size of and that also subsumes the timelines of . But then must be a timeline of , by our choice of , so that every timeline of 0 subsumes a timeline of . It follows that 0 subsumes , and that is an LGG of subsumed by all other LGGs of , as desired. 2 Given that the AMA LGG exists and is unique we now show how to compute it. Our first step is to strengthen “or-to-and” from Proposition 6 to get an LGG for the MA sublanguage.\nTheorem 13. For a set of MA formulas, the conjunction of all MA timelines in IG( ) is an AMA LGG of . Proof: Let be the specified conjunction. Since each timeline of IG( ) subsumes all timelines in , subsumes each member of . To show is a least-general such formula, consider an AMA formula 0 that also subsumes all members of . Since each timeline of 0 must subsume all members of , Lemma 5 implies that each timeline of 0 subsumes a member of IG( ) and thus each timeline of 0 subsumes . This implies 0. 2 We can now characterize the AMA LGG using IS and IG. Theorem 14. IG(S 2 IS( )) is an AMA LGG of the set of AMA formulas. Proof: Let = f 1; : : : ; ng and E = 1 _ _ n. We know that the AMA LGG of must subsume E, or it would fail to subsume one of the i. Using “and-to-or” we can representE as a disjunction of MA timelines given by E = (W IS( 1)) _ _ (W IS( n)). Any AMA LGG must be a least-general formula that subsumes E—i.e., an AMA LGG of the set of MA timelines\nSfIS( )j 2 g. Theorem 13 tells us that an LGG of these timelines is given by IG(SfIS( )j 2 g). 2\n9. There must be at least one such timeline, the timeline where the only state is true\nFERN, GIVAN, & SISKIND\nTheorem 14 leads directly to an algorithm for computing the AMA LGG—Figure 8 gives pseudo-code for the computation. Lines 4-9 of the pseudo-code correspond to the computation of SfIS( )j 2 g, where timelines are not included in the set if they are subsumed by timelines already in the set (which can be checked with the polynomial time MA subsumption algorithm). This pruning, accomplished by the if test in line 7, often drastically reduces the size of the timeline set for which we perform the subsequent IG computation—the final result is not affected by the pruning since the subsequent IG computation is a generalization step. The remainder of the pseudo-code corresponds to the computation of IG(SfIS( )j 2 g) where we do not include timelines in the final result that subsume some other timeline in the set. This pruning step (the if test in line 12) is sound since when one timeline subsumes another, the conjunction of those timelines is equivalent to the most specific one. Section 4.4.1 traces the computations of this algorithm for an example LGG calculation.\nSince the sizes of both IS( ) and IG( ) are exponential in the sizes of their inputs, the code in Figure 8 is doubly exponential in the input size. We conjecture that we cannot do better than this, but we have not yet proven a doubly exponential lower bound for the AMA case. When the input formulas are MA timelines the algorithm takes singly exponential time, since IS(f g) = when is in MA. We now prove an exponential lower bound when the input formulas are in MA. Again, readers uninterested in the technical details of this proof can safely skip forward to Section 4.3. For this argument, we take the available primitive propositions to be those in the set fpi;j j 1 i n; 1 j ng, and consider the MA timelines 1 = s1; ; s2; ; : : : ; sn; and 2 = s ;1; s ;2; : : : ; s ;n; where\nLEARNING TEMPORAL EVENTSsi; = pi;1 ^ ^ pi;n and s ;j = p1;j ^ ^ pn;j:\nWe will show that any AMA LGG of 1 and 2 must contain an exponential number of timelines. In particular, we will show that any AMA LGG is equivalent to the conjunction of a subset of IG(f 1; 2g), and that certain timelines may not be omitted from such a subset. Lemma 15. Any AMA LGG of a set of MA timelines is equivalent to a conjunction 0 of timelines from IG( ) with j 0j j j Proof: Lemma 5 implies that any timeline in must subsume some timeline 0 2 IG( ). But then the conjunction 0 of such 0 must be equivalent to , since it clearly covers and is covered by the LGG . Since 0 was formed by taking one timeline from IG( ) for each timeline in , we have j 0j j j. 2We can complete our argument then by showing that exponentially many timelines in IG(f 1; 2g) cannot be omitted from such a conjunction while it remains an LGG.\nNotice that for any i; j we have that si; \\s ;j = pi;j . This implies that any state in IG(f 1; 2g) contains exactly one proposition, since each such state is formed by intersecting a state from 1 and 2. Furthermore, the definition of interdigitation, applied here, implies the following two facts for any timeline q1; q2; : : : ; qm in IG(f 1; 2g):\n1. q1 = p1;1 and qm = pn;n. 2. For consecutive states qk = pi;j and qk+1 = pi0;j0 , i0 is either i or i+1, j0 is either j or j +1,\nand not both i = i0 and j = j0. Together these facts imply that any timeline in IG(f 1; 2g) is a sequence of propositions starting with p1;1 and ending with pn;n such that any consecutive propositions pi;j; pi0;j0 are different withi0 equal to i or i + 1 and j0 equal to j or j + 1. We call a timeline in IG(f 1; 2g) square if and only if each pair of consecutive propositions pi;j and pi0;j0 have either i0 = i or j0 = j. The following lemma implies that no square timeline can be omitted from the conjunction of timelines in IG( 1; 2) if it is to remain an LGG of 1 and 2. Lemma 16. Let 1 and 2 be as given above and let = V IG(f 1; 2g). For any 0 whose timelines are a subset of those in that omits some square timeline, we have < 0.\nThe number of square timelines in IG(f 1; 2g) is equal to (2n 2)!(n 1)!(n 1)! and hence is exponential in the size of 1 and 2. We have now completed the proof of the following result. Theorem 17. The smallest LGG of two MA formulas can be exponentially large.\nProof: By Lemma 15, any AMA LGG 0 of 1 and 2 is equivalent to a conjunction of the same number of timelines chosen from IG(f 1; 2g). However, by Lemma 16, any such conjunction must have at least (2n 2)!(n 1)!(n 1)! timelines, and then so must 0, which must then be exponentially large. 2 Conjecture 18. The smallest LGG of two AMA formulas can be doubly-exponentially large.\nFERN, GIVAN, & SISKIND\nWe now show that our lower-bound on AMA LGG complexity is not merely a consequence of the existence of large AMA LGGs. Even when there is a small LGG, it can be expensive to compute due to the difficulty of testing AMA subsumption:\nTheorem 19. Determining whether a formula is an AMA LGG for two given AMA formulas 1 and 2 is co-NP-hard, and is in co-NEXP, in the size of all three formulas together. Proof: To show co-NP-hardness we use a straightforward reduction from AMA subsumption. Given two AMA formulas 1 and 2 we decide 1 2 by asking whether 2 is an AMA LGG of 1 and 2. Clearly 1 2 iff 2 is an LGG of the two formulas.\nTo show the co-NEXP upper bound, note that we can check in exponential time whether 1 and 2 using Proposition 7 and the polynomial-time MA subsumption algorithm. It remains to show that we can check whether is not the “least” subsumer. Since Theorem 14 shows that the LGG of 1 and 2 is IG(IS( 1) [ IS( 2)), if is not the LGG then 6 IG(IS( 1) [ IS( 2)). Thus, by Proposition 7, if is not a least subsumer, there must be timelines 1 2 IS( ) and 2 2 IG(IS( 1) [ IS( 2)) such that 1 6 2. We can then use exponentially long certificates for “No” answers: each certificate is a pair of an interdigitation I1 of and an interdigitation I2 of IS( 1)[IS( 2), such that the corresponding members 1 2 IS( ) and 2 2 IG(IS( 1)[IS( 2)) have 1 6 2. Given the pair of certificates I1 and I2, 1 can be computed in polynomial time, 2 can be computed in exponential time, and the subsumption between them can be checked in polynomial time (relative to their size, which can be exponential). If is the LGG then IG(IS( 1) [ IS( 2)), so that no such certificates will exist. 2"
    }, {
      "heading" : "4.3 Syntactic Subsumption and Syntactic Least-General Generalization.",
      "text" : "Given the intractability results for semantic AMA subsumption, we now introduce a tractable generality notion, syntactic subsumption, and discuss the corresponding LGG problem. The use of syntactic forms of generality for efficiency is familiar in ILP (Muggleton & De Raedt, 1994)— where, for example, -subsumption is often used in place of the entailment generality relation. Unlike AMA semantic subsumption, syntactic subsumption requires checking only polynomially many MA subsumptions, each in polynomial time (via Theorem 9).\nDefinition 5. AMA 1 is syntactically subsumed by AMA 2 (written 1 syn 2) iff for each MA timeline 2 2 2, there is an MA timeline 1 2 1 such that 1 2. Proposition 20. AMA syntactic subsumption can be decided in polynomial time.\nSyntactic subsumption trivially implies semantic subsumption—however, the converse does not hold in general. Consider the AMA formulas (A;B) ^ (B;A), and A;B;A where A and B are primitive propositions. We have (A;B) ^ (B;A) A;B;A; however, we have neither A;B A;B;A nor B;A A;B;A, so that A;B;A does not syntactically subsume (A;B) ^ (B;A). Syntactic subsumption fails to recognize constraints that are only derived from the interaction of timelines within a formula.\nSyntactic Least-General Generalization. A syntactic AMA LGG is a syntactically least-general AMA formula that syntactically subsumes the input AMA formulas. Here, “least” means that no\nLEARNING TEMPORAL EVENTS\nformula properly syntactically subsumed by a syntactic LGG can syntactically subsume the input formulas. Based on the hardness gap between syntactic and semantic AMA subsumption, one might conjecture that a similar gap exists between the syntactic and semantic LGG problems. Proving such a gap exists requires closing the gap between the lower and upper bounds on AMA LGG shown in Theorem 14 in favor of the upper bound, as suggested by Conjecture 18. While we cannot yet show a hardness gap between semantic and syntactic LGG, we do give a syntactic LGG algorithm that is exponentially more efficient than the best semantic LGG algorithm we have found (that of Theorem 14). First, we show that syntactic LGGs exist and are unique up to mutual syntactic subsumption (and hence up to semantic equivalence).\nTheorem 21. There exists a syntactic LGG for any AMA formula set that is syntactically subsumed by all syntactic generalizations of . Proof: Let be the conjunction of all the MA timelines that syntactically generalize while having size no larger than . As in the proof of Theorem 12, is well defined. We show that is a syntactic LGG for . First, note that syntactically generalizes because each timeline of generalizes a timeline in every member of , by the choice of . Now consider an arbitrary syntactic generalization 0 of . By the definition of syntactic subsumption, each timeline in 0 must subsume some timeline in each member of . Lemma 5 then implies that there is a timeline 0 of size no larger than that subsumes all the while being subsumed by . By our choice of , the timeline 0 must be a timeline of . It follows then that 0 syntactically subsumes , and that is a syntactic LGG of subsumed by all other syntactic generalizations of . 2\nIn general, we know that semantic and syntactic LGGs are different, though clearly the syntactic LGG is a semantic generalization and so must subsume the semantic LGG. For example, (A;B) ^(B;A), and A;B;A have a semantic LGG of A;B;A, as discussed above; but their syntactic LGG is (A;B; true) ^ (true;B;A), which subsumes A;B;A but is not subsumed by A;B;A. Even so, for MA formulas:\nProposition 22. For MA and AMA , syn is equivalent to . Proof: The forward direction is immediate since we already know syntactic subsumption implies semantic subsumption. For the reverse direction, note that implies that each timeline of subsumes —thus since is a single timeline each timeline in subsumes “some timeline” in which is the definition of syntactic subsumption. 2 Proposition 23. Any syntactic AMA LGG for an MA formula set is also a semantic LGG for . Proof: Now, consider a syntactic LGG for . Proposition 22 implies that is a semantic generalization of . Consider any semantic LGG 0 of . We show that 0 to conclude that is a semantic LGG for . Proposition 22 implies that 0 syntactically subsumes . It follows that 0 ^ syntactically subsumes . But, 0 ^ is syntactically subsumed by , which is a syntactic LGG of —it follows that 0 ^ syntactically subsumes , or would not be a least syntactic generalization of . But then ( 0 ^ ), which implies 0, as desired. 2 We note that the stronger result stating that a formula is a syntactic LGG of a set of MA formulas if and only if it is a semantic LGG of is not an immediate consequence of our results above. At\nFERN, GIVAN, & SISKIND\nfirst examination, the strengthening appears trivial, given the equivalence of and syn for MA . However, being semantically least is not necessarily a stronger condition than being syntactically least—we have not ruled out the possibility that a semantically least generalization may syntactically subsume another generalization that is semantically (but not syntactically) equivalent. (This question is open, as we have not found an example of this phenomenon either.)\nProposition 23 together with Theorem 21 have the nice consequence for our learning approach that the syntactic LGG of two AMA formulas is a semantic LGG of those formulas, as long as the original formulas are themselves syntactic LGGs of sets of MA timelines. Because our learning approach starts with training examples that are converted to MA timelines using the LGCF operation, the syntactic LGGs computed (whether combining all the training examples at once, or incrementally computing syntactic LGGs of parts of the training data) are always syntactic LGGs of sets of MA timelines and hence are also semantic LGGs, in spite of the fact that syntactic subsumption is weaker than semantic subsumption. We note, however, that the resulting semantic LGGs may be considerably larger than the smallest semantic LGG (which may not be a syntactic LGG at all).\nUsing Proposition 23, we now show that we cannot hope for a polynomial-time syntactic LGG algorithm.\nTheorem 24. The smallest syntactic LGG of two MA formulas can be exponentially large.\nProof: Suppose there is always a syntactic LGG of two MA formulas that is not exponentially large. Since by Proposition 23 each such formula is also a semantic LGG, there is always a semantic LGG of two MA formulas that is not exponentially large. This contradicts Theorem 17. 2\nWhile this is discouraging, we have an algorithm for the syntactic LGG whose time complexity matches this lower-bound, unlike the semantic LGG case, where the best algorithm we have is doubly exponential in the worst case. Theorem 14 yields an exponential time method for computing the semantic LGG of a set of MA timelines —since for a timeline , IS( ) = , we can simply conjoin all the timelines of IG( ). Given a set of AMA formulas, the syntactic LGG algorithm uses this method to compute the polynomially-many semantic LGGs of sets of timelines, one chosen from each input formula, and conjoins all the results. Theorem 25. The formula V i2 i IG(f 1; : : : ; ng) is a syntactic LGG of the AMA formulas 1; : : : ; n. Proof: Let be V i2 i IG(f 1; : : : ; ng). Each timeline of must subsume each i because is an output of IG on a set containing a timeline of i—thus syntactically subsumes each i. To show that is a syntactically least such formula, consider a 0 that syntactically subsumes every i. We show that syn 0 to conclude. Each timeline 0 in 0 subsumes a timeline Ti 2 i, for each i, by our assumption that i syn 0. But then by Lemma 5, 0 must subsume a member of IG(fT1; : : : ; Tng)—and that member is a timeline of —so each timeline 0 of 0 subsumes a timeline of . We conclude syn 0, as desired. 2\nThis theorem yields an algorithm that computes a syntactic AMA LGG in exponential time— pseudo-code for this method is given in Figure 9. The exponential time bound follows from the fact that there are exponentially many ways to choose 1; : : : ; m in line 5, and for each of these there are exponentially many semantic-LGG members in line 6 (since the i are all MA timelines)—the product of these two exponentials is still an exponential.\nLEARNING TEMPORAL EVENTS\nThe formula returned by the algorithm shown is actually a subset of the syntactic LGG given by Theorem 25. This subset is syntactically (and hence semantically) equivalent to the formula specified by the theorem, but is possibly smaller due to the pruning achieved by the if statement in lines 7–9. A timeline is pruned from the set if it is (semantically) subsumed by any other timeline in the set (one timeline is kept from any semantically equivalent group of timelines, at random). This pruning of timelines is sound, since a timeline is pruned from the output only if it subsumes some other formula in the output—this fact allows an easy argument that the pruned formula is syntactically equivalent to (i.e. mutually syntactically subsumed by) the unpruned formula. Section 4.4.2 traces the computations of this algorithm for an example LGG calculation. We note that in our empirical evaluation discussed in Section 6, there was no cost in terms of accuracy for using the more efficient syntactic vs. semantic LGG. We know this because our learned definitions made errors in the direction of being overly specific—thus, since the semantic-LGG is at least as specific as the syntactic-LGG there would be no advantage to using the semantic algorithm.\nThe method does an exponential amount of work even if the result is small (typically because many timelines can be pruned from the output because they subsume what remains). It is still an open question as to whether there is an output-efficient algorithm for computing the syntactic AMA LGG—this problem is in coNP and we conjecture that it is coNP-complete. One route to settling this question is to determine the output complexity of semantic LGG for MA input formulas. We believe that problem also to be coNP-complete, but have not proven this; if that problem is in P, there is an output-efficient method for computing syntactic AMA LGG based on Theorem 25.\nA summary of the algorithmic complexity results from this section can be found in Table 3 in the conclusions section of this paper."
    }, {
      "heading" : "4.4 Examples: Least-General Generalization Calculations",
      "text" : "Below we work through the details of a semantic and a syntactic LGG calculation. We consider the AMA formulas = (A;B) ^ (B;A) and = A;B;A, for which the semantic LGG is A;B;A and the syntactic LGG is (A;B; true) ^ (true;B;A).\nFERN, GIVAN, & SISKIND"
    }, {
      "heading" : "4.4.1 SEMANTIC LGG EXAMPLE",
      "text" : "The first step in calculating the semantic LGG, according to the algorithm given in Figure 8, is to compute the interdigitation-specializations of the input formulas (i.e., IS( ) and IS( )). Trivially, we have that IS( ) = = A;B;A. To calculate IS( ), we must consider the possible interdigitations of , for which there are three,f hA;Bi ; hB;Bi ; hB;Ai gf hA;Bi ; hB;Ai gf hA;Bi ; hA;Ai ; hB;Ai g Each interdigitation leads to the corresponding member of IS( ) by unioning (conjoining) the states in each tuple, so IS( ) is f (A ^B);B; (A ^B);(A ^B);(A ^B);A; (A ^B) g: Lines 5–9 of the semantic LGG algorithm compute the set S, which is equal to the union of the timelines in IS( ) and IS( ), with all subsumed timelines removed. For our formulas, we see that each timeline in IS( ) is subsumed by —thus, we have that S = = A;B;A.\nAfter computing S, the algorithm returns the conjunction of timelines in IG(S), with redundant timelines removed (i.e., all subsuming timelines are removed). In our case, IG(S) = A;B;A, trivially, as there is only one timeline in S, thus the algorithm correctly computes the semantic LGG of and to be A;B;A."
    }, {
      "heading" : "4.4.2 SYNTACTIC LGG EXAMPLE",
      "text" : "The syntactic LGG algorithm, shown in Figure 9, computes a series of semantic LGGs for MA timeline sets, returning the conjunction of the results (after pruning). Line 5 of the algorithm, cycles through timeline tuples from the cross-product of the input AMA formulas. In our case the tuples in are T1 = hA;B;A; A;Bi and T2 = hA;B;A; B;Ai—for each tuple, the algorithm computes the semantic LGG of the tuple’s timelines.\nThe semantic LGG computation for each tuple uses the algorithm given in Figure 8, but the argument is always a set of MA timelines rather than AMA formulas. For this reason, lines 4– 9 are superfluous, as for an MA timeline 0, IS( 0) = 0. In the case of tuple T1, lines 4–9 of the algorithm just compute S = fA;B;A; A;Bg. It remains to compute the interdigitationgeneralizations of S (i.e., IG(S)), returning the conjunction of those timelines after pruning (lines 10–15 in Figure 8). The set of all interdigitations of S are,f hA;Ai ; hB;Ai ; hB;Bi ; hB;Ai gf hA;Ai ; hB;Bi ; hB;Ai gf hA;Ai ; hA;Bi ; hB;Bi ; hB;Ai gf hA;Ai ; hA;Bi ; hB;Ai gf hA;Ai ; hA;Bi ; hA;Ai ; hB;Ai g By intersecting states in interdigitation tuples we get IG(S),f A; true;B; true; A;B; true; A; true;B; true; A; true; true; A; true;A; true g\nLEARNING TEMPORAL EVENTS\nSince the timeline A;B; true is subsumed by all timelines in IG(S), all other timelines will be pruned. Thus the semantic LGG algorithm returns A;B; true as the semantic LGG of the timelines in T1.\nNext the syntactic LGG algorithm computes the semantic LGG of the timelines in T2. Following the same steps as for T1, we find that the semantic LGG of the timelines in T2 is true;B;A. SinceA;B; true and true;B;A do not subsume one another, the set G computed by lines 5–9 of the syntactic LGG algorithm is equal to f A;B; true; true;B;A g. Thus, the algorithm computes the syntactic LGG of and to be (A;B; true) ^ (true;B;A). Note that, in this case, the syntactic LGG is more general than the semantic LGG."
    }, {
      "heading" : "5. Practical Extensions",
      "text" : "We have implemented a specific-to-general AMA learning algorithm based on the LGCF and syntactic LGG algorithms presented earlier. This implementation includes four practical extensions. The first extension aims at controlling the exponential complexity by limiting the length of the timelines we consider. Second we describe an often more efficient LGG algorithm based on a modified algorithm for computing pairwise LGGs. The third extension deals with applying our propositional algorithm to relational data, as is necessary for the application domain of visual event recognition. Fourth, we add negation into the AMA language and show how to compute the corresponding LGCFs and LGGs using our algorithms for AMA (without negation). Adding negation into AMA turns out to be crucial to achieving good performance in our experiments. We end this section with a review of the overall complexity of our implemented system."
    }, {
      "heading" : "5.1 k-AMA Least-General Generalization",
      "text" : "We have already indicated that our syntactic AMA LGG algorithm takes exponential time relative to the lengths of the timelines in the AMA input formulas. This motivates restricting the AMA language to k-AMA in practice, where formulas contain timelines with no more than k states. As k is increased the algorithm is able to output increasingly specific formulas at the cost of an exponential increase in computational time. In the visual-event–recognition experiments shown later, as we increased k, the resulting formulas became overly specific before a computational bottleneck is reached—i.e., for that application the best values of k were practically computable and the ability to limit k provided a useful language bias.\nWe use a k-cover operator in order to limit our syntactic LGG algorithm to k-AMA. A k-cover of an AMA formula is a syntactically least general k-AMA formula that syntactically subsumes the input—it is easy to show that a k-cover for a formula can be formed by conjoining all k-MA timelines that syntactically subsume the formula (i.e., that subsume any timeline in the formula) . Figure 10 gives pseudo-code for computing the k-cover of an AMA formula. It can be shown that this algorithm correctly computes a k-cover for any input AMA formula. The algorithm calculates the set of least general k-MA timelines that subsume each timeline in the input—the resulting k-MA formulas are conjoined and “redundant” timelines are pruned using a subsumption test. We note that the k-cover of an AMA formula may itself be exponentially larger than that formula; however, in practice, we have found k-covers not to exhibit undue size growth. Given the k-cover algorithm we restrict our learner to k-AMA as follows: 1) Compute thek-cover for each AMA input formula. 2) Compute the syntactic AMA LGG of the resulting kAMA formulas. 3) Return the k-cover of the resulting AMA formula. The primary bottleneck of\nFERN, GIVAN, & SISKIND\nthe original syntactic LGG algorithm is computing the exponentially large set of interdigitationgeneralizations—the k-limited algorithm limits this complexity as it only computes interdigitationgeneralizations involving k-MA timelines."
    }, {
      "heading" : "5.2 Incremental Pairwise LGG Computation",
      "text" : "Our implemented learner computes the syntactic k-AMA LGG of AMA formula sets—however, it does not directly use the algorithm describe above. Rather than compute the LGG of formula sets via a single call to the above algorithm, it is typically more efficient to break the computation into a sequence of pairwise LGG calculations. Below we describe this approach and the potential efficiency gains.\nIt is straightforward to show that for both syntactic and semantic subsumption we have that LGG( 1; : : : ; m) = LGG( 1;LGG( 2; : : : ; m)) where the i are AMA formulas. Thus, by recursively applying this transformation we can incrementally compute the LGG of m AMA formulas via a sequence of m 1 pairwise LGG calculations. Note that since the LGG operator is\nLEARNING TEMPORAL EVENTS\ncommutative and associative the final result does not depend on the order in which we process the formulas. We will refer to this incremental pairwise LGG strategy as the incremental approach and to the strategy that makes a single call to the k-AMA LGG algorithm (passing in the entire formula set) as the direct approach.\nTo simplify the discussion we will consider computing the LGG of an MA formula set —the argument can be extended easily to AMA formulas (and hence to k-AMA). Recall that the syntactic LGG algorithm of Figure 9 computes LGG( ) by conjoining timelines in IG( ) that do not subsume any of the others, eliminating subsuming timelines in a form of pruning. The incremental approach applies this pruning step after each pair of input formulas is processed—in contrast, the direct approach must compute the interdigitation-generalization of all the input formulas before any pruning can happen. The resulting savings can be substantial, and typically more than compensates for the extra effort spent checking for pruning (i.e. testing subsumption between timelines as the incremental LGG is computed). A formal approach to describing these savings can be constructed based on the observation that both\nS 2IG(f 1; 2g) IG(f g[ ) and S 2LGG( 1; 2) IG(f g[ ) can be seen to compute the LGG of [ f 1; 2g, but with the latter being possibly much cheaper to compute due to pruning. That is, LGG( 1; 2) typically contains a much smaller number of timelines than IG(f 1; 2g).\nBased on the above observations our implemented system uses the incremental approach to compute the LGG of a formula set. We now describe an optimization used in our system to speedup the computation of pairwise LGGs, compared to directly running the algorithm in Figure 9. Given a pair of AMA formulas 1 = 1;1 ^ ^ 1;m and 2 = 2;1 ^ ^ 2;n, let be their syntactic LGG obtained by running the algorithm in Figure 9. The algorithm constructs by computing LGGs of all MA timeline pairs (i.e., LGG( 1;i; 2;j) for all i and j) and conjoining the results while removing subsuming timelines. It turns out that we can often avoid computing many of these MA LGGs. To see this consider the case when there exists i and j such that 1;i 2;j , we know LGG( 1;i; 2;j) = 2;j which tells us that that 2;j will be considered for inclusion into (it may be pruned). Furthermore we know that any other LGG involving 2;j will subsume 2;j and thus will be pruned from . This shows that we need not compute any MA LGGs involving 2;j , rather we need only to consider adding 2;j when constructing .\nThe above observation leads to a modified algorithm (used in our system) for computing the syntactic LGG of a pair of AMA formulas. The new algorithm only computes LGGs between non-subsuming timelines. Given AMA formulas 1 and 2, the modified algorithm proceeds as follows: 1) Compute the subsumer set S = f 2 1 j 9 0 2 2 s:t: 0 g [ f 2 2 j 9 0 2 1 s:t: 0 g. 2) Let AMA 01 ( 02) be the result of removing timelines from 1 ( 2) that are in S. 3) Let 0 be the syntactic LGG of 01 and 02 computed by running the algorithm in Figure 9 (if either 0i is empty then 0 will be empty). 4) Let S0 be the conjunction of timelines in S that do not subsume any timeline in 0. 5) Return = 0 ^S0. This method avoids computing MA LGGs involving subsuming timelines (an exponential operation) at the cost of performing polynomially many MA subsumption tests (a polynomial operation). We have noticed a significant advantage to using this procedure in our experiments. In particular, the advantage tends to grow as we process more training examples. This is due to the fact that as we incrementally process training examples the resulting formulas become more general—thus, these more general formulas are likely to have more subsuming timelines. In the best case when 1 syn 2 (i.e., all timelines in 2 are subsuming), we see that step 2 produces an empty formula and thus step 3 (the expensive step) performs no work—in this case we return the set S = 2 as desired.\nFERN, GIVAN, & SISKIND"
    }, {
      "heading" : "5.3 Relational Data",
      "text" : "LEONARD produces relational models that involve objects and (force dynamic) relations between those objects. Thus event definitions include variables to allow generalization over objects. For example, a definition for PICKUP(x; y; z) recognizes both PICKUP(hand;block; table) as well as PICKUP(man;box;floor). Despite the fact that our k-AMA learning algorithm is propositional, we are still able to use it to learn relational definitions.\nWe take a straightforward object-correspondence approach to relational learning. We view the models output by LEONARD as containing relations applied to constants. Since we (currently) support only supervised learning, we have a set of distinct training examples for each event type. There is an implicit correspondence between the objects filling the same role across the different training models for a given type. For example, models showing PICKUP(hand;block; table) and PICKUP(man;box;floor) have implicit correspondences given by hhand;mani, hblock;boxi, and htable;floori. We outline two relational learning methods that differ in how much objectcorrespondence information they require as part of the training data."
    }, {
      "heading" : "5.3.1 COMPLETE OBJECT CORRESPONDENCE",
      "text" : "This first approach assumes that a complete object correspondence is given, as input, along with the training examples. Given such information, we can propositionalize the training models by replacing corresponding objects with unique constants. The propositionalized models are then given to our propositional k-AMA learning algorithm which returns a propositional k-AMA formula. We then lift this propositional formula by replacing each constant with a distinct variable. Lavrac et al. (1991) has taken a similar approach."
    }, {
      "heading" : "5.3.2 PARTIAL OBJECT CORRESPONDENCE",
      "text" : "The above approach assumes complete object-correspondence information. While it is sometimes possible to provide all correspondences (for example, by color-coding objects that fill identical roles when recording training movies), such information is not always available. When only a partial object correspondence (or even none at all) is available, we can automatically complete the correspondence and apply the above technique.\nFor the moment, assume that we have an evaluation function that takes two relational models and a candidate object correspondence, as input, and yields an evaluation of correspondence quality. Given a set of training examples with missing object correspondences, we perform a greedy search for the best set of object-correspondence completions over the models. Our method works by storing a set P of propositionalized training examples (initially empty) and a set U of unpropositionalized training examples (initially the entire training set). For the first step, when P is empty, we evaluate all pairs of examples from U , under all possible correspondences, select the pair that yields the highest score, remove the examples involved in that pair from U , propositionalize them according to the best correspondence, and add them to P . For each subsequent step, we use the previously computed values of all pairs of examples, one from U and one from P , under all possible correspondences. We then select the example from U and correspondence that yields the highest average score relative to all models in P—this example is removed from U , propositionalized according to the winning correspondence, and added to P . For a fixed number of objects, the effort expended here is polynomial in the size of the training set; however, if the number of objects b that appear in a training example is allowed to grow, the number of correspondences that must be considered grows\nLEARNING TEMPORAL EVENTS\nas bb. For this reason, it is important that the events involved manipulate only a modest number of objects.\nOur evaluation function is based on the intuition that object roles for visual events (as well as events from other domains) can often be inferred by considering the changes between the initial and final moments of an event. Specifically, given two models and an object correspondence, we first propositionalize the models according to the correspondence. Next, we compute ADD and DELETE lists for each model. The ADD list is the set of propositions that are true at the final moment but not the initial moment. The DELETE list is the set of propositions that are true at the initial moment but not the final moment. These add and delete lists are motivated by STRIPS action representations (Fikes & Nilsson, 1971). Given such ADDi and DELETEi lists for models 1 and 2, the evaluation function returns the sum of the cardinalities of ADD1 \\ ADD2 and DELETE1 \\ DELETE2. This heuristic measures the similarity between the ADD and DELETE lists of the two models. The intuition behind this heuristic is similar to the intuition behind the STRIPS actiondescription language—i.e., that most of the differences between the initial and final moments of an event occurrence are related to the target event, and that event effects can be described by ADD and DELETE lists. We have found that this evaluation function works well in the visual-event domain.\nNote, that when full object correspondences are given to the learner (rather than automatically extracted by the learner), the training examples are interpreted as specifying that the target event took place as well as which objects filled the various event roles (e.g., PICKUP(a,b,c)). Rather, when no object correspondences are provided the training examples are interpreted as specifying the existence of a target event occurrence but do not specify which objects fill the roles (i.e., the training example is labeled by PICKUP rather than PICKUP(a,b,c)). Accordingly, the rules learned when no correspondences are provided only allow us to infer that a target event occurred and not which objects filled the event roles. For example when object correspondences are manually provided the learner might produce the rule, PICKUP(x; y; z) 4= \" (SUPPORTS(z; y) ^ CONTACTS(z; y));(SUPPORTS(x; y) ^ ATTACHED(x; y)) # whereas a learner that automatically extracts the correspondences would instead produce the rule,\nPICKUP 4= \" (SUPPORTS(z; y) ^ CONTACTS(z; y));(SUPPORTS(x; y) ^ ATTACHED(x; y)) #\nIts worth noting, however, that upon producing the second rule the availability of a single training example with correspondence information allows the learner to determine the roles of the variables, upon which it can output the first rule. Thus, under the assumption that the learner can reliably extract object correspondences, we need not label all training examples with correspondence information in order to obtain definitions that explicitly recognize object roles."
    }, {
      "heading" : "5.4 Negative Information",
      "text" : "The AMA language does not allow negated propositions. Negation, however, is sometimes necessary to adequately define an event type. In this section, we consider the language AMA , which is a superset of AMA, with the addition of negated propositions. We first give the syntax and semantics of AMA , and extend AMA syntactic subsumption to AMA . Next, we describe our approach to\nFERN, GIVAN, & SISKIND\nlearning AMA formulas using the above-presented algorithms for AMA. We show that our approach correctly computes the AMA LGCF and the syntactic AMA LGG. Finally, we discuss an alternative, related approach to adding negation designed to reduce the overfitting that appears to result from the full consideration of negated propositions.\nAMA has the same syntax as AMA, only with a new grammar for building states with negated propositions:\nliteral ::= true j prop j :3prop state ::= literal j literal ^ state\nwhere prop is any primitive proposition. The semantics of AMA are the same as for AMA except for state satisfaction. A positive literal P (negative literal :3P ) is satisfied by model hM; Ii iff M [x℄ assigns P true (false), for every x 2 I .10 A state l1 ^ ^ lm is satisfied by model hM; Ii iff each literal li is satisfied by hM; Ii. Subsumption. An important difference between AMA and AMA is that Proposition 2, establishing the existence of witnessing interdigitations to MA subsumption, is no longer true for MA . In other words, if we have two timelines 1; 2 2 AMA , such that 1 2, there need not be an interdigitation that witnesses 1 2. To see this, consider the AMA timelines: 1 = (a ^ b ^ ); b; a; b; (a ^ b ^ : ) 2 = b; a; ; a; b; a;: ; a; b We can then argue:\n1. There is no interdigitation that witnesses 1 2. To see this, first show that, in any such witness, the second and fourth states of 1 (each just “b”) must interdigitate to align with either the first and fifth, or the fifth and ninth states of 2 (also, each just “b”). But in either of these cases, the third state of 1 will interdigitate with states of 2 that do not subsume it.\n2. Even so, we still have that 1 2. To see this, consider any model hM; Ii that satisfies 1. There must be an interval [i1; i2℄ within I such that hM; [i1; i2℄i satisfies the third state of 1, that is the state “a.” We have two cases:\n(a) The proposition is true at some point in hM; [i1; i2℄i. Then, one can verify that hM; Ii satisfies both 1 and 2 in the following alignment: 1 = (a ^ b ^ ); b; a; b; (a ^ b ^ : ) 2 = b; a; ; a; b; a;: ; a; b\n10. We note that it is important that we use the notation :3P rather than just :P . In event-logic, the formula :P is satisfied by a model whenever P is false as some instant in the model. Rather, event-logic interprets :3P as indicating that P is never true in the model (as defined above). Notice that the first form of negation does not yield a liquid property—i.e., :P can be true along an interval but not necessarily during all subintervals. The second form of negation, however, does yield a liquid property provided that P is liquid. This is important to our learning algorithms, since they all assume states are built from liquid properties.\nLEARNING TEMPORAL EVENTS\n(b) The proposition is false everywhere in hM; [i1; i2℄i. Then, one can verify that hM; Ii satisfies both 1 and 2 in the following alignment: 1 = (a ^ b ^ ); b; a; b; (a ^ b ^ : ) 2 = b; a; ; a; b; a;: ; a; b\nIt follows that 1 2. In light of such examples, we conjecture that it is computationally hard to compute AMA\nsubsumption even between timelines. For this reason, we extend our definition of syntactic subsumption to AMA in a way that provides a clearly tractable subsumption test analogous to that discussed above for AMA.\nDefinition 6. AMA 1 is syntactically subsumed by AMA 2 (written 1 syn 2) iff for each timeline 2 2 2, there is a timeline 1 2 1 such that there is a witnessing interdigitation for 1 2. The difference between the definition here and the previous one for AMA is that here we only need to test for witnessing interdigitations between timelines rather than subsumption between timelines. For AMA formulas, we note that the new and old definition are equivalent (due to Proposition 2); however, for AMA the new definition is weaker, and will result in more general LGG formulas. As one might expect, AMA syntactic subsumption implies semantic subsumption and can be tested in polynomial-time using the subsumption graph described in Lemma 8 to test for witnesses.\nLearning. Rather than design new LGCF and LGG algorithms to directly handle AMA , we instead compute these functions indirectly by applying our algorithms for AMA to a transformed problem. Intuitively, we do this by adding new propositions to our models (i.e., the training examples) that represent the proposition negations. Assume that the training-example models are over the set of propositions P = fp1; : : : ; png. We introduce a new set P = f p1; : : : ; png of propositions and use these to construct new training models over P [ P by assigning true to pi at a time in a model iff pi is false in the model at that time. After forming the new set of training models (each with twice as many propositions as the original models) we compute the least general AMA formula that covers the new models (by computing the AMA LGCFs and applying the syntactic AMA LGG algorithm), resulting in an AMA formula over the propositions P [P . Finally we replace each pi in with :3pi resulting in an AMA formula 0 over propositions in P—it turns out that under syntactic subsumption 0 is the the least general AMA formula that covers the original training models.\nWe now show the correctness of the above transformational approach to computing the AMA LGCF and syntactic LGG. First, we introduce some notation. Let M be the set of all models overP . Let M be the set of models over P [ P , such that at any time, for each i, exactly one of pi and pi is true. Let T be the following mapping from M to M: for hM; Ii 2 M, T [hM; Ii℄ is the unique hM 0; Ii 2 M such that for all j 2 I and all i, M 0(j) assigns pi true iff M(j) assigns pi true. Notice that the inverse of T is a functional mapping from M to M. Our approach to handling negation using purely AMA algorithms begins by applying T to the original training models. In what follows, we consider AMA formulas over the propositions in P , and AMA formulas over the propositions in P [ P .\nLet F be a mapping from AMA to AMA where for 2 AMA , F [ ℄ is an AMA formula identical to except that each :3pi in is replaced with pi. Notice that the inverse of F is a func-\nFERN, GIVAN, & SISKIND\ntion from AMA to AMA and corresponds to the final step in our approach described above. The following lemma shows that there is a one-to-one correspondence between satisfaction of AMA formulas by models in M and satisfaction of AMA formulas by models in M. Lemma 26. For any model hM; Ii 2 M and any 2 AMA , covers hM; Ii iff F [ ℄ coversT [hM; Ii℄. Using this lemma, it is straightforward to show that our transformational approach computes the AMA LGCF under semantic subsumption (and hence under syntactic subsumption). Proposition 27. For any hM; Ii 2 M, let be the AMA LGCF of the model T [hM; Ii℄. Then,F 1[ ℄ is the unique AMA LGCF of hM; Ii, up to equivalence. Proof: We know that covers T [hM; Ii℄, therefore by Lemma 26 we know that F 1[ ℄ covershM; Ii. We now show that F 1[ ℄ is the least-general formula in AMA that covers hM; Ii. For the sake of contradiction assume that some 0 2 AMA covers hM; Ii but that 0 < F 1[ ℄. It follows that there is some model hM 0; I 0i that is covered by F 1[ ℄ but not by 0. By Lemma 26 we have that F [ 0℄ covers T [hM; Ii℄ and since is the unique AMA LGCF of T [hM; Ii℄, up to equivalence, we have that F [ 0℄. However, we also have that T [hM 0; I 0i℄ is covered by but not by F [ 0℄ which gives a contradiction. Thus, no such 0 can exist. It follows that is an AMA LGCF. The uniqueness of the AMA LGCF up to equivalence follows because AMA is closed under conjunction; so that if there were any two non-equivalent LGCF formulas, they could be conjoined to get an LGCF formula strictly less than one of them. 2\nBelow we use the fact that the F operator preserves syntactic subsumption. In particular, given two MA timelines 1; 2, it is clear that any witnessing interdigitation of 1 2 can be trivially converted into a witness for F [ 1℄ F [ 2℄ (and vice versa). Since syntactic subsumption is defined in terms of witnessing interdigitations, it follows that for any 1; 2 2 AMA , ( 1 syn 2) iff(F [ 1℄ syn F [ 2℄). Using this property, it is straightforward to show how to compute the syntactic AMA LGG using the syntactic AMA LGG algorithm. Proposition 28. For any AMA formulas 1; : : : ; m, let be the syntactic AMA LGG offF [ 1℄; : : : ; F [ m℄g. Then, F 1[ ℄ is the unique syntactic AMA LGG of f 1; : : : ; mg. Proof: We know that for each i, F [ i℄ syn —thus, since F 1 preserves syntactic subsumption, we have that for each i, i syn F 1[ ℄. This shows that F 1[ ℄ is a generalization of the inputs. We now show that F 1[ ℄ is the least such formula. For the sake of contradiction assume thatF 1[ ℄ is not least. It follows that there must be a 0 2 AMA such that 0 <syn F 1[ ℄ and for each i, i syn 0. Combining this with the fact that F preserves syntactic subsumption, we get that F [ 0℄ <syn and for each i, F [ i℄ F [ 0℄. But this contradicts the fact that is an LGG; so we must have that F 1[ ℄ is a syntactic AMA LGG. As argued elsewhere, the uniqueness of this LGG follows from the fact that AMA is closed under conjunction. 2\nThese propositions ensure the correctness of our transformational approach to computing the syntactic LGG within AMA . For the case of semantic subsumption, the transformational approach does not correctly compute the AMA LGG. To see this, recall that above we have given two timelines 1; 2 2 AMA , such that 1 2, but there is no witnessing interdigitation. Clearly under\nLEARNING TEMPORAL EVENTS\nsemantic subsumption, the AMA LGG of 1 and 2 is 2. However, the semantic AMA LGG ofF [ 1℄ and F [ 2℄ is not F [ 2℄. The reason for this is that since there is no witness to F [ 1℄ F [ 2℄ (and the F [ i℄ are MA timelines), we know by Proposition 2 that F [ 1℄ 6 F [ 2℄. Thus, F [ 2℄ cannot be returned as the AMA LGG, since it does not subsume both input formulas—this shows that the transformational approach will not return 2 = F 1[F [ 2℄℄. Here, the transformational approach will produce an AMA formula that is more general than 2.\nOn the computational side, we note that, since the transformational approach doubles the number of propositions in the training data, algorithms specifically designed for AMA may be more efficient. Such algorithms might leverage the special structure of the transformed examples that our AMA algorithms ignore—in particular, that exactly one of pi or pi is true at any time. Boundary Negation. In our experiments, we actually compare two methods for assigning truth values to the pi propositions in the training data models. The first method, called full negation, assigns truth values as described above, yielding the syntactically least-general AMA formula that covers the examples. We found, however, that using full negation often results in learning overly specific formulas. To help alleviate this problem, our second method places a bias on the use of negation. Our choice of bias is inspired by the idea that, often, much of the useful information for characterizing an event type is in its pre- and post-conditions. The second method, called boundary negation, differs from full negation in that it only allows pi to be true in the initial and final moments of a model (and then only if pi is false). pi must be false at all other times. That is, we only allow “informative” negative information at the beginnings and ends of the training examples. We have found that boundary negation provides a good trade-off between no negation (i.e., AMA), which often produces overly general results, and full negation (i.e., AMA ), which often produces overly specific and much more complicated results."
    }, {
      "heading" : "5.5 Overall Complexity and Scalability",
      "text" : "We now review the overall complexity of our visual event learning component and discuss some scalability issues. Given a training set of temporal models (i.e., a set of movies), our system does the following: 1) Propositionalize the training models, translating negation as descried in Section 5.4. 2) Compute the LGCF of each propositional model. 3) Compute the k-AMA LGG of the LGCFs. 4) Return a lifted (variablized) version of the LGG. Steps two and four require little computational overhead, being linear in the sizes of the input and output respectively. Steps one and three are the computational bottlenecks of the system—they encompass the inherent exponential complexity arising from the relational and temporal problem structure.\nStep One. Recall from Section 5.3.2 that our system allows the user to annotate training examples with object correspondence information. Our technique for propositionalizing the models was shown to be exponential in the number of unannotated objects in a training example. Thus, our system requires that the number of objects be relatively small or that correspondence information be given for all but a small number of objects. Often the event class definitions we are interested in do not involve a large number of objects. When this is true, in a controlled learning setting we can manage the relational complexity by generating training examples with only a small number (or zero) irrelevant objects. This is the case for all of the domains studied empirically in this paper.\nIn a less controlled setting, the number of unannotated objects may prohibit the use of our correspondence technique—there are at least three ways one might proceed. First, we can try to\nFERN, GIVAN, & SISKIND\ndevelop efficient domain-specific techniques for filtering objects and finding correspondences. That is, for a particular problem it may be possible to construct a simple filter that removes irrelevant objects from consideration and then to find correspondences for any remaining objects. Second, we can provide the learning algorithm with a set of hand-coded first-order formulas, defining a set of domain-specific features (e.g., in the spirit of Roth & Yih, 2001). These features can then be used to propositionalize the training instances. Third, we can draw upon ideas from relational learning to design a “truly first-order” version of the k-AMA learning algorithm. For example, one could use existing first-order generalization algorithms to generalize relational state descriptions. Effectively this approach pushes the object correspondence problem into the k-AMA learning algorithm rather than treating it as a preprocessing step. Since it is well known that computing first-order LGGs can be intractable (Plotkin, 1971), practical generalization algorithms retain tractability by constraining the LGGs in various ways (e.g., Muggleton & Feng, 1992; Morales, 1997).\nStep Three. Our system uses the ideas of Section 5.2 to speedup the k-AMA LGG computation for a set of training data. Nevertheless, the computational complexity is still exponential in k—thus, in practice we are restricted to using relatively small values of k. While this restriction did not limit performance in our visual event experiments, we expect that it will limit the direct applicability of our system to more complex problems. In particular, many event types of interest may not be adequately represented via k-AMA when k is small. Such event types, however, often contain significant hierarchical structure—i.e., they can be decomposed into a set of “short” sub-event types. An interesting research direction is to consider using our k-AMA learner as a component of a hierarchical learning system—there it could be used to learn k-AMA sub-event types. We note that our learner alone cannot be applied hierarchically because it requires liquid primitive events, but learns non-liquid composite event types. Further work is required (and intended) to construct a hierarchical learner based perhaps on non-liquid AMA learning.\nFinally, recall that to compute the LGG of m examples, our system uses a sequence of m 1 pairwise LGG calculations. For a fixed k, each pairwise calculation takes polynomial time. However, since the size of a pairwise LGG can grow by at least a constant factor with respect to the inputs, the worst-case time complexity of computing the sequence of m 1 pairwise LGGs is exponential in m. We expect that this worst case will primarily occur when the target event type does not have a compact k-AMA representation—in which case a hierarchical approach as described above is more appropriate. When there is a compact representation, our empirical experience indicates that such growth does not occur—in particular, each pairwise LGG tends to yield significant pruning. For such problems, reasonable assumptions about the amount of pruning11 imply that the time complexity of computing the sequence of m 1 pairwise LGGs is polynomial in m."
    }, {
      "heading" : "6. Experiments",
      "text" : ""
    }, {
      "heading" : "6.1 Data Set",
      "text" : "Our data set contains examples of 7 different event types: pick up, put down, stack, unstack, move, assemble, and disassemble. Each of these involve a hand and two to three blocks. For a detailed description and sample video sequences of these event types, see Siskind (2001). Key frames from sample video sequences of these event types are shown in Figure 11. The results of segmentation,\n11. In particular, assume that the size of a pairwise k-AMA LGG is “usually” bounded by the sizes of the k-covers of the inputs.\nLEARNING TEMPORAL EVENTS\ntracking, and model reconstruction are overlaid on the video frames. We recorded 30 movies for each of the 7 event classes resulting in a total of 210 movies comprising 11946 frames.12 We replaced one assemble movie (assemble-left-qobi-04), with a duplicate copy of another (assembleleft-qobi-11) because of segmentation and tracking errors.\nSome of the event classes are hierarchical in that occurrences of events in one class contain occurrences of events in one or more simpler classes. For example, a movie depicting a MOVE(a; b; ; d) event (i.e. a moves b from to d) contains subintervals where PICKUP(a; b; ) and PUTDOWN(a; b; d) events occur. In our experiments, when learning the definition of an event class only the movies for that event class are used in training. We do not train on movies for other event classes that may also depict an occurrence of the event class being learned as a subevent. However, in evaluating the learned definitions, we wish to detect both the events that correspond to an entire movie as well as subevents that correspond to portions of that movie. For example, given a movie depicting a MOVE(a; b; ; d) event, we wish to detect not only the MOVE(a; b; ; d) event but also the PICKUP(a; b; ) and PUTDOWN(a; b; d) subevents as well. For each movie type in our data set, we have a set of intended events and subevents that should be detected. If a definition does not detect an intended event, we deem the error a false negative. If a definition detects an unintended event, we deem the error a false positive. For example, if a movie depicts a MOVE(a; b; ; d) event, the intended events are MOVE(a; b; ; d), PICKUP(a; b; ), and PUTDOWN(a; b; ). If the definition for pick up detects the occurrence of PICKUP( ; b; a) and PICKUP(b; a; ), but not PICKUP(a; b; ), it will be charged two false positives as well as one false negative. We evaluate our definitions in terms of false positive and negative rates as describe below."
    }, {
      "heading" : "6.2 Experimental Procedure",
      "text" : "For each event type, we evaluate the k-AMA learning algorithm using a leave-one-movie-out crossvalidation technique with training-set sampling. The parameters to our learning algorithm are k and the degree D of negative information used. The value of D is either P, for positive propositions only, BN, for boundary negation, or N, for full negation. The parameters to our evaluation procedure include the target event type E and the training-set size N . Given this information, the evaluation proceeds as follows: For each movie M (the held-out movie) from the 210 movies, apply the kAMA learning algorithm to a randomly drawn training sample of N movies from the 30 movies of event type E (or 29 movies if M is one of the 30). Use LEONARD to detect all occurrences of the learned event definition in M . Based on E and the event type of M , record the number of false positives and false negatives in M , as detected by LEONARD. Let FP and FN be the total number of false positives and false negatives observed over all 210 held-out movies respectively. Repeat the entire process of calculating FP and FN 10 times and record the averages as FP and FN.13\nSince some event types occur more frequently in our data than others because simpler events occur as subevents of more complex events but not vice versa, we do not report FP and FN directly. Instead, we normalize FP by dividing by the total number of times LEONARD detected the target event correctly or incorrectly within all 210 movies and we normalize FN by dividing by the total 12. The source code and all of the data used for these experiments are available as Online Appendix 1, and also from\nftp://ftp.ecn.purdue.edu/qobi/ama.tar.Z. 13. While we did not record the times for our experiments, the system is fast enough to give live demos when N = 29\nand k = 3 with boundary negation, giving the best results we show here (though we don’t typically record 29 training videos in a live demo for other reasons). Some of the less favorable parameter settings (particularly k = 4 and full negation) can take a (real-time) hour or so.\nLEARNING TEMPORAL EVENTS\nnumber of correct occurrences of the target event within all 210 movies (i.e., the human assessment of the number of occurrences of the target event). The normalized value of FP estimates the probability that the target event did not occur given that it was predicted to occur, while the normalized value of FN estimates the probability that the event was not predicted to occur given that it did occur."
    }, {
      "heading" : "6.3 Results",
      "text" : "To evaluate our k-AMA learning approach, we ran leave-one-movie-out experiments, as described above, for varying k, D, andN . The 210 example movies were recorded with color-coded objects to provide complete object-correspondence information. We compared our learned event definitions to the performance of two sets of hand-coded definitions. The first set HD1 of hand-coded definitions appeared in Siskind (2001). In response to subsequent deeper understanding of the behavior of LEONARD’s model-reconstruction methods, we manually revised these definitions to yield another set HD2 of hand-coded definitions that gives a significantly better FN performance at some cost in FP performance. Appendix C gives the event definitions in HD1 and HD2 along with a set of machine-generated definitions, produced by the k-AMA learning algorithm, given all training data for k = 30 and D = BN."
    }, {
      "heading" : "6.3.1 OBJECT CORRESPONDENCE",
      "text" : "To evaluate our algorithm for finding object correspondences, we ignored the correspondence information provided by color coding and applied the algorithm to all training models for each event type. The algorithm selected the correct correspondence for all 210 training models. Thus, for this data set, the learning results when no correspondence information is given will be identical to those where the correspondences are manually provided, except that, in the first case, the rules will not specify particular object roles, as discussed in section 5.3.2. Since our evaluation procedure uses role information, the rest of our experiments use the manual correspondence information, provided by color-coding, rather than computing it.\nWhile our correspondence technique was perfect in these experiments, it may not be suited to some event types. Furthermore, it is likely to produce more errors as noise levels increase. Since correspondence errors represent a form of noise and our learner makes no special provisions for handling noise, the results are likely to be poor when such errors are common. For example, in the worst case, it is possible for a single extremely noisy example to cause the the LGG to be trivial (i.e., the formula true). In such cases, we will be forced to improve the noise tolerance of our learner. 6.3.2 VARYING k The first three rows of Table 1 show the FP and FN values for all 7 event types for k 2 f2; 3; 4g,N = 29 (the maximum), and D = BN. Similar trends were found for D = P and D = N. The general trend is that, as k increases, FP decreases or remains the same and FN increases or remains the same. Such a trend is a consequence of our k-cover approach. This is because, as k increases, the k-AMA language contains strictly more formulas. Thus for k1 > k2, the k1-cover of a formula will never be more general than the k2-cover. This strongly suggests, but does not prove, that FP will be non-increasing with k and FN will be non-decreasing with k.\nOur results show that 2-AMA is overly general for put down and assemble, i.e. it gives high FP. In contrast, 3-AMA achieves FP = 0 for each event type, but pays a penalty in FN compared\nto 2-AMA. Since 3-AMA achieves FP = 0, there is likely no advantage in moving to k-AMA fork > 3. That is, the expected result is for FN to become larger. This effect is demonstrated for4-AMA in the table."
    }, {
      "heading" : "6.3.3 VARYING D",
      "text" : "Rows four through six of Table 1 show FP and FN for all 7 event types forD 2 fP;BN;Ng,N = 29, and k = 3. Similar trends were observed for other values of k. The general trend is that, as the degree of negative information increases, the learned event definitions become more specific. In other words, FP decreases and FN increases. This makes sense since, as more negative information is added to the training models, more specific structure can be found in the data and exploited by the k-AMA formulas. We can see that, with D = P, the definitions for pick up and put down are overly general, as they produce high FP. Alternatively, with D = N, the learned definitions are overly specific, giving FP = 0, at the cost of high FN. In these experiments, as well as others, we have found that D = BN yields the best of both worlds: FP = 0 for all event types and lower FN than achieved with D = N.\nExperiments not shown here have demonstrated that, without negation for pick up and put down, we can increase k arbitrarily, in an attempt to specialize the learned definitions, and never significantly reduce FP. This indicates that negative information plays a particularly important role in constructing definitions for these event types.\nLEARNING TEMPORAL EVENTS"
    }, {
      "heading" : "6.3.4 COMPARISON TO HAND-CODED DEFINITIONS",
      "text" : "The bottom two rows of table 1 show the results for HD1 and HD2. We have not yet attempted to automatically select the parameters for learning (i.e. k and D). Rather, here we focus on comparing the hand-coded definitions to the parameter set that we judged to be best performing across all event types. We believe, however, that these parameters could be selected reliably using cross-validation techniques applied to a larger data set. In that case, the parameters would be selected on a perevent-type basis and would likely result in an even more favorable comparison to the hand-coded definitions.\nThe results show that the learned definitions significantly outperform HD1 on the current data set. The HD1 definitions were found to produce a large number of false negatives on the current data set. Notice that, although HD2 produces significantly fewer false negatives for all event types, it produces more false positives for pick up and put down. This is because the hand definitions utilize pick up and put down as macros for defining the other events.\nThe performance of the learned definitions is competitive with the performance of HD2. The main differences in performance are: (a) for pick up and put down, the learned and HD2 definitions achieve nearly the same FN but the learned definitions achieve FP = 0 whereas HD2 has significant FP, (b) for unstack and disassemble, the learned definitions perform moderately worse than HD2 with respect to FN, and (c) the learned definitions perform significantly better than HD2 on assemble events.\nWe conjecture that further manual revision could improve HD2 to perform as well as (and perhaps better than) the learned definitions for every event class. Nonetheless, we view this experiment as promising, as it demonstrates that our learning technique is able to compete with, and sometimes outperform, significant hand-coding efforts by one of the authors."
    }, {
      "heading" : "6.3.5 VARYING N",
      "text" : "It is of practical interest to know how training-set size affects our algorithm’s performance. For this application, it is important that our method work well with fairly small data sets, as it can be tedious to collect event data. Table 2 shows the FN of our learning algorithm for each event type, as N is reduced from 29 to 5. For these experiments, we used k = 3 and D = BN. Note that FP = 0 for all event types and all N and hence is not shown. We expect FN to increase as N is decreased, since, with specific-to-general learning, more data yields more-general definitions. Generally, FN is flat for N > 20, increases slowly for 10 < N < 20, and increases abruptly for 5 < N < 10. We also see that, for several event types, FN decreases slowly, as N is increased from 20 to 29. This indicates that a larger data set might yield improved results for those event types."
    }, {
      "heading" : "6.3.6 PERSPICUITY OF LEARNED DEFINITIONS",
      "text" : "One motivation for using a logic-based event representation is to support perspicuity—in this respect our results are mixed. We note that perspicuity is a fuzzy and subjective concept. Realizing this, we will say that an event definition is perspicuous if most humans with knowledge of the language would find the definition to be “natural.” Here, we do not assume the human has a detailed knowledge of the model-reconstruction process that our learner is trying to fit. Adding that assumption would presumably make the definitions qualify as more perspicuous, as many of the complex features of the learned definitions appear in fact to be due to idiosyncrasies of the model-reconstruction process. In this sense, we are evaluating the perspicuity of the output of the entire system, not just\nFERN, GIVAN, & SISKIND\nof the learner itself, so that a key route to improving perspicuity in this sense would be to improve the intuitive properties of the model-reconstruction output without any change to the learner.\nWhile the learned and hand-coded definitions are similar with respect to accuracy, typically the learned definitions are much less perspicuous. For our simplest event types, however, the learned definitions are arguably perspicuous. Below we look at this issue in more detail. Appendix C gives the hand-coded definitions in HD1 and HD2 along with a set of machine-generated definitions. The learned definitions correspond to the output of our k-AMA learner when run on all 30 training movies from each event type with k = 3 and D = BN (i.e., our best performing configuration with respect to accuracy).\nPerspicuous Definitions. The PICKUP(x; y; z) and PUTDOWN(x; y; z) definitions are of particular interest here since short state sequences appear adequate for representing these event types— thus, we can hope for perspicuous 3-AMA definitions. In fact, the hand-coded definitions involve short sequences. Consider the hand-coded definitions of PICKUP(x; y; z)—the definitions can roughly be viewed as 3-MA timelines of the form begin;trans;end.14 State begin asserts facts that indicate y is on z and is not being held by x and end asserts facts that indicate y is being held byx and is not on z. State trans is intended to model the fact that LEONARD’s model-reconstruction process does not always handle the transition between begin and end smoothly (so the definition begin;end does not work well). We can make similar observations for PUTDOWN(x; y; z).\nFigure 15 gives the learned 3-AMA definitions of PICKUP(x; y; z) and PUTDOWN(x; y; z)— the definitions contain six and two 3-MA timelines respectively. Since the definitions consists of multiple parallel timelines, they may at first not seem perspicuous. However, a closer examination reveals that, in each definition, there is a single timeline that is arguably perspicuous—we have placed these perspicuous timelines at the beginning of each definition. The perspicuous timelines have a natural begin;trans;end interpretation. In fact, they are practically equivalent to the definitions of PICKUP(x; y; z) and PUTDOWN(x; y; z) in HD2.15\nWith this in mind, notice that the HD2 definitions are overly general as indicated by significant false positive rates. The learned definitions, however, yield no false positives without a significant increase in false negatives. The learned definitions improve upon HD2 by essentially specializing the HD2 definitions (i.e., the perspicuous timelines) by conjoining them with the non-perspicuous timelines. While these non-perspicuous timelines are often not intuitive, they capture patterns in the events that help rule out non-events. For example, in the learned definition of PICKUP(x; y; z) some of the non-perspicuous timelines indicate that ATTACHED(y; z) is true during the transition period of the event. Such an attachment relationship does not make intuitive sense. Rather, it represents a systematic error made by the model reconstruction process for pick up events.\nIn summary, we see that the learned definitions of PICKUP(x; y; z) and PUTDOWN(x; y; z) each contain a perspicuous timeline and one or more non-perspicuous timelines. The perspicuous timelines give an intuitive definition of the events, whereas the non-perspicuous timelines capture nonintuitive aspects of the events and model reconstruction process that are important in practice. We note that, for experienced users, the primary difficulty of hand-coding definitions for LEONARD is\n14. Note that the event-logic definition for PICKUP(x; y; z) in HD2 is written in a more compact form than 3-MA, but this definition can be converted to 3-MA (and hence 3-AMA). Rather, HD1 cannot be translated exactly to 3-MA since it uses disjunction—it is the disjunction of two 3-MA timelines. 15. The primary difference is that the HD2 definitions contain more negated propositions. The learner only considers a proposition and its negation if the proposition is true at some point during the training movies. Many of the negated propositions in HD2 never appear positively, thus they are not included in the learned definitions.\nLEARNING TEMPORAL EVENTS\nto determining which non-perspicuous properties must be included. Typically this requires many iterations of trial and error. Our automated technique can relieve the user of this task. Alternatively, we could view the system as providing guidance for this task.\nLarge Definitions. The STACK(w; x; y; z) and UNSTACK(w; x; y; z) events are nearly identical to put down and pick up respectively. The only difference is that now we are picking up from and putting down onto a two block (rather than single block) tower (i.e., composed of blocks y and z). Thus, here again we might expect there to be perspicuous 3-AMA definitions. However, we see that the learned definitions for STACK(w; x; y; z) and UNSTACK(w; x; y; z) in Figures 16 and 17 involve many more timelines than those for PICKUP(w; x; y) and PUTDOWN(w; x; y). Accordingly, the definitions are quite overwhelming and much less perspicuous.\nDespite the large number of timelines, these definitions have the same general structure as those for pick up and put down. In particular, they each contain a distinguished perspicuous timeline, placed at the beginning of each definition, that is conjoined with many non-perspicuous timelines. It is clear that, as above, the perspicuous timelines have a natural begin;trans;end interpretation and, again, they are very similar to the definitions in HD2. In this case, however, the definitions in HD2 are not overly general (committing no false positives). Thus, here the inclusion of the non-perspicuous timelines has a detrimental effect since they unnecessarily specialize the definition resulting in more false negatives.\nWe suspect that a primary reason for the large number of non-perspicuous timelines relative to the definitions of pick up and put down stems from the increased difficulty of constructing force-dynamic models. The inclusion of the two block tower in these examples causes the modelreconstruction process to produce more unintended results, particularly during the transition periods of STACK and UNSTACK. The result is that often many unintuitive and physically incorrect patterns involving the three blocks and the hand are produced during the transition period. The learner captures these patterns roughly via the non-perspicuous timelines. It is likely that generalizing the definitions by including more training examples would filter out some of these timelines, making the overall definition more perspicuous. Alternatively, it is of interest to consider pruning the learned definitions. A straightforward way to do this is to generate negative examples. Then with these, we could remove timelines (generalizing the definition) that do not contribute toward rejecting the negative examples. It is unclear how to prune definitions without negative examples.\nHierarchical Events. MOVE(w; x; y; z), ASSEMBLE(w; x; y; z), and DISASSEMBLE(w; x; y; z) are inherently hierarchical, being composed of the four simpler event types. The hand-coded definitions leverage this structure by utilizing the simpler definitions as macros. In this light, it should be clear that, when viewed non-hierarchically, (as our learner does) these events involve relatively long state sequences. Thus, 3-AMA is not adequate for writing down perspicuous definitions. In spite of this representational shortcoming, our learned 3-AMA definitions perform quite well. This performance supports one of our arguments for using AMA from section 3.2. Namely, given that it is easier to find short rather than long sequences, a practical approach to finding definitions for long events is to conjoin the short sequences within those events. Examining the timelines of the learned 3-AMA definitions reveals what we might expect. Each timeline captures an often understandable property of the long event sequence, but the conjunction of those timelines cannot be considered to be a perspicuous definition. A future direction is to utilize hierarchical learning techniques to improve the perspicuity of our definitions while maintaining accuracy.\nWe note, however, that, at some level, the learned definition of MOVE(w; x; y; z) given in Figure 18 is perspicuous. In particular, the first 3-MA timeline is naturally interpreted as giving the pre- and post-conditions for a move action. That is, initially x is supported by y and the hand w is empty and finally x is supported by z and the hand w is empty. Thus, if all we care about is preand post-conditions, we might consider this timeline to be perspicuous. The remaining timelines in the definition capture pieces of the internal event structure such as facts indicating that x is moved by the hand. A weaker case can be made for assemble and disassemble. The first timeline in each of the learned definitions in Figures 19 and 20 can be interpreted as giving pre- and post-conditions. However, in these cases, the pre(post)-conditions for assemble(disassemble) are quite incomplete. The incompleteness is due to the inclusion of examples where the model-reconstruction process did not properly handle the initial(final) moments."
    }, {
      "heading" : "7. Related Work",
      "text" : "Here we discuss two bodies of related work. First, we present previous work in visual event recognition and how it relates to our experiments here. Second, we discuss previous approaches to learning temporal patterns from positive data."
    }, {
      "heading" : "7.1 Visual Event Recognition",
      "text" : "Our system is unique in that it combines positive-only learning with a temporal, relational, and force-dynamic representation to recognize events from real video. Prior work has investigated various subsets of the features of our system—but, to date, no system has combined all of these pieces together. Incorporating any one of these pieces into a system is a significant endeavor. In this respect, there are no competing approaches to directly compare our system against. Given this, the following is a representative list of systems that have common features with ours. It is not meant to be comprehensive and focuses on pointing out the primary differences between each of these systems and ours, as these primary differences actually render these systems only very loosely related to ours.\nBorchardt (1985) presents a representation for temporal, relational, force-dynamic event definitions but these definitions are neither learned nor applied to video. Regier (1992) presents techniques for learning temporal event definitions but the learned definitions are neither relational, force dynamic, nor applied to video. In addition the learning technique is not truly positive-only—rather, it extracts implicit negative examples of an event type from positive examples of other event types.\nLEARNING TEMPORAL EVENTS\nYamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize events in video but these definitions are neither learned nor force dynamic. Brand (1997b) and Mann and Jepson (1998) present techniques for analyzing force dynamics in video but neither formulate event definitions nor apply these techniques to recognizing events or learning event definitions."
    }, {
      "heading" : "7.2 Learning Temporal Patterns",
      "text" : "We divide this body of work into three main categories: temporal data mining, inductive logic programming, and finite-state–machine induction.\nTemporal Data Mining. The sequence-mining literature contains many general-to-specific (“levelwise”) algorithms for finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen, & Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001). Here we explore a specific-togeneral approach. In this previous work, researchers have studied the problem of mining temporal patterns using languages that are interpreted as placing constraints on partially or totally ordered sets of time points, e.g., sequential patterns (Agrawal & Srikant, 1995) and episodes (Mannila et al., 1995). These languages place constraints on time points rather than time intervals as in our work here. More recently there has been work on mining temporal patterns using interval-based pattern languages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).\nThough the languages and learning frameworks vary among these approaches, they share two central features which distinguish them from our approach. First, they all typically have the goal of finding all frequent patterns (formulas) within a temporal data set—our approach is focused on finding patterns with a frequency of one (covering all positive examples). Our first learning application of visual-event recognition has not yet required us to find patterns with frequency less than one. However, there are a number of ways in which we can extend our method in that direction when it becomes necessary (e.g., to deal with noisy training data). Second, these approaches all use standard general-to-specific level-wise search techniques, whereas we chose to take a specificto-general approach. One direction for future work is to develop a general-to-specific level-wise algorithm for finding frequent MA formulas and to compare it with our specific-to-general approach. Another direction is to design a level-wise version of our specific-to-general algorithm—where for example, the results obtained for the k-AMA LGG can be used to more efficiently calculate the(k+1)-AMA LGG. Whereas a level-wise approach is conceptually straightforward in a general-tospecific framework it is not so clear in the specific-to-general case. We are not familiar with other temporal data-mining systems that take a specific-to-general approach.\nFirst-Order Learning In Section 3.3, we pointed out difficulties in using existing first-order clausal generalization techniques for learning AMA formulas. In spite of these difficulties, it is still possible to represent temporal events in first-order logic (either with or without capturing the AMA semantics precisely) and to apply general-purpose relational learning techniques, e.g., inductive logic programming (ILP) (Muggleton & De Raedt, 1994). Most ILP systems require both positive and negative training examples and hence are not suitable for our current positive-only framework. Exceptions include GOLEM (Muggleton & Feng, 1992), PROGOL (Muggleton, 1995), and CLAUDIEN (De Raedt & Dehaspe, 1997), among others. While we have not performed a full evaluation\nFERN, GIVAN, & SISKIND\nof these systems, our early experiments in the visual-event recognition domain confirmed our belief that horn clauses, lacking special handling of time, give a poor inductive bias. In particular, many of the learned clauses find patterns that simply do not make sense from a temporal perspective and, in turn, generalize poorly. We believe a reasonable alternative to our approach may be to incorporate syntactic biases into ILP systems as done, for example, in Cohen (1994), Dehaspe and De Raedt (1996), Klingspor, Morik, and Rieger (1996). In this work, however, we chose to work directly in a temporal logic representation.\nFinite-State Machines Finally, we note there has been much theoretical and empirical research into learning finite-state machines (FSMs) (Angluin, 1987; Lang, Pearlmutter, & Price, 1998). We can view FSMs as describing properties of strings (symbol sequences). In our case, however, we are interested in describing sequences of propositional models rather than just sequences of symbols. This suggests learning a type of “factored” FSM where the arcs are labeled by sets of propositions rather than by single symbols. Factored FSMs may be a natural direction in which to extend the expressiveness of our current language, for example by allowing repetition. We are not aware of work concerned with learning factored FSMs; however, it is likely that inspiration can be drawn from symbol-based FSM-learning algorithms."
    }, {
      "heading" : "8. Conclusion",
      "text" : "We have presented a simple logic for representing temporal events called AMA and have shown theoretical and empirical results for learning AMA formulas. Empirically, we’ve given the first system for learning temporal, relational, force-dynamic event definitions from positive-only input and we have applied that system to learn such definitions from real video input. The resulting performance matches that of event definitions that are hand-coded with substantial effort by human domain experts. On the theoretical side, Table 3 summarizes the upper and lower bounds that we have shown for the subsumption and generalization problems associated with this logic. In each case, we have provided a provably correct algorithm matching the upper bound shown. The table also shows the worst-case size that the smallest LGG could possibly take relative to the input size, for both AMA and MA inputs. The key results in this table are the polynomial-time MA subsumption and AMA syntactic subsumption, the coNP lower bound for AMA subsumption, the exponential size of LGGs in the worst case, and the apparently lower complexity of syntactic AMA LGG versus semantic LGG. We described how to build a learner based on these results and applied it to the visual-event learning domain. To date, however, the definitions we learn are neither crossmodal nor perspicuous. And while the performance of the learned definitions matches that of hand-\nLEARNING TEMPORAL EVENTS\ncoded ones, we wish to surpass hand coding. In the future, we intend to address cross-modality by applying our learning technique to the planning domain. We also believe that addressing perspicuity will lead to improved performance."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors wish to thank our anonymous reviewers for helping to improve this paper. This work was supported in part by NSF grants 9977981-IIS and 0093100-IIS, an NSF Graduate Fellowship for Fern, and the Center for Education and Research in Information Assurance and Security at Purdue University. Part of this work was performed while Siskind was at NEC Research Institute, Inc."
    }, {
      "heading" : "Appendix A. Internal Positive Event Logic",
      "text" : "Here we give the syntax and semantics for an event logic called Internal Positive Event Logic (IPEL). This logic is used in the main text only to motivate our choice of a small subset of this logic, AMA, by showing, in Proposition 4, that AMA can define any set of models that IPEL can define. An event type (i.e., set of models) is said to be internal if whenever it contains any modelM = hM; Ii, it also contains any model that agrees withM on truth assignments M [i℄ where i 2 I . Full event logic allows the definition of non-internal events, for example, the formula = 3<P is satisfied by hM; Ii when there is some interval I 0 entirely preceding I such that P is satisfied by hM; I 0i, thus is not internal. The applications we are considering do not appear to require non-internal events, thus we currently only consider events that are internal.\nCall an event type positive if it contains the model M = hM; [1; 1℄i where M(1) is the truth assignment assigning all propositions the value true. A positive event type cannot require any proposition to be false at any point in time.\nIPEL is a fragment of full propositional event logic that can only describe positive internal events. We conjecture, but have not yet proven, that all positive internal events representable in the full event logic of Siskind (2001) can be represented by some IPEL formula. Formally, the syntax of IPEL formulas is given byE ::= true j prop j E1 _E2 j 3R0E1 j E1 ^R E2; where the Ei are IPEL formulas, prop is a primitive proposition (sometimes called a primitive event type), R is a subset of the thirteen Allen interval relations fs,f,d,b,m,o,=,si,fi,di,bi,ai,oig (Allen, 1983), and R0 is a subset of the restricted set of Allen relations fs,f,d,=g, the semantics for each Allen relation is given in Table 4. The difference between IPEL syntax and that of full propositional event logic is that event logic allows for a negation operator, and that, in full event logic, R0 can be any subset of all thirteen Allen relations. The operators ^ and ; used to define AMA formulas are merely abbreviations for the IPEL operators ^f=g and ^fmg respectively, so AMA is a subset of IPEL (though a distinguished subset as indicated by Proposition 4).\nEach of the thirteen Allen interval relations are binary relations on the set of closed naturalnumber intervals. Table 4 gives the definitions of these relations, defining [m1;m2℄ r [n1; n2℄ for each Allen relation r. Satisfiability for IPEL formulas can now be defined as follows,\nFERN, GIVAN, & SISKINDI1 Relation I2 English Definition Inverse[m1;m2℄ s [n1; n2℄ starts m1 = n1 and m2 n2 si[m1;m2℄ f [n1; n2℄ finishes m1 n1 and m2 = n2 fi[m1;m2℄ d [n1; n2℄ during m1 n1 and m2 n2 di[m1;m2℄ b [n1; n2℄ before m2 n1 bi[m1;m2℄ m [n1; n2℄ meets m2 = n1 or m2 + 1 = n1 mi[m1;m2℄ o [n1; n2℄ overlaps m1 n1 m2 n2 oi[m1;m2℄ = [n1; n2℄ equals m1 = n1 and m2 = n2 = Table 4: The Thirteen Allen Relations (adapted to our semantics). true is satisfied by every model. prop is satisfied by model hM; Ii iff M [x℄ assigns prop true for every x 2 I . E1 _E2 is satisfied by a model M iff M satisfies E1 or M satisfies E2. 3RE is satisfied by model hM; Ii iff for some r 2 R there is an interval I 0 such that I 0 r I and hM; I 0i satisfies E. E1 ^R E2 is satisfied by model hM; Ii iff for some r 2 R there exist intervals I1 and I2 such that I1 r I2, SPAN(I1; I2) = I and both hM; I1i satisfies E1 and hM; I2i satisfies E2.\nwhere prop is a primitive proposition, E and Ei are IPEL formulas, R is a set of Allen relations, and SPAN(I1; I2) is the minimal interval that contains both I1 and I2. From this definition, it is easy to show, by induction on the number of operators and connectives in a formula, that all IPEL formulas define internal events. One can also verify that the definition of satisfiability given earlier for AMA formulas corresponds to the one we give here."
    }, {
      "heading" : "Appendix B. Omitted Proofs",
      "text" : "Lemma 1. For any MA timeline and any model M, if M satisfies then there is a witnessing interdigitation for MAP(M) . Proof: Assume that M = hM; Ii satisfies the MA timeline = s1; : : : ; sn, and let 0 = MAP(M). It is straightforward to argue, by induction on the length of , that there exists a mappingV 0 from states of to sub-intervals of I , such that for any i 2 V 0(s), M [i℄ satisfies s, V 0(s1) includes the initial time point of I , V 0(sn) includes the final time point of I , and for any i 2 [1; n 1℄, we have V 0(si) meets V 0(si+1) (see Table 4).\nLEARNING TEMPORAL EVENTS\nLet V be the relation between states s 2 and members i 2 I that is true when i 2 V 0(s). Note that the conditions on V 0 ensure that every s 2 and every i 2 I appear in some tuple in V (not necessarily together). Below we use V to construct a witnessing interdigitation W .\nLet R be the total, one-to-one, onto function from time-points in I to corresponding states in 0, noting that 0 has one state for each time-point in I , as 0 = MAP(hM; Ii). Note that R preserves ordering in that, when i j, R(i) is no later than R(j) in 0. Let W be the composition V Æ R of the relations V and R.\nWe show that W is an interdigitation. We first show that each state from or 0 appears in a tuple in W , so W is piecewise total. States from must appear, trivially, because each appears in a tuple of V , and R is total. States from 0 appear because each i 2 I appears in a tuple of V , and R is onto the states of 0. It now suffices to show that for any states s before t from , W (s; s0) and W (t; t0) implies thats0 is no later than t0 in 0, so that W is simultaneously consistent. The conditions defining V 0 above imply that every number in i 2 V (s) is less than or equal to every j 2 V (t). The order-preservation property of R, noted above, then implies that every state s0 2 V Æ R(s) is no later than any statet0 2 V ÆR(t) in 0, as desired. So W is an interdigitation.\nWe now argue that W witnesses 0 . Consider s 2 and t 2 0 such that W (s; t). By the construction of W , there must be i 2 V 0(s) for which t is the i’th state of 0. Since 0 = MAP(M), it follows that t is the set of true propositions in M [i℄. Since i 2 V 0(s), we know that M [i℄ satisfiess. It follows that s t, and so t s. 2 Lemma 3. For any E 2 IPEL, if model M embeds a model that satisfies E then M satisfies E. Proof: Consider the models M = hM; Ii and M0 = hM 0; I 0i such that M embeds M0, let = MAP(M) and 0 = MAP(M0). Assume that E 2 IPEL is satisfied by M0, we will show thatE is also satisfied by M.\nWe know from the definition of embedding that 0 and thus there is a witnessing interdigitation W for 0 by Proposition 2. We know there is a one-to-one correspondence between numbers in I (I 0) and states of ( 0) and denote the state in ( 0) corresponding to i 2 I (i0 2 I 0) as si (ti0). This correspondence allows us to naturally interpret W as a mapping V from subsets ofI 0 to subsets of I as follows: for I 01 I 0, V (I 01) equals the set of all i 2 I such that for some i0 2 I 01,si co-occurs with ti0 in W . We will use the following properties of V ,\n1. If I 01 is a sub-interval of I 0, then V (I 01) is a sub-interval of I . 2. If I 01 is a sub-interval of I 0, then hM;V (I 01)i embeds hM 0; I 01i. 3. If I 01 and I 02 are sub-intervals of I 0, and r is an Allen relation, then I 01rI 02 iff V (I 01)rV (I 02). 4. If I 01 and I 02 are sub-intervals of I 0, then V (SPAN(I 01; I 02)) = SPAN(V (I 01); V (I 02)). 5. V (I 0) = I . We sketch the proofs of these properties. 1) Use induction on the length of I 01, with the definition of interdigitation. 2) Since V (I 01) is an interval, MAP(hM;V (I 01)i) is well defined. MAP(hM;V (I 01)i) MAP(hM 0; I 01i) follows from the assumption that M embeds M0. 3) From Appendix A, we see that all Allen relations are defined in terms of the relation on the natural\nFERN, GIVAN, & SISKIND\nnumber endpoints of the intervals. We can show that V preserves (but not <) on singleton sets (i.e., every member of V (fi0g) is every member of V (fj0g) when i0 j0) and that V commutes with set union. It follows that V preserves the Allen interval relations. 4) Use the fact thatV preserves in the sense just argued, along with the fact that SPAN(I 01; I 02) depends only on the minimum and maximum numbers in I 01 and I 02. 5) Follows from the definition of interdigitation and the construction of V .\nWe now use induction on the number of operators and connectives in E to prove that, if M0 satisfies E, then so mustM. The base case is whenE = prop, where prop is a primitive proposition, or true. SinceM0 satisfies E, we know that prop is true in allM 0[x0℄ for x0 2 I 0. Since W witnesses 0, we know that, if prop is true in M 0[x℄, then prop is true in all M [x℄, where x 2 V (x0). Therefore, since V (I 0) = I , prop is true for all M 0[x℄, where x 2 I , hence M0 satisfies E.\nFor the inductive case, assume that the claim holds for IPEL formulas with fewer than N operators and connectives—let E1; E2 be two such formulas. When E = E1 _ E2, the claim trivially holds. When E = 3RE1, R must be a subset of the set of relations fs,f,d,=g. Notice that E can be written as a disjunction of 3rE1 formulas, where r is a single Allen relation from R. Thus, it suffices to handle the case where R is a single Allen relation. Suppose E = 3fsgE1. Since M0 satisfies E, there must be a sub-interval I 01 of I 0 such that I 01 s I 0 and hM 0; I 01i satisfies E1. LetI1 = V (I 01), we know from the properties of V that V (I 0) = I , and, hence, that I1 s I . Furthermore, we know that hM; I1i embeds hM 0; I 01i, and, thus, by the inductive hypothesis, hM; I1i satisfies E1. Combining these facts, we get that E is satisfied by M. Similar arguments hold for the remaining three Allen relations. Finally, consider the case when E = E1 ^R E2, where R can be any set of Allen relations. Again, it suffices to handle the case when R is a single Allen relationr. Since M0 satisfies E = E1 ^r E2, we know that there are sub-intervals I 01 and I 02 of I 0 such that SPAN(I 01; I 02) = I 0, I 01 r I 02, hM 0; I 01i satisfies E1, and hM 0; I 02i satisfies E2. From these facts, and the properties of V , it is easy to verify that M satisfies E. 2 Lemma 5. Given an MA formula that subsumes each member of a set of MA formulas, also subsumes some member 0 of IG( ). Dually, when is subsumed by each member of , we have that is also subsumed by some member 0 of IS( ). In each case, the length of 0 can be bounded by the size of . Proof: We prove the result for IG( ). The proof for IS( ) follows similar lines. Let =f 1; : : : ; ng, = s1; : : : ; sm, and assume that for each 1 i n, i . From Proposition 2, for each i, there is a witnessing interdigitation Wi for i . We will combine the Wi into an interdigitation of , and show that the corresponding member of IG( ) is subsumed by . To construct an interdigitation of , first notice that, for each sj , each Wi specifies a set of states (possibly a single state but at least one) from i that all co-occur with sj . Furthermore, sinceWi is an interdigitation, it is easy to show that this set of states corresponds to a consecutive subsequence of states from i—let j;i be the MA timeline corresponding to this subsequence. Now let j = f j;i j 1 i ng, and j be any interdigitation of j . We now take I to be the union of all j , for 1 j m. We show that I is an interdigitation of . Since each state s appearing in must co-occur with at least one state sj in in at least one Wi, s will be in at least one tuple of j , and, hence, be in some tuple of I—so I is piecewise total.\nNow, define the restriction Ii;j of I to components i and j, with i < j, to be the relation given by taking the set of all pairs formed by shortening tuples of I by omitting all components except\nLEARNING TEMPORAL EVENTS\nthe i’th and the j’th. Likewise define i;jk for each k. To show I is an interdigitation, it now suffices to show that each Ii;j is simultaneously consistent. Consider states si and sj from timelines i and j , respectively, such that Ii;j(si; sj). Suppose that ti occurs after si in i, and for some tj 2 j ,Ii;j(ti; tj) holds. It suffices to show that sj is no later than tj in j . Since Ii;j(si; sj) and Ii;j(ti; tj), we must have i;jk (si; sj) and i;jk0 (ti; tj), respectively, for some k and k0. We know k k0 becausesi is before ti in i and Wi is simultaneously consistent. If k = k0, then sj is no later than tj in j , because k must be simultaneously consistent, being an interdigitation. Otherwise, k < k0. Then sj is no later than tj in j , as desired, because Wj is simultaneously consistent. So I is simultaneously consistent, and an interdigitation of .\nLet 0 be the member of IG( ) corresponding to I . We now show that 0 . We know that each state s0 2 0 is the intersection of the states in a tuple of some j—we say that s0 derives from j . Consider the interdigitation I 0 between and 0, where I 0(sj; s0), for sj 2 and s0 2 0, if and only if s0 derives from j . I 0 is piecewise total, as every tuple of I 0 derives from some j , and no j is empty. I 0 is simultaneously consistent because tuples of I 0 deriving from later k must be later in the lexicographic ordering of I , given the simultaneous consistency of the Wk interdigitations used to construct each j . Finally, we know that sj subsumes (i.e., is a subset of) each state in each tuple of j , because each Wk is a witnessing interdigitation to k , and, hence, subsumes (is a subset of) the intersection of those states. Therefore, if sj 2 co-occurs with s0 2 0 in I 0 we have thats0 sj . Thus, I 0 is a witnessing interdigitation for 0 , and by Proposition 2 we have 0 .\nThe size bound on 0 follows, since, as pointed out in the main text, the size of any member of IG( ) is upper-bounded by the number of states in . 2 Lemma 8. Given MA timelines 1 = s1; : : : ; sm and 2 = t1; : : : ; tn, there is a witnessing interdigitation for 1 2 iff there is a path in the subsumption graph SG( 1; 2) from v1;1 tovm;n. Proof: Subsumption graph SG( 1; 2) is equal to hV;Ei with V = fvi;j j 1 i m; 1 j ng and E = hvi;j ; vi0;j0i j si tj ; si0 tj0 ; i i0 i+ 1; j j0 j + 1 . Note that there is a correspondence between vertices and state tuples—with vertex vi;j corresponding to hsi; tji.\nFor the forward direction, assume that W is a witnessing interdigitation for 1 2. We know that, if the states si and tj co-occur in W , then si tj since W witnesses 1 2. The vertices corresponding to the tuples of W will be called co-occurrence vertices, and satisfy the first condition for belonging to some edge in E (that si tj). It follows from the definition of interdigitation that both v1;1 and vm;n are both co-occurrence vertices. Consider a co-occurrence vertex vi;j not equal to vm;n, and the lexicographically least co-occurrence vertex vi0;j0 after vi;j (ordering vertices by ordering the pair of subscripts). We show that i, j, i0, and j0 satisfy the requirements for\nvi;j; vi0;j0 2 E. If not, then either i0 > i + 1 or j0 > j + 1. If i0 > i + 1, then there can be no co-occurrence vertex vi+1;j00 , contradicting that W is piecewise total. If j0 > j + 1, then since W is piecewise total, there must be a co-occurrence vertex vi00;j+1: but if i00 < i ori00 > i0, this contradicts the simultaneous consistency of W , and if i00 = i, this contradicts the lexicographically least choice of vi0;j0 . It follows that every co-occurrence vertex but vm;n has an edge to another co-occurrence vertex closer in Manhattan distance to vm;n, and thus that there is a path from v1;1 to vm;n.\nFor the reverse direction assume there is a path of vertices in SG( 1; 2) from v1;1 to vm;n given by, vi1;j1 ; vi2;j2 ; : : : ; vir;js with i1 = j1 = 1, ir = m; js = n. Let W be the set of state\nFERN, GIVAN, & SISKIND\ntuples corresponding to the vertices along this path. W must be simultaneously consistent with the i orderings because our directed edges are all non-decreasing in the i orderings. W must be piecewise total because no edge can cross more than one state transition in either 1 or 2, by the edge set definition. So W is an interdigitation. Finally, the definition of the edge set E ensures that each tuple hsi; tji in W has the property si tj , so that W is a witnessing interdigitation for 1 2, showing that 1 2, as desired. 2 Lemma 10. Given some n, let be the conjunction of the timelinesn[i=1f(PROPn;Truei;Falsei;PROPn); (PROPn;Falsei;Truei;PROPn)g: We have the following facts about truth assignments to the Boolean variables p1; : : : ; pn:\n1. For any truth assignment A, PROPn; sA;PROPn is semantically equivalent to a member of IS( ).\n2. For each 2 IS( ) there is a truth assignment A such that PROPn; sA;PROPn. Proof: To prove the first part of the lemma, we construct an interdigitation I of such that the corresponding member of IS( ) is equivalent to PROPn; sA;PROPn. Intuitively, we construct I by ensuring that some tuple of I consists only of states of the form Truek or Falsek that agree with the truth assignment—the union of all the states in this tuple, taken by IS( ) will equal sA. LetI = fT0; T1; T2; T3; T4g be an interdigitation of with exactly five state tuples Ti. We assign the states of each timeline of to the tuples as follows:\n1. For any k, such that 1 k n and A(pk) is true, for the timeline s1; s2; s3; s4 = Q;Truek;Falsek;Q, assign each state si to tuple Ti, and assign state s1 to T0 as well, and for the timeline s01; s02; s03; s04 = Q;Falsek;Truek;Q, assign each state s0i to tuple Ti 1, and state s04 to tuple T4 as well.\n2. For any k, such that 1 k n and A(pk) is false, assign states to tuples as in item 1 while interchanging the roles of Truek and Falsek.\nIt should be clear that I is piecewise total and simultaneously consistent with the state orderings in , and so is an interdigitation. The union of the states in each of T0, T1, T3, and T4 is equal to PROPn, since PROPn is included as a state in each of those tuples. Furthermore, we see that the union of the states in T2 is equal to sA. Thus, the member of IS( ) corresponding to I is equal to PROPn;PROPn; sA;PROPn;PROPn, which is semantically equivalent to PROPn; sA;PROPn, as desired.\nTo prove the second part of the lemma, let be any member of IS( ). We first argue that every state in must contain either Truek or Falsek for each 1 k n. For any k, since contains PROPn;Truek;Falsek;PROPn, every member of IS( ) must be subsumed by PROPn;Truek; Falsek;PROPn. So, is subsumed by PROPn;Truek;Falsek;PROPn. But every state in PROPn; Truek;Falsek;PROPn contains either Truek or Falsek, implying that so does , as desired.\nLEARNING TEMPORAL EVENTS\nNext, we claim that for each 1 k n, either Truek or Falsek—i.e., either all states in include Truek, or all states in include Falsek (and possibly both). To prove this claim, assume, for the sake of contradiction, that, for some k, 6 Truek and 6 Falsek. Combining this assumption with our first claim, we see there must be states s and s0 in such that s contains Truek but not Falsek, and s0 contains Falsek but not Truek, respectively. Consider the interdigitation I of that corresponds to as a member of IS( ). We know that s and s0 are each equal to the union of states in tuples T and T 0, respectively, of I . T and T 0 must each include one state from each timelines1; s2; s3; s4 = PROPn;Truek;Falsek;PROPn and s01; s02; s03; s04 = PROPn;Falsek;Truek;PROPn. Clearly, since s does not include Falsek, T includes the states s1 and s02, and likewise T 0 includes the states s2 and s01. It follows that I is not simultaneously consistent with the state orderings ins1; s2; s3; s4 and s01; s02; s03; s04, contradicting our choice of I as an interdigitation. This shows that either Truek or Falsek.\nDefine the truth assignment A such that for all 1 k n, A(pk) if and only if Truek. Since,for each k, Truek or Falsek, it follows that each state of is subsumed bysA. Furthermore, since begins and ends with PROPn, it is easy to give an interdigitation of and PROPn; sA;PROPn that witnesses PROPn; sA;PROPn. Thus, we have that PROPn; sA;PROPn. 2 Lemma 16. Let 1 and 2 be as given on page 402, in the proof of Theorem 17, and let =V\nIG(f 1; 2g). For any 0 whose timelines are a subset of those in that omits some square timeline, we have < 0. Proof: Since the timelines in 0 are a subset of the timelines in , we know that 0. It remains to show that 0 6 . We show this by constructing a timeline that is covered by 0, but not by . Let = s1; s2; : : : ; s2n 1 be a square timeline in that is not included in 0. Recall that eachsi is a single proposition from the proposition set P = fpi;j j 1 i n; 1 j ng, and that, for consecutive states si and si+1, if si = pi;j , then si+1 is either pi+1;j or pi;j+1. Define a new timeline = s2; s3; : : : ; s2n 2 with si = (P si). We now show that 6 (so that 6 ), and that, for any 0 in f g, 0 (so that 0).\nFor the sake of contradiction, assume that —then there must be a interdigitation W witnessing . We show by induction on i that, for i 2, W (si; sj) implies j > i. For the base case, when i = 2, we know that s2 6 s2, since s2 6 s2, and so W (s2; s2) is false, sinceW witnesses subsumption. For the inductive case, assume the claim holds for all i0 < i, and thatW (si; sj). We know that si 6 si, and thus i 6= j. Because W is piecewise total, we must haveW (si 1; sj0) for some j0, and, by the induction hypothesis, we must have j0 > i 1. Since W is simultaneously consistent with the sk and sk0 state orderings, and i 1 < i, we have j0 j. It follows that j > i as desired. Given this claim, we see that s2n 2 cannot co-occur in W with any state in , contradicting the fact that W is piecewise total. Thus we have that 6 .\nLet 0 = s01; : : : ; s0m be any timeline in f g, we now construct an interdigitation that witnesses 0. Note that while is assumed to be square, 0 need not be. Let j be the smallest index where sj 6= s0j— since s1 = s01 = p1;1, and 6= 0, we know that such a j must exist, and is in the range 2 j m. We use the index j to guide our construction of an interdigitation. Let W be an interdigitation of and 0, with exactly the following co-occurring states (i.e., state tuples):\n1. For 1 i j 1, si+1 co-occurs with s0i.\nFERN, GIVAN, & SISKIND\n2. For j i m, sj co-occurs with s0i. 3. For j + 1 i 2n 2, si co-occurs with s0m.\nIt is easy to check that W is both piecewise total and simultaneously consistent with the state orderings in and , and so is an interdigitation. We now show that W witnesses 0 by showing that all states in are subsumed by the states they co-occur with in W . For co-occurring states si+1 and s0i corresponding to the first item above we have that s0i = si—this implies that s0i is contained in si+1, giving that si+1 s0i. Now consider co-occurring states sj and s0i from the second item above. Since is square, choose k and l so that sj 1 = pk;l, we have that sj is eitherpk+1;l or pk;l+1. In addition, since sj 1 = s0j 1 we have that s0j is either pk+1;l; pk;l+1 or pk+1;l+1 but that sj 6= s0j . In any of these cases, we find that no state in 0 after s0j can equal sj—this follows by noting that the proposition indices never decrease across the timeline 016. We therefore have that, for i j, sj s0i. Finally, for co-occurring states si and s0m from item three above, we havesi s0m, since s0m = pn;n, which is in all states of . Thus, we have shown that for all co-occurring states in W , the state from is subsumed by the co-occurring state in 0. Therefore, W witnesses 0, which implies that 0. 2 Lemma 26. For any model hM; Ii 2 M and any 2 AMA , covers hM; Ii iff F [ ℄ coversT [hM; Ii℄. Proof: Recall that M is the set of models over propositions in the set P = fp1; : : : ; png and that we assume AMA uses only primitive propositions from P (possibly negated). We also have the set of propositions P = f p1; : : : ; png, and assume that formulas in AMA use only propositions inP [ P and that M is the set of models over P [ P , where for each i, exactly one of pi and pi is true at any time. Note that F [ ℄ is in AMA and that T [hM; Ii℄ is in M. We prove the lemma via straightforward induction on the structure of —proving the result for literals, then for states, then for timelines, and finally for AMA formulas.\nTo prove the result for literals, we consider two cases (the third case of true is trivial). First, can be a single proposition pi, so that 0 = F [pi℄ = pi. Consider any model hM; Ii 2 M and lethM 0; Ii = T [hM; Ii℄. The following relationships yield the desired result. covers hM; Ii iff for each i 2 I , M [i℄ assigns pi true (by definition of satisfiability)\niff for each i 2 I , M 0[i℄ assigns pi true (by definition of T ) iff 0 = pi covers T [hM; Ii℄ (by definition of satisfiability)\nThe second case is when is a negated proposition :3pi—here, we get that 0 = pi. LethM; Ii 2 M and hM 0; Ii = T [hM; Ii℄. The following relationships yield the desired result. covers hM; Ii iff for each i 2 I , M [i℄ assigns pi false (by definition of satisfiability) iff for each i 2 I , M 0[i℄ assigns pi true (by definition of T ) iff 0 = pi covers T [hM; Ii℄ (by definition of satisfiability)\nThis proves the lemma for literals. 16. Note that if were not required to be square then it is possible for s0j+1 to equal sj—i.e., they could both equalpk+1;l+1.\nLEARNING TEMPORAL EVENTS\nTo prove the result for states, we use induction on the number k of literals in a state. The base case is when k = 1 (the state is a single literal) and was proven above. Now assume that the lemma holds for states with k or fewer literals and let = l1 ^ ^ lk+1 and hM; Ii 2 M. From the inductive assumption we know that = l1^ ^ lk covers hM; Ii iff F [ ℄ covers T [hM; Ii℄. From our base case we also know that lk+1 covers hM; Ii iff F [lk+1℄ covers T [hM; Ii℄. From these facts and the definition of satisfiability for states, we get that covers hM; Ii iff F [ ℄ ^ F [lk+1℄ coversT [hM; Ii℄. Clearly F has the property that F [ ℄ ^ F [lk+1℄ = F [ ℄, showing that the lemma holds for states.\nTo prove the result for timelines, we use induction on the number k of states in the timeline. The base case is when k = 1 (the timeline is a single state) and was proven above. Now assume that the lemma holds for timelines with k or fewer states. Let = s1; : : : ; sk+1 and hM; [t; t0℄i 2 M withhM 0; [t; t0℄i = T [hM; [t; t0℄i℄. We have the following relationships. covers hM; [t; t0℄i iff there exists some t00 2 [t; t0℄, such that s1 covers hM; [t; t00℄i and = s2; : : : ; sk+1 covers either hM; [t00; t0℄i or hM; [t00 + 1; t0℄i\niff there exists some t00 2 [t; t0℄, such that F [s1℄ covers hM 0; [t; t00℄i andF [ ℄ covers either hM 0; [t00; t0℄i or hM 0; [t00 + 1; t0℄i iff F [s1℄;F [ ℄ covers hM 0; [t; t0℄i iff F [ ℄ covers hM 0; [t; t0℄i\nWhere the first iff follows from the definition of satisfiability; the second follows from our inductive hypothesis, our base case, and the fact that for I [t; t0℄ we have T [hM; Ii℄ = hM 0; Ii; the third follows from the definition of satisfiability; and the fourth follows from the fact that F [s1℄;F [ ℄ =F [ ℄.\nFinally, we prove the result for AMA formulas, by induction on the number k of timelines in the formula. The base case is when k = 1 (the formula is a single timeline) and was proven above. Now assume that the lemma holds for AMA formulas with with k or fewer timelines and let = 1 ^ ^ k+1 and hM; Ii 2 M. From the inductive assumption, we know that 0 = 1 ^ ^ k covers hM; Ii iff F [ 0℄ covers T [hM; Ii℄. From our base case, we also know that k+1 covers hM; Ii iff F [ k+1℄ covers T [hM; Ii℄. From these facts and the definition of satisfiability, we get that covers hM; Ii iff F [ 0℄^ F [ k+1℄ covers T [hM; Ii℄. Clearly F has the property that F [ 0℄ ^ F [ k+1℄ = F [ ℄, showing that the lemma holds for AMA formulas. This completes the proof. 2"
    }, {
      "heading" : "Appendix C. Hand-coded and Learned Definitions Used in Our Experiments",
      "text" : "Below we give the two sets of hand-coded definitions, HD1 and HD2, used in our experimental evaluation. We also give a set of learned AMA event definitions for the same seven event types. The learned definitions correspond to the output of our k-AMA learning algorithm, given all available training examples (30 examples per event type), with k = 3 and D = BN. All the event definitions are written in event logic, where :3p denotes the negation of proposition p.\nLEARNING TEMPORAL EVENTS"
    } ],
    "references" : [ {
      "title" : "Mining sequential patterns",
      "author" : [ "R. Agrawal", "R. Srikant" ],
      "venue" : "In Proceedings of the Eleventh International Conference on Data Engineering,",
      "citeRegEx" : "Agrawal and Srikant,? \\Q1995\\E",
      "shortCiteRegEx" : "Agrawal and Srikant",
      "year" : 1995
    }, {
      "title" : "Maintaining knowledge about temporal intervals",
      "author" : [ "J.F. Allen" ],
      "venue" : "Communications of the ACM, 26(11), 832–843.",
      "citeRegEx" : "Allen,? 1983",
      "shortCiteRegEx" : "Allen",
      "year" : 1983
    }, {
      "title" : "Learning regular sets from queries and counterexamples",
      "author" : [ "D. Angluin" ],
      "venue" : "Information and Computation, 75, 87–106.",
      "citeRegEx" : "Angluin,? 1987",
      "shortCiteRegEx" : "Angluin",
      "year" : 1987
    }, {
      "title" : "Using temporal logics to express search control knowledge for planning",
      "author" : [ "F. Bacchus", "F. Kabanza" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bacchus and Kabanza,? \\Q2000\\E",
      "shortCiteRegEx" : "Bacchus and Kabanza",
      "year" : 2000
    }, {
      "title" : "Action recognition using probabilistic parsing",
      "author" : [ "A.F. Bobick", "Y.A. Ivanov" ],
      "venue" : "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Bobick and Ivanov,? \\Q1998\\E",
      "shortCiteRegEx" : "Bobick and Ivanov",
      "year" : 1998
    }, {
      "title" : "Event calculus",
      "author" : [ "G.C. Borchardt" ],
      "venue" : "Proceedings of the Ninth International Joint Conference on Artificial Intelligence, pp. 524–527, Los Angeles, CA.",
      "citeRegEx" : "Borchardt,? 1985",
      "shortCiteRegEx" : "Borchardt",
      "year" : 1985
    }, {
      "title" : "The inverse Hollywood problem: From video to scripts and storyboards via causal analysis",
      "author" : [ "M. Brand" ],
      "venue" : "Proceedings of the Fourteenth National Conference on Artificial Intelligence, pp. 132–137, Providence, RI.",
      "citeRegEx" : "Brand,? 1997a",
      "shortCiteRegEx" : "Brand",
      "year" : 1997
    }, {
      "title" : "Physics-based visual understanding",
      "author" : [ "M. Brand" ],
      "venue" : "Computer Vision and Image Understanding, 65(2), 192–205.",
      "citeRegEx" : "Brand,? 1997b",
      "shortCiteRegEx" : "Brand",
      "year" : 1997
    }, {
      "title" : "Causal analysis for visual gesture understanding",
      "author" : [ "M. Brand", "I. Essa" ],
      "venue" : "In Proceedings of the AAAI Fall Symposium on Computational Models for Integrating Language and Vision",
      "citeRegEx" : "Brand and Essa,? \\Q1995\\E",
      "shortCiteRegEx" : "Brand and Essa",
      "year" : 1995
    }, {
      "title" : "Coupled hidden Markov models for complex action recognition",
      "author" : [ "M. Brand", "N. Oliver", "A. Pentland" ],
      "venue" : "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
      "citeRegEx" : "Brand et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Brand et al\\.",
      "year" : 1997
    }, {
      "title" : "Fluent learning: Elucidating the structure of episodes",
      "author" : [ "P. Cohen" ],
      "venue" : "Proceedings of the Fourth Symposium on Intelligent Data Analysis.",
      "citeRegEx" : "Cohen,? 2001",
      "shortCiteRegEx" : "Cohen",
      "year" : 2001
    }, {
      "title" : "Grammatically biased learning: Learning logic programs using an explicit antecedent description lanugage",
      "author" : [ "W. Cohen" ],
      "venue" : "Artificial Intelligence, 68, 303–366.",
      "citeRegEx" : "Cohen,? 1994",
      "shortCiteRegEx" : "Cohen",
      "year" : 1994
    }, {
      "title" : "Learning the CLASSIC description logic: Theoretical and experimental results",
      "author" : [ "W. Cohen", "H. Hirsh" ],
      "venue" : "In Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning,",
      "citeRegEx" : "Cohen and Hirsh,? \\Q1994\\E",
      "shortCiteRegEx" : "Cohen and Hirsh",
      "year" : 1994
    }, {
      "title" : "DLAB: A declarative language bias formalism",
      "author" : [ "L. Dehaspe", "L. De Raedt" ],
      "venue" : "In Proceedings of the Ninth International Syposium on Methodologies for Intelligent Systems,",
      "citeRegEx" : "Dehaspe and Raedt,? \\Q1996\\E",
      "shortCiteRegEx" : "Dehaspe and Raedt",
      "year" : 1996
    }, {
      "title" : "STRIPS: A new approach to the application of theorem proving to problem solving",
      "author" : [ "R. Fikes", "N. Nilsson" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Fikes and Nilsson,? \\Q1971\\E",
      "shortCiteRegEx" : "Fikes and Nilsson",
      "year" : 1971
    }, {
      "title" : "Discovery of temporal patterns—Learning rules about the qualitative behaviour of time series",
      "author" : [ "F. Hoppner" ],
      "venue" : "Proceedings of the Fifth European Conference on Principles and Practice of Knowledge Discovery in Databases.",
      "citeRegEx" : "Hoppner,? 2001",
      "shortCiteRegEx" : "Hoppner",
      "year" : 2001
    }, {
      "title" : "Discovering temporal patterns for interval-based events",
      "author" : [ "P. Kam", "A. Fu" ],
      "venue" : "In Proceedings of the Second International Conference on Data Warehousing and Knowledge Discovery",
      "citeRegEx" : "Kam and Fu,? \\Q2000\\E",
      "shortCiteRegEx" : "Kam and Fu",
      "year" : 2000
    }, {
      "title" : "Learning concepts from sensor data of a mobile robot",
      "author" : [ "V. Klingspor", "K. Morik", "A.D. Rieger" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Klingspor et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Klingspor et al\\.",
      "year" : 1996
    }, {
      "title" : "Results of the Abbadingo one DFA learning competition and a new evidence-driven state merging algorithm",
      "author" : [ "K. Lang", "B. Pearlmutter", "R. Price" ],
      "venue" : "In Proceedings of the Fourth International Colloquium on Grammatical Inference",
      "citeRegEx" : "Lang et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Lang et al\\.",
      "year" : 1998
    }, {
      "title" : "Learning nonrecursive definitions of relations with LINUS",
      "author" : [ "N. Lavrac", "S. Dzeroski", "M. Grobelnik" ],
      "venue" : "In Proceedings of the Fifth European Working Session on Learning,",
      "citeRegEx" : "Lavrac et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Lavrac et al\\.",
      "year" : 1991
    }, {
      "title" : "Toward the computational perception of action",
      "author" : [ "R. Mann", "A.D. Jepson" ],
      "venue" : "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Mann and Jepson,? \\Q1998\\E",
      "shortCiteRegEx" : "Mann and Jepson",
      "year" : 1998
    }, {
      "title" : "Discovery of frequent episodes in sequences",
      "author" : [ "H. Mannila", "H. Toivonen", "A.I. Verkamo" ],
      "venue" : "In Proceedings of the First International Conference on Knowledge Discovery and Data Mining",
      "citeRegEx" : "Mannila et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Mannila et al\\.",
      "year" : 1995
    }, {
      "title" : "Generalization as search",
      "author" : [ "T. Mitchell" ],
      "venue" : "Artificial Intelligence, 18(2), 517–42.",
      "citeRegEx" : "Mitchell,? 1982",
      "shortCiteRegEx" : "Mitchell",
      "year" : 1982
    }, {
      "title" : "Pal: A pattern-based first-order inductive system",
      "author" : [ "E. Morales" ],
      "venue" : "Machine Learning, 26, 227– 252.",
      "citeRegEx" : "Morales,? 1997",
      "shortCiteRegEx" : "Morales",
      "year" : 1997
    }, {
      "title" : "Inverting entailment and Progol",
      "author" : [ "S. Muggleton" ],
      "venue" : "Machine Intelligence, 14, 133–188.",
      "citeRegEx" : "Muggleton,? 1995",
      "shortCiteRegEx" : "Muggleton",
      "year" : 1995
    }, {
      "title" : "Efficient induction of logic programs",
      "author" : [ "S. Muggleton", "C. Feng" ],
      "venue" : "Inductive Logic Programming,",
      "citeRegEx" : "Muggleton and Feng,? \\Q1992\\E",
      "shortCiteRegEx" : "Muggleton and Feng",
      "year" : 1992
    }, {
      "title" : "Inductive logic programming: Theory and methods",
      "author" : [ "S. Muggleton", "L. De Raedt" ],
      "venue" : "Journal of Logic Programming,",
      "citeRegEx" : "Muggleton and Raedt,? \\Q1994\\E",
      "shortCiteRegEx" : "Muggleton and Raedt",
      "year" : 1994
    }, {
      "title" : "Scripts in machine understanding of image sequences",
      "author" : [ "C. Pinhanez", "A. Bobick" ],
      "venue" : "In Proceedings of the AAAI Fall Symposium Series on Computational Models for Integrating Language and Vision",
      "citeRegEx" : "Pinhanez and Bobick,? \\Q1995\\E",
      "shortCiteRegEx" : "Pinhanez and Bobick",
      "year" : 1995
    }, {
      "title" : "Automatic Methods of Inductive Inference",
      "author" : [ "G.D. Plotkin" ],
      "venue" : "Ph.D. thesis, Edinburgh University.",
      "citeRegEx" : "Plotkin,? 1971",
      "shortCiteRegEx" : "Plotkin",
      "year" : 1971
    }, {
      "title" : "The Acquisition of Lexical Semantics for Spatial Terms: A Connectionist Model of Perceptual Categorization",
      "author" : [ "T.P. Regier" ],
      "venue" : "Ph.D. thesis, University of California at Berkeley.",
      "citeRegEx" : "Regier,? 1992",
      "shortCiteRegEx" : "Regier",
      "year" : 1992
    }, {
      "title" : "Relational learning via propositional algorithms: An information extraction case study",
      "author" : [ "D. Roth", "W. Yih" ],
      "venue" : "In Proeedings of the Seventeenth International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "Roth and Yih,? \\Q2001\\E",
      "shortCiteRegEx" : "Roth and Yih",
      "year" : 2001
    }, {
      "title" : "Temporal logics in AI: Semantical and ontological considerations",
      "author" : [ "Y. Shoham" ],
      "venue" : "Artificial Intelligence, 33(1), 89–104.",
      "citeRegEx" : "Shoham,? 1987",
      "shortCiteRegEx" : "Shoham",
      "year" : 1987
    }, {
      "title" : "Visual event classification via force dynamics",
      "author" : [ "J.M. Siskind" ],
      "venue" : "Proceedings of the Seventeenth National Conference on Artificial Intelligence, pp. 149–155, Austin, TX.",
      "citeRegEx" : "Siskind,? 2000",
      "shortCiteRegEx" : "Siskind",
      "year" : 2000
    }, {
      "title" : "Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic",
      "author" : [ "J.M. Siskind" ],
      "venue" : "Journal of Artificial Intelligence Research, 15, 31–90.",
      "citeRegEx" : "Siskind,? 2001",
      "shortCiteRegEx" : "Siskind",
      "year" : 2001
    }, {
      "title" : "A maximum-likelihood approach to visual event classification",
      "author" : [ "J.M. Siskind", "Q. Morris" ],
      "venue" : "In Proceedings of the Fourth European Conference on Computer Vision,",
      "citeRegEx" : "Siskind and Morris,? \\Q1996\\E",
      "shortCiteRegEx" : "Siskind and Morris",
      "year" : 1996
    }, {
      "title" : "Force dynamics in language and cognition",
      "author" : [ "L. Talmy" ],
      "venue" : "Cognitive Science, 12, 49–100.",
      "citeRegEx" : "Talmy,? 1988",
      "shortCiteRegEx" : "Talmy",
      "year" : 1988
    }, {
      "title" : "Recognizing human action in time-sequential images using hidden Markov model",
      "author" : [ "J. Yamoto", "J. Ohya", "K. Ishii" ],
      "venue" : "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Yamoto et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Yamoto et al\\.",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 35,
      "context" : "This suggests that the primitive relations used to build event representations are force dynamic (Talmy, 1988).",
      "startOffset" : 97,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "LEONARD (Siskind, 2001) classifies events from video using temporal, relational, force-dynamic representations but does not learn these representations.",
      "startOffset" : 8,
      "endOffset" : 23
    }, {
      "referenceID" : 33,
      "context" : "LEONARD (Siskind, 2001) is a system for recognizing visual events from video camera input— an example of a simple visual event is “a hand picking up a block.",
      "startOffset" : 8,
      "endOffset" : 23
    }, {
      "referenceID" : 32,
      "context" : "LEONARD (Siskind, 2001) is a system for recognizing visual events from video camera input— an example of a simple visual event is “a hand picking up a block.” This research was originally motivated by the problem of adding a learning component to LEONARD—allowing LEONARD to learn to recognize an event by viewing example events of the same type. Below, we give a high-level description of the LEONARD system. LEONARD is a three-stage pipeline depicted in Figure 1. The raw input consists of a video-frame image sequence depicting events. First, a segmentation-and-tracking component transforms this input into a polygon movie: a sequence of frames, each frame being a set of convex polygons placed around the tracked objects in the video. Figure 2a shows a partial video sequence of a pick up event that is overlaid with the corresponding polygon movie. Next, a model-reconstruction component transforms the polygon movie into a force-dynamic model. This model describes the changing support, contact, and attachment relations between the tracked objects over time. Constructing this model is a somewhat involved process as described in Siskind (2000). Figure 2b shows a visual depiction of the force-dynamic model corresponding to the pick up event.",
      "startOffset" : 9,
      "endOffset" : 1153
    }, {
      "referenceID" : 31,
      "context" : "An important assumption leveraged by our learner is that the primitive propositions used to construct states describe liquid properties (Shoham, 1987).",
      "startOffset" : 136,
      "endOffset" : 150
    }, {
      "referenceID" : 28,
      "context" : "2 This learning approach has been pursued for a variety of different languages within the machine-learning literature, including clausal first-order logic (Plotkin, 1971), definite clauses (Muggleton & Feng, 1992), and description logic (Cohen & Hirsh, 1994).",
      "startOffset" : 155,
      "endOffset" : 170
    }, {
      "referenceID" : 22,
      "context" : "This avoids the need for negative examples and corresponds to finding the specific boundary of the version space (Mitchell, 1982).",
      "startOffset" : 113,
      "endOffset" : 129
    }, {
      "referenceID" : 33,
      "context" : "We study a subset of an interval-based logic called event logic (Siskind, 2001) utilized by LEONARD for event recognition in video sequences.",
      "startOffset" : 64,
      "endOffset" : 79
    }, {
      "referenceID" : 1,
      "context" : "resenting each of the possible interval relationships given originally by Allen (1983) in his calculus of interval relations (e.",
      "startOffset" : 74,
      "endOffset" : 87
    }, {
      "referenceID" : 32,
      "context" : "We note that Siskind (2001) gives a continuous-time semantics for event logic where the models",
      "startOffset" : 13,
      "endOffset" : 28
    }, {
      "referenceID" : 32,
      "context" : "Siskind (2001) provides a method to determine whether a given model satisfies a given AMA formula.",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 28,
      "context" : "However, it is well known that least-general generalizations relative to such background theories need not exist (Plotkin, 1971), so prior work on clausal generalization does not simply subsume our results for the AMA language.",
      "startOffset" : 113,
      "endOffset" : 128
    }, {
      "referenceID" : 19,
      "context" : "Lavrac et al. (1991) has taken a similar approach.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 28,
      "context" : "Since it is well known that computing first-order LGGs can be intractable (Plotkin, 1971), practical generalization algorithms retain tractability by constraining the LGGs in various ways (e.",
      "startOffset" : 74,
      "endOffset" : 89
    }, {
      "referenceID" : 23,
      "context" : "Since it is well known that computing first-order LGGs can be intractable (Plotkin, 1971), practical generalization algorithms retain tractability by constraining the LGGs in various ways (e.g., Muggleton & Feng, 1992; Morales, 1997).",
      "startOffset" : 188,
      "endOffset" : 233
    }, {
      "referenceID" : 32,
      "context" : "For a detailed description and sample video sequences of these event types, see Siskind (2001). Key frames from sample video sequences of these event types are shown in Figure 11.",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 32,
      "context" : "The first set HD1 of hand-coded definitions appeared in Siskind (2001). In response to subsequent deeper understanding of the behavior of LEONARD’s model-reconstruction methods, we manually revised these definitions to yield another set HD2 of hand-coded definitions that gives a significantly better FN performance at some cost in FP performance.",
      "startOffset" : 56,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "Borchardt (1985) presents a representation for temporal, relational, force-dynamic event definitions but these definitions are neither learned nor applied to video.",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 5,
      "context" : "Borchardt (1985) presents a representation for temporal, relational, force-dynamic event definitions but these definitions are neither learned nor applied to video. Regier (1992) presents techniques for learning temporal event definitions but the learned definitions are neither relational, force dynamic, nor applied to video.",
      "startOffset" : 0,
      "endOffset" : 179
    }, {
      "referenceID" : 5,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 5,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic.",
      "startOffset" : 32,
      "endOffset" : 81
    }, {
      "referenceID" : 5,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic.",
      "startOffset" : 32,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic.",
      "startOffset" : 122,
      "endOffset" : 147
    }, {
      "referenceID" : 4,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize events in video but these definitions are neither learned nor force dynamic.",
      "startOffset" : 122,
      "endOffset" : 314
    }, {
      "referenceID" : 4,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize events in video but these definitions are neither learned nor force dynamic.",
      "startOffset" : 122,
      "endOffset" : 332
    }, {
      "referenceID" : 4,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize events in video but these definitions are neither learned nor force dynamic. Brand (1997b) and Mann and Jepson (1998) present techniques for analyzing force dynamics in video but neither formulate event definitions nor apply these techniques to recognizing events or learning event definitions.",
      "startOffset" : 122,
      "endOffset" : 485
    }, {
      "referenceID" : 4,
      "context" : "Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver, and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize events in video but these definitions are neither learned nor force dynamic. Brand (1997b) and Mann and Jepson (1998) present techniques for analyzing force dynamics in video but neither formulate event definitions nor apply these techniques to recognizing events or learning event definitions.",
      "startOffset" : 122,
      "endOffset" : 512
    }, {
      "referenceID" : 10,
      "context" : "The sequence-mining literature contains many general-to-specific (“levelwise”) algorithms for finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen, & Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).",
      "startOffset" : 121,
      "endOffset" : 226
    }, {
      "referenceID" : 15,
      "context" : "The sequence-mining literature contains many general-to-specific (“levelwise”) algorithms for finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen, & Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).",
      "startOffset" : 121,
      "endOffset" : 226
    }, {
      "referenceID" : 21,
      "context" : ", sequential patterns (Agrawal & Srikant, 1995) and episodes (Mannila et al., 1995).",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 10,
      "context" : "More recently there has been work on mining temporal patterns using interval-based pattern languages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).",
      "startOffset" : 101,
      "endOffset" : 145
    }, {
      "referenceID" : 15,
      "context" : "More recently there has been work on mining temporal patterns using interval-based pattern languages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).",
      "startOffset" : 101,
      "endOffset" : 145
    }, {
      "referenceID" : 24,
      "context" : "Exceptions include GOLEM (Muggleton & Feng, 1992), PROGOL (Muggleton, 1995), and CLAUDIEN (De Raedt & Dehaspe, 1997), among others.",
      "startOffset" : 58,
      "endOffset" : 75
    }, {
      "referenceID" : 10,
      "context" : "We believe a reasonable alternative to our approach may be to incorporate syntactic biases into ILP systems as done, for example, in Cohen (1994), Dehaspe and De Raedt (1996), Klingspor, Morik, and Rieger (1996).",
      "startOffset" : 133,
      "endOffset" : 146
    }, {
      "referenceID" : 10,
      "context" : "We believe a reasonable alternative to our approach may be to incorporate syntactic biases into ILP systems as done, for example, in Cohen (1994), Dehaspe and De Raedt (1996), Klingspor, Morik, and Rieger (1996).",
      "startOffset" : 133,
      "endOffset" : 175
    }, {
      "referenceID" : 10,
      "context" : "We believe a reasonable alternative to our approach may be to incorporate syntactic biases into ILP systems as done, for example, in Cohen (1994), Dehaspe and De Raedt (1996), Klingspor, Morik, and Rieger (1996). In this work, however, we chose to work directly in a temporal logic representation.",
      "startOffset" : 133,
      "endOffset" : 212
    }, {
      "referenceID" : 2,
      "context" : "Finite-State Machines Finally, we note there has been much theoretical and empirical research into learning finite-state machines (FSMs) (Angluin, 1987; Lang, Pearlmutter, & Price, 1998).",
      "startOffset" : 137,
      "endOffset" : 186
    }, {
      "referenceID" : 32,
      "context" : "We conjecture, but have not yet proven, that all positive internal events representable in the full event logic of Siskind (2001) can be represented by some IPEL formula.",
      "startOffset" : 115,
      "endOffset" : 130
    }, {
      "referenceID" : 1,
      "context" : "where the Ei are IPEL formulas, prop is a primitive proposition (sometimes called a primitive event type), R is a subset of the thirteen Allen interval relations fs,f,d,b,m,o,=,si,fi,di,bi,ai,oig (Allen, 1983), and R0 is a subset of the restricted set of Allen relations fs,f,d,=g, the semantics for each Allen relation is given in Table 4.",
      "startOffset" : 196,
      "endOffset" : 209
    } ],
    "year" : 2011,
    "abstractText" : "We develop, analyze, and evaluate a novel, supervised, specific-to-general learner for a simple temporal logic and use the resulting algorithm to learn visual event definitions from video sequences. First, we introduce a simple, propositional, temporal, event-description language called AMA that is sufficiently expressive to represent many events yet sufficiently restrictive to support learning. We then give algorithms, along with lower and upper complexity bounds, for the subsumption and generalization problems for AMA formulas. We present a positive-examples–only specific-to-general learning method based on these algorithms. We also present a polynomialtime–computable “syntactic” subsumption test that implies semantic subsumption without being equivalent to it. A generalization algorithm based on syntactic subsumption can be used in place of semantic generalization to improve the asymptotic complexity of the resulting learning algorithm. Finally, we apply this algorithm to the task of learning relational event definitions from video and show that it yields definitions that are competitive with hand-coded ones.",
    "creator" : "dvips(k) 5.86 Copyright 1999 Radical Eye Software"
  }
}