{
  "name" : "1708.04765.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Dialogue Act Segmentation for Vietnamese Human-Human Conversational Texts",
    "authors" : [ "Thi–Lan Ngo" ],
    "emails" : [ "ntlan@ictu.edu.vn", "phamkhaclinh2017@gmail.com", "soncm_58@vnu.edu.vn", "sonpb@vnu.edu.vn", "hieupx@vnu.edu.vn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords—Dialog act segmentation, functional segment, Vietnamese conversation.\nI. INTRODUCTION\nAutomatic recognition of user intent from utterances in their interaction with systems through the conversational interface is a very challenging task that has attracted a lot of attention from research community for two decades. The goal is to design methods to make computers interact more naturally with human beings. Identifying dialog acts (DAs) within an utterance, i.e. identifying its illocutionary act of communication, plays a key role in understanding user’s intent. Because, “Dialog act is a communicative activity of dialog participant, interpreted as having a certain communicative function and semantic content\" [1]. It presents meaning of utterances at the discourse level. It is a complementary process\nto concept extraction. Therefore, it is essential for the complete understanding of conversations. It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean. Whilst in Vietnamese languages, dialog act has only been studied in linguistics, our work in this paper is a preliminary study about automatic identification of dialog act, as well as dialog act segmentation.\nPrior to DA identification, utterances must be segmented according to DA boundaries. In the past, there have been studies of DA segmentation such as Umit Guz et al. implemented DA segmentation of speech using multi-view semisupervised learning [5]; Jeremy Ang et al. explored DA segmentation using simple lexical and prosodic knowledge sources [6]; Warnke et al. calculated hypotheses for the probabilities exceeded a predefined threshold level in VERBMOBIL corpus [7]; Silvia Quarteroni et al. segmented human-human dialog into turns and intra-turn segmentation into DA boundaries using CRFs to learn models for simultaneous segmentation of DAs from whole human-human spoken dialogs [8]. These studies segmented turns into sentence unit to do dialog act segmentation. In my work, different from those studies, we segment utterances into the smallest meaningful units – “functional segment\" unit. According to ISO 24617-2 standard about Dialog Act, a functional segment (FS) is defined as “minimal stretch of communicative behavior that have a communicative function\" [1]. For example, in the utterance “xin chào cậu khỏe chứ\" (“hello are you fine\"), there are two functional segments: “xin chào\" (“hello”) (its dialog act is greeting), and “cậu khoẻ chứ\" (“are you fine”) (its dialog act is check question). We investigate thoroughly functional segment identification in two approaches: (1) machine learning approach with ME, CRF; (2) deep learning approach with Bi–LSTM–CRF. Recently, ME, CRF and Bi–LSTM–CRF have been applied to a variety of sequence labeling and segmentation tasks in Natural Language Processing and have achieved state-ofthe-art results [9]. Therefore, we expect that these methods ar X iv :1 70 8. 04 76\n5v 1\n[ cs\n.C L\n] 1\napply to the FS identification task for Vietnamese can make similar successes. To do the task, we first build two annotated corpus from Facebook messages and transcription from phone conversations. For a careful evaluation, different ME, CRF and Bi–LSTM–CRF models were trained and their results are compared and shown contrast with each other. Moreover, we also show the characteristics of two different conversational data sets and their effect on the experimental results of the task of the dialog act segmentation task.\nWe can summary our main contributions in this paper in two aspects:\n• First, we built two Vietnamese conversational text datasets which are segmented into FSs based on FS concept from the ISO standard and ready to contribute to the DialogBank 1 for Vietnamese. We also built online chat dictionary which contains abbreviations, slang words and teen code and Vietnamese local dialect dictionary.\n• Second, two machine learning techniques and a deep learning technique are applied and compared on the task of automatic dialog act segmentation. Deep learning technique is also applied for the first time to dialog act segmentation. The results of the deep learning technique are very promising, opening up a new way to approach dialog act segmentation and dialog act in general for applications for future studies.\nThe rest of the paper is organized as follows: Section II presents briefly background about FS formation in Vietnamese conversational texts and units of a dialogue. In Section III we describe our two human-human conversation corpus. We also discuss the impact of our conversational data sets to the functional segment identification task in this section. We describe quickly the two learning models ME, CRF and the deep learning model, Bi–LSTM–CRF for labeling and segmenting FS in Section IV. Section V mainly presents the framework of using MEs, CRFs, Bi–LSTM–CRF for Vietnamese FS segmentation and result comparison and evaluation. Finally, Section VI shows some conclusions and the work that need research in the future."
    }, {
      "heading" : "II. BACKGROUD: FUNCTIONAL SEGMENT AND UNITS OF A DIALOGUE",
      "text" : "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform. It is the meaning of an utterance at the level of illocutionary force, such as statement, question and greeting. Detection of dialog acts need to perform: 1) the segmentation of human–human dialogues into turns, 2) the intra-turn segmentation into DA boundaries, i.e. functional segment identification and 3) the classification of each segment according to a DA tag [12].\nIn which, “turn\", “dialog act\", “functional segment\" terms are defined slightly different between different domains and different purposes. But these are standardized and united in ISO standards as follows:\n1https://dialogbank.uvt.nl/"
    }, {
      "heading" : "Turn:",
      "text" : "A “turn\" is definite as “stretch of communicative activity produced by one participant who occupies the speaker role bounded by periods where another participant occupies the speaker role\". Dialogue participants (sender, addressee) normally take turns in conversation. Several utterances from one of the dialogues in our corpus are shown as examples of Turn, Message, and Functional segment in Table I and Table II. In our Message data, a turn is seen as a collection of continuous messages sent by one participant. In which, a message is defined as a group of words that are sent from one dialogue participant to the other. For instance, turn t2 includes four messages ms2, ms3, ms4, ms5 (Table I)."
    }, {
      "heading" : "Functional segment:",
      "text" : "A functional segment is the “minimal stretch of communicative behavior that has a communicative function”, “minimal in the sense of not including material that does not contribute to the expression of the function or the semantic content of the dialogue act\" [1]. A functional segment may be shorter than turns and continuous, for example as in Table I, t1 includes two functional segments fs1 and fs2. A functional segment may be discontinuous, with examples such as fs4 and fs10. fs5 is nested within fs4. In addition, functional segment fs10 is combined from two messages, fs8 overlaps fs10. Thus, we can see that a functional segment may be continuous, may be discontinuous, may be overlapped and nested. The detailed explanation of the types of FS is presented in [13] and the ISO 24617-2 standard."
    }, {
      "heading" : "Dialog Act:",
      "text" : "DA is “communicative activity of a dialogue participant, interpreted as having a certain communicative function and semantic content\". For example:\n“xin chào cậu khoẻ chứ\" (“hello are you fine”)\nDAs of “xin chào\" (hello) are Greeting and Opening. DA of “cậu khoẻ chứ\" (“are you fine”) is Check Question."
    }, {
      "heading" : "III. CORPUS BUILDING: MESSAGE DATA & PHONE DATA",
      "text" : "In Vietnamese, there is no publicly available standard corpus. Therefore we need to build first a reference corpus for training and evaluation. For this work, we have to build two corpora of data from human-human conversations in various domains. One is chat texts and other is spoken texts."
    }, {
      "heading" : "A. Message corpus",
      "text" : "Our Message data set is collected from Facebook messages of 20 volunteers. The data set contains 280 human-human Vietnamese dialogues in any topics with a total number of 4583 messages. The average length of dialogues is 16.4 messages. The data set was independently labeled by three annotators. The agreement score of our data set achieved 0.87 Fleiss’ kappa measure [14]. As observed from our data, there are some challenges as follows:\n1) The data is very noisy because it contains many acronyms, misspellings, slang, and emoticons. These\nFS identification but sometimes a FS may contain multiple messages, and even may include only a part of one message and a part of the next message. This indistinct end of a turn also leads to the end of a misleading message. In sudden interruption cases, messages can become out of sync. Each participant tends to respond to a message earlier than the previous one, making the conversation also being out of order and the conversation seem inconsistent when read in sequence. This is a difficult problem for processing the dialog act segmentation.\nIn short, unlike carefully authored news text, conversational text poses a number of new challenges, due to their short, context-dependent, noisy and dynamic nature. Tackling this challenge, ideally, requires changing related natural language processing tools to become suitable for texts from social media network or normalizing conversational texts to fit with existing tools. However, both of which are hard tasks. In the scope of this paper, we standardize the message data using our online chat dictionary to match popular abbreviations, acronyms, and slang with standard words in the pre-processing stage."
    }, {
      "heading" : "Online chat dictionary",
      "text" : "Our online chat dictionary includes abbreviations, slang and the words that are written in teen style (teen code) such as “bj\"- “bây giờ\" (“now\"), “ck\" - “chồng\" (“husband\"), “4u\" - “cho bạn\" (“for you\"). The letters “c\", “k\", “q\" are usually replaced by “k\", “ch” but often replaced with “ck” ... Using online chat dictionary to standardize the message data, the noisiness of input data will be reduced. This make it more formal and help the models run better."
    }, {
      "heading" : "B. Phone corpus",
      "text" : "Our Phone data set is build from scripted telephone speech of LDC2017S01 data (IARPA Babel Vietnamese Language Pack IARPA-babel107b-v0.7 2). LDC2017S01 contains Vietnamese phone audios and transcripts. The Vietnamese conversations in these corpus contain different dialects that spoken in the North, North-Central, Central and Southern regions in Vietnam. We selected 22 conversations and segment its transcripts into the turn by manual. Then, the turns are annotated FS. The Phone data includes 1545 turns and 3500 FSs with an average of 70 turns and 160 FSs per conversation. The agreement scores of the phone data set is 0.84 Fleiss’ kappa measure. FS recognition for spoken texts, however, is more challenging than working with written documents due to some reasons as follows:\n1) First, spoken text are commonly shorter and less grammatical, not comply with rigid syntactic constraints. Sentence elements like subject or object are often omitted. It is very context-dependent. Also, there are no punctuation marks in the texts. It, therefore, is non–trivial to segment and parse spoken sentences correctly. 2) Second, conversational speech contains a lot of selfcorrecting, hesitation, and stutter. This is one of the\n2https://catalog.ldc.upenn.edu/LDC2017S01\nmain reasons that causes nested FS. fs9 and fs13 within turn t4 in Table II are the instances.\n3) Third, the output text of Automatic Speech Recognition are all in lowercase and bearing a small percentage of errors.\nThese challenges make it extremely difficult to recognize FS in particular and in understanding spoken language in general.\nVietnamese local dialect dictionary\nThe LDC2017S01 data is built from spoken conversations in the North, North-Central, Central and Southern Vietnamese dialect. Because of the nature of Vietnamese dialects, a lot of words in local dialects can be changed to standard dialect (the North Vietnamese dialect) without affecting the meaning of the utterances in which they belongs. For instances, “Răng rứa\" means “sao thế\" (what up); “Mi đi mô\" means “Mày đi đâu\" (where are you going?). Therefore we created a dictionary to match these words with standardized words. By doing so, the data sets become more uniform. This makes it easier to handle and help the models to run better. Our dictionary is not only useful in this study but also can be very helpful in all other studies that involve Vietnamese human–human, and human–machine conversation."
    }, {
      "heading" : "IV. DA SEGMETATION WITH ME, CRF AND BI-LSTM-CRF",
      "text" : "The number of discontinuous or nested functional segments account for a very small percent in both data sets (0.5% in the Message corpus, 0.9% in the Phone corpus). Hence there are not enough discontinuous or nested functional segments so the models can learn to identify them. For that reason, this paper only focuses on identifying continuous and unnested functional segments (which make up more than 99% of both data sets). In future studies, we intend to increase the size of our data sets, the number of discontinuous or nested functional segments and study methods to identify these functional segments. In this paper, we cast the segmentation problem as a sequential tagging task: the first word of a FS is marked with B_fs (Begin of a FS), the token that is inside of a FS is marked with I_FS (Inside of a FS). The problem of FS identification in a sentence is modeled as the problem of labeling syllables in that sentence with two above labels. Let t = {t1, t2, ...tn} be turns and y = {B, I} be per-token output tags. We predict the most likely y, given a conditional model P (y|t)."
    }, {
      "heading" : "A. Maximum Entropy",
      "text" : "The ME (Maxent) model defines conditional distribution of class (y) given an observation vector t as the exponential form in Formula (1) [15]:\nP (y/t) = 1\nZ(t) exp ( K∑ 1 θk(t, y) ) (1)\nwhere θk is a weight parameter to be estimated for the corresponding feature function fk(t, y), and Z(t) is a normalizing factor over all classes to ensure a proper probability. K is the total number of feature functions. We decided to use ME for evaluation and comparison because it is commented that it is suitable for sparse data like natural language, encode various rich and overlapping features at different levels of granularity [16]."
    }, {
      "heading" : "B. Conditional Random Fields",
      "text" : "The CRFs model defines also the conditional distribution of the class (y) given an observation vector t as the Formular (1) [17]. In which θk is a weight parameter to be estimated for the corresponding feature function fk(t, y), and Z(t) is a normalizing factor over all classes to ensure a proper probability. And K is the total number of feature functions. It is essentially a ME model over the entire sequence. It is unlike the Maxent above since it models the sequence information, because the Maxent model decides for each state independently with the other states. For example, a transcription utterance together with class tags used for the CRF word detection model in Dialog act segmentation as follows:\nTraining ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using advanced convex optimization techniques like L–BFGS [18]."
    }, {
      "heading" : "C. Deep learning–based models with Bi–LSTM–CRF",
      "text" : "Bi–LSTM–CRF network is formed by combining a bidirectional LSTM network and a CRF network [9]. Therefore Bi– LSTM–CRF can efficiently use past and future input features via a Bi–LSTM layer and sentence level tag information via a CRF layer. A CRF layer is represented by lines which connect consecutive output layers. A CRF layer has a state transition matrix as parameters. The following are examples of a text in the Bi–LSTM–CRF model: BI–LSTM–CRF has emerged as a\nstandard method for obtaining per-token vector representations serving as input to various token labeling tasks. We expect that dialog act segmentation in Vietnamese using BI–LSTM–CRFs model will also similar to highly accurate results."
    }, {
      "heading" : "V. EVALUATION",
      "text" : "The simple lexical feature, n–gram (unigram, bigram and trigram), is used for the ME and CRF models. We do experi-\nments on two different conversational data sets (Message data set and Phone data set) after normalizing these data sets using local dialect dictionary and online chat dictionary.\nTraining ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using quasi-Newton methods like L–BFGS [18]. Thus, in the experiments with ME and CRF, we use L-BFGS method. For CRF models, we use second-order Markov dependency. On experiment with CRF, we use tools: FlexCRFs - a C/C++ implementation of CRFs 3. On experiment with Bi–LSTM– CRF, our setup is based on study of Lample et al. 4 [19] .\nFor evaluating each experiments, we randomly divide each corpus into five parts to do 5-fold cross-validation test. In each fold we take one partition for testing and 4 partitions for training. The summary of the experiment results on Message data set is shown in Table III, the experiment results on Phone data set is shown in Table IV. The results of label-based performance evaluation are significantly higher than the results of label-based performance evaluation and chunk-based performance evaluation. The evaluation measures for this task are precision and recall based on labels:\nprecision = number of correctly predicted label by the modelnumber of label predicted by the model ;\nrecall = number of correctly predicted label by the modelnumber of actual label annotated by humans ;\nAveragemacro is the average of the precision and recall of the model on different classes. Averagemicro is sum up the individual true positives, false positives, and false negatives of the model for different classes.\nThe precision and recall based on chunks is as follows:\nprecision = number of correctly predicted FS by the modelnumber of FS predicted by the model ;\nrecall = number of correctly predicted FS by the modelnumber of actual FS annotated by humans ;\nF1– score in the both of evaluations is calculated as follows:\nF1 = 2∗(precision∗recall) (precision+recall) ;\nBI–LSTM–CRF models achieved the highest performance (average F1 of 90.42% with Messages dataset, 73.26% with Phone dataset). This was an indication that it is robust and less affected by the removal of engineering features.\nPerformance results with Messages data (manual texts) are higher than results achieved with Phones data (Automatic Speech Recognition transcripts) because turns in Messages data set are often shorter and less ambiguous for dialog act segmentation than turns in Phone data set. Turns in Phone data set also includes hesitance, repeat, and overlap. These make discontinuous segments, either within a turn or spread over several turns as we have already discussed. A greater challenge is posed by those cases where different functional segments overlapped.\nAnother observation from the results is that Bi-LSTMCRFs, the deep learning approach, performs significantly bet-\n3http://flexcrfs.sourceforge.net/ 4https://github.com/glample/tagger\nter than both CRF and ME, the machine learning approaches, by every measure. Because deep learning has never been used for dialog act segmentation before, this result opens up a very promising new direction for future studies to approach dialog act segmentation and dialog act in general. Between the machine learning approaches, CRF performs better than ME overall. This can be explained by looking at how CRF and ME works. ME is locally re-normalized and suffers from the label bias problem, while CRFs are globally re-normalized. This label bias problem can happen a lot, especially with very context-dependent data sets like Message corpus and Phone corpus."
    }, {
      "heading" : "VI. CONCLUSIONS",
      "text" : "We have presented a thorough investigation on Vietnamese FS identification using machine learning approach and deep learning approach. We built two annotated corpora for evaluation and two dictionaries that make the data sets more uniform and help the models run better. Two machine learning techniques and a deep learning technique are applied and compared on the task of automatic dialog act segmentation. Deep learning technique is also applied for the first time to dialog act segmentation. We also draw some useful conclusions observed from the experimental results that can be very helpful for future studies.\nThese encouraging results show that the task of identifying functional segment is promising to continue to the next dialogue act identification steps and towards understanding intentions in the users’ utterances for Vietnamese. For future work, we intend to extend the studies into two directions. First,\nwe plan to increase the size of our data set to get sufficient amount of instances in different types of functional segment and study deeper methods to solve nested FS identification. Second, we intend to use features included in the data sets as dialogue history, prosody to improve automatic FSs recognition and dialogue processing."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "This work was supported by the project QG.15.29 from Vietnam National University, Hanoi (VNU)."
    } ],
    "references" : [ {
      "title" : "ISO 24617- 2: A Semantically-Based Standard for Dialogue Annotation.",
      "author" : [ "H. Bunt", "J. Alexandersson", "J.W. Choe", "A.C. Fang", "K. Hasida", "V. Petukhova", "A. Popescu-Belis", "D. Traum" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2012
    }, {
      "title" : "An efficient statistical speech act type tagging system for speech translation systems.",
      "author" : [ "H. Tanaka", "A. Yokoo" ],
      "venue" : "In ACL’37,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1999
    }, {
      "title" : "Spoken language understanding: An introduction to the statistical framework.",
      "author" : [ "Y. Wang", "L. Deng", "A. Acero" ],
      "venue" : "IEEE Signal Processing Magazine, vol. 22,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2005
    }, {
      "title" : "Dialogue act recognition approaches.",
      "author" : [ "P. Král", "C. Cerisara" ],
      "venue" : "In Computing and Informatics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Multi-view semisupervised learning for dialog act segmentation of speech.",
      "author" : [ "U. Guz", "S. Cuendet", "D. Hakkani-Tur", "G. Tur" ],
      "venue" : "IEEE transactions on audio, speech, and language processing,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "Shriberg.“Automatic dialog act segmentation and classification in multiparty meetings.\" In: ICASSP’05",
      "author" : [ "Ang", "Jeremy", "Yang Liu", "Elizabeth" ],
      "venue" : "IEEE International Conference on. Vol,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2005
    }, {
      "title" : "Simultaneous dialog act segmentation and classification from human-human spoken conversations.",
      "author" : [ "S. Quarteroni", "A.V. Ivanov", "G. Riccardi" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "Bidirectional LSTM-CRF models for sequence tagging.",
      "author" : [ "Z. Huang", "W. Xu", "K. Yu" ],
      "venue" : "arXiv preprint arXiv:1508.01991,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "How to do things with words.",
      "author" : [ "J.L. Austin" ],
      "venue" : "Oxford university press,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1975
    }, {
      "title" : "A taxonomy of illocutionary acts.",
      "author" : [ "J.R. Searle" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1975
    }, {
      "title" : "Dialogue Act Detection from Human-Human Spoken Conversations.",
      "author" : [ "Ramacandran", "Nithin" ],
      "venue" : "In: International Journal of Computer Applications,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Multifunctionality in dialogue.",
      "author" : [ "H. Bunt" ],
      "venue" : "Computer Speech & Language 25.2,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Measuring nominal scale agreement among many raters",
      "author" : [ "J.L. Fleiss" ],
      "venue" : "Psychological bulletin,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1971
    }, {
      "title" : "A maximum entropy approach to natural language processing.",
      "author" : [ "A. Berger", "S.A.D. Pietra", "V.J.D. Pietra" ],
      "venue" : "Computational Linguistics,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1996
    }, {
      "title" : "Using maximum entropy for text classifi- cation",
      "author" : [ "K. Nigam", "J. Lafferty", "A. McCallum" ],
      "venue" : "IJCAI Workshop on Machine Learn. for Info. Filtering,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1999
    }, {
      "title" : "Conditional random fields: probabilistic models for segmenting and labeling sequence data.",
      "author" : [ "J.D. Lafferty", "A. McCallum", "F. Pereira" ],
      "venue" : "In: ICML,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2001
    }, {
      "title" : "On the limited memory BFGS method for large–scale opti- mization.",
      "author" : [ "D. Liu", "J. Nocedal" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1989
    }, {
      "title" : "Neural architectures for named entity recognition.",
      "author" : [ "G. Lample", "M. Ballesteros", "S. Subramanian", "K. Kawakami", "C. Dyer" ],
      "venue" : "arXiv preprint arXiv:1603.01360,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Because, “Dialog act is a communicative activity of dialog participant, interpreted as having a certain communicative function and semantic content\" [1].",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 1,
      "context" : "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 2,
      "context" : "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 3,
      "context" : "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 4,
      "context" : "implemented DA segmentation of speech using multi-view semisupervised learning [5]; Jeremy Ang et al.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 5,
      "context" : "explored DA segmentation using simple lexical and prosodic knowledge sources [6]; Warnke et al.",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "segmented human-human dialog into turns and intra-turn segmentation into DA boundaries using CRFs to learn models for simultaneous segmentation of DAs from whole human-human spoken dialogs [8].",
      "startOffset" : 189,
      "endOffset" : 192
    }, {
      "referenceID" : 0,
      "context" : "According to ISO 24617-2 standard about Dialog Act, a functional segment (FS) is defined as “minimal stretch of communicative behavior that have a communicative function\" [1].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 7,
      "context" : "Recently, ME, CRF and Bi–LSTM–CRF have been applied to a variety of sequence labeling and segmentation tasks in Natural Language Processing and have achieved state-ofthe-art results [9].",
      "startOffset" : 182,
      "endOffset" : 185
    }, {
      "referenceID" : 8,
      "context" : "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 9,
      "context" : "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : "functional segment identification and 3) the classification of each segment according to a DA tag [12].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 0,
      "context" : "A functional segment is the “minimal stretch of communicative behavior that has a communicative function”, “minimal in the sense of not including material that does not contribute to the expression of the function or the semantic content of the dialogue act\" [1].",
      "startOffset" : 259,
      "endOffset" : 262
    }, {
      "referenceID" : 11,
      "context" : "The detailed explanation of the types of FS is presented in [13] and the ISO 24617-2 standard.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "87 Fleiss’ kappa measure [14].",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 13,
      "context" : "The ME (Maxent) model defines conditional distribution of class (y) given an observation vector t as the exponential form in Formula (1) [15]:",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 14,
      "context" : "We decided to use ME for evaluation and comparison because it is commented that it is suitable for sparse data like natural language, encode various rich and overlapping features at different levels of granularity [16].",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 15,
      "context" : "The CRFs model defines also the conditional distribution of the class (y) given an observation vector t as the Formular (1) [17].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 16,
      "context" : "Training ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using advanced convex optimization techniques like L–BFGS [18].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 7,
      "context" : "Bi–LSTM–CRF network is formed by combining a bidirectional LSTM network and a CRF network [9].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 16,
      "context" : "Training ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using quasi-Newton methods like L–BFGS [18].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 17,
      "context" : "4 [19] .",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "[1] Bunt, H.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] Tanaka, H.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] Y.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] Král, P.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] Guz, U.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] Ang, Jeremy, Yang Liu,Elizabeth Shriberg.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[8] Quarteroni, S.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[9] Huang, Z.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[10] Austin, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[11] Searle, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[12] Ramacandran, Nithin.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[13] Bunt, H.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[14] Fleiss, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[15] Berger, A.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[16] Nigam, K.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[17] Lafferty, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[18] Liu, D.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[19] Lample, G.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2017,
    "abstractText" : "Dialog act identification plays an important role in understanding conversations. It has been widely applied in many fields such as dialogue systems, automatic machine translation, automatic speech recognition, and especially useful in systems with human-computer natural language dialogue interfaces such as virtual assistants and chatbots. The first step of identifying dialog act is identifying the boundary of the dialog act in utterances. In this paper, we focus on segmenting the utterance according to the dialog act boundaries, i.e. functional segments identification, for Vietnamese utterances. We investigate carefully functional segment identification in two approaches: (1) machine learning approach using maximum entropy (ME) and conditional random fields (CRFs); (2) deep learning approach using bidirectional Long Short-Term Memory (LSTM) with a CRF layer (Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages (Message data); (2) transcription from phone conversations (Phone data). To the best of our knowledge, this is the first work that applies deep learning based approach to dialog act segmentation. As the results show, deep learning approach performs appreciably better as to compare with traditional machine learning approaches. Moreover, it is also the first study that tackles dialog act and functional segment identification for Vietnamese. Keywords—Dialog act segmentation, functional segment, Vietnamese conversation.",
    "creator" : "LaTeX with hyperref package"
  }
}