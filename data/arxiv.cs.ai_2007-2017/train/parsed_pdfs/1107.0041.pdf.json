{
  "name" : "1107.0041.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Ariel Felner", "Roni Stern", "Asaph Ben-Yair", "Nathan Netanyahu" ],
    "emails" : [ "felner@bgumail.bgu.ac.il", "sternr2@cs.biu.ac.il", "benyaya@cs.biu.ac.il", "sarit@cs.biu.ac.il", "nathan@cs.biu.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Journal of Arti cial Intelligence Research 21 (2004) 631-670 Submitted 9/03; published 6/04PHA*: Finding the Shortest Path with A* in An UnknownPhysical EnvironmentAriel Felner felner@bgumail.bgu.ac.ilDepartment of Information Systems Engineering,Ben-Gurion University of the Negev, Beer-Sheva, 85104, IsraelRoni Stern sternr2@cs.biu.ac.ilAsaph Ben-Yair benyaya@cs.biu.ac.ilSarit Kraus sarit@cs.biu.ac.ilNathan Netanyahu nathan@cs.biu.ac.ilDepartment of Computer Science, Bar-Ilan UniversityRamat-Gan, Israel, 52900 AbstractWe address the problem of nding the shortest path between two points in an unknownreal physical environment, where a traveling agent must move around in the environmentto explore unknown territory. We introduce the Physical-A* algorithm (PHA*) for solvingthis problem. PHA* expands all the mandatory nodes that A* would expand and returnsthe shortest path between the two points. However, due to the physical nature of theproblem, the complexity of the algorithm is measured by the traveling e ort of the movingagent and not by the number of generated nodes, as in standard A*. PHA* is presented asa two-level algorithm, such that its high level, A*, chooses the next node to be expandedand its low level directs the agent to that node in order to explore it. We present anumber of variations for both the high-level and low-level procedures and evaluate theirperformance theoretically and experimentally. We show that the travel cost of our bestvariation is fairly close to the optimal travel cost, assuming that the mandatory nodes ofA* are known in advance. We then generalize our algorithm to the multi-agent case, wherea number of cooperative agents are designed to solve the problem. Speci cally, we providean experimental implementation for such a system. It should be noted that the problemaddressed here is not a navigation problem, but rather a problem of nding the shortestpath between two points for future usage.1. IntroductionIn this paper we address the problem of nding the shortest path between two pointsin an unknown real physical environment, in which a mobile agent must travel aroundthe environment to explore unknown territories. Search spaces of path- nding problemsare commonly represented as graphs, where states associated with the search space arerepresented by graph nodes, and the transition between states is captured by graph edges.Graphs can represent di erent environments, such as road maps, games, and communicationnetworks. Moving from one node of the graph to another can be done by applying logicaloperators that manipulate the current state or by having an actual agent move from onenode to another. The sliding-tile puzzle and Rubik's Cube (Korf, 1999) are examples of thec 2004 AI Access Foundation. All rights reserved.\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu rst type, while a road map is an example of the second type. Graphs in search problemscan be divided into the following three classes: Fully known graphs: If all the nodes and edges of a graph are stored in the com-puter, then the graph is fully known. The input for such problems is usually thecomplete graph which is represented by an adjacency matrix or an adjacency list. Arelevant problem in this case would be to nd, for example, the shortest path in aroad map in which all the nodes and edges are known in advance. Very large graphs: Graphs that due to storage and time limitations are not com-pletely known and cannot be fully stored in any storage device. Many graphs forsearch problems have an exponential number of nodes. For example, the 24-tile puz-zle problem has 1025 states and cannot be completely stored on current machines.The input for such problems is usually speci ed by the general structure of a statein the search space, the di erent operators, an initial state, and a set of goal states.Only very small portions of such graphs are visited by the search algorithms or arestored in memory. Small, partially known graphs: The third class contains graphs that represent apartially known physical environment. For example, a mobile agent in an unknownarea without a map does not have full knowledge of the environment. Given enoughtime, however, the agent can fully explore the environment since it is not very large.Due to the partial knowledge, only a small portion of the graph is given as input.For the class of fully-known graphs, classical algorithms, such as Dijkstra's single-sourceshortest-path algorithm (Dijkstra, 1959) and the Bellman-Ford algorithm (Bellman, 1958),can be used to nd the optimal path between any two nodes. These algorithms assume thateach node of the graph can be accessed by the algorithm in constant time. This assumptionis valid since all the nodes and edges of the graph are known in advance and are stored inthe computer's memory. Thus the time complexity of these algorithms is measured by thenumber of nodes and edges that they process during the course of the search.For the second class of graphs the above algorithms are usually not e cient, since thenumber of nodes in the graph is very large (usually exponential). Also, only a very smallportion of the graph is stored in memory at any given time. The A* algorithm (Hart, Nils-son, & Raphael, 1968) and its linear space versions, e.g., IDA* (Korf, 1985) and RBFS (Korf,1993), are the common methods for nding the shortest paths in large graphs. A* keeps anopen list of nodes that have been generated but not yet expanded, and chooses from it themost promising node (the best node) for expansion. When a node is expanded it is movedfrom the open list to the closed list, and its neighbors are generated and put in the openlist. The search terminates when a goal node is chosen for expansion or when the openlist is empty. The cost function of A* is f(n) = g(n) + h(n); where g(n) is the distancetraveled from the initial state to n, and h(n) is a heuristic estimate of the cost from noden to the goal. If h(n) never overestimates the actual cost from node n to the goal, we saythat h(n) is admissible. When using an admissible heuristic h(n), A* was proved to beadmissible, complete, and optimally e ective (Dechter & Pearl, 1985). In other words, withsuch a heuristic, A* is guaranteed to always return the shortest path. Furthermore, any632\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentother algorithm claiming to return the optimal path must expand at least all of the nodesthat are expanded by A* given the same heuristic.An A* expansion cycle is carried out in constant time. This is because it takes a constantamount of time to retrieve a node from the open list, and to generate all its neighbors. Thelatter involves applying domain-speci c operators to the expanded node. Thus the timecomplexity of A* can also be measured in terms of the number of generated nodes.1In this paper we deal with nding the shortest path in graphs of the third class, i.e.,small, partially known graphs which correspond to a real physical environment. Unlikegraphs of the other two classes, where a constant number of computer operations are donefor node expansion, we cannot assume, for this type of graphs, that visiting a node takesconstant time. Many of the nodes and edges of this graph are not known in advance.Therefore, to expand a node that is not known in advance, a mobile agent must rst travelto that node in order to explore it and learn about its neighbors. The cost of the search inthis case is the cost of moving an agent in a physical environment, i.e., it is proportionalto the distance traveled by the agent. An e cient algorithm would therefore minimize thedistance traveled by the agent until the optimal path is found. Note that since small graphsare considered here, we can omit the actual computation time and focus only on the traveltime of the agent. In this paper we introduce the Physical-A* algorithm (PHA*) for solvingthis problem. PHA* expands all the mandatory nodes that A* would expand and returnsthe shortest path between the two points. However, the complexity of the algorithm ismeasured by the traveling e ort of the moving agent. In order to minimize the travelingAs will be shown, PHA* is designed to to minimize the traveling e ort of the agent byintelligently choosing the next assignment of the traveling agent. As described below, manytimes the agent chooses to rst move to nearby nodes even though they do not immediatelycontribute to the proceeding of A*.Unlike ordinary navigation tasks (Cucka, Netanyahu, & Rosenfeld, 1996; Korf, 1990;Stentz, 1994; Shmoulian & Rimon, 1998), the purpose of the agent is not to reach the goalnode as soon as possible, but rather explore the graph in such a manner that the shortestpath will be retrieved for future usage. On the other hand, our problem is not an ordinaryexploration problem (Bender, Fernandez, Ron, Sahai, & Vadhan, 1998), where the entiregraph should be explored in order for it to be mapped out. Following are two motivatingexamples of real world applications for our problem: Example 1: A division of troops is ordered to reach a speci c location. The coordi-nates of the location are known. Navigating with the entire division through unknownhostile territory until reaching its destination is unreasonable and ine cient. It is com-mon in such a case to have a team of scouts search for the best path for the division topass through. The scouts explore the terrain and report the best path for the divisionto move along in order to reach its destination in an e cient manner.1. In fact, for A*, if the open list is stored as a priority queue, then it would take logarithmic time toretrieve the best node. However, for many problems, such as the sliding tile puzzles and Rubik's Cube,a simple rst-in rst-out queue su ces (Korf, 1993; Taylor & Korf, 1993; Korf, 1997). Likewise, for thelinear space versions, such as IDA* and RBFS (which are based on depth- rst search), the assumptionthat it takes constant time per each node is valid. Also we assume that the number of neighbors isbounded. 633\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu Example 2: Computer systems connected to networks can be on- or o -line atdi erent times, and their throughput can be seriously degraded due to busy commu-nication channels. Therefore, many networks cannot be represented as xed, fullyknown graphs. Transferring large amounts of data (e.g., multimedia les) betweentwo computers over a network can often be time consuming, since the data may berouted through many communication channels and computer systems before reachingtheir destination. Finding the optimal path between these computer systems couldimprove the transfer time of large les. Since the network may not be fully known, nding an optimal path between two nodes requires some exploration of the network.An e cient and elegant solution might be to send small packets (operating as scouts)to explore the network and return the optimal path, given that the network is stablefor at least a short period of time. Assuming that a computer system on the networkis recognized only by its neighboring systems, we are faced with the problem of ndingan optimal path in a real physical environment.2In general, it would be worthwhile to search for the optimal path when the followingconditions hold: Preliminary search (with the usage of scouts) is possible and cheap. The optimal path is required for future usage.Often one might settle for a suboptimal path. However, if the path is needed for aconsiderable tra c volume, e.g., the path should be traveled a large number of times orthe path should be traveled simultaneously by a large number of agents, then nding theoptimal path is essential. In this paper we focus on solving such a problem.The paper is organized as follows. Section 2 provides a more speci c formulation ofthe problem in question. Section 3 discusses related work, and Section 4 presents thePHA* algorithm for a single mobile agent. Several (enhanced) variations are introducedand discussed for this domain, followed by extensive empirical results that demonstrate thesuperiority of the more enhanced variants pursued. In Section 5 we provide an analysis ofPHA* and an overall evaluation of its performance. In Section 6, we provide a number ofgeneralizations for the multi-agent case, where a number of traveling agents are available forsolving the problem. Experimental results for these schemes are presented and discussed.Section 7 contains concluding remarks and discusses future research. A preliminary versionof this paper appeared earlier (Felner, Stern, & Kraus, 2002).2. Our research is concerned with high-level, abstract graphs and we do not intend to provide here a newapplicable routing algorithm. Current routing technologies maintain large databases that store the bestpaths from node to node, broadcast changes in the network, and update the paths if necessary, thusmaking essentially the network graph fully known. Also, in some network domains one can create anddestroy packages at will and thus does not necessarily have a given number of agents. Our algorithmmay be relevant to future network architectures and routing technologies, where routers will not usethese databases. This is not far-fetched in view, for example, of the rapid growth of the Internet. It isthus conceivable that in the future storing all the paths would become infeasible.634\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment2. Problem Speci cationAs was mentioned in general terms, the problem is to nd the shortest path between twonodes in an unknown undirected graph. More speci cally, we assume a weighted graph,where each node is represented by a 2-dimensional coordinate (i.e., its location in the realworld), and the weight of an edge is the Euclidean distance between its two nodes. Theinput to the problem consists of the coordinates of the initial and goal nodes. The othernodes are assumed not to be known in advance. The agent is assumed to be located atthe start node. The task is to nd the shortest path in the (unknown) graph between theinitial node and the goal node for future usage. In order to accomplish that, the agent isrequired to traverse the graph and explore its relevant parts leading to the desired solution.The agent is allowed to visit nodes and travel from one node to another via existing edges.We assume here that when a node v is visited by the search agent, the neighboringnodes are discovered, as well as the edges connecting them to v. This assumption is notunreasonable, considering, e.g., that (tra c) signs at a road intersection often indicate itsneighboring destinations and the lengths of the corresponding road segments that connectit with these locations. Even without road signs, as scouts reach a new location, they canlook around, observe the neighboring locations, and assess their distances from their currentlocation. In general, the assumption that the neighboring nodes are discovered instantly isfairly common in search problems and algorithms.3Since the goal of the search is to nd the best path to the goal, it is clear { givenan admissible heuristic { that the agent must expand all nodes expanded by A*, as A*is optimally e ective (Dechter & Pearl, 1985). Let C be the length of the shortest pathfrom the initial node to the goal node. A* will expand all the nodes, such that, f(n) =g(n) + h(n) < C and some of the nodes for which f(n) = C. We will refer to these nodesas the (set of mandatory) A* nodes. As stated above, the agent must visit all the A* nodesin order to nd the shortest path. However, it may need to visit additional nodes.We make the following fundamental observations with respect to the problem in ques-tion: First, even if the set of A* nodes is known in advance, the agent may need to visitadditional nodes while traversing related portions of the graph. This is because theshortest path between two of the A* nodes may include graph nodes that do notbelong to the A* nodes, i.e., their f value is greater than C. Given the A* nodes, nding the shortest path that visits all of them { this should not be confused withthe shortest path between the origin node and the goal node { could be consideredas solving the traveling salesman problem (TSP) with respect to the set of A* nodes.Note that the TSP solution may include nodes that do not belong to the A* nodes. Second, the agent does not know the A* nodes in advance. These nodes are added tothe open list and they are expanded as the search progresses. Thus our agent cannotuse a solution to the TSP, since TSP assumes that the nodes to be visited are providedas input.3. There are, however, domains where this assumption may not hold. In such domains, a node becomesfully known only when the agent reaches it physically. In this work we restrict ourselves to the aboveassumption. Other domains will be addressed as part of future work.635\nFelner, Stern, Ben-Yair, Kraus, & NetanyahuIn most of the cases, the order in which A* nodes are expanded is very di erent fromthe order in which they are visited according to the TSP solution. Thus the minimalpath traversing the A* nodes cannot be used. Third, when a node is added to the open list the agent cannot know whether or not itbelongs to the A* nodes, since C is known only after the search is concluded. Considera node n that is in the open list, but is not at the head of the open list. Supposefurther that the agent is physically located near that node. It should decide whetherto slightly extend its path and visit node n or skip n and continue to the node atthe head of the open list. If n turned out to belong to the A* nodes, then visiting itnow may prove very bene cial. (This is because n might reach the head of the openlist when the agent will be physically located far away from it, so that visiting n atthat point will incur a signi cant travel cost.) However, if it turns out that n doesnot belong to the A* nodes, then the (small) detour of visiting it has proven useless.Intuitively, however, a decision never to visit such would result in a very bad strategy.Thus the agent may visit nodes that do not belong to the A* nodes because of futureexpected bene ts. The actual decision as to whether or not to visit n will depend onthe distance between the agent's location and n (at the time of the decision) and onthe agent's estimate as to whether n belongs to the set of A* nodes.In the following sections we present the PHA* algorithm for e cient exploration of agraph, in order to nd the shortest path between two given nodes by a single travelingagent, as well as by multiple agents. We study di erent heuristics that direct the agent tomake an intelligent decision, in an attempt to achieve a small overall travel cost.3. Related WorkMuch research has been devoted to guiding a mobile agent for exploring new and unknownenvironments in order to study them and map them out. Our work is di erent, in thesense that it explores merely the necessary regions of the graph in order to retrieve theshortest path between two nodes and not the entire graph. Most of the literature in thisarea deals with a physical mobile robot that moves in a real environment. The publishedresearch focuses usually on the issue of assisting the robot to recognize physical objects inits environment. We refer the reader to (Bender et al., 1998), which contains an extensivesurvey of various related approaches and state of the art techniques.Another class of algorithms is navigation algorithms. A navigation problem is concernedwith navigating a mobile agent to the goal as fast as possible, not necessarily via the shortest(optimal) path. A navigator will always proceed towards the goal, ignoring whether thetrail traversed thus far lies on the shortest path. Deviations from the optimal path areneglected since the navigation problem is reconsidered after every move with respect to anew source node, i.e., the current position of the agent. A navigation algorithm halts whenthe mobile agent reaches the goal. The path passed usually lacks importance and is usuallynot optimal. Our problem, on the other hand, is to nd an optimal path to the goal nodefor future usage. Even if the agent nds a path to the goal node, the search continues until636\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentthe shortest path to the goal is found. Next, we describe brie y some of the work done onnavigation in partially known graphs.(Cucka et al., 1996) have introduced navigation algorithms for sensory-based envi-ronments such as automated robots moving in a room. They have used depth rst search(DFS)-based navigation algorithms, that use a heuristic function for choosing the next nodethat the agent should go to.Real-Time-A* (RTA*) (Korf, 1990) and its more sophisticated version, Learning Real-Time-A* (LRTA*), are also algorithms for nding paths between two nodes in a graph.However, they deal with large graphs and assume that there is a constraint on the time ofcomputation and that a move should be retrieve in a given constant time. Thus a limitedsearch is performed, and the node with best cost in the search frontier is picked. Theproblem solver then moves one step along the path to that node. The search then continuesfrom the new state of the problem solver. The merit of node n (in RTA* and LRTA*) isf(n) = g(n) +h(n), similarly to A*. Unlike A*, though, g(n) is the actual distance of noden from the current state of the problem solver, rather than from the original initial state.The di erence between RTA* and LRTA* is that after the search is terminated, LRTA*also stores the heuristic estimation value of each node visited by the problem solver. Alsothe method that successor nodes are chosen are di erent for the two variations. Korf (Korf,1990) proves that over a large number of runs, where for each run the start node is selectedat random, the stored value of each node visited by the LRTA* problem solver convergesto the optimal distance to the goal. Both RTA* and LRTA* are signi cantly di erent fromour approach, as they assume that a node can be expanded in the computer's memorywithout an agent having to physically visit that node. (Also, these algorithms are designedfor large graphs.) Furthermore, RTA* does not nd the optimal path to the goal. A trivialversion of LRTA* could be used to solve our problem, e.g., by limiting the search depth toone level, so that every node visited by the agent could be physically expanded. However,such a variant will not be competitive with our approach, as it will perform like a simplehill-climbing procedure. In addition, in order to attain the optimal path, LRTA* has toselect many start nodes at random. This is not relevant in our case, as we are given onlyone initial node.MARTA* (Knight, 1993) is a multi-agent version of RTA*. In MARTA* every agent runsRTA* independently. Kitamura et al. (Kitamura, Teranishi, & Tatsumi, 1996) have mod-i ed MARTA* by using coordination strategies based on attraction and repulsion. Thesestrategies are employed only in tie-breaking situations. When using a repulsion strategy,the idea is to spread agents, such that each agent intends to maximize its distance from theothers. Again, the path provided by this algorithm is not optimal and also, agents do notneed to physically visit a node in order to expand it. This work has inspired the algorithmspresented in this paper, as far as handling our multi-agent mutual decision is concerned.Life-long planing A* (LPA*) (Koenig & Likhachev, 2002b) is a remarkable algorithmthat generalizes A* to handle a dynamically changing graph. LPA* is activated every timethe graph was changed in order to nd the current shortest path from the same given startand goal nodes. It utilizes the fact that much of the old data explored by previous runs ofLPA* are still valid in the current run. A* is a special case of LPA* where the entire graphhas not been explored yet. 637\nFelner, Stern, Ben-Yair, Kraus, & NetanyahuD*-lite (Koenig & Likhachev, 2002a) applies LPA* to the case that a mobile robot needsto nd the shortest path in an unknown environment or in an environment that changesdynamically (i.e., where edges are added and deleted at all times). In LPA*, the startnode is identical for all the runs. In D*-lite, however, the robot moves along the path andcalculates a new shortest path from its current location. D*-lite modi es LPA* so thatold data from previous runs will be e ciently used in the case that the start node is alsochanged according to the new location of the robot. D*-Lite is actually a simpli ed versionof a previous algorithm D* by Stenz (Stentz, 1994).The main di erence between these algorithms and our approach is that they, too, expanda node in the computer's memory without requiring that the mobile agent physically visitthat node. Indeed, following every move of the robot in D* Lite, changes in the graph areprovided immediately ; the robot does not need to physically visit nodes in order to gather rsthand this information. The task of the agent, in the context of D*, is to repeatedlydetermine the shortest path between the current location of the robot and the goal locationas the edge costs of the graph changes while the robot moves. D* lite does not nd a pathand returns it. It is simply a navigation algorithm that guides the agent to the goal nodebased on previous and new information about the terrain.An agent operating in the real world must often choose between maximizing its expectedutility (according to its current knowledge of the \\world\") and learning more about itsenvironment, in an attempt to improve its future gains. This problem is known as the trade-o between exploitation and exploration in reinforcement learning (Kaelbling & Moore,1996). Argamon et al. (Argamon-Engelson, Kraus, & Sina, 1998, 1999) address the trade-o between exploration and exploitation for an agent that moves repeatedly between twolocations. They propose a utility-based on-line exploration algorithm which takes intoaccount both the cost of attempting to improve the currently best route known and anestimate of the potential bene ts over future task repetitions. If the expected utility fromexploration is positive, then the agent takes actions to improve its route; otherwise, itcontinues using the known path. The authors compare the utility-based on-line explorationwith a heuristic backtracking search algorithm that exhaustively searches the graph beforestarting to perform the task, and with a randomized interleaved exploration algorithm.They assume that the agent knows a path between any two nodes, while we make no suchassumption.Argamon et al. also suggest that the larger the number of times that the task is repeated,the more the merit of interleaved exploration diminishes. If the agent is required to moveback and forth between two nodes a large number of times, there is no need to decideon-line whether to exploit or explore; instead, the shortest path should be found as soonas possible. Thus a good search algorithm may prove useful. In this respect our workcomplements Argamon et al., as it provides e cient search algorithms in situations wherethe optimal path is needed in advance. In contrast, applying the techniques of Argamon etal. in these situations yields poor results as demonstrated in their experiments.Roadmap-A* (Shmoulian & Rimon, 1998) is a more sophisticated single agent navigationalgorithm. It chooses to navigate to a node that is assumed to be close to the goal node. Thealgorithm is supervised by a high-level procedure called A \" (Pearl & Kim, 1982). Insteadof always selecting the best node from the open list, A \" allows the search agent to choosefrom a set of \\good nodes\". This set is called the focal set. The focal is a set of nodes from638\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentthe open list whose f value is greater than the value of the best node by no more than \".Once the focal nodes are determined, a local search is performed to navigate the agent toone of these nodes, which is believed to be close to the goal node. The role of the high-levelphase is to prevent the navigating agent from going in the wrong direction by consideringalso the path traveled thus far.In Roadmap-A*, \" is a pre-speci ed constant, which determines the trade-o betweenthe local search and A*. For example, A0 is A* while A1 is just a local search, choosingat each iteration any node that is believed to be close to the goal node. This algorithmhalts when the goal node is reached, and thus for \" > 0 the optimal path might not beknown. The paradigm of Roadmap-A* is similar to ours, in the sense that a node is knownonly after the agent explores it. In fact, in the trivial case where \" = 0, Roadmap-A* isvery similar to our approach with the simple heuristic \\shortest-known path\" (presented inSubsection 4.1 below). Further comments as to the basic di erence between RoadmapA*and PHA* are provided in Section 5.In summary, most of the above listed algorithms are navigation algorithms, i.e., they donot necessarily require an agent to physically visit a node in order to expand it, and do notnecessarily return the optimal path to the goal node. Thus they inherently solve a di erentproblem from the one pursued in this paper.4. PHA* for a Single AgentWe now turn to the description of the PHA* algorithm, focusing rst on the case whereonly a single mobile agent is available.Nodes in the environment can be divided into explored and unexplored nodes. Exploringa node means physically visiting that node by the agent, and learning about its locationand the location of its neighbors. Our new algorithm PHA* activates essentially A* on theenvironment. However, in order to expand a node by A*, this node must rst be exploredby the agent in order to obtain the relevant data associated with it (i.e., neighboring nodesand incident edges). Throughout the discussion in this paper we treat PHA* as a two-level algorithm. Although in principle PHA* could also be viewed as a one-level algorithm(see further discussion in Subsection 4.2), we nd its two-level presentation to be morewell-structured and better understood conceptually. The two-level framework consists of ahigh-level and a low-level routine. The high level (which invokes the low level at variousstages of PHA*), acts essentially like a regular A* search algorithm. It chooses at eachcycle a node from the open list for expansion. The heuristic function h(n) used here is theEuclidean distance between n and the goal node. (This heuristic is admissible of course, byde nition.) If the node chosen by the high level has not been explored by the agent, thelow level, which is a navigation algorithm, is activated to navigate the agent to that nodeand explore it. After a node has been explored by the low level it is expandable by the highlevel. If the chosen node has already been explored, or if its neighbors are already known,then it is readily expandable by the high level without the need to send the agent to visitthat node. The pseudo-code for the high level is given below.639\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuhigh-level(open-list) f. while(open-list is not empty) f. target = best node from open-list;. if target is unexplored then f. explore(target) by the low level;. g. expand(target);. gg4.1 Low-Level AlgorithmsThe high-level algorithm, A*, chooses to expand the node with the smallest f value in theopen list, regardless of whether or not the agent has already visited that node. If the chosennode has not been visited by the agent, the low level instructs the agent to visit that node.We call this node the target node for the low level. In order to reach the target node, wemust use some navigation algorithm. We have implemented a number of navigation variantsfor the low level. We rst describe simple algorithms which only use known informationabout the graph. We then present more e cient algorithms, which also explore the graphduring the navigation and provide new information for the high level. We assume that theagent is in the current node and that it needs to navigate to the target node.4.1.1 Simple Navigation Algorithms Tree path: Like every best- rst search, A* spans the nodes which it generates in atree which is called the search tree. Every known node is a node in the search tree. Themost trivial way to move from one node to the other is through the search tree. Thetree-path algorithm instructs the agent to move from the current node to the targetnode through the shortest path between them in the search tree. In other words,the agent will walk up the tree from the current node until it reaches an ancestor ofthe target node, and then walk from that node to the target node. This is a trivialalgorithm, and is presented here mainly for comparison purposes. Shortest known path: Some of the nodes of the search tree have already beenexplored by the agent, so that all of their incident edges are known. The search treenodes plus the additional edges of the explored nodes can be viewed as a subgraphthat is fully known. All the nodes of this subgraph are connected because they areall part of the search tree. Using this subgraph, we can calculate the shortest path tothe target node via known nodes and edges. As mentioned above, nding the shortestpath in a known graph can be done easily, so the agent simply computes this shortestpath to the target node and travels along that path.4 Aerial path: Assuming that the agent is able to move freely in the environment andis not restricted to the edges of the graph, we can simply move the agent from the4. This navigation algorithm is similar to the local A* search in Roadmap-A* for the trivial case where\" = 0. In Roadmap-A*, the shortest path to the target node is determined in the known graph and theagent moves along that path. 640\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentcurrent node to the target node via the straight line connecting these nodes. Thismethod may be relevant when the search agents are highly mobile, and they explorethe environment for agents that are restricted to travel only along the edges. Notethat the length due to \\aerial path\" can never be greater than the length due \\shortestknown path\".4.1.2 DFS-Based Navigation AlgorithmsIn the simple navigation algorithms described above, the exploration of new nodes is doneonly by the high-level algorithm. Thus the low level does not add any new knowledge aboutthe graph, and in that sense it is ine cient. We propose here more intelligent navigationapproaches for nding a path to the target that can pass also trough unexplored nodes.These approaches provide the following advantages: The paths that are currently known tothe agent may be much longer than other paths that have not been explored yet. It mayprove more e cient to navigate through unknown parts of the graph if they seem to lead toa better path to the target. A more important advantage is that while navigating throughunknown parts of the graph, the agent might visit new nodes that have not been exploredand explore them on the y. This may save the need to travel back to those nodes at alater time, should they be selected for expansion by the high-level algorithm.The above advantages suggest the use of a DFS-based navigation for the low level. Ina DFS-based navigation algorithm, the search agent moves to a neighboring node, that hasnot been visited, in a typical DFS manner. The algorithm backtracks upon reaching a dead-end and the search continues until it reaches the target. If there is more than one neighbor,we use a heuristic to evaluate which neighbor is more likely to lead faster to the target,and visit that node rst. We have experimented with the following DFS-based navigationalgorithms that were proposed by (Cucka et al., 1996): Positional DFS (P-DFS):This DFS-based navigation algorithm sorts the neighborsaccording to their Euclidean distance from the target node, choosing the node withminimum distance to the target node rst. Directional DFS (D-DFS): This DFS-based navigation algorithm sorts the neigh-bors according to the direction of the edges between them and the current node v. It rst chooses the node u for which the di erence in angle between the line segments(v; u) and (v; t) is the smallest, where t denotes the target node. In other words, thenodes are prioritized by the directional di erence between them and the target node,giving priority to nodes that di er the least. A*DFS: A*DFS is an improved version of P-DFS. At each step the agent choosesthe neighbor w that minimizes the sum of the distances from the current node v tow and from w to the target node t. We call it A*DFS since it uses a cost functionwhich is similar to that of A*, i.e., f(n) = g(n)+h(n).5 Note, however, that this costfunction is used here locally to nd a path from the current node to the target node.5. A generalized version of navigating with a cost function similar to that of A* called \\robotic A*\" (RA*),was also proposed by (Cucka et al., 1996); the node w is either a neighbor (of v) or an already visitednode. 641\nFelner, Stern, Ben-Yair, Kraus, & NetanyahuThis is di erent from the high-level A* which uses this cost function to nd a pathfrom the input initial state to the input goal state. TC R\nD\nP\nA 1 2\nFigure 1: Illustration of various low-level navigation algorithms.Figure 1 illustrates the navigation algorithms listed above. Let R denote the sourcenode, and suppose that the search agent is currently at node C, and that the high-levelprocedure chooses to expand node T . The squared nodes have already been visited by theagent, i.e., they have already been explored. These nodes and the edges connecting themcomprise the tree spanned by the high-level A* search. Since T has yet to be explored, thelow-level procedure will now navigate to the target node T . The tree path will navigatealong the path C 1 R 2 T , whereas the shortest known path will navigate along thepath C 1 2 T . Note that since node A has yet to be explored, the path from C to T viaA is not known at this point. The aerial path will go directly from C to T . Using one of theDFS-based navigations, the agent will move to T via P , D, or A depending, respectively,on whether P-DFS, D-DFS, or A*DFS was used. The bene t of the DFS-based algorithmsis that they explore new nodes during the navigation (nodes P , D, and A in the aboveexample), and they will not revisit such nodes, should the high-level procedure expandthem at a later stage.4.2 Enhanced PHA*4.2.1 PHA* as a One-Level ProcedureAs mentioned in the previous subsection, PHA* can be presented in principle as a one-levelalgorithm. This can be done as follows. Whenever the best node in the open list is known(i.e., it has been explored), an expansion cycle of A* takes place in the background, anda new best node is determined. Upon arriving at a node, the agent makes a navigationdecision as follows: If the best node in the open list is one of the current node's neighbors, then the agentmoves to that node. Otherwise, the agent moves to the neighboring node that minimizes the relevantheuristic function (among the variants proposed in the previous subsection).642\nPHA*: Finding the Shortest Path with A* in An Unknown Physical EnvironmentAny of the these heuristics would be valid for a heuristic function of this one-levelalgorithm. (The latter should not be confused with the heuristic function that is associatedwith the A* expansion cycle.) For example, if the agent is at node v, then using A*DFS itwill visit the neighbor w that minimizes the sum of the distances from the current node vto w and from w to the best current node in the open list.The compact one-level presentation notwithstanding, we prefer { for reasons of clarity{ to use the two-level formulation of PHA*. We believe that the clear distinction betweenthe high-level A* and the low-level navigation procedure provides an overall frameworkthat is well-structured and conceptually more clearly understood. In addition, the two-level framework lends itself naturally to the two enhancements presented in the followingsubsections.These enhancements draw on the basic principle that navigation might proceed notnecessarily to the best node, but to a di erent node that is fairly close to the currentlocation of the agent. (The idea being that in the long run this would prove bene cial.) Thisprinciple can be realized under two main scenarios: (1) When navigating to the best node,the agent might choose rst to visit a nearby neighbor, and (2) the procedure might chooseto ignore the best node in the open list and select instead a di erent node from the open listwhich is very close to the agent's location. In the context of the two-level framework, the rst scenario corresponds to a low-level enhancement (see I-A*DFS below), and the secondscenario corresponds to a high-level enhancement (see WinA*, subsection 4.2.3).For all of the above reasons, we choose to stick with our proposed two-level approach ofPHA*.4.2.2 Improved Low Level: I-A*DFSThe DFS-based navigation algorithms explore new nodes as they traverse the graph, therebyavoiding future navigations should these nodes be selected later for expansion by the highlevel. While this is very bene cial, as can be seen from the experimental results of the nextsubsection, we can take this approach much further.Suppose that the agent is navigating to a target node. Along the way, it may pass nearnodes that have a small f value without visiting them, as they are not on the path to thetarget node according to the navigation algorithm. This is counter-productive, since nodeswith small f values are likely to be chosen for expansion by the high level in the near future.Visiting such nodes when the agent is nearby, may save a lot of traveling e ort in the future.In order to motivate the agent to visit such nodes, we want to identify them and arti ciallydecrease their cost value (without changing the value of other nodes).To incorporate this notion, we introduce the Improved A*DFS (I-A*DFS) variant. Thebasic concept is that while navigating to a target, the low level will select the next node tovisit by considering not only its approximate distance from the target but also the node's fvalue. On its way to the target, I-A*DFS should tend to visit, on the one hand, nodes witha small f value, and avoid visiting, on the other hand, nodes that are completely o track.Let T and n denote, respectively, the target node and the neighboring node that is beingcurrently evaluated. Also, let f(:) denote the f value of a node provided by the high-levelA*, and let c1, c2 denote constants to be speci ed. We used the following heuristic functionfor selecting the next node by I-A*DFS: 643\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuh(n) = ( A DFS(n) 1 c1 f(T )f(n) c2 if n 2 OPENA DFS(n) otherwise: (1)If a neighbor n is not in the open list, then its h(n) value due to A*DFS remains intact. If,however, the neighboring node is in the open list, then I-A*DFS considers also the goodnessof its f value. The node's h(n) is adjusted according to a product term that decreases withthe node's f value (i.e., a node with a small f value will be assigned a smaller heuristic)6.Speci cally, the goodness of f is measured by the ratio f(T )=f(n). The target node T hasthe smallest f value among the nodes in the open list (for otherwise it would not have beenselected for expansion by the high level) and therefore 0 < f(T )=f(n) < 1. If f(T )=f(n) isclose to 1, then f(n) is close to f(T ). In this case, it is highly probable that node n will bevisited by A* in the next few steps. Thus we want to assign a higher priority to such a nodeto be visited by the agent, by decreasing its heuristic value. If, however, f(n) >> f(T )(i.e., f(T )=f(n)! 0), then it is highly unlikely that node n will be selected anytime soonby the high level A*. It is of no interest to raise the node's priority, in such a case, and itsA*DFS heuristic should be retained, just like other nodes that are not in the open list.The expression provided in (1) meets all of the above requirements. If f(n) f(T ), thenthe term 1 f(T )=f(n) becomes small, and the overall h value for such a node decreases.This provides the agent with an option to visit nodes that are in the open list and whichhave small f values, even though their A*DFS heuristic is not the best. If, on the otherhand, f(n) >> f(T ), then the term 1 f(T )=f(n) will approach 1, having a negligible e ecton h(n). The main reason for multiplying the A*DFS heuristic by 1 f(T )=f(n) (and notby f(n)=f(T ), for example) is to leave intact the cost value of a node with a relatively largef value, so that it can continue to compete (in a local heuristic sense) with nodes whichare not in the open list. The free parameters, c1 and c2, do not a ect qualitatively theperformance of I-A*DFS, but merely add to the module's overall exibility.We have experimented with various constants for c1 and c2, in an attempt to determineoptimal performance. Our extensive empirical studies have shown that c1 = 0:25 andc2 = 2:5 produced the best performance. Our experiments have also demonstrated thatusing I-A*DFS yielded better results than those obtained by the other navigation algorithmslisted in Subsection 4.1.2.Figure 2 illustrates the di erence between A*DFS and I-A*DFS. The numeric values ofthe nodes indicate the order by which they are expanded by A*. Suppose that the agentis currently located at node C and that node 1 is the target. A*DFS will navigate to thetarget via node 5, since this node has the best f(= g + h) value for the scenario described.Once at node 1, the agent will have to travel back to the other side of the graph, as node 2is selected (by the high level) to be expanded next. The agent will then go back to node 3and eventually reach the goal via node 4. I-A*DFS, on the other hand, will navigate fromC to node 1 via node 2; although node 2 is not assumed to be on the shortest path tonode 1, it has a smaller f value than node 5. Thus I-A*DFS chooses to visit node 2 rst.Incorporating this principle saves a considerable amount of travel cost. When the agentwill be located at node 1 and the next node to be expanded will be node 2, the high level6. Since A*DFS(.) and f (:) measure distances on the graph, they represent, essentially, the same scale.Thus they can be combined directly. 644\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment 2 5 C R\nA*DFS I-A*DFS\n1\n3\n4\nGFigure 2: An example of A*DFS versus I-A*DFS navigation.will expand it immediately, as it has been explored before by the agent, and will thus bereadily available. Thus the agent will travel directly from node 1 to node 3 and will avoidnavigating back and forth between opposite sides of the graph.4.2.3 Improved High-Level: WinA*A* expands the nodes from the open list in a best- rst order according to their f value.This order is optimal when the complexity of expanding a node is O(1). However, in a realphysical environment, where node expansion requires an agent to perform costly tasks, it isnot always e cient to expand the current best node. Consider, for example, a nearby nodethat is not the best node in the open list, but whose f value is su ciently small, such thatwith high probability it would be selected for expansion by A* in the next few iterations.An intelligent agent will choose to explore such a node rst, even though it is not currentlythe best node in the open list. G 97 5 8 6 4 R Figure 3: An example illustrating the disadvantage of A*.The above principle is illustrated, for example, by the subgraph of Figure 3 whichcontains two node clusters. The numeric label of each node is associated with its f value.An agent visiting the nodes in a best- rst order (i.e., the order by which A* expands them),will have to travel back and forth from one cluster to the other. A much better approach645\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuwould be to explore all the nodes in one cluster and then move to the other cluster, therebytraveling only once from one cluster to the other.In order to incorporate this capability into our algorithm, we generalized A* to what wecall Window A* (WinA*). While A* chooses to expand the node with the lowest f value,WinA* creates a set (i.e., a window) of k nodes with the smallest f values and then choosesone node from the set for expansion7. Our window uses the same principle of A \" (Pearl& Kim, 1982) which was mentioned before. After constructing the window we select fromit a node for expansion. Our objective is to minimize the traveling e ort of the agent,and not to reduce, necessarily, the number of expanded nodes. Thus rather than selectingonly those nodes that have a small f value, we choose also nodes that are su ciently closeto the location of the agent. Having experimented with a large number of combinations,we concluded that the best way of capturing these two aspects was by simply taking theirproduct. Thus we order the nodes of the window by the cost functionc(n) = f(n) dist(curr; n);where n is the node evaluated, f(n) is its f value, and dist(curr; n) is the distance between nand the current location of the agent. We choose to expand the node with the smallest cost c.(It is sensible to combine f(n) and dist(curr; n) in the above manner, as both are expressedin the same distance units.) Note that if a node with a small f value is not chosen forexpansion, then its f value relative to other nodes in the open list will tend to decrease overtime. This is because the f value of newly generated nodes is monotonically increasing,as the heuristic used is consistent and admissible. This property reduces the chance forstarvation. (At least we have not encountered this phenomenon in our experiments.)Our intention was to demonstrate that combining these two factors, in a manner thatfavors nearby nodes having a small f value, indeed yields enhanced performance. We havetried many functions that combine the two factors (e.g. weighted sum) but choose in thispaper to only discuss the product, c(n) = f(n) dist(curr; n), since it provided the bestresults.Combining this modi ed high-level variant with the low-level navigation creates sometechnical di culties, due to the fact that we no longer expand nodes from the open listin a best- rst order. Recall that standard A* expands a node by generating its neighborsand putting the node in the closed list. When a node v is in the closed list, the shortestpath from the source node to v is known. Hence, when the goal is expanded we have foundthe shortest path to it, and the search can terminate. However, in WinA* a node maybe expanded although there exists another node with a smaller f value that has not beenexpanded yet. In other words, when a node v is expanded, it does not necessarily implythat the best path to v has been found. Expanding a node with a smaller f value mightdiscover a better path. Thus the search cannot simply terminate once the goal node ischosen for expansion.This problem is solved by splitting the standard node expansion stage into two phases:7. In a related algorithm that we have derived, k-best rst search (KBFS) (Felner, Kraus, & Korf, 2003),a window of size k is determined from the open list, and all of the window nodes are expanded at thesame stage. The neighbors of all the nodes are generated and added to the open list, and only then doesa new iteration begins. 646\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment1. Node expansion. Expanding a node means visiting the node, generating all itsneighbors, and adding them to the open list. This stage takes place immediately foreach node chosen by the high level.2. Node closing. Closing a node means removing it from the open list and putting iton the closed list. This takes place only after all the nodes with a smaller f valuehave been explored. This ensures, essentially, that a node will be placed in the closedlist only when the best path to it from the source node has been found (See Section 5for further comments). Thus the search will continue, even if the goal node has beenexpanded, until it is placed in the closed list. Only when the goal node is placed inthe closed list, does the search terminate.Following is the pseudo-code for WinA*. Note that the standard expansion is dividedaccording to the above two phases. At the end of each cycle, the algorithm attempts toclose as many nodes as possible.WinA*() f. while (goal is not in closed-list) f. target = node from window that minimizes f(node) dist(current;node);. if target is unexplored then. explore(target) by low level;. expand(target);. while (best node (with minimal f value) in open-list was expanded). close(best node);. gg4.3 Experimental Results Figure 4: A 20-node Delaunay graph.We have experimented with Delaunay graphs (Okabe, Boots, & Sugihara, 1992), which arederived from Delaunay triangulations. The latter are computed over a set of planar pointpatterns, generated by a Poisson point process (Okabe et al., 1992). Points are distributed647\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuat random over a unit square, using a uniform probability density function. A Delaunaytriangulation of a planar point pattern is constructed by creating a line segment betweeneach pair of points (u; v), such that there exists a circle passing through u and v that enclosesno other point. Such a triangulation can be characterized, in a sense, as one where eachpoint is joined by a line segment to each of its nearest neighbors but not to other points.(We will refer to this type of Delaunay graphs as regular Delaunay graphs.) We have usedthe Qhull software package (Barber, Dobkin, & Huhdanpaa, 1993) to construct Delaunaytriangulations (i.e., Delaunay graphs) over sets of points that were generated at random ina unit square. Figure 4 illustrates a 20-node Delaunay graph.In principle, the characteristic whereby each node is connected to all its neighbors seemssuitable for representing real road maps, which are the main object of our research. Inpractice, however, additional characteristics should be accommodated to capture more ad-equately a real road map. Thus we have also pursued sparse and dense Delaunay graphsthat can be obtained from regular Delaunay graphs by random deletion and addition ofedges, respectively. (See Appendix A for a more detailed discussion.)4.3.1 Low Level Experimental Results 0 10 20 30 40 50 60 70 80 90\n500 1000 1500 2000 2500 3000 3500 4000\nS ea\nrc h\nco st\nNumber of nodes in the graph\nTree path Shrtest known path\nAerial path P-DFS D-DFS A*DFS\nI-A*DFS\nFigure 5: Search cost versus the number of nodes of regular Delaunay graphs for variouslow-level algorithms.Figure 5 displays the traveling distance (or search cost) of the agent as a function ofthe number of nodes in the Delaunay graph (i.e., 500, 1000, 2000, and 4000 nodes). Thegraphs depicted correspond to the various low-level algorithms that PHA* was tested on.Every data point (here and in all the other experiments) corresponds to an average of 250di erent pairs of initial and goal nodes, that were picked at random. The average optimalpath observed was about 0.55.8 The gure clearly demonstrates the higher e ciency of themore involved algorithms. In particular, I-A*DFS is consistently superior to all the otheralgorithms for all graph sizes. For a graph of size 4000, for example, it outperformed the8. Note the closeness between the average optimal path observed (i.e., 0.55) and the expected arc length ofa random graph de ned over the same set of points (i.e., 0.521) (Ghosh, 1951).648\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentmost simple algorithm by a factor of more than 10, and outperformed the basic A*DFS bya factor of more than 2. Note that the search cost increases as the number of nodes grows,i.e., as the domain becomes denser or more connected. This is attributed to the fact that asthe number of nodes grows, so does the number of nodes in the closed list that the I-A*DFSprocedure has to visit.The relative performance of the various algorithms we have considered remained thesame for sparse and dense Delaunay graphs (see Appendix A).4.3.2 Experimental Results for WinA* 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6\n0 10 20 30 40 50 60 70 80\nS ea\nrc h\nco st\nWindow size\n500 nodes 1000 nodes 2000 nodes\nFigure 6: Search cost of WinA* versus window size for various sizes of regular Delaunaygraphs.Our experiments show that using WinA* as the high-level procedure of PHA* leads toa signi cant improvement of the e ciency of our algorithm. Figure 6 presents the averagedistance traveled by the search agent until the optimal path was found, as a function ofthe window size. I-A*DFS was employed for the low-level algorithm. The results shown inFigure 6 indicate that using a window of size larger than 1 (which corresponds to standardA*) signi cantly improves the algorithm's performance for the various graph sizes that wehave experimented with. Also, we have found that the optimal size of the window tends tovary with the size of the graph. Based on our empirical observations, setting the optimalwindow size to (1=50) times the number of nodes in the graph seemed to provide a verygood approximation. (For example, the best window sizes observed for 500- and 2000-nodegraphs were 10 and 40, respectively.) Note that as the window size becomes larger (i.e.,the number of candidate nodes increases), the algorithm tends to select nodes with a largef value, which results in performance degradation. Additional results for sparse and denseDelaunay graphs are presented in Appendix A.At a rst glance, the improvement of WinA* over standard A* (for the high level) seemssomewhat modest, as it does not exceed 30%. This is due to the fact that I-A*DFS exploresmany nearby nodes, and is already very powerful to begin with. Both WinA* and I-A*DFSare designed to assign high priority to nearby nodes. They do so at di erent stages ofthe PHA* algorithm, but in a sense they \\compete\" for the same type of improvement.649\nFelner, Stern, Ben-Yair, Kraus, & NetanyahuIndeed, using any of the other navigating algorithms, the improvement of WinA* relativeto standard A* was much more signi cant. However, in dealing with real physical agents |let alone humans | even the 30%-time reduction by WinA* (relative to I-A*DFS) shouldbe viewed as signi cant. Similar results were obtained for sparse and dense Delaunay graphs(see Appendix A).5. Analysis of PHA*Analyzing the performance of PHA*, we distinguish between the following three parameters:(1) Cost of returned path, (2) shortest possible path that the agent can travel, and (3) costof actual path traveled by the agent. In Subsection 5.1 we argue that the path reported byPHA* (for future use) is optimal. In addition, we present in Subsection 5.2 an extensiveempirical study that compares between (2) and (3). Finally, we provide in Subsection 5.3a brief discussion of PHA*'s underlying methodology and overall performance.5.1 Optimality of SolutionRecall that A* expands nodes in a best- rst order according to their f value. If the heuristicfunction, h(n), is admissible, then f(n) = g(n)+h(n) is a lower bound on a path to the goalvia node n. It is well-known, under this paradigm, that once the goal node is selected forexpansion, A* has found an optimal path (Hart et al., 1968; Karp & Pearl, 1983; Dechter& Pearl, 1985). Put di erently, if upon goal expansion f(goal) = c, then all other nodeswith estimated paths of f(n) < c have already been expanded and the length of the optimalpath to the goal is c (Karp & Pearl, 1983; Dechter & Pearl, 1985).PHA* is supervised by the high level, which activates an admissible A*. (Recall thath(n) is the Euclidean distance from n to the goal, i.e., it is admissible.) By design of thealgorithm, the high level terminates once the goal node is selected for expansion. Thus bythe properties of admissible A*, all the nodes having a smaller f value must have alreadybeen expanded, and the f value of the goal is optimal. Note that this also holds for enhancedPHA* with WinA* (see Subsection 4.2.3). Although WinA* does not necessarily expandnodes according to the best f value, it is designed to remove a node from the open list onlyif it has the smallest f value among the nodes on the list. The algorithm halts only afterthe goal node has been expanded and removed from the open list, implying that its f valueis the smallest on the list. Thus our enhanced PHA* variant is also compatible with theadmissible A* paradigm, and the path it returns is optimal. The basic theoretical result ofthe paper follows.Theorem: PHA* and its enhanced versions return the optimal path between the startnode and the goal.5.2 Performance Evaluation of PHA*As demonstrated above, the more complex algorithmic schemes provided a dramatic im-provement in search time. It is of interest to assess, at least to some extent, the performanceof our best navigation variant, i.e., WinA* (for the high level) in conjunction with I-A*DFS(for the low level). 650\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentgraph closed jTSP0 j PHA* ratiosize nodes30 11.32 0.62 0.80 1.2950 15.45 0.74 0.94 1.2775 17.93 0.77 0.97 1.22100 20.32 0.85 1.10 1.29150 24.12 0.91 1.27 1.39200 28.43 0.99 1.42 1.43250 31.57 1.02 1.48 1.45300 35.78 1.05 1.51 1.44Table 1: Comparison between shortest paths through nodes in closed list and actual pathsobtained by PHA*.The agent's task is to visit essentially all the nodes that are expanded by A*. Thesenodes comprise the set of nodes that are in the closed list when the algorithm terminates.In general, invoking A* on the subgraph induced by these nodes, with the same source andgoal states and the same heuristic function, will exhibit the same behavior and yield thesame open and closed lists. Thus given a static graph, the set of nodes which A* should visitis xed. Ideally, we would like the agent to visit this set of closed nodes along the shortestpossible path. This is of course infeasible, since the nodes are not known in advance, butrather determined on the y. However, in order to evaluate our algorithm's performance,we can compare its output with the shortest possible path that travels through all thesenodes. The computation of the latter is carried out o -line, i.e., after the set of (closed)nodes is known.Speci cally, we have computed the shortest possible path in each case with respect to thecomplete graph of the corresponding set of closed nodes. The weight w(ni; nj) associatedwith an edge (ni; nj) (in the complete graph) was set to the length of the shortest pathfrom ni to nj (in the original Delaunay graph instance). Finding the shortest path thattravels via a given set of nodes is known as the traveling salesman problem (TSP), whichis notorious for its exponential running time. A conventional TSP path travels through allthe nodes and then returns to the start node. However, we are interested in a path thattravels through all the nodes without returning to the start node. We denote this path byTSP0 to distinguish it from the conventional TSP tour. A TSP0 tour is actually a TSP tourwithout the last edge. In view of the exponential nature of the problem, we have used asimple branch-and-bound tree search to compute the desired paths. However, solving thisproblem optimally was feasible only for relatively small graph sizes.Table 1 provides a comparison between PHA* and the shortest path that travels throughall the closed nodes for various small sized graphs. The table indicates that our PHA*algorithm is quite e cient for small graphs. Speci cally, the average travel cost (due toPHA*) was not greater than the shortest possible path (passing through all the closed651\nFelner, Stern, Ben-Yair, Kraus, & Netanyahunodes) by more than 45%. For graphs having 200 nodes or less, the number of closednodes observed was smaller than 30. The average cost in these cases was computed over 50random instances. For graphs sizes greater than 200, the average cost was computed over5 instances only.In order to evaluate, however, the performance of PHA* for graphs of larger size (wherethe optimal path could not be computed in a reasonable amount of time), we employed alower-bound approximation to the cost of TSP0 . Speci cally, we have computed a minimumspanning tree (MST) of the complete graph (de ned by the set of closed nodes). Let jTSP0 jand jMSTj denote, respectively, the costs associated with the desired path and the minimumspanning tree.Claim: 0:5 jTSP0 j < jMSTj jTSP0 j:Proof: The claim follows from basic graph theory (Cormen, Leiserson, Rivest, & Stein,2001). Speci cally, the inequality on the right hand side stems from the fact that TSP0 isa spanning tree of the complete graph. Thus the cost of a minimum spanning tree must besmaller than (or equal to) jTSP0 j.To prove the inequality on the left hand side, we note that the triangular inequalityholds with respect to the above de ned complete graph. (That is, for any three nodes, ni,nj , and nk, w(nj; nk) w(ni; nj) +w(nj; nk).) This can be easily shown, based on the factthat the triangular inequality holds with respect to the original Delaunay graphs and byde nition of an edge weight in the complete graph. Thus we can construct a tour that goestwice around the MST and then use the triangular inequality to shortcut some of its edges.Hence 2 jMSTj jTSPj > jTSP0 j;and the inequality on the left hand side follows. 2Given the infeasible computation of jTSP0 j, the claim suggests jMSTj, instead, as areasonably good approximation. Speci cally, the inequality on the right hand side impliesthat if the travel cost of the agent performing PHA* is, say, c jMSTj, then the travel costof PHA* is no greater than c jTSP0 j. Given that this is merely a lower bound, PHA* isexpected to perform better in practice.Table 2 provides a comparison between PHA* and the MST lower bound on the shortestpath as described above. The average cost entered for each graph size was computed over250 randomly generated instances. The table indicates that, on the average, the cost ofPHA* is at most 2.74 times that of the best possible path for graph sizes up to 8000 nodesand corresponding sets of closed nodes of up to 460 nodes.5.3 DiscussionAs was repeatedly noted, any algorithm that returns the optimal solution must expand atleast all the nodes that are expanded by A*. Drawing on this basic premise, our PHA*algorithm was designed to visit the set of \\mandatory\" nodes as e ciently as possible. Therationale of visiting also nearby nodes (whose f value is not necessarily the smallest) is thatsuch nodes are likely to be expanded in the next few iterations. In contrast, there is no652\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentgraph closed jMSTj PHA* ratiosize nodes approx.400 40.27 1.05 1.91 1.82500 43.00 1.15 1.97 1.871000 62.72 1.42 3.03 2.132000 131.56 2.01 4.89 2.434000 233.26 2.52 6.76 2.698000 460.66 3.45 9.44 2.74Table 2: Comparison between lower bounds on shortest paths through nodes in closed listand actual paths obtained by PHA*.bene t to this enhanced variation in the context of a navigation algorithm that does notpresume to return an optimal solution.Reconsider Roadmap-A*, for example. A \" is only activated to prevent the local naviga-tion phase from going in the wrong direction. However, since this algorithm is not designedto return an optimal solution, it will not deviate at any stage from its promising route tovisit a nearby node that may be expanded later on. Put di erently, there is no notion hereof a set of mandatory nodes that the agent has to visit. Furthermore, as soon as the agentreaches the goal, the search halts. In conclusion, although both PHA* and Roadmap-A*are two-level navigation schemes, their objectives are di erent and they solve essentiallydi erent problems.Based on the properties of admissible A* and by design of our algorithm, we haveargued that (enhanced) PHA* returns a path (for future use) that is optimal. In addition,in the absence of a theoretically known bound on the actual cost of PHA*, we have runan extensive empirical study, comparing between observed costs and the best possible costscomputed o -line. Given that the agent lacks a priori information as to the set of mandatorynodes, it is highly unlikely that there exists an on-line PHA*-like algorithm that performs ase ciently as an o -line version. Our extensive empirical study demonstrates, nevertheless,that the actual cost associated with PHA* is on the same order of magnitude as the optimalcost computed o -line.6. MAPHA*: Multi-Agent PHA*In this section we generalize the techniques discussed in the previous sections to the multi-agent case, where a number of agents cooperate in order to nd the shortest path. We callthe resulting algorithm Multi-Agent Physical A* (MAPHA*).We would like to divide the traveling e ort between the agents in the most e cient waypossible. We can measure this e ciency for the multi-agent case using two di erent criteria.The rst is the overall global time needed to solve the problem. The second is the totalamount of fuel that is consumed by all agents during the search. If the requirement is tominimize the cost of moving the agents and time is not important, then considering the fuel653\nFelner, Stern, Ben-Yair, Kraus, & Netanyahucost of mobilizing the agents will be the cost function of choice. In this case, it may be wiseto move some agents while other agents remain idle. However, if the task is to nd the bestpath to the goal, as soon as possible, idle agents seem wasteful, as they can better utilizetheir time by further exploration of the graph. In such a case, all available agents should bemoving at all times. We introduce below two algorithms for these two perspectives, namelya fuel-e cient algorithm and a time-e cient algorithm. Note that in the single agent casethese two criteria coincide.We assume that each agent can communicate freely with all the other agents and sharedata at any time. Thus any information gathered by one agent is available and known toall of the other agents. This framework can be obtained by using a model of a centralizedsupervisor that moves the agents according to the complete knowledge that was gatheredby all of them. This is a reasonable assumption since in many cases there is a dispatcheror some centralized controller that gathers information from the agents and instructs themaccordingly. Another possible model for complete knowledge-sharing is that each agentbroadcasts any new data about the graph to all the other agents. Future research mayaddress a more restrictive communication model, by limiting the communication range orinducing communication errors.We also assume that the search terminates, as soon as the goal node is expanded andmoved to the closed list. Our objective is to minimize the travel e ort up to that point,and we do not care about moving all the agents to some pre-speci ed location (e.g., thegoal vertex or the start node), after the desired shortest path is identi ed. This conventionis in accordance with many algorithms which neglect to report the time spent to \\reset\" asystem (e.g., garbage collection), once the desired solution is arrived at.The main idea of the MAPHA* algorithm is very similar to that of PHA* for a singleagent. We use again a two-level framework. The high level chooses which nodes to expand,while the low level navigates the agents to these nodes. We have studied the multi-agentcase with our enhanced techniques only, i.e., WinA* for the high level and I-A*DFS for thelow level. The problem that we deal with below is how to assign the di erent agents toexplore e ciently the di erent nodes.6.1 MAPHA*: Fuel-E cient AlgorithmFor simplicity, we assume that the amount of fuel consumed by an agent is equal to itstraveling distance during the search. Since the purpose of the algorithm in this case is tominimize the amount of fuel consumed by the agents, regardless of the overall search time,there is no bene t to moving more than one agent at a time. This is because by movingonly one agent, that agent might gain new knowledge of the graph that would allow theother agents to make more informed and intelligent moves.At the beginning, all the agents are situated at the source node. Then, as in the case ofa single agent, the high level de nes a window of unexplored nodes from the open list thatare potential candidates for expansion. For each pair (a; n), where a is an agent and n is anode from the window, we compute the allocation cost functionc(a; n) = f(n) dist(a; n);where f(n) is the f value of node n and dist(a; n) denotes the distance from the location ofagent a to node n. We then select an agent and a target node that minimize that allocation654\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentfunction. In the case of tie-breaking (e.g., at the beginning of the search where all agents arelocated at the initial state), we pick randomly one agent from the relevant candidates. Atthis stage, the low-level algorithm navigates the selected agent to the target node selectedfrom the window in order to explore that node. As in the single-agent case, additionalknowledge about the graph is being obtained during the navigation as many unexplorednodes are visited by the traveling agent. Only when the selected agent reaches its target isa new cycle activated for the high- and low-level procedures.9 Following is the pseudo-codefor the fuel e cient algorithm.fuel-efficient algorithm() f. while (goal is not in closed-list) f. for each agent ai. select node ni from the window that minimizes f(n) dist(ai; n);. abest = agent that minimizes f(ni) dist(ai; ni);. if nbest is unexplored then. explore(nbest) by low level using abest;. expand(nbest);. while (best node in open-list was expanded). close(best node);. gg6.2 MAPHA*: Time-E cient AlgorithmThe time-e cient algorithm is very similar to the above described fuel-e cient algorithmwith one basic modi cation. Instead of moving only one agent during each high-level cycle,we now move all of the available agents since we only care about the time spent by theagents and not about their fuel consumption. Having an idle agent will not save any time.Every moving agent can only help gather more knowledge about the environment with noadditional cost, as the clock ticks away regardless and the time is measured globally.We cannot use here the same allocation function that was used for the fuel-e cientalgorithm, as all agents are located initially at the same node, and the fuel-e cient allocationfunction will choose the same node for all the agents. The main idea of the time-e cientstrategy is that all agents move simultaneously. Thus to ensure e cient performance weneed to distribute them as much as possible. Suppose that we have p available agents and knodes in the window. We would like to distribute these p agents to the k nodes as e cientlyas possible. A brute-force approach will be to randomly distribute the agents to the nodes.However, to provide an e ective distribution, we incorporate the following three criteriainto our distribution formula for the time-e cient procedure:1. Since the f values of neighboring nodes are somewhat correlated with each other,nodes with a small f value are more likely to generate new nodes with a small f9. We have also implemented a more complex variant, such that whenever a new unexplored node is reached,a new high-level cycle is activated. Results obtained were not signi cantly di erent, and we omit thedetails of this variant for simplicity. See (Stern, 2001) for a comprehensive description.655\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuvalues than nodes with a large f value. Therefore, the distribution should favorassigning an agent to a node with a small f value.2. Another attribute that should be taken into consideration is the distance of the targetnode from an agent. We would like to assign an agent to one of the nodes in sucha manner, that the expected travel distance of the agent (for that assignment) isminimized. In other words, an agent will be assigned, preferably, to a relatively close-by node.3. In order to expand the entire window and prevent \\starvation\", we would also like ourdistribution function to raise the priority of nodes that were assigned a small numberof agents. Thus we should keep track of the number of agents that were assigned toeach node and give preference to nodes with a small number of assignments.Note that the rst and third criteria may contradict, i.e, the rst criterion will prefernodes with a small f value while the third criterion will favor nodes with a large f value,as only a small number of agents was assigned to them.We have found that taking the product of the values associated with these three criteriagives a good distribution function with a suitable load balancing between these criteria.Speci cally, the agent allocation procedure iterates through all the agents and picks, foreach agent, the node that minimizes the following allocation function:alloc(agent;node) = f(node) dist(agent;node) (count(node) + 1);where dist(node; agent) is the Euclidean distance between the node and the agent, f(node)is that node's f value, and count(node) is a counter that keeps track of the number of agentsthat have already been assigned to explore that node. count(node) is initially set to 0 andis incremented every time an agent is assigned to that node. Thus a load balancing betweenthe three factors is being kept throughout the distribution process. At the beginning ofthe search all the agents are located at the start node, and their initial allocation to thedi erent nodes is determined, essentially, by the count factor. (Without this factor, theproduct f(n) dist(agent; n) would have returned the same node n for all agents.) As thesearch progresses, the agents move to di erent locations and get assigned at each step tonodes that are closer to their location and that have a small f value. Thus the product ofthe above three factors creates a good distribution (of the agents) over di erent parts ofthe graph.Consider, for example, the case illustrated in Figure 7. Suppose that 100 agents are alllocated at node x, and that the window consists of the three nodes a, b, and c that are locatedat an equal distance from x. Suppose also that f(a) = 2, f(b) = 4 and, f(c) = 8. Thenumbers of agents that are assigned to these nodes, using the above allocation procedure,are 57, 29, and 17, respectively. This is a good balance between the various requirements.We have tried many other variations for the distribution procedure and found that theyall performed well as long as the above three requirements were met. See (Stern, 2001) forfurther discussion on agent distribution.As before, each agent navigates to its assigned target using our enhanced low-level al-gorithm, I-A*DFS. Another high-level iteration begins as soon the the rst agent reaches656\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment c\nb a\nx\nf(c)=8 f(b)=4 f(a)=2Figure 7: An example of agent distribution according to the proposed allocation procedure.its target node.10 Note that the computation time of the window and that of the agentdistribution/allocation can be neglected, since we only care about the travel time of theagents. Following is the pseudo code for the time-e cient algorithm.time-efficient algorithm() f. while (goal is not in closed-list) f. for each free agent ai. select a window node ni that minimizes dist(ai; n) f(n) (count(n+1));. move all agents until an agent reaches a node;. expand all nodes currently visited by an agent;. while (best node in open-list was expanded). close(best node);. gg6.3 Experimental ResultsThe experiments performed for the multi-agent case were also conducted on Delaunaygraphs with 500, 1000, 2000, 4000, and 8000 nodes. Additional results for sparse anddense Delaunay graphs are provided in Appendix A.6.3.1 MAPHA*: Results for the Fuel-Efficient AlgorithmWe provide here results for the fuel-e cient algorithm of Subsection 6.1. The fuel con-sumption reported is the total fuel consumed by all the agents. (As before, the graphs weregenerated on a unit square, for which the average optimal path observed was about 0.55.)Figure 8 presents the costs of the fuel-e cient algorithm as a function of the numberagents for various sizes of regular Delaunay graphs. (Results for sparse graphs, as wellas graphs with edges added at random, are presented in Appendix A.) The gure clearly10. We have observed that when a new iteration begins, almost every agent is assigned to the same nodethat it was assigned to in the previous iteration. Typically this is because an agent's location becomescloser to \\its\" target node, while the other criteria do not change. Thus in practice, most of the agentsgo on to complete their (original) tasks, and only the agent that has reached its target is assigned a newgoal node. See (Stern, 2001) for a detailed discussion.657\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5\n1 2 3 4 5 6 7 8 9\nF ue\nl c on\nsu m\npt io\nn\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes\nFigure 8: Fuel consumption as a function of number of agents for various sizes of regularDelaunay graphs.demonstrates that as more agents are added, the overall fuel consumption decreases upto a point where adding more agents tends to increase the overall consumption. Thus anoptimal number of agents exists for each of the graphs. This phenomenon is due to the factthat A* is usually characterized by a small number of search regions. Therefore, a smallnumber of agents su ces to cover these regions. As the number of agents increases, the fuelconsumption goes up. This phenomenon is explained as follows. A large number of agentsincreases the likelihood that a nearby agent will be assigned to a speci c node, in whichcase relatively little exploration of the graph takes place. Assigning, on the other hand,a distant agent to the node would result in a larger degree of graph exploration, which isessential, in the long run, for e cient navigation (especially if I-A*DFS is employed). Thusa large number of agents navigating in a small graph (which has few search regions), wouldresult in excessive fuel consumption. See (Stern, 2001) for a more detailed explanation ofthis phenomenon.The optimal number of agents increases as the number of nodes in the graph increases.While the optimal number of agents for a graph of 500 nodes is 2, this number increases upto 7 for a graph of size 4000. This stems from the fact that larger graphs have more searchregions and thus more agents are needed to explore them.As described before, only one agent is allowed to move in this experiment, at any pointin time. Up to now we have measured the total amount of fuel consumed by all of theagents. It is of interest to nd out whether the work is uniformly distributed among theagents, or whether a large portion of the work is carried out by a small number of agents.Table 3 presents the distribution of the work among the agents when up to 14 agents wereactive on Delaunay graphs of size 8000. For each graph instance, we sorted the agents indecreasing order of their fuel consumption. The table shows the relative fuel consumptionof the agents for 3, 7, and 14 activated agents.In general, we remark that while the overall work is not uniformly distributed, it is quitebalanced. For example, when 14 agents are activated, 40% of the work is done by only 4658\nPHA*: Finding the Shortest Path with A* in An Unknown Physical EnvironmentAgent No. 3 agents [%] 7 agents [%] 14 agents [%]1 42.03 28.34 16.012 33.54 19.32 13.213 24.43 16.23 11.414 12.76 10.315 9.02 6.646 7.86 5.487 6.48 5.088 4.549 4.1010 3.5911 3.2012 3.0213 2.8114 2.70Table 3: Work distribution among multiple agents running our fuel-e cient algorithm onDelaunay graphs of size 8000.agents. A similar tendency was observed for graphs of other sizes, as well as for sparse anddense Delaunay graphs (see Appendix A).In order to improve the e ciency of the fuel-e cient algorithm and to make the overallwork distribution more balanced, several improvements might be suggested. For example,currently all the agents are positioned initially at the same source node. We might considerto rst spread the agents in a number of directions and only then invoke the algorithm.Notwithstanding the additional overhead that may be incurred by spreading the agents,this technique can result in a more balanced work distribution and in a reduced overall fuelconsumption.6.3.2 MAPHA*: Results for the Time-Efficient AlgorithmIn this subsection we report the results for the time-e cient algorithm of Subsection 6.2.As was explained, if our main objective is to conclude the task as fast as possible, suchthat fuel consumption is of no concern, then all agents should always be moving, i.e., noneof them should be idle at any point in time. The overall search time in this case is themaximal distance that either agent travels until the shortest path to the goal node is found.Figure 9 shows the search time obtained by the time-e cient algorithm as a function ofthe number of agents, for various regular Delaunay graphs. Note that the search time cannever be smaller than the time it takes to travel along the shortest path to the goal. As theresults indicate, adding more agents is always e cient since we only measure the overalltime that has elapsed until the goal is found. What makes our algorithm interesting ande cient is the fact that as we add more agents, the search time converges asymptotically to659\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu 0 1 2 3 4 5 6 7 8 9 10\n0 2 4 6 8 10 12 14\nS ea\nrc h\nti m\ne\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes 8000 nodes\nFigure 9: Time consumption as a function of the number of agents, for various regularDelaunay graphs.the length of the shortest path. Recall that the average length observed of the shortest pathwas approximately 0.55. Indeed, a large number of agents will tend to nd the optimal pathwithin a time frame that approaches the above limit. While the overall time was 2.3 witha single agent, it was reduced to 0.7 with 14 agents for graphs with 500 nodes for example.Using our proposed agent allocation procedure, we note that asymptotically all pathsfrom the initial state are traveled in a breadth- rst search manner. This is to say that asu ciently large team of agents is likely to produce a single agent that will travel along theactual shortest path with very little deviation from it. Similar results for the time- e cientalgorithm were also obtained for other types of graphs (see Appendix A).6.4 Combined Requirements of Fuel and TimeWhile the distinction between the time-e cient algorithm and fuel-e cient algorithm isreasonable, it may not be suitable in many practical situations. Practical considerations oftime and fuel resources may suggest a combined approach, as the one described below.Consider, for example, a commander operating under a constraint of fuel consumptionbut with no restriction on the number of troops that can be assigned to a certain task. Inorder to complete the task as fast as possible, the commander may want to use the maximalpossible number of agents without exceeding the fuel consumption limit.In essence, we seek to generalize MAPHA*, such that the agents will minimize a costfunction which is a combination of time and fuel consumption. We suggest a general costfunction that takes into account the requirements on both these measures. The objectivewill be to activate MAPHA*, so as to minimize this cost function. Speci cally, we suggestthe following linear combination:Ctotal = wt time + wf fuel;where wt and wf are the (normalized) weights attached, respectively, to the time and fuelconsumption (i.e., 0:0 wt; wf 1:0 and wt + wf = 1:0). Ctotal is calculated globally, i.e.,660\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentwe measure the amount of time from the beginning of the task until the optimal path isfound, and the total amount of fuel consumed by all the agents. We then multiply thesequantities by their corresponding weights and report the combined cost.Both wt and wf are prespeci ed by the user. If wt = 0, there is no time cost and thefuel-e cient algorithm will be the appropriate one to use. If wf = 0, there is no fuel cost,and we can use the time-e cient algorithm. Otherwise, if neither wt nor wf is 0, we shoulduse a di erent algorithm to minimize Ctotal.We suggest two algorithms for this general case. Simple combined algorithm.This algorithm is actually identical to the time-e cient algorithm. The number ofparticipating agents is a parameter provided by the user. At each iteration of thehigh level all the participating agents move according to the allocation function ofthe time-e cient algorithm. Given the formulation of the total cost, Ctotal, we wouldlike to determine the optimal number of agents, for any wt and wf . Note that in thetrivial case where wf = 0, adding more agents is always valuable, since they do notconsume any resources, and can only reduce the time cost. However, as wf increases,a large number of agents may increase the total cost. Improved combined algorithm.The main limitation of the simple combined algorithm is that even though cost isincurred for fuel consumption, all the agents are always moving. The improved com-bined algorithm addresses this problem and suggests moving only some of the agentssimultaneously. Using this formalization, we rst determine p, i.e., the number ofagents that will participate in the task. Given p, we then determine m, i.e., the num-ber of agents that will actually be distributed to nodes selected from the window (bythe high level). The remaining p m agents will stay idle. Note that for the simplecombined algorithm p anm coincide. We use the same mechanism of the time-e cientallocation function, except that here the algorithm chooses only m (out of p) agentsthat minimize this allocation function. As in the time-e cient algorithm, we rstdetermine the size of the window, i.e., the number of nodes from the open list thatshould be expanded. Then, we invoke the same allocation function. Whereas in thetime-e cient case the allocation terminates once all the agents are assigned to nodes,here the allocation stops after m agents are selected. The selected agents are the bestm agents for this expansion cycle since they minimize the allocation function.6.5 Results for the Combined AlgorithmWe provide experimental results for the combined algorithm that was introduced in theprevious subsection. The results in Tables 4 and 5 were obtained for Delaunay graphsof size 2000; each table entry represents the average of 250 problem instances. For eachcolumn, the bold face number is the smallest total cost for the corresponding wt=wf ratio.These minimal costs determine the optimal number of agents for a given wt=wf ratio.Table 4 provides total costs for the simple combined algorithm as a function of thenumber of agents for various wt=wf ratios. The leftmost column corresponds to the case661\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu wt 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0wf 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0# agents1 4.82 4.82 4.82 4.82 4.82 4.82 4.82 4.82 4.82 4.82 4.822 2.58 2.84 3.10 3.36 3.61 3.87 4.13 4.39 4.65 4.91 5.163 1.74 2.09 2.44 2.79 3.14 3.49 3.84 4.18 4.53 4.88 5.234 1.44 1.87 2.30 2.73 3.16 3.60 4.03 4.46 4.89 5.32 5.755 1.24 1.73 2.23 2.72 3.22 3.71 4.21 4.70 5.20 5.69 6.196 1.11 1.67 2.22 2.78 3.33 3.89 4.44 5.00 5.55 6.11 6.667 1.03 1.64 2.26 2.88 3.49 4.11 4.73 5.34 5.96 6.58 7.198 0.97 1.65 2.33 3.01 3.69 4.37 5.05 5.73 6.41 7.09 7.779 0.93 1.68 2.42 3.17 3.91 4.66 5.40 6.15 6.89 7.64 8.3810 0.89 1.70 2.50 3.31 4.11 4.92 5.72 6.53 7.33 8.14 8.9511 0.85 1.70 2.56 3.41 4.26 5.11 5.96 6.81 7.67 8.52 9.3712 0.84 1.77 2.70 3.63 4.56 5.49 6.42 7.35 8.27 9.20 10.1313 0.84 1.84 2.84 3.84 4.84 5.85 6.85 7.85 8.85 9.86 10.8614 0.82 1.88 2.94 4.01 5.07 6.13 7.19 8.26 9.32 10.38 11.44Table 4: Ctotal for the simple combined algorithm as a function of the number of agents,for various ratio wt=wf ratios.\n662\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environmentwhere only time matters. Thus its entries are identical to the values obtained by the time-e cient algorithm. As fuel consumption becomes more signi cant, it is no longer bene cialto increase the number of agents and thus the optimal number of agents decreases. Forwt = wf = 0:5, Ctotal = 0:5 time + 0:5 fuel, the optimal number of agents obtainedis three, for a total cost of 3.49. The more critical fuel consumption becomes, the morebene cial it is to use a smaller number of agents. The rightmost column corresponds to theother extreme case, where wf = 1:0, i.e., when only fuel consumption matters. Note thatthe entries of this column di er from their counterpart costs obtained by the fuel-e cientalgorithm. The di erence stems from the fact that, in the context of the simple combinedalgorithm, picking p agents means that they will all be moving simultaneously, whereas incase the fuel-e cient algorithm is employed only one agent (out of p) will be allowed tomove at all times. Note that the fuel-e cient algorithm is essentially a special case of theimproved combined algorithm with m = 1.Table 5 provides total costs for the improved combined algorithm as a function of thenumber of agents for various wt=wf ratios. The number of participating agents was p = 14(i.e., up to 14 available agents could move simultaneously). Each row corresponds to adi erent m, i.e., to the actual number of moving agents. (Clearly, 1 m p = 14.) Asbefore, for each column the bold face number is the smallest total cost for the correspondingwt=wf ratio. These minimal costs determine the optimal number of moving agents for agiven wt=wf ratio.The top entry of the rightmost column is identical to the cost obtained by the fuel-e cient algorithm, for 14 agents. In this case wf = 1, and only one agent is allowed tomove at any point in time. The bottom entry of the leftmost column is identical to the costobtained by the time-e cient algorithm, for 14 agents. In this case wt = 1, and all of the14 participating agents are moving at all times.The more signi cant fuel consumption becomes, the less bene cial it is to move manyagents. Thus the optimal number of moving agents decreases. For example, for wt = wf =0:5, the optimal number of moving agents obtained was three, for a total cost of 3.23. Asfuel consumption becomes more crucial, it would be bene cial to move a smaller number ofparticipating agents.Comparing the results of the simple combined algorithm with those of the improvedcombined algorithm reveals that for the same wt=wf ratio and for the same number ofmoving agents (which is equal to the number of all participating agents in the simplecombined case) the improved combined algorithm usually performs better. This is becauseit can pick the moving agents from a larger sample. Also, it appears that the optimal numberof moving agents is smaller for the improved combined algorithm. In this algorithm, themoving agents are picked in a clever manner at each cycle and thus can be better utilized.Additional experiments were conducted for other graph sizes, as well as for sparse anddense Delaunay graphs. The results obtained in all cases were rather consistent. Futurework will attempt to predict in advance the best number of agents.7. Conclusions and Future WorkWe have addressed the problem of nding the shortest path to a goal node in unknowngraphs that represent physical environments. We have presented the two-level algorithm,663\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu wt 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0wf 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0# agents1 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.022 2.26 2.49 2.72 2.94 3.17 3.40 3.62 3.85 4.08 4.30 4.533 1.61 1.94 2.26 2.58 2.91 3.23 3.55 3.88 4.20 4.52 4.844 1.31 1.70 2.09 2.49 2.88 3.27 3.67 4.06 4.45 4.84 5.245 1.13 1.58 2.03 2.48 2.93 3.38 3.83 4.28 4.73 5.18 5.636 1.00 1.49 1.99 2.49 2.99 3.49 3.98 4.48 4.98 5.48 5.987 0.92 1.47 2.02 2.57 3.13 3.68 4.23 4.78 5.33 5.88 6.438 0.85 1.45 2.05 2.65 3.25 3.85 4.44 5.04 5.64 6.24 6.849 0.82 1.47 2.12 2.77 3.43 4.08 4.73 5.39 6.04 6.69 7.3410 0.79 1.50 2.21 2.92 3.63 4.34 5.05 5.76 6.47 7.18 7.8911 0.77 1.54 2.31 3.07 3.84 4.61 5.38 6.15 6.92 7.69 8.4612 0.76 1.59 2.42 3.25 4.09 4.92 5.75 6.58 7.41 8.25 9.0813 0.75 1.64 2.54 3.44 4.33 5.23 6.13 7.02 7.92 8.82 9.7114 0.75 1.72 2.69 3.67 4.64 5.61 6.59 7.56 8.53 9.51 10.48Table 5: Total costs for the improved combined algorithm as a function of the number ofmoving agents (out of 14 participating agents), for various wt=wf values.\n664\nPHA*: Finding the Shortest Path with A* in An Unknown Physical EnvironmentPHA*, for such environments for a single search agent, and the MAPHA* algorithm formultiple-agents. We have experimented with several variations of Delaunay graphs, con-taining up to 8000 nodes. The enhanced single agent algorithm yielded signi cantly betterresults than the ones obtained by the simpler variants. The results for the fuel-e cientalgorithm show that using more agents is bene cial only to some extent. This is because allthe agents are initially located at the same source node and they all consume fuel for eachmove they make. For the same reason, the bene t of using the optimal number of agentsas opposed to only one agent is modest. The results for the time-e cient algorithm arevery encouraging, since the search time converges quickly to the optimum as the number ofsearch agents increases. We have also introduced a cost function that combines both timeconsumption and fuel consumption, and have presented two algorithms for this paradigm.The results show that for each combination there exists an optimal number of agents whichtends to increase as the weight of the time cost increases.Future work can be pursued along the following directions: We have assumed that upon reaching a node, the agent can learn the locations ofall of its neighbors. In many domains this model may not be valid, and the locationof a node is known only when the agent actually visits it. Such a model was alsosuggested in (Shmoulian & Rimon, 1998). Further research should be done in orderto implement our algorithms, in the context of such a model. We have used traveling agents to solve the shortest path problem. A similar mech-anism might be used for solving other known graph problems, such as the minimumspanning tree, the traveling salesman problem, or any other problem that requiresconsideration as to which node should be visited next. We have proposed two algorithms for combining time consumption and fuel consump-tion. Both algorithms assume that the number of agents is determined a priori. Futurework can try to theoretically determine the optimal number of agents given the con-straints. Also, future work can be done to see whether changing this number on the ywould increase the e ciency of these algorithm. Also, we have assumed that agentsconsume fuel only when they move, and have measured only the total performancetime of a task. Thus idle agents do not consume any resources. However, we canthink of a model where idle agents do consume resources (e.g., time and energy). We have assumed a centralized model, where all the agents share their knowledge atall times. Future work can assume other communication paradigms. In particular,we are interested in a model where there is no communication at all between theagents. This model is known as the ant-robotics model (Wagner & Bruckstein, 2000;Yanovski, Wagner, & Bruckstein, 2001). In this model, information is spread to otheragents by pheromones, i.e., data that are written by an agent at a node. Other agentscan read these pheromones when reaching those nodes. We are currently workingtowards applying our MAPHA* algorithm to such a model. We believe that if weincrease the size of the data that are allowed to be written at each node, then eachagent will be able to write its complete knowledge at a node of the environment. Thechallenge of applying A* in such a model lies in the fact that since A* maintains aglobal open list, data from opposite sides of the graph can in uence the behavior of665\nFelner, Stern, Ben-Yair, Kraus, & Netanyahuthe algorithm. Thus we need the knowledge sharing of such a system to be as largeas possible. For this purpose, we believe that a new type of communication agentsshould be introduced. Agents of this type will not try to increase the search frontierbut rather move around the environment and spread the most recent data available.AcknowledgmentsA preliminary version of this paper appeared in Proceedings of the First International JointConference on Autonomous Agents and Multi-Agent Systems, 2002 (Felner et al., 2002).The work was carried out while the rst author was at Bar-Ilan University. This material isbased upon work supported in part by NSF under grant #0222914 and by ISF under grant#8008.Appendix A. Additional Experimental ResultsAs mentioned in Subsection 4.3, each node in a regular Delaunay graph is connected toall its neighbors. This property may not always apply to a real road map. For example,nearby geographic locations may not always be connected by a road segment, due to thethe existence of obstacles like a mountain or a river. In addition, distant locations are oftenconnected by highways. To capture these additional characteristics, we have also consid-ered so-called sparse and dense Delaunay graphs. Instances of these variants can be easilyobtained from regular Delaunay graphs by random deletion and addition of edges, respec-tively. Speci cally, we have generated sparse Delaunay graph instances by deleting roughly60% of the edges at random. Likewise, dense instances were generated by introducing 400edges at random. (A new edge is created by selecting at random a pair of nodes.)We have run all of the algorithms presented in the main body of the paper also on theabove Delaunay graph variants. The results obtained are presented here.As can be expected, the more sparse the graph, the more often the agent runs into dead-ends. Indeed, all the algorithms required additional travel e ort to nd the optimal pathafter edges were removed. However, the ratio between the travel cost of any two algorithmsseems to remain the same (for the various Delaunay graph types), and I-A*DFS exhibitssuperior performance for all graph instances. See Figures 10(a), (b). This behavior provedconsistent in all of our experiments, for both a single agent and a multi-agent environment.Also, Figures 11(a), (b) exhibit similar behavior of search cost of WinA* versus windowsize for sparse Delaunay graphs and dense Delaunay graphs, respectively, to that observedfor regular Delaunay graphs (see Figure 6).Figures 12(a), (b) present the costs of the fuel-e cient algorithm as a function of thenumber agents for various sizes of sparse and dense Delaunay graphs, respectively. Theoverall fuel consumption recorded for the sparse Delaunay graphs is larger than the fuelconsumption recorded for their counterpart regular graphs (see Figure 8) by a factor ofabout 1.5. For graphs simulating highways (i.e., the dense graphs) the fuel consumptiondecreases relative to both sparse and regular Delaunay graphs.Note that the optimal number of agents navigating in a sparse graph also increases, sinceagents need to backtrack more often in this case. Thus having more agents will assist the666\nPHA*: Finding the Shortest Path with A* in An Unknown Physical Environment\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n500 1000 1500 2000 2500 3000 3500 4000\nS ea\nrc h\nco st\nNumber of nodes in the graph\nTree path Shrtest known path\nAerial path P-DFS D-DFS A*DFS\nI-A*DFS\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n500 1000 1500 2000 2500 3000 3500 4000\nS ea\nrc h\nco st\nNumber of nodes in the graph\nTree path Shrtest known path\nAerial path P-DFS D-DFS A*DFS\nI-A*DFS\n(a) (b)Figure 10: Search cost versus the number of nodes of: (a) Sparse Delaunay graphs, and (b)dense Delaunay graphs for various low-level algorithms.\n2\n2.5\n3\n3.5\n4\n4.5\n5\n5.5\n6\n6.5\n7\n0 10 20 30 40 50 60 70 80\nS ea\nrc h\nco st\nWindow size\n500 nodes 1000 nodes 2000 nodes\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\n0 10 20 30 40 50 60 70 80\nS ea\nrc h\nco st\nWindow size\n500 nodes 1000 nodes 2000 nodes\n(a) (b)Figure 11: Search cost of WinA* versus window size for various sizes of: (a) Sparse Delaunaygraphs, and (b) dense Delaunay graphs.667\nFelner, Stern, Ben-Yair, Kraus, & Netanyahu 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7 7.5\n1 2 3 4 5 6 7 8 9\nF ue\nl c on\nsu m\npt io\nn\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes\n1\n1.2\n1.4\n1.6\n1.8\n2\n2.2\n2.4\n2.6\n2.8\n3\n1 2 3 4 5 6 7 8 9\nF ue\nl c on\nsu m\npt io\nn\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes\n(a) (b)Figure 12: Fuel consumption as a function of the number of agents for various sizes of: (a)Sparse Delaunay graphs, and (b) dense Delaunay graphs.search. On the other hand, adding random edges to the graphs causes the opposite e ect,i.e., less fuel is consumed and the optimal number of agents is reduced. This is explainedby the fact that new edges add more connections between nodes, i.e., many \"shortcuts\" arecreated and the search can be carried out faster and with a smaller number of agents. 0 1 2 3 4 5 6 7 8 9 10 11\n1 2 3 4 5 6 7 8 9\nS ea\nrc h\nti m\ne\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes 8000 nodes\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n1 2 3 4 5 6 7 8 9\nS ea\nrc h\nti m\ne\nNumber of agents\n500 nodes 1000 nodes 2000 nodes 4000 nodes 8000 nodes\n(a) (b)Figure 13: Time consumption as a function of the number of agents for various sizes of: (a)Sparse Delaunay graphs, and (b) dense Delaunay graphs.Figures 13(a), (b) present the costs of the time-e cient algorithm as a function of thenumber agents for various sizes of sparse and dense Delaunay graphs, respectively. Theresults con rm the same tendency that was observed for regular Delaunay graphs (see668\nPHA*: Finding the Shortest Path with A* in An Unknown Physical EnvironmentFigure 9), namely that as the number of agents grows, the overall cost converges to thelength of the optimal path.ReferencesArgamon-Engelson, S., Kraus, S., & Sina, S. (1998). Utility-based on-line exploration forrepeated navigation in an embedded graph. Arti cial Intelligence, 101(1-2), 967{984.Argamon-Engelson, S., Kraus, S., & Sina, S. (1999). Interleaved vs. a priori explorationfor repeated navigation in a partially-known graph. International Journal of PatternRecognition and Arti cial Intelligence, 13(7), 963{968.Barber, C. B., Dobkin, D. P., & Huhdanpaa, H. (1993). The Quickhull algorithm for convexhull. Tech. rep., Geometry Center Technical Report GCG53, University of Minnesota.Bellman, R. (1958). On a routing problem. Quarterly of Applied Mathematics, 16 (1), 87{90.Bender, M. A., Fernandez, A., Ron, D., Sahai, A., & Vadhan, S. P. (1998). The powerof a pebble: Exploring and mapping directed graphs. In Proceedings of the ThirtiethAnnual ACM Symposium on the Theory of Computing, pp. 269{278, Dallas, Texas.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction to Algo-rithms. MIT Press, Cambridge, Massachusetts. 2nd edition.Cucka, P., Netanyahu, N. S., & Rosenfeld, A. (1996). Learning in navigation: Goal ndingin graphs. International Journal of Pattern Recognition and Arti cial Intelligence,10(5), 429{446.Dechter, R., & Pearl, J. (1985). Generalized best- rst search strategies and the optimalityof A*. Journal of the Association for Computing Machinery, 32(3), 505{536.Dijkstra, E. W. (1959). A note on two problems in connexion with graphs. NumerischeMathematik, 1, 269{271.Felner, A., Kraus, S., & Korf, R. E. (2003). KBFS: K-best rst search. Annals of Mathe-matics and Arti cial Intelligence, in press.Felner, A., Stern, R., & Kraus, S. (2002). PHA*: Performing A* in unknown physical envi-ronments. In Proceedings of the First International Joint Conference on AutonomousAgents and Multi-Agent Systems, pp. 240{247, Bologna, Italy.Ghosh, B. (1951). Random distances within a rectangle and between two rectangles. Bulletinof the Culcutta Mathematical Society, 43, 17{24.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for the heuristic determina-tion of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics,SCC-4(2), 100{107.Kaelbling, L. P., & Moore, A. W. (1996). Reinforcement learning: A survey. Journal ofArti cial Intelligence Research, 4, 237{285.Karp, R., & Pearl, J. (1983). Searching for an optimal path in a tree with random costs.Arti cial Intelligence, 21(1-2), 99{116.669\nFelner, Stern, Ben-Yair, Kraus, & NetanyahuKitamura, Y., Teranishi, K., & Tatsumi, S. (1996). Organizational strategies for multi-agent real-time search. In Proceedings of the Second International Conference onMulti-Agent Systems, 409{416.Knight, K. (1993). Are many reactive agents better than a few deliberative ones?. InProceedings of the Thirteenth International Joint Conference on Arti cial Intelligence,pp. 432{437, Chamb ery, France.Koenig, S., & Likhachev, M. (2002a). D* lite. In Proceedings of the Eighteenth NationalConference on Arti cial Intelligence (AAAI), pp. 476{483, Edmonton, Canada.Koenig, S., & Likhachev, M. (2002b). Incremental A*. In Advances in Neural InformationProcessing Systems 14 (NIPS). MIT Press, Cambridge, MA.Korf, R. E. (1985). Depth- rst iterative-deepening: An optimal admissible tree search.Arti cial Intelligence, 27(1), 97{109.Korf, R. E. (1990). Real-time heuristic search. Arti cial Intelligence, 42(3), 189{211.Korf, R. E. (1993). Linear-space best- rst search. Arti cial Intelligence, 62(1), 41{78.Korf, R. E. (1997). Finding optimal solutions to Rubik's Cube using pattern databases.In Proceedings of the Fourteenth National Conference on Arti cial Intelligence, pp.700{705, Providence, Rhode Island.Korf, R. E. (1999). Sliding-tile puzzles and Rubik's Cube in AI research. IEEE IntelligentSystems, 14, 8{12.Okabe, A., Boots, B., & Sugihara, K. (1992). Spatial Tessellations, Concepts, and Applica-tions of Voronoi Diagrams. Wiley, Chichester, UK.Pearl, J., & Kim, J. H. (1982). Studies in semi-admissible heursitics. IEEE Transactionson Pattern Analysis and Machine Intelligence, 4, 392{400.Shmoulian, L., & Rimon, E. (1998). Roadmap-A*: An algorithm for minimizing travel e ortin sensor based mobile robot navigation. In Proceedings of the IEEE InternationalConference on Robotics and Automation, pp. 356{362, Leuven, Belgium.Stentz, A. (1994). Optimal and e cient path planning for partially-known environments.In Proceedings of the IEEE International Conference on Robotics and Automation,pp. 3310{3317, San Diego, CA.Stern, R. (2001). Optimal Path Search in Unknown Physical Enviroments. M.Sc.Thesis, Department of Computer Science, Bar-Ilan University, Israel; available onhttp://www.cs.biu.ac.il/ felner.Taylor, L., & Korf, R. (1993). Pruning duplicate nodes in depth- rst search. In Proceedingsof the Eleventh National Conference on Arti cial Intelligence, pp. 756{761, Washing-ton, D.C.Wagner, A., & Bruckstein, A. M. (2000). ANTS: Agents, networks, trees, and subgraphs.Future Generation Computer Systems Journal, 16(8), 915{926.Yanovski, V., Wagner, I. A., & Bruckstein, A. M. (2001). Vertex-ant-walk: A robust methodfor e cient exploration of faulty graphs. Annals of Mathematics and Arti cial Intel-ligence, 31(1-4), 99{112. 670"
    } ],
    "references" : [ {
      "title" : "Utility-based on-line exploration",
      "author" : [ "S. Argamon-Engelson", "S. Kraus", "S. Sina" ],
      "venue" : null,
      "citeRegEx" : "Argamon.Engelson et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Argamon.Engelson et al\\.",
      "year" : 1998
    }, {
      "title" : "Interleaved vs. a priori exploration",
      "author" : [ "S. Argamon-Engelson", "S. Kraus", "S. Sina" ],
      "venue" : null,
      "citeRegEx" : "Argamon.Engelson et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Argamon.Engelson et al\\.",
      "year" : 1999
    }, {
      "title" : "The Quickhull algorithm for convex",
      "author" : [ "C.B. Barber", "D.P. Dobkin", "H. Huhdanpaa" ],
      "venue" : null,
      "citeRegEx" : "Barber et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Barber et al\\.",
      "year" : 1993
    }, {
      "title" : "On a routing problem",
      "author" : [ "R. Bellman" ],
      "venue" : "Quarterly of Applied Mathematics,",
      "citeRegEx" : "Bellman,? \\Q1958\\E",
      "shortCiteRegEx" : "Bellman",
      "year" : 1958
    }, {
      "title" : "Learning in navigation: Goal",
      "author" : [ "P. Cucka", "N.S. Netanyahu", "A. Rosenfeld" ],
      "venue" : null,
      "citeRegEx" : "Cucka et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Cucka et al\\.",
      "year" : 1996
    }, {
      "title" : "Generalized best- rst search strategies and the optimality",
      "author" : [ "R. Dechter", "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Dechter and Pearl,? \\Q1985\\E",
      "shortCiteRegEx" : "Dechter and Pearl",
      "year" : 1985
    }, {
      "title" : "A note on two problems in connexion with graphs",
      "author" : [ "E.W. Dijkstra" ],
      "venue" : null,
      "citeRegEx" : "Dijkstra,? \\Q1959\\E",
      "shortCiteRegEx" : "Dijkstra",
      "year" : 1959
    }, {
      "title" : "KBFS: K-best rst search",
      "author" : [ "A. Felner", "S. Kraus", "R.E. Korf" ],
      "venue" : null,
      "citeRegEx" : "Felner et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Felner et al\\.",
      "year" : 2003
    }, {
      "title" : "PHA*: Performing A* in unknown physical",
      "author" : [ "A. Felner", "R. Stern", "S. Kraus" ],
      "venue" : null,
      "citeRegEx" : "Felner et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Felner et al\\.",
      "year" : 2002
    }, {
      "title" : "Random distances within a rectangle and between two rectangles",
      "author" : [ "B. Ghosh" ],
      "venue" : null,
      "citeRegEx" : "Ghosh,? \\Q1951\\E",
      "shortCiteRegEx" : "Ghosh",
      "year" : 1951
    }, {
      "title" : "A formal basis for the heuristic determina",
      "author" : [ "P.E. Hart", "N.J. Nilsson", "B. Raphael" ],
      "venue" : null,
      "citeRegEx" : "Hart et al\\.,? \\Q1968\\E",
      "shortCiteRegEx" : "Hart et al\\.",
      "year" : 1968
    }, {
      "title" : "Reinforcement learning: A survey",
      "author" : [ "L.P. Kaelbling", "A.W. Moore" ],
      "venue" : null,
      "citeRegEx" : "Kaelbling and Moore,? \\Q1996\\E",
      "shortCiteRegEx" : "Kaelbling and Moore",
      "year" : 1996
    }, {
      "title" : "Searching for an optimal path in a tree with random costs",
      "author" : [ "R. Karp", "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "Karp and Pearl,? \\Q1983\\E",
      "shortCiteRegEx" : "Karp and Pearl",
      "year" : 1983
    }, {
      "title" : "Organizational strategies for multi",
      "author" : [ "Y. Kitamura", "K. Teranishi", "S. Tatsumi" ],
      "venue" : null,
      "citeRegEx" : "Kitamura et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Kitamura et al\\.",
      "year" : 1996
    }, {
      "title" : "Are many reactive agents better than a few deliberative ones",
      "author" : [ "K. Knight" ],
      "venue" : null,
      "citeRegEx" : "Knight,? \\Q1993\\E",
      "shortCiteRegEx" : "Knight",
      "year" : 1993
    }, {
      "title" : "Incremental A",
      "author" : [ "S. Koenig", "M. Likhachev" ],
      "venue" : "In Advances in Neural Information",
      "citeRegEx" : "Koenig and Likhachev,? \\Q2002\\E",
      "shortCiteRegEx" : "Koenig and Likhachev",
      "year" : 2002
    }, {
      "title" : "Depth- rst iterative-deepening: An optimal admissible tree search",
      "author" : [ "R.E. Korf" ],
      "venue" : null,
      "citeRegEx" : "Korf,? \\Q1985\\E",
      "shortCiteRegEx" : "Korf",
      "year" : 1985
    }, {
      "title" : "Real-time heuristic search",
      "author" : [ "R.E. Korf" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Korf,? \\Q1990\\E",
      "shortCiteRegEx" : "Korf",
      "year" : 1990
    }, {
      "title" : "Linear-space best- rst search",
      "author" : [ "R.E. Korf" ],
      "venue" : "Arti cial Intelligence,",
      "citeRegEx" : "Korf,? \\Q1993\\E",
      "shortCiteRegEx" : "Korf",
      "year" : 1993
    }, {
      "title" : "Finding optimal solutions to Rubik's Cube using pattern databases",
      "author" : [ "R.E. Korf" ],
      "venue" : null,
      "citeRegEx" : "Korf,? \\Q1997\\E",
      "shortCiteRegEx" : "Korf",
      "year" : 1997
    }, {
      "title" : "Sliding-tile puzzles and Rubik's Cube in AI research",
      "author" : [ "R.E. Korf" ],
      "venue" : null,
      "citeRegEx" : "Korf,? \\Q1999\\E",
      "shortCiteRegEx" : "Korf",
      "year" : 1999
    }, {
      "title" : "Spatial Tessellations, Concepts, and Applica",
      "author" : [ "A. Okabe", "B. Boots", "K. Sugihara" ],
      "venue" : null,
      "citeRegEx" : "Okabe et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Okabe et al\\.",
      "year" : 1992
    }, {
      "title" : "Studies in semi-admissible heursitics",
      "author" : [ "J. Pearl", "J.H. Kim" ],
      "venue" : "IEEE Transactions",
      "citeRegEx" : "Pearl and Kim,? \\Q1982\\E",
      "shortCiteRegEx" : "Pearl and Kim",
      "year" : 1982
    }, {
      "title" : "Roadmap-A*: An algorithm for minimizing travel e ort",
      "author" : [ "L. Shmoulian", "E. Rimon" ],
      "venue" : null,
      "citeRegEx" : "Shmoulian and Rimon,? \\Q1998\\E",
      "shortCiteRegEx" : "Shmoulian and Rimon",
      "year" : 1998
    }, {
      "title" : "Optimal and e cient path planning for partially-known environments",
      "author" : [ "A. Stentz" ],
      "venue" : null,
      "citeRegEx" : "Stentz,? \\Q1994\\E",
      "shortCiteRegEx" : "Stentz",
      "year" : 1994
    }, {
      "title" : "Optimal Path Search in Unknown Physical Enviroments",
      "author" : [ "R. Stern" ],
      "venue" : null,
      "citeRegEx" : "Stern,? \\Q2001\\E",
      "shortCiteRegEx" : "Stern",
      "year" : 2001
    }, {
      "title" : "Pruning duplicate nodes in depth- rst search",
      "author" : [ "L. Taylor", "R. Korf" ],
      "venue" : null,
      "citeRegEx" : "Taylor and Korf,? \\Q1993\\E",
      "shortCiteRegEx" : "Taylor and Korf",
      "year" : 1993
    }, {
      "title" : "Vertex-ant-walk: A robust method",
      "author" : [ "V. Yanovski", "I.A. Wagner", "A.M. Bruckstein" ],
      "venue" : null,
      "citeRegEx" : "Yanovski et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Yanovski et al\\.",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "The sliding-tile puzzle and Rubik's Cube (Korf, 1999) are examples of the c 2004 AI Access Foundation.",
      "startOffset" : 41,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "For the class of fully-known graphs, classical algorithms, such as Dijkstra's single-source shortest-path algorithm (Dijkstra, 1959) and the Bellman-Ford algorithm (Bellman, 1958), can be used to nd the optimal path between any two nodes.",
      "startOffset" : 116,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "For the class of fully-known graphs, classical algorithms, such as Dijkstra's single-source shortest-path algorithm (Dijkstra, 1959) and the Bellman-Ford algorithm (Bellman, 1958), can be used to nd the optimal path between any two nodes.",
      "startOffset" : 164,
      "endOffset" : 179
    }, {
      "referenceID" : 16,
      "context" : ", IDA* (Korf, 1985) and RBFS (Korf, 1993), are the common methods for nding the shortest paths in large graphs.",
      "startOffset" : 7,
      "endOffset" : 19
    }, {
      "referenceID" : 18,
      "context" : ", IDA* (Korf, 1985) and RBFS (Korf, 1993), are the common methods for nding the shortest paths in large graphs.",
      "startOffset" : 29,
      "endOffset" : 41
    }, {
      "referenceID" : 17,
      "context" : "Unlike ordinary navigation tasks (Cucka, Netanyahu, & Rosenfeld, 1996; Korf, 1990; Stentz, 1994; Shmoulian & Rimon, 1998), the purpose of the agent is not to reach the goal node as soon as possible, but rather explore the graph in such a manner that the shortest path will be retrieved for future usage.",
      "startOffset" : 33,
      "endOffset" : 121
    }, {
      "referenceID" : 24,
      "context" : "Unlike ordinary navigation tasks (Cucka, Netanyahu, & Rosenfeld, 1996; Korf, 1990; Stentz, 1994; Shmoulian & Rimon, 1998), the purpose of the agent is not to reach the goal node as soon as possible, but rather explore the graph in such a manner that the shortest path will be retrieved for future usage.",
      "startOffset" : 33,
      "endOffset" : 121
    }, {
      "referenceID" : 18,
      "context" : "However, for many problems, such as the sliding tile puzzles and Rubik's Cube, a simple rst-in rst-out queue su ces (Korf, 1993; Taylor & Korf, 1993; Korf, 1997).",
      "startOffset" : 116,
      "endOffset" : 161
    }, {
      "referenceID" : 19,
      "context" : "However, for many problems, such as the sliding tile puzzles and Rubik's Cube, a simple rst-in rst-out queue su ces (Korf, 1993; Taylor & Korf, 1993; Korf, 1997).",
      "startOffset" : 116,
      "endOffset" : 161
    }, {
      "referenceID" : 4,
      "context" : "(Cucka et al., 1996) have introduced navigation algorithms for sensory-based environments such as automated robots moving in a room.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 17,
      "context" : "Real-Time-A* (RTA*) (Korf, 1990) and its more sophisticated version, Learning RealTime-A* (LRTA*), are also algorithms for nding paths between two nodes in a graph.",
      "startOffset" : 20,
      "endOffset" : 32
    }, {
      "referenceID" : 17,
      "context" : "Korf (Korf, 1990) proves that over a large number of runs, where for each run the start node is selected at random, the stored value of each node visited by the LRTA* problem solver converges to the optimal distance to the goal.",
      "startOffset" : 5,
      "endOffset" : 17
    }, {
      "referenceID" : 14,
      "context" : "MARTA* (Knight, 1993) is a multi-agent version of RTA*.",
      "startOffset" : 7,
      "endOffset" : 21
    }, {
      "referenceID" : 24,
      "context" : "D*-Lite is actually a simpli ed version of a previous algorithm D* by Stenz (Stentz, 1994).",
      "startOffset" : 76,
      "endOffset" : 90
    }, {
      "referenceID" : 4,
      "context" : "We have experimented with the following DFS-based navigation algorithms that were proposed by (Cucka et al., 1996): Positional DFS (P-DFS):This DFS-based navigation algorithm sorts the neighbors according to their Euclidean distance from the target node, choosing the node with minimum distance to the target node rst.",
      "startOffset" : 94,
      "endOffset" : 114
    }, {
      "referenceID" : 4,
      "context" : "A generalized version of navigating with a cost function similar to that of A* called \\robotic A*\" (RA*), was also proposed by (Cucka et al., 1996); the node w is either a neighbor (of v) or an already visited node.",
      "startOffset" : 127,
      "endOffset" : 147
    }, {
      "referenceID" : 21,
      "context" : "The latter are computed over a set of planar point patterns, generated by a Poisson point process (Okabe et al., 1992).",
      "startOffset" : 98,
      "endOffset" : 118
    }, {
      "referenceID" : 9,
      "context" : "521) (Ghosh, 1951).",
      "startOffset" : 5,
      "endOffset" : 18
    }, {
      "referenceID" : 10,
      "context" : "It is well-known, under this paradigm, that once the goal node is selected for expansion, A* has found an optimal path (Hart et al., 1968; Karp & Pearl, 1983; Dechter & Pearl, 1985).",
      "startOffset" : 119,
      "endOffset" : 181
    }, {
      "referenceID" : 25,
      "context" : "See (Stern, 2001) for a comprehensive description.",
      "startOffset" : 4,
      "endOffset" : 17
    }, {
      "referenceID" : 25,
      "context" : "See (Stern, 2001) for further discussion on agent distribution.",
      "startOffset" : 4,
      "endOffset" : 17
    }, {
      "referenceID" : 25,
      "context" : "See (Stern, 2001) for a detailed discussion.",
      "startOffset" : 4,
      "endOffset" : 17
    }, {
      "referenceID" : 25,
      "context" : "See (Stern, 2001) for a more detailed explanation of this phenomenon.",
      "startOffset" : 4,
      "endOffset" : 17
    }, {
      "referenceID" : 8,
      "context" : "Acknowledgments A preliminary version of this paper appeared in Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems, 2002 (Felner et al., 2002).",
      "startOffset" : 171,
      "endOffset" : 192
    } ],
    "year" : 2011,
    "abstractText" : null,
    "creator" : "dvips 5.76 Copyright 1997 Radical Eye Software (www.radicaleye.com)"
  }
}