{
  "name" : "1610.07273.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Encoding Temporal Markov Dynamics in Graph for Time Series Visualization",
    "authors" : [ "Lu Liu", "Zhiguang Wang" ],
    "emails" : [ "liulumy@umbc.edu", "zgwang813@gmail.com" ],
    "sections" : [ {
      "heading" : "1 INTRODUCTION",
      "text" : "Time series data is ubiquitous in both industry and academia. Except for the perceptual signals that we are able to easily understand like audio, video and nature language, most of the other time series generated are mechanical signals. Therefore, Understanding temporal patterns is key to gaining knowledge and insight.\nCollectively, our ability to store data now far exceeds the rate at which we are able to understand it. Scientists and domain experts expect to discover patterns, thus to help the further understanding of those mechanical signals in various tasks like classification and anomaly detection. Learning the (long) temporal correlations that are often embedded in time series remains a major challenge. Visualization of time series provides a new perspective to explore those complex dynamics more intuitively.\nMany visualization methods have been introduced to address time series mining tasks. The line graph is widely used [9, 14]. While the standard time series graph is effective when dealing with a small data space, it is more challenging to perform common tasks on larger data. Pixel plot is explored to represent a time-series as an arrangement of pixels encoded with different hues which encode the underlying data [10, 5]. Besides aggregating the data into temporal segments with lens view, layout based techniques provide a linear mapping by modifying the spatial arrangement of the time while transforming those graphs which enhance the display. [6] proposes an early importance driven layout scheme. [7] presents a multi-focus zooming approach which maintains context and temporal distance zooming. [8] compares stack zooming against standard techniques for navigation of temporal data.\nHowever, more complex and noisy real-world time series data is often difficult to observe through visualization because the dynam-\n∗liulumy@umbc.edu †zgwang813@gmail.com\nics are either too complex or unintuitive. To provide more profound insights about the temporal dynamics embedded in time series, one possible solution is to reformulating the data to explicitly extract features for better visual encode of the temporal dependency.\nActually, reformulating the features of time series as visual clues has been studied in physics as a kind of dynamical systems and raised much attention in data mining and machine learning research. One major approach is to build different network structures from time series for visual analytics. Recurrence Networks were proposed to analyze the structural properties of time series from complex systems [4]. They build adjacency matrices from the predefined recurrence functions to interpret the time series as complex networks for visual inspection and metric based classification. [15] extended the recurrence plot paradigm for time series classification using compression distance. Another way to build a weighted adjacency matrix is to model the temporal-spatial transition dynamics with first order Markov matrix [3]. Although these maps demonstrate distinct topological properties among different time series to visualize the intrinsic statistics, it remains unclear how these topological properties relate to the original time series to help visual analytics as they have no exact inverse operations.\n[16] proposed a novel encoding framework to transform time series to images as the input for deep convolution neural networks and achieved state-of-the-art classification performance. We found proposed temporal Markov encoding maps have exact/approximate inverse maps, making such transformation more interpretable with graph visualization techniques.\nInspired by the temporal Markov encoding approaches, we design a novel visualization framework to translate time series into complex networks while preserve both temporal ordering and statistical dynamics. Our encoding map also has a natural inverse, which makes it possible to visually explore the interesting patterns in the generated graph and match them back to the original data. Our experimental results suggest the effectiveness on various tasks such as system identification, classification and anomaly detection on both benchmark and real time series data."
    }, {
      "heading" : "2 DATA TRANSFORMATION AND QUANTITATIVE ENCODING",
      "text" : "Temporal and frequency correlation are major dependencies embedded in time series data. To build a comprehensive but intuitive visualization, the extracted features from the designed data transformation framework should be able to represent the dynamics in both time and frequencies while there exists a reverse operation to map the information back to raw time series. In this section, we will introduce how to encode the dynamical frequency information in the temporal ordering step by step (Figure 1)."
    }, {
      "heading" : "2.1 Quantization and Markov Matrix",
      "text" : "This framework is similar to [3] for encoding dynamical transition statistics. We develop that idea by representing the Markov transition probabilities sequentially to preserve information in the temporal dimension. The first step is to quantize time series to build the first order Markov Matrix.\nGiven a time series X = {x1,x2, · · · ,xn}, we need to quantize its values in Q bins. Quantile is the most common way to achieve a discretized dictionary. By identifying the Q quantile bins, each value\nar X\niv :1\n61 0.\n07 27\n3v 1\n[ cs\n.L G\n] 2\n4 O\nct 2\n01 6\nxi is mapped to each qi. In [13], a different quantization approach is proposed. Based on the empirical observation that normalized time series has a Gaussian distribution [11], it is desirable to have a discretization technique that will produce bins with equiprobability. We can simply determine the breakpoints that will produce an equal-sized areas under Gaussian curve. Breakpoints are a sorted list of numbers Q = q1,q2, ...,qQ such that the area under a N(0,1) Gaussian curve follows P(qi+1)−P(qi) = 1Q .\nQuantile mapping ignored the Gaussian priori, so it is more data-specific while the distribution on different datasets could drift significantly, although some data actually comes from the similar distribution. Gaussian mapping does not have such problems and performs well with Symbolic Aggregate Approximation (SAX) in classification and query tasks. In the next sections, we use Gaussian mapping to create the dictionary for quantizing time series.\nAfter assigning each xi to its corresponding bin q j ( j ∈ [1,Q]), we construct a Q×Q weighted adjacency matrix W by counting transitions among bins in the manner of a first-order Markov chain along each time step. wi, j is the frequency of a point in the bin q j followed by a point in the bin qi. After normalization by ∑ j wi j = 1, W is a Markov matrix:\nW =  w11|P(xt∈q1|xt−1∈q1) · · · w1Q|P(xt∈q1|xt−1∈qQ) w21|P(xt∈q2|xt−1∈q1) · · · w2Q|P(xt∈q2|xt−1∈qQ)\n... . . . ... wQ1|P(xt∈qQ|xt−1∈q1) · · · wQQ|P(xt∈qQ|xt−1∈qQ)\n (1)"
    }, {
      "heading" : "2.2 Markov Transition Field and Network Graph",
      "text" : "Markov matrix, while incorporating the Markov dynamics, discards the conditional relationship between the distribution of X and the temporal dependency on the time steps ti. Markov Transition Field (MTF) extends Markov matrix by aligning each probability along the temporal order.\nM =\n M11 M12 · · · M1n M21 M22 · · · M2n\n... . . . ... Mn1 Mn2 · · · Mnn\n\n=  wi j|x1∈qi,x1∈q j · · · wi j|x1∈qi,xn∈q j wi j|x2∈qi,x1∈q j · · · wi j|x2∈qi,xn∈q j\n... . . . ... wi j|xn∈qi,x1∈q j · · · wi j|xn∈qi,xn∈q j  (2) That is, in the Markov matrix M, the quantile bins that contain the data at time steps i and j (temporal axis) are qi and q j (q ∈ [1,Q]). Mi j denotes the transition probability of qi → q j. In other words, we spread out matrix W , which contains the transition probability on the magnitude axis, into the W by considering temporal positions.\nBy assigning the probability from the quantile at time step i to the quantile at time step j at each pixel Mi j, the MTF M actually encodes multi-scale transition probabilities of the time series. Mi, j||i− j|=k denotes the transition probability between the points with time interval k. For example, Mi j| j−i=1 illustrates the transition process along the time axis with a skip step. The main diagonal Mii, which is a special case when k = 0 captures the probability from each quantile to itself (the self-transition probability).\nThe square matrix M can be interpreted as a network graph G = (V,E) directly. Each value Mi j represents the edge weights, each row/column corresponds to the vertex index. Note that such settings allow the inverse operation to match nodes back to the time series, as the mapping between node Vi in the graph and the point xi in the time series is bijective. As in Figure 1, the nodes in red, blue and yellow exactly match different time points respectively."
    }, {
      "heading" : "2.3 Dimension Reduction",
      "text" : "To make the matrix size manageable for more efficient computation and visualization, two common dimension reduction techniques can be performed before or after the MTF encoding:\n• Piecewise Aggregate Approximation (PAA) suppose to reduce the time series from n dimensions to w dimensions, the data is divided into w equal sized frames. The mean/median value of the data falling within a frame is calculated and a vector of these values becomes the data-reduced representation. The representation can be visualized as an attempt to approximate the original time series with a linear combination of box basis functions. PAA is a special case of moving average model when the skip size equals to the length of the sliding window.\n• Blurring on MTF is fulfilled by averaging the pixels in each non-overlapping m×m patch with a blurring kernel, typically\na Bivariate Gaussian { 12πσ 2 e − x\n2 1+x 2 2\n2σ2 }m×m or a simple average kernel { 1m2 }m×m. That is, we aggregate the transition probabilities in each subsequence of length m together with a convolution operation with a smaller kernel. The final output size S = d nme.\nPAA is simple and effective especially when the detailed structure of the time series can be ignored while the major\ntrends/patterns are important, like in the tasks of classification and query. For analyzing the visual patterns, small information loss and minimum manipulation on the raw data is preferred to preserve the information in the raw data. Hence, we only use Gaussian blurring to reduce the MTF size."
    }, {
      "heading" : "3 VISUAL ENCODING AND INVERSE MAPPING",
      "text" : "For general inspection, the graph G = (V,E) generated from MTF has a direct mapping from the vertex V to the time index i in the original time series. It is easy to encode the time index {1,2, ...,n} as the color of the vertices. Along the temporal axis, we choose PageRank weights as the vertex size and Markov matrix weight as the edge color to observe when (to which vertex) do the big information/citation flow occurs.\nModularity is an important pattern in network analysis to identify the specific local structures. To verify the modules and distinct patterns, we also figure out the modularity label and the clustering coefficient [2, 12] for each vertex and map them back to the original time series. and assign the modularity labels to each vertex. In this way, another visual encoding idea is to encode the vertex/edge color as the module labels it belongs to and the vertex size as the\nclustering coefficient. So we have two visual encoding frameworks for general/flow inspection and modularity discovery (Table 1).\nAs each vertex index and the time index are one-to-one mapping, we can easily map the interesting patterns we find in the graph back to the time series. As in Figure 1 (c) and (d), the three communities discovered in both graph have their corresponding shapelets in the raw time series."
    }, {
      "heading" : "4 EXPERIMENTS AND ANALYSIS",
      "text" : ""
    }, {
      "heading" : "4.1 System Identification",
      "text" : "To highlight the potential of the encoding graph described above, we first apply it to two time series belonging to different dynamical systems (Figure 1 (a)). The first time series is the variable of the chaotic Lorenz equations\ndx dt = σ(−x+ y) dy dt = rx− y− xz dz dt = bz+ xy (3)\nwith parameter values σ = 10,b = 83 and r = 28. Numerical solutions of these equations leads to an attractor embedded in a three-dimensional space with coordinates. The trajectory rotates about one of two unstable fixed points then escapes to orbit the other fixed point. This behavior is recognizable in the variable x since its values oscillate between the positive and the negative.\nThe second time series is the variable of the chaotic Rossler equations\ndx dt = −(y+ z) dy dt = x+ay dz dt = b+ z(x− c) (4)\nwith parameter values a = 0.432, b = 2 and c = 4. The trajectory within the attractor follows an outward spiral close to the plane around an unstable fixed point. Once the trajectory spirals out enough, a second fixed point influences it, causing a rise and twist in the z dimension. This behavior generates a quasi-periodic oscillatory pattern in the x variable, with peaks and troughs in different amplitudes.\nFrom Figure 2, we can clearly identify the difference between these two dynamical systems. The network of Rossler system has a clear sparse connection area like a bipartite graph. The big blue vertices near the boarder of the bipartite gap indicate the homogeneous large transition towards the time end. This means the system has either converging or periodical behavior, which is consistent with the three even peaks at the ends, as the system begin to orbit in\na quasi-periodical way. Lorenz system indicates strong coherence without any gap inside the graph. Instead, the big transition flow incurs from the start to the end as we can observe both enough big blue and red vertices. This means the system is very unstable, transiting among states very often without a converging or periodical trend.\nThe most interesting results are the shapelet discovered from the graph communities, as shown in Figure 3. The community detection algorithm recognizes three modules in both systems. After matching the vertices with different module labels back to the raw time series, the time series shapelets share the common patterns respectively. For Lorenz system, three communities correspond to the high frequency oscillation (red), low frequency oscillation (green) and the alternating behavior switching between those two fixed points (blue). Rossler system is quasi-periodic with steady slow transition among multiple magnitudes. The shapelet mapped from the community can be summarized as three basic ’wavelet’ type: the convex wavelets within small (red) and big (blue) magnitude and the concave wavelet (green). Thus, the basic patterns embedded in the time series are discovered through the graph visualization and network statistics."
    }, {
      "heading" : "4.2 Anomaly Detection",
      "text" : "We test our visualization approach on three typical compound functions [17] with different types of outliers to see if we can identify the outliers by the graph and network statistics.\n1). The notch function is defined by\nf1(x) =\n{ 0 if x ∈ [0,1] ⋃ [3.5,4.5]\n1 otherwise\nThe outliers in the middle range are generated by the function\nf ∗1 (x) =  0.25 if x ∈ [2.9,3] 0.5 if x ∈ [1.6,1.7] 0.75 if x ∈ [2.2,2.3]\nwhere x∈ X = [0,4.5]. xi are obtained by random sampling 2000 non-repeatable numbers from X with a uniform distribution, and the corresponding output values yk are computed by f (x) and f ∗(x). The overall function is F1(x) = f1(x)+ f ∗1 (x).\n2). The smooth function is defined by\nf2(x) = g(x, 1 6 , 1 2 , 1 6 )\nThe outliers with very large derivations is given by\nf ∗2 (x) = g(x, 1\n64 , 1 4 , 1 128 )+g(x, 1 64 , 1 20 , 1 128 )\nWhere x ∈ X = [0,1], g is defined as\ng(x) = α√ 2πτ cos( (x−µ)π τ )e− (x−µ)2 2τ2 (5)\nThe overall function is F2(x) = f2(x) + f ∗2 (x). The input values xi are selected by sampling 2000 numbers from a uniformly distributed grid on X . The corresponding output values yi are computed by f (x) and f ∗(x).\n3). Define a smooth function as\nF3(x) = g(x, 1 5 , 1 4 , 1 12 )+g(x, 1 5 , 3 4 , 1 12 )\nThe outliers from the under-sampled points are given by the lower sampling frequency. x ∈ X = [0,1.5], the outliers x∗i are collected by sampling 200 numbers from a uniform distributed grid on [0,0.5] and 200 numbers from a uniform distributed grid on [1.0,1.5]. The smooth function is generated by 2000 numbers of points from a uniform distributed grid on (0.5,1.0). So the oracle function is f3(x) = F3(x),x ∈ (0.5,1) and the outlier generating function is f3(x) = F3(x),x ∈ [0,0.5] ⋃ [1,1.5]. The output yi is\ncomputed by F3(x). The data with 2400 (xi,yi) pairs is the function contaminated by the unevenly under-sampled segments.\nThese functions represent three typical sources of outliers (Figure 4 (a)). The outliers in F1(x) are in the range of the uncontaminated data but appearing at wrong positions. This sometimes occurs when the value in a time series is within normal magnitude but maybe corrupted or inaccurate. F2(x) is affected by outliers with significant large deviations (even exceeding the bounds), indicating the situations where the time series contains some unknown samples with extraordinary bounds. F3(x) includes seemingly uncontaminated but shifted and under-sampled data. This may happen among heterogeneous observations from several experiments where the time series obtained is highly sparse and biased, and the main function needs to get rid of their influence.\nThe network graphs (Figure 4(b) and (c)) are generated with Q = {10,10,10} and S = {50,200,200} respectively. The ground truth is highlighted in red. To recognize the outlier structures in the graph, we should select the vertices that are not bundled so closely within its near communities, since the outlier has few but sudden pattern in the time series, the rareness and weirdness isolate the corresponding vertices in the graph to be comparatively independent. The recognition process combines two procedures:\n• We visually inspect the graph and select the most isolated vertices, denote as the set H.\n• The top k vertices with the smallest clustering coefficients are selected, denote as the set S\nThen we use the union H ∪ S to finally decide which vertices are most isolated, which should be recognized as the outlier candidates (green vertices in Figure 4(c)). The vertices marked as outlier candidates are mapped back to the original time series to show the outlier subsequence and their raw patterns. Comparing Figure 4 (a) and (d), our results demonstrate accurate recognition performance on where and what the outliers are.\nNote that sometimes the vertices selected by visual inspection and lowest clustering coefficient are significantly different. Choosing the set intersection H∩S will sometimes leads to the high falsenegative rate as some vital outlier patterns might be ignored. This is actually the worst case in anomaly detection. So we choose the union H ∪ S to guarantee the low false-negative rate, as the falsepositive patterns can be easily eliminated by inversely mapping the vertices to the original time series and comparing the subsequence distances or even by visually inspecting on those mapped shapelets."
    }, {
      "heading" : "4.3 Classification",
      "text" : "Our final experiment is to identify the class labels on three real time series dataset: ECG, Wafer and Gun Point [18]. The ECG dataset is a time series of the measurements recorded by one electrode during one heartbeat. The data has been annotated by cardiologists and a label of normal or abnormal is assigned to each data record. The Gun Point dataset contains two-dimensional time series extracted from video of two actors either aiming a gun or simply pointing at a target. The two dimensions correspond to the X and Y coordinates of the actors right hand. For simplicity we only consider the Y-axes. The Wafer dataset is recorded by one vacuum-chamber sensor during the etch process of silicon wafers for semiconductor fabrication with the normal or abnormal.\nWe randomly picked one sample of each label and draw the network graph with Q = {50,50,10} for the Gun Point, ECG and Wafer dataset. Dimension reduction is skipped as we suppose to keep full information in the original data. The network graph uses modularity encoding to highlight the distinct structures for different labels (Figure 5).\nAn interesting finding is, even we cannot observe the reasonable difference from the mechanical signals, network graph could show us the clear difference in their network structures. For ECG dataset, the label difference is more differentiable from the network struc-\ntures, where the healthy ECG has a linear structure with four close communities, while the unhealthy ECG has a round structure with five vague communities.\nFor the Gun Point dataset, the time series seems to be very similar as the Point pattern is stretched from the Gun-draw to have a wider plateau in the middle. However, their network structures show a huge difference with seven and three clear communities."
    }, {
      "heading" : "4.4 Network Statistics and Summary",
      "text" : "Our encoding network graph not only supports the purpose of visualization of time series, it also bridges the visual analytics, network dynamics and time series analysis with a natural inverse map from network graph to the original time series. Networks can be analyzed by exploring an extensive set of statistical properties of the associated time series with an active visual understanding. For example, motifs discovered in a network are mapped as specific spatial-temporal patterns in a time series, which are characterized by looking at the corresponding forward and backward maps. At the same time, different dynamical regimes in time series can be visualized and understood by exploring an extensive set of topological statistics at the associated network domain.\nTable 2 summarizes some common network statistics on all of our experimental datasets [1]. On the ECG, Wafer and Gun Point dataset, the average across all the samples with specific labels are reported.\nSpecifically, some statistics associated with different labels are significantly different. The average degree and weighted degree are the right features to distinguish between the negative and positive labels across all three dataset. This means that the network graph generated from each label has different overall network topology. The network density and the number of communities are also helpful in classifying healthy and unhealthy samples for the ECG dataset. For the Gun Point dataset, all statistics shows significant difference between the action of Gun-draw and Point. Our network graph captures the essential features of the spatial-temporal dynamics to describe those two actions. Rather than user study, the network statistics also provide a more objective and efficient way, together with the inspection of the visualization graphs, to verify the effectiveness of our visualization approach across all the three tasks."
    }, {
      "heading" : "5 CONCLUSION AND FUTURE WORK",
      "text" : "In this work, we present a novel visualization framework to translate time series into the network graph. Built through Markov matrix variant called Markov transition field, the graph is able to encode both temporal ordering and statistical dynamics. Our encoding map also has a natural inverse, enable the visual exploring of the\ninteresting patterns in the generated graph and the inverse mapping to the original data. The experiments on both benchmark and real time series data demonstrate the effectiveness of our visualization framework on three tasks: system identification, classification and anomaly detection. The inverse mapping is one-to-one, which provides a link between pattern recognition in the network graph and time series analysis. Moreover, our work bridges the gap between visual analytics on time series and network analysis, as the the generated network graph can be analyzed by exploring an extensive set of statistical properties of the associated time series with an active visual understanding.\nAs one of the future work, we are interested in designing a unified user interface to build a set of interaction mechanism to enable the active exploring of the time series through the network graph by the users. Another interesting work to do is to deeply incorporate the statistical complex network theory with the visual analytics framework to provide theoretical support and further reinforce the profile of time series visualization."
    } ],
    "references" : [ {
      "title" : "Gephi: an open source software for exploring and manipulating networks",
      "author" : [ "M. Bastian", "S. Heymann", "M. Jacomy" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Fast unfolding of communities in large networks",
      "author" : [ "V.D. Blondel", "J.-L. Guillaume", "R. Lambiotte", "E. Lefebvre" ],
      "venue" : "Journal of statistical mechanics: theory and experiment,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Duality between time series and networks",
      "author" : [ "A.S. Campanharo", "M.I. Sirer", "R.D. Malmgren", "F.M. Ramos", "L.A.N. Amaral" ],
      "venue" : "PloS one,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Recurrence networksa novel paradigm for nonlinear time series analysis",
      "author" : [ "R.V. Donner", "Y. Zou", "J.F. Donges", "N. Marwan", "J. Kurths" ],
      "venue" : "New Journal of Physics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2010
    }, {
      "title" : "Multi-resolution techniques for visual exploration of large time-series data",
      "author" : [ "M. Hao", "U. Dayal", "D. Keim", "T. Schreck" ],
      "venue" : "In Proceedings of the 9th Joint Eurographics / IEEE VGTC Conference on Visualization,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2007
    }, {
      "title" : "Importance-driven visualization layouts for large time series data",
      "author" : [ "M.C. Hao", "U. Dayal", "D.A. Keim", "T. Schreck" ],
      "venue" : "In IEEE Symposium on Information Visualization,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2005
    }, {
      "title" : "Stack zooming for multi-focus interaction in time-series data visualization",
      "author" : [ "W. Javed", "N. Elmqvist" ],
      "venue" : "In 2010 IEEE Pacific Visualization Symposium (PacificVis),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Stack zooming for multifocus interaction in skewed-aspect visual spaces",
      "author" : [ "W. Javed", "N. Elmqvist" ],
      "venue" : "IEEE transactions on visualization and computer graphics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2013
    }, {
      "title" : "Graphical perception of multiple time series",
      "author" : [ "W. Javed", "B. McDonnel", "N. Elmqvist" ],
      "venue" : "IEEE transactions on visualization and computer graphics,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2010
    }, {
      "title" : "Line graph explorer: Scalable display of line graphs using focus+context",
      "author" : [ "R. Kincaid", "H. Lam" ],
      "venue" : "In Proceedings of the Working Conference on Advanced Visual Interfaces,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "An introduction to mathematical statistics and its applications",
      "author" : [ "R.J. Larsen", "M.L. Marx" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1986
    }, {
      "title" : "Main-memory triangle computations for very large (sparse (power-law)) graphs",
      "author" : [ "M. Latapy" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2008
    }, {
      "title" : "A symbolic representation of time series, with implications for streaming algorithms",
      "author" : [ "J. Lin", "E. Keogh", "S. Lonardi", "B. Chiu" ],
      "venue" : "In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "Liverac: interactive visual exploration of system management time-series data",
      "author" : [ "P. McLachlan", "T. Munzner", "E. Koutsofios", "S. North" ],
      "venue" : "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Time series classification using compression distance of recurrence plots",
      "author" : [ "D.F. Silva", "V. Souza", "M. De", "G.E. Batista" ],
      "venue" : "In Data Mining (ICDM),",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "Imaging time-series to improve classification and imputation",
      "author" : [ "Z. Wang", "T. Oates" ],
      "venue" : "In Twenty-Fourth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2015
    }, {
      "title" : "Adopting robustness and optimality in fitting and learning",
      "author" : [ "Z. Wang", "T. Oates", "J. Lo" ],
      "venue" : "arXiv preprint arXiv:1510.03826,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Semi-supervised time series classification",
      "author" : [ "L. Wei", "E. Keogh" ],
      "venue" : "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The line graph is widely used [9, 14].",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "The line graph is widely used [9, 14].",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 9,
      "context" : "Pixel plot is explored to represent a time-series as an arrangement of pixels encoded with different hues which encode the underlying data [10, 5].",
      "startOffset" : 139,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "Pixel plot is explored to represent a time-series as an arrangement of pixels encoded with different hues which encode the underlying data [10, 5].",
      "startOffset" : 139,
      "endOffset" : 146
    }, {
      "referenceID" : 5,
      "context" : "[6] proposes an early importance driven layout scheme.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] presents a multi-focus zooming approach which maintains context and temporal distance zooming.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] compares stack zooming against standard techniques for navigation of temporal data.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "Recurrence Networks were proposed to analyze the structural properties of time series from complex systems [4].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 14,
      "context" : "[15] extended the recurrence plot paradigm for time series classification using compression distance.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "Another way to build a weighted adjacency matrix is to model the temporal-spatial transition dynamics with first order Markov matrix [3].",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 15,
      "context" : "[16] proposed a novel encoding framework to transform time series to images as the input for deep convolution neural networks and achieved state-of-the-art classification performance.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "This framework is similar to [3] for encoding dynamical transition statistics.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 12,
      "context" : "In [13], a different quantization approach is proposed.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "Based on the empirical observation that normalized time series has a Gaussian distribution [11], it is desirable to have a discretization technique that will produce bins with equiprobability.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 1,
      "context" : "To verify the modules and distinct patterns, we also figure out the modularity label and the clustering coefficient [2, 12] for each vertex and map them back to the original time series.",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 11,
      "context" : "To verify the modules and distinct patterns, we also figure out the modularity label and the clustering coefficient [2, 12] for each vertex and map them back to the original time series.",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 16,
      "context" : "We test our visualization approach on three typical compound functions [17] with different types of outliers to see if we can identify the outliers by the graph and network statistics.",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 0,
      "context" : "f1(x) = { 0 if x ∈ [0,1] ⋃ [3.",
      "startOffset" : 19,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : "Where x ∈ X = [0,1], g is defined as",
      "startOffset" : 14,
      "endOffset" : 19
    }, {
      "referenceID" : 17,
      "context" : "Our final experiment is to identify the class labels on three real time series dataset: ECG, Wafer and Gun Point [18].",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 0,
      "context" : "Table 2 summarizes some common network statistics on all of our experimental datasets [1].",
      "startOffset" : 86,
      "endOffset" : 89
    } ],
    "year" : 2017,
    "abstractText" : "Time series is attracting more attention across statistics, machine learning and pattern recognition as it appears widely in both industry and academia, but few advances has been achieved in effective time series visualization due to its temporal dimensionality and complex dynamics. Inspired by recent effort on using network metrics to characterize time series for classification, we present an approach to visualize time series as complex networks based on first order Markov process and temporal ordering. Different to classical bar charts, line plots and other statistics based graph, our approach delivers more intuitive visualization that better preserves both the temporal dependency and frequency structures. It provides a natural inverse operation to map the graph back to time series, making it possible to use graph statistics to characterize time series for better visual exploration and statistical analysis. Our experimental results suggest the effectiveness on various tasks such as system identification, classification and anomaly detection on both synthetic and the real time series data.",
    "creator" : "LaTeX with hyperref package"
  }
}