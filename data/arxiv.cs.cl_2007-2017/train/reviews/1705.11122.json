{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Controllable Invariance through Adversarial Feature Learning", "abstract": "Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data, leading to better generalization. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved test performance.", "histories": [["v1", "Wed, 31 May 2017 14:57:33 GMT  (1664kb,D)", "http://arxiv.org/abs/1705.11122v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL", "authors": ["qizhe xie", "zihang dai", "yulun du", "eduard hovy", "graham neubig"], "accepted": false, "id": "1705.11122"}
