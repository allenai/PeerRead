{
  "name" : "1301.7403.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Multivariate Discretization Method for Learning Bayesian Networks from Mixed Data",
    "authors" : [ "Stefano Montit" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this paper we address the problem of discretization in the context of learning Bayesian networks (BNs) from data con taining both continuous and discrete vari ables. We describe a new technique for multivariate discretization, whereby each continuous variable is discretized while tak ing into account its interaction with the other variables. The technique is based on the use of a Bayesian scoring metric that scores the discretization policy for a con tinuous variable given a BN structure and the observed data. Since the metric is rel ative to the BN structure currently being evaluated, the discretization of a variable needs to be dynamically adjusted as the BN structure changes.\n1 Introduction\nIn most approaches to learning Bayesian networks (BNs) from data, simplifying assumptions are made to circumvent practical problems in the implementa tion of the theory. One common assumption is that all variables are discrete [3, 7], or that all variables are continuous and normally distributed [6]. This is often too restrictive an assumption, since most real world domains are best described by a combination of continuous and discrete attributes (mixed data).\nA possible solution around this limitation is to dis cretize the continuous variables, so as to be able to apply one of the well established techniques for learning BNs containing discrete variables only. The alternative is the direct modeling of the continuous data as such. However, when the direct modeling is based on a limited set of families of probability den-\nsities, it can fail to capture the nature of the inter action between the continuous variables. The adop tion of a more general parametric representation is marred by a often prohibitive computational cost. In these cases, discretization can actually be preferable, and some empirical evidence supports this conclu sion [4, 12]. One of the appeals of this method is that discretization can be interpreted as a form of non parametric density estimation (14]. An additional advantage of this approach is its relative simplicity. However, discretization can in general generate spu rious dependencies among variables, especially dis cretization strategies that deal with the single vari ables individually, without considering their inter action with other variables. We refer to this class of discretization strategies as univariate discretiza tion, to distinguish it from multivariate discretiza tion, whereby each variable is discretized taking into account its interaction with the other variables.\nThe majority of the discretization techniques cur rently available are devised with a classification task in mind. In current state-of-the-art discretization methods for classification, the search for the best discretization of a given feature variable is carried out by at most considering its interaction with the class variable of interest, while ignoring possible in teractions with other feature variables [4]. For the reasons previously outlined, this approach does not seem appropriate for learning BNs, where modeling the interaction among all variables often is of pri mary importance, when for example the goal of the learning task is to gain insight into the causal or probabilistic dependencies that exist among the do main variables. Very few multivariate discretization strategies have been proposed in machine learning [2], and to our knowledge there is only one example of multivariate discretization strategy tailored to the needs of BN learning [5].\nSimilar to the approach proposed in [5], we describe a technique for multivariate discretization where each continuous variable is discretized by taking into consideration its interaction with the other variables. The technique is based on the use of a Bayesian scoring metric that scores the discretization policy of a continuous variable given the BN structure. In order to define the scoring metric according to the Bayesian paradigm, we make the discretization strategy part of the model generating the observed data. That is, we assume that there is an underly ing discrete mechanism governing the behavior of the observed continuous variables. This framing of the discretization problem allows for the natural specifi cation of a Bayesian scoring metric for discretiza tion, defined to be the posterior probability of a discretization policy, given a BN structure and the data.\nSince the proposed scoring metric for discretization is dependent on the BN structure currently searched, the discretization of a variable needs to be dynam ically adjusted as the BN structure changes. The dependence of one variable's discretization on the other variables in the BN implies that the effects of the discretization will possibly propagate through out the network.\nThe derived Bayesian scoring metric shares many of the properties of the scoring metric described in [5], which is based on the MDL principle. The adop tion of the Bayesian paradigm, however, forces us to make explicit many modeling assumptions that could be left implicit in the MDL-based approach, and it provides for a possible semantics of the dis cretization process.\nThe remainder of this paper is organized as follows. In Section 2, we briefly introduce the Bayesian net work formalism, and a particular method for learn ing BNs from data containing discrete variables only. In Section 3, we describe our approach to discretiza tion. We first introduce it in the context of discretiz ing a single variable (univariate discretization). We then generalize it to the multivariate case. Finally, Section 4 lists a set of issues for future research.\n2 Notation and background\nIn this section, we very briefly introduce the Bayesian network formalism. This is by no means a comprehensive introduction to the topic, and its main purpose is to establish some common notation, and to frame the research issue which is the focus of this paper.\nBayesian Multivariate Discretization 405\nIn general, we denote random variables with upper case letters, such as X, Y , and their instantiation or realization with the corresponding lower case let ters, x, y, or x<l), y(l), where we use the latter no tation when we need to distinguish between differ ent instantiations. Similarly, we denote random vec tors with bold upper case letters, such as V, W, and their instantiation or realization with the corre sponding bold lower case letters, v, w. Given a do main of interest, we denote with X= {X1, ... ,Xn} the complete set of variables in that domain, and with x or x<l) the full instantiations of the variables in X. Marginal and conditional probabilities over arbi trary subsets Y and Z of X will be denoted with p(Y) and p(Y I Z) respectively, and they denote ei ther a probability density or a probability mass, de pending on whether the variables involved are con tinuous or discrete.\n2.1 Bayesian networks\nA Bayesian network B is defined by a pair (S, es) , where S = (X,E) is a directed acyclic graph (DAG) with set of nodes X, and with a set of arcs E = {(Xi,Xj) I xi,Xj E X, xi =f. Xj} rep resenting probabilistic dependencies among domain variables1. e 8 represents the parameterization of a probability measure p defined over the space of pos sible instantiations of X. Given a node Xi E X, we use Pai to denote the set of parents of Xi inS. The essential property of BNs is summarized by the Markov property, which asserts that each variable is independent of its non-descendants given its parents [13]. This property allows for the representation of the multivariate joint probability distribution over X in terms of the univariate conditional distribu tions p(Xi I Pai, es) of each variable xi given its parents Pai. Application of the chain rule, together with the Markov property, yields the following fac torization of the joint probability of any particular instantiation x of all n variables:\nn p(x) = p(xl, ... ,xn) = IIp(xi I pai , es) . (1)\ni=l The complete set of conditional independence asser tions implied by a network structure can be deter mined by means of the concept of d-separation, a graphical characterization introduced by Pearl [13). Using the concept of d-separation, it is also possi ble to show that a BN variable, conditioned on the\n1 In this paper, we make no distinction between the network nodes and the variables they represent.\n406 Monti and Cooper\nset of nodes containing its parents, its children, and its children's parents, is independent of all the other variables in the network. This set of nodes is called the Markov blanket of the variable.\n2.2 Learning Bayesian networks: A Bayesian approach\nThe task of learning BNs involves learning the net work structure and learning the parameters of the conditional probability distributions. A well estab lished set of leaming methods is based on the defi nition of a scoring metric measuring the fitness of a network structure to the data, and on the search for high-scoring network structures based on the defined scoring metric [3, 7, 9]. In a Bayesian framework, ideally classification and prediction would be performed by taking a weighted average over the inferences of every possible BN con taining the domain variables. Since this method is in general computationally infeasible, often an at tempt has been made to use a high scoring BN for classification and prediction. The latter approach is also preferable when the goal of the learning task is to gain insight into the causal or statistical depen dencies that may exist among the domain variables. We will assume the use of this approach in the re mainder of this paper.\nThe basic idea of the Bayesian approach is to max imize the probability p(S I 'D) = p(S, V) j p(D) of a network structure S given a database of cases V, and a set of assumptions and priors that we leave implicit. Because for all network structures the term p(V) is the same, for the purpose of model selection it suffices to calculate p(S, V) = p(V I S)p(S). The term p(S) is the prior probability of the struc ture S, and needs to be given as input. The term p(V I S) is the marginal likelihood, also called the evidence, and it measures how well the given struc tures fits the data.\nThe computation of the marginal likelihood involves the evaluation of a high-dimensional integral. The analytical evaluation of this integral has been de veloped for the cases when all variables in X are discrete, [3, 7] or all the variables are continuous and normally distributed [6]. In the general case however, and in particular when dealing with data containing both continuous and discrete variables, it is unlikely that analytic evaluation of the term p(V I S) is feasible, and approximations would need to be used (1]. 2\n2 A notable exception is the Conditional Gaussian\nA relatively simple alternative is to discretize the continuous data, so as to be able to apply one of the scoring metrics available for discrete domains. This is the approach investigated in this paper, and the remainder of this section is devoted to the de scription of the Bayesian scoring metric for discrete domains upon which our discretization strategy is built. To simplify exposition, in the remainder of this paper we will assume a uniform prior p(S) over the space of BN structures.\n2.2.1 A Bayesian scoring metric for discrete domains\nFor each variable Xi E X, let ri indicate the number of values Xi can take, and let qi indicate the number of distinct values its parent set Pai can take. With these notational conventions, let the set of parame ters es be decomposable as:\n=\n= {01, . . . , On} {oil, . . . , oiq.}, {Oi j1, . . . , ei irJ, i = 1, . . . , n (2) j = 1, 0 . 0 , qi ·\nAs it should be clear from the definition of a BN, for each node Xi, the vector Oi is the set of pa rameters necessary to fully characterize the con ditional probability distribution p(Xi I Pai) · Ac cordingly, the parameter set oi j specifies the dis tribution of xi conditioned on the j-th instantia tion of the parent set Pai. Finally, the parameter eijk = p(Xi = k I Pai = j) specifies the probability of observing the k-th value of xi conditioned on the observation of the j-th value of Pai.\nGiven the above decomposition of the parameter vector 0 s, if we further assume Dirichlet priors over 0s, of the form Oii \"'Dirichlet(aii1, . . . , aiirJ, for all Xi's and for all instantiations ofPai, then we can factorize the prior probability of the parameter set es as follows:\nn qi Ti p(Gs IS) ex: II II II e�·t-1 .\ni=1 j=l k=1 (3)\nThe assumption of Dirichlet priors is a strong but very convenient assumption, since it implies strong assumptions of parameter independence within the set 0s, as is evident from the form of Equation (3).3 Under the assumptions just described, and provided\nmodel introduced by Lauritzen in (11], whereby a mix ture of continuous and discrete variables is modeled by assuming that each continuous variable has no discrete descendants.\n3In [7) it is shown that there is a close relationship between these assumptions and a Dirichlet prior for 8s.\nD has no missing data, the likelihood p(D I S) can be evaluated analytically, and, expressed in log terms, it has the following form:\nlog p(V IS)\n+\nn L Sd(Xi, Pai; D), (4) i=1\nwhere r(.) is the Gamma function4' and CXij = Lk aijk, with the CXijk as part of the Dirichlet prior specification. Also, N;jk is the number of cases in D where the variable Xi = k, and the parent set\nPai = j, and N;j is the number of cases in D where Xi's parent set Pai takes its j-th value, irrespective of the value of Xi [3, 7]. In Equation (4), we use the term Sd(Xi,Pai;D) to denote the group of terms between square brackets. This notation clearly shows the decomposability of the likelihood term, in that the overall score is given by a sum of terms Sd(Xi, Pai; D), each measuring the contribution of a node and its parents. The sub script din sd is to emphasize that the score is defined over discrete variables only. This qualification will become relevant in the next section, where the score defined here will be one of the building blocks for our discretization strategy.\n3 Bayesian discretization\nThe discretization of a continuous variable can be interpreted as the selection of the number of values the discretized variable should take, as well as of the thresholds in the continuous range of the continu ous variable that delimit the intervals to be mapped into the values of the discretized variable. Given a dataset D, the number of values the discretized variable can take is upper-bounded by the cardinal ity N of D. Furthermore, as candidate thresholds for the partition of the continuous range of a contin uous variable, we only consider the (at most) N- 1 mid-points between contiguous data points in D. Let Ax; = {ri, �xJ be a discretization policy for the continuous variable Xi, where ri ;::: 2 is the num ber of categories used in the discretization of xi, and �x. = {Jil, . . . , 8ir;-d is the set of thresholds in the\n4For an integer value n > 0, the Gamma function corresponds to the factorial function offset by one, i.e., r(n+l) =n!.\nBayesian Multivariate Discretization 407\nvalue range of Xi delimiting these categories. 5 We denote with Yi the discretized variable correspond ing to Xi, taking values {y[ , ... , y[' }. Variable Yi's relationship to Xi is fully specified by the mapping Yi = y(Xi)A (the subscript A in y(xi)A will often be dropped as the discretization policy used will be clear from the context), defined as:\nif xi::;J1, if xi> 8r;-l if Jk-1 < X; :::;; 8k,\nk = 2, . . . , r; - 1 . (5)\nWe denote the interval (Jik-1, 8ik] with [yf], with the boundary cases to be interpreted as [y}] = ( -oo, 8;1] and [y[;] = (8ir;-u +oo). Finally, we denote with A= {A1, ... , An} the discretization policy for the whole set of continuous variable in X, and with y(X)A = {y(Xl)A1, • • • , y(Xn)An} the discretization of all the variables in X according to the discretiza tion policy A. To simplify exposition, we consider a discretization policy over the whole set X, and we assume the trivial discretization y(X;) =X; for each discrete variable X; in X.\nThe specification of a discretization strategy in volves the definition of a scoring metric S(A; D, S), which scores a discretization policy with respect to a database D and a BN structure S, and the definition of a search algorithm to search for the discretization policy that maximizes the given scoring metric. 6\nOur approach to the specification of a multivariate discretization strategy is based on a problem trans formation, whereby we suppose that each of the con tinuous variables in the domain of interest is a noisy observation of an underlying discrete variable. The problem of finding a \"good\" discretization is thus translated into the problem of finding a set of dis crete variables, and their (probabilistic) mapping into the corresponding continuous variables, that best account for the observed interactions between the continuous variables.\nIn the remainder of this section, we show that this framing of the discretization problem allows for the natural specification of a Bayesian scoring metric for discretization policies. We first illustrate our ap proach when applied to a single variable. We then generalize it to the multivariate case.\n5These thresholds are such that 6il < . .. < 6ir;-l· 6In keeping with the usual notation for score func tions, we denote a generic scoring metric with S(a;/3) where the left parameter(s) a is the parameter with re spect to which we want to maximize the score, while the right parameter{s) (3 is kept constant.\n408 Monti and Cooper\n3.1 Univariate Bayesian discretization\nIn the univariate case, we have X = {X}, with X a continuous variable, and the dataset D = x = {x(l ), . . ,x<N}}. As previously pointed out, the pur pose of the discretization is the computation of the marginal likelihood p(x IS). Conditioning on S is in this case superfluous, since we are dealing with a one-variable BN, therefore p(x IS)= p(x).\nAs informally outlined in the previous section, the problem of scoring a given discretization policy can be formalized by assuming that the mechanism by which the data x was generated by the environment involves a discrete variable. More specifically, we assume that the density of the observed continu ous variable X is governed by an underlying discrete variable Y , whose relationship to X is fully specified by the (unknown) discretization policy A, and the (unknown) A-induced conditional density function p(X I Y, A, fh). We assume that Y follows a multino mial distribution with a Dirichlet prior of the form described in Section 2.2.1 . Furthermore, although the parameters (}A of the conditional density func tion p(X I Y, A,OA) will be in general unknown, we restrict its general form to be as shown in Table 1, where 1o is the indicator function (i.e., 1{cond} = 1, if cond holds, 0 otherwise), and it is used to bound the support of the density to be within the appro priate interval.\nWe further assume that all the probability compo nents are of the same parametric form and that the corresponding parameters are independent, that is, that the prior p(OA) can be factorized as p(OA) = TI�=l p(OAk)· To fully specify a probabilistic model, we also need to give a probabilistic meaning to a discretization policy A. To this end, and to simplify notation, we use A to denote both the discretization policy and the corresponding hypothesis that A is the discretiza tion policy according to which the data x were gen erated. Furthermore, we assume that all the possible discretization policies of the form A represent a mu-\ntually exclusive and exhaustive set of hypotheses.7 This allows for the specification of a prior proba bility p(A) over the space of possible discretization policies {A}. Based on this conceptualization of the discretization problem, we now show that an appropriate score S(A; D) for a discretization policy A with respect to the data D is given by the (logarithm of) the pos terior probability of A given the data D. In fact, we can rewrite the marginal likelihood p(x) by making explicit its dependency on Y and A,\np(x) = L L p(x I y, A)p(y I A)p(A) A y\n= L p(x I y(x), A)p(y(x) I A)p(A) A\nL p(x I A)p(A) , A\n(6)\nwhere the elimination of the summation over y is possible because of the particular nature of the prob ability function p(X I Y, A), which assigns probabil ity zero whenever.y :/; y(x). From Equation (u), we see that a possible solution to its computation is to sample from the A space a given number of data points, and use model aver aging to approximate the likelihood. Alternatively, application of the maximum a posteriori (MAP), also known as plug-in, approximation to solve Equa tion (6) yields\np(x) � p(x I A)= p(x I y(x), A)p(y(x) I A) , (7) where A is the posterior mode of A, i.e., A = argmaxA[p(A I x)]. The selection of a discretiza tion policy is thus reduced to the problem of find ing the discretization policy that maximizes the posterior probability p(A I x) or, given the propor tionality p(A I x) <X p(x, A), the discretization pol icy that maximizes the joint probability p(x, A) = p(x I A)p(A). Furthermore, if we assume a uniform prior probability p(A), the problem reduces to max imum likelihood estimation, i.e., to the search for the discretization policy that maximizes the like lihood p(x I A) or, equivalently, the log-likelihood logp(x I A).\nThe computation of p(y(x) I A) in Equation (7) is straightforward. Based on the previously made as sumption that y(x) is a multinomial sample with Dirichlet prior, we notice that logp(y(x) I A) is a\n7Provided we consider as discretization thresholds only the mid-points between the data points in x, this set . . . \"'N-1 (N-1) 2(N-1) is finite, and 1t has cardmahty L.,1=1 1 = ·\nspecial case of the log-likelihood of Equation (4). In this case, we have a one-variable BN, given by the variable Y with an empty parent set. We can thus apply the result established in Equation (4) to the computation of logp(y(x) I A) to obtain\nlogp(y(x) I A)= Sd(Y, 0, A; V) =\nlog r(a) + � l r(ak + Nk) (8) r(a + N) � og r(ak) '\nwhere Nk denotes the number of cases with y(X) = yk, the ak 's are part of the prior specifica tion of Oy, and a= Lk ak. Notice that in a slight change of notation from Section 2.2. 1, we have here made explicit the dependency on A in Sd(Y, 0, A; V). The dependency of the above expression on the dis cretization policy A is through the sufficient statis tics Nk, whose value depends on how the continuous range of X is partitioned by A. For the computation of the term p(x I y(x), A) of Equation (7), we need to specify the parametric form of the conditional density p(X I Y, A). A convenient choice is to assume that within each interval [yk], the values of X are distributed uniformly, i.e.,\n( k dx p X I Y 'A) = Ok - Ok-l 1{xE[yk]} := Pk ' (9)\nwhere Pk is a constant for any given A. Notice that the above distribution is not normalizable for the boundary cases corresponding to the intervals [y1] and [yr]. We can easily solve this problem by using the smallest value of X in the dataset as a lower bound for the interval [y1], and the largest value of X in the dataset as an upper-bound for the interval [yr]. Alternatively, for those variables whose domain is known to be bound above and below (a situation frequently occurring, e.g., with variables measuring medical findings) , we can use these domain-specific bounds to delimit the two intervals [y1] and [yr]. The use of the uniform distribution considerably simplifies the computation of p(xly(x),A)., since the probability of each case x<ll is only depen dent on y(x(ll). In fact, if we denote with x1 = { x(ll, ... , x(l-l)} the set of the first l- 1 cases in x, we can rewrite p(x I y(x), A) as follows:\nN p(xly(x),A) = ITp(x<ll ly(x(ll),xz,y(x1),A)\nl=l N r\n= IT p(x(l) I y(x(l) ), A) = IT pfk, (10) l=l k=l\nw�ch, in log terms, yields logp(xly(x),A) = Lk=l Nk logpk = Sc(X, Y,A;V).\nBayesian Multivariate Discretization 409\nTo summarize, under the assumption of a uniform prior p(A), we define the scoring metric for a univari ate discretization policy A, given the data V = x as\nS(A; V) = Sd(Y, 0, A; V) + Sc(X, Y, A; V), (11) where we refer to the term Sd(Y, 0, A; V) of Equa tion (8), as the discrete component of the score, and to the term Sc(X, Y, A; V) of Equation (10), as the continuous component of the score.\nThe continuous and the discrete components in Equation (11) play complementary roles in the de termination of the score of a given discretization policy. On the one hand, the continuous compo nent rewards prediction accuracy with respect to the continuous variable (i.e., it measures how well the discretized data predict the original non-disct\"etized data) . It also rewards model complexity. This should be clear by looking at Equation (10), where we expressed the continuous component of the score as a function of the Pk 's, the parameters specifying the uniform density. As the width of an interval [yk] becomes smaller, the corresponding Pk increases, thus increasing the probability of any given point x in that interval. As a consequence, everything else being equal, increasing the number r of partition of a variable will in general increase the continuous component of the corresponding score, which could lead to overfitting the data. On the other hand, the discrete component penalizes model complexity. In fact, this component measures the likelihood of the discretized data, and this increases as we decrease the number of values of the discretized variable. In the limit case of a one-value variable, the discrete component will be highest, since that one value will always have probability 1 (with reference to Equa tion (8), for r = 1 the discrete component of the score takes the maximum attainable value of 0, since Nk = N, and the two terms of the sum cancel out) . As a result, the scoring metric of Equation (11) tries to establish a trade-off between model accuracy and model complexity.\n3.1.1 Choice of the conditional density\nIn the previous section, we used the uniform distri bution for the conditional density p(X I Y, A) of a continuous variable X given its discretized counter part Y. Choices other than the uniform distribution are possible. However, the resulting conditional like lihood p(x I y(x), A) would not have as simple a form (because of the indicator function in Table 1 the ' given distribution would be truncated) . Parametric distributions belonging to the exponential family seem to be the best choice in light of the fact that\n410 Monti and Cooper\nthey allow for the analytical computation of the rel evant statistics.\nThe discretization metric described above can be applied to the case where we want to \"discretize\" an already discrete variable, by grouping together subsets of its values, a transformation more appro priately characterized as abstraction. In this case, an appropriate choice would be to model the condi tional p(X I Y, A) as a multinomial distribution with a Dirichlet prior, which would result in a continuous component of the score having the same form as the discrete component of the score.\nWe can use the multinomial distribution as a proxy for the conditional density also in those cases when X is continuous. Provided we choose a uniform prior, the resulting density would \"default\" to a uni form distribution in those cases where a given inter val contains datapoints that are all distinct. How ever, in those intervals with repetitions, the condi tional distribution would give higher probability to the repeated values. This is very similar to the con ditional distribution implied by the MDL-metric de scribed in [5]. In fact, in a MLD framework, each continuous value within a given interval is assigned a Huffman code whose length is inversely proportional to the frequency of occurrence of that value within the interval. This code is approximately equal to - log fx, where fx is the frequency of occurrence of the value x. When there are no repetitions within an interval, each value is assigned an equal length code, which corresponds to assuming a uniform dis tribution within that interval.\n3.1.2 Choice of the prior probability\nIn this section, we briefly explore the use of informa tive priors for p(A), and how these could be specified. As previously illustrated, the discretization of a sin gle variable X is defined as A= {r, Llx }, with r the number of categories ofY = y(X), and Llx the set of cut points in the continuous domain of X. A natural way of factorizing the prior p{Ax) is thus in terms of its components, that is, p(Ax) = p(Llx I r)p(r). An informative prior over r is relatively simple to specify. For example, we might model p(r) as a trun cated Poisson distribution (truncated above at N -1, where N is the number of cases in the database), with mean >., 2 :S >. :S N - 1. The Poisson distri bution is a sensible choice in light of the fact that it penalizes large values of r, which would tend to be favored if we based our selection on the likelihood term p(x I A) only. Given r, a uniform prior probability p(Llx I r) could\nbe assumed. Alternatively an informative prior could be defined based on the definition of a \"base line\" discretization, and of a \"distance\" metric mea suring the difference of a given discretization from this baseline. The baseline could be based on sim ple discretization method (e.g., equal bin discretiza tion), or it could be provided by a domain expert.\n3.2 Multivariate Bayesian discretization\nWe can generalize the approach illustrated in the previous section to the multivariate case, where X= {Xl> . .. , Xn}, with n > 1. As in the uni variate case, we assume the existence of an un derlying discrete mechanism that governs the be havior of the observed continuous variables in X. That is, we assume the existence of a set of dis crete variables Y = {Yi, . . . , Yn}, where each vari able Yi governs the behavior of the correspond ing continuous variable Xi, and that the relation ship between each Xi and the corresponding Yi is fully specified by the discretization policy A = { A1. . . . , An} and the set of A-induced conditional densities {p(Xi I Yi, Ai, S) h=l, .. . ,n· Notice that in this case the conditioning on S cannot be ignored. In fact, to complete the specification of the discrete mechanism, we further assume that the probabilistic dependencies over X implied by the structure S are in fact probabilistic dependencies over the discrete variables Y which are manifested over X when the variables in Y are marginalized out. This assump tion corresponds to transforming the BN structure\nS into a structure S' augmented with the variables in Y, such that each continuous variable Xi in S' has Yi = y(Xi) as its unique parent, and the parent set of Yi inS' contains }j = y(Xi) if and only if Xi is a parent of Xi in S. In graphical terms, the in troduction of the discrete variables Y corresponds to the transformation shown in Figure 1. Notice that an immediate consequence of this transformation is that a continuous variable xi is independent of its parents Pai given its corresponding discretized vari able Yi, i.e., VXi EX,\nEquation (12) simply asserts that the discretized value of a variable Xi is all we need to know to com pute the probability of its non-discretized value. An important consequence of this result is that the con ditional probability of a complete case x given its discretization y(x) is decomposable as follows:\np(x I y(x), A)= IT p(xi I y(xi), A). (13) X; EX\nBased on Equation (13), on the application of the Markov property (as defined in Equation (1), Section 2.1), and on the assumption that the prior p(A IS) is decomposable, i.e., p(A IS) = fl p(Ai IS), we can factorize the joint probability of a case x as follows:\np(x I A)= [ IT p(xi I y(xi), Ai)l x X;EX\n[ IT p(y(xi) I y(pai), Ai)] . (14) X; EX\nFrom Equation (14), we can see that the joint probability of a database case x containing both continuous and discrete variables can be factor ized as a product of terms containing discrete variables only (i.e., the product over the terms p(y(xi) I y(pai), Ai)) times a product of terms con taining continuous variables only (i.e., the product over the terms p(xi I y(xi) , Ai)). We thus have all the ingredients for the definition of the scoring metric of a multivariate discretiza tion policy A, given a BN structure S and database V. Analogously to the univariate case, under the assumption of a uninformative prior, this metric is taken to be the log-likelihood log p(V I A, S) of the data given the discretization policy A, and the BN structure S (if we use an informative prior, we just need to add the extra term logp(A)).\nThe metric can be computed as follows. Let Ai = {Ai} U {Aj : Xi E Pai} be the set of discretiza tion policies for Xi and its parent set Pai. Also, let y(Pai) denote the set of discrete variables asso ciated with the continuous variables in Pai. Finally, let Vt = { x(ll, . . . , x(l-l)} be the set of first l - 1 cases in the database TJ. Then, the scoring metric for multivariate discretization S(A; V, S) can be de-\nfined as n\nS(A; V, S) = L Sc(Xi, y(Xi), Ai; V) + i=l\nn\n+ L Sd(y(Xi), y(Pai), Ai; V). (15) i=l\nThe terms Sc(Xi, y(Xi), Ai; V) in Equation (15) are the continuous components of the score, and under the assumption of a uniform distribution for the con ditional densities p(Xi I y(Xi), Ai), they are defined as shown in Equation (10).\nThe terms Sd(y(Xi), y(Pai), Ai; V) in Equation (15) are the discrete components of the score, and they are defined as the analogous terms Sd(Xi, Pai; TJ) of Equation (4), which were based on the variables Xi and Pai being discrete. With regard to the discrete components, it is impor tant to emphasize the dependency on Ai of each dis crete component Sd(y(Xi), y(Pai), Ai; TJ). This de pendency is manifested through the sufficient statis tics Nii and Nijk, which are now based on dis cretized variables. As such, they are dependent on the discretization policy. More importantly, the suf ficient statistics for a given Sd(y(Xi), y(Pai), Ai; V) term depend on the discretization policy of xi as well as on the discretization policy of the variables in Pai. The immediate consequence of this depen dency is that when selecting the discretization pol icy Ai for a given variable Xi with respect to the BN structureS, we should aim to maximize the following local score:\nS(Ai; V, S) = Sc(Xi, y(Xi), Ai; V) + + Sd(y(Xi), y(Pai), Ai; TJ) (16) + L Sd(y(Xj),y(Pai),Ai; TJ),\nX;ECh;\n412 Monti and Cooper\nwhere Chi is the set of children of Xi. In fact, each of the Aj contains the discretization policy Ai. It follows that if we change Ai (i.e, if we change the discretization of Xi), besides recomput ing Sd(y(Xi), y(Pai), Ai; D), we also need to recom pute the term Sd(y(Xj),y(Paj),Aj; D) for each of the Xi (if any) having Xi among its parents, i.e., for each of the Xi in Chi. As previously indicated, not surprisingly this result agrees with the results de rived based on the MDL principle described in (5].\nA consequence of Equation (16) is that changing the discretization of a variable xi will possibly affect the discretization of all the other variables in the network which are not d-separated from xi either by the empty set, or by some d-separator contain ing discrete variables only (e.g., if the BN contains continuous variables only, the discretization of any variable will possibly affect the discretization of all the other variables in the network) .\n3.3 Searching the space of discretization policies\nPutting aside search strategies that search directly over the space of joint discretizations of all depen dent variables at once, the simplest search strategy is to start from some initial discretization of all vari ables. We then search for the maximum score dis cretization for each single variable while keeping the discretization of the other variables fixed. We re peat this process until the overall score does not im prove of a given amount (this is the search strategy adopted in (5]) .\nHere, we want to focus on a search strategy which is suggested by the similarity between the set of in dependency properties satisfied by the discretization score, and the probabilistic independencies implied by a BN structure. As outlined in the previous sec tion, the discretization of a variable xi is indepen dent of the discretization of a variable Xj, if the two variables are d-separated by the empty set or by a set containing discrete variables only. 8 It also follows that if we hold fixed the discretization of a variable d-separating Xi and Xi, the discretization of these two variables can be carried out independently of each other's.\nNotice that these are the same independence asser tions used in the definition of efficient exact algo rithms for BN inference. Based on these similarities, we can draw a natural correspondence between the\n8In this discussion, we refer to independence asser tions implied by the original structure S, not the aug mented structure S'.\nproblem of finding the most probable discretization of all the continuous variables in the BN and the problem of finding the most probable instantiation of all the variables of a BN. For this purpose, we need to replace the act of holding fixed the instan tiation of a :variable in the BN inference problem, with the act of holding fixed the discretization of a variable in the multivariate discretization problem. We can thus modify any of the available exact or approximate algorithms for BN inference that can return the most probable instantiation of the BN variables (e.g., (8, 10]), so as to have it return the most probable discretization instead.\nWhile the method outlined above allows for a more efficient search over the space of multivariate dis cretizations, exact computation (i.e., selection of the optimal discretization) often remains infeasible. In fact, since even in the univariate case searching for the optimal discretization has a complexity that is exponential in the number of data points, it is clear that the multivariate search outlined above still has to rely on some form of heuristic search when select ing the thresholds to be included in the discretiza tion of a given variable.\nAnother solution worth investigating is the appli cation of Monte Carlo techniques applied to Equa tion (6).\n4 Conclusions and future work\nWe have described a new approach to multivariate discretization that is specifically tailored to the task of learning Bayesian networks from data containing both continuous and discrete variables. The method is based on the specification of a Bayesian scoring metric for discretization policies. In order to derive the scoring metric, we have relied on a conceptual ization of the discretization problem in terms of the existence of an underlying discrete mechanism gov erning the behavior of the observed continuous vari ables. We want to emphasize here that, although there are real domains for which such an interpre tation could be entirely plausible,9 we are not sug gesting this model has causal plausibility in general. Rather, we view this conceptualization as the ba sis for an initial Bayesian analysis which is subject to modification based on future research. There are\n9 As an example, think of a radio dial, which is defined on a continuous range, but that works only for a finite number of frequencies. As the dial is moved from the \"right\" location, the reception degrades, until a latent thresholds is crossed, when the reception shift to another frequency.\nseveral issues that need to be further investigated. Extensive experimental evaluation need to be per formed, in order to assess the merits of the pro posed method. We are currently working on the im plementation of a search algorithm for the selection of a high-scoring discretization policy, based on the adaptation of the clique-tree propagation algorithm for BN inference [8) . Another important issue that needs to be addressed regards the specification of informative priors over the space of discretization policies {A}. We pointed out that the specification of such a prior could be useful to avoid attaining too finely grained a dis cretization, which would tend to be preferred over \"coarser\" discretizations if the selection was based solely on the data.\nAnother issue we consider worth exploring is the use of density functions other than the uniform for the specification of the conditional density p(X I Y, A). We believe a more informative density could yield more accurate discretizations.\nAcknowledgments\nWe thank Roger Day and the anonymous reviewers for their useful comments on a preliminary version of this manuscript. The research presented here was supported in part by grants BES-9315428 and IRl9509792 from the National Science Foundation and by grant LM05291-02 from the National Library of Medicine.\nReferences\n[1] D. M. Chickering and D. Heckerman. Efficient ap proximation for the marginal likelihood of incom plete data given a Bayesian network. In Proceedings of the 12-th Conference of Uncertainty in AI, 1996.\n[2] M. R. Chmielewski and J. W. Grzymala-Busse. Global discretization of continuous attributes as preprocessing for machine learning. International Journal of Approximate Reasoning, 15:319-331, 1996.\n[3] G. F. Cooper and E. Herskovits. A Bayesian method for the induction of probabilistic networks from data. Machine Learning, 9:309-347, 1992.\n[4] J. Dougherty, R. Kohavi, and M. Sahami. Super vised and unsupervized discretization of continuous features. In A. Prieditis and S. Russel, editors, Ma chine Learning: Proocedings of the 12th Interna tional Conference, San Francisco, CA, 1995. Mor gan Kaufmann.\n[5] N. Friedman and M. Goldszmidt. Discretization of continuous attributes while learning Bayesian net-\nBayesian Multivariate Discretization 413\nworks. In L. Saitta, editor, Proceedings of 13-th In ternational Conference on Machine Learning, pages 157-165, 1996.\n[6] D. Geiger and D. Heckerman. Learning Gaussian networks. In R. L. de Mantras and D. Poole, edi tors, Prooceedings of the 1Oth Conference of Uncer tainty in AI, San Francisco, California, 1994. Mor gan Kaufmann.\n[7] D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks: The combination of knowledge and statistical data. Machine Learning, 20:197-243, 1995.\n[8] F. Jensen, S. Lauritzen, and K. Olesen. Bayesian updating in causal probabilistic networks by local computation. Computational Statistics, 4:269-282, 1990.\n[9] W. Lam and F. Bacchus. Learning Bayesian belief networks- an approach based on the MDL princi ple. Computational Intelligence, 10( 4) , 1994.\n[10] S. Lauritzen and D. Spiegelhalter. Local computa tions with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society, 50:157-224, 1990.\n[11] S. L. Lauritzen. Mixed graphical association models (with discussion). Scandinavian Journal of Statis tics, 16:273-306, 1989.\n[12] S. Monti and G. F. Cooper. Learning hybrid Bayesian networks from data. In M. Jordan, ed itor, Learning and Inference in Graphical Models, New York, 1998. Springer Verlag.\n[13] J. Pearl. Probabilistic Reasoning in Intelligent Sys tems: Networks of Plausible Inference. Morgan Kaufman Publishers, Inc., 1988.\n[14] D. Scott. Multivariate Density Estimation, Theory, Practice, and Visualization. John Wiley & Sons, Inc., New York, 1992."
    } ],
    "references" : [ {
      "title" : "Efficient ap­ proximation for the marginal likelihood of incom­ plete data given a Bayesian network",
      "author" : [ "D.M. Chickering", "D. Heckerman" ],
      "venue" : "In Proceedings of the 12-th Conference of Uncertainty in AI,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1996
    }, {
      "title" : "Global discretization of continuous attributes as preprocessing for machine learning",
      "author" : [ "M.R. Chmielewski", "J.W. Grzymala-Busse" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1996
    }, {
      "title" : "A Bayesian method for the induction of probabilistic networks from data",
      "author" : [ "G.F. Cooper", "E. Herskovits" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1992
    }, {
      "title" : "Super­ vised and unsupervized discretization of continuous features",
      "author" : [ "J. Dougherty", "R. Kohavi", "M. Sahami" ],
      "venue" : "Ma­ chine Learning: Proocedings of the 12th Interna­ tional Conference,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1995
    }, {
      "title" : "Discretization of continuous attributes while learning Bayesian net-  Bayesian Multivariate Discretization 413 works",
      "author" : [ "N. Friedman", "M. Goldszmidt" ],
      "venue" : "Proceedings of 13-th In­ ternational Conference on Machine Learning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1996
    }, {
      "title" : "Learning Gaussian networks",
      "author" : [ "D. Geiger", "D. Heckerman" ],
      "venue" : "Prooceedings of the 1Oth Conference of Uncer­ tainty in AI,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1994
    }, {
      "title" : "Learning Bayesian networks: The combination of knowledge and statistical data",
      "author" : [ "D. Heckerman", "D. Geiger", "D.M. Chickering" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1995
    }, {
      "title" : "Bayesian updating in causal probabilistic networks by local computation",
      "author" : [ "F. Jensen", "S. Lauritzen", "K. Olesen" ],
      "venue" : "Computational Statistics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1990
    }, {
      "title" : "Learning Bayesian belief networks- an approach based on the MDL princi­ ple",
      "author" : [ "W. Lam", "F. Bacchus" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1994
    }, {
      "title" : "Local computa­ tions with probabilities on graphical structures and their application to expert systems",
      "author" : [ "S. Lauritzen", "D. Spiegelhalter" ],
      "venue" : "Journal of the Royal Statistical Society,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1990
    }, {
      "title" : "Mixed graphical association models (with discussion)",
      "author" : [ "S.L. Lauritzen" ],
      "venue" : "Scandinavian Journal of Statis­ tics,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1989
    }, {
      "title" : "Learning hybrid Bayesian networks from data",
      "author" : [ "S. Monti", "G.F. Cooper" ],
      "venue" : "ed­ itor, Learning and Inference in Graphical Models,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1998
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Sys­ tems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1988
    }, {
      "title" : "Multivariate Density Estimation, Theory, Practice, and Visualization",
      "author" : [ "D. Scott" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "One common assumption is that all variables are discrete [3, 7], or that all variables are continuous and normally distributed [6].",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 6,
      "context" : "One common assumption is that all variables are discrete [3, 7], or that all variables are continuous and normally distributed [6].",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 5,
      "context" : "One common assumption is that all variables are discrete [3, 7], or that all variables are continuous and normally distributed [6].",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 3,
      "context" : "In these cases, discretization can actually be preferable, and some empirical evidence supports this conclu­ sion [4, 12].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 11,
      "context" : "In these cases, discretization can actually be preferable, and some empirical evidence supports this conclu­ sion [4, 12].",
      "startOffset" : 114,
      "endOffset" : 121
    }, {
      "referenceID" : 3,
      "context" : "discretization of a given feature variable is carried out by at most considering its interaction with the class variable of interest, while ignoring possible in­ teractions with other feature variables [4].",
      "startOffset" : 202,
      "endOffset" : 205
    }, {
      "referenceID" : 1,
      "context" : "Very few multivariate discretization strategies have been proposed in machine learning [2], and to our knowledge there is only one example of multivariate discretization strategy tailored to the needs of BN learning [5].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 4,
      "context" : "Very few multivariate discretization strategies have been proposed in machine learning [2], and to our knowledge there is only one example of multivariate discretization strategy tailored to the needs of BN learning [5].",
      "startOffset" : 216,
      "endOffset" : 219
    }, {
      "referenceID" : 4,
      "context" : "Similar to the approach proposed in [5], we describe a technique for multivariate discretization where each continuous variable is discretized by taking into consideration its interaction with the other variables.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 4,
      "context" : "The derived Bayesian scoring metric shares many of the properties of the scoring metric described in [5], which is based on the MDL principle.",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 12,
      "context" : "The essential property of BNs is summarized by the Markov property, which asserts that each variable is independent of its non-descendants given its parents [13].",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 2,
      "context" : "high-scoring network structures based on the defined scoring metric [3, 7, 9].",
      "startOffset" : 68,
      "endOffset" : 77
    }, {
      "referenceID" : 6,
      "context" : "high-scoring network structures based on the defined scoring metric [3, 7, 9].",
      "startOffset" : 68,
      "endOffset" : 77
    }, {
      "referenceID" : 8,
      "context" : "high-scoring network structures based on the defined scoring metric [3, 7, 9].",
      "startOffset" : 68,
      "endOffset" : 77
    }, {
      "referenceID" : 2,
      "context" : "analytical evaluation of this integral has been de­ veloped for the cases when all variables in X are discrete, [3, 7] or all the variables are continuous and normally distributed [6].",
      "startOffset" : 112,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "analytical evaluation of this integral has been de­ veloped for the cases when all variables in X are discrete, [3, 7] or all the variables are continuous and normally distributed [6].",
      "startOffset" : 112,
      "endOffset" : 118
    }, {
      "referenceID" : 5,
      "context" : "analytical evaluation of this integral has been de­ veloped for the cases when all variables in X are discrete, [3, 7] or all the variables are continuous and normally distributed [6].",
      "startOffset" : 180,
      "endOffset" : 183
    }, {
      "referenceID" : 2,
      "context" : "Also, N;jk is the number of cases in D where the variable Xi = k, and the parent set Pai = j, and N;j is the number of cases in D where Xi's parent set Pai takes its j-th value, irrespective of the value of Xi [3, 7].",
      "startOffset" : 210,
      "endOffset" : 216
    }, {
      "referenceID" : 6,
      "context" : "Also, N;jk is the number of cases in D where the variable Xi = k, and the parent set Pai = j, and N;j is the number of cases in D where Xi's parent set Pai takes its j-th value, irrespective of the value of Xi [3, 7].",
      "startOffset" : 210,
      "endOffset" : 216
    }, {
      "referenceID" : 4,
      "context" : "ditional distribution implied by the MDL-metric de­ scribed in [5].",
      "startOffset" : 63,
      "endOffset" : 66
    } ],
    "year" : 2011,
    "abstractText" : "In this paper we address the problem of discretization in the context of learning Bayesian networks (BNs) from data con­ taining both continuous and discrete vari­ ables. We describe a new technique for multivariate discretization, whereby each continuous variable is discretized while tak­ ing into account its interaction with the other variables. The technique is based on the use of a Bayesian scoring metric that scores the discretization policy for a con­ tinuous variable given a BN structure and the observed data. Since the metric is rel­ ative to the BN structure currently being evaluated, the discretization of a variable needs to be dynamically adjusted as the BN structure changes.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}