{
  "name" : "1610.02213.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Challenges of Computational Processing of Code-Switching",
    "authors" : [ "Özlem Çetinoğlu", "Sarah Schulz", "Ngoc Thang Vu" ],
    "emails" : [ "ozlem@ims.uni-stuttgart.de", "schulzsh@ims.uni-stuttgart.de", "thangvu@ims.uni-stuttgart.de" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Data that includes mixing of two or more languages finds more place in the Natural Language Processing (NLP) tasks over the last few years. This changing picture induces its own challenges as well.\nThe analysis of mixed language is not a new field, and has been extensively studied from several sociological and linguistic aspects (Poplack, 1980; Myers-Scotton, 1993; Muysken, 2000; Auer and Wei, 2007; Bullock and Toribio, 2012). This has also brought different perspectives on the definition and types of mixed language. Switching between sentences (inter-sentential) is distinguished from switching inside of one sentence (intra-sentential). Poplack (1980) defines code-switching as ‘the alternation of two languages within a single discourse,\nsentence or constituent’. Muysken (2000) avoids this term arguing that it suggests alternation but not insertion, and prefers code-mixing for intrasentential switching. Myers-Scotton (1993) employs the cover term code-switching for the use of two languages in the same conversation, sentence, or phrase. In this paper we use code-switching (CS) as a cover term for all types of mixing. The terminology is still controversial among researchers, but there is no doubt that all types pose challenges for computational systems built with monolingual data.\nComputational approaches in the analysis of CS data are quite recent as compared to linguistic studies. The first theoretical framework to parse codeswitched sentences dates back to the early 1980s (Joshi, 1982), yet few studies are done in the 2000s (Goyal et al., 2003; Sinha and Thakur, 2005; Solorio and Liu, 2008a; Solorio and Liu, 2008b). With the beginning of the last decade, this picture has changed due to increasingly multi-cultural societies and the rise of social media. Supported with the introduction of annotated data sets on several language pairs, different tasks are applied on CS data.\nThe characteristics of mixed data affect tasks in different ways, sometimes changing the definition (e.g. in language identification, the shift from document-level to word-level), sometimes by creating new lexical and syntactic structures (e.g. mixed words that consist of morphemes from two different languages). Thus, it is clear that mixed data calls for dedicated tools tailored to the specific problems and contexts encountered. In order to take these specialties into account, these different cases have to be understood. This way, differences in techniques for\nar X\niv :1\n61 0.\n02 21\n3v 1\n[ cs\n.C L\n] 7\nO ct\n2 01\nmonolingual and mixed language processing can be unfolded to yield good results.\nIn this paper, we view CS processing from a variety of perspectives, and discuss the unique challenges that one encounters. We redescribe NLP tasks under the assumption that the data contains more than one language. For tasks that are studied more compared to others we compile approaches taken by previous work. Examples from different language pairs highlight the challenges, supporting the need for awareness about the nature of mixed data for successful automatic processing."
    }, {
      "heading" : "2 Data",
      "text" : "Nature of the data Annotated CS corpora, that are designed for computational purposes, center around three sources so far: spoken data (Solorio and Liu, 2008b; Lyu et al., 2015; Yılmaz et al., 2016), social media (Nguyen and Doğruöz, 2013; Barman et al., 2014; Vyas et al., 2014; Solorio et al., 2014; Choudhury et al., 2014; Jamatia et al., 2015; Çetinoğlu, 2016; Samih and Maier, 2016), and historical text (Schulz and Keller, 2016). All these data sources are challenging on their own even if they do not exhibit CS. They are non-canonical in their orthography, lexicon, and syntax, thus the existing resources and tools should be adapted, or new ones should be created to handle domain-specific issues in addition to the challenges of CS itself. Accessing the data Although CS is prominent in every day life, especially in countries with a high percentage of multilingual communities, accessing it is still problematic. Speech as one of the main sources requires consent prior to recording. One way to keep recordings as natural as possible is to not mention the goal as capturing CS instances to participants. Being recorded however raises selfawareness, and could possibly change how the language is used. Many bilinguals are not keen on mixing languages, e.g. human annotators comment “we shouldn’t code-switch” (Solorio and Liu, 2008a).\nOn this point, social media has an advantage: users of Facebook, Twitter, forums, or blogs, are not aware that their data will be used for analysis, which therefore makes it a more naturalistic setting. They give their consent after, once the content is created. Among social media sites, Twitter has its disadvan-\ntages like license issues, and limited characters per tweet. Other media that does not have these advantages remain popular sources."
    }, {
      "heading" : "3 Normalisation",
      "text" : "Text normalisation is the task of standardising text that deviates from some agreed-upon (or canonical) form. This can e.g. refer to normalising social media language to standard language (“newspaper language”) (cf. e.g. Schulz et al. (2016) and Aw et al. (2006)) or historical language to its modern form (Bollmann et al., 2011). Since mixed text often occurs in spoken language or text close in nature to spoken language like social media, normalisation is a highly relevant task for the processing of such text. In the case of mixed text there are two languages embedded into each other. Defining a canonical form is a challenge because each of the languages should be standardised to its own normal form.\nNormalisation of text has started out as a task mainly solved on token-level. Most of the recent approaches are based on context e.g. in characterbased machine translation (Liu et al., 2012; Schulz et al., 2016). This results from the fact that normalisation requires a certain degree of semantic disambiguation of words in context to determine if there is a normalisation problem. These problems can appear on two levels: a) The word is an out-ofvocabulary (OOV) word (which are the easy cases), thus it does not exist in the lexicon. b) The word is the wrong word in context (often just the wrong graphematic realisation e.g. tree instead of three).\nThis context dependency results in issues for mixed text. The presence of CS increases the number of possible actions regarding an erroneous word. The word could be incorrect in one language and not in the other, or incorrect in both. Either way, the intended language should be decided as well as the usage. (1) emphasises the need for semantic understanding in context (Çetinoğlu, 2016) in which Turkish (in italics) is mixed with German (in bold).\n(1) meisten Meis.Abl(TR)/mostly(DE) kıyımıza shore.P1pl.Dat\nvurmuş hit.EvidPast olmasi be.Inf muhtemel possible :)\n‘It is possible that it hit our shore from Meis.’/‘Mostly it is possible that it hit our shore.’\nThe first word in the example can be interpreted in two different ways. In Turkish it could be an orthographically incorrect form of Meis’ten ‘from Meis’ which refers to the Greek island Kastellorizo. Or it could be a typo where the s of German meistens ‘mostly’ is missing. Such uncertainty might be observed more when language pairs are from similar languages, and share identical and similar words.\nAnother example is taken from a corpus of Facebook chats (Androutsopoulos, 2015). In this example, three languages, Greek (in italics), German (in bold) and English, are used within one sentence:\n(2) hahahahaha hahahahaha ade come on(GR)/goodbye(DE)\nok okay(GR/DE/EN) tanz dance zebekiko zebekiko aber but bei on billy Billy jean Jean please please\n‘hahahahaha come on ok dance zebekiko but on Billy Jean please’\nAndroutsopoulos (2015) explains that the post starts with a bilingual discourse marker that indexes concessiveness (ade ok ‘come on, ok’). The Greek vernacular item ade is combined with ok, which could be assigned to any of the three languages whereas the preceding hahahahaha is not a word in any of them. Ade ‘goodbye’, however, is an existing German word and without larger context of the sentence it is hard to determine if the German Ade is intended, in which case a normalisation action (capitalisation) is required, or indeed the Greek vernacular ade. Semantic contextualisation is aggravated due to the trilingual context.\nOne solution is the approach by Zhang et al. (2014). They use a neural net based translation architecture for Chinese-English text normalisation. It includes a Chinese language model and a ChineseEnglish translation model as well as user historybased context. Since training material for such systems might be sparse for some language pairs, methods for mixed text tend to return to smaller context windows as done by Dutta et al. (2015). They suggest to use two monolingual language models with context windows depending on the neighbouring words using language identification information. In case of a high density of switch points between languages, the context window might be small.\nAs another normalisation challenge, Kaur and Singh (2015) describe issues emerging from mixing different scripts in Punjabi-English and Sarkar (2016) for Hindi-English and Bengali-English social media text. Since text is often realised in Roman script, in order to utilise resources from other writing systems, the text has to be mapped back to the system of the respective language. Due to this problem Barman et al. (2014) do not use existing Bengali and Hindi resources in their dictionary-based approach. Das and Gambäck (2014) Romanised the resources whereas Vyas et al. (2014) go in the opposite direction and develop a back-transliteration component."
    }, {
      "heading" : "4 Language Modelling",
      "text" : "A statistical language model assigns a probability to a given sentence or utterance. Models such as ngram models (Brown et al., 1992), factored language models (Bilmes and Kirchhoff, 2003) and neural language models (Bengio et al., 2003) are used in many NLP applications such as machine translation and automatic speech recognition. One can consider mixed text as an individual language and use existing techniques to train the model. Tokenisation and normalisation are the first steps to prepare the training data. Hence, one will face the problems presented in Section 3 first. Another serious problem is the lack of CS training data which makes statistical language models unreliable. We consider three kinds of CS to identify challenges of code-switching language modelling (LM). Inter-sentential CS In addition to the CS data corpus, we can use monolingual data to train several language models and interpolate them. Under the assumption that we can find monolingual data which has the same domain as the CS data, there is no obvious problem in this case. Intra-sentential CS The only available data resource is the code-switching training data. Previous work suggests to add syntactic and semantic information into the original statistical model to first predict the CS points and then the current word. It shows improvement when integrating additional resources such as language identification and POS tags into the recurrent neural language model (Adel et al., 2013a), the factored language model (Adel et al., 2015) and their combination (Adel et al., 2013b).\nTheir statistical analysis in Table 1 on the MandarinEnglish CS data set (Lyu et al., 2015) gives some insights on how accurate one can predict CS points based on POS tags. Additional information such as\nlanguage identification and POS tags might not be accurate due to problems presented in Section 5 and Section 6. In their work, they propose to combine Stanford Mandarin and English POS taggers to generate POS tags. There is, however, no report on POS tagger performance due to the lack of gold data.\nLi and Fung (2012;2014) propose another research direction which assembles syntactic inversion constraints into the language model. Instead of learning to predict the CS points alone, they suggest to learn the permission probabilities of CS points from a parallel corpus as to not violate the grammatical rules of both languages. This information is then integrated in a language model to constrain the CS points. It appears to be a promising approach if a large amount of parallel data of the two language exists and if the assumption holds that people do not change the grammatical rules of the mixed languages.1 Intra-word CS In addition to challenges presented in the previous paragraphs, one has to face the outof-vocabulary problem when CS appears within a word. This word has a high potential to be an unknown word. For example in the German-Turkish corpus (Çetinoğlu, 2016), 1.16% of the corpus are mixed words. 93.4% of them appear only once which indicates a big challenge not only for language modelling but also for other tasks.\n1This assumption is quite controversial among CS researchers, even Section 7 has counter-examples that show grammar changes. The assumption, however, could still be useful in statistical systems if the majority of switches follow the rules."
    }, {
      "heading" : "5 Language Identification",
      "text" : "Identifying the language of a text as one of the given languages is considered to be a solved task (McNamee, 2005). Simple n-gram approaches (Cavnar and Trenkle, 1994), character encoding detection (Dunning, 1994) or stop word lists (Grefenstette, 1995) can lead to a recognition accuracy of up to 100% on benchmark data sets.\nDiscriminating between closely related languages that show a significant lexical and structural overlap, like Croatian and Serbian, already poses a bigger problem. Stop word list approaches are problematic in such language pairs. N-gram approaches show an accuracy of up to 87% (Tan et al., 2014).\nHowever, all these techniques rely on the assumption that the input text is encoded in exactly one language. As soon as different languages are mixed inside a text or further within a sentence, a more finegrained detection is needed. CS reduces the minimum unit of detection to a token.\nLanguage identification (LID) is the most wellstudied task among computational CS approaches: there is relatively more annotated data; it is one of the preprocessing steps for more complex tasks; and shared tasks (Solorio et al., 2014; Choudhury et al., 2014) attract more research.\nLanguage identifiers with good performance on monolingual input (Cavnar and Trenkle, 1994; Lui and Baldwin, 2012) encounter accuracy loss due to shorter and/or unobserved context (Nguyen and Doğruöz, 2013; Volk and Clematide, 2014). Thus researchers have chosen to build new tools tailored to CS, using simple dictionary-based methods or machine learning techniques such as Naive Bayes, CRF, and SVM (Lignos and Marcus, 2013; Nguyen and Doğruöz, 2013; Voss et al., 2014; Das and Gambäck, 2014; Barman et al., 2014 and cf. Solorio et al., 2014). While they outperform language identifiers trained on monolingual data, they reach accuracies in the mid-90s. Shared task results (Solorio et al., 2014) report even lower F-scores (80- 85%), for some language pairs (Modern Standard Arabic- Egyptian Arabic, and surprise data sets for Nepalese-English, Spanish-English).\nSome of the challenges CS poses are inherent to the languages involved, which then propagate to language annotation and identification. One of the\nlanguage-specific challenges is language annotation when the mixed languages are closely related either linguistically or historically, e.g., Modern Standard Arabic and dialects (Elfardy and Diab, 2012; Samih and Maier, 2016) and Frisian-Dutch (Yılmaz et al., 2016). In such cases it is hard to find a clear distinction between code-switching and borrowing, thus deciding the language ID of a particular token. For English-Hindi, Das and Gambäck (2014) give the word ‘glass’ as an example. The concept was borrowed during the British colonisation in India, and Indian dictionaries contain the transliterated version. Yet, annotators sometimes labelled it as English.\nThe opposite is also observed. Both Vyas et al. (2014) and Barman et al. (2014) propose to label English borrowings in Hindi and Bengali as English. However, Barman et al. (2014) report that some annotators still annotated them as Hindi and Bengali. In the end almost 7% of the unique tokens were labelled in more than one language during annotation, which demonstrates that it is challenging to decide language IDs even for humans.\nVague division between CS and borrowing partially affects the language pairs when one or both are influenced by another language, e.g. English in present day. For instance in the Turkish-German corpus (Çetinoğlu, 2016), the word leggings was controversial among annotators, as some think it is English while others believe it is already integrated in the German language. This phenomenon could be challenging for statistical systems too, if the monolingual resources contain those controversial words inconsistently or in the opposite label of gold data.\nAnother big challenge for LID is mixing two languages inside one single word. These mixed words are treated differently among researchers. While many do not specify a special tag for intra-word mixing due to very infrequent representation in their corpus, Das and Gambäck (2014) propose 10 tags that mark the combinations of root and suffix languages. The CodeSwitch Workshop 2014 Shared Task (Maharjan et al., 2015), Barman et al. (2014), and Çetinoğlu (2016) use a Mixed tag.\nThis pattern is e.g. very productive in GermanTurkish code-switching where the suffixes of Turkish, as an agglutinating language, are attached to\nGerman words.2 This can result in words like Aufgabeler ‘assignments’ in (3) where the Turkish plural suffix -ler is appended to the German word Aufgabe ‘assignment’ and poses problems not only for LID but also for existing tools for POS tagging and morphological analysis."
    }, {
      "heading" : "6 POS Tagging",
      "text" : "POS tagging assigns a category from a given set to each input token. It has a popular use as a standalone application or as part of a preprocessing step for other tasks, e.g., parsing. It is the second most popular task after language identification in the current state of CS research. Unlike LID, CS does not change the definition of the task. Nevertheless, the task gets harder compared to tagging monolingual text. While state-of-the-art models reach over 97% accuracy on canonical data3, in work on CS data scores mostly around 70% are reported.\nOne problem, as expected, is the lack of large annotated data. Table 2 shows all the POS-annotated CS corpora to our knowledge and their sizes. CS POS tagging requires more annotated data compared to monolingual tagging, as CS increases the possible context of tokens.\n2The Turkish-German CS tweets (Çetinoğlu, 2016) have 1.16% Mixed tokens as compared to 0.32% Mixed in En-Bn-Hi (Barman et al., 2014) and 0.08-0.60% in Ne-En and 0.04-0.03% in Es-En (Maharjan et al., 2015) corpora.\n3https://aclweb.org/aclwiki/index.php? title=POS_Tagging_(State_of_the_art)\nThe last column of Table 2 shows the tag sets used in annotating POS. Only one corpus uses languagespecific tags (Solorio and Liu, 2008b), which predates universal tag sets. With the introduction of Google Universal Tags (UT) (Petrov et al., 2012) and later, its extended version Universal Dependencies (UD) tag set (Nivre et al., 2016) preference has moved to using a common tag set for all tokens. Vyas et al. (2014) employ 3 additional tags for named entities. Jamatia et al. (2015) and ICON 2015 Shared Task use a Hindi tag set that is mappable to UT. They also adopt 5 Twitter-specific tags.\nSolorio and Liu (2008b) show that high accuracy English and Spanish taggers achieve only 54% and 26% accuracy respectively on their data, indicating that off-the-shelf monolingual taggers are not suitable for CS text. Common methods applied to overcome this problem in several experiments (Solorio and Liu, 2008b; Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016; Schulz and Keller, 2016) are to choose between monolingual tagger outputs based on probabilities, utilising monolingual dictionaries and language models, and applying machine learning on the annotated CS data. One feature that deviates from standard POS tagging is language IDs, which are shown to be quite useful in previous work. Thus another challenge that comes with CS is predicting language IDs as a prior step to POS tagging.\nSolorio and Liu (2008b) achieve a high score of 93.48% with an SVM classifier, but this could be partly due to monolingual English sentences that constitute 62.5% of the corpus. In corpora with higher level of mixing, e.g. (Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016) best scores drop to 65.39%, 72%, and 68.25% respectively. Schulz and Keller (2016) have an accuracy of 81.6%. At the ICON 2015 Shared Task, the best system has an average of 76.79% accuracy. These scores show POS-tagging on CS data has room for improvement."
    }, {
      "heading" : "7 Parsing",
      "text" : "Parsing, the task of determining syntactic relations between words and phrases of a given sentence, has\n4Solorio and Liu (2008b) report the tagset is a slightly modified version of PTB, but do not give the exact number of tags.\n5Data from the ICON 2015 Shared Task on Pos Tagging For Code-mixed Indian Social Media Text. It is available at http://amitavadas.com/Code-Mixing.html\nadvanced substantially over the last decade. With the current rise of deep learning, a lot of parsers are developed, that, e.g. go above 93% unlabelled attachment score in dependency parsing of English (cf. Kiperwasser and Goldberg (2016) for a recent comparison of various high-performing parsers).\nWhile theories on parsing CS text have started quite early (Joshi, 1982) and a rule-based HPSG prototype is available (Goyal et al., 2003), there are no statistical parsers developed to handle CS. The main reason is the lack of treebanks that contain CS instances. Nevertheless, two recent works signal that research is moving in this direction.\nSharma et al. (2016) build a pipeline for HindiEnglish social media text. They create a corpus with four layers of annotation: language IDs, normalisation, POS tags, and for the first time, chunk boundaries and labels. Each component of their pipeline predicts one layer with data-driven approaches. When all steps are predicted the accuracy for chunking is measured as 61.95%.\nVilares et al. (2016) train lexicalised bilingual parsers by merging the training sets of two languages into one. They compare these models to monolingual ones on 10 Universal Dependencies treebanks (Nivre et al., 2016). The authors also apply their approach on English-Spanish codeswitching data in a toy experiment. They have annotated 10 tweets exhibiting CS according to UD rules. They train an English-Spanish POS tagger by merging the training sets of both languages. Their experiments show that using the bilingual tagger and parser is a promising direction for parsing CS.\nChallenges in parsing CS stem from error propogation in previous steps, but also from the syntactic constructions that are not native to monolingual languages. (3) is such an example from an ongoing corpus collection.\n(3) birkaç a few Aufgabeler assignment(DE).Pl(TR) yaptık make.Past.1Pl\narkadaşla friend.Sg.Ins ‘We made a few assignments with a friend.’\nThe sentence above contains a German-Turkish mixed word Aufgabeler (German portion in italics) as explained in Section 5 and the rest of the words are Turkish. The whole sentence employs Turkish\nsyntax, except that in the NP birkaç Aufgabeler, the noun modified by birkaç should be singular to be grammatical in Turkish. Perhaps the speaker utilises the German syntax where the noun is expected to be plural for this construction.\n(4) is a similar example from Broersma (2009) where the word order is from the embedded language (English, in italics), and shows how the syntactic and lexical systems of the two languages are combined during production: lexical items of one language are ordered according to the syntax of the other.\n(4) Later Later ik I naaide sewed voor for mensen. people.\n‘Later I sewed for people.’ correct: ‘Later naaide ik voor mensen.’\nAlthough not explicitly CS, code-switching bilinguals produce monolingual instances that do not follow the syntax of the uttered language. (5) and (6) show such instances where German syntax interferes with English (Albrecht, 2006, p.130) and Dutch syntax interferes with Turkish (Doğruöz and Backus, 2009). We include them into parsing challenges as the CS corpora to be parsed is likely to contain similar monolingual constructions.\n(5) Daniel: but me too not Faye: no, no, that goes not correct: ‘Daniel: but me neither Faye: no, no, that does not go’\n(6) Beyimin Husband.Gen ailesi family.Poss hep all o it da also burda. here\n‘My husband’s family is also all here.’ correct: ‘Beyimin ailesi de hep burda.’\nRepeating a word or a whole clause in both languages in a loose or direct translation is a common CS phenomenon, especially in speech or historical documents, and it might pose syntactic challenges e.g. when repetitive subordinate clauses exist which lead to complex coordinations (7) (Lodge and Wood, 2008, p.259). In this example the French portion (in italics) affirmatively translates and completes the Latin Pater Noster verse.\n(7) Sed But libera deliver nos, us, mais but livre deliver nous, us, Sire, God, a from\nmalo, evil, de of tout all mal evil et and de of cruel cruel martire martyrdom ‘But deliver us, God, of all evil and martyrdom’\nAll these examples demonstrate that, in addition to the solutions that would improve preprocessing steps of parsing, new models and methods should be developed to handle parsing-specific problems."
    }, {
      "heading" : "8 Machine Translation",
      "text" : "Machine translation (MT) explores methods to translate text from one language to another. Like all other tasks that rely on large amounts of data for training, MT quality decreases when encountering CS text. Not only the parallel text used for compiling phrase tables and translation probabilities but also the language models included are trained on monolingual data. Mixed text results in a high number of words unknown to the system and low probabilities for translations. Training dedicated translation systems for mixed text is, however, often not feasible due to the insufficient availability of data.\nMoreover, translation quality increases with increasing context lengths (cf. phrase-based MT). CS, however, leads to limited accessibility of context (in form of phrases included as such in the phrase table) and thus leads to a decrease in translation quality.\nA solution is to detect foreign words and then translate them into the matrix language before translating into a third language (Sinha and Thakur, 2005). Identifying foreign material and translating them into the fitting word in context poses similar problems as described in Sections 3 and 5. The lexical translations of inserted parts can be considered as a normalisation approach. In addition, an underlying assumption of this approach is the availability of a bilingual lexicon for the mixed language pairs which is not always a given. Even in a perfect foreign word translation scenario, it is questionable if the “monolingualised” text syntactically and lexically behaves like any other monolingual text so that a conventional MT system can handle it.\nAnother challenge is intra-word CS due to morphological binding of one language to a stem from another language as often observed in e.g. HindiEnglish text (Sinha and Thakur, 2005) or TurkishGerman (Çetinoğlu, 2016) which is shown in (8) .\n(8) Lehrerzimmerde staff room(DE).Loc(TR) schokolade chocolate\ndağıtıyorlar distribute.Prog.3Pl ‘They give away chocolate in the staff room.’\n(9) Handing schokolade Lehrerzimmer\nGoogle translate6 returns (9) as a translation from Turkish to English. The Turkish morpheme de is correctly recognised as an inflectional suffix and severed from the base word Lehrerzimmer ‘staff room’. Yet, it is not translated as the preposition in as expected. The German word is present, but without a translation. Moreover, the subject of the sentence (which should be they) is not translated at all even though the information is contained in the purely Turkish word dağıtıyorlar ‘they distribute’. Another word oblivious to the translation is schokolade ‘chocolate’. When the same sentence is input to Google Translate, all in German and all in Turkish, both cases receive a fully-translated output.7 Thus, the mixed context seems to harm the correct translation of the sentence.\nManandise and Gdaniec (2011) describe a way to deal with morphological bindings in the context of MT. They use a morphological analyser to first separate the base word from its morphological affixes. Those are then analysed and translated according to the morphology of the target base. They give Example (10), an English-Spanish mixed word anticooldad ‘anti-coolness’:\n(10) a. anticooldad b. anticool: dad c. cooldad:anti d. cool: anti, dad e. dummy: anti, dad\nThe analyser returns all possible base terms (shown as the string before the colon in (10)) along with the possible morphemes (shown as the strings after the colon in (10)). Since the word cool appears in the English dictionary and the other suggested base terms do not, the translation of the morphemes along with the correct morphological analysis and language-specific rules lead to the translation anticoolness.\nEven though there might be suggested solutions for token-based translations of embedded words as a preprocessing step, translation of the monolingualised sentence might still pose problems due to syntactic specificities as described in Section 7. In\n6 Google Translate, translate.google.com, 29.07.16.\n7The outputs are grammatical in both languages yet the semantics do not exactly match the original sentence.\ncase the sentence is monolingualised into one language and uses the syntax of the other original language, MT faces the problem of two separate combined systems: the lexical system of one language and the syntax of another."
    }, {
      "heading" : "9 Automatic Speech Recognition",
      "text" : "For automated processing of spoken communication, an automatic speech recognition (ASR) system, which transforms speech signal to text, is an essential component. In the context of CS, ASR is important because CS appears mainly in conversational speech. To develop an ASR system, three major components need to be built: a pronunciation dictionary, a language model and an acoustic model (AM) (Young, 1996). In general, there are two possible ways to build an ASR system for CS speech (Vu et al., 2012). In the first approach, a LID system is used to split the CS speech into monolingual parts and, afterwards, monolingual recognisers are applied to the corresponding speech segments. This method is straightforward since the monolingual systems are already available. We lose, however, the semantic information between the segments and the mistakes of the LID system cannot be recovered especially if speech segments are short (e.g. < 3s). The second approach is building an integrated system with a multilingual AM, dictionary and language model. Compared to the first approach, it allows handling of CS within a word and the semantic information can be used between languages. Therefore, we focus only on identifying challenges of developing pronunciation dictionaries and acoustic models for multilingual ASR. Pronunciation dictionary A pronunciation dictionary is a collection of words and phoneme sequences which describe how a word is pronounced. A straightforward implementation of a dictionary is to combine pronunciations of the mixed languages. This is often not suitable because pronunciation often changes in a CS context due to the articulation effect when speakers switch from one language to another. Another challenge is how to automatically create the pronunciation for CS words. To our best knowledge, this is a difficult task which has never been addressed so far. Acoustic modelling An AM estimates the proba-\nbility of sound state given a speech frame. The most crucial problem is again the lack of transcribed CS data. Another one is the phonetic transfer phenomenon which occurs even when the speaker is proficient in both languages. Hence, most recent proposed approaches focus on bilingual acoustic models which combine the properties of both languages and to some extent overcome the sparsity problem. Vu et al. (2012) merge the phoneme sets based on the International Phonetic Alphabet (IPA) manual mapping to share training data between phonemes across languages. Furthermore, their system allows to ask language specific questions during the context dependent decision tree building process. They achieve an improvement over the baseline with concatenated phoneme sets. Li and Fung (2013) propose an asymmetric AM which automatically derives phone clusters based on a phonetic confusion matrix. In the decision tree building process, they identify similar context dependent tree states across languages. The new output distribution is a linear interpolation of the pretrained monolingual state models. Their proposed approach outperforms the baseline with a large margin.\nAnother direction is to integrate LID prediction into ASR during testing. The LID gives the probability of a language given a speech frame which can be combined directly with the acoustic score for testing. Weiner et al. (2012) show good improvement when the LID system is sufficiently accurate. It is, however, a challenging task to develop a LID system on the acoustic frame level."
    }, {
      "heading" : "10 Conclusion",
      "text" : "In this paper, we discuss the challenges that surface when well-established NLP tasks deal with CS data. Some of these challenges are language-pair dependent e.g. Romanisation and back-translation in Hindi or Bengali. Others are recurring throughout various tasks regardless of the language such as the increased amount of unseen constructions caused by combining lexicon and syntax of two languages.\nWorking on NLP for mixed data yields the advantage that resources and tools for the respective languages can be beneficial. Although we do not have to start from scratch, the tasks and required techniques are significantly different from those for\nmonolingual data. Context-sensitive methods suffer due to increased combinatoric possibilities crossing syntactic and lexical systems of different languages.\nIn addition, CS is a phenomenon that appears in data with hard-to-process factors other than mixing. CS-typical genres are often close to spoken text and thus have to deal with problems that colloquial text poses from non-canonicity to incomplete syntactic structures to OOV-words. Although this would already suggest that a higher number of training instances are needed, there are just small amounts of annotated data available. So far there are annotated bilingual training resources for just three of the tasks (LID, POS and ASR) for specific language pairs. Since each mixed language comes with its own challenges, each pair requires a dedicated corpus.\nTo alleviate the data sparsity problem, some approaches work by generating artificial CS text based on a CS-aware recurrent neural network decoder (Vu and Schultz, 2014) or a machine translation system to create CS data from monolingual data (Vu et al., 2012). Such techniques would benefit from better understanding of the characteristics of codeswitching data. This is why we enriched our paper with examples from data sets covering different language pairs. So far, very little NLP research makes use of linguistic insights into CS patterns (cf. Li and Fung (2014)). Such cues might improve results in the discussed tasks herein.\nAnother recurring and not yet addressed issue8, is the inter-relatedness of all these tasks. Features required for one task are the output of the other. Pipeline approaches cannot take advantage of these features when task dependencies are cyclic (e.g., normalisation and language identification). Moreover pipelines cause error propagation. This fact asks for attention on joint modelling approaches."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank our anonymous reviewers for their helpful comments. This work was funded by the Deutsche Forschungsgemeinschaft (DFG) via SFB 732, projects D2 and A8, and by the German Federal Ministry of Education and Research (BMBF) via CRETA Project.\n8Vyas et al. (2014) discuss joint modelling in the conclusion."
    } ],
    "references" : [ {
      "title" : "Recurrent neural network language modeling for code switching conversational speech",
      "author" : [ "Adel et al.2013a] H. Adel", "N.T. Vu", "F. Kraus", "T. Schlippe", "T. Schultz", "H. Li" ],
      "venue" : "Proceedings of ICASSP",
      "citeRegEx" : "Adel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Adel et al\\.",
      "year" : 2013
    }, {
      "title" : "Combination of recurrent neural networks and factored language models for code-switching language modeling",
      "author" : [ "Adel et al.2013b] H. Adel", "N.T. Vu", "T. Schultz" ],
      "venue" : "Proceedings of ACL",
      "citeRegEx" : "Adel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Adel et al\\.",
      "year" : 2013
    }, {
      "title" : "Syntactic and semantic features for code-switching factored language models",
      "author" : [ "Adel et al.2015] H. Adel", "N.T. Vu", "K. Kirchhoff", "D. Telaar", "T. Schultz" ],
      "venue" : null,
      "citeRegEx" : "Adel et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Adel et al\\.",
      "year" : 2015
    }, {
      "title" : "I can speak German-und Deutsch: The development and use of code-switching among simultaneous and successive English-German bilingual children",
      "author" : [ "E. Albrecht" ],
      "venue" : "Rombach Druckund Verlagshaus",
      "citeRegEx" : "Albrecht.,? \\Q2006\\E",
      "shortCiteRegEx" : "Albrecht.",
      "year" : 2006
    }, {
      "title" : "Networked multilingualism: Some language practices on facebook and their implications",
      "author" : [ "J. Androutsopoulos" ],
      "venue" : "International Journal of Bilingualism,",
      "citeRegEx" : "Androutsopoulos.,? \\Q2015\\E",
      "shortCiteRegEx" : "Androutsopoulos.",
      "year" : 2015
    }, {
      "title" : "A phrase-based statistical model for sms text normalization",
      "author" : [ "Aw et al.2006] A. Aw", "M. Zhang", "J. Xiao", "J. Su" ],
      "venue" : "In Proceedings COLING/ACL",
      "citeRegEx" : "Aw et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Aw et al\\.",
      "year" : 2006
    }, {
      "title" : "Code mixing: A challenge for language identification in the language of social media",
      "author" : [ "Barman et al.2014] U. Barman", "A. Das", "J. Wagner", "J. Foster" ],
      "venue" : "In Proceedings of the CodeSwitch Workshop",
      "citeRegEx" : "Barman et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Barman et al\\.",
      "year" : 2014
    }, {
      "title" : "A neural probabilistic language model",
      "author" : [ "Bengio et al.2003] Y. Bengio", "R. Ducharme", "P. Vincent", "C. Jauvin" ],
      "venue" : "Journal of machine learning research,",
      "citeRegEx" : "Bengio et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2003
    }, {
      "title" : "Factored language models and generalized parallel backoff",
      "author" : [ "Bilmes", "Kirchhoff2003] J. Bilmes", "K. Kirchhoff" ],
      "venue" : "In Proceedings of NAACL",
      "citeRegEx" : "Bilmes et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Bilmes et al\\.",
      "year" : 2003
    }, {
      "title" : "Rule-Based Normalization of Historical Texts",
      "author" : [ "Bollmann et al.2011] M. Bollmann", "F. Petran", "S. Dipper" ],
      "venue" : "In Proceedings of LaTeCH",
      "citeRegEx" : "Bollmann et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bollmann et al\\.",
      "year" : 2011
    }, {
      "title" : "Triggered codeswitching between cognate languages. Bilingualism: Language and Cognition, 12:447–462",
      "author" : [ "M. Broersma" ],
      "venue" : null,
      "citeRegEx" : "Broersma.,? \\Q2009\\E",
      "shortCiteRegEx" : "Broersma.",
      "year" : 2009
    }, {
      "title" : "Class-based n-gram models of natural language",
      "author" : [ "Brown et al.1992] P. Brown", "P. de Souza", "R. Mercer", "V. Della Pietra", "J. Lai" ],
      "venue" : null,
      "citeRegEx" : "Brown et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 1992
    }, {
      "title" : "The Cambridge handbook of linguistic code-switching",
      "author" : [ "Bullock", "Toribio2012] B.E. Bullock", "A.J. Toribio" ],
      "venue" : null,
      "citeRegEx" : "Bullock et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bullock et al\\.",
      "year" : 2012
    }, {
      "title" : "N-gram-based text categorization",
      "author" : [ "Cavnar", "Trenkle1994] W.B. Cavnar", "J.M. Trenkle" ],
      "venue" : "Proceedings of SDAIR-94",
      "citeRegEx" : "Cavnar et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cavnar et al\\.",
      "year" : 1994
    }, {
      "title" : "Code-mixing in social media text: the last language identification frontier",
      "author" : [ "Das", "Gambäck2014] A. Das", "B. Gambäck" ],
      "venue" : "Traitement Automatique des Langues (TAL): Special Issue on Social Networks and NLP,",
      "citeRegEx" : "Das et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2014
    }, {
      "title" : "Innovative constructions in dutch turkish: An assessment of ongoing contact-induced change",
      "author" : [ "Doğruöz", "Backus2009] S. Doğruöz", "A. Backus" ],
      "venue" : "Bilingualism: language and cognition,",
      "citeRegEx" : "Doğruöz et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Doğruöz et al\\.",
      "year" : 2009
    }, {
      "title" : "Statistical identification of language. Technical report",
      "author" : [ "T. Dunning" ],
      "venue" : null,
      "citeRegEx" : "Dunning.,? \\Q1994\\E",
      "shortCiteRegEx" : "Dunning.",
      "year" : 1994
    }, {
      "title" : "Text normalization in code-mixed social media text. In Recent Trends in Information Systems (ReTIS)",
      "author" : [ "Dutta et al.2015] S. Dutta", "T. Saha", "S. Banerjee", "S.K. Naskar" ],
      "venue" : null,
      "citeRegEx" : "Dutta et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dutta et al\\.",
      "year" : 2015
    }, {
      "title" : "Simplified guidelines for the creation of large scale dialectal arabic annotations",
      "author" : [ "Elfardy", "Diab2012] H. Elfardy", "M. Diab" ],
      "venue" : "In Proceedings of LREC",
      "citeRegEx" : "Elfardy et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Elfardy et al\\.",
      "year" : 2012
    }, {
      "title" : "A bilingual parser for hindi, english and codeswitching structures",
      "author" : [ "Goyal et al.2003] P. Goyal", "M.R. Mital", "A. Mukerjee", "A.M. Raina", "D. Sharma", "P. Shukla", "K. Vikram" ],
      "venue" : "Proceedings of EACL",
      "citeRegEx" : "Goyal et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Goyal et al\\.",
      "year" : 2003
    }, {
      "title" : "Comparing two language identification schemes",
      "author" : [ "G. Grefenstette" ],
      "venue" : "In Proceedings of JADT",
      "citeRegEx" : "Grefenstette.,? \\Q1995\\E",
      "shortCiteRegEx" : "Grefenstette.",
      "year" : 1995
    }, {
      "title" : "Pos tagging for code-mixed english-hindi twitter and facebook chat messages",
      "author" : [ "Jamatia et al.2015] A. Jamatia", "B. Gambäck", "A. Das" ],
      "venue" : "In Proc. of RANLP",
      "citeRegEx" : "Jamatia et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Jamatia et al\\.",
      "year" : 2015
    }, {
      "title" : "Processing of sentences with intra-sentential code-switching",
      "author" : [ "A.K. Joshi" ],
      "venue" : "In Proc. of COLING",
      "citeRegEx" : "Joshi.,? \\Q1982\\E",
      "shortCiteRegEx" : "Joshi.",
      "year" : 1982
    }, {
      "title" : "Toward normalizing romanized gurumukhi text from social media",
      "author" : [ "Kaur", "Singh2015] J. Kaur", "J. Singh" ],
      "venue" : "Indian Journal of Science and Technology,",
      "citeRegEx" : "Kaur et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kaur et al\\.",
      "year" : 2015
    }, {
      "title" : "Simple and accurate dependency parsing using bidirectional LSTM feature",
      "author" : [ "Kiperwasser", "Goldberg2016] E. Kiperwasser", "Y. Goldberg" ],
      "venue" : "representations. TACL,",
      "citeRegEx" : "Kiperwasser et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kiperwasser et al\\.",
      "year" : 2016
    }, {
      "title" : "Code-switch language model with inversion constraints for mixed",
      "author" : [ "Li", "Fung2012] Y. Li", "P. Fung" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2012
    }, {
      "title" : "Improved mixed language speech recognition using asymmetric acoustic model and language model with code-switch inversion constraints",
      "author" : [ "Li", "Fung2013] Y. Li", "P. Fung" ],
      "venue" : "Proceedings of ICASSP",
      "citeRegEx" : "Li et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2013
    }, {
      "title" : "Language modeling with functional head constraint for code switching speech recognition",
      "author" : [ "Li", "Fung2014] Y. Li", "P. Fung" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "Li et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2014
    }, {
      "title" : "Toward web-scale analysis of the codeswitching",
      "author" : [ "Lignos", "Marcus2013] C. Lignos", "M. Marcus" ],
      "venue" : "In Proceedings of of LSA",
      "citeRegEx" : "Lignos et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lignos et al\\.",
      "year" : 2013
    }, {
      "title" : "A broad-coverage normalization system for social media language",
      "author" : [ "F. Liu", "F. Weng", "X. Jiang" ],
      "venue" : "In Proceedings of ACL",
      "citeRegEx" : "Liu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2012
    }, {
      "title" : "Modern Criticism and Theory: A Reader",
      "author" : [ "Lodge", "Wood2008] D. Lodge", "N. Wood" ],
      "venue" : null,
      "citeRegEx" : "Lodge et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Lodge et al\\.",
      "year" : 2008
    }, {
      "title" : "langid. py: An off-the-shelf language identification tool",
      "author" : [ "Lui", "Baldwin2012] M. Lui", "T. Baldwin" ],
      "venue" : "In Proc. of ACL",
      "citeRegEx" : "Lui et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lui et al\\.",
      "year" : 2012
    }, {
      "title" : "Mandarin–english code-switching speech corpus in south-east asia: Seame",
      "author" : [ "Lyu et al.2015] D.-C. Lyu", "T.-P. Tan", "E.-S. Chng", "H. Li" ],
      "venue" : null,
      "citeRegEx" : "Lyu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lyu et al\\.",
      "year" : 2015
    }, {
      "title" : "Developing language-tagged corpora for code-switching tweets",
      "author" : [ "Maharjan et al.2015] S. Maharjan", "E. Blair", "S. Bethard", "T. Solorio" ],
      "venue" : "In Proceedings of LAW-9",
      "citeRegEx" : "Maharjan et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Maharjan et al\\.",
      "year" : 2015
    }, {
      "title" : "Morphology to the rescue redux: Resolving borrowings and code-mixing in machine translation",
      "author" : [ "Manandise", "Gdaniec2011] E. Manandise", "C. Gdaniec" ],
      "venue" : "In Proceedings of SFCM",
      "citeRegEx" : "Manandise et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Manandise et al\\.",
      "year" : 2011
    }, {
      "title" : "Language identification: A solved problem suitable for undergraduate instruction",
      "author" : [ "P. McNamee" ],
      "venue" : "J. Comput. Sci. Coll.,",
      "citeRegEx" : "McNamee.,? \\Q2005\\E",
      "shortCiteRegEx" : "McNamee.",
      "year" : 2005
    }, {
      "title" : "Word level language identification in online multilingual communication",
      "author" : [ "Nguyen", "Doğruöz2013] D. Nguyen", "A.S. Doğruöz" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "Nguyen et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2013
    }, {
      "title" : "Universal dependencies v1: A multilingual treebank collection",
      "author" : [ "J. Nivre", "M.-C. de Marneffe", "F. Ginter", "Y. Goldberg", "J. Hajič", "C. Manning", "R. McDonald", "S. Petrov", "S. Pyysalo", "N. Silveira", "R. Tsarfaty", "D. Zeman" ],
      "venue" : "Proceedings of LREC",
      "citeRegEx" : "Nivre et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2016
    }, {
      "title" : "A universal part-of-speech tagset",
      "author" : [ "S. Petrov", "D. Das", "R. McDonald" ],
      "venue" : "In Proceedings of LREC",
      "citeRegEx" : "Petrov et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Petrov et al\\.",
      "year" : 2012
    }, {
      "title" : "Sometimes I’ll start a sentence in Spanish y termino en Espanol: toward a typology of code-switching",
      "author" : [ "S. Poplack" ],
      "venue" : null,
      "citeRegEx" : "Poplack.,? \\Q1980\\E",
      "shortCiteRegEx" : "Poplack.",
      "year" : 1980
    }, {
      "title" : "An arabic-moroccan darija code-switched corpus",
      "author" : [ "Samih", "Maier2016] Y. Samih", "W. Maier" ],
      "venue" : "In Proceedings of LREC",
      "citeRegEx" : "Samih et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Samih et al\\.",
      "year" : 2016
    }, {
      "title" : "Part-of-speech tagging for code-mixed indian social media text at ICON",
      "author" : [ "K. Sarkar" ],
      "venue" : null,
      "citeRegEx" : "Sarkar.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sarkar.",
      "year" : 2016
    }, {
      "title" : "Code-switching ubique est - language identification and part-of-speech tagging for historical mixed text",
      "author" : [ "Schulz", "Keller2016] S. Schulz", "M. Keller" ],
      "venue" : "In Proc. of LaTeCH",
      "citeRegEx" : "Schulz et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Schulz et al\\.",
      "year" : 2016
    }, {
      "title" : "Multimodular text normalization of dutch usergenerated content",
      "author" : [ "Schulz et al.2016] S. Schulz", "G. De Pauw", "O. De Clercq", "B. Desmet", "V. Hoste", "W. Daelemans", "L. Macken" ],
      "venue" : "ACM Trans. Intell. Syst. Technol.,",
      "citeRegEx" : "Schulz et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Schulz et al\\.",
      "year" : 2016
    }, {
      "title" : "Shallow parsing pipeline - hindienglish code-mixed social media text",
      "author" : [ "Sharma et al.2016] A. Sharma", "S. Gupta", "R. Motlani", "P. Bansal", "M. Shrivastava", "R. Mamidi", "D.M. Sharma" ],
      "venue" : "Proceedings of NAACL",
      "citeRegEx" : "Sharma et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Sharma et al\\.",
      "year" : 2016
    }, {
      "title" : "Machine translation of bi-lingual hindi-english (hinglish) text",
      "author" : [ "Sinha", "Thakur2005] R.M.K. Sinha", "A. Thakur" ],
      "venue" : "In Proceedings of the MT Summit",
      "citeRegEx" : "Sinha et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Sinha et al\\.",
      "year" : 2005
    }, {
      "title" : "Learning to predict code-switching points",
      "author" : [ "Solorio", "Liu2008a] T. Solorio", "Y. Liu" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "Solorio et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Solorio et al\\.",
      "year" : 2008
    }, {
      "title" : "Part-of-Speech tagging for English-Spanish codeswitched text",
      "author" : [ "Solorio", "Liu2008b] T. Solorio", "Y. Liu" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "Solorio et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Solorio et al\\.",
      "year" : 2008
    }, {
      "title" : "Overview for the first shared task on language identification in code-switched data",
      "author" : [ "Solorio et al.2014] T. Solorio", "E. Blair", "S. Maharjan", "S. Bethard", "M. Diab", "M. Ghoneim", "A. Hawwari", "F. AlGhamdi", "J. Hirschberg", "A. Chang", "P. Fung" ],
      "venue" : null,
      "citeRegEx" : "Solorio et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Solorio et al\\.",
      "year" : 2014
    }, {
      "title" : "Merging comparable data sources for the discrimination of similar languages: The dsl corpus collection",
      "author" : [ "Tan et al.2014] L. Tan", "M. Zampieri", "J. Tiedemann" ],
      "venue" : "Proceedings of BUCC",
      "citeRegEx" : "Tan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2014
    }, {
      "title" : "One model, two languages: training bilingual parsers with harmonized treebanks",
      "author" : [ "Vilares et al.2016] D. Vilares", "M.A. Alonso", "C. Gómez-Rodríguez" ],
      "venue" : "In Proc. of ACL",
      "citeRegEx" : "Vilares et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Vilares et al\\.",
      "year" : 2016
    }, {
      "title" : "Detecting code-switching in a multilingual alpine heritage corpus",
      "author" : [ "Volk", "Clematide2014] M. Volk", "S. Clematide" ],
      "venue" : "In Proceedings of the CodeSwitch Workshop",
      "citeRegEx" : "Volk et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Volk et al\\.",
      "year" : 2014
    }, {
      "title" : "Finding romanized arabic dialect in codemixed tweets",
      "author" : [ "Voss et al.2014] C. Voss", "S. Tratz", "J. Laoudi", "D. Briesch" ],
      "venue" : "In Proceedings of LREC",
      "citeRegEx" : "Voss et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Voss et al\\.",
      "year" : 2014
    }, {
      "title" : "Exploration of the impact of maximum entropy in recurrent neural network language models for codeswitching speech",
      "author" : [ "Vu", "Schultz2014] N.T. Vu", "T. Schultz" ],
      "venue" : "In Proceedings of the CodeSwitch Workshop",
      "citeRegEx" : "Vu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vu et al\\.",
      "year" : 2014
    }, {
      "title" : "A first speech recognition system for mandarin-english code-switch conversational speech",
      "author" : [ "Vu et al.2012] N.T. Vu", "D. Lyu", "J. Weiner", "D. Telaar", "T. Schlippe", "F. Blaicher", "E.-S. Chng", "T. Schultz", "H. Li" ],
      "venue" : "In Proc. of ICASSP",
      "citeRegEx" : "Vu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Vu et al\\.",
      "year" : 2012
    }, {
      "title" : "Pos tagging of englishhindi code-mixed social media content",
      "author" : [ "Vyas et al.2014] Y. Vyas", "S. Gella", "J. Sharma", "K. Bali", "M. Choudhury" ],
      "venue" : "In Proceedings of EMNLP",
      "citeRegEx" : "Vyas et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Vyas et al\\.",
      "year" : 2014
    }, {
      "title" : "Integration of language identification into a recognition system for spoken conversations containing code-switches",
      "author" : [ "Weiner et al.2012] J. Weiner", "N.T. Vu", "D. Telaar", "F. Metze", "T. Schultz", "D.g Lyu", "E.-S. Chng", "H. Li" ],
      "venue" : "Proceedings of SLTU",
      "citeRegEx" : "Weiner et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Weiner et al\\.",
      "year" : 2012
    }, {
      "title" : "A longitudinal bilingual frisian-dutch radio broadcast database designed for code-switching",
      "author" : [ "Yılmaz et al.2016] E. Yılmaz", "M. Andringa", "S. Kingma", "J. Dijkstra", "F. Van der Kuip", "H. Van de Velde", "F. Kampstra", "J. Algra", "H. van den Heuvel", "D. van Leeuwen" ],
      "venue" : null,
      "citeRegEx" : "Yılmaz et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Yılmaz et al\\.",
      "year" : 2016
    }, {
      "title" : "A review of largevocabulary continuous-speech",
      "author" : [ "S. Young" ],
      "venue" : "IEEE SPM,",
      "citeRegEx" : "Young.,? \\Q1996\\E",
      "shortCiteRegEx" : "Young.",
      "year" : 1996
    }, {
      "title" : "Chinese-english mixed text normalization",
      "author" : [ "Q. Zhang", "H. Chen", "X. Huang" ],
      "venue" : "In Proc. of WSDM",
      "citeRegEx" : "Zhang et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 39,
      "context" : "sociological and linguistic aspects (Poplack, 1980; Myers-Scotton, 1993; Muysken, 2000; Auer and Wei, 2007; Bullock and Toribio, 2012).",
      "startOffset" : 36,
      "endOffset" : 134
    }, {
      "referenceID" : 39,
      "context" : "sociological and linguistic aspects (Poplack, 1980; Myers-Scotton, 1993; Muysken, 2000; Auer and Wei, 2007; Bullock and Toribio, 2012). This has also brought different perspectives on the definition and types of mixed language. Switching between sentences (inter-sentential) is distinguished from switching inside of one sentence (intra-sentential). Poplack (1980) defines code-switching as ‘the alternation of two languages within a single discourse, sentence or constituent’.",
      "startOffset" : 37,
      "endOffset" : 365
    }, {
      "referenceID" : 39,
      "context" : "sociological and linguistic aspects (Poplack, 1980; Myers-Scotton, 1993; Muysken, 2000; Auer and Wei, 2007; Bullock and Toribio, 2012). This has also brought different perspectives on the definition and types of mixed language. Switching between sentences (inter-sentential) is distinguished from switching inside of one sentence (intra-sentential). Poplack (1980) defines code-switching as ‘the alternation of two languages within a single discourse, sentence or constituent’. Muysken (2000) avoids this term arguing that it suggests alternation but not insertion, and prefers code-mixing for intra-",
      "startOffset" : 37,
      "endOffset" : 493
    }, {
      "referenceID" : 22,
      "context" : "(Joshi, 1982), yet few studies are done in the 2000s (Goyal et al.",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 19,
      "context" : "(Joshi, 1982), yet few studies are done in the 2000s (Goyal et al., 2003; Sinha and Thakur, 2005; Solorio and Liu, 2008a; Solorio and Liu, 2008b).",
      "startOffset" : 53,
      "endOffset" : 145
    }, {
      "referenceID" : 32,
      "context" : "Nature of the data Annotated CS corpora, that are designed for computational purposes, center around three sources so far: spoken data (Solorio and Liu, 2008b; Lyu et al., 2015; Yılmaz et al., 2016), social media (Nguyen and Doğruöz, 2013; Barman et al.",
      "startOffset" : 135,
      "endOffset" : 198
    }, {
      "referenceID" : 57,
      "context" : "Nature of the data Annotated CS corpora, that are designed for computational purposes, center around three sources so far: spoken data (Solorio and Liu, 2008b; Lyu et al., 2015; Yılmaz et al., 2016), social media (Nguyen and Doğruöz, 2013; Barman et al.",
      "startOffset" : 135,
      "endOffset" : 198
    }, {
      "referenceID" : 9,
      "context" : "(2006)) or historical language to its modern form (Bollmann et al., 2011).",
      "startOffset" : 50,
      "endOffset" : 73
    }, {
      "referenceID" : 40,
      "context" : "Schulz et al. (2016) and Aw et al.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 5,
      "context" : "(2016) and Aw et al. (2006)) or historical language to its modern form (Bollmann et al.",
      "startOffset" : 11,
      "endOffset" : 28
    }, {
      "referenceID" : 4,
      "context" : "Another example is taken from a corpus of Facebook chats (Androutsopoulos, 2015).",
      "startOffset" : 57,
      "endOffset" : 80
    }, {
      "referenceID" : 17,
      "context" : "Since training material for such systems might be sparse for some language pairs, methods for mixed text tend to return to smaller context windows as done by Dutta et al. (2015). They suggest to use two monolingual language models with context windows depending on the neighbouring words using language identification information.",
      "startOffset" : 158,
      "endOffset" : 178
    }, {
      "referenceID" : 17,
      "context" : "Since training material for such systems might be sparse for some language pairs, methods for mixed text tend to return to smaller context windows as done by Dutta et al. (2015). They suggest to use two monolingual language models with context windows depending on the neighbouring words using language identification information. In case of a high density of switch points between languages, the context window might be small. As another normalisation challenge, Kaur and Singh (2015) describe issues emerging from mixing different scripts in Punjabi-English and Sarkar (2016) for Hindi-English and Bengali-English social",
      "startOffset" : 158,
      "endOffset" : 486
    }, {
      "referenceID" : 17,
      "context" : "Since training material for such systems might be sparse for some language pairs, methods for mixed text tend to return to smaller context windows as done by Dutta et al. (2015). They suggest to use two monolingual language models with context windows depending on the neighbouring words using language identification information. In case of a high density of switch points between languages, the context window might be small. As another normalisation challenge, Kaur and Singh (2015) describe issues emerging from mixing different scripts in Punjabi-English and Sarkar (2016) for Hindi-English and Bengali-English social",
      "startOffset" : 158,
      "endOffset" : 578
    }, {
      "referenceID" : 6,
      "context" : "Due to this problem Barman et al. (2014) do not use existing Bengali and Hindi resources in their dictionary-based approach.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "Due to this problem Barman et al. (2014) do not use existing Bengali and Hindi resources in their dictionary-based approach. Das and Gambäck (2014) Romanised the resources whereas Vyas et al.",
      "startOffset" : 20,
      "endOffset" : 148
    }, {
      "referenceID" : 6,
      "context" : "Due to this problem Barman et al. (2014) do not use existing Bengali and Hindi resources in their dictionary-based approach. Das and Gambäck (2014) Romanised the resources whereas Vyas et al. (2014) go in the opposite direction and develop a back-transliteration component.",
      "startOffset" : 20,
      "endOffset" : 199
    }, {
      "referenceID" : 11,
      "context" : "Models such as ngram models (Brown et al., 1992), factored language models (Bilmes and Kirchhoff, 2003) and neural",
      "startOffset" : 28,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "language models (Bengio et al., 2003) are used in many NLP applications such as machine translation and automatic speech recognition.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 2,
      "context" : ", 2013a), the factored language model (Adel et al., 2015) and their combination (Adel et al.",
      "startOffset" : 38,
      "endOffset" : 57
    }, {
      "referenceID" : 32,
      "context" : "Their statistical analysis in Table 1 on the MandarinEnglish CS data set (Lyu et al., 2015) gives some insights on how accurate one can predict CS points based on POS tags.",
      "startOffset" : 73,
      "endOffset" : 91
    }, {
      "referenceID" : 35,
      "context" : "languages is considered to be a solved task (McNamee, 2005).",
      "startOffset" : 44,
      "endOffset" : 59
    }, {
      "referenceID" : 16,
      "context" : "Simple n-gram approaches (Cavnar and Trenkle, 1994), character encoding detection (Dunning, 1994) or stop word lists (Grefenstette, 1995) can lead to a recognition accuracy of up to 100% on benchmark data sets.",
      "startOffset" : 82,
      "endOffset" : 97
    }, {
      "referenceID" : 20,
      "context" : "Simple n-gram approaches (Cavnar and Trenkle, 1994), character encoding detection (Dunning, 1994) or stop word lists (Grefenstette, 1995) can lead to a recognition accuracy of up to 100% on benchmark data sets.",
      "startOffset" : 117,
      "endOffset" : 137
    }, {
      "referenceID" : 49,
      "context" : "N-gram approaches show an accuracy of up to 87% (Tan et al., 2014).",
      "startOffset" : 48,
      "endOffset" : 66
    }, {
      "referenceID" : 48,
      "context" : "studied task among computational CS approaches: there is relatively more annotated data; it is one of the preprocessing steps for more complex tasks; and shared tasks (Solorio et al., 2014; Choudhury et al., 2014) attract more research.",
      "startOffset" : 167,
      "endOffset" : 213
    }, {
      "referenceID" : 52,
      "context" : "Thus researchers have chosen to build new tools tailored to CS, using simple dictionary-based methods or machine learning techniques such as Naive Bayes, CRF, and SVM (Lignos and Marcus, 2013; Nguyen and Doğruöz, 2013; Voss et al., 2014; Das and Gambäck, 2014; Barman et al., 2014 and cf. Solorio et al., 2014).",
      "startOffset" : 167,
      "endOffset" : 310
    }, {
      "referenceID" : 48,
      "context" : "Shared task results (Solorio et al., 2014) report even lower F-scores (8085%), for some language pairs (Modern Standard Arabic- Egyptian Arabic, and surprise data sets for Nepalese-English, Spanish-English).",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 57,
      "context" : "and Maier, 2016) and Frisian-Dutch (Yılmaz et al., 2016).",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 57,
      "context" : "and Maier, 2016) and Frisian-Dutch (Yılmaz et al., 2016). In such cases it is hard to find a clear distinction between code-switching and borrowing, thus deciding the language ID of a particular token. For English-Hindi, Das and Gambäck (2014) give the word ‘glass’ as an example.",
      "startOffset" : 36,
      "endOffset" : 244
    }, {
      "referenceID" : 54,
      "context" : "Both Vyas et al. (2014) and Barman et al.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "(2014) and Barman et al. (2014) propose to label",
      "startOffset" : 11,
      "endOffset" : 32
    }, {
      "referenceID" : 6,
      "context" : "However, Barman et al. (2014) report that some annotators still annotated them as Hindi and Bengali.",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 33,
      "context" : "The CodeSwitch Workshop 2014 Shared Task (Maharjan et al., 2015), Barman et al.",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 6,
      "context" : ", 2015), Barman et al. (2014), and Çetinoğlu (2016) use a Mixed tag.",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : ", 2015), Barman et al. (2014), and Çetinoğlu (2016) use a Mixed tag.",
      "startOffset" : 9,
      "endOffset" : 52
    }, {
      "referenceID" : 55,
      "context" : "S&L’08:Solorio and Liu (2008b), V’14:Vyas et al. (2014),",
      "startOffset" : 37,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "J’15:Jamatia et al. (2015), Ç&Ç’16:Çetinoğlu and Çöltekin",
      "startOffset" : 5,
      "endOffset" : 27
    }, {
      "referenceID" : 44,
      "context" : "(2016), S’16:Sharma et al. (2016), S&K’16:Schulz and Keller",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 38,
      "context" : "UT: Google Universal Tags (Petrov et al., 2012).",
      "startOffset" : 26,
      "endOffset" : 47
    }, {
      "referenceID" : 37,
      "context" : "Universal Dependencies tag set (Nivre et al., 2016).",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 6,
      "context" : "32% Mixed in En-Bn-Hi (Barman et al., 2014) and 0.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 33,
      "context" : "03% in Es-En (Maharjan et al., 2015) corpora.",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 38,
      "context" : "Google Universal Tags (UT) (Petrov et al., 2012) and later, its extended version Universal Dependencies (UD) tag set (Nivre et al.",
      "startOffset" : 27,
      "endOffset" : 48
    }, {
      "referenceID" : 37,
      "context" : ", 2012) and later, its extended version Universal Dependencies (UD) tag set (Nivre et al., 2016) preference has moved to using a common tag set for all tokens.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 36,
      "context" : ", 2012) and later, its extended version Universal Dependencies (UD) tag set (Nivre et al., 2016) preference has moved to using a common tag set for all tokens. Vyas et al. (2014) employ 3 additional tags for named entities.",
      "startOffset" : 77,
      "endOffset" : 179
    }, {
      "referenceID" : 21,
      "context" : "Jamatia et al. (2015) and ICON 2015 Shared Task use a Hindi tag set that is mappable to UT.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 55,
      "context" : "Common methods applied to overcome this problem in several experiments (Solorio and Liu, 2008b; Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016; Schulz and Keller, 2016)",
      "startOffset" : 71,
      "endOffset" : 182
    }, {
      "referenceID" : 21,
      "context" : "Common methods applied to overcome this problem in several experiments (Solorio and Liu, 2008b; Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016; Schulz and Keller, 2016)",
      "startOffset" : 71,
      "endOffset" : 182
    }, {
      "referenceID" : 44,
      "context" : "Common methods applied to overcome this problem in several experiments (Solorio and Liu, 2008b; Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016; Schulz and Keller, 2016)",
      "startOffset" : 71,
      "endOffset" : 182
    }, {
      "referenceID" : 55,
      "context" : "(Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016) best scores drop to 65.",
      "startOffset" : 0,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : "(Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016) best scores drop to 65.",
      "startOffset" : 0,
      "endOffset" : 62
    }, {
      "referenceID" : 44,
      "context" : "(Vyas et al., 2014; Jamatia et al., 2015; Sharma et al., 2016) best scores drop to 65.",
      "startOffset" : 0,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : ", 2014; Jamatia et al., 2015; Sharma et al., 2016) best scores drop to 65.39%, 72%, and 68.25% respectively. Schulz and Keller (2016) have an accuracy of 81.",
      "startOffset" : 8,
      "endOffset" : 134
    }, {
      "referenceID" : 22,
      "context" : "While theories on parsing CS text have started quite early (Joshi, 1982) and a rule-based HPSG prototype is available (Goyal et al.",
      "startOffset" : 59,
      "endOffset" : 72
    }, {
      "referenceID" : 19,
      "context" : "While theories on parsing CS text have started quite early (Joshi, 1982) and a rule-based HPSG prototype is available (Goyal et al., 2003), there are no statistical parsers developed to handle CS.",
      "startOffset" : 118,
      "endOffset" : 138
    }, {
      "referenceID" : 37,
      "context" : "They compare these models to monolingual ones on 10 Universal Dependencies treebanks (Nivre et al., 2016).",
      "startOffset" : 85,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : "(4) is a similar example from Broersma (2009) where the word order is from the embedded language (English, in italics), and shows how the syntactic and lexical systems of the two languages are combined during production: lexical items of one language are ordered according to the syntax of the other.",
      "startOffset" : 30,
      "endOffset" : 46
    }, {
      "referenceID" : 58,
      "context" : "To develop an ASR system, three major components need to be built: a pronunciation dictionary, a language model and an acoustic model (AM) (Young, 1996).",
      "startOffset" : 139,
      "endOffset" : 152
    }, {
      "referenceID" : 53,
      "context" : "Vu et al. (2012) merge the phoneme sets based on the International Phonetic Alphabet (IPA) manual mapping to share training data between phonemes across languages.",
      "startOffset" : 0,
      "endOffset" : 17
    }, {
      "referenceID" : 56,
      "context" : "Weiner et al. (2012) show good improvement when the LID system is sufficiently accurate.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 54,
      "context" : "tem to create CS data from monolingual data (Vu et al., 2012).",
      "startOffset" : 44,
      "endOffset" : 61
    } ],
    "year" : 2016,
    "abstractText" : "This paper addresses challenges of Natural Language Processing (NLP) on non-canonical multilingual data in which two or more languages are mixed. It refers to code-switching which has become more popular in our daily life and therefore obtains an increasing amount of attention from the research community. We report our experience that covers not only core NLP tasks such as normalisation, language identification, language modelling, part-of-speech tagging and dependency parsing but also more downstream ones such as machine translation and automatic speech recognition. We highlight and discuss the key problems for each of the tasks with supporting examples from different language pairs and relevant previous work.",
    "creator" : "LaTeX with hyperref package"
  }
}