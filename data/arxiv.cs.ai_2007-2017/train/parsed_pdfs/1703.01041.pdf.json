{
  "name" : "1703.01041.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Large-Scale Evolution of Image Classifiers",
    "authors" : [ "Esteban Real", "Sherry Moore", "Andrew Selle", "Saurabh Saxena", "Yutaka Leon Suematsu", "Quoc Le", "Alex Kurakin" ],
    "emails" : [ "<ereal@google.com>." ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al. (2016a), among many others). It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016). One of the ear-\n1Google Brain, Mountain View, California, USA 2Google Research, Mountain View, California, USA. Correspondence to: Esteban Real <ereal@google.com>.\nliest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016). Despite the promising results, the deep learning community generally perceives evolutionary algorithms to be incapable of matching the accuracies of handdesigned models (Verbancsics & Harguess, 2013; Baker et al., 2016; Zoph & Le, 2016). In this paper, we show that it is possible to evolve such competitive models today, given enough computational power.\nWe used slightly-modified known evolutionary algorithms and scaled up the computation to unprecedented levels, as far as we know. This, together with a set of novel and intuitive mutation operators, allowed us to reach competitive accuracies on the CIFAR-10 dataset. This dataset was chosen because it requires large networks to reach high accuracies, thus presenting a computational challenge. We also took a small first step toward generalization and evolved networks on the CIFAR-100 dataset. In transitioning from CIFAR-10 to CIFAR-100, we did not modify any aspect or parameter of our algorithm. Our typical neuroevolution outcome on CIFAR-10 had a test accuracy with µ=94.1%, σ=0.4% @ 9×1019 FLOPs, and our top model (by validation accuracy) had a test accuracy of 94.6% @ 4×1020 FLOPs. On CIFAR-100, our single experiment resulted in a test accuracy of 76.3% @ 7×1019 FLOPs. As far as we know, these are the most accurate results obtained on these datasets by automated discovery methods that start from trivial initial conditions.\nThroughout this study, we placed special emphasis on the simplicity of the algorithm. In particular, it is a “oneshot” technique, in the sense that it produces a fully trained neural network that does not require any post-processing. It also has few impactful meta-parameters (i.e. parameters not optimized by the algorithm). Starting out with poor-performing linear models, the algorithm must evolve complex convolutional neural networks while navigating a fairly unrestricted search space: no fixed depth, arbitrary skip connections, and numerical parameters that have few restrictions on the values they can take. We also paid close attention to result reporting. Namely, we present the vari-\nar X\niv :1\n70 3.\n01 04\n1v 1\n[ cs\n.N E\n] 3\nM ar\n2 01\n7\nability in our results in addition to the top value, we account for researcher degrees of freedom (Simmons et al., 2011), we study the dependence on the meta-parameters, and we disclose the amount of computation necessary to reach the main results."
    }, {
      "heading" : "2. Related Work",
      "text" : "Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture. Stanley & Miikkulainen (2002) showed that it was advantageous to simultaneously evolve the architecture using the NEAT algorithm. NEAT has three kinds of mutations: (i) modify a weight, (ii) add a connection between existing nodes, or (iii) insert a node while splitting an existing connection. It also has a mechanism for recombining two models into one and a strategy to promote diversity known as fitness sharing (Goldberg et al., 1987). Evolutionary algorithms represent the models using an encoding that is convenient for their purpose— analogous to nature’s DNA. NEAT uses a direct encoding: every node and every connection is stored in the DNA. The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016). For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales. Also, Kim & Rigazio (2015) use an indirect encoding to improve the convolution filters in an initially highly-optimized fixed architecture.\nResearch on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988). Back-propagation\nand evolution can be combined as in Stanley et al. (2009), where only the structure is evolved. Their algorithm follows an alternation of architectural mutations and weight back-propagation. Similarly, Breuel & Shafait (2010) use this approach for hyper-parameter search. Fernando et al. (2016) also use back-propagation, allowing the trained weights to be inherited through the structural modifications.\nThe above studies create neural networks that are small in comparison to the typical modern architectures used for image classification (He et al., 2016; Huang et al., 2016a). Their focus is on the encoding or the efficiency of the evolutionary process, but not on the scale. When it comes to images, some neuro-evolution results reach the computational scale required to succeed on the MNIST dataset (LeCun et al., 1998). Yet, modern classifiers are often tested on realistic images, such as those in the CIFAR datasets (Krizhevsky & Hinton, 2009), which are much more challenging. These datasets require large models to achieve high accuracy.\nNon-evolutionary neuro-discovery methods have been more successful at tackling realistic image data. Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reaching a new state of the art at the time. Zoph & Le (2016) used reinforcement learning on a deeper fixed-length architecture. In their approach, a neural network—the “discoverer”—constructs a convolutional neural network—the “discovered”—one layer at a time. In addition to tuning layer parameters, they add and remove skip connections. This, together with some manual postprocessing, gets them very close to the (current) state of the art. (Additionally, they surpassed the state of the art on a sequence-to-sequence problem.) Baker et al. (2016) use\nQ-learning to also discover a network one layer at a time, but in their approach, the number of layers is decided by the discoverer. This is a desirable feature, as it would allow a system to construct shallow or deep solutions, as may be the requirements of the dataset at hand. Different datasets would not require specially tuning the algorithm. Comparisons among these methods are difficult because they explore very different search spaces and have very different initial conditions (Table 2).\nTangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper. Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of “supernetwork” with many parallel paths. Their algorithm then selects and ensembles paths in the super-network. Finally, canonical approaches to hyper-parameter search are grid search (used in Zagoruyko & Komodakis (2016), for example) and random search, the latter being the better of the two (Bergstra & Bengio, 2012).\nOur approach builds on previous work, with some important differences. We explore large model-architecture search spaces starting with basic initial conditions to avoid priming the system with information about what’s known to work for the specific dataset at hand. Our encoding is different from the neuro-evolution methods mentioned above: we use a simplified graph as our DNA, which is transformed to a full neural network graph for training and evaluation (Section 3). Some of the mutations acting on this DNA are reminiscent of NEAT. However, instead of\nsingle nodes, one mutation can insert whole layers—i.e. tens to hundreds of nodes at a time. We also allow for these layers to be removed, so that the evolutionary process can simplify an architecture in addition to complexifying it. Layer parameters are also mutable, but we do not prescribe a small set of possible values to choose from, to allow for a larger search space. We do not use fitness sharing or recombination in the spirit of simplicity. On the other hand, we do use back-propagation to optimize the weights, which can be inherited across mutations. Together with a learning rate mutation, this allows the exploration of the space of learning rate schedules, yielding fully trained models at the end of the evolutionary process (Section 3). Tables 1 and 2 compare our approach with hand-designed architectures and with other neuro-discovery techniques, respectively."
    }, {
      "heading" : "3. Methods",
      "text" : ""
    }, {
      "heading" : "3.1. Evolutionary Algorithm",
      "text" : "To automatically search for high-performing neural network architectures, we evolve a population of models. Each model—or individual—is a trained architecture. The model’s accuracy on a separate validation dataset is a measure of the individual’s quality or fitness. During each evolutionary step, a computer—a worker—chooses two individuals at random from this population and compares their fitnesses. The worst of the pair is immediately removed from the population—it is killed. The best of the pair is selected to be a parent, that is, to undergo reproduction. By this we mean that the worker creates a copy of the par-\nent and modifies this copy by applying a mutation, as described below. We will refer to this modified copy as the child. After the worker creates the child, it trains this child, evaluates it on the validation set, and puts it back into the population. The child then becomes alive—i.e. free to act as a parent. Our scheme, therefore, uses repeated pairwise competitions of random individuals, which makes it an example of tournament selection (Goldberg & Deb, 1991).\nUsing this strategy to search large spaces of complex image models requires considerable computation. To achieve scale, we developed a massively-parallel, lock-free infrastructure. Many workers operate asynchronously on different computers. They do not communicate directly with each other. Instead, they use a shared file-system, where the population is stored. The file-system contains directories that represent the individuals. Operations on these individuals, such as the killing of one, are represented as atomic renames on the directory2. Occasionally, a worker may concurrently modify the individual another worker is operating on. In this case, the affected worker simply gives up and tries again. The population size is 1000 individuals, unless otherwise stated. The number of workers is always 1 4 of the population size. To allow for long run-times with a limited amount of space, dead individuals’ directories are frequently garbage-collected."
    }, {
      "heading" : "3.2. Encoding and Mutations",
      "text" : "Individual architectures are encoded as a graph that we refer to as the DNA. In this graph, the vertices represent rank-3 tensors or activations. As is standard for a convolutional network, two of the dimensions of the tensor represent the spatial coordinates of the image and the third is a number of channels. Activation functions are applied at the vertices and can be either (i) batch-normalization (Ioffe & Szegedy, 2015) with rectified linear units (ReLUs) or (ii) plain linear units. The graph’s edges represent identity connections or convolutions and contain the mutable numerical parameters defining the convolution’s properties. When multiple edges are incident on a vertex, their spatial scales or numbers of channels may not coincide. However, the vertex must have a single size and number of channels for its activations. The inconsistent inputs must be resolved. Resolution is done by choosing one of the incoming edges as the primary one. We pick this primary edge to be the one that is not a skip connection. The activations coming from the non-primary edges are reshaped through zerothorder interpolation in the case of the size and through truncation/padding in the case of the number of channels, as in He et al. (2016). In addition to the graph, the learning-rate\n2The use of the file-name string to contain key information about the individual was inspired by Breuel & Shafait (2010), and it speeds up disk access enormously. In our case, the file name contains the state of the individual (alive, dead, training, etc.).\nvalue is also stored in the DNA.\nA child is similar but not identical to the parent because of the action of a mutation. In each reproduction event, the worker picks a mutation at random from a predetermined set. The set contains the following mutations:\n• ALTER-LEARNING-RATE (sampling details below). • IDENTITY (effectively means “keep training”). • RESET-WEIGHTS (sampled as in He et al. (2015), for\nexample). • INSERT-CONVOLUTION (inserts a convolution at a ran-\ndom location in the “convolutional backbone”, as in Figure 1. The inserted convolution has 3 × 3 filters, strides of 1 or 2 at random, number of channels same as input. May apply batch-normalization and ReLU activation or none at random). • REMOVE-CONVOLUTION. • ALTER-STRIDE (only powers of 2 are allowed). • ALTER-NUMBER-OF-CHANNELS (of random conv.). • FILTER-SIZE (horizontal or vertical at random, on ran-\ndom convolution, odd values only). • INSERT-ONE-TO-ONE (inserts a one-to-one/identity\nconnection, analogous to insert-convolution mutation). • ADD-SKIP (identity between random layers). • REMOVE-SKIP (removes random skip).\nA mutation that acts on a numerical parameter chooses the new value at random around the existing value. All sampling is from uniform distributions. For example, a mutation acting on a convolution with 10 output channels will result in a convolution having between 5 and 20 output channels (that is, half to twice the original value). All values within the range are possible. As a result, the models are not constrained to a number of filters that is known to work well. The same is true for all other parameters, yielding a “dense” search space. In the case of the strides, this applies to the log-base-2 of the value, to allow for activation shapes to match more easily3. In principle, there is also no upper limit to any of the parameters. All model depths are attainable, for example. Up to hardware constraints, the search space is unbounded. The dense and unbounded nature of the parameters result in the exploration of a truly large set of possible architectures."
    }, {
      "heading" : "3.3. Initial Conditions",
      "text" : "Every evolution experiment begins with a population of simple individuals that contain no convolutions and a learning rate of 0.1. They are all very bad performers. Each initial individual constitutes just a basic linear regression model. This conscious choice of poor initial conditions\n3For integer DNA parameters, we actually store and mutate a floating-point value. This allows multiple small mutations to have a cumulative effect in spite of integer round-off.\nforces evolution to make the discoveries by itself. The experimenter contributes mostly through the choice of mutations that demarcate a search space. Altogether, the use of poor initial conditions and a large search space limits the experimenter’s impact. In other words, it prevents the experimenter from “rigging” the experiment to succeed."
    }, {
      "heading" : "3.4. Training and Validation",
      "text" : "Training and validation is done on the CIFAR-10 dataset. This dataset consists of 50,000 training examples and 10,000 test examples, all of which are 32 x 32 color images labeled with 1 of 10 common object classes (Krizhevsky & Hinton, 2009). 5,000 of the training examples are held out in a validation set. The remaining 45,000 examples constitute our actual training set. The training set is augmented as in He et al. (2016). The CIFAR-100 dataset has the same number of dimensions, colors and examples as CIFAR-10, but uses 100 classes, making it much more challenging.\nTraining is done with TensorFlow (Abadi et al., 2016), using SGD with a momentum of 0.9 (Sutskever et al., 2013), a batch size of 50, and a weight decay of 0.0001. Each training runs for 25,600 steps, a value chosen to be brief enough so that each individual could be trained in a few seconds to a few hours, depending on model size. The target function is the cross-entropy. Once training is complete, a single evaluation on the validation set provides the accuracy to use as the individual’s fitness."
    }, {
      "heading" : "3.5. Computation cost",
      "text" : "To estimate computation costs, we identified the basic TensorFlow (TF) operations used by our model training and validation, like convolutions, generic matrix multiplications, etc. For each of these TF operations, we estimated the theoretical number of floating-point operations (FLOPs) required. This resulted in a map from TF operation to FLOPs, which is valid for all our experiments.\nFor each individual within an evolutionary experiment, we compute the total FLOPs incurred by the TF operations in its architecture, both during its training (Ft FLOPs) and during its validation (Fv FLOPs). Then we assign to the individual the cost FtNtE+FvNv , whereNt andNv are the number of training and validation examples, respectively, and E is the number of training epochs. The cost of the experiment is then the sum of the costs of all its individuals.\nWe only intend our FLOPs measurement as a coarse estimate only. We do not take into account input/output, data preprocessing, TF graph building or memory-copying operations. Some of these unaccounted operations take place once per training run or once per step and some have a component that is constant in the model size (such as diskaccess latency or input data cropping). We therefore expect\nthe estimate to be more useful for large architectures (for example, those with many convolutions)."
    }, {
      "heading" : "3.6. Weight Inheritance",
      "text" : "We need architectures that are trained to completion within an evolutionary experiment. If this does not happen, we are forced to retrain the best model at the end, possibly having to explore its hyper-parameters. Such extra exploration tends to depend on the details of the model being retrained. On the other hand, 25,600 steps are not enough to fully train each individual. Training a large model to completion is prohibitively slow for evolution. To resolve this dilemma, we allow the children to inherit the parents’ weights whenever possible. Namely, if a layer has matching shapes, the weights are preserved. Consequently, some mutations preserve all the weights (like the identity or learning-rate mutations), some preserve none (the weightresetting mutation), and most preserve some but not all. An example of the latter is the filter-size mutation: only the filters of the convolution being mutated will be discarded."
    }, {
      "heading" : "3.7. Reporting Methodology",
      "text" : "To avoid over-fitting, neither the evolutionary algorithm nor the neural network training ever see the testing set. Each time we refer to “the best model”, we mean the model with the highest validation accuracy. However, we always report the test accuracy. This applies not only to the choice of the best individual within an experiment, but also to the choice of the best experiment. Moreover, we only include experiments that we managed to reproduce, unless explicitly noted. Any statistical analysis was fully decided upon before seeing the results of the experiment reported, to avoid tailoring our analysis to our experimental data (Simmons et al., 2011)."
    }, {
      "heading" : "4. Experiments and Results",
      "text" : "We want to answer the following questions:\n• Can a simple one-shot evolutionary process start from trivial initial conditions and yield fully trained models that rival hand-designed architectures? • What are the variability in outcomes, the parallelizability, and the computation cost of the method? • Can an algorithm designed iterating on CIFAR-10 be applied, without any changes at all, to CIFAR-100 and still produce competitive models?\nWe used the algorithm in Section 3 to perform several experiments. Each experiment evolves a population in a few days, typified by the example in Figure 1. The figure also contains examples of the architectures discovered, which turn out to be surprisingly simple. Evolution attempts skip connections but frequently rejects them.\nTo get a sense of the variability in outcomes, we repeated the experiment 5 times. Across all 5 experiment runs, the best model by validation accuracy has a testing accuracy of 94.6%. Not all experiments reach the same accuracy, but they get close (µ=94.1%, σ=0.4). Fine differences in the experiment outcome may be somewhat distinguishable by validation accuracy (correlation coefficient = 0.894). The total amount of computation across all 5 experiments was 4×1020 FLOPs (or 9×1019 FLOPs on average per experiment). Each experiment was distributed over 250 parallel workers (Section 3.1). Figure 2 shows the progress of the experiments in detail.\nAs a control, we disabled the selection mechanism, thereby reproducing and killing random individuals. This is the form of random search that is most compatible with our infrastructure. The probability distributions for the parameters are implicitly determined by the mutations. This control only achieves an accuracy of 87.3% in the same amount of run time on the same hardware (Figure 2). The total amount of computation was 2×1017 FLOPs. The low FLOP count is a consequence of random search generating many small, inadequate models that train quickly but\nconsume roughly constant amounts of setup time. We attempted to minimize this overhead by avoiding unnecessary disk access operations, to no avail: too much overhead remains spent on a combination of neural network setup, data augmentation, and training step initialization.\nWe also ran a partial control where the weight-inheritance mechanism is disabled. This run also results in a lower accuracy (92.2%) in the same amount of time (Figure 2), using 9×1019 FLOPs. This shows that weight inheritance is important in the process.\nFinally, we applied our neuro-evolution algorithm, without any changes and with the same meta-parameters, to CIFAR-100. Our only experiment reached an accuracy of 76.3%, using 7× 1019 FLOPs. We did not attempt other datasets. Table 1 shows that both the CIFAR-10 and CIFAR-100 results are competitive with modern handdesigned networks."
    }, {
      "heading" : "5. Analysis",
      "text" : "Meta-parameters. We observe that populations evolve until they plateau at some local optimum (Figure 2). The fitness (i.e. validation accuracy) value at this optimum varies between experiments (Figure 2, inset). Since not all experiments reach the highest possible value, some populations are getting “trapped” at inferior local optima. This entrapment is affected by two important meta-parameters (i.e. parameters that are not optimized by the algorithm). These are the population size and the number of training steps per individual. Below we discuss them and consider their relationship to local optima.\nEffect of population size. Larger populations explore the space of models more thoroughly, and this helps reach better optima (Figure 3, left). Note, in particular, that a population of size 2 can get trapped at very low fitness values. Some intuition about this can be gained by considering the fate of a super-fit individual, i.e. an individual such that any\none architectural mutation reduces its fitness (even though a sequence of many mutations may improve it). In the case of a population of size 2, if the super-fit individual wins once, it will win every time. After the first win, it will produce a child that is one mutation away. By definition of super-fit, therefore, this child is inferior4. Consequently, in the next round of tournament selection, the super-fit individual competes against its child and wins again. This cycle repeats forever and the population is trapped. Even if a sequence of two mutations would allow for an “escape” from the local optimum, such a sequence can never take place. This is only a rough argument to heuristically suggest why a population of size 2 is easily trapped. More generally, Figure 3 (left) empirically demonstrates a benefit from an increase in population size. Theoretical analyses of this dependence are quite complex and assume very specific models of population dynamics; often larger populations are better at handling local optima, at least beyond a size threshold (Weinreich & Chao (2005) and references therein).\nLocal optima and mutation rate. Entrapment at a local optimum may mean a general lack of exploration in our search algorithm. To encourage more exploration, we increased the mutation rate. In more detail, we carried out experiments in which we first waited until the populations converged. Some reached higher fitnesses and others got\n4Except after identity or learning rate mutations, but these produce a child with the same architecture as the parent.\ntrapped at poor local optima. At this point, we modified the algorithm slightly: instead of performing 1 mutation at each reproduction event, we performed 5 mutations. We evolved with this increased mutation rate for a while and finally we switched back to the original single-mutation version. During the 5-mutation stage, some populations escape the local optimum, as in Figure 4 (top), and none get worse. Across populations, however, the escape was not frequent enough (8 out of 10) and took too long for us to propose this as an efficient technique to escape optima. An interesting direction for future work would be to study more elegant methods to manage the exploration vs. exploitation trade-off in large-scale neuro-evolution.\nEffect of number of training steps. The other metaparameter is the number T of training steps for each individual. Accuracy increases with T (Figure 3, right). Larger T means an individual needs to undergo fewer identity mutations to reach a given level of training.\nLocal optima and weight resetting. The identity mutation offers a mechanism for populations to get trapped in local optima. Some individuals may get trained more than their peers just because they happen to have undergone more identity mutations. It may, therefore, occur that a poor architecture may become more accurate than potentially better architectures that still need more training. In the extreme case, the well-trained poor architecture may become a super-fit individual and take over the population. Suspecting this scenario, we performed experiments in which we simultaneously reset all the weights in a population that had plateaued. The simultaneous reset should put all the individuals on the same footing, so individuals that had accidentally trained more no longer have the unfair advantage. Indeed, the results matched our expectation. The populations suffer a temporary degradation in fitness immediately after the reset, as the individuals need to retrain. Later, however, the populations end up reaching higher optima (for example, Figure 4, bottom). Across 10 experiments, we find that three successive resets tend to cause improvement (p < 0.001). We mention this effect merely as evidence of this particular drawback of weight inheritance. In our main results, we circumvented the problem by using longer training times and larger populations. Future work may explore more efficient solutions."
    }, {
      "heading" : "6. Conclusion",
      "text" : "In this paper we have shown that (i) neuro-evolution is capable of constructing large, accurate networks for two challenging and popular image classification benchmarks; (ii) neuro-evolution can do this starting from trivial initial conditions while searching a very large space; (iii) the process described, once started, needs no participation from the experimenter; and (iv) the process yields fully trained models. To train models to completion, weight inheritance was key (Sections 3.6). In contrast to reinforcement learning, evolution provides a natural framework for weight inheritance: mutations can be constructed so as to guarantee a large degree of similarity between the original and the mutated models—as we have done.\nWhile in this work we did not focus on reducing computation costs, we hope that future improvements to the algorithms and the hardware will allow for more economical implementations. In that case, evolution would become an appealing approach to neuro-discovery for reasons beyond the scope of this paper. For example, it “hits the ground running”, improving on arbitrary initial models as soon as\nthe experiment begins. The mutations used can implement recent advances in the field and can be introduced without having to restart an experiment. Furthermore, recombination can merge improvements developed by different individuals, even if they come from other populations. Moreover, it may be possible to combine neuro-evolution with other automatic architecture discovery methods."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We wish to thank Vincent Vanhoucke, Megan Kacholia, Rajat Monga and especially Jeff Dean for their support and valuable input; Geoffrey Hinton, Samy Bengio, Tom Breuel, Mark DePristo, Martin Abadi, Noam Shazeer, Yoram Singer, Dumitru Erhan, Pierre Sermanet, Xiaoqiang Zheng and Vijay Vasudevan for helpful discussions; Thomas Breuel, Xin Pan and Andy Davis for coding contributions; Shan Carter for technical advice; and the larger Google Brain team for help with TensorFlow and training vision models."
    } ],
    "references" : [ {
      "title" : "Designing neural network architectures using reinforcement learning",
      "author" : [ "Baker", "Bowen", "Gupta", "Otkrist", "Naik", "Nikhil", "Raskar", "Ramesh" ],
      "venue" : "arXiv preprint arXiv:1611.02167,",
      "citeRegEx" : "Baker et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 2016
    }, {
      "title" : "Evolving memory cell structures for sequence learning",
      "author" : [ "Bayer", "Justin", "Wierstra", "Daan", "Togelius", "Julian", "Schmidhuber", "Jürgen" ],
      "venue" : "In International Conference on Artificial Neural Networks,",
      "citeRegEx" : "Bayer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Bayer et al\\.",
      "year" : 2009
    }, {
      "title" : "Random search for hyper-parameter optimization",
      "author" : [ "Bergstra", "James", "Bengio", "Yoshua" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Bergstra et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Bergstra et al\\.",
      "year" : 2012
    }, {
      "title" : "Automlp: Simple, effective, fully automated learning rate and size adjustment",
      "author" : [ "Breuel", "Thomas", "Shafait", "Faisal" ],
      "venue" : "In The Learning Workshop. Utah,",
      "citeRegEx" : "Breuel et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Breuel et al\\.",
      "year" : 2010
    }, {
      "title" : "Convolution by evolution: Differentiable pattern producing networks",
      "author" : [ "Fernando", "Chrisantha", "Banarse", "Dylan", "Reynolds", "Malcolm", "Besse", "Frederic", "Pfau", "David", "Jaderberg", "Max", "Lanctot", "Marc", "Wierstra", "Daan" ],
      "venue" : "In Proceedings of the 2016 on Genetic and Evolutionary",
      "citeRegEx" : "Fernando et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Fernando et al\\.",
      "year" : 2016
    }, {
      "title" : "Genetic synthesis of modular neural networks",
      "author" : [ "Gruau", "Frederic" ],
      "venue" : "In Proceedings of the 5th International Conference on Genetic Algorithms,",
      "citeRegEx" : "Gruau and Frederic.,? \\Q1993\\E",
      "shortCiteRegEx" : "Gruau and Frederic.",
      "year" : 1993
    }, {
      "title" : "Learning both weights and connections for efficient neural network",
      "author" : [ "Han", "Song", "Pool", "Jeff", "Tran", "John", "Dally", "William" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Han et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2015
    }, {
      "title" : "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification",
      "author" : [ "He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian" ],
      "venue" : "In Proceedings of the IEEE international conference on computer vision,",
      "citeRegEx" : "He et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian" ],
      "venue" : "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "He et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Densely connected convolutional networks",
      "author" : [ "Huang", "Gao", "Liu", "Zhuang", "Weinberger", "Kilian Q", "van der Maaten", "Laurens" ],
      "venue" : "arXiv preprint arXiv:1608.06993,",
      "citeRegEx" : "Huang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep networks with stochastic depth",
      "author" : [ "Huang", "Gao", "Sun", "Yu", "Liu", "Zhuang", "Sedra", "Daniel", "Weinberger", "Kilian Q" ],
      "venue" : "In European Conference on Computer Vision,",
      "citeRegEx" : "Huang et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2016
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Ioffe", "Sergey", "Szegedy", "Christian" ],
      "venue" : "arXiv preprint arXiv:1502.03167,",
      "citeRegEx" : "Ioffe et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ioffe et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep clustered convolutional kernels",
      "author" : [ "Kim", "Minyoung", "Rigazio", "Luca" ],
      "venue" : "arXiv preprint arXiv:1503.01824,",
      "citeRegEx" : "Kim et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning multiple layers of features from tiny images",
      "author" : [ "Krizhevsky", "Alex", "Hinton", "Geoffrey" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2009
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing",
      "author" : [ "Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E" ],
      "venue" : null,
      "citeRegEx" : "Krizhevsky et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "The mnist database of handwritten digits",
      "author" : [ "LeCun", "Yann", "Cortes", "Corinna", "Burges", "Christopher JC" ],
      "venue" : null,
      "citeRegEx" : "LeCun et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "LeCun et al\\.",
      "year" : 1998
    }, {
      "title" : "Designing neural networks using genetic algorithms",
      "author" : [ "Miller", "Geoffrey F", "Todd", "Peter M", "Hegde", "Shailesh U" ],
      "venue" : "In Proceedings of the third international conference on Genetic algorithms,",
      "citeRegEx" : "Miller et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 1989
    }, {
      "title" : "Simple evolutionary optimization can rival stochastic gradient descent in neural networks",
      "author" : [ "Morse", "Gregory", "Stanley", "Kenneth O" ],
      "venue" : "In Proceedings of the 2016 on Genetic and Evolutionary Computation Conference,",
      "citeRegEx" : "Morse et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Morse et al\\.",
      "year" : 2016
    }, {
      "title" : "Evolving multimodal controllers with hyperneat",
      "author" : [ "Pugh", "Justin K", "Stanley", "Kenneth O" ],
      "venue" : "In Proceedings of the 15th annual conference on Genetic and evolutionary computation,",
      "citeRegEx" : "Pugh et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Pugh et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning representations by back-propagating errors",
      "author" : [ "Rumelhart", "David E", "Hinton", "Geoffrey E", "Williams", "Ronald J" ],
      "venue" : "Cognitive modeling,",
      "citeRegEx" : "Rumelhart et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Rumelhart et al\\.",
      "year" : 1988
    }, {
      "title" : "Convolutional neural fabrics",
      "author" : [ "Saxena", "Shreyas", "Verbeek", "Jakob" ],
      "venue" : "In Advances In Neural Information Processing Systems,",
      "citeRegEx" : "Saxena et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Saxena et al\\.",
      "year" : 2016
    }, {
      "title" : "False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant",
      "author" : [ "Simmons", "Joseph P", "Nelson", "Leif D", "Simonsohn", "Uri" ],
      "venue" : "Psychological science,",
      "citeRegEx" : "Simmons et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Simmons et al\\.",
      "year" : 2011
    }, {
      "title" : "Very deep convolutional networks for large-scale image recognition",
      "author" : [ "Simonyan", "Karen", "Zisserman", "Andrew" ],
      "venue" : "arXiv preprint arXiv:1409.1556,",
      "citeRegEx" : "Simonyan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Simonyan et al\\.",
      "year" : 2014
    }, {
      "title" : "Practical bayesian optimization of machine learning algorithms",
      "author" : [ "Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "Snoek et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Snoek et al\\.",
      "year" : 2012
    }, {
      "title" : "Striving for simplicity: The all convolutional net",
      "author" : [ "Springenberg", "Jost Tobias", "Dosovitskiy", "Alexey", "Brox", "Thomas", "Riedmiller", "Martin" ],
      "venue" : "arXiv preprint arXiv:1412.6806,",
      "citeRegEx" : "Springenberg et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Springenberg et al\\.",
      "year" : 2014
    }, {
      "title" : "Compositional pattern producing networks: A novel abstraction of development",
      "author" : [ "Stanley", "Kenneth O" ],
      "venue" : "Genetic programming and evolvable machines,",
      "citeRegEx" : "Stanley and O.,? \\Q2007\\E",
      "shortCiteRegEx" : "Stanley and O.",
      "year" : 2007
    }, {
      "title" : "Evolving neural networks through augmenting topologies",
      "author" : [ "Stanley", "Kenneth O", "Miikkulainen", "Risto" ],
      "venue" : "Evolutionary computation,",
      "citeRegEx" : "Stanley et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Stanley et al\\.",
      "year" : 2002
    }, {
      "title" : "A hypercube-based encoding for evolving largescale neural networks",
      "author" : [ "Stanley", "Kenneth O", "D’Ambrosio", "David B", "Gauci", "Jason" ],
      "venue" : "Artificial life,",
      "citeRegEx" : "Stanley et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Stanley et al\\.",
      "year" : 2009
    }, {
      "title" : "On the importance of initialization and momentum in deep learning",
      "author" : [ "Sutskever", "Ilya", "Martens", "James", "Dahl", "George E", "Hinton", "Geoffrey E" ],
      "venue" : "ICML (3),",
      "citeRegEx" : "Sutskever et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2013
    }, {
      "title" : "Generative neuroevolution for deep learning",
      "author" : [ "Verbancsics", "Phillip", "Harguess", "Josh" ],
      "venue" : "arXiv preprint arXiv:1312.5355,",
      "citeRegEx" : "Verbancsics et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Verbancsics et al\\.",
      "year" : 2013
    }, {
      "title" : "Rapid evolutionary escape by large populations from local fitness peaks is likely in nature",
      "author" : [ "Weinreich", "Daniel M", "Chao", "Lin" ],
      "venue" : null,
      "citeRegEx" : "Weinreich et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Weinreich et al\\.",
      "year" : 2005
    }, {
      "title" : "Planet-photo geolocation with convolutional neural networks",
      "author" : [ "Weyand", "Tobias", "Kostrikov", "Ilya", "Philbin", "James" ],
      "venue" : "In European Conference on Computer Vision,",
      "citeRegEx" : "Weyand et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Weyand et al\\.",
      "year" : 2016
    }, {
      "title" : "Wide residual networks",
      "author" : [ "Zagoruyko", "Sergey", "Komodakis", "Nikos" ],
      "venue" : "arXiv preprint arXiv:1605.07146,",
      "citeRegEx" : "Zagoruyko et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zagoruyko et al\\.",
      "year" : 2016
    }, {
      "title" : "An empirical exploration of recurrent network architectures",
      "author" : [ "Zaremba", "Wojciech" ],
      "venue" : null,
      "citeRegEx" : "Zaremba and Wojciech.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zaremba and Wojciech.",
      "year" : 2015
    }, {
      "title" : "Neural architecture search with reinforcement learning",
      "author" : [ "Zoph", "Barret", "Le", "Quoc V" ],
      "venue" : "arXiv preprint arXiv:1611.01578,",
      "citeRegEx" : "Zoph et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Zoph et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016).",
      "startOffset" : 108,
      "endOffset" : 167
    }, {
      "referenceID" : 31,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016).",
      "startOffset" : 108,
      "endOffset" : 167
    }, {
      "referenceID" : 23,
      "context" : "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).",
      "startOffset" : 139,
      "endOffset" : 239
    }, {
      "referenceID" : 6,
      "context" : "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).",
      "startOffset" : 139,
      "endOffset" : 239
    }, {
      "referenceID" : 0,
      "context" : "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).",
      "startOffset" : 139,
      "endOffset" : 239
    }, {
      "referenceID" : 5,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al.",
      "startOffset" : 109,
      "endOffset" : 435
    }, {
      "referenceID" : 5,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al.",
      "startOffset" : 109,
      "endOffset" : 464
    }, {
      "referenceID" : 5,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al.",
      "startOffset" : 109,
      "endOffset" : 487
    }, {
      "referenceID" : 5,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al.",
      "startOffset" : 109,
      "endOffset" : 505
    }, {
      "referenceID" : 5,
      "context" : "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al. (2016a), among many others).",
      "startOffset" : 109,
      "endOffset" : 527
    }, {
      "referenceID" : 16,
      "context" : "liest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).",
      "startOffset" : 57,
      "endOffset" : 293
    }, {
      "referenceID" : 1,
      "context" : "liest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).",
      "startOffset" : 57,
      "endOffset" : 293
    }, {
      "referenceID" : 27,
      "context" : "liest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).",
      "startOffset" : 57,
      "endOffset" : 293
    }, {
      "referenceID" : 4,
      "context" : "liest such “neuro-discovery” methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).",
      "startOffset" : 57,
      "endOffset" : 293
    }, {
      "referenceID" : 0,
      "context" : "Despite the promising results, the deep learning community generally perceives evolutionary algorithms to be incapable of matching the accuracies of handdesigned models (Verbancsics & Harguess, 2013; Baker et al., 2016; Zoph & Le, 2016).",
      "startOffset" : 169,
      "endOffset" : 236
    }, {
      "referenceID" : 9,
      "context" : "The † indicates a result reported by Huang et al. (2016b) instead of the original author.",
      "startOffset" : 37,
      "endOffset" : 58
    }, {
      "referenceID" : 9,
      "context" : "The † indicates a result reported by Huang et al. (2016b) instead of the original author. Much of this table was based on that presented in Huang et al. (2016a).",
      "startOffset" : 37,
      "endOffset" : 161
    }, {
      "referenceID" : 21,
      "context" : "ability in our results in addition to the top value, we account for researcher degrees of freedom (Simmons et al., 2011), we study the dependence on the meta-parameters, and we disclose the amount of computation necessary to reach the main results.",
      "startOffset" : 98,
      "endOffset" : 120
    }, {
      "referenceID" : 16,
      "context" : "Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 27,
      "context" : "The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016).",
      "startOffset" : 99,
      "endOffset" : 200
    }, {
      "referenceID" : 4,
      "context" : "The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016).",
      "startOffset" : 99,
      "endOffset" : 200
    }, {
      "referenceID" : 27,
      "context" : "For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales.",
      "startOffset" : 22,
      "endOffset" : 59
    }, {
      "referenceID" : 15,
      "context" : "Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture. Stanley & Miikkulainen (2002) showed that it was advantageous to simultaneously evolve the architecture using the NEAT algorithm.",
      "startOffset" : 39,
      "endOffset" : 165
    }, {
      "referenceID" : 4,
      "context" : ", 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016). For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales. Also, Kim & Rigazio (2015) use an indirect encoding to improve the convolution filters in an initially highly-optimized fixed architecture.",
      "startOffset" : 51,
      "endOffset" : 230
    }, {
      "referenceID" : 19,
      "context" : "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988).",
      "startOffset" : 180,
      "endOffset" : 204
    }, {
      "referenceID" : 18,
      "context" : "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988). Back-propagation and evolution can be combined as in Stanley et al. (2009), where only the structure is evolved.",
      "startOffset" : 181,
      "endOffset" : 281
    }, {
      "referenceID" : 18,
      "context" : "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988). Back-propagation and evolution can be combined as in Stanley et al. (2009), where only the structure is evolved. Their algorithm follows an alternation of architectural mutations and weight back-propagation. Similarly, Breuel & Shafait (2010) use this approach for hyper-parameter search.",
      "startOffset" : 181,
      "endOffset" : 449
    }, {
      "referenceID" : 4,
      "context" : "Fernando et al. (2016) also use back-propagation, allowing the trained weights to be inherited through the structural modifications.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 8,
      "context" : "The above studies create neural networks that are small in comparison to the typical modern architectures used for image classification (He et al., 2016; Huang et al., 2016a).",
      "startOffset" : 136,
      "endOffset" : 174
    }, {
      "referenceID" : 15,
      "context" : "When it comes to images, some neuro-evolution results reach the computational scale required to succeed on the MNIST dataset (LeCun et al., 1998).",
      "startOffset" : 125,
      "endOffset" : 145
    }, {
      "referenceID" : 22,
      "context" : "Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reaching a new state of the art at the time.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 22,
      "context" : "Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reaching a new state of the art at the time. Zoph & Le (2016) used reinforcement learning on a deeper fixed-length architecture.",
      "startOffset" : 0,
      "endOffset" : 168
    }, {
      "referenceID" : 0,
      "context" : ") Baker et al. (2016) use",
      "startOffset" : 2,
      "endOffset" : 22
    }, {
      "referenceID" : 1,
      "context" : "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper.",
      "startOffset" : 73,
      "endOffset" : 108
    }, {
      "referenceID" : 1,
      "context" : "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper. Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of “supernetwork” with many parallel paths.",
      "startOffset" : 74,
      "endOffset" : 215
    }, {
      "referenceID" : 1,
      "context" : "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper. Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of “supernetwork” with many parallel paths. Their algorithm then selects and ensembles paths in the super-network. Finally, canonical approaches to hyper-parameter search are grid search (used in Zagoruyko & Komodakis (2016), for example) and random search, the latter being the better of the two (Bergstra & Bengio, 2012).",
      "startOffset" : 74,
      "endOffset" : 505
    }, {
      "referenceID" : 7,
      "context" : "The activations coming from the non-primary edges are reshaped through zerothorder interpolation in the case of the size and through truncation/padding in the case of the number of channels, as in He et al. (2016). In addition to the graph, the learning-rate",
      "startOffset" : 197,
      "endOffset" : 214
    }, {
      "referenceID" : 7,
      "context" : "• RESET-WEIGHTS (sampled as in He et al. (2015), for example).",
      "startOffset" : 31,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "The training set is augmented as in He et al. (2016). The CIFAR-100 dataset has the same number of dimensions, colors and examples as CIFAR-10, but uses 100 classes, making it much more challenging.",
      "startOffset" : 36,
      "endOffset" : 53
    }, {
      "referenceID" : 28,
      "context" : "9 (Sutskever et al., 2013), a batch size of 50, and a weight decay of 0.",
      "startOffset" : 2,
      "endOffset" : 26
    }, {
      "referenceID" : 21,
      "context" : "Any statistical analysis was fully decided upon before seeing the results of the experiment reported, to avoid tailoring our analysis to our experimental data (Simmons et al., 2011).",
      "startOffset" : 159,
      "endOffset" : 181
    } ],
    "year" : 2017,
    "abstractText" : "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.",
    "creator" : "LaTeX with hyperref package"
  }
}