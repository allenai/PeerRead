{"conference": "ICLR 2017 conference submission", "title": "Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks", "abstract": "We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods.", "reviews": [{"is_meta_review": true, "comments": "After rebuttal:\n\nThanks for reporting the AlexNet results. The fact that they are not great is not so bad by itself, and as the authors mention, it would be interesting to understand why this happens. But the fact that these results  were not in the paper (and in fact still are not there) is disturbing. Moreover, some claims in the paper look wrong in the light of these results, for example:\n- \"This suggests that our gains stem from the CC-GAN method rather than the use of a better architecture.\"\n- \"Since discrimination of real/fake in-paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in-filling, it is not surprising that we are able to exceed the performance of Pathak et al. (2016) on PASCAL classification.\"\n\nThese statements, and possibly other parts of the paper, have to be updated. I think the paper cannot be published in its current form. Perhaps after a revision.\n\n--------\nInitial review:\n\nThe paper demonstrates an application of generative adversarial networks (GAN) to unsupervised feature learning. The authors show that the representation learned by the discriminator of a conditional GAN trained for image inpainting performs well on image classification. As a side-effect, fairly convincing inpaintings are produced.\n\nThe proposed method combines two existing ideas: using the discriminator of a GAN as a feature learner [Radford et al. 2015] and performing unsupervised feature learning with image inpainting [Pathak et al. 2016]. Therefore conceptual novelty of the paper is limited. On the plus side, the authors implement their idea well and demonstrate state-of-the-art results on STL-10 and good results on Pascal VOC (although Pascal experiments are incomplete, see below). Overall, I am in the borderline mode, and I will gladly raise the score if the authors address my concerns regarding the experiments.\n\n1) Experimental evaluation on Pascal VOC is not quite satisfactory. Comparison with prior work is unfair because the network architecture used by the authors (VGG) is different from the architecture used by all existing methods (AlexNet). It is great that the authors do not try to hide this fact in the paper, but I do not understand why the authors are not willing to simply run their method with AlexNet architecture, although two commenters asked them to do so. Such an experiment would strongly support authors\u2019 claims. Current reasoning that \u201cwe thought it reasonable to use more current models while making the difference clear\u201d is not convincing. It is great that better architectures lead to better results, but it is also very important to properly compare to prior work. On a related topic, Doersch et al. also tried using VGG architecture, would it be possible to compare to that? Yet another question: why are you not comparing to [Noroozi&Favaro, ECCV 2016] ? I would also like the authors to address the comment by Richard Zhang.\n\n2) Qualitative inpainting results are incomplete: comparison with previous methods (for instance, [Pathak et al 2016]) is missing, and it is impossible to compare different versions of the proposed method because different images are used for different variants. I realize there may be too little space in the main paper to show all the results, but many more results should be shown in the supplementary material. Quantitative results are missing. Currently the inpainting results are just interesting pictures to look at, but they do not add as much to the paper as they could.", "IS_META_REVIEW": true}, {"TITLE": "ICLR committee final decision", "OTHER_KEYS": "ICLR 2017 pcs", "comments": "There has been prior work on semi-supervised GAN, though this paper is the first context conditional variant. The novelty of the approach was questioned by two of the reviewers, as the approach seems more incremental. Furthermore, it would have been helpful if the issues one of the reviewer had with statements in the document were addressed.", "IS_META_REVIEW": false, "DATE": "06 Feb 2017", "is_meta_review": false}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "TITLE": "review", "is_meta_review": false, "comments": "This paper presents a semi-supervised algorithm for regularizing deep convolutional neural networks.\nThey propose an adversarial approach for image inpainting where the discriminator learns to identify whether an inpainted image comes from the data distribution or the generator, while at the same time it learns to recognize objects in an image from the data distribution. In experiments, they show the usefulness of their algorithm in which the features learned by the discriminator result in comparable or better object recognition performance to the reported state-of-the-art in two datasets.\nOverall, the proposed idea seems a simple yet an effective way for regularize CNNs to improve the classification performance. ", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "21 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "TITLE": "Review", "is_meta_review": false, "comments": "This paper proposes a method to incorporate super-resolution and inpainting in the GAN framework for semi-supervised learning using the GAN discriminative features on larger images.\n\nThe core idea of the paper is not very novel. The usefulness of the GAN discriminative features for semi-supervised learning is already established in previous works such as CatGAN, DCGAN and Salimans et al. However this paper does a good job in actually getting the semi-supervised GAN framework working on larger images such as STL-10 and Pascal datasets using the proposed context conditioning approach, and achieves the state-of-the-art on these datasets.\n\nI think that the authors should provide the SSL-GAN baseline for the PASCAL dataset as it is very important to compare the contribution of the context conditioning idea with the standard way of using GAN for semi-supervised learning, i.e., SSL-GAN. I can't see why the SSL-GAN can not be applied to the 64*64 and 96*96 version of the Pascal dataset (Table 3). If they have trouble training the vanilla GAN on Pascal even on the 64*64 image size, this should be mentioned in the paper and be explained. I am concerned about this specially because CC-GAN almost matches the SSL-GAN baseline on STL-10, and CC-GAN2, to me, seems like a hacky way to improve upon the core CC-GAN idea. So it would be great to compare CC-GAN and SSL-GAN on some other dataset, even if it is a downsampled PASCAL dataset.", "IS_META_REVIEW": false, "RECOMMENDATION": 6, "DATE": "19 Dec 2016", "REVIEWER_CONFIDENCE": 4}, {"OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "TITLE": "Final review", "is_meta_review": false, "comments": "\nAfter rebuttal:\n\nThanks for reporting the AlexNet results. The fact that they are not great is not so bad by itself, and as the authors mention, it would be interesting to understand why this happens. But the fact that these results  were not in the paper (and in fact still are not there) is disturbing. Moreover, some claims in the paper look wrong in the light of these results, for example:\n- \"This suggests that our gains stem from the CC-GAN method rather than the use of a better architecture.\"\n- \"Since discrimination of real/fake in-paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in-filling, it is not surprising that we are able to exceed the performance of Pathak et al. (2016) on PASCAL classification.\"\n\nThese statements, and possibly other parts of the paper, have to be updated. I think the paper cannot be published in its current form. Perhaps after a revision.\n\n--------\nInitial review:\n\nThe paper demonstrates an application of generative adversarial networks (GAN) to unsupervised feature learning. The authors show that the representation learned by the discriminator of a conditional GAN trained for image inpainting performs well on image classification. As a side-effect, fairly convincing inpaintings are produced.\n\nThe proposed method combines two existing ideas: using the discriminator of a GAN as a feature learner [Radford et al. 2015] and performing unsupervised feature learning with image inpainting [Pathak et al. 2016]. Therefore conceptual novelty of the paper is limited. On the plus side, the authors implement their idea well and demonstrate state-of-the-art results on STL-10 and good results on Pascal VOC (although Pascal experiments are incomplete, see below). Overall, I am in the borderline mode, and I will gladly raise the score if the authors address my concerns regarding the experiments.\n\n1) Experimental evaluation on Pascal VOC is not quite satisfactory. Comparison with prior work is unfair because the network architecture used by the authors (VGG) is different from the architecture used by all existing methods (AlexNet). It is great that the authors do not try to hide this fact in the paper, but I do not understand why the authors are not willing to simply run their method with AlexNet architecture, although two commenters asked them to do so. Such an experiment would strongly support authors\u2019 claims. Current reasoning that \u201cwe thought it reasonable to use more current models while making the difference clear\u201d is not convincing. It is great that better architectures lead to better results, but it is also very important to properly compare to prior work. On a related topic, Doersch et al. also tried using VGG architecture, would it be possible to compare to that? Yet another question: why are you not comparing to [Noroozi&Favaro, ECCV 2016] ? I would also like the authors to address the comment by Richard Zhang.\n\n2) Qualitative inpainting results are incomplete: comparison with previous methods (for instance, [Pathak et al 2016]) is missing, and it is impossible to compare different versions of the proposed method because different images are used for different variants. I realize there may be too little space in the main paper to show all the results, but many more results should be shown in the supplementary material. Quantitative results are missing. Currently the inpainting results are just interesting pictures to look at, but they do not add as much to the paper as they could.", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "DATE": "16 Dec 2016 (modified: 24 Jan 2017)", "REVIEWER_CONFIDENCE": 4}, {"TITLE": "question for SSL experiments", "OTHER_KEYS": "(anonymous)", "comments": "Nice work! I am curious about the SSL experiments: since ", "IS_META_REVIEW": false, "DATE": "08 Dec 2016", "is_meta_review": false}, {"TITLE": "questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer3", "comments": "", "IS_META_REVIEW": false, "DATE": "05 Dec 2016", "is_meta_review": false}, {"TITLE": "few questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer2", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}, {"TITLE": "pre-review questions", "OTHER_KEYS": "ICLR 2017 conference AnonReviewer1", "comments": "", "IS_META_REVIEW": false, "DATE": "02 Dec 2016", "is_meta_review": false}], "SCORE": 5, "authors": "Emily Denton, Sam Gross, Rob Fergus", "KEYWORDS": "Training GANs to in-paint images produces feature representations that yield leading results on various benchmarks.", "accepted": false, "id": ""}
