{
  "name" : "1501.00653.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Hostile Intent Identification by Movement Pattern Analysis: Using Artificial Neural Networks",
    "authors" : [ "Souham Biswas", "Manisha J. Nene" ],
    "emails" : [ "souhambiswas@outlook.com", "mjnene@diat.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords—Hostility; Neural Networks; Artificial Intelligence; Defence; Maritime\nI. INTRODUCTION One of the most daunting tasks pertaining to the defence forces of a country has always been the effective identification and elimination of threats which interfere with the interests or the security of the nation. In situations of conflict, the fallibility of human judgement caused by stress or any such factor in determining the hostility of a given target can prove to be fatal and might result in considerable loss of resources. Therefore, a need to automate the same is highly desirable.\nThe term “hostility” is inherently multifarious. The meaning depends upon the observer. This implies that, there are a considerable number of variables pertaining to this characteristic, if viewed analytically. Every day, new attack techniques are observed and defence tactics are being innovated. It is impossible to define an all-encompassing set of parameters or variables which would successfully quantify “hostility” in a general sense. However, there is one parameter of hostility pertaining to the object in question that spans over the others and is potentially impervious to the nature of the observer; the location/existence of the object under observation. The location of a given object can be grilled to obtain a multitude of characteristics from which certain behavioural traits can be extracted and analysed. Although, a perfect analytical solution to this problem statement is far-\nfetched as of now, a more promising approach is to incorporate the way humans try to solve this problem into a machine; to include the element of “intuition”. The approach posited here draws on the fact that the human mind is a continuously evolving palimpsest of neurons, which adapt and evolve to any situation. Hence, the deployment of artificial neural networks; even more for their reputation for being extremely fault tolerant which is of paramount importance when considering such problems with high margins for error.\nBackground and related work: During the literature survey, it was observed that a small set of analytical approaches do exist [1], [5], which address this problem. The most prominent of which, is the US Patent termed “Detection of Hostile Intent from Movement Patterns” [1]. But, what these approaches lack is the trait to adapt according to situation. It is not possible to discretely classify a given behaviour as “hostile” or “not hostile”. Therefore, it is imperative that the system intended to make that classification, learn how to do so by itself and adapt in pace with the constantly evolving attack/defence tactics.\nPresented in this paper is an approach which seeks to make for the shortcomings faced by the present systems. The paper is organized as follows: Section II describes the various parameters and assumptions involved and basis of the methodology. Section III enumerates the actual methodology, critical parameters, algorithms and the processes involved. In Section IV, simulation results have been elucidated. Finally, Section V summarises and concludes the proposed work and mentions the scope for future work.\nII. PROPOSED WORK"
    }, {
      "heading" : "A. Basis of Hostility Detection",
      "text" : "One of the most prominent characteristics of the human brain is the tendency to correlate between new information and previous “experiences” to draw conclusions [7]. The degree of this correlation and the subsequent processing of the same allow us to make fuzzy predictions [6] or in one way, form an intuition. The notion of hostility in general, lies in previous experiences of such situations endured by an individual. When presented with a scenario for hostility detection, the brain tries to discern the degree of similarity between the new situation and a catalogue of “hostile” labelled situations previously\nencountered. A high similarity calls for evasive measures. To summarize, one takes steps to ensure that the sequence of events which led to the previously sustained events of hostility do not repeat. To model this as an automated solution, we consider neural networks. We follow a similar process of training the network that is; an expansive dataset of known hostile situations is made incident on the network. As the training proceeds, the network tends to form its own notions for enumerating hostilities. In other words, an artificial sense of intuition is formed."
    }, {
      "heading" : "B. Assumptions & Parameters Involved",
      "text" : "To parameterize a given situation for neural network training [4], we consider the locations of the objects. This quantity maybe in parametric, polar or any other co-ordinate form. The definitions of a few prominent terminologies are given below-\n• Area of Observation: It is the physical region which is being monitored for hostile activities. Practically, this can translate to a given region on the shore, the range of a radar, etc.\n• Object: Any entity inside the area of observation which will be subject to probation for determination of hostility is termed as “object”.\n• Hostility: It is the probability that an object will commit an act of hostility in the immediate future.\nOther parameters derived from the locations of objects like the speed and direction of object, density of objects in a given area etc. may also be computed and added as inputs to the neural network. The shape of the area of observation does not pose any constraint in location determination.\nIII. METHODOLOGY The system will take inputs as the locations of the multiple objects inside the area of observation in the form of X and Y coordinates. The neural network being utilized will be a 2- layer feed forward network [8] with sigmoid function (1) as the activation function.\n. (1) The datasets involved in training are of the following types-\n• Raw Dataset – This contains the records of locations of all the objects in the area of observation and their corresponding probabilities of hostility.\n• Normalized Dataset – This is the dataset which is actually used to train the neural network. Normalized Dataset is obtained by generating all the permutations of the raw dataset.\nSystem Variables and Relations-\n• : Number of objects inside the area of observation.\n• : Number of entries in raw dataset having dataset index “ ” ( raw dataset).\n• : Number of training datasets.\n• : Number of entries in normalized dataset having dataset index “ ” ( raw dataset).\n• : X coordinate of object having index “ ” in raw dataset at observation index “ ”.\n• : X coordinate of object having index “ ” in normalized dataset at observation index “ ”.\n• : Y coordinate of object having index “ ” in raw dataset at observation index “ ”.\n• : Y coordinate of object having index “ ” in normalized dataset at observation index “ ”.\n• Ω : Probability of hostility of object having index “ ” in raw dataset at observation index “ ”.\n• Ω : Probability of hostility of object having index “ ” in normalized dataset at observation index “ ”.\n• : This denotes the location of object having index “ ” at observation index “ ” at the raw dataset index.\n• : This denotes the location of object having index “ ” at observation index “ ” at the normalized dataset index.\n• : Locations of all objects (sets of X-Y coordinates) in raw dataset at observation index “ ”.\n• : Locations of all objects (sets of X-Y coordinates) in normalized dataset at observation index “ ”.\n• : Probabilities of hostility of all objects (sets of Ω values) in raw dataset at observation index “ ”. • : Probabilities of hostility of all objects (sets of Ω values) in normalized dataset at observation index “ ”.\n• : Raw training data having observation index “ ” at training dataset.\n• : Normalized training data having observation index “ ” at training dataset.\n• : Raw training dataset.\n• : Normalized training dataset.\n• : raw dataset.\n• : normalized dataset.\n• : Dataset containing location data of all objects in the area of observation with raw dataset index “ ” ( raw dataset).\n• : Dataset containing hostility probability data of all objects in the area of observation with raw dataset index “ ” ( raw dataset).\n• : Dataset containing location data of all objects in the area of observation with normalized dataset index “ ” ( normalized dataset).\n• : Dataset containing hostility probability data of all objects in the area of observation with normalized dataset index “ ” ( normalized dataset).\nObject index is a number assigned to each of the objects inside the area of observation for uniquely identifying them.\nRelations – The mathematical relations between the variables mentioned previously are enumerated as follows. , (2) 1, 1, , 1, (3) 1, 1, (4) Ω 1, 1, , 1, (5) 1, 1, (6) , 1, , 1, (7) , 1, (8) 1, (9) , (10) 1, 1, , 1, (11) 1, 1, (12) Ω 1, 1, , 1, (13) 1, 1, (14) , 1, , 1, (15) , 1, (16) 1, (17) ! (18)"
    }, {
      "heading" : "A. Procurement of Training Data",
      "text" : "Initially, the set is to be generated which is basically the raw dataset as previously explained.\nTable I is a tabular illustration of sample , since this is the first dataset, 1 . Here, the cell at index 2, 3 can be represented as ; the same can be extended to the other cells. This example dataset assumes there are only 3 objects in the area of observation. Similarly, we can have multiple training datasets."
    }, {
      "heading" : "1. 568 248 278 698 421 297",
      "text" : ""
    }, {
      "heading" : "2. 354 014 685 032 682 413",
      "text" : ""
    }, {
      "heading" : "3. 570 694 724 031 824 246",
      "text" : "Table II illustrates another dataset involved in training. Note that the two datasets are mutually independent and merely represent the log of locations of the multiple objects in the area of observation when an event of hostility had been previously sustained. Tables III and IV illustrate the tabular representations of the observed hostility probabilities ( ) of the objects in the area of interest for each of the datasets with\n= 1 and = 2 respectively.\nThe probabilities in Table III are only “0” or “1” because the network will undergo supervised training. The cell at index 3, 1 in Table IV can be represented as Ω ; the same can be extended to the other cells. The system variables defined previously are illustrated in the context of the present example in the succeeding text.\n• 3 • 2 • 4 • 5\n• = Table I • = Table II • = Dataset containing hostility probability data\nof all objects in the area of observation with raw dataset index “ 1 ” (Table III). Similarly, is defined. • = 3rd row of Table II. • = 2nd row of Table III. • = Collection of all tables I-IV organized as\n{(Table I, Table III), (Table II, Table IV)}\nSimilarly, the other system variables can be computed. In practical application, this data can be obtained by analysing previous events of hostility sustained. The set so generated cannot be used to train the neural network yet. It has to be subjected to normalization to get (normalized dataset) which will be used to train the neural network."
    }, {
      "heading" : "B. Generation of Normalized Training Data",
      "text" : "Normalization refers to generation of all permutations of\nthe sets & for all from 1 to . This process is important because, a hostile object need not be assigned the same object index every time it is inside the area of observation. For example, suppose the neural network is trained using and that in the dataset, for some , and , Ω 1.00.Correspondingly, the network is trained to output Ω 1.00 whenever the input is . Here, it is evident that the object with index is hostile. But suppose in the future, the same object is assigned an object index of ; then, the system will fail to identify successfully this hostile object as it has been trained to identify the hostile traits of object at index and not at . Although, if the system is also trained with all the permutations of and as input and output respectively, the system will always identify the hostile object irrespective of the object index assigned to it. To explain the normalization process, consider a scenario with 2, 1, 2. , , Ω , Ω Ω , Ω\nGenerating all permutations of , , and , , , , Similarly, generate normalized dataset for set ! [From (18)] 2 2! 8\nFor some 1, , 1, , [From (15)] (19)\nEq. 19 is the normalized training data at observation index “ ” as previously stated in Section II, B. In this, is input data to the neural network and is the set of target outputs. The derivation of is as follows –\n1, 8 1, 1 [From (12)] 1, 8 1, 1 [From (14)] , 1, 1 [From (16)] 1, 1 [From (17)]"
    }, {
      "heading" : "C. Neural Network Training",
      "text" : "The structure of the neural network to be trained by is illustrated in Fig. 1.\nAs shown in Fig. 1 the set is defined as: 1, 2 Hence, represents the set of input nodes and for an object with index , the set is defined as – , The set represents the location of object having index as a set of X and Y co-ordinates. Similarly, is the hostility of object having index . While training, for a given , we set and Ω and cycle the value of from 1 to\n. In each iteration, the system is trained using backpropagation and gradually the certitude with which the system predicts the hostility probability of each object increases. We repeat this process for each training dataset i.e. for all 1, . But in each dataset, only 70% should be used for training, 20% for validation and the remaining 10% for testing purposes. The distribution of the data amongst these three groups has to be random.\nD. Validation of Neural Network The process of validation is carried out so as to determine when to stop training and to avoid over-fitting. At each iteration, error is calculated from the validation data, the formula of which is given in Eq. 38.\n∑ , , . (20) Eq. 20 is used, as the network is a feed-forward network which is trained using back-propagation [2]. The network\nhere, is a set of functional mappings , [3], which relate an input with a given set of bias weights whose values are obtained through minimizing . Here, the joint probability density functions for the training data are given by , where 1,2, . . . , corresponds to each of the output neurons, is the output of neuron and is the target output for that neuron. Initially the error decreases and the gradient of the error decrease rate changes until approaching zero. Training stops when generalization stops improving network performance as measured from the validation data."
    }, {
      "heading" : "E. Deployment of Neural Network",
      "text" : "The flowchart to illustrate the system working is given in Fig. 2.\nA given neural network can cater to only a fixed number of objects in the area of observation. Therefore, multiple neural networks having different number of inputs must be trained and generated before pragmatic deployment. For example, first, a neural network (having 8 inputs) maybe generated to\nanalyze situations when only 4 objects are present in the area of observation; now, if the number of objects changes to 5, another neural network having 10 inputs will be needed. In node 001, the corresponding network is chosen. Subsequently in node 002, hostility probabilities of all the objects are calculated; now if an object with alarming hostility is identified (003), defensive measures should be taken to avoid any casualty. Finally, if the system fails to warn of an impending hostile event, then the network will retrain itself and learn from the experience after the hostile situation has subsided (006); much like the way humans learn from experiences. Therefore, a similar attack could be prevented in the future. This is indeed a drawback and is caused due to incomplete training. This is the reason why the network is trained with an expansive dataset of known hostile situations before deployment.\nIV. SIMULATION & RESULTS The proposed system has been simulated and implemented using MATLAB and C# on MonoGame® Framework. The neural network was generated in MATLAB. The simulation involves a front-end C# GUI application simulating a maritime radar environment running in parallel with MATLAB in the background in which the actual neural network computation and live-time training is taking place.\nFor simulation purposes, a scenario with defined as 5, 1, 494 was co 4 & 5 show characteristics of the neural net training and testing. Shown in Fig. 3 is the c which maps the outputs of the neural netwo actual output over test data (10% of the datase the diagonal, it is evident that the neural netw predicted the hostilities of all objects for a illustrates how the mean squared error decreases as training proceeds. We can derive the network starts to produce proper results iterations. Fig. 5 basically shows the error rang of the network outputs lie, over the input dat of the outputs lie in the error range of around is negligible, we can say that the network probabilities with sufficient certitude. Fig. 6 i the actual simulation. Here, each dot repre inside the area of observation. The dot enclo controllable by the user. To the extreme r landmass which is to be protected. The enc\ning\nsystem variables nsidered. Fig. 3, work right after onfusion matrix rk to that of the t). By observing ork has correctly ll inputs. Fig. 4 of the network from Fig. 4 that after 16 training e in which most a. Here, as most 0.000169 which outputs hostility s a screenshot of sents an object sed in the box is ight, there is a ircled dots have\ntwo numbers associated with them other; the one below, represents o above, is the probability of hosti observed that the patterns of attac network, were successfully highligh whenever an attack with a sim Moreover, if the user performed an similar kind of attack made by th highlighted, which exemplifies th proposed system. The simulation pr a number of scenarios with diffe similar results were obtained.\nV. CONCLUS A solution has been proposed w for fully automating the process o The system takes inputs as only th therefore, it can be directly deploye systems or other visual surveillanc location of the target, the incor specialized to the domain of applica potential to yield results with great system presented in this paper inco of the object so as to maintain a s Therefore, a framework has been specialized to encompass different detection.\nThe framework posited in this p\nin fields apart from maritime surve The system can be deployed in c analysis and detection of malicious that the system has the ability to lea by accepting data pertaining to the the location of which, greatly application of this methodology.\nREFERENC [1] Jeffrey V. Nickerson, Weehawken, NJ\n(JP), US Patent 8145591 B2, Det Movement Patterns, 2012\n[2] C.M. Bishop, “Novelty detection and Proc.-Vis. Image Signal Process., Vol.\n[3] Navneet P. Singh, Manisha J. Nene Analysis of GPR Images: Using Neu International Conference on Microe Renewable Energy (ICMiCR-2013), 20\n[4] David Kriesel, “A Brief Introduction to [5] Maritime Agent Analysis T\nhttp://www.atl.lmco.com/programs/EM [6] Timothy J. Ross, “Fuzzy Logic with\nWiley & Sons Publishing, 2009 [7] Daniel L. Schacter, Donna Rose\n“Remembering the past to imagine th Nature Reviews Neuroscience 8, Septe\n[8] David J. Montana and Lawrence Davi Networks Using Genetic Algorithms”, Artificial Intelligence, 1989\nplaced one on top of the bject index and the other lity of the object. It was k used to train the neural ted in this implementation ilar pattern was made. attack, then in the future, a e user was automatically e learning ability of the ocess was carried out over rent system variables and\nION hich can serve as the basis f hostile intent detection. e locations of the objects; d in conjunction with radar e systems. Apart from the poration of other factors tion of this system has the er certitude. However, the rporates only the locations ubtle degree of generality. presented which can be domains of hostile object\naper has many applications illance and radar systems. yber-security domains for data packets. The very fact rn and adapt to new tactics object not limited to only expands the domain of\nES (US); Toshihiko Matsuka, Chiba ection of Hostile Intent from\nneural network validation”, EE 141, No. 4, August 1994. , “Buried Object Detection and ral Network and Curve Fitting”, lectronics, Communication and 12 Neural Networks”, 2007 oolset, Lockheed Martin, AA/ Engineering Applications”, John\nAddis & Randy L. Buckner, e future: the prospective brain”, mber 2007 s, “Training Feedforward Neural International Joint Conference on"
    } ],
    "references" : [ {
      "title" : "Weehawken, NJ (JP), US Patent 8145591 B2",
      "author" : [ "Jeffrey V. Nickerson" ],
      "venue" : "Det Movement Patterns,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2012
    }, {
      "title" : "Networks Using Genetic Algorithms",
      "author" : [ "David J. Montana", "Lawrence Davi" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1989
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Background and related work: During the literature survey, it was observed that a small set of analytical approaches do exist [1], [5], which address this problem.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 0,
      "context" : "The most prominent of which, is the US Patent termed “Detection of Hostile Intent from Movement Patterns” [1].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "The neural network being utilized will be a 2layer feed forward network [8] with sigmoid function (1) as the activation function.",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 0,
      "context" : "[1] Jeffrey V.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "Schacter, Donna Rose “Remembering the past to imagine th Nature Reviews Neuroscience 8, Septe [8] David J.",
      "startOffset" : 94,
      "endOffset" : 97
    } ],
    "year" : 2014,
    "abstractText" : "In the recent years, the problem of identifying suspicious behavior has gained importance and identifying this behavior using computational systems and autonomous algorithms is highly desirable in a tactical scenario. So far, the solutions have been primarily manual which elicit human observation of entities to discern the hostility of the situation. To cater to this problem statement, a number of fully automated and partially automated solutions exist. But, these solutions lack the capability of learning from experiences and work in conjunction with human supervision which is extremely prone to error. In this paper, a generalized methodology to predict the hostility of a given object based on its movement patterns is proposed which has the ability to learn and is based upon the mechanism of humans of “learning from experiences”. The methodology so proposed has been implemented in a computer simulation. The results show that the posited methodology has the potential to be applied in real world tactical scenarios. Keywords—Hostility; Neural Networks; Artificial Intelligence; Defence; Maritime",
    "creator" : "'Certified by IEEE PDFeXpress at 11/04/2014 7:52:09 PM'"
  }
}