{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning", "abstract": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.", "histories": [["v1", "Thu, 15 Jun 2017 20:04:35 GMT  (3869kb,D)", "http://arxiv.org/abs/1706.05064v1", "ICML 2017"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["junhyuk oh", "satinder p singh", "honglak lee", "pushmeet kohli"], "accepted": true, "id": "1706.05064"}
