{
  "name" : "1302.6819.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An Alternative Proof Method for Possibilistic Logic and its Application to Terminological Logics",
    "authors" : [ "Bernhard Hollunder" ],
    "emails" : [ "hollunder@dfki.uni-sb.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 Introduction\nThere have been many proposals for the treatment of uncertainty in Artificial Intelligence, in particular for expert systems and knowledge representation systems (for an overview see, e .g. , [17, 14]). If uncertainty can be estimated in terms of possibility and necessity mea sures (as used in the framework of possibility theory [22]) possibilistic logic is a promising candidate. In fact, a basic feature of possibilistic logic is its abil ity to model states of knowledge ranging from com plete information to total ignorance by expressing low er bounds for the possibility or necessity of some piece\nof knowledge. This allows, for instance, to distinguish between the total lack of certainty in the truth of a proposition and the certainty that the proposition is false.\nFrom a syntactical point of view, possibilistic logic em ploys closed first-order formulas which are equipped with a possibility degree or a necessity degree: A weight ITa (resp. N a) attached to a formula p models to what extent p is possibly (resp. necessarily) true, where a ranges between 0 and 1. To express, for ex ample, that p is likely to be true one may use the necessity-valued formula (p, N0.7), whereas one may write (p, 110.9} to model that p is to a high degree possible, but not certain at all .\nRecently, a semantics for possibilistic logic has been presented for the general case where possibility- as well as necessity-valued formulas are allowed ( cf. [15]). The semantics is based on fuzzy sets of interpretations, i.e., with each classical interpretation w of the language as sociated with the first-order formulas occurring in a set of possibilistic formulas a value 7r(w) between 0 and 1 is assigned. The possibility and necessity of a formu la pis then given by II(p) = sup{7r(w) I w f= p} and N(p) = 1 -Il(•p). A fuzzy set of interpretations sat isfies a possibilistic formula (p, Ila) (resp. (p, Ncr)) iff II(p) � a (resp. N(p) � a). Entailment is then straightforwardly defined as follows : A possibilistic formula 4; is a logical consequence of a possibilistic knowledge base 41, i.e., a set of possibilistic formulas, iff every fuzzy set of interpretations satisfying each el ement in Ill also satisfies ¢.\nThe entailment of a possibilistic formula from a pos sibilistic knowledge base can be checked mechanically on the basis of possibilistic resolution-an extension of the well-known resolution principle to possibilistic logic-which ha.s been introduced in [8] . If applications of the possibilistic resolution rule to Ill U {(...,p, N1)} yield a derivation of an empty possibilistic clause (D, v) then Ill entails (p, v) , where v is either II a or N a for some a E [0, 1].\nA drawback, which possibilistic resolution inherits from classical resolution, is that it may not termi nate if applied to formulas belonging to decidable frag-\n328 Hollunder\nments of first-order logic. In fact, if the input formu las contain existential quantifiers in the scope of uni versal quantifiers, the (Skolem) function symbols that result from transforming these formulas into clause form may cause non-termination of standard resolu tion (and thus possibilistic resolution) .1 Moreover, the transformation of possibilistic formulas into clause form yields another problem: A set of possibility valued formulas cannot always be transformed into an \"equivalent\" set of clauses-not even for the proposi tional case (cf. [15], Section 3.1).\nFor these reasons we propose an alternative proof method for possibilistic logic. The main feature of this method is that it completely abstracts from a concrete calculus (such as the resolution or tableaux calculus), and instead uses as basic operation a test for classical entailment. If this test is effective for a given fragment of first-order logic, we show that possibilistic reasoning is also decidable for this fragment. Additionally, if one has an algorithm that solves the entailment problem, our proof method automatically yields an algorithm realizing possibilistic entailment. We prove that the proposed method is sound and complete (for the gen eral case where both possibility- and necessity-valued formulas are allowed) with respect to the semantics of possibilistic logic.\nWe then show how our method can be utilized to ob tain decision procedures for a possibilistic extension of terminological knowledge representation formalisms, also called terminological logics. These formalisms, which are employed in terminological representation systems such as BACK [18), CLASSIC (5), KRIS (3], or LOOM [16) are in general decidable fragments of first order logic, but are nevertheless expressive enough to define the relevant concepts of a problem domain. This is done by building complex concepts from primitive concepts (unary predicates) and roles (binary pred icates) with the help of operations provided by the concept language of the particular formalism. For ex ample, if we assume that person and car are concepts and that owns is a role, the concept personn3owns.car describes the set of all persons having some car. Ad ditionally, objects (or individuals) can be introduced by stating that an object is instance of a concept (e.g., Tom : person), or that two objects are related by a role (e.g., (Tom, car _7): owns).\nSeveral approaches have already been proposed to en hance the expressivity of terminological formalisms with (some form of) uncertainty (e.g., probabilistic implications between concepts (lOJ or subsumption be tween fuzzy concepts [20]). The approach that comes nearest to ours, is described in [21). It outlines an architecture for incorporating approximate reasoning\n1 It should be noted that the resolution calculus can be modified such that it yields decision procedures for vari ous decidable fragments of first-order logic (see e.g. [19]). However, it is not yet clear whether or not this approach can be extended to the possibilistic case.\ninto terminological systems. The main problem of this approach, however, is that its behavior is only de scribed informally, i.e., neither a complete semantics nor algorithms for the main inference problems are given.\nAn extension of terminological formalisms towards the representation of uncertain knowledge which is satis factory both from a semantic and algorithmic point of view can be obtained by instantiating possibilistic log ic with a terminological logic. This means that we do not allow arbitrary first-order formulas in possibilistic formulas, but only those which can be formed by a par ticular terminological formalism. To be more precise, in the possibilistic extension we present one can, on the one hand, state plausible rules between concepts. For example, the rule\n(person n rich -t 3owns.Porsche, II0.7), expresses that \"rich persons are likely to own a Porsche.\" Of course, universally valid rules, i.e., strict implications between concepts such as \"every Porsche is car\" can be formulated by using the maximal ne cessity value N 1. On the other hand, one can express uncertain knowledge concerning particular objects by adding possibility or necessity values to formulas ex pressing concept and role instanceships.\nThis approach has not only the advantage of being semantically sound. It also provides one with deci sion procedures for the basic inference problems (e.g., possibilistic entailment) which are sound and com plete with respect to the semantics for possibilistic logic. These decision procedures can immediately be obtained by instantiating our proof method with in ference algorithms for terminological logics as, for ex ample , described in (6, 2].\nThe paper is organized as follows. In Section 2 we introduce syntax and semantics of possibilistic log ic. The alternative proof method and the proof of its soundness and completeness are given in Section 3. Fi nally, in Section 4, we propose a possibilistic extension of terminological logics.\n2 Possibilistic Logic\nThis section reviews possibilistic logic. 2 We start with introducing the syntax for possibilistic formulas, and then we recapitulate the semantics for possibilistic log ic as defined in [15). Finally, possibilistic resolution, a proof calculus for possibilistic logic, is presented.\nA possibilistic formula is either a pair (p, Ih) or (p, Na) where pis a closed first-order formula and a E [0, 1] is a real number. A finite set of possibilistic formulas is called a possibilistic knowledge base.\nIntuitively, a possibility-valued formula (p, ITa) (resp. necessity-valued formula (p, N a)) expresses that p is possibly (resp. necessarily) true at least to degree a .\n2For a more thorough introduction consult [7].\nAn Alternative Proof Method for Possibilistic Logic 329\nLet 0 be the set of interpretations of a first-order lan guage. A possibility distribution 1r on 0 is a mapping from 0 to (0, 1] such that 1r(w) = 1 for some w E n.\nNote that the normalization requirement, i.e., 1r(w) = 1 for some w E SJ, guarantees that there is at least one world which could be considered the real one. Every possibility distribution 1r on n induces two functions, denoted by II' and N', mapping elements of\ni ={pI (p, Na) E � or (p, IIa) E �}\nto [0, 1]. These functions, called possibility measure and necessity measure, are defined as follows.\nLet 1r be a possibility distribution on a set 0 of inter pretations. The functions II' and N' defined by\n• II'(p) = sup{7r(w) I w E n and w F p} • N'(p) = inf{l- 7r(w) I w E n and w � p}\nare called possibility measure and necessity measure, where sup{} := 0 and inf{} := 1.\nA direct consequence of the definition is IT' (p V q) = max{IT'(p), II'(q)} and IT'(pl\\q):::; min{IT'(p), II'(q)}, which in fact shows that the possibility measure is in accordance with the basic axioms of possibility the ory ( cf. (22]). Moreover, by duality of the measures IT' and N', i.e., IT'(p) = 1- N'(..,p), we have for the necessity measure N'(p 1\\ q) = min{N'(p), N'(q)} and N'(p V q) � max{N'(p), N'(q)}. If a (first-order) for mula p--+ q is valid, i.e. {p} I= q, it is easy to ver ify that IT'(p) :::; IT'(q) and N'(p) :::; N'(q); further more IT'(T) = N'(T) = 1 for any tautology T, and II'(l.) = N'(l.) = 0 for any inconsistent formula l..\nIn possibilistic logic, the notions of satisfaction and entailment are defined with respect to possibility dis tributions.\nA possibility distribution 1r on a set n of interpreta tions satisfies a possibilistic formula (p, ITa), written as 1r F (p, ITa), iff ll'(p) �a, and it satisfies (p, Na), written as 1r F (p, N a ) , iff N'(p) � a. A possibility disttibution 1r on n satisfies a possibilistic knowledge base � iff 1r f= ¢ for all ¢ E �. Finally, we say that a possibilistic formula ¢ is entailed by a possibilistic knowledge base�. denoted by � F ¢, iff 1r f= ifJ for all 1r such that 1r F � holds.\nLet us consider an example. Consider the possibilistic knowledge base\n.P = {(p, N0.8), (p--? q, N0.4), (q-+ r, ll0.7)}.\nThen � entails the formula (r, IT0.7). To see this, let 1r be a possibility distribution satisfying ci>. We first observe that 1r f=: (q, N 0.4). In fact, since {p,p --+ q} F q we conclude N'(q) � N'(p 1\\ (p --+ q)) = min{N'(p), N'(p -+ q)} � 0.4. Duality gives us IT'(...,q) :::; 0.6. Furthermore, note that 0.7 :::; II'(q-+ r) = IT'(...,q V r) =max {ll'(--.q), II'(r)}. Since IT'(-.q) :::; 0.6 we can conclude that IT'(r) � 0.7. This shows that 1r satisfies (r, ll0.7).\nThere are possibilistic knowledge bases which are not satisfied by any possibilistic distribution. For exam ple, if � contains both (p, N 0.7) and (...,p, N 0.4), one gets TI'(--.p) = sup{rr(w) I w F ...,p} $ 0.3 and IT'(p) = sup{1r(w) I w I= p}:::; 0.6 for every possibility distribution 1r. But this means that 1r(w) :::; 0.6 for every w, which shows that the normalization require ment, i.e., 1r(w) = 1 for some w, is not satisfied. Thus\n� cannot be satisfied by any possibilistic distribution. This, of course, means that every possibilistic formula is entailed by �. However, the fact that we have more confidence in the truth of p than in the truth of ...,p is not taken into account by the semantics just described.\nTo achieve this behavior, i.e., to block the entailment of a possibilistic formula from an \"inconsistent\" knowl edge base, we need the notion of an absurd interpreta tion. To define this notion, we (temporarily) view an interpretation w as a function that maps a first-order formula p to an element of the set {0, 1} such that w(p) = 1 if w != p and w(p) = 0 ifw � p.\nThe function that maps each formula p to 1 is called the absurd interpretation and is denoted by w l., i.e., w 1. (p) = 1 for all formulas p. By abuse of notation, in the following we simply write WJ. F p if£ WJ. (p) = L\nLet 0 be a set of (classical) interpretations and let wl. be the absurd interpretation. A possibility distribu tion is now a mapping from ol. := n u {wl.} to [0, 1] such that 1r(w) = 1 for some w E n.L. The possibili ty measure IT and necessity measure N induced by a possibility distribution 1r on nl. is defined by\n• IT(p) = sup{rr(w) I wE 01. and w F= p} and • N(p) = inf{l- rr(w) I w E fh and wit= p}.\nObserve that II(p) = max{IT'(p), 1r(wl.)} and N(p) = N'(p), which means that the duality between II and N can be expressed by IT(p) � max{1- N(...,p), 1r(wl.)}. Furthermore, it can easily be verified that the thus defined possibility and necessity measures satisfy the basic axioms of possibility theory.\nSatisfaction and entailment are defined as before ex cept that we now consider possibility distributions on o.L (instead of 0).\nIn [15] it has already been mentioned that both seman tics coincide for possibilistic knowledge bases that are \"consistent.\" To be more precise, suppose that there is a possibilistic distributions 1r on 0 satisfying�- Then ¢ is entailed by � according to the first semantics if and only if ifJ is entailed by � according to the modified, inconsistency tolerant, semantics. Of course, both se mantics differ in the case where � is inconsistent. Re call that ci> given by { (p, N). 7), ( --.p, NJ.4)} entails every possibilistic formula according to the first semantics. However, according to the inconsistency tolerant se mantics we have ci> f= (p, N0.7) and� F {...,p, N0.4), but ci> � (p, Na) for a> 0.7 and ci> � (...,p, Na') for a'> 0.4. This shows that one can no longer derive any possibilistic formula from an inconsistent possibilistic knowledge base.\n330 Hollunder\nA possibilistic knowledge base that is inconsistent ac cording to the first semantics is more or less inconsis tent according to the inconsistency tolerant semantics. For example, { (p, No) , ( •p, No)} should be considered more inconsistent than {(p, N/3) , (•p, N/3)} if a> (3. To measure the strength of inconsistency the following definition has been introduced in [ 15] .\nThe inconsistency degree of a possibilistic knowledge base�. Incons(�), is defined as follows:\n• If there is a possibility distribution 11\" on n.L such that 1r f= �and 1r(w) = 1 for some w E 0, then <I> is possibly inconsistent and Jncons(<I>) = Ih where a = inf{rr(w.i) lrr F= <I>}. If Jncons(<I>) = no we say that � is completely consistent .\n• If for all possibility distributions 1r on n.L, 1r F= � implies 1r(w) < 1 for every w E n, � is neces sarily inconsistent and Jncons(<I>) = N a where 0 = inf{1- 1r(w) I wEn and 11\" I= <I>}.\nTo illustrate this definition let us consider some ex amples. To determine the inconsistency degree of �1 = {(p, N a) , ( •p, II /3)} we construct an appropri ate possibility distribution 11\" on n.L satisfying <1>1 . If 1r I= �1 then 1r(w) � 1 - a for every interpretation w with w � p (because N(p) = 1 -sup{1r(w) I w E n.L and w � p} � a). First assume that o + (3 � 1. We observe that the possibility distribution defined by { 1 if w � •p\n1r(w) = (3 if w�p 0 if W::;; W.L\nsatisfies �1· In fact , N(p) = 1 - sup{1r(w) I w E OJ. and w � p} = 1- f3 �a and ll(•p) = sup{rr(w) I w E nJ. and w F •p} � /3, which shows that 11\" F= <'1>1. Thus �1 is completely consistent if o + (3 � 1.\nNow assume that o + f3 > 1. Recall that rr(w) � 1-a for every w with w � p, which shows that sup{ 1r(w) I w E OJ. and w � p} < (3 (since 1- a < /3). But this means that rr(w .L ) � (3 for all 11\" satisfying <1>1 because Il(•p) = max{II'(•p) , rr(w.L)} � /3. Since the possibility distribution defined by { 1 if w � •p\nrr(w) = 1 -a if w � p (3 if W = W.L,\nsatisfies <l>t, we can conclude that <1>1 is possibly incon sistent and Incons(�1) = II/3.\nAn example for a necessarily inconsistent possibilistic knowledge base is <1>2 = { (p, N a) , ( •p, N /3) } where a > 0 and (3 > 0. It can easily be checked that Incons(<I>2) = Nmin{a,(3}.\nThe total ordering on possibility and necessity mea sures is defined by ITa � ITa' iff a � a', N a � N a' iff a� o' > 0, and No� ITa' iff a> 0 and a'� 1 .\nThus we have that Incons(<l>) �ITa (resp. Incons(<l>) � No) implies Incons(<l>) �ITa' (resp. Incons(<I>) � Na') if a > a'. Furthermore, Incons(<I>) � N a implies\nIn cons( <I>) � II a1 if a > 0 and a1 � 1 . This defi nition is justified by the fact that if <I> is necessarily inconsistent, then rr(w.L) = 1 for all 11\" satisfying <1>. But this means that 1 = inf { 1r(w .L ) lrr f= <I>} > o for any inconsistency degree ITo.\nThe following proposition, which has been proved in [ 15] , shows that the entailment problem in possibilistic logic can be reduced to the problem of determining the inconsistency degree of a possibilistic knowledge base, and vice versa .\nProposition 2.1 (Lang, Dubois, and Prade) Let <I> be a possibilistic knowledge base. Then:\n• <I> I= (p, ITo) iff Incons(<l> U {(•p , N1)}) �ITa,\n• �I= ( p, No) iff Incons(<l> U {(•p, N1)}) � Na.\nIn order to determine (lower bounds for) the inconsis tency degree of a possibilistic knowledge base the reso lution principle has been extended such that it can be applied to possibilistic formulas (see, e.g . , [ 15]) . Let (c, v) , (c', v' ) be possibilistic formulas, where c,c' are first-order formulas in clause form and v, v1 are pos sibility or necessity degrees. The possibilistic resolu tion rule allows the derivation of a possibilistic formula ( res(c, c' ), vov') , where res(c, c1) is a classical resolvent of c,c', and o is defined as No o No' = Nmin{o, o'}, ITo 0 ITo' = no I and\nN 11 ' II , N { no' if o + a' > 1 0 0 a = a 0 a = no else We notice that if a derived formula has the possibility degree no, the formula does not carry any addition al information and can therefore be discarded. This means in particular that the resolution rule need not be applied to two possibility-valued clauses.\nIf applications of the rule yield a derivation of an emp ty possibilistic clause (D, v) from a set <I> of possibilistic clauses, a lower bound for the inconsistency degree of <I> is given by v, i.e . , Incons(<l>) � v (cf. [15] ) .\nIn [15] i t has been shown that possibilistic resolution is sound and complete in the following sense: Let <I> be a set of possibility- and necessity-valued propositional clauses, or a set of necessity-valued first-order clauses. Then Incons( <I>) � v iff there is a derivation of an empty possibilistic clause (D, v) from <I> by applications of the possibilistic resolution rule.\nAlthough possibilistic resolution has this nice property, the overall calculus, i.e, transforming arbitrary possi bilistic formulas into clause form and then applying the possibilistic resolution rule, has some drawbacks. In the presence of possibility-valued formulas it is in general not possible to transform a set of possibilistic formulas into a set of possibilistic clauses which have the same inconsistency degree ( see [ 15], Section 3.1). Also standard resolution may not terminate even if ap plied to decidable fragments of first-order logic. This, of course, means that possibilistic resolution does in\nAn Alternative Proof Method for Possibilistic Logic 331\ngeneral not yield a decision procedure for a possibilis tic extension of terminological logics.\n3 An Alternative Proof Method for Possibilistic Logic\nThis section describes an alternative method for solv ing the entailment problem in possibilistic logic and for determining the inconsistency degree of a possibilistic knowledge base. The main feature of this method is that it completely abstracts from a concrete calculus, but uses as basic operation a test for classical entail ment. If this test is effective for a given fragment of first-order logic, we will see that possibilistic reasoning is also decidable for this fragment.\nIn the following we assume that the possibility and necessity degree of a possibilistic formula is not equal to zero. This assumption is justified by the fact that by definition IT(p} 2: 0 and N(p} 2: 0 hold, which shows that every possibility distribution satisfies formulas of the form (p, ITO} or (p, NO}. Hence such formulas do not carry any additional information and can therefore be discarded from possibilistic knowledge bases.\nLet � be a possibilistic knowledge base and let a E [0, 1}. We denote by �\" (resp. �\") the first-order for mulas of necessity-valued formulas in � that have a value greater (resp. strictly greater) than a, i.e.,\n• �a:= {pI (p, Na') E �. a'� a} and • �\" :={pI (p, Na') E �. a'> a}.\nThese abbreviations are quite useful to give an alterna tive characterization of possibilistic entailment. Let � be a possibilistic knowledge base, let p be a first-order formula, and let 0 < a � 1. We show that\n• � F (p, Na) iff�a f=p • � f= (p, ITa) iff\n- �0 f= p or - there is some ( q, II [J) E � such that {3 2: a\nand �1-f:l U {q} F p. This means that {p, N a) is entailed by � iff the first-order formulas of necessity-valued formulas in � whose value is not less than a classically entail p. For possibility-valued formulas the situation is slight ly more complex: (p, II a) is a possibilistic conse quence of� iff { 1) the first-order formulas of necessity valued formulas in � classically entail p, or (2) there is a possibility-valued formula (q, II[J), {J 2: a, in � such that q together with the first-order formulas of necessity-valued formulas in � whose value is strictly greater than 1 - {3 yield a classical proof for p.\nDue to lack of space we omit the soundness and com pleteness proof for necessity-valued formulas (see [11]). Lemma 3.1 Let � be a possibilistic knowledge base and let (p, ITa) be a possibilistic formula with a > 0. If �0 f= p or there is some ( q, IJP) E � such that {3 2: a and �1-f:l U {q} f= p, then� f= (p, ITa).\nProof. Assume that �0 f= p holds. There is a subset {(p1, Na!), ... ,(pn, N an)} of � such that {PI.···,Pn} f= p and min{a t, ... ,an} > 0 . This shows that N (p) > 0. Thus, if 1r is a possibility dis tribution satisfying �, we can conclude that for all wE !:!1., wit= p implies tr(w) < 1. Because of the normalization requirement there is an interpretation w' such that tr(w') = 1. Since w1 I= p it follows that II(p) = 1, and hence 1r I= (p, ITa). Thus we can con clude that <11 F (p, II a).\nNow assume that there is some (q, II {3) E � such that {3 2: a and �1-� U {q} I= p. Thus there is a subset {(pl, N a1), ... , (Pn, Nan)} of � such that {pt, ... ,pn, q} f= pand a;> 1- {3 for all i, 1 $ i � n. Let 1r be a possibility distribution on !:!1. such that 1r F= �. We show that 1r satisfies (p , ITa). Let us recall that IT(q) = max{II'(q), tr(wl.)} 2: {3 2: a. Case 1: IT(q) = 1r(w1.). Then II(p) = sup{1r(w) I wE !:!1. and w F p} 2: tr(wl.) 2: a, which shows that 7r satisfies (p, II a) . Case 2: II(q) -:j; 1r(w1.). Hence II(q) = II'(q). First we show that II'(q /\\p1 1\\ . . . 1\\pn) 2: {3. Observe that\n{3 � II'(q) = ll'((q /\\p1 1\\ ... 1\\pn) V (q 1\\ -.(pt 1\\. · · 1\\pn)))\nIT' ( ( q 1\\ Pt 1\\ ... 1\\ Pn) V ( q 1\\ ...,Pt) V ... V ( q 1\\. ...,Pn)) max{II'(q /\\p1 1\\ ... 1\\pn),\nII'(q 1\\ -.pi}, .. . , II'(q 1\\ -.pn)}, and thus it remains to be shown that II'(q 1\\ •p;) < {3 for all i, 1 � i � n. Since N(p;) = N'(p;) 2: a; (which follows from the fact that 1r satisfies every (p;, Na;)) we have II' ( -.p;) $ 1 -a;. Recall that a; > 1 - {3, which shows that II' ( •p;) < {3, and therefore II' ( q 1\\ -.p;) < {3 for i, 1 � i � n. Thus we can conclude that II'{q) = II'(q 1\\pt 1\\ ... 1\\pn) 2: {3. Since IT(q /\\p1 1\\ ... 1\\pn) 2: II' ( q 1\\ Pt 1\\ ... 1\\ Pn) and {Pt, ... , Pn, q} f= p we know that II(p) 2: {3 2: a. Thus 1r satisfies (p, ITa). 0\nBefore we prove completeness we need one more defini tion and a proposition. Let � be a possibilistic knowl edge base only containing necessity-valued formulas. The canonical possibility distribution3 tr on f!.t for � is defined by tr(w) = 1-max{a I (p, Na) E � and w � p}, where max{}:= 0.\nNotice that -rr(w.t ) = 1- max{ a I (p, N a) E � and w1. it= p} = 1, which shows that the canonical possibil ity distribution satisfies the normalization constraint.\nProposition 3.2 Let � be a finite set of necessity valued formulas and let 1r be the canonical possibility distribution for �. Then:\n1. tr(w) � 1-a if(p, Na) E � andw �p.\n2. 1r satisfies �. The proof is an immediate consequence of the defini tion (cf. [11]).\n3Such a distribution is also called least specific pouibil ity distribution in [4].\n332 Hollunder\nLemma 3.3 Let ci> be a possibilistic knowledge base and let (p, IIo:) be a possibilistic formula with a > 0. If ci> f= (p, ITo:) then cl>0 f= p or there is some (q, llJ1) E ci> such that {3 � o: and c�>1-{j U {q} f= p.\nProof. Assume that ci> f= (p, ITo:) for some a > 0. If cl>0 f= p we are done. Thus assume that ct>0 � p. We show that there is a formula (q, IT/3) in ci> such that {3 �a and c�>l-/3 U {q} f= p. Suppose to the contrary that for all ( q, IT/3) in ci> such that {3 � a we have 411-13 U { q} Pf: p. In the following we construct a possibility distribution 1r1 such that 1r1 satisfies � U { (...,p, N 1)} and 1r'(w1.) < o:. But this means that Incons(<I>U {(-,p, N1)}) < ITa, which shows that ci> p6: (p, ITa) (Proposition 2.1), thus contradicting the assumption that <I> f= (p, ITo:) holds.\nLet 1r be the canonical possibility distribution for {(p', Na') I (p', Na') E <I>} U {(-.p, N1)}. The possi bility distribution 1r1 for <I> U { ( -,p, N1)} is constructed as follows:\n{ 1r(w) if w�ct>0U{...,p} 1r1(w) = lh{o: + 1) if w = Wl.\n1 otherwise,\nwhere 1 = max{/31 (r, N/3) E <I> and {3 <a}. We first show that the normalization constraint is sat isfied and that 1r1{w1.) < o:. On the one hand, we assumed that <1>0 � p, which means that there is some interpretation w1 such that w' f= ct>0 U { --.p}. Hence we have 1r1 (w') = 1. On the other hand, we observe that 1 < a, which means that 1r1(w1.) < o:.\nNext we prove that 1r1 satisfies <I> U {( --,p, N1)}, i.e., we show that 11\"1 f= q, for every q, E <I> U {( -,p, N 1)}.\n(1.) (p', Na') E <I> U {(...,p, N1)}: Then:\nN(p') = 1- sup{1r'{w) I wE fh, w � p'} = 1- sup{1r(w) I w E �h, w li= p'} � o/,\nwhich shows that 1r1 f= (p', No:').\n(2.) (p', ITo:') E <I> where o:' � o:. Note that IT(p') = sup{1r'(w) I wE !J:1., w f= p'}, and thus it suffices to show that there is some w' E !h such that w' f= p1 and 1r'(w') � c/. Case 1: There is an interpretation w' different from w l. such that w' f= ct>0 U {p', -,p}. Then 1r1(w') = 1 (defini tion of 1r1), which shows that IT(p') � 1r1 (w') = 1 � o:'. Thus 1r' I== (p', ITo:'). Case 2: Now suppose that w � <I>0 U {p', --.p} for every interpretation w different from w l. . Recall that we as sumed that <I>1-a' U{p'} ji: p. This means that <I>1-a' U {p', --.p} is consistent, and hence there is some inter pretation w' :f; WJ. such that w' f= c�>l-a' U {p', ...,p}. Since we assumed that w p6: <I>0 U {p', --.p} for every in terpretation w different from w l., we can conclude that\nthere is some (p\", N a\" ) E ci> such that w' � p11 and a\"� 1- o:'.\nSince 1r1(w') = 1r(w') (definition of 1r1), it remains to be shown that 1r{w') � o:'. In fact,\n1r(w') = 1-max{/31 (r, N/3) E<l> U { (...,p, N1)},w' � r} = 1-max{/3 I (r, N/3) E <I> U {(-,p, N1)},\n{3 � 1 - o:', w' � r} > o:' (since {3 � 1 - a').\nThus we have shown that TI(p') � 1r'(w') = 1r(w') � a' and therefore we can conclude that 1r1 f= (p', II o:'). (3.) (p', ITo:') E <I> where o:' < o:. Since IT(p') � 1r' (wl. ) it suffices to show that 1r1(w1.) � a'. In fact , 1r'(w1.) = lf2(a + 1) � a' (because 1 � o:' as well as o: > o:').\nThus we have shown that 1r1 satisfies <I> U {(...,p, Nl)}, which concludes the proof. 0\nThe previous two lemmata together with Lemma 3.1 and Lemma 3.4 of [11] establish the main result of this section .\nTheorem 3.4 Let ci> be a possibilistic knowledge base, let p be a first-order formula, and let a > 0. Then\n• <II f= (p, No:) iff<I>a f=p and\n• cl> F (p, ITa) iff - <IJO F p or - there is some ( q, IT {3) E <I> such that {3 � a\nand <I>1-i3 U { q} f= p.\nCorollary 3.5 Possibilistic entailment is decidable in those languages in which classical entailment is decid able.\nIn the rest of this section we consider the problem of how to determine (with the help of Theorem 3.4) the inconsistency degree of a possibilistic knowledge base cl>. By Proposition 2.1 we know that ci> f= (..i, v) iff Incons(cl> U {(...,_1_, Nl)}) � v, and hence ci> f= (..i,v) iff Incons( ci>) � v, where ..l is an inconsistent formula and v is a necessity or possibility measure. Thus the problem is to find the maximal value v such that ci> f= (..i, v) .\nLet 1 := min{ a j (p, N a) E <I>}. First assume that ct>,. f= ..l. This means that <II is necessarily inconsistent at least to degree I· 0 bserve that <I> a 2 <I> a' iff a � o:'. Hence, in order to determine the number a E {/3 j (p, N {3) E ci>} such that ci> a f= ..l but <I> a li= ..L one can for instance apply a binary search algorithm (rather than testing for each element a E {a j (p, N a) E <I>} whether or not <lla is inconsistent). The inconsistency degree of <I> is then given by No:. Now assume that <I>,. jb ..l. lf<I>1-Pu{q} is consistent for every ( q, II /3) in ci>, we can conclude that <I> is\nAn Alternative Proof Method for Possibilistic Logic 333\ncompletely consistent (which means that Incons(�) = II 0) . Otherwise, the maximal number f3 such that (q, II.B) E IJ> and �l-P U {q} is inconsistent yields the inconsistency degree of 4>, i .e., Incons(tl>) = TI,B. Note that if (q, II/3) and (q', IT,B') are in IJ> where .B::::; {3', in general neither Th( { q} U ��>1-P) � Th( { q'} u ��>1-P') nor Th({q}Uti>1-P) 2 Th({q'}Uti>1-P') hold. This, however, means that one cannot employ binary search to determine the required value {3.\nTo sum up, assume that 4> is a possibilistic knowledge base with n formulas and p is a first-order formula. Then one can determine the maximal number a such that 4> I= (p, N a) holds with O(log n) classical entail ment tests. In contrast to this, one can determine with 0( n) entailment tests the maximal number a such that 4> I= (p, ITa) holds.\n4 A Possibilistic Extension of Terminological Logics\nThis section describes an extension of terminological knowledge representation formalisms that handles un certain knowledge and allows for approximate reason ing. This approach is not only satisfactory from a se mantical point of view; it also provides sound and com plete decision procedures for the basic inference prob lems. These algorithms can immediately be obtained by instantiating our proof method with the well-known inference algorithms for terminological logics.\n4.1 Terminological knowledge representation\nIn the following we briefly introduce a particular ter minological formalism, called A.CCN (cf. [13]). Such a formalism can be used to define the relevant concepts of a problem domain. Relationships between concepts, for instance inclusion or disjointness axioms, can be expressed in the terminological part. The assertion a} part allows one to describe objects of the problem domain with respect to their relation to concepts and their interrelation with each other .\nWe assume two disjoint alphabets of symbols, called primitive concepts and roles. The set of concepts is in ductively defined as follows. Every primitive concept is a concept . Now let C, D be concepts already de fined and let R be a role. Then C n D (conjunction), C U D (disjunction) , -.C (negation), VR.C (value restriction), 3R.C (exists-restriction), and (� n R) and (::5 n R) (number-restrictions) are concepts of the language A.CCN.\nConcepts are usually interpreted as subsets of a do main and roles as binary relations over a domain. This means that primitive concepts (resp. roles) are consid ered as symbols for unary (resp. binary) predicates, and that concepts correspond to formulas with one free variable. Thus primitive concepts A and roles R are translated into atomic formulas A( x) and R( x, y),\nwhere x, y are free variables. The semantics of the concept-forming constructs is given by\n(C n D)(x) := C(x) 1\\ D(x), (C u D)(x) := C(x) V D(x), (-.C)(x) := -.C(x), (VR.C)(x) := 'Vy (R(x, y)-+ C(y)), (3R.C)(x) := 3y (R(x, y) 1\\ C(y)), (� n R)(x) := 3yt, ... ,y,. Yt # Y21\\Y1 # Yal\\\n· · . I\\ Yn-1 # Yn 1\\ R(x, y!) 1\\ · · . I\\ R(x, Yn), (::5 n R)(x) := 'Vy1, . .. , y,.+l R(x, yl) 1\\ ... 1\\\nR(x,y,.+l)-+ Yt = Y2 Vyt = Ya V . . . Vy,._l = Yn ·"
    }, {
      "heading" : "It should be noted that the formulas thus obtained be long to a restricted subclass of all first-order formulas with one free variable.",
      "text" : ""
    }, {
      "heading" : "A terminological knowledge base is described by a set",
      "text" : "of inclusion axioms and-to introduce objects with re spect to their relation to concepts and their interrela tion with each others-a set of membership assertions.\nTo be more formal, let C, D be concepts, R be a role, and let a , b be names for individuals, so-called objects. A term inological axiom is of the form C -+ D, and expresses that every instance of C is also an instance of D. To state that an object a belongs to a concept C, or that two objects a, b are related by a role R one can use assertions having the form C(a) or R(a, b).\nThe semantics of a terminological axiom C -+ D is giv en by the formula Vx C(x)-+ D(x), where C(x), D(x) are the first-order formulas corresponding to the con cepts C, D. To define the semantics of assertions we consider individual names as symbols for constants. In terminological systems one usually has a unique name assumption, which can be expressed by the formulas a# b for all distinct individual names a, b. The formu la corresponding to the assertion C(a) (resp. R(a, b)) is obtained by replacing the free variable(s) in the for mula corresponding to C (resp. R) by a (resp. a, b).\nA terminological knowledge base is a pair (T, A) where Tis a finite set of terminological axioms (the so-called TBox) and A is a finite set of assertions (the so-called A Box). Observe that a terminological knowledge base (T, A) can be viewed as a finite set of first-order formu las that can be obtained by taking the translations of the TBox and ABox facts, and the formulas expressing unique name assumption.\nThe basic inference services for terminological knowl edge bases are defined as follows:\nConsistency checking: Does there exist a model for a given terminological knowledge base (T, A) ? Subsumpt ion problem: Is a terminological axiom C -+ D entailed by (T, A), i.e., (T, A) f= \\fx C(x) -+ D(x)? Instant iat ion problem: Is an assertion C(a) (resp. R(a,b)) entailed by (T,A), i.e., (T,A) � C(a) (resp. (T,A) f= R(a,b))? It should be noted that these inference problems are decidable for most terminological logics.\n334 Hollunder\n4.2 The possibilistic extension\nThe possibilistic extension of the terminological for malism introduced in the previous subsection is ob tained as follows: Each terminological axiom (resp . assertion) is equipped with a possibility or a neces sity value and will be called possibilistic terminologi cal axiom (resp. possibilistic assertion) . A possibilistic knowledge base is now a set of possibilistic terminolog ical axioms together with a set of possibilistic asser tions.\nIn order to give some impression on the expressivity of the extended terminological language, let us consider two examples. The first one, which is taken from [21] , is concerned with strict terminological axioms but un certain assertions. Assume that 7 is given by\n(father H- man n (;:;:: 1 child ) , N1) (successfuUather H- father n Vchild .college..grad . , N 1 ) ,\nwhere ( C H- D , N 1 ) is an abbreviation for the axioms (C � D, N I ) and (D � C, N 1 ) . The first axiom expresses that someone is a father iff he is a man and has some child; the latter one states that someone is a successful father iff he is a father and all his children are college graduates .\nFirst consider the (certain) assertions\nA = { (John : man n (:5 2 child ) , N1) , ( (John, Phi l ip) : chi ld, N1 ) , (Philip : college..grad . , N l ) , ( (John, Angela) : child , N l) , (Angela : college..grad. , N l) } ,\nwhich state that John is a man having at most two children, that Philip and Angela are children of John , and that both are college graduates. Since Phi l ip and Angela are the only children of John (because he has at most two children) and both children are col lege graduates, we can conclude that John is a suc cessful father, i .e . , the possibilistic assertion (John : successfuLfather, N1 ) is entailed by (7, A) .\nNow assume that it is only likely that Phi l ip is a college graduate, which can be encoded by (Phi l ip : college_grad . , N0.8) . Again, by possibilistic entailment we conclude that John is a successful father but, of course, only with a necessity degree of 0.8.\nIn the second example, possibility and necessity de grees are utilized to express plausible rules. Assume that the TBox 7 contains the following possibilistic aXIoms:\n(3owns .porsche � rich_person U car _fanatic, N0.8) (rich_person � golfer , TI0.7) .\nThe first axiom expresses that it is rather certain that someone is either rich or a car fanatic if (s)he owns a Porsche. The second one states that rich persons are possibly golfers.\nThe assertional knowledge is given by the facts that\nTom owns a Porsche 9 1 1 and that he is probably not a car fanatic , i .e . ,\nA = { ((Tom, 9 1 1) : owns, N l), (9 1 1 : porsche , N 1 ) , (Tom : -,car_fanatic, N0.7) } .\nWe are interested i n the question of whether o r not Tom is a golfer. To answer the query observe that {(Tom, 911) : Owns, 9 1 1 : porsche }f= Tom : 3owns.porsche,\nwhich shows that (Tom : 3owns .porsche, N 1) is en tailed by l[• A) . Hence, it can easily be verified that (T, A)1-0· U {Tom : rich_person } f= Tom : golfer. This shows that (Tom : golfer, TI0.7) is a possibilistic con sequence of (/, A) , which means that we have some reasons to believe that Tom is a golfer.\nThe following proposition shows that possibilistic rea soning restricted to the introduced terminological for malism is decidable. This result is an immediate con sequence of Theorem 3 .4 and the fact that the instanti ation problem in A.CCN-knowledge bases is decidable (cf. [6, 1] ) .\nProposition 4 . 1 Let T be a finite set of possibilistic axioms and let A be a finite set of possibilistic asser tions. It is decidable whether or not a possibilistic ax iom (resp. possibilistic assertion) is entailed by (T, A) .\nAlmost all terminological systems do not allow arbi trary TBoxes, but only those that satisfy certain con ditions (for instance, the left hand side of an axiom must be a primitive concept , and a primitive concept may appear at most once at the left hand side of an axiom) . In [12 , Chapter 7 .3] it has been shown how to obtain more efficient inference procedures if possibilis tic TBoxes satisfy the additional restrictions.\n5 Conclusion\nWe have developed an alternative proof method for possibilistic logic which exploits the fact that possi bilistic reasoning can be reduced to reasoning in clas sical, i .e. first-order, logic. Consequently, possibilistic reasoning is decidable for a fragment of first-order logic iff classical entailment is decidable for it. Moreover, if one has an algorithm solving the entailment problem, our method automatically yields an algorithm realizing possibilistic entailment which is sound and complete with respect to the semantics for possibilistic logic.\nFurthermore, we have instantiated possibilistic logic with a terminological logic, which is a decidable frag ment of first-order logic, but nevertheless much more expressive than propositional logic. This leads to an extension of terminological logics towards the repre sentation of uncertain knowledge which is-in con trast to other approaches-satisfactory from a seman tic point of view. Moreover, a sound and complete algorithm for possibilistic entailment in such an ex tension can be obtained by using inference procedures\nAn Alternative Proof Method for Possibilistic Logic 335\nwhich have already been developed for terminological logics.\nAn interesting point for further research is to employ possibilistic logic in order to represent and reason with defaults in terminological formalisms. In fact, in [9 , 4] it has been argued that possibilistic logic yields a good basis for nonmonotonic reasoning. Roughly speaking, the idea is as follows: If the necessity of a formula p is greater than the necessity of -.p with respect to a set � of necessity-valued formulas, then infer non monotonically p from �- This intuitive definition in fact characterizes an appropriate nonmonotonic con sequence relation as (1) the operator can be described in terms of preferential models, and (2) most of the axioms which a nonmonotonic operator should satis fy are met (see [9] on these points) . The approach presented in [4) , however, uses propositional logic and cannot directly be applied to the terminological case. One reason for this is that terminological default rules usually allow one to state that \"C's are normally D's\" where C, D are concepts, i .e. , first-order formulas with one free variable.\nAcknowledgements I would like to thank Werner Nutt who helped me to simplify notations, and Franz Baader, Detlef Fehrer , and Jorg Siekmann for helpful comments on a draft of this paper. This work has been supported by the Ger man Ministry for Research and Technology (BMFT) under research contract ITW 92 01 .\nReferences\n[1] F. Baader, M. Buchheit , and B . Hollunder. Cardi nality restrictions on concepts. Research Report RR-93-48, DFKI Saarbriicken, 1993 .\n[2] F . Baader , H.-J . Biirckert , B . Hollunder, W. Nutt, and J. H. Siekmann. Concept logics. In Proceed ings of the Symposium on Computational Logics, Briissel , Belgium, 1990 .\n[3) F. Baader and B . Hollunder. KRIS: Knowledge 'Representation and Inference System . SIGART Bulletin, 2(3) :8-14, 199 1 .\n[4] S . Benferhat, D . Dubois, and H. Prade. Repre senting default rules in possibilistic logic. In Pro ceedings of KR '92, Cambridge, Mass. , 1992.\n[5) R. J. Brachman, D. L . McGuinness, P. F . Patel Schneider, L . A. Resnick, and A . Borgida. Living with CLASSIC: When and how to use a KL-ONE like language. In J. Sowa, editor, Principles of Se mantic Networks, pages 401-456. Morgan Kauf mann, San Mateo, Calif. , 199 1 .\n[6) M. Buchheit, F . M . Donini, and A . Schaerf. Decidable reasoning in terminological knowledge representation systems. In Proceedings of IJ CAI'93, Chambery, France, 1993 .\n[7) D. Dubois, J . Lang, and H. Prade. Possibilistic logic. In D. M . Gabbay, editor, Handbook of logic\nin A rtificial Intelligence and logic programming, Volume 3. Oxford University Press, 1993.\n[8] D. Dubois and H. Prade. Necessity measures and the resolution principle. IEEE transactions on systems, man, and cybernetics, 17(3) :474-478, 1987 .\n[9] D. Dubois and H . Prade. Possibilistic logic, pref erential models, non-monotonicity and related is sues. In Proceedings of JJCAI'91, Sydney, Aus tralia, 1991 .\n[10] J . Heinsohn . A hybrid approach for modelling uncertainty in terminological logics. In Proceed ings of the 1st European Conference on Symbol ic and Quantitative Approaches for Uncertainty, Marseille, France, 1991 . Springer-Verlag.\n[ 11] B. Hollunder. An alternative proof method for possibilistic logic and its application to termino logical logics. Research Report RR-93-01 , DFKI Saarbriicken, 1993.\n[ 12] B. Hollunder. Algorithmic Foundations of Ter minological Knowledge Representation Systems. PhD thesis, University of Saarbriicken, 1994. To appear .\n[ 13] B. Hollunder, W. Nutt, and M . Schmidt-SchauB. Subsumption algorithms for concept description languages. In Proceedings of ECAI'90, pages 348- 353 , Stockholm, Sweden, 1990.\n[14] R. Kruse, E . Schwecke, and J. Heinsohn. Uncer taznty and Vagueness in Knowledge Based Sys tems. Springer-Verlag, Berlin, Germany, 1991 .\n[ 15) J . Lang, D. Dubois, and H . Prade. A logic of graded possibility and certainty coping with par tial inconsistency. In Proceedings of the 7th Con ference on Uncertainty in Artificial Intelligence, pages 188-196 , Los Angeles, CA. , 1 991 . Morgan Kaufmann .\n[16) R. MacGregor. Inside the LOOM description clas sifier. SIGART Bulletin, 2 (3 ) :88-92, 1991 .\n[ 17) J . Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Mor gan Kaufmann, San M ateo, Calif. , 1988.\n[18) C. Peltason. The BACK system - an overview. SIGART Bulletin, 2(3) : 1 14-1 19 , 1991 .\n[19] T. Tammet. Resolution methods for decision prob lems and finite-model building. PhD thesis, Uni versity of Goteborg, 1992.\n[20] J. Yen . Generalizing term subsumption languages for fuzzy logic. In Proceedings of /JCAI'91, Syd ney, Australia, 199 1 .\n[21] J . Yen and P. Bonissone. Extending term sub sumption systems for uncertainty management. In Proceedings of the 6th Conference on Un certainty in A rtificial Intelligence, Cambridge, Mass. , 1990.\n[22] L. A. Zadeh. Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems, 1 :3-28 , 1978."
    } ],
    "references" : [ {
      "title" : "Cardi­ nality restrictions on concepts. Research Report RR-93-48",
      "author" : [ "F. Baader", "M. Buchheit", "B . Hollunder" ],
      "venue" : "DFKI Saarbriicken,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : ", p, N1)} yield a derivation of an empty possibilistic clause (D, v) then Ill entails (p, v) , where v is either II a or N a for some a E [0, 1].",
      "startOffset" : 138,
      "endOffset" : 144
    }, {
      "referenceID" : 0,
      "context" : "A possibilistic formula is either a pair (p, Ih) or (p, Na) where pis a closed first-order formula and a E [0, 1] is a real number.",
      "startOffset" : 107,
      "endOffset" : 113
    }, {
      "referenceID" : 0,
      "context" : "to [0, 1].",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "} to [0, 1] such that 1r(w) = 1 for some w E n.",
      "startOffset" : 5,
      "endOffset" : 11
    }, {
      "referenceID" : 0,
      "context" : "[6, 1] ) .",
      "startOffset" : 0,
      "endOffset" : 6
    } ],
    "year" : 2011,
    "abstractText" : "Possibilistic logic, an extension of first-order logic, deals with uncertainty that can be es­ timated in terms of possibility and necessity measures. Syntactically, this means that a first-order formula is equipped with a possi­ bility degree or a necessity degree that ex­ presses to what extent the formula is pos­ sibly or necessarily true. Possibilistic reso­ lution yields a calculus for possibilistic logic which respects the semantics developed for possibilistic logic. A drawback, which possibilistic resolution in­ herits from classical resolution, is that it may not terminate if applied to formulas belong­ ing to decidable fragments of first-order log­ ic. Therefore we propose an alternative proof method for possibilistic logic. The main fea­ ture of this method is that it completely ab­ stracts from a concrete calculus but uses as basic operation a test for classical entailment. We then instantiate possibilistic logic with a terminological logic, which is a decidable subclass of first-order logic but nevertheless much more expressive than propositional log­ ic. This yields an extension of terminological logics towards the representation of uncer­ tain knowledge which is satisfactory from a semantic as well as algorithmic point of view.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}