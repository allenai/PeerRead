{
  "name" : "1303.5734.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Sensitivity Analysis of Pathfinder: A Follow-up Study",
    "authors" : [ "Keung-Chi Ng" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 INTRODUCTION\nA great deal of recent attention has been focused on the relationship of artificial intelligence (AI) to deci sion analysis (DA). Most of the work on probability theory as a mechanism for uncertainty management (Cheeseman 1988; Ng and Abramson 1990b), belief networks as representations of uncertainty (Abramson 1990; Howard and Matheson 1984), the propagation of information through a belief network (Pearl 1988; Shachter 1986; Shachter 1987), and the design of sys tems based on belief networks (Abramson and Finizza 1991; Andereassen, Woldbye, Falck, and Anderson 1987; Heckerman, Horvitz, and Nathwani 1990), falls into this category. These topics are all familiar to de-\ncision analysts; they deal with the representation of uncertainty and the derivation of inference. There is, however, a third concern frequently studied in DA: analysis.\nIn order to be useful, a model and/ or system must pass through several stages of development: it must capture the information that it claims to be modeling, it must allow questions to be answered, and it must be (in some sense) validated. Sensitivity analyses fall into this last area of concern. In a classic DA sense, a sensi tivity analysis measures the degree to which a decision is sensitive to changes in its inputs. These analyses are generally done one variable at a time. Most well designed models exhibit a phenomenon known as a fiat maximum; small (and even medium-sized) changes in input variables rarely lead to changed decisions (von Winterfeldt and Edwards 1986).\nSensitivity analyses are as important to AI systems as they are to DA models. Two characteristics of AI sys tems, however, force the standard techniques of sensi tivity analyses to be rethought: they generate outputs other than decisions, and they include huge numbers of variables. Pathfinder, for example, is an AI system that diagnoses the 63 diseases of the human lymph system; its underlying belief network also contains over 100 distinct symptoms (Heckerman, Horvitz, and Nathwani 1990). In 1990, at the Sixth Conference on Uncertainty in Artificial Intelligence, we presented a sensitivity analysis of Pathfinder that led to a surpris ing conclusion: the system did not exhibit a flat max imum. Instead, it seemed to be highly sensitive to the parameters specified by its contributing expert; even minor changes to these parameters led to drastic de clines in the system's performance (Ng and Abramson 1990a). These results were presented with a fairly de tailed description of the modified sensitivity analysis techniques upon which our studies were based, and a challenge to the conference participants to suggest possible causes underlying our results. Several useful suggestions were made. This paper revises our modi fications to the analysis and provides results that are more in line with previous (empirical) experience.\nA Sensitivity Analysis of Pathfinder: A Follow-Up Study 243\nSturcture of Pathfinder's belief network\n-A Random number ..,..\ngenerator\nexpert's assessments\n(9(3;> • • • • @ <D Parameters of Pathfinder's\nbelief network\n-A\n0<9 • 0 . . GO\n� 0 � I\"' Random number\ngenerate\n• . -• •\n�0\nRun\nthe\nsame\ntest\ncases\nFigure 1: Block diagram of the sensitivity analysis of Pathfinder.\n2 DETAILS OF THE ANALYSIS\nThe goals of a sensitivity analysis are (i) to gain insight into the nature of a problem, (ii) to find a simple and elegant structure that does justice to the problem, and (iii) to check the correctness of the numbers and the need for precision in refining them (von Winterfeldt and Edwards 1986). In most decision problems, once the numbers have reached a certain degree of precision, further refinement of these numbers has little effect on the decisions. Our studies are directed towards determining whether or not similar observations are true for diagnostic systems, (i.e., once the prior and conditional probabilities have reached certain quality, further improvement on these probabilities has little effect on its diagnoses). A block diagram of the study is shown ' in F igure 1. In our study, experiments were run on a. body of 60 \"clas sic\" cases in which the diagnosis was known. Since a network's parameters include prior and conditional probabilities, both sets of probabilities had to be var ied. The experiments used two sets of prior proba bilities (those specified by the experts and a uniform distribution across all the diseases) and three types of conditionals:\n1. The original values, exactly as assessed by ex perts.\n2. Randomly generated probabilities. This class of parameters includes probabilities distributed both uniformly and normally.\n3. The values assessed by experts plus randomly gen erated noise, using both uniformly and normally distributed noise functions.\nAll the conditional probabilities, either generated or augmented with noise, were renormalized.\nEach body of tests served a different purpose; the orig inal knowledge base defined a standard against which others would be judged, the random parameters ad dressed the relative importance of parameters, and the random noise addressed the issue of sensitivity. The use of two different sets of priors addressed the effect of priors on system performance.\n3 THE INITIAL STUDY\nThe results discussed in this section were first re ported at the 1990 Uncertainty in AI Conference (Ng and Abramson 1990a). This study implied that Pathfinder's performance degraded so significantly with randomly generated probabilities that the resul tant system had negligible discriminating power. The same results were observed regardless of the choice of distribution function or the selection of priors. These\n244 Ng and Abramson\nfindings led us to conclude that parameters are crucial to a belief network (or at least to Pathfinder's belief network) and that experts are needed to provide the parameters.\nOur experiments also studied variations in both prior and conditional probabilities. Priors were fixed either at the expert-assessed set or at a uniform set. Con ditionals were varied by augmenting the expert's as sessment with randomly generated noise. The resul tant conditional probabilities were then renormalized. The random noise functions followed uniform or nor mal distributions with mean of 0 (J.t = 0) and sev eral values of standard deviation (a} For each noise function, five parameter sets were created. Sixty cases were run on each network, for a total of 300 test cases per noise function. A total of seven noise generat ing schemes were used, including uniformly generated noise (uniform noise), normally generated noise (nor mal noise) with o of 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, all with 11 = 0 (to ensure that any probability has equal chance of being increased or decreased). A sum mary of the test results with expert priors is shown in Table 1. In the table, the percentage of correct diag noses, (i.e., the number of cases in which the known diagnosis was assigned the highest posterior probabil ity divided by the total number of cases), is intended to provide a measure of the diagnostic power. The av erage confidence, (average difference in posterior prob abilities between the two diseases with the highest pos terior probabilities on the differential diagnosis for all the cases run), with respect to the correct diagnosis and incorrect diagnosis, 1 provides a measure of the discriminating power of the leading disease (disease with the highest posterior probability on the differen tial diagnosis) from the other diseases on the differen tial diagnosis. It should be pointed out that although the percentage of correct diagnoses is more important than average confidence in system performance, aver age confidence is also useful in gaging system perfor mance. Systems scoring perfectly ( 100%) in the cor rect diagnosis column with 0 average confidence (e.g., all diseases have the same posterior probability with respect to all the test cases) could be as useless a sys tem as one with no correct diagnoses and absolute av erage confidence (1.0). Also shown in Table 1, in the column headed \"Percentage Better,\" is the percent age of cases in which the noisy network a�signed the correct diagnosis with posterior probability that is no tably higher than did the original network.\nTable 1 indicates that the original knowledge base had the highest score in both percentage of correct diag-\n1Correct diagnosis is defined as the situation in which the disease with the highest posterior probability on the differential diagnosis provided by the system is the same as the known diagnosis for a test case; incorrect diagnosis is the situation in which the disease with the highest posterior probability on the differential diagnosis is different from the known diagnosis.\nnoses and average confidence; augmentation with uni form noise produced the lowest scores on both items. Adding normal noise to the original know ledge base produced a system with scores that lie between these extremes, with better results for systems with smaller standard deviations (or less noise). Furthermore, the chance of producing a better diagnosis than the origi nal knowledge base is higher for knowledge bases with less noise than those with more noise. Table 2 sum marizes the results of networks with equal priors. The results are similar to those of Table 1.\n4 THE FOLLOW-UP STUDY\nThe results summarized in Tables 1 and 2 implied that Pathfinder's belief network did not exhibit a flat max imum. This observation was quite unexpected; flat maxima have been observed in almost all tested mod els (von Winterfeldt and Edwards 1986). A closer look at our study revealed that one possible reason for this surprise: all probabilities were varied, includ ing those that were equal to 0.0 and 1.0. The varia tion of these probabilities was undoubtedly a mistake; whereas probabilities in (0, 1) represent degrees of be lief that may be varied and refined, probabilities at the endpoints represent absolute certainty. Although studying perturbations of beliefs is reasonable, study ing perturbations of certainty is not. Furthermore, be liefs close to 0.0 and 1.0 are less prone to adjustment than those located elsewhere.\nIn an attempt to account for this observation, we re ran our study using a scheme that generated noise in a slightly different way; the augmented noise function depended on both the random noise function and the actual value of the conditional probability. If the origi nal conditional probability was 0.0 or 1.0 (i.e., the rela tionship is crisp or definitional), the conditional prob ability remained unchanged. For other values of con ditional probability with normally distributed noise functions, the noise would be more for probabilities close to 0.5 than for those close to either 0.0 or 1.0. The approach that we used is (i) convert the origi nal probability p , with range (0.0, 1.0), to a value v of range (-oo,oo), by a function f(p) = ln(1�P), (ii) add the generated noise to v to obtain v', and then (iii) con vert v' back to a probability by using f-1 (the inverse of the function f). With this scheme, the changes in likelihood ratios due to the added noise are compara ble for the probabilities that are close to the endpoints (0.0 and 1.0) and those that are close to 0.5, while the actual variations in probabilities are smaller for prob abilities that are close to either ends than those near 0.5. The new results are shown in Tables 3 and 4. In these tables, the average improvement in posterior probability for the cases in which the noisy network outperforms the original network is also shown (under the column labelled \"average amount better\").\nPercentage Correct\nOriginal 98.3% knowledge base\nNormal noise, 90.0% SD=0.005 Normal nmse, 87.6% SD=0.01 Normal nmse, 78.0% SD=0.025 Normal nmse, 70.7% SD=0.05 Normal nmse, 6l.O'i'o SD=O.l Normal nmse, 36.7% SD=0.25 U mtorm nmse 32.7'i'o\nA Sensitivity Analysis of Pathfinder: A Follow-Up Study 245\nAverage Confidence Percentage\nt;orrect Incorrect Better (# cases) (# cases)\n0.7910 0.8247 -\n(59) (1) 0.7329 0.2511 22.0'i'o (270) (30) 0.6963 0.3685 21.6'i'o (263) (37) 0.6803 0.2692 16.3'i'o (234) (66) 0.6997 0.2541 15.7'i'o (212) (88) 0.6212 0.3262 9.3'i'o (183) (117) 0.5614 0.2988 6.0% (110) (190) 0.5417 0.3142 5.0'i'o (98) (202)\nTable 1: Summary of results of the initial (1990) sensitivity analysis of Pathfinder. In this set, expert-assessed priors were used for all networks. A variety of noise functions were added to the expert's conditional probabilities.\nAverage Percentage Confidence Percentage\nCorrect t;orrect Incorrect Better (# cases) (# cases)\nOriginal 88.3% 0.8262 0.1569 knowledge base (53) (7) - Normal noise, 84.7% 0.7900 0.1279 24.3'!'o SD=0.005 (254) (46) Normal noise, 83.0% 0.7688 0.1444 17.7% SD=0.01 (249) (51) Normal noise, 80.0% 0.7019 0.2052 18.3'i'o SD=0.025 (240) (60) Normal noise, 73.7'.7o 0.6784 0.1831 13.7% SD=0.05 (221) (79) Normal noise, 62.3'i'o 0.6458 0.3019 10.0% SD=O.l (187) (113) Normal noise, 42.3% 0.4914 0.2516 7.3'i'o SD=0.25 (127) (173) Uniform noise 36.7% 0.4347 0.2927 6.0% (110) (190)\nTable 2: Summary of results of the initial (1990) sensitivity analysis of Pathfinder. In this set , uniform priors were used for all networks. A variety of noise functions were added to the expert's conditional probabilities.\n246 Ng and Abramson\nTable 3 indicates that the percentage of correct diag noses and average confidence for the original knowl edge base and knowledge bases with small noise are comparable. With more noise added to the original knowledge base, the percentage of correct diagnoses drops, but the average confidence remains compara ble to that of the original knowledge base. Knowledge bases with more noise, however, have a higher chance of providing better diagnoses and the improvements are more significant (see the column under percentage better )-an average improvement of more than 0.1 in posterior probability for the correct diagnosis over that of the original knowledge base, both for normal noise with .<T = 0.25 and uniform noise. All these observa tions suggest that although small refinements to the probabilities will not produce significant differences in performance, larger proper refinements may produce stronger results (at least with respect to the test cases). Table 4 summarizes the results of networks with equal priors. The results are similar to those of Table 3.\nThe results in Table 1 to 4 contain a lot of fine details on our study, which can be nicely summarized through the use of a scoring rule. Table 5 shows the results of our earlier study and this follow-up study evaluated by a quadratic scoring rule (see von Winterfeldt and Ed wards 1986 for examples of popular scoring schemes). The scoring rule that we used is\nscore = 2 * Pk - L(P;)2, where p; denotes the probability assigned to hypothe-\nsis i, and Pk is the probability assigned to the correct hypothesis k, which is the correct disease in a test case in our study. It can be observed that score can take on values between 1.0 and -1.0, with 1.0 denoting a perfect score-in Pathfinder, this denotes that the sys tem's diagnosis is the same as the diagnosis in the test cases. The values shown in the table are the average scores of each study for the 300 test cases. The results shown in Table 5 revealed the same key message as in Tables 1 to 4, however, the fine details of our results can only be found in Tables 1 to 4.\n5 CONCLUSIONS\nThe results presented in this paper are hardly revolu tionary; they indicate that Pathfinder exhibits a flat maximum. They are, however, interesting in several respects. First, they help extend the flat maximum phenomenon beyond decision settings to diagnostic settings. Second, they show how to extend an anal ysis that is usually conducted one variable at a time to one that can be conducted on all of a domain's variables simultaneously. Third, they reveal the im portance of parameters to a belief network, especially those that are close to (or at) 0.0 and 1.0. Fourth, (and of perhaps greatest significance to the authors), they correct results that we have already published. This paper, combined with our earlier one (N g and Abramson 1990a), then, suggest a viable extension of a common DA analysis to the larger, more complex settings generally encountered in AI.\nPercentage Correct\nOriginal 88.3'1o knowledge base\nNormal noise, 86.0% <7=0.005\nNormal noise, 86.3% <7=0.01 Normal noise, 85. 7'1o <7=0.025 Normal noise, 86.7% <7=0.05 Normal noise, 85.7% <7=0.1 Normal noise, 84.0% <7=0.25\nUniform noise 66.7%\nA Sensitivity Analysis of Pathfinder: A Follow-Up Study 247\nAverage Percentage Confidence Better\nCorrect Incorrect (average amount (# cases) (# cases) better)\n0.8262 0.1569 (53) (7)\n0.8499 0.1335 3.3% (258) ( 42) (0.0280) 0.8464 0.1304 6.3% (259) ( 41) (0.0238) 0.8562 0.1388 12.0'1o (257) ( 43) (0.0312) 0.8444 0.1933 14.7% (260) ( 40) (0.0398) 0 8583 0.2187 19.7'1o (257) ( 43) (0.0616) 0.8331 0.3793 16.7'1o (252) ( 48) (0.1274) 0.8707 0.4628 12.0% (200) (100) (0.2145)\nTable 4: Summary of results of the sensitivity analysis of Pathfinder. In this set, uniform priors were used for all networks. A variety of noise functions were added to the expert's conditional probabilities. In this study, more noise was added to probabilities that were close to 0.5 than those that were close to either 0.0 or 1.0, and no change would be made to probabilities that were 0.0 or 1.0.\nFirst Study F()_llow-up J:itudy t;xpert Pnors Eq u a.l\n_ !:'nors �xpertynors _ t;qu� Pnors Original 0.8829 0.8393 0.8829 0.8393\nknowledge base Nor mal noise, 0.8151 0.8114 0.8837 0.8392\n<7=0.005 Normal noise, 0.7542 0.7891 0.8835 0.8399\n<7=0.01 Normal noise, 0.6695 0.7052 0.8824 0.8390\n<7=0.025 Normal noise, 0.6045 0.6619 0.8774 0.8333\n<7=0.05 Normal noise, 0.4408 0.4727 0.8809 0.8276\n<7=0.1 Normal noise, 0.1480 0.2226 0.8255 0.7660\n<7=0.25 Uniform noise 0.0748 0.1055 0.4923 0.5186\nTable 5: A table summarizing our first study and this follow-up study of the sensitivity analysis of Pathfinder. The number in each entry denotes the average score computed by a quadratic scoring rule.\n248 Ng and Abramson\nAcknowledgments\nThis work was supported in part by the National Li brary of Medicine under grant R01LM04529 and by the NSF under grant IRI-8910173.\nReferences\nBruce Abramson. On Knowledge Representation in Belief Networks. In Proceedings of the 3rd In ternational Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems, July 2-6, 1990.\nBruce Abramson and Anthony J. Finizza. Using Belief Networks to Forecast Oil Prices. International Journal of Forecasting, 1991. In press.\nS. Andreassen, M. Woldbye, B. Falck, and S. K. An derson. MUNIN - A Causal Probabilistic Net work for the Interpretation of Electromyographic Findings. In Proceedings of the 1Oth International Joint Conference on Artificial Intelligence, pages 366-372, 1987.\nPeter Cheeseman. An Inquiry into Computer Under standing. Computational Intelligence, 4(1):58-66, 129-142, 1988.\nD. E. Beckerman, E. J. Horvitz, and B. N. Nath wani. Toward Normative Expert Systems: The Pathfinder Project. Technical Report KSL-90-08, Stanford University, 1990.\nRonald A. Howard and James E. Matheson. Influence Diagrams. In Ronald A. Howard and James E. Matheson, editors, Readings on the Principles and Applications of Decision Analysis, val. II, pages 721-762. Strategic Decisions Group, 1984.\nKeung-Chi Ng and Bruce Abramson. A Sensitivity Analysis of Pathfinder. In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelli gence, 1990a.\nKeung-Chi Ng and Bruce Abramson. Uncertainty Management in Expert Systems. IEEE Expert, 5(2):29-48, 1990b.\nJudea Pearl. Probabilistic Reasoning in Intelligent Sys tems. Morgan Kaufmann, 1988.\nRoss D. Shachter. Probabilistic Inference and Influ ence Diagram. Operation Research, 36:589-604, 1988.\nRoss D. Shachter. Evaluating Influence Diagrams. Op erations Research, 34(6):871-882, 1986.\nDetlof von Winterfeldt and Ward Edwards. Decision Analysis and Behavioral Research . Cambridge University Press, 1986."
    } ],
    "references" : [ {
      "title" : "On Knowledge Representation in Belief Networks",
      "author" : [ "Bruce Abramson" ],
      "venue" : "In Proceedings of the 3rd In­ ternational Conference on Information Processing and Management of Uncertainty in Knowledge­ Based Systems,",
      "citeRegEx" : "Abramson.,? \\Q1990\\E",
      "shortCiteRegEx" : "Abramson.",
      "year" : 1990
    }, {
      "title" : "Using Belief Networks to Forecast Oil Prices",
      "author" : [ "Bruce Abramson", "Anthony J. Finizza" ],
      "venue" : "International Journal of Forecasting,",
      "citeRegEx" : "Abramson and Finizza.,? \\Q1991\\E",
      "shortCiteRegEx" : "Abramson and Finizza.",
      "year" : 1991
    }, {
      "title" : "An Inquiry into Computer Under­ standing",
      "author" : [ "Peter Cheeseman" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "Cheeseman.,? \\Q1988\\E",
      "shortCiteRegEx" : "Cheeseman.",
      "year" : 1988
    }, {
      "title" : "Toward Normative Expert Systems: The Pathfinder Project",
      "author" : [ "D.E. Beckerman", "E.J. Horvitz", "B.N. Nath­ wani" ],
      "venue" : "Technical Report KSL-90-08,",
      "citeRegEx" : "Beckerman et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Beckerman et al\\.",
      "year" : 1990
    }, {
      "title" : "Influence Diagrams",
      "author" : [ "Ronald A. Howard", "James E. Matheson" ],
      "venue" : "Readings on the Principles and Applications of Decision Analysis,",
      "citeRegEx" : "Howard and Matheson.,? \\Q1984\\E",
      "shortCiteRegEx" : "Howard and Matheson.",
      "year" : 1984
    }, {
      "title" : "A Sensitivity Analysis of Pathfinder",
      "author" : [ "Keung-Chi Ng", "Bruce Abramson" ],
      "venue" : "In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelli­ gence,",
      "citeRegEx" : "Ng and Abramson.,? \\Q1990\\E",
      "shortCiteRegEx" : "Ng and Abramson.",
      "year" : 1990
    }, {
      "title" : "Uncertainty Management in Expert Systems",
      "author" : [ "Keung-Chi Ng", "Bruce Abramson" ],
      "venue" : "IEEE Expert,",
      "citeRegEx" : "Ng and Abramson.,? \\Q1990\\E",
      "shortCiteRegEx" : "Ng and Abramson.",
      "year" : 1990
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Sys­ tems",
      "author" : [ "Judea Pearl" ],
      "venue" : "Ross D. Shachter. Probabilistic Inference and Influ­ ence Diagram. Operation Research,",
      "citeRegEx" : "Pearl.,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl.",
      "year" : 1988
    }, {
      "title" : "Evaluating Influence Diagrams",
      "author" : [ "Ross D. Shachter" ],
      "venue" : "Op­ erations Research,",
      "citeRegEx" : "Shachter.,? \\Q1986\\E",
      "shortCiteRegEx" : "Shachter.",
      "year" : 1986
    } ],
    "referenceMentions" : [ ],
    "year" : 2011,
    "abstractText" : "At last year's Uncertainty in AI Confer­ ence, we reported the results of a sensitiv­ ity analysis study of Pathfinder. Our find­ ings were quite unexpected-slight variations to Pathfinder's parameters appeared to lead to substantial degradations in system perfor­ mance. A careful look at our first analysis, together with the valuable feedback provided by the participants of last year's conference, led us to conduct a follow-up study. Our follow-up differs from our initial study in two ways: (i) the probabilities 0.0 and 1.0 re­ mained unchanged, and (ii) the variations to the probabilities that are close to both ends (0.0 or 1.0) were less than the ones close to the middle (0.5). The results of the follow­ up study look more reasonable-slight varia­ tions to Pathfinder's parameters now have lit­ tle effect on its performance. Taken together, these two sets of results suggest a viable ex­ tension of a common decision analytic sen­ sitivity analysis to the larger, more complex settings generally encountered in artificial in­ telligence.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}