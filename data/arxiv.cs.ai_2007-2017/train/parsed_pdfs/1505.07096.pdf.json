{
  "name" : "1505.07096.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "A U.S. Research Roadmap for Human Computation A COMMUNITY REPORT FROM THE 2014 HUMAN COMPUTATION ROADMAP SUMMIT\nA U.S. Research Roadmap for Human Computation A Community Report from the 2014 Human Computation Roadmap Summit\nOrganized by\nHuman Computation Institute\nWoodrow Wilson International Center for Scholars\nCornell University\nSponsored by\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n1 Summary ........................................................................................................................................................................ 2 Humans and Machines Participating in the Same System ......................................................................................... 2 Impact of Human Computation .................................................................................................................................... 3 A Success Case .............................................................................................................................................................. 3 Toward Repeatability .................................................................................................................................................... 3 New Project Ideas ......................................................................................................................................................... 4 Project Houston ............................................................................................................................................................ 4 Pathways to Radiology .................................................................................................................................................5 Optimizing Effective Utilization of Social Services ....................................................................................................6 Predicting Technology Trends ...................................................................................................................................... 7 UpRiver ...........................................................................................................................................................................8 Antisocial Computing ...................................................................................................................................................10 A New Set of Questions .................................................................................................................................................11 Participation ..................................................................................................................................................................11 Analysis .........................................................................................................................................................................11 Architecture .................................................................................................................................................................. 12 Design Methods ............................................................................................................................................................ 12 Infrastructure .............................................................................................................................................................. 12 Emerging Research ...................................................................................................................................................... 13 Funding Environment .................................................................................................................................................. 13 National Initiative ........................................................................................................................................................ 14 Contributors ................................................................................................................................................................. 14 Organizing Committee ................................................................................................................................................. 14 Program Committee ..................................................................................................................................................... 14 CCC Liaisons .................................................................................................................................................................. 14 Policy Keynote .............................................................................................................................................................. 14 Facilitators ................................................................................................................................................................... 14 Workshop Support Staff ..............................................................................................................................................15 Complete List of Participants ......................................................................................................................................15 References ....................................................................................................................................................................16 Appendix: The Visioning Process .................................................................................................................................18 Overview .......................................................................................................................................................................18 Shared Context .............................................................................................................................................................18 Problems and Solutions .............................................................................................................................................. 20 Solution Concept Development ................................................................................................................................... 21 Success Cases and Solution Refinement ................................................................................................................... 22\n2"
    }, {
      "heading" : "A U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION",
      "text" : "Summary The Web has made it possible to harness human cognition en masse to achieve new capabilities. Some of these successes are well known; for example Wikipedia has become the go-to place for basic information on all things; Duolingo engages millions of people in real-life translation of text, while simultaneously teaching them to speak foreign languages; and fold.it has enabled public-driven scientific discoveries by recasting complex biomedical challenges into popular online puzzle games. These and other early successes hint at the tremendous potential for future crowd-powered capabilities for the benefit of health, education, science, and society. In the process, a new field called Human Computation has emerged to better understand, replicate, and improve upon these successes through scientific research. Human Computation refers to the science that underlies online crowd-powered systems and was the topic of a recent visioning activity in which a representative cross-section of researchers, industry practitioners, visionaries, funding agency representatives, and policy makers came together to understand what makes crowd-powered systems successful. Teams of experts considered past, present, and future human computation systems to explore which kinds of crowd-powered systems have the greatest potential for societal impact and which kinds of research will best enable the efficient development of new crowd-powered systems to achieve this impact. In this report, we summarize the products and findings of those activities. The unconventional process and activities employed by the workshop were informed by human computation research and are described in the Appendix. Humans and Machines Participating in the Same System Solving today’s most challenging and complex problems requires an ability to build consensus around common goals and gather, process, and act on information at massive scales with increasing efficiency. We do not know how to create machines with the critical cognitive abilities required for solving important human-centered problems. But what if we could engineer systems that combine the respective strengths of machines and humans toward new capabilities? Human Computation is an emerging field that considers the design and analysis of information processing systems in which humans participate as computational agents[1]. A multidisciplinary community of academics, visionaries, private industry researchers, and federal program officers, met to explore the transformative potential of directly employing human cognition within larger computational systems. During a three-day workshop held in June 2014, we explored the full landscape of human computation. We considered stakeholders and goals, examined historical successes, designed promising new systems, and ultimately sought to identify high-impact research strategies for achieving near-term societal benefits.\n3 Impact of Human Computation We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6]. Human computation also has been used to support important behavioral change (e.g., to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming. It has been used to crowdsource the world’s most comprehensive encyclopedia via massively distributed contributions and sharing of knowledge. And when extended into the physical world via participatory sensing (i.e., geographically distributed data acquisition and sharing using mobile devices or sensors) and coordinated action, human computation methods have been employed to save lives by amplifying situational awareness and coordinating rescue actions for crisis relief[13]. Furthermore, emergent human computation has been used to improve real-time epidemiology via predictive analytics and to reliably anticipate world events via social informatics[14]. A Success Case Notable successes, such as the fold.it project (see Figure 1), have demonstrated dramatic results[15] using even simple human computation project designs. Fold.it is an online puzzle game that has enticed thousands of Internet participants to contribute their mental energies to folding virtual proteins. Recasting a biomedical research activity into a game that doesn’t require specialized medical knowledge enabled thousands of volunteers to solve a problem and helped researchers better understand protein structures. In only a few weeks’ time, it gave rise to the discovery of the tertiary structure of a regulatory protein for the pro-simian immunodeficiency virus (SIV), which previously eluded the research community for decades[16], and now may lead\nto new medications to treat the AIDS virus. At the time of this writing, fold.it is generating promising molecular topologies that could lead to treatment targets for the Ebola virus[17].\nToward Repeatability Efforts to replicate such successes have led to mixed results. This stems from the difficulty of ascertaining the precise, complex, and multidisciplinary combination of ingredients necessary for effective sustainable human computation. In traditional computer science, machinebased systems tend to exhibit predictable behavior such that machine errors can almost always be traced to faulty instructions. Indeed, a mature body of theoretical and applied methods exists today as a result of decades of funded research to support the development of such deterministic systems. Due to the vagaries of human behavior, however, these traditional methodologies are inadequate for human computation[18], which suggests the need for a new approach. The next section describes results from a set of ideation exercises to help inform new classes of methods better suited to systems with humans in the loop.\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n4\nNew Project Ideas In order to explore in depth the unique set of considerations that arise in human computation, we formed multidisciplinary breakout teams to develop new human computation project ideas. In addition to suggesting promising new potential capabilities, this exercise helped reveal risks and opportunities specific to this field and illuminated critical research areas that will be instrumental in advancing the field. Six projects are described below. When setting up the breakout groups, the organizers gave permission for one group to “do evil”, that is, to formulate ways that human computation systems could be manipulated to yield outcomes that are socially undesirable. This is the last project idea described on page 10.\nProject Houston\nOn April 14, 1970, 56 hours into its space mission to the moon, Apollo 13 transmitted, “Houston, we’ve had a problem.” What followed was a calmly heroic effort of remote engineering that led to a safe return. Imagine if\nwe all could call on a calm, competent voice when we really needed help. We envision this resource as Project Houston, a mixed computer/human-computation service for distressed people. Overwhelming situations cause enormous societal and economic costs: violence, suicide attempts, hunger, lack of transport, homelessness, failure to access care, and job loss. When unaddressed, these problems tend to intensify, piling misery upon misery. They especially touch those least equipped to solve their problems including: the elderly infirm, people with mental illnesses, the isolated, ex-prisoners and youth. Individuals do not always have the appropriate expertise to address these problems but could benefit from access to the expertise of others. For example, the Apollo 13 mission landed successfully because they were able to access remote expertise in Houston and used their knowledge to redesign the spacecraft’s carbon dioxide scrubbers.\nSpecialist social-work and mental-health workers have neither the numbers nor the 24-hour availability needed to aid people in distress before problems get worse. Project Houston would address these issues by using\nFigure 2: Project Houston project diagram – 24-hour distributed assistance for people in distress.\nProject Houston\nToo Many Distressed People\nWho? – Isolated, elderly, mentally ill, ex-prisoners, military So we get societal problems- expensive, violence, suicide, homelessness, joblessness\nDistress Detection • Human computer collaboration for sustained\npersonalized support • Distributed social support • Adaptive group composition and transformation • Integrated human/machine learning • Composite personalitites\nSo we need\nWhich requires research on\nUbiquitous scalable continuous detection intervention & bridge\ntreatment\nMALFEASANCE PRIVACY\n5\nstate of the art sensing, speech analysis, and natural language understanding to detect distress and offer help. Once help is requested, it would provide triage and first-level care using crowd-sourced, computersupported composite personalities, bringing together the various traits needed to support the person. By semi-automatically assembling dynamic teams of volunteers, along with low and high level specialists, Project Houston could provide immediate 24-hour assistance. With computer-supported persistent memory and response integration enhanced by continuous machine learning, Project Houston could provide a consistently kind and patient personality even if the “crowd” changes completely over time in response to an escalating problem until the problem is resolved – just like mission control. Pathways to Radiology With soaring numbers of individuals who are unemployed and under employed, the global community needs novel approaches to train workers and transition them into fulfilling professions. Crowdsourcing is a\nrapidly growing sector of the online economy where workers around the world perform tasks of short duration for small monetary incentives. Through online crowds, employers have access to a highly scalable, sometimes largely unskilled workforce. Currently, crowdsourcing typically only leverages basic cognitive abilities and may not train people with skills that could transfer to professional settings. In concert with this shift, recent advances in massively open online courses provide unprecedented opportunities for skills training, which when combined with performance of online tasks, could lead to measurable enhancement of skills needed in the offline workforce.\nWe explored a vision to combine online education with crowdsourced work in a way that provides pathways between low-skill micro-task crowdsourcing and the more complex tasks associated with professional vocations. The web app “Duolingo,” is an example of this vision. It offers free language lessons while simultaneously creating value as a document translation service. If this dual-purpose strategy pays dividends, why stop with language learning and translation? The\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n6\nright kind of online ecosystem can enable endless opportunities to “level up” and learn new on-the-job skills, while also creating real value in the labor marketplace. Each worker could perform tasks, learn new skills, and receive credentials that enable them to take on more complex roles – such as reviewing and training others.\nThis could be used in the field of radiology. Novice workers may enter the task market to perform tumor detection on x-ray images; this object recognition task is difficult for vision algorithms to perform reliably, but is a natural fit for crowdsourcing. As workers demonstrate proficiency, they may graduate to judge more difficult films by looking at edge cases that have less overall agreement, and then move on to write training materials for future workers, or review performance for a staff of newbies. Within this progression, the worker has learned about the subtleties of tumor detection and helped to author materials that propagate this knowledge throughout the system. We believe that online learning that doubles as work (and vice versa) can have a transformative impact on the future of work and education.\nOptimizing Effective Utilization of Social Services\nOn average, the poorest 20% of American families earn only $7,600 before taxes - approximately half of the federal poverty line for a 2-person household[19]. In addition to the obvious relationship between poverty and the difficulty meeting basic needs such as food, clothing and shelter, negative effects ripple out into other areas of well-being such as education, domestic abuse, and mental and physical health. While many state and federal programs exist to try to address issues related to poverty through social welfare programs, a family’s burden of accessing those appropriate programs is often prohibitively high. At present, if a family is eligible for multiple services, they must be aware that the service exists, and then make and keep individual intake appointments with each potential service provider. This is grossly inefficient. Indeed, navigating the existing system represents a disproportionate hardship for marginalized populations such as homeless individuals, people with disabilities, and the working poor, groups that are most likely to benefit from these very programs.\nFigure 4: Optimizing Effective Utilization of Limited Social Services project diagram\nOptimizing Effective Utilization of Limited Social Services\nAn efficient, distribution network of providers,\nclients, and intermediate care workers that could help optimize the disbarring,\nallocation, and provision of service to those in need\nWiki\nAwareness of currently available services\nPrediction markets\nResource Allocation and Matchmaking\nPredict and articulate\nupcoming service demands and availability\nStream lining service provision\nAggregation / Crowdsource\nMarketplaces Recommended Systems\nTelepresence / Scheduling\nOnline tutoring systemsWaze\nMicrolanding\nPrivacy\nU.S. Department of Children and\nFamilies\nLoss of confidentiality and\nparticipation\nUtilization of Limited Social Services\nIt’s hard to know what services are\navailable at any\ngiven time; dynamic landscape\nIf people ask for help\nand don’t get it, they lose faith in support\nsystems and problems get\nworse\nAssigning cases to known recoveries is complex\nand services can become\ncostly\n7\nImagine if instead of requiring those in need to learn about each individual service and then travel to individual offices to check their eligibility, we were to harness the power of communities to solve this problem. Innovation in the area of human computation could make this possible. First, crowdsourcing platforms could be leveraged to aggregate and centralize information about all social welfare programs. This would include information such as eligibility requirements and real-time availability of the service (i.e. number of beds available in a drug treatment program and wait lists for mental health services.). The next step would be to streamline the process of verifying eligibility and bringing the process out of city hall and back into the community by empowering community members to serve as liaisons. If liaisons have full access to the centralized system and the ability to facilitate the enrollment process, a family no longer has to provide information multiple times and would become aware of the broad range of services available in their area. Through the use of both virtual and in-person human processing power, the solution to this resource allocation problem may well be within our grasp.\nIn just this past year, we have seen the dramatic impact of a similar technical challenge of health insurance enrollment through the Affordable Care Act. However, as evidenced by the frustrating roll-out of healthcare marketplaces, it is clear that the problem of coordination across multiple disparate agencies is nontrivial. Additionally, the process of verifying eligibility for social services is somewhat more complex than eligibility for health insurance subsidies, which are based solely on income. Because of these additional challenges, the intentional and efficient incorporation of human intervention is a necessary component of any successful solution. The benefits to streamlining access to social welfare programs could be enormous. With nearly $1 trillion spent by state and federal governments to fund social welfare programs, we can stand to gain in efficiency by streamlining information flow about access to these resources.\nPredicting Technology Trends\nNew technology is often a disruptive economic force, because it is hard to understand and can be enormously hyped. The resultant market volatility creates great\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n8\nupheaval in the economy and in workers’ lives. To fix problems such as these, and help avoid financial crises due to overinvestment in technology startups, we need to be able to better estimate when is the right time to invest in technology.\nToday, tech news travels through news sites and is analyzed by domain experts but not necessarily technology experts. For example, in 2012, there were expectations about a meteoric rise in Massive Open Online Courses (MOOCs). There were fears that they would upset traditional universities by the over investment of money and time in their development, such as San Jose State University’s heavily publicized but failed efforts [21]. The idea was good, but it was not the right time for heavy investment. To fix problems such as these, we need to be able to better estimate when is the right time to invest in technology.\nAlthough knowing the future with certainty is of course impossible, it is possible to make much more informed forecasts of technological impact – driven by data, research, and expertise in the dynamics of technological growth. For example, IARPA (Intelligence Advanced Research Projects Activity) in the Office of the Director of National Intelligence has been successfully predicting political events in efforts such as The Good Judgment Project. Meeting participants proposed to do the same for technology foresight, using technology experts and models of growth in the technology sector.\nThe crowdsourcing research challenges involve identifying the right experts in the crowd and building interactive machine learning models that can be trained and improved over time. Right now, only people with the right knowledge can inform these models, and these people are spread across the world. We envision developing a platform that will bring together and organize this knowledge from experts. The collective knowledge would be used to develop models with much better predictive accuracy. Access to this information will ensure steady technological investing and provide protection against devastating tech bubbles.\nUpRiver\nAround the world, humanitarian teams are constantly responding to devastation caused by extreme events. For example, exceptional rainfall upstream can wreak havoc on those living in the floodplains. There are many attempts to design and implement early warning systems, but too often vulnerable communities do not access, understand, or trust the information produced by others.\nThe Red Cross Red Crescent Climate Centre, in collaboration with the Engagement Lab at Emerson College and partners in developing countries, is developing the pervasive game “UpRiver,” which extends into the real world and aims to:\n◗ Improve river level data collection (and thus\nhydrological models to predict floods)\n◗ Increase chances of communities trusting and acting\non early warnings\nUpRiver utilizes people as sensors, that is, players observe real-world river levels and report the levels via text message service. Players can also submit their ‘forecast river level’ (a guess) with a certain lead time (for example 48 hours). Whoever submits the forecast that is closest to the observed value wins an imaginary point. Players can use data from upstream communities to try to improve their forecasts.\nEventually when a good-enough predictive hydrological model is developed, the model will be added as a player (“Mike”). Participants who submit their forecast before the deadline (for example 8am) will receive a text message one minute after the deadline, indicating Mike’s submission. Players that perform better than the model also earn a point. This will help people notice that the model tends to be accurate and trust the information. For example, if river levels are rising, and Mike predicts the river level to be ~3 meters above their home’s kitchen floor, they would be more likely to act on that information. Eventually the trust earned through gameplay should help communities take the\n9\nFigure 6: UpRiver project diagram – local involvement in river level monitoring builds trust in early warning system\nearly warning seriously. More information about this evolving initiative is available online1. At the end of the rainy season, the player who earned the most points within each community exchanges them for a prize – something of monetary value (cash, mobile phone credit, etc.). We believe this gives people incentives to read river gauges and engage in collecting and submitting data. This kind of game will simultaneously improve models and increase trust in those models, saving property and lives. A suitable deployment venue would be the Climate Centre’s promising flood risk management project in West Africa, in collaboration with the Togo Red Cross2. With proper support, the next steps would be to refine the game concept, deploy the game to the Mono River Basin in Togo, and add a research layer to investigate the efficacy of the proposed human computation approach. There are also opportunities to infuse human computation approaches to the development of the predictive hydrological model, for example distributing tasks to pre-calculate flood scenarios by running numerous simulations in a decentralized fashion.\nUpRiver\nRed Cross Red\nCrescent\nMobile data collection with low technological\nresources\nField test a game that will gather data, improved river\nhydrology model and help resources\nallocation\nScalable, replicable, transferable\nData analytics & visualizations\nMobile game app challenges\nresidents to predict rain impact\nPilot utilize\nin-place red cross volunteer\nEmpowers local residents to measure\nriver height and predict impacts\nCrowdsourcing\nRed Cross ResourcesLives Saved!\n1 http://engagementgamelab.org/projects/upriver/ 2 http://www.climatecentre.org/site/news/456/togo-red-cross-prepared-for-preparedness\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n10\nExploiting Coated\nAntisocial Computing\nSocial media and digital communication tools have largely been considered positive vehicles of change. However, the power of social media has been harnessed by extremists and terrorist groups to spread propaganda and influence mass thinking. As our government and corporations begin to rely more and more on social media and online crowdsourcing for situational awareness and data, they will need to be able to identify, track in real time, and mitigate the risks. Existing approaches to cyberthreat assessment and mitigation strategies overlook the societal aspect, which warrants the need for novel human computational methods.\nA social network can be exploited to cause mayhem, ranging from cyber to physical attacks on individuals or corporations, to causing widespread social unrest or panic. The agents behind such exploits could be motivated by money (e.g., through extortion or market manipulation), antisocial tendencies, or they may be acting as agents of a terrorist group or an unfriendly nation state.\nSetting up and conducting such an operation was a fundamental engineering problem (a field participants termed “disinformation engineering”), involving identifying desired outcomes, formulating strategies to achieve those outcomes, and then taking corrective measures when things don’t go according to plan. It\nAntisocial Computing\nFigure 7: Antisocial Computing project diagram – disinformation campaigns are enabled by HC technology\nDisinformation Engineering Crafting disinformation that: 1. Gets picked up. 2. Gets propagated and enhanced 3. Has desired effect on behavior 4. Survives possible counter measures\nDISINFORMATION\nCreating Addicted\nParticipants\nMixed Haran/BoT\nNets\nPrivacy Protections\nReal time\nfalsehood detection e.g.,\npattern and structure\nTruth Injection\nRun or Control\nBoT Detection\nQA/QC venfication validation\nRealtime & forensic\ndetection of attach\nGood BoT\nantibodies injected\nVolunteer vetting\nRealtime data repair\nHijack Social Media\nCorrupt Crowdsourced\nDataDeniability Anticipate Corruption Commuaretics linguistics\nSucker Identified\nStructural Social Trust\nAI: Machine Learning\nPsych\nManipulation of perception and\nbehavior\nCognitive Security\n• Security • Trust • Reliability\nAmazing Opportunities\nWar Extortion Stock Manipulation Extortion Mayhem\nHC System Vulnerability\nGriefer recruitment\nSABOTAGE Participatory\nprocesses Introducing\nmisinformation, misdirection, other deception, discourage\nparticipation\nUnderstanding Social Media\nPropagation and Distortion\nCommented gullible humans\nGriefer recruitment Sociopath BoT\n11\nis only by understanding the technological innovations behind disinformation engineering that we can engineer protective technologies.\nSome elements of an attack would include:\n◗ Preparing a social network that would enable\ncascading communication patterns that would rapidly amplify small seeds of disinformation on a global scale. This network could consist of gullible people (a.k.a. “suckers”) inclined to believe the planted information, people inclined to cause trouble (“griefers”) and computerized agents (“sociopathic bots”).\n◗ Manipulating the network through planted\ndisinformation, dynamically steering the communications toward the desired outcomes. Here, the bots and griefers could serve as the active agents, while the suckers innocently propagate and corrupt the information they receive.\n◗ Guarding against attempts by others to intervene\n(e.g., by planting truthful or counter information or by attempting to expose the agents and their conspirators).\nSuch a scheme would require careful design and an understanding of how people interact in social networks in order to manipulate those systems. Just as the adoption of networked information systems has led to entire new categories of disruption by cyber attack, human computation systems, especially social networks are already being exploited by malicious agents.\nThese ideas are further fleshed out in the article, “Antisocial computing: exploring design risks in social computing systems.”[20]\nA New Set of Questions These multi-day project explorations led to numerous useful insights about the new research challenges posed by human computation. When humans become part of the computational process, five new lines of inquiry arise: participation, analysis, architecture, design methods, and infrastructure.\nParticipation\nIn contrast to the deterministic computing systems of today, humans have operating characteristics that vary from one individual to another. Moreover, human behavior is governed by a complex set of psychological and social phenomena. Therefore, the success of any system with humans in the loop depends heavily on a detailed and accurate understanding of factors related to participation. The following research questions seek to address this need:\n◗ What are the ethical, legal, and social implications\n(ELSI) of human computation? What new issues arise in security, privacy, intellectual property, and fair labor practices and how should they be addressed? What are the roles, stakeholders, and power differentials that arise and how should we define best practices?\n◗ How can systems be designed to be humanistic, that\nis, to ensure meaningful, dignified human participation? [22]\n◗ What are the incentives that will attract and sustain\na sufficient population of participants with the right skills to ensure a significant impact on the problem at hand?\n◗ What are the most effective mappings between\nincentive models and project types to increase participation and effort?\n◗ What are best practices in designing and governing\na participatory system? For example: identify stakeholders, participant populations, a set of specific and overarching goals for the type of environment being developed, and then design to account for audience motivation and behaviors.\n◗ How can methods be tailored and diffused to enable\nthe poorest and most vulnerable sectors of the global population to engage in and benefit from human computation?\nAnalysis\nIn many online systems, computation can be emergent rather than engineered[24]. In other words, information can arise through analysis as a useful byproduct of a\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n12\nlarge population of interacting individuals. For example, when people receive tweets as input in Twitter and produce tweets as output, the resultant activity traces can be analyzed in goal-directed ways, such as to predict events. The need for relevant analytic methods leads to the following questions:\n◗ How can the mechanisms that underlie individual\nhuman behavior be revealed by online activity traces?\n◗ How do such mechanisms inform models of collective\nbehavior that arise from technology-mediated interactions among many individuals?\n◗ What useful information and outcomes can be derived\nfrom collective behavior?\n◗ What are best practices for measuring and classifying\nonline social behavior for assessing its societal impact?\n◗ How can the analysis of emergent collective behavior\nhelp inform the design of human computation systems?\nArchitecture\nEngineering new, effective human computation systems will require a conceptual framework for making highlevel design decisions that address these questions:\n◗ What classes of problems are most effectively\naddressed by human computation approaches? In other words, when is it appropriate to use human computation?\n◗ Which architectural approaches are best suited to\nwhich problems (e.g., in crowdsourcing, sometimes we may wish to reassemble many individual human products into a single aggregate product, while in other cases, we may seek to identify the single best product)?\n◗ What is the optimal division of labor between\nmachines and humans that will result in a specific capability?\n◗ How can machine capabilities be put to use for\nmanaging and evaluating the impacts of individual human variation?\n◗ Given the variability of human behavior, what\ncan we assert about the expected performance characteristics of the planned system? For example, how might we reliably estimate upper and lower performance bounds?\nDesign Methods\nEven with sound architectural principles in place, the core functionality of new human computation systems must be designed case by case. Both positive and negative examples of human computation design patterns currently exist. The following questions point to theoretical and empirical work that is needed to support repeatable methods that would ensure higher success rates.\n◗ What are the basic project typologies, associated\ntechniques, and interaction modalities?\n◗ How do we design workflow architectures that most\neffectively combine human and machine input toward desired capabilities? How do we design to support emergent behaviors?\n◗ system from malicious behavior? What is the\npotential impact on participants? How do we track such behavior in real time and what are effective countermeasures?\n◗ How can expertise among participants be identified\nand leveraged?\nInfrastructure\nThe ability to answer the research questions above and create new human computation systems efficiently critically depends upon the existence and broad availability of specialized tools and network enhancements. The following research questions support the development of such human computation infrastructure:\n◗ How do we build integrated software development\nenvironments (IDEs) that allow us to write, test, execute, and reuse code that operates on distributed human/machine systems?\n13\n◗ How can we simulate human behavior in an IDE to\nreduce the financial and logistical costs of testing such systems before engaging potentially costly human participants?\n◗ What embellishments are needed to the current\ninfrastructure (e.g., Internet, communication protocols, etc.) that will enable always-on, asynchronous human participation?\nEmerging Research A broad smattering of loosely connected research activities (the large yellow band in Figure 8) has begun to address this list of research questions. However, most of these pursuits occur in isolation and ignorance of each other, due to their distinctive disciplinary origins\n(see “Enabling Disciplines” and “Relevant Sub-Fields” bands in Figure 8) and consequent publication in narrowly scoped journals. Fortunately, these conditions are improving due to the open call to include other disciplines at the AAAI HCOMP conference and the new transdisciplinary journal Human Computation.\nFunding Environment Despite these improvements in scientific communication, there is a paucity of U.S. federal funding for human computation research. The few counterexamples to this (e.g., the Cyber-Human Systems and Cyberlearning programs at the National Science Foundation) are notable for their pioneering vision. Furthermore, human computation, which often lies near the conceptual\nFigure 8. High-impact societal benefits will be supported by a scaffolding of new human computation research.\nIM PA CT NE W C AP AB IL IT IE S [W /E XA M PL ES ]\nEM ER\nGI NG\nRE\nSE AR\nCH A\nRE AS\nRE LE\nVA NT\nSU\nBFI\nEL DS\nEN AB\nLI NG\nDI\nSC IP\nLI NE\nS\nProject Human Rights Stimulate Economy Improve Health Outcomes\nAmplify Crisis Relief Alleviate Poverty Preserve Earth-System Reduce Global Conflict Educate All\nEnhanced Groups\n• Ushahidi\nUbiquitous Sensing • Urbanopoly\nCrowdsourcing Marketplaces\n• Amazon Mechanical Turk\n• CrowdFlower\n• Applause\nCrowdfunding/ Microlending\n• Kickstarter • Women’s Microfinance Initiative\n• SHARE\n• KIVA\n• Indiegogo\nCollaborative Innovation\n• topcoder\n• innocentive\n• FabLab\nDistributed Knowledge Collection • Wikipedia\n• DBpedia\nQuid Pro Quo Applications\n• reCAPTCHA • duoLingo\nSocial Prediction • Google Flu\nTrends\nCitizen Science • fold.it • eBird\n• YardMap • MalariaSpot\n• Near-Earth Asteroids Precovery • EyeWire\n• GalaxyZoo • St. Louis Baby Tooth Project\nInfrastructure • HC code libraries and APIs\n• hybrid human/ machine state space\n• security • networks and protocols • human-based services\n• Web of Agents • privacy-preserving\nframeworks • infrastructure reuse\nArchitecture • design patterns • human/crowd\nsimulation • HC complexity\n• emergent behavior design • organismic computing • task-specific methods\n• hybrid machine learning • best practices\nParticipation • reputation systems\n• engagement methods • games with a purpose\n• competitions • local/online reciprocity\n• social influence • graduated reward systems\n• certification systems • gamification\n• sustainable market design\nAnalysis • social synchrony\n• social network analysis • analytical gaming • hybrid prediction\nmarkets • marketplace recommender\nsystems • online skill assessment\n• mashups • Group IQ\nDesign Methods • collaborative modeling\n• collective/coordinated action • aggregation methods\n• wisdom of crowds • distributed knowledge engineering\n• distributed problem solving • concept decomposition/fusion\n• citizen science • participatory sensing\n• predictive modeling\n• knowledge engineering • informatics\nnetwork theory\n• computational complexity\n• distributed computing • software engineering\n• swarm intelligence\n• machine learning\n• distributed artificial intelligence\n• cognitive neuroscience\n• cybernetics\n• epistemology\n• ethics\n• cultural modeling\n• sociobiology\n• evolutionary biology\n• social psychology\n• mechanism design • motivation theory\n• game theory\n• collaboration workflows\n• cognitive architecture\n• information theory\n• augmented reality\n• telepresence\n• data visualization\nInformation Science Cognitive Science Sociology Operations Research\nComputer Science Biology Behavioral Economics Human-Computer Interaction\nStatistics Complexity Science Philosophy Psychology Computer-Supported Cooperative Work\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n14\nperimeter of established disciplines, is often at a disadvantage in competing for core program funding because there are relatively few qualified reviewers with sufficiently interdisciplinary backgrounds to evaluate the soundness of such proposals.\nThe situation is improving but not quickly enough. As a step in the right direction, the second recommendation of the 2013 President’s Council of Advisors on Science and Technology (PCAST) report called for an interagency initiative to explore cross-agency collaboration in Social Computing [24]. This resulted in the formation of a Networking and Information Technology Research and Development (NITRD-SEW) subcommittee for Social Computing that brings together national funding agency representatives on a regular basis to learn more about ongoing work in this area. Fortunately, this seems to be engendering greater acceptance of the field and increasing awareness of related research. However, new funding programs have not yet directly resulted from this activity.\nNational Initiative We believe that the rapid advancement of this field toward repeatable and sustainable success models requires a concerted effort by policy-makers, federal funding agencies, multidisciplinary research institutions, private industry, and the public (via direct participation). Only through the collective action of these organizations and entities can we hope to endow human computation with the full apparatus of scientific inquiry and methodological maturity necessary to conscientiously[25] leverage the full transformative power of this new technology.\nFurthermore, we advocate the creation of a national center for human computation, analogous to the National Socio-Environmental Synthesis Center (SESYNC), but dedicated to solving societal problems by bringing together different disciplines and stakeholders to develop human computation methods and capabilities. Due to the transdisciplinary nature of the field, we believe such a center would best support the rapid advancement of methods that might not be easily pursued in narrower contexts.\nToward these ends, we propose a new national initiative in human computation, with policy and funding support at all levels, to broaden and accelerate the research and development of collaborative information processing systems that leverage the respective strengths of machines and humans toward unprecedented capabilities to address our nation’s and, indeed, humanity’s most pressing societal needs.\nContributors Organizing Committee\n◗ Pietro Michelucci, chair, Executive Director, Human\nComputation Institute\n◗ Janis Dickinson, Professor of Natural Resources,\nCornell University; Director of Citizen Science, Cornell Lab of Ornithology\n◗ Haym Hirsh, Dean of the Faculty of Computing and\nInformation Science, Cornell University\n◗ Lea Shanley, Former Director, Commons Lab of the\nScience and Technology Innovation Program, Woodrow Wilson International Center for Scholars\nProgram Committee\n◗ Matthew Blumberg, Executive Director, GridRepublic ◗ Michael Witbrock, VP for Research, Cycorp\nCCC Liaisons\n◗ Ann Drobnis, Director, Computing Community\nConsortium\n◗ Randal Bryant, Dean of the School of Computer\nScience, Carnegie Mellon University\nPolicy Keynote\n◗ Tom Kalil, Deputy Director for Technology and\nInnovation, Office of Science and Technology Policy, The White House\nFacilitators\n◗ Luke Hohmann, Lead Facilitator, Sunni Brown Ink ◗ Stacy Weitzner, Live Visual Capture Facilitator, Sunni\nBrown Ink\n15\nWorkshop Support Staff\n◗ Melissa Gedney, Woodrow Wilson International Center\nfor Scholars\n◗ Elizabeth Tyson, Woodrow Wilson International Center\nfor Scholars\n◗ Helen Vasaly Wright, Computing Community\nConsortium\nComplete List of Participants\n◗ Dave Ackley, UNM CS ◗ Nitin Agarwal, University of Arkansas at Little Rock ◗ Larissa Albantakis, UW Madison ◗ Mary Catherine Bateson, George Mason University ◗ Nancy Baym, Microsoft Research ◗ Steven Becker, NIH ◗ Paul Bennett, Microsoft Research ◗ Andrew Bernat, CRA ◗ Abraham Bernstein, University of Zurich ◗ Jeff Bigham, Carnegie Mellon University ◗ Matthew Blumberg, GridRepublic ◗ Tom Boellstorff, University of California, Irvine ◗ David Brin, Science Fiction Novelist ◗ Sunni Brown, Sunni Brown Ink ◗ Randal Bryant, Carnegie Mellon University ◗ Edward Castronova, Indiana University ◗ Yiling Chen, Harvard University ◗ Adam Cheyer, Change.org ◗ Lydia Chilton, University of Washington ◗ Noshir Contractor, Northwestern University ◗ R. Jordan Crouser, MIT Lincoln Laboratory ◗ Kevin Crowston, National Science Foundation ◗ Janis Dickinson, Cornell ◗ Steven Dow, HCI Institute, Carnegie Mellon ◗ Edmund Durfee, University of Michigan ◗ Hamid Ekbia, Indiana University ◗ Christina Engelbart, Doug Engelbart Institute ◗ Michael Franklin, UC Berkeley ◗ Liane Gabora, University of British Columbia ◗ Susan Graham, University of California, Berkeley ◗ David Alan Grier, George Washington University ◗ Greg Hager, Johns Hopkins University ◗ Haym Hirsh, Cornell University ◗ Luke Hohmann, Sunni Brown Ink ◗ Panos Ipeirotis, New York University\n◗ Tom Kalil, White House OSTP ◗ Geoff Kaufman, Tiltfactor Laboratory, Dartmouth\nCollege\n◗ Markus Krause, Leibniz University ◗ Debbie Lockhart, NSF ◗ Stuart Lynn, Adler Planetarium / Zooniverse ◗ Thomas Malone, MIT ◗ Mimi McClure, NSF ◗ David McDonald, University of Washington ◗ Pietro Michelucci, Human Computation Institute ◗ Beth Mynatt, GT Institute for People and Technology ◗ Theodore (Ted) Pavlic, School of Life Sciences, Arizona\nState University\n◗ Nathan Prestopnik, Ithaca College ◗ Lea Shanley, Science and Technology Innovation\nProgram, Wilson Center\n◗ Yiyang Shen, CRA ◗ Katie Shilton, University of Maryland College Park ◗ Paul Smaldino, Johns Hopkins University ◗ Nigel Snoad, Google Crisis Response ◗ Ram Sriram, NIST ◗ George Strawn, NITRD ◗ Pablo Suarez, Red Cross Red Crescent Climate Centre ◗ Seth Teicher, CrowdFlower ◗ Shailin Thomas, Berkman Center for Internet and\nSociety, Harvard University\n◗ Mike Webster, Macaulay Library, Cornell University ◗ Andrea Wiggins, DataONE ◗ Michael Witbrock, Cycorp Inc\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n16\nReferences [1] P. Michelucci, “Synthesis and Taxonomy of Human\nComputation,” in Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 83–86.\n[2] S. Kunst, “Is Crowdsourced Labor the Future of Middle\nClass Employment?,” The Daily Beast, 26-Mar-2014. [Online]. Available: http://www.thedailybeast.com/ articles/2014/03/26/is-crowdsourced-labor-the-futureof-middle-class-employment.html. [Accessed: 02-Feb2015].\n[3] J. Chandler, G. Paolacci, and P. Mueller, “Risks and\nRewards of Crowdsourcing Marketplaces,” in Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 377–392.\n[4] I. Garcia, “Learning a Language for Free While\nTranslating the Web. Does Duolingo Work?,” Int. J. Engl. Linguist., vol. 3, no. 1, Jan. 2013.\n[5] L. Bennett, B. Chin, and B. Jones, “Crowdfunding: A\nNew Media & Society Special Issue,” New Media Soc., p. 1461444814558906, Nov. 2014.\n[6] S. L. McKinnon, E. Dickinson, J. N. Carr, and K. R.\nChávez, “Kiva.org, Person-to-Person Lending, and the Conditions of Intercultural Contact,” Howard J. Commun., vol. 24, no. 4, pp. 327–347, Oct. 2013.\n[7] J. L. Dickinson and R. Bonney, Eds., Citizen Science:\nPublic Participation in Environmental Research, 1 edition. Ithaca: Comstock Publishing Associates, 2012.\n[8] A. E. J. Wals, M. Brody, J. Dillon, and R. B. Stevenson,\n“Convergence Between Science and Environmental Education,” Science, vol. 344, no. 6184, pp. 583–584, May 2014.\n[9] J. Lee, “Six Citizen Science milestones from 2014 –\nnumber four is out of this world,” Cancer Research UK - Science blog. [Online]. Available: http://scienceblog. cancerresearchuk.org/2014/12/18/six-citizen-sciencemilestones-from-2014-number-four-is-out-of-thisworld/. [Accessed: 02-Feb-2015].\n[10] C. R. Beal, C. T. Morrison, and J. C. Villegas, “Human\nComputation as an Educational Opportunity,” in Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 163–170.\n[11] C. Rosen, “Neighborhood leaders play game to help\nSan Jose prioritize budget.” [Online]. Available: http:// www.mercurynews.com/san-jose-neighborhoods/ ci_19882023. [Accessed: 02-Feb-2015].\n[12] S. E. Alhabash and K. Wise, “PeaceMaker: Changing\nStudents’ Attitudes Toward Palestinians and Israelis Through Video Game Play,” Int. J. Commun., vol. 6, no. 0, p. 25, Mar. 2012.\n[13] P. Meier, “Human Computation for Disaster Response,”\nin Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 95–104.\n[14] A. F. Dugas, M. Jalalpour, Y. Gel, S. Levin, F. Torcaso, T.\nIgusa, and R. E. Rothman, “Influenza Forecasting with Google Flu Trends,” PLoS ONE, vol. 8, no. 2, Feb. 2013.\n[15] C. B. Eiben, J. B. Siegel, J. B. Bale, S. Cooper, F. Khatib,\nB. W. Shen, F. Players, B. L. Stoddard, Z. Popovic, and D. Baker, “Increased Diels-Alderase activity through backbone remodeling guided by Foldit players,” Nat. Biotechnol., vol. 30, no. 2, pp. 190–192, Jan. 2012.\n[16] F. Khatib, F. DiMaio, F. C. Group, F. V. C. Group, S. Cooper,\nM. Kazmierczyk, M. Gilski, S. Krzywda, H. Zabranska, I. Pichova, J. Thompson, Z. Popović, M. Jaskolski, and D. Baker, “Crystal structure of a monomeric retroviral protease solved by protein folding game players,” Nat. Struct. Mol. Biol., vol. 18, no. 10, pp. 1175–1177, Oct. 2011.\n[17] K. Long, “Gamers helping UW in Ebola research,” The\nSeattle Times. [Online]. Available: http://seattletimes. com/html/localnews/2024389152_folditebolaxml.html. [Accessed: 02-Feb-2015].\n[18] R. J. Crouser, B. Hescott, and R. Chang, “Toward\nComplexity Measures for Systems Involving,” Hum. Comput., vol. 1, no. 1, Sep. 2014.\n[19] “The Distribution of Household Income and Federal\nTaxes, 2008 and 2009,” Jul. 2012.\n17\n[20] D. W. McDonald, D. H. Ackley, R. Bryant, M. Gedney,\nH. Hirsh, and L. Shanley, “Antisocial computing: exploring design risks in social computing systems,” Interactions 21, 6 (October 2014), ACM, pp. 72-75.\n[21] T. Lewin, “After Setbacks, Online Courses Are\nRethought,” The New York Times, 10-Dec-2013.\n[22] R. Goolsby, “On cybersecurity, crowdsourcing, and\nsocial cyber-attack,” 1, 2013.\n[23] G. Chamales, “Towards Trustworthy Social Media and\nCrowdsourcing,” 2.\n[24] M. Witbrock, “Infrastructure and Architecture for\nHuman Computer Intelligent Collaboration,” in Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 505–508.\n[25] K. Lerman, “Analysis: An Introduction,” in Handbook of\nHuman Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 745–749.\n[26] P. Michelucci, “Human Computation: A Manifesto,” in\nHandbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 1021–1038.\n[27] L. von Ahn and L. Dabbish, “Labeling Images with\na Computer Game,” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, New York, NY, USA, 2004, pp. 319–326.\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n18\nAppendix: The Visioning Process Overview\nThe goal of the three-day summit was to reveal research areas and opportunities that would lead to the design of human computation systems that generate high impact societal outcomes. Beginning with agreed-upon societal outcomes, we worked backwards to develop candidate solutions that would be enabled by human computation. The resulting catalog of such methods, in turn, pointed to the need for fundamental research in a specific set of domains. We hoped that mapping the fundamental research to new capabilities and outcomes would help inform a new national initiative leading to the anticipated societal benefits. Figure 9 depicts the intended three-day path for arriving ultimately at a comprehensive research roadmap that would connect fundamental research to new capabilities that address societal challenges.\nWe used participatory gaming, discourse, and introspective/collaborative analysis to examine motivation at different scales and stimulate innovation.\nThis set the stage for collaborative analysis of additional material throughout the process.\nShared Context\nIn this vein, Day 1 was kicked off with a simulation game conducted by participatory gaming expert Pablo Suarez of the Red Cross Red Crescent Climate Centre, which allowed workshop participants to directly experience aggregate and individual outcomes associated with participating in a human computation system, as well to observe their own responses to shifting incentive structures. The rest of the morning was a combination of presentations and lightning talks (see Figure 10).\nThese served both to set a historical context for discussing human computation and to get to know participants through the lens of their individual perspectives on the topic. Figure 11 is a “live visual capture” of highlights from the opening session, while Figure 12 depicts key concepts from participant presentations.\nFigure 9: Path of workshop activities leading to integrated research roadmap.\n19\nFigure 10: Sample of four slides from lightning talks.\nFigure 11: Live visual capture of the opening session of the Human Computation Roadmap Summit.\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n20\nProblems and Solutions\nThe afternoon session of Day 1 was filled with participatory activities that generated introspection and sharing of personal motivations under the assumption that creative approaches arise out of meaning. This led to a multidimensional, generative analysis of societal\nproblems ranging from somewhat tractable issues to wicked problems rife with uncertainties, feedbacks, and complexities that are poorly understood. This exercise, in turn, set a context for brainstorming about new human computation solution concepts. The live visual capture of this session’s activities is illustrated in Figure 13.\nFigure 12: Live visual capture of key concepts from invited speakers.\nFigure 13: Live visual capture of societal problem and solution generation activities.\n21\nSolution Concept Development\nDay 2 began with a risk analysis exercise aimed at revealing the worst case scenarios associated with human computation system development. This was intended to bring awareness to the importance of incorporating risk analysis into emerging solution concepts. Next, participants were invited to aggregate around solutions of interest to form solution concept development teams. Eight solution teams self-organized to flesh out their human computation ideas (see Figure 14 and Figure 15) and prepared to present those ideas in the session that followed.\nIn the afternoon session, teams presented their concepts (Figure 16) to Tom Kalil (Figure 17), who provided constructive feedback through the lens of a policymaker. This helped sharpen ideas and increased their accessibility to relevant audiences.\nIn addition to specific feedback about each solution concept, Tom Kalil provided general feedback by suggesting that the groups narrow the scope of the proposed solutions to more specific implementable projects. The activities of Day 2 are captured in Figure 19.\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n22\nSuccess Cases and Solution Refinement\nKalil’s feedback suggested a deviation from the original plan for Day 3 activities. Originally, the third day of the workshop had been designated for integrating the new solution concepts into a single coalescent research roadmap for human computation. Instead, we responded\nto Kalil’s feedback by using Day 3 to further refine the solution concepts and relegate the roadmap integration to post-workshop activities that would be left to the organizers. This detour is depicted in Figure 18.\nAdditionally, a decision was made to develop roadmap diagrams for recent human computation success cases\nFigure 18: Kalil’s feedback suggested a course-correction for Day 3 of the workshop to further concretize the solution tracks.\nFigure 19: Live visual capture of Day 2: Individual solution generation and pitch feedback from Kalil.\n(Figure 20) prior to developing such diagrams for the workshop-generated solutions. This served two purposes: 1) a deep technical assessment of the success cases helped inform a down-select of the workshop-generated solutions to those most amenable to the recommended scoping, and 2) the full set of solution diagrams, including\nboth old and new, would help ensure a more complete and representative assessment of the underlying research space.\nFoundations Individual/ Group Values Societal Problems Solution Tracks\nRisk Analysis\nPitches/ Feedback\n(Kalil)\nSolution Refinement\nRoadmap Coalescence\nSuccess Stories\nSolution Refinement DET O\nUR\n23\nPablo Suarez kicked off Day 3 with a fast-paced participatory game called “Snap!”, which might be described as an offline, concept-based implementation of the “ESP game”[26], designed to achieve some measure of descriptiveness and consensus around the term “Human Computation”. The results of this exercise are presented in Figure 21 as a word cloud.\nFigure 20: Roadmap diagram for human computation success story.\nOnce the roadmap diagrams were produced for both historical success cases and the workshop-generated ideas (e.g., Figure 22), the workshop concluded.\nExample: Malaria Diagnosis\nA global network of virtual “malaria hunters”\ncould help with the routine job of diagnosing\nmalaria everywhere.\nParasite detection training/\ncorroboration\nMassive Participation\nContinuity/ Consistency of\nService Gamification\nScalable, fast, ubiquitous\nand accurate screening\n100 images/ patient\nAggregation/Crowdsourced QA\nMechanism Design\nDistributed Computing\nHCI\nProtein Folding Bigham: Realtime Crowd Support\nGalazyZoo\nBOSSA: Stardust@home\nAfrican Clinics\nFalse negative\nUntreated patient\nOne child dies every minute\nMalaria\nA single diagnosis\ntakes a specialist\n30 minutes using a microscope to count parasites\nIf a patient leaves clinic\nwithout a diagnosis, it is unlikely that s/he will receive treatment Not enough specialists to have one at each clinic\n70% reduction in undiagnosed cases. 40% reduction in untreated cases. 130,000 lives saved/year\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n24\nFigure 22: Roadmap diagram for new human computation solution.\nThe success cases and new ideas that were selected and diagrammed in Day 3 are visually summarized in Figure 23. However, the new project ideas are detailed in the body of this report.\nFigure 23: Live visual capture of historical human computation success stories and new human computation solution ideas.\n25\nA U.S. RESEARCH ROADMAP FOR HUMAN COMPUTATION\n26\nNotes:\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n____________________________________________________________________________________________\n1828 L Street, NW, Suite 800 Washington, DC 20036 P: 202 234 2111 F: 202 667 1066 www.cra.org cccinfo@cra.org"
    } ],
    "references" : [ {
      "title" : "Synthesis and Taxonomy of Human Computation",
      "author" : [ "P. Michelucci" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 83–86.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Is Crowdsourced Labor the Future of Middle Class Employment",
      "author" : [ "S. Kunst" ],
      "venue" : "The Daily Beast, 26-Mar-2014. [Online]. Available: http://www.thedailybeast.com/ articles/2014/03/26/is-crowdsourced-labor-the-futureof-middle-class-employment.html. [Accessed: 02-Feb- 2015].",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Risks and Rewards of Crowdsourcing Marketplaces",
      "author" : [ "J. Chandler", "G. Paolacci", "P. Mueller" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 377–392.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Learning a Language for Free While Translating the Web. Does Duolingo Work",
      "author" : [ "I. Garcia" ],
      "venue" : "Int. J. Engl. Linguist., vol. 3, no. 1, Jan. 2013.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Crowdfunding: A New Media & Society Special Issue",
      "author" : [ "L. Bennett", "B. Chin", "B. Jones" ],
      "venue" : "New Media Soc., p. 1461444814558906, Nov. 2014.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Kiva.org, Person-to-Person Lending, and the Conditions of Intercultural Contact",
      "author" : [ "S.L. McKinnon", "E. Dickinson", "J.N. Carr", "K.R. Chávez" ],
      "venue" : "Howard J. Commun., vol. 24, no. 4, pp. 327–347, Oct. 2013.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Citizen Science: Public Participation in Environmental Research, 1 edition",
      "author" : [ "J.L. Dickinson", "R. Bonney", "Eds" ],
      "venue" : "Ithaca: Comstock Publishing Associates,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "Convergence Between Science and Environmental Education",
      "author" : [ "A.E.J. Wals", "M. Brody", "J. Dillon", "R.B. Stevenson" ],
      "venue" : "Science, vol. 344, no. 6184, pp. 583–584, May 2014.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Six Citizen Science milestones from 2014 – number four is out of this world",
      "author" : [ "J. Lee" ],
      "venue" : "Cancer Research UK - Science blog. [Online]. Available: http://scienceblog. cancerresearchuk.org/2014/12/18/six-citizen-sciencemilestones-from-2014-number-four-is-out-of-thisworld/. [Accessed: 02-Feb-2015].",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Human Computation as an Educational Opportunity",
      "author" : [ "C.R. Beal", "C.T. Morrison", "J.C. Villegas" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 163–170.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Neighborhood leaders play game to help San Jose prioritize budget.",
      "author" : [ "C. Rosen" ],
      "venue" : "[Online]. Available: http:// www.mercurynews.com/san-jose-neighborhoods/ ci_19882023",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "PeaceMaker: Changing Students’ Attitudes Toward Palestinians and Israelis Through Video Game Play",
      "author" : [ "S.E. Alhabash", "K. Wise" ],
      "venue" : "Int. J. Commun., vol. 6, no. 0, p. 25, Mar. 2012.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Human Computation for Disaster Response",
      "author" : [ "P. Meier" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 95–104.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Influenza Forecasting with Google Flu Trends",
      "author" : [ "A.F. Dugas", "M. Jalalpour", "Y. Gel", "S. Levin", "F. Torcaso", "T. Igusa", "R.E. Rothman" ],
      "venue" : "PLoS ONE, vol. 8, no. 2, Feb. 2013.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Increased Diels-Alderase activity through backbone remodeling guided by Foldit players",
      "author" : [ "C.B. Eiben", "J.B. Siegel", "J.B. Bale", "S. Cooper", "F. Khatib", "B.W. Shen", "F. Players", "B.L. Stoddard", "Z. Popovic", "D. Baker" ],
      "venue" : "Nat. Biotechnol., vol. 30, no. 2, pp. 190–192, Jan. 2012.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Crystal structure of a monomeric retroviral protease solved by protein folding game players",
      "author" : [ "F. Khatib", "F. DiMaio", "F.C. Group", "F.V.C. Group", "S. Cooper", "M. Kazmierczyk", "M. Gilski", "S. Krzywda", "H. Zabranska", "I. Pichova", "J. Thompson", "Z. Popović", "M. Jaskolski", "D. Baker" ],
      "venue" : "Nat. Struct. Mol. Biol., vol. 18, no. 10, pp. 1175–1177, Oct. 2011.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Gamers helping UW in Ebola research",
      "author" : [ "K. Long" ],
      "venue" : "The Seattle Times. [Online]. Available: http://seattletimes. com/html/localnews/2024389152_folditebolaxml.html. [Accessed: 02-Feb-2015].",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2024
    }, {
      "title" : "Toward Complexity Measures for Systems Involving",
      "author" : [ "R.J. Crouser", "B. Hescott", "R. Chang" ],
      "venue" : "Hum. Comput., vol. 1, no. 1, Sep. 2014.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Antisocial computing: exploring design risks in social computing systems",
      "author" : [ "D.W. McDonald", "D.H. Ackley", "R. Bryant", "M. Gedney", "H. Hirsh", "L. Shanley" ],
      "venue" : "Interactions 21, 6 (October 2014), ACM, pp. 72-75.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "After Setbacks, Online Courses Are Rethought",
      "author" : [ "T. Lewin" ],
      "venue" : "The New York Times, 10-Dec-2013.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On cybersecurity, crowdsourcing, and social cyber-attack",
      "author" : [ "R. Goolsby" ],
      "venue" : "1, 2013.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Towards Trustworthy Social Media and Crowdsourcing",
      "author" : [ "G. Chamales" ],
      "venue" : "2.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 0
    }, {
      "title" : "Infrastructure and Architecture for Human Computer Intelligent Collaboration",
      "author" : [ "M. Witbrock" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 505–508.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Analysis: An Introduction",
      "author" : [ "K. Lerman" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 745–749.",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Human Computation: A Manifesto",
      "author" : [ "P. Michelucci" ],
      "venue" : "Handbook of Human Computation, P. Michelucci, Ed. Springer New York, 2013, pp. 1021–1038.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Human Computation is an emerging field that considers the design and analysis of information processing systems in which humans participate as computational agents[1].",
      "startOffset" : 163,
      "endOffset" : 166
    }, {
      "referenceID" : 1,
      "context" : "We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6].",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 2,
      "context" : "We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6].",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 3,
      "context" : "We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6].",
      "startOffset" : 184,
      "endOffset" : 187
    }, {
      "referenceID" : 4,
      "context" : "We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6].",
      "startOffset" : 212,
      "endOffset" : 215
    }, {
      "referenceID" : 5,
      "context" : "We found that human computation methods have stimulated the economy via an online workforce ecosystem[2], which includes crowdsourced labor markets[3], contributive vocational training[4], innovation crowdfunding[5], and microlending to third-world entrepreneurs[6].",
      "startOffset" : 262,
      "endOffset" : 265
    }, {
      "referenceID" : 6,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 7,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 8,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 9,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 10,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 11,
      "context" : ", to encourage health-related behaviors) via social networks[7][8], accelerate research[9], educate the public[10] through citizen science, enable new modes of civic engagement[11] through democratic processes, and reduce geopolitical conflict[12] through participatory gaming.",
      "startOffset" : 243,
      "endOffset" : 247
    }, {
      "referenceID" : 12,
      "context" : ", geographically distributed data acquisition and sharing using mobile devices or sensors) and coordinated action, human computation methods have been employed to save lives by amplifying situational awareness and coordinating rescue actions for crisis relief[13].",
      "startOffset" : 259,
      "endOffset" : 263
    }, {
      "referenceID" : 13,
      "context" : "Furthermore, emergent human computation has been used to improve real-time epidemiology via predictive analytics and to reliably anticipate world events via social informatics[14].",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 14,
      "context" : "it project (see Figure 1), have demonstrated dramatic results[15] using even simple human computation project designs.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 15,
      "context" : "In only a few weeks’ time, it gave rise to the discovery of the tertiary structure of a regulatory protein for the pro-simian immunodeficiency virus (SIV), which previously eluded the research community for decades[16], and now may lead to new medications to treat the AIDS virus.",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 16,
      "context" : "it is generating promising molecular topologies that could lead to treatment targets for the Ebola virus[17].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 17,
      "context" : "Due to the vagaries of human behavior, however, these traditional methodologies are inadequate for human computation[18], which suggests the need for a new approach.",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 19,
      "context" : "There were fears that they would upset traditional universities by the over investment of money and time in their development, such as San Jose State University’s heavily publicized but failed efforts [21].",
      "startOffset" : 201,
      "endOffset" : 205
    }, {
      "referenceID" : 18,
      "context" : "”[20]",
      "startOffset" : 1,
      "endOffset" : 5
    }, {
      "referenceID" : 20,
      "context" : "◗ How can systems be designed to be humanistic, that is, to ensure meaningful, dignified human participation? [22]",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 22,
      "context" : "In many online systems, computation can be emergent rather than engineered[24].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 22,
      "context" : "As a step in the right direction, the second recommendation of the 2013 President’s Council of Advisors on Science and Technology (PCAST) report called for an interagency initiative to explore cross-agency collaboration in Social Computing [24].",
      "startOffset" : 240,
      "endOffset" : 244
    }, {
      "referenceID" : 23,
      "context" : "Only through the collective action of these organizations and entities can we hope to endow human computation with the full apparatus of scientific inquiry and methodological maturity necessary to conscientiously[25] leverage the full transformative power of this new technology.",
      "startOffset" : 212,
      "endOffset" : 216
    } ],
    "year" : 2015,
    "abstractText" : null,
    "creator" : "Adobe InDesign CC 2014 (Macintosh)"
  }
}